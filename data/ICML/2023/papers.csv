forum,title,authors,authorids,keywords,abstract,pdf,match,venue,year,type
https://openreview.net/forum?id=zodnF0pqK7,{'value': 'Semi-Dual Unbalanced Quadratic Optimal Transport: fast statistical rates and convergent algorithm.'},Adrien Vacher; François-Xavier Vialard,~Adrien_Vacher1; ~François-Xavier_Vialard2,,"{'value': 'In this paper, we derive a semi-dual formulation for the problem of unbalanced quadratic optimal transport and we study its stability properties, namely we give upper and lower bounds for the Bregman divergence of the new objective that hold globally. We observe that the new objective gains even more convexity than in the balanced case. We use this formulation to prove the first results on statistical estimation of UOT potentials and we leverage the extra convexity to recover super-parametric rates. Interestingly, unlike in the balanced case, we do not require the potentials to be smooth. Then, use variable metric descent to solve the semi-dual problem for which we prove convergence at a $1/k$ rate for strongly convex potentials and exponential convergence in the balanced case when potentials are also smooth. We emphasize that our convergence results has an interest on its own as it generalizes previous convergence results to non-equivalent metrics. Last, we instantiate a proof-of-concept tractable version of our theoretical algorithm that we benchmark on a 2D experiment in the balanced case and on a medium dimension synthetic experiment in the unbalanced case.'}",https://openreview.net{'value': '/pdf/da802a84cb724bb3c34440fa22e5b6727d786fa9.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=zkdHgAKedJ,{'value': 'An Effective Meaningful Way to Evaluate Survival Models'},Shi-ang Qi; Neeraj Kumar; Mahtab Farrokh; Weijie Sun; Li-Hao Kuan; Rajesh Ranganath; Ricardo Henao; Russell Greiner,~Shi-ang_Qi1; ~Neeraj_Kumar5; farrokn@ualberta.ca; weijie2@ualberta.ca; lihao@ualberta.ca; ~Rajesh_Ranganath2; ~Ricardo_Henao1; ~Russell_Greiner2,,"{'value': 'One straightforward metric to evaluate a survival prediction model is based on the Mean Absolute Error (MAE) – the average of the absolute difference between the time predicted by the model and the true event time, over all subjects. Unfortunately, this is challenging because, in practice, the test set includes (right) censored individuals, meaning we do not know when a censored individual actually experienced the event. In this paper, we explore various metrics to estimate MAE for survival datasets that include (many) censored individuals. Moreover, we introduce a novel and effective approach for generating realistic semi-synthetic survival datasets to facilitate the evaluation of metrics. Our findings, based on the analysis of the semi-synthetic datasets, reveal that our proposed metric (MAE using pseudo-observations) is able to rank models accurately based on their performance, and often closely matches the true MAE – in particular, is better than several alternative methods.'}",https://openreview.net{'value': '/pdf/1bf41d10e72903081168a308b51d0d04731ed740.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=zIVu5Yidhm,{'value': 'Trading-Off Payments and Accuracy in Online Classification with Paid Stochastic Experts'},Dirk van der Hoeven; Ciara Pike-Burke; Hao Qiu; Nicolò Cesa-Bianchi,~Dirk_van_der_Hoeven1; ~Ciara_Pike-Burke2; ~Hao_Qiu2; ~Nicolò_Cesa-Bianchi1,,"{'value': ""We investigate online classification with paid stochastic experts. Here, before making their prediction, each expert must be paid. The amount that we pay each expert directly influences the accuracy of their prediction through some unknown Lipschitz ``productivity'' function. In each round, the learner must decide how much to pay each expert and then make a prediction. They incur a cost equal to a weighted sum of the prediction error and upfront payments for all experts. We introduce an online learning algorithm whose total cost after $T$ rounds exceeds that of a predictor which knows the productivity of all experts in advance by at most $\\mathcal{O}\\big(K^2(\\ln T)\\sqrt{T}\\big)$ where $K$ is the number of experts. In order to achieve this result, we combine Lipschitz bandits and online classification with surrogate losses. These tools allow us to improve upon the bound of order $T^{2/3}$ one would obtain in the standard Lipschitz bandit setting. Our algorithm is empirically evaluated on synthetic data.""}",https://openreview.net{'value': '/pdf/01513ab984971ad1592f91e18e38224e2bc2a41e.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=yu3Q5iU9hi,{'value': 'Multi-Objective GFlowNets'},Moksh Jain; Sharath Chandra Raparthy; Alex Hernández-García; Jarrid Rector-Brooks; Yoshua Bengio; Santiago Miret; Emmanuel Bengio,~Moksh_Jain1; ~Sharath_Chandra_Raparthy3; ~Alex_Hernández-García1; ~Jarrid_Rector-Brooks2; ~Yoshua_Bengio1; ~Santiago_Miret1; ~Emmanuel_Bengio1,,"{'value': 'We study the problem of generating *diverse* candidates in the context of Multi-Objective Optimization. In many applications of machine learning such as drug discovery and material design, the goal is to generate candidates which simultaneously optimize a set of potentially conflicting objectives. Moreover, these objectives are often imperfect evaluations of some underlying property of interest, making it important to generate diverse candidates to have multiple options for expensive downstream evaluations. We propose Multi-Objective GFlowNets (MOGFNs), a novel method for generating diverse Pareto optimal solutions, based on GFlowNets. We introduce two variants of MOGFNs: MOGFN-PC, which models a family of independent sub-problems defined by a scalarization function, with reward-conditional GFlowNets, and MOGFN-AL, which solves a sequence of sub-problems defined by an acquisition function in an active learning loop. Our experiments on wide variety of synthetic and benchmark tasks demonstrate advantages of the proposed methods in terms of the Pareto performance and importantly, improved candidate diversity, which is the main contribution of this work.'}",https://openreview.net{'value': '/pdf/71f05ad2a4afb8322d27dbe681c2c64b5910f0ed.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=ybl9lzdZw7,{'value': 'Taxonomy-Structured Domain Adaptation'},Tianyi Liu; Zihao Xu; Hao He; Guang-Yuan Hao; Guang-He Lee; Hao Wang,~Tianyi_Liu4; ~Zihao_Xu2; ~Hao_He1; ~Guang-Yuan_Hao1; ~Guang-He_Lee1; ~Hao_Wang3,,"{'value': ""Domain adaptation aims to mitigate distribution shifts among different domains. However, traditional formulations are mostly limited to categorical domains, greatly simplifying nuanced domain relationships in the real world. In this work, we tackle a generalization with taxonomy-structured domains, which formalizes domains with nested, hierarchical similarity structures such as animal species and product catalogs. We build on the classic adversarial framework and introduce a novel *taxonomist*, which competes with the adversarial discriminator to preserve the taxonomy information. The equilibrium recovers the classic adversarial domain adaptation's solution if given a non-informative domain taxonomy (e.g., a flat taxonomy where all leaf nodes connect to the root node) while yielding non-trivial results with other taxonomies. Empirically, our method achieves state-of-the-art performance on both synthetic and real-world datasets with successful adaptation.""}",https://openreview.net{'value': '/pdf/55d1fefadeff43b3d9743776af06fa3b476fc0b0.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=xDIppoiFrA,{'value': 'Learning to Incentivize Information Acquisition: Proper Scoring Rules Meet Principal-Agent Model'},Siyu Chen; Jibang Wu; Yifan Wu; Zhuoran Yang,~Siyu_Chen2; ~Jibang_Wu1; ~Yifan_Wu5; ~Zhuoran_Yang1,,"{'value': ""We study the incentivized information acquisition problem, where a principal hires an agent to gather information on her behalf. Such a problem is modeled as a Stackelberg game between the principal and the agent, where the principal announces a scoring rule that specifies the payment, and then the agent then chooses an effort level that maximizes her own profit and reports the information. We study the online setting of such a problem from the principal's perspective, i.e., designing the optimal scoring rule by repeatedly interacting with the strategic agent. We design a provably sample efficient algorithm that tailors the UCB algorithm (Auer et al., 2002) to our model, which achieves a $\\mathcal{O} (K^2\\cdot T^{2/3})$ regret after $T$ iterations, where $K$ is the number of effort levels of the agent. Our algorithm features a delicate estimation procedure for the optimal profit of the principal, and a conservative correction scheme that ensures the desired agent's actions are incentivized. Furthermore, a key feature of our regret bound is that it is independent of the number of states of the environment.""}",https://openreview.net{'value': '/pdf/cfc9196c4bdfc93919c066f054350ef0a64e7de6.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=wcUppxYfLH,{'value': 'Fast Rates for Maximum Entropy Exploration'},Daniil Tiapkin; Denis Belomestny; Daniele Calandriello; Eric Moulines; Remi Munos; Alexey Naumov; pierre perrault; Yunhao Tang; Michal Valko; Pierre MENARD,~Daniil_Tiapkin1; ~Denis_Belomestny1; ~Daniele_Calandriello1; ~Eric_Moulines1; ~Remi_Munos1; ~Alexey_Naumov1; ~pierre_perrault2; ~Yunhao_Tang1; ~Michal_Valko1; ~Pierre_MENARD1,,"{'value': 'We address the challenge of exploration in reinforcement learning (RL) when the agent operates in an unknown environment with sparse or no rewards. In this work, we study the maximum entropy exploration problem of two different types. The first type is visitation entropy maximization previously considered by Hazan et al. (2019) in the discounted setting. For this type of exploration, we propose a game-theoretic algorithm that has $\\widetilde{\\mathcal{O}}(H^3S^2A/\\varepsilon^2)$ sample complexity thus improving the $\\varepsilon$-dependence upon existing results, where $S$ is a number of states, $A$ is a number of actions, $H$ is an episode length, and $\\varepsilon$ is a desired accuracy. The second type of entropy we study is the trajectory entropy. This objective function is closely related to the entropy-regularized MDPs, and we propose a simple algorithm that has a sample complexity of order $\\widetilde{\\mathcal{O}}(\\mathrm{poly}(S,A,H)/\\varepsilon)$. Interestingly, it is the first theoretical result in RL literature that establishes the potential statistical advantage of regularized MDPs for exploration. Finally, we apply developed regularization techniques to reduce sample complexity of visitation entropy maximization to $\\widetilde{\\mathcal{O}}(H^2SA/\\varepsilon^2)$, yielding a statistical separation between maximum entropy exploration and reward-free exploration.'}",https://openreview.net{'value': '/pdf/0c14f6937cb92e902920030591ec61664d69fd5e.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=wVGreJ2338,{'value': 'Featured Graph Coarsening with Similarity Guarantees'},Manoj Kumar; Anurag Sharma; Shashwat Saxena; Sandeep Kumar,~Manoj_Kumar4; ~Anurag_Sharma1; ~Shashwat_Saxena1; ~Sandeep_Kumar8,,"{'value': ""Graph coarsening is a dimensionality reduction technique that aims to learn a smaller-tractable graph while preserving the properties of the original input graph. However, many real-world graphs also have features or contexts associated with each node. The existing graph coarsening methods do not consider the node features and rely solely on a graph matrix(e.g., adjacency and Laplacian) to coarsen graphs. However, some recent deep learning-based graph coarsening methods are designed for specific tasks considering both node features and graph matrix. In this paper, we introduce a novel optimization-based framework for graph coarsening that takes both the graph matrix and the node features as the input and jointly learns the coarsened graph matrix and the coarsened feature matrix while ensuring desired properties. To the best of our knowledge, this is the first work that guarantees that the learned coarsened graph is $\\epsilon\\in[0,1)$ similar to the original graph. Extensive experiments with both real and synthetic benchmark datasets elucidate the proposed framework's efficacy and applicability for numerous graph-based applications, including graph clustering, node classification, stochastic block model identification, and graph summarization.""}",https://openreview.net{'value': '/pdf/91cc907a19f3d29670a505150dabe44fc1a4d4cd.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=vDMHusV7J0,{'value': 'Deep Generative Symbolic Regression with Monte-Carlo-Tree-Search'},Pierre-Alexandre Kamienny; Guillaume Lample; sylvain lamprier; Marco Virgolin,~Pierre-Alexandre_Kamienny1; ~Guillaume_Lample1; ~sylvain_lamprier1; ~Marco_Virgolin1,,"{'value': 'Symbolic regression (SR) is the problem of learning a symbolic expression from numerical data. Recently, deep neural models trained on procedurally-generated synthetic datasets showed competitive performance compared to more classical Genetic Programming (GP) ones. Unlike their GP counterparts, these neural approaches are trained to generate expressions from datasets given as context. This allows them to produce accurate expressions in a single forward pass at test time. However, they usually do not benefit from search abilities, which result in low performance compared to GP on out-of-distribution datasets. In this paper, we propose a novel method which provides the best of both worlds, based on a Monte-Carlo Tree Search procedure using a context-aware neural mutation model, which is initially pre-trained to learn promising mutations, and further refined from successful experiences in an online fashion. The approach demonstrates state-of-the-art performance on the well-known SRBench benchmark.'}",https://openreview.net{'value': '/pdf/313427c55bc0b547903e24fa2de5a384f09dc0e4.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=v6izzusLDO,{'value': 'Sampling-Based Accuracy Testing of Posterior Estimators for General Inference'},Pablo Lemos; Adam Coogan; Yashar Hezaveh; Laurence Perreault-Levasseur,~Pablo_Lemos1; ~Adam_Coogan1; hezaveh@astro.umontreal.ca; llevasseur@astro.umontreal.ca,,"{'value': 'Parameter inference, i.e. inferring the posterior distribution of the parameters of a statistical model given some data, is a central problem to many scientific disciplines. Posterior inference with generative models is an alternative to methods such as Markov Chain Monte Carlo, both for likelihood-based and simulation-based inference. However, assessing the accuracy of posteriors encoded in generative models is not straightforward. In this paper, we introduce ""Tests of Accuracy with Random Points"" (TARP) coverage testing as a method to estimate coverage probabilities of generative posterior estimators. Our method differs from previously-existing coverage-based methods, which require posterior evaluations. We prove that our approach is necessary and sufficient to show that a posterior estimator is accurate. We demonstrate the method on a variety of synthetic examples, and show that TARP can be used to test the results of posterior inference analyses in high-dimensional spaces. We also show that our method can detect inaccurate inferences in cases where existing methods fail.'}",https://openreview.net{'value': '/pdf/738d17e17025ef82f39b206c6d7febdac4294613.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=uSJP34JCTu,{'value': 'Predicting Rare Events by Shrinking Towards Proportional Odds'},Gregory Faletto; Jacob Bien,~Gregory_Faletto1; jbien@usc.edu,,"{'value': 'Training classifiers is difficult with severe class imbalance, but many rare events are the culmination of a sequence with much more common intermediate outcomes. For example, in online marketing a user first sees an ad, then may click on it, and finally may make a purchase; estimating the probability of purchases is difficult because of their rarity. We show both theoretically and through data experiments that the more abundant data in earlier steps may be leveraged to improve estimation of probabilities of rare events. We present PRESTO, a relaxation of the proportional odds model for ordinal regression. Instead of estimating weights for one separating hyperplane that is shifted by separate intercepts for each of the estimated Bayes decision boundaries between adjacent pairs of categorical responses, we estimate separate weights for each of these transitions. We impose an L1 penalty on the differences between weights for the same feature in adjacent weight vectors in order to shrink towards the proportional odds model. We prove that PRESTO consistently estimates the decision boundary weights under a sparsity assumption. Synthetic and real data experiments show that our method can estimate rare probabilities in this setting better than both logistic regression on the rare category, which fails to borrow strength from more abundant categories, and the proportional odds model, which is too inflexible.'}",https://openreview.net{'value': '/pdf/80360174c19ae6c349cf0158a2d1caee22a8333b.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=uP5xXIULdH,{'value': 'On the Estimation of Gaussian Mixture Copula Models'},ASHUTOSH TEWARI,~ASHUTOSH_TEWARI1,,"{'value': 'This paper revisits Gaussian Mixture Copula Model (GMCM), a more expressive alternative to the widely used Gaussian Mixture Model (GMM), with the goal to make its parameter estimation tractable. Both the Expectation Maximization and the direct Likelihood Maximization frameworks for GMCM have to grapple with a likelihood function that lacks a closed form. This has led to a few approximation schemes that alleviate the problem, nonetheless leaving the issue still unresolved. Additionally, past works have alluded to an additional challenge of parameter non-identifiability, but none has offered a rigorous treatment and a commensurate solution framework to overcome the same. This work offers solutions to each of these issues in an attempt to help GMCM realize its full potential. The source of non-identifiability is not only proven but also suitable priors are proposed that eliminate the problem. Additionally, an efficient numerical framework is proposed to evaluate the intractable likelihood function, while also providing its analytical derivatives. Finally, a view of GMCM as a series of bijective mappings from a base distribution is presented, which paves the way to synthesize GMCM using modern, probabilistic programming languages (PPLs). The main claims of this work are supported by empirical evidence gathered on synthetic and real-world datasets.'}",https://openreview.net{'value': '/pdf/afe98b5c6059fbe4aa68683841e38ac547d43653.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=uDeP2vJmho,{'value': 'Which Invariance Should We Transfer? A Causal Minimax Learning Approach'},Mingzhou Liu; Xiangyu Zheng; Xinwei Sun; Fang Fang; Yizhou Wang,~Mingzhou_Liu1; ~Xiangyu_Zheng1; ~Xinwei_Sun1; ~Fang_Fang1; ~Yizhou_Wang1,,"{'value': ""A major barrier to deploying current machine learning models lies in their non-reliability to dataset shifts. To resolve this problem, most existing studies attempted to transfer stable information to unseen environments. Particularly, independent causal mechanisms-based methods proposed to remove mutable causal mechanisms via the do-operator. Compared to previous methods, the obtained stable predictors are more effective in identifying stable information. However, a key question remains: which subset of this whole stable information should the model transfer, in order to achieve optimal generalization ability? To answer this question, we present a comprehensive minimax analysis from a causal perspective. Specifically, we first provide a graphical condition for the whole stable set to be optimal. When this condition fails, we surprisingly find with an example that this whole stable set, although can fully exploit stable information, is not the optimal one to transfer. To identify the optimal subset under this case, we propose to estimate the worst-case risk with a novel optimization scheme over the intervention functions on mutable causal mechanisms. We then propose an efficient algorithm to search for the subset with minimal worst-case risk, based on a newly defined equivalence relation between stable subsets. Compared to the exponential cost of exhaustively searching over all subsets, our searching strategy enjoys a polynomial complexity. The effectiveness and efficiency of our methods are demonstrated on synthetic data and the diagnosis of Alzheimer's disease.""}",https://openreview.net{'value': '/pdf/2193bf59d0935f062a7581127e5acf34f5593e46.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=u1fhtP15l5,{'value': 'Conformalization of Sparse Generalized Linear Models'},Etash Kumar Guha; Eugene Ndiaye; Xiaoming Huo,~Etash_Kumar_Guha1; ~Eugene_Ndiaye1; ~Xiaoming_Huo1,,"{'value': 'Given a sequence of observable variables $\\{(x_1, y_1), \\ldots, (x_n, y_n)\\}$, the conformal prediction method estimates a confidence set for $y_{n+1}$ given $x_{n+1}$ that is valid for any finite sample size by merely assuming that the joint distribution of the data is permutation invariant. Although attractive, computing such a set is computationally infeasible in most regression problems. Indeed, in these cases, the unknown variable $y_{n+1}$ can take an infinite number of possible candidate values, and generating conformal sets requires retraining a predictive model for each candidate. In this paper, we focus on a sparse linear model with only a subset of variables for prediction and use numerical continuation techniques to approximate the solution path efficiently. The critical property we exploit is that the set of selected variables is invariant under a small perturbation of the input data. Therefore, it is sufficient to enumerate and refit the model only at the change points of the set of active features and smoothly interpolate the rest of the solution via a Predictor-Corrector mechanism. We show how our path-following algorithm accurately approximates conformal prediction sets and illustrate its performance using synthetic and real data examples.'}",https://openreview.net{'value': '/pdf/a8aec617b3ad8c8a95ea360273d45eaca1075bd4.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=tgm43aFDXD,{'value': 'Improving Expert Predictions with Conformal Prediction'},Eleni Straitouri; Lequn Wang; Nastaran Okati; Manuel Gomez Rodriguez,~Eleni_Straitouri1; ~Lequn_Wang1; ~Nastaran_Okati2; ~Manuel_Gomez_Rodriguez1,,"{'value': 'Automated decision support systems promise to help human experts solve multiclass classification tasks more efficiently and accurately. However, existing systems typically require experts to understand when to cede agency to the system or when to exercise their own agency. Otherwise, the experts may be better off solving the classification tasks on their own. In this work, we develop an automated decision support system that, by design, does not require experts to understand when to trust the system to improve performance. Rather than providing (single) label predictions and letting experts decide when to trust these predictions, our system provides sets of label predictions constructed using conformal prediction---prediction sets---and forcefully asks experts to predict labels from these sets. By using conformal prediction, our system can precisely trade-off the probability that the true label is not in the prediction set, which determines how frequently our system will mislead the experts, and the size of the prediction set, which determines the difficulty of the classification task the experts need to solve using our system. In addition, we develop an efficient and near-optimal search method to find the conformal predictor under which the experts benefit the most from using our system. Simulation experiments using synthetic and real expert predictions demonstrate that our system may help experts make more accurate predictions and is robust to the accuracy of the classifier the conformal predictor relies on.'}",https://openreview.net{'value': '/pdf/c9c62c0750eb86cd54fd61f347d6f5899ab9060f.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=tNRyU4Plfl,{'value': 'On the Interplay Between Misspecification and Sub-optimality Gap in Linear Contextual Bandits'},Weitong Zhang; Jiafan He; Zhiyuan Fan; Quanquan Gu,~Weitong_Zhang2; ~Jiafan_He1; ~Zhiyuan_Fan1; ~Quanquan_Gu1,,"{'value': 'We study linear contextual bandits in the misspecified setting, where the expected reward function can be approximated by a linear function class up to a bounded misspecification level $\\zeta>0$. We propose an algorithm based on a novel data selection scheme, which only selects the contextual vectors with large uncertainty for online regression. We show that, when the misspecification level $\\zeta$ is dominated by $\\tilde O(\\Delta / \\sqrt{d})$ with $\\Delta$ being the minimal sub-optimality gap and $d$ being the dimension of the contextual vectors, our algorithm enjoys the same gap-dependent regret bound $\\tilde O ({d^2} /{\\Delta})$ as in the well-specified setting up to logarithmic factors. Given this result, we show that the existing SupLinUCB algorithm (Chu et al., 2011) can also achieve a gap-dependent constant regret bound without the knowledge of sub-optimality gap $\\Delta$. Together with a lower bound adapted from Lattimore et al. (2020), our result suggests an interplay between the misspecification level and the sub-optimality gap: (1) the linear contextual bandit model is efficiently learnable when $\\zeta \\leq \\tilde O({\\Delta} / \\sqrt{d})$; and (2) it is not efficiently learnable when $\\zeta \\geq \\tilde \\Omega({\\Delta} / {\\sqrt{d}})$. Experiments on both synthetic and real-world datasets corroborate our theoretical results.'}",https://openreview.net{'value': '/pdf/8826314293c1da10457c2296e0b5a984e9a3b8a7.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=tIJMebbcRF,{'value': 'Intrinsic Sliced Wasserstein Distances for Comparing Collections of Probability Distributions on Manifolds and Graphs'},Raif M. Rustamov; Subhabrata Majumdar,~Raif_M._Rustamov1; ~Subhabrata_Majumdar2,,"{'value': 'Collections of probability distributions arise in a variety of applications ranging from user activity pattern analysis to brain connectomics. In practice these distributions can be defined over diverse domain types including finite intervals, circles, cylinders, spheres, other manifolds, and graphs. This paper introduces an approach for detecting differences between two collections of distributions over such general domains. To this end, we propose the intrinsic slicing construction that yields a novel class of Wasserstein distances on manifolds and graphs. These distances are Hilbert embeddable, allowing us to reduce the distribution collection comparison problem to a more familiar mean testing problem in a Hilbert space. We provide two testing procedures one based on resampling and another on combining p-values from coordinate-wise tests. Our experiments in various synthetic and real data settings show that the resulting tests are powerful and the p-values are well-calibrated.'}",https://openreview.net{'value': '/pdf/5fab317e9845085687add141c0d2db5f49afe6e4.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=tE3BMOyUl5,{'value': 'Infusing Lattice Symmetry Priors in Attention Mechanisms for Sample-Efficient Abstract Geometric Reasoning'},Mattia Atzeni; Mrinmaya Sachan; Andreas Loukas,~Mattia_Atzeni1; ~Mrinmaya_Sachan3; ~Andreas_Loukas1,,"{'value': 'The Abstraction and Reasoning Corpus (ARC) (Chollet, 2019) and its most recent language-complete instantiation (LARC) has been postulated as an important step towards general AI. Yet, even state-of-the-art machine learning models struggle to achieve meaningful performance on these problems, falling behind non-learning based approaches. We argue that solving these tasks requires extreme generalization that can only be achieved by proper accounting for core knowledge priors. As a step towards this goal, we focus on geometry priors and introduce LatFormer, a model that incorporates lattice symmetry priors in attention masks. We show that, for any transformation of the hypercubic lattice, there exists a binary attention mask that implements that group action. Hence, our study motivates a modification to the standard attention mechanism, where attention weights are scaled using soft masks generated by a convolutional network. Experiments on synthetic geometric reasoning show that LatFormer requires 2 orders of magnitude fewer data than standard attention and transformers. Moreover, our results on ARC and LARC tasks that incorporate geometric priors provide preliminary evidence that these complex datasets do not lie out of the reach of deep learning models.'}",https://openreview.net{'value': '/pdf/891b91d3b11346d2b8149b02ad0587ed7c9b5e71.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=sy9oDku9Lu,{'value': 'CoDi: Co-evolving Contrastive Diffusion Models for Mixed-type Tabular Synthesis'},Chaejeong Lee; Jayoung Kim; Noseong Park,~Chaejeong_Lee1; ~Jayoung_Kim1; ~Noseong_Park1,,"{'value': 'With growing attention to tabular data these days, the attempt to apply a synthetic table to various tasks has been expanded toward various scenarios. Owing to the recent advances in generative modeling, fake data generated by tabular data synthesis models become sophisticated and realistic. However, there still exists a difficulty in modeling discrete variables (columns) of tabular data. In this work, we propose to process continuous and discrete variables separately (but being conditioned on each other) by two diffusion models. The two diffusion models are co-evolved during training by reading conditions from each other. In order to further bind the diffusion models, moreover, we introduce a contrastive learning method with a negative sampling method. In our experiments with 11 real-world tabular datasets and 8 baseline methods, we prove the efficacy of the proposed method, called $\\texttt{CoDi}$. Our code is available at https://github.com/ChaejeongLee/CoDi.'}",https://openreview.net{'value': '/pdf/75966f66c170a6919f12ec35a965ea973b849b2a.pdf'},{'abstract_filter': 'Data Synthesis'},ICML.cc,2023,Conference
https://openreview.net/forum?id=srcA0Dzooj,{'value': 'End-to-End Learning for Stochastic Optimization: A Bayesian Perspective'},Yves Rychener; Daniel Kuhn; Tobias Sutter,~Yves_Rychener1; ~Daniel_Kuhn2; ~Tobias_Sutter1,,"{'value': 'We develop a principled approach to end-to-end learning in stochastic optimization. First, we show that the standard end-to-end learning algorithm admits a Bayesian interpretation and trains a posterior Bayes action map. Building on the insights of this analysis, we then propose new end-to-end learning algorithms for training decision maps that output solutions of empirical risk minimization and distributionally robust optimization problems, two dominant modeling paradigms in optimization under uncertainty. Numerical results for a synthetic newsvendor problem illustrate the key differences between alternative training schemes. We also investigate an economic dispatch problem based on real data to showcase the impact of the neural network architecture of the decision maps on their test performance.'}",https://openreview.net{'value': '/pdf/93aeea0fcbe3c32553f0e201893b00a1ba60ad7b.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=smrYWkIV9J,{'value': 'Effectively Using Public Data in Privacy Preserving Machine Learning'},Milad Nasr; Saeed Mahloujifar; Xinyu Tang; Prateek Mittal; Amir Houmansadr,~Milad_Nasr2; ~Saeed_Mahloujifar1; ~Xinyu_Tang1; ~Prateek_Mittal1; ~Amir_Houmansadr1,,"{'value': 'Differentially private (DP) machine learning techniques are notorious for their degradation of model utility (e.g., they degrade classification accuracy). A recent line of work has demonstrated that leveraging *public data* can improve the trade-off between privacy and utility when training models with DP guaranteed. In this work, we further explore the potential of using public data in DP models, showing that utility gains can in fact be significantly higher than what shown in prior works. Specifically, we introduce DOPE-SGD, a modified DP-SGD algorithm that leverages public data during its training. DOPE-SGD uses public data in two complementary ways: (1) it uses advance augmentation techniques that leverages public data to generate synthetic data that is effectively embedded in multiple steps of the training pipeline; (2) it uses a modified gradient clipping mechanism (which is a standard technique in DP training) to change the *origin* of gradient vectors using the information inferred from available public and synthetic data, therefore boosting utility. We also introduce a technique to ensemble intermediate DP models by leveraging the post processing property of differential privacy to further improve the accuracy of the predictions. Our experimental results demonstrate the effectiveness of our approach in improving the state-of-the-art in DP machine learning across multiple datasets, network architectures, and application domains. For instance, assuming access to $2,000$ public images, and for a privacy budget of $\\varepsilon=2,\\delta=10^{-5}$, our technique achieves an accuracy of $75.1\\%$ on CIFAR10, significantly higher than $68.1\\%$ achieved by the state of the art.'}",https://openreview.net{'value': '/pdf/c0e6beab93f95442c51ca026aeacc30a3501c43f.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=sag7iLqPvC,{'value': 'SeedGNN: Graph Neural Network for Supervised Seeded Graph Matching'},Liren Yu; Jiaming Xu; Xiaojun Lin,~Liren_Yu1; ~Jiaming_Xu4; ~Xiaojun_Lin1,,"{'value': 'There is a growing interest in designing Graph Neural Networks (GNNs) for seeded graph matching, which aims to match two unlabeled graphs using only topological information and a small set of seed nodes. However, most previous GNNs for this task use a semi-supervised approach, which requires a large number of seeds and cannot learn knowledge that is transferable to unseen graphs. In contrast, this paper proposes a new supervised approach that can learn from a training set how to match unseen graphs with only a few seeds. Our SeedGNN architecture incorporates several novel designs, inspired by theoretical studies of seeded graph matching: 1) it can learn to compute and use witness-like information from different hops, in a way that can be generalized to graphs of different sizes; 2) it can use easily-matched node-pairs as new seeds to improve the matching in subsequent layers. We evaluate SeedGNN on synthetic and real-world graphs and demonstrate significant performance improvements over both non-learning and learning algorithms in the existing literature. Furthermore, our experiments confirm that the knowledge learned by SeedGNN from training graphs can be generalized to test graphs of different sizes and categories.'}",https://openreview.net{'value': '/pdf/68c5ee0bdb156c24f867c0307bfc9be4feb4d2c1.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=sGvHRYUPeA,{'value': 'Reliable Measures of Spread in High Dimensional Latent Spaces'},Anna Marbut; Katy McKinney-Bock; Travis J Wheeler,~Anna_Marbut1; katymck@gmail.com; twheeler@arizona.edu,,"{'value': ""Understanding geometric properties of the latent spaces of natural language processing models allows the manipulation of these properties for improved performance on downstream tasks. One such property is the amount of data spread in a model's latent space, or how fully the available latent space is being used. We demonstrate that the commonly used measures of data spread, average cosine similarity and a partition function min/max ratio I(V), do not provide reliable metrics to compare the use of latent space across data distributions. We propose and examine six alternative measures of data spread, all of which improve over these current metrics when applied to seven synthetic data distributions. Of our proposed measures, we recommend one principal component-based measure and one entropy-based measure that provide reliable, relative measures of spread and can be used to compare models of different sizes and dimensionalities.""}",https://openreview.net{'value': '/pdf/767c652ab6956f2c1638a94b5916a17821f1a439.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=rxT5EVRNEu,{'value': 'GraphCleaner: Detecting Mislabelled Samples in Popular Graph Learning Benchmarks'},Yuwen Li; Miao Xiong; Bryan Hooi,~Yuwen_Li2; ~Miao_Xiong2; ~Bryan_Hooi1,,"{'value': 'Label errors have been found to be prevalent in popular text, vision, and audio datasets, which heavily influence the safe development and evaluation of machine learning algorithms. Despite increasing efforts towards improving the quality of generic data types, such as images and texts, the problem of mislabel detection in graph data remains underexplored. To bridge the gap, we explore mislabelling issues in popular real-world graph datasets and propose GraphCleaner, a post-hoc method to detect and correct these mislabelled nodes in graph datasets. GraphCleaner combines the novel ideas of 1) Synthetic Mislabel Dataset Generation, which seeks to generate realistic mislabels; and 2) Neighborhood-Aware Mislabel Detection, where neighborhood dependency is exploited in both labels and base classifier predictions. Empirical evaluations on 6 datasets and 6 experimental settings demonstrate that GraphCleaner outperforms the closest baseline, with an average improvement of $0.14$ in F1 score, and $0.16$ in MCC. On real-data case studies, GraphCleaner detects real and previously unknown mislabels in popular graph benchmarks: PubMed, Cora, CiteSeer and OGB-arxiv; we find that at least 6.91% of PubMed data is mislabelled or ambiguous, and simply removing these mislabelled data can boost evaluation performance from 86.71% to 89.11%.'}",https://openreview.net{'value': '/pdf/2954802bff9716b5a5ede11f2a6b92a113a1fed2.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=rSOMtDM1mB,{'value': 'Stable Estimation of Heterogeneous Treatment Effects'},Anpeng Wu; Kun Kuang; Ruoxuan Xiong; Bo Li; Fei Wu,~Anpeng_Wu1; ~Kun_Kuang1; ~Ruoxuan_Xiong1; ~Bo_Li29; ~Fei_Wu1,,"{'value': 'Estimating heterogeneous treatment effects (HTE) is crucial for identifying the variation of treatment effects across individuals or subgroups. Most existing methods estimate HTE by removing the confounding bias from imbalanced treatment assignments. However, these methods may produce unreliable estimates of treatment effects and potentially allocate suboptimal treatment arms for underrepresented populations. To improve the estimation accuracy of HTE for underrepresented populations, we propose a novel Stable CounterFactual Regression (StableCFR) to smooth the population distribution and upsample the underrepresented subpopulations, while balancing confounders between treatment and control groups. Specifically, StableCFR upsamples the underrepresented data using uniform sampling, where each disjoint subpopulation is weighted proportional to the Lebesgue measure of its support. Moreover, StableCFR balances covariates by using an epsilon-greedy matching approach. Empirical results on both synthetic and real-world datasets demonstrate the superior performance of our StableCFR on estimating HTE for underrepresented populations.'}",https://openreview.net{'value': '/pdf/9b91315196306e979446dd87ae9e5d2a35c498eb.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=qszhULcjUh,{'value': 'Retrosynthetic Planning with Dual Value Networks'},Guoqing Liu; Di Xue; Shufang Xie; Yingce Xia; Austin Tripp; Krzysztof Maziarz; Marwin Segler; Tao Qin; Zongzhang Zhang; Tie-Yan Liu,~Guoqing_Liu3; ~Di_Xue1; ~Shufang_Xie1; ~Yingce_Xia1; ~Austin_Tripp1; ~Krzysztof_Maziarz1; ~Marwin_Segler2; ~Tao_Qin1; ~Zongzhang_Zhang1; ~Tie-Yan_Liu1,,"{'value': 'Retrosynthesis, which aims to find a route to synthesize a target molecule from commercially available starting materials, is a critical task in drug discovery and materials design. Recently, the combination of ML-based single-step reaction predictors with multi-step planners has led to promising results. However, the single-step predictors are mostly trained offline to optimize the single-step accuracy, without considering complete routes. Here, we leverage reinforcement learning (RL) to improve the single-step predictor, by using a tree-shaped MDP to optimize complete routes. Specifically, we propose a novel online training algorithm, called Planning with Dual Value Networks (PDVN), which alternates between the planning phase and updating phase. In PDVN, we construct two separate value networks to predict the synthesizability and cost of molecules, respectively. To maintain the single-step accuracy, we design a two-branch network structure for the single-step predictor. On the widely-used USPTO dataset, our PDVN algorithm improves the search success rate of existing multi-step planners (e.g., increasing the success rate from 85.79% to 98.95% for Retro$^{\\ast}$, and reducing the number of model calls by half while solving 99.47% molecules for RetroGraph). Additionally, PDVN helps find shorter synthesis routes (e.g., reducing the average route length from 5.76 to 4.83 for Retro$^{\\ast}$, and from 5.63 to 4.78 for RetroGraph).'}",https://openreview.net{'value': '/pdf/c743bbcd81cc196d2e640d68d0599581de16a6ba.pdf'},{'title_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=qorOnDor89,{'value': 'On the Role of Attention in Prompt-tuning'},Samet Oymak; Ankit Singh Rawat; Mahdi Soltanolkotabi; Christos Thrampoulidis,~Samet_Oymak2; ~Ankit_Singh_Rawat1; ~Mahdi_Soltanolkotabi1; ~Christos_Thrampoulidis1,,"{'value': 'Prompt-tuning is an emerging strategy to adapt large language models (LLM) to downstream tasks by learning a (soft-)prompt parameter from data. Despite its success in LLMs, there is limited theoretical understanding of the power of prompt-tuning and the role of the attention mechanism in prompting. In this work, we explore prompt-tuning for one-layer attention architectures and study contextual mixture-models where each input token belongs to a context-relevant or -irrelevant set. We isolate the role of prompt-tuning through a self-contained prompt-attention model. Our contributions are as follows: (1) We show that softmax-prompt-attention is provably more expressive than softmax-self-attention and linear-prompt-attention under our contextual data model. (2) We analyze the initial trajectory of gradient descent and show that it learns the prompt and prediction head with near-optimal sample complexity and demonstrate how the prompt can provably attend to sparse context-relevant tokens. (3) Assuming a known prompt but an unknown prediction head, we characterize the exact finite sample performance of prompt-attention which reveals the fundamental performance limits and the precise benefit of the context information. We also provide experiments that verify our theoretical insights on real datasets and demonstrate how prompt-tuning enables the model to attend to context-relevant information.'}",https://openreview.net{'value': '/pdf/42c357eb17ba824c308e6f9b38652d2531151f6a.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=qn9ZWZ3Pg7,{'value': 'Nested Elimination: A Simple Algorithm for Best-Item Identification From Choice-Based Feedback'},Junwen Yang; Yifan Feng,~Junwen_Yang1; ~Yifan_Feng2,,"{'value': 'We study the problem of best-item identification from choice-based feedback. In this problem, a company sequentially and adaptively shows display sets to a population of customers and collects their choices. The objective is to identify the most preferred item with the least number of samples and at a high confidence level. We propose an elimination-based algorithm, namely Nested Elimination (NE), which is inspired by the nested structure implied by the information-theoretic lower bound. NE is simple in structure, easy to implement, and has a strong theoretical guarantee for sample complexity. Specifically, NE utilizes an innovative elimination criterion and circumvents the need to solve any complex combinatorial optimization problem. We provide an instance-specific and non-asymptotic bound on the expected sample complexity of NE. We also show NE achieves high-order worst-case asymptotic optimality. Finally, numerical experiments from both synthetic and real data corroborate our theoretical findings.'}",https://openreview.net{'value': '/pdf/a76c5b58e5ab85d5b601f9c689835e8368e67f40.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=qmwtMuRh1j,{'value': 'Benign Overfitting in Two-layer ReLU Convolutional Neural Networks'},Yiwen Kou; Zixiang Chen; Yuanzhou Chen; Quanquan Gu,~Yiwen_Kou1; ~Zixiang_Chen1; ~Yuanzhou_Chen1; ~Quanquan_Gu1,,"{'value': 'Modern deep learning models with great expressive power can be trained to overfit the training data but still generalize well. This phenomenon is referred to as benign overfitting. Recently, a few studies have attempted to theoretically understand benign overfitting in neural networks. However, these works are either limited to neural networks with smooth activation functions or to the neural tangent kernel regime. How and when benign overfitting can occur in ReLU neural networks remains an open problem. In this work, we seek to answer this question by establishing algorithm-dependent risk bounds for learning two-layer ReLU convolutional neural networks with label-flipping noise. We show that, under mild conditions, the neural network trained by gradient descent can achieve near-zero training loss and Bayes optimal test risk. Our result also reveals a sharp transition between benign and harmful overfitting under different conditions on data distribution in terms of test risk. Experiments on synthetic data back up our theory.'}",https://openreview.net{'value': '/pdf/26b1e832d7003698f407d1d83c8abc93544d6cd9.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=qEcJpq2Kjr,{'value': 'Complementary Attention for Multi-Agent Reinforcement Learning'},Jianzhun Shao; Hongchang Zhang; Yun Qu; Chang Liu; Shuncheng He; Yuhang Jiang; Xiangyang Ji,~Jianzhun_Shao1; ~Hongchang_Zhang1; ~Yun_Qu2; ~Chang_Liu9; ~Shuncheng_He1; ~Yuhang_Jiang3; ~Xiangyang_Ji1,,"{'value': 'In cooperative multi-agent reinforcement learning, centralized training with decentralized execution (CTDE) shows great promise for a trade-off between independent Q-learning and joint action learning. However, vanilla CTDE methods assumed a fixed number of agents could hardly adapt to real-world scenarios where dynamic team compositions typically suffer from dramatically variant partial observability. Specifically, agents with extensive sight ranges are prone to be affected by trivial environmental substrates, dubbed the ""distracted attention"" issue; ones with limited observation can hardly sense their teammates, degrading the cooperation quality. In this paper, we propose Complementary Attention for Multi-Agent reinforcement learning (CAMA), which applies a divide-and-conquer strategy on input entities accompanied with the complementary attention of enhancement and replenishment. Concretely, to tackle the distracted attention issue, highly contributed entities\' attention is enhanced by the execution-related representation extracted via action prediction with an inverse model. For better out-of-sight-range cooperation, the lowly contributed ones are compressed to brief messages with a conditional mutual information estimator. Our CAMA facilitates stable and sustainable teamwork, which is justified by the impressive results reported on the challenging StarCraftII, MPE, and Traffic Junction benchmarks.'}",https://openreview.net{'value': '/pdf/918014d3e2c7c01d11c8b77f7bc80773cd1198d7.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=q7hlNyetZ2,{'value': 'Causal Modeling of Policy Interventions From Treatment–Outcome Sequences'},Çağlar Hızlı; S. T. John; Anne Tuulikki Juuti; Tuure Tapani Saarinen; Kirsi Hannele Pietiläinen; Pekka Marttinen,~Çağlar_Hızlı1; ~S._T._John1; ~Anne_Tuulikki_Juuti1; ~Tuure_Tapani_Saarinen1; ~Kirsi_Hannele_Pietiläinen1; ~Pekka_Marttinen1,,"{'value': 'A *treatment policy* defines when and what treatments are applied to affect some outcome of interest. Data-driven decision-making requires the ability to predict *what happens if a policy is changed*. Existing methods that predict how the outcome evolves under different scenarios assume that the tentative sequences of future treatments are fixed in advance, while in practice the treatments are determined stochastically by a policy and may depend, for example, on the efficiency of previous treatments. Therefore, the current methods are not applicable if the treatment policy is unknown or a counterfactual analysis is needed. To handle these limitations, we model the treatments and outcomes jointly in continuous time, by combining Gaussian processes and point processes. Our model enables the estimation of a treatment policy from observational sequences of treatments and outcomes, and it can predict the interventional and counterfactual progression of the outcome *after an intervention on the treatment policy* (in contrast with the causal effect of a single treatment). We show with real-world and semi-synthetic data on blood glucose progression that our method can answer causal queries more accurately than existing alternatives.'}",https://openreview.net{'value': '/pdf/708ad217223c7e9981ef0a75743e52fc1fe6d123.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=q2L5r7WEHT,{'value': 'Topological Point Cloud Clustering'},Vincent Peter Grande; Michael T Schaub,~Vincent_Peter_Grande1; ~Michael_T_Schaub1,,"{'value': 'We present Topological Point Cloud Clustering (TPCC), a new method to cluster points in an arbitrary point cloud based on their contribution to global topological features. TPCC synthesizes desirable features from spectral clustering and topological data analysis and is based on considering the spectral properties of a simplicial complex associated to the considered point cloud. As it is based on considering sparse eigenvector computations, TPCC is similarly easy to interpret and implement as spectral clustering. However, by focusing not just on a single matrix associated to a graph created from the point cloud data, but on a whole set of Hodge-Laplacians associated to an appropriately constructed simplicial complex, we can leverage a far richer set of topological features to characterize the data points within the point cloud and benefit from the relative robustness of topological techniques against noise. We test the performance of TPCC on both synthetic and real-world data and compare it with classical spectral clustering.'}",https://openreview.net{'value': '/pdf/75c683d614bb32c46f28615c6bfcc57daed6fde6.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=priTMs7n6e,{'value': 'Improved Policy Evaluation for Randomized Trials of Algorithmic Resource Allocation'},Aditya Mate; Bryan Wilder; Aparna Taneja; Milind Tambe,~Aditya_Mate1; ~Bryan_Wilder2; ~Aparna_Taneja3; ~Milind_Tambe1,,"{'value': 'We consider the task of evaluating policies of algorithmic resource allocation through randomized controlled trials (RCTs). Such policies are tasked with optimizing the utilization of limited intervention resources, with the goal of maximizing the benefits derived. Evaluation of such allocation policies through RCTs proves difficult, notwithstanding the scale of the trial, because the individuals’ outcomes are inextricably interlinked through resource constraints controlling the policy decisions. Our key contribution is to present a new estimator leveraging our proposed novel concept, that involves retrospective reshuffling of participants across experimental arms at the end of an RCT. We identify conditions under which such reassignments are permissible and can be leveraged to construct counterfactual trials, whose outcomes can be accurately ascertained, for free. We prove theoretically that such an estimator is more accurate than common estimators based on sample means -- we show that it returns an unbiased estimate and simultaneously reduces variance. We demonstrate the value of our approach through empirical experiments on synthetic, semisynthetic as well as real case study data and show improved estimation accuracy across the board.'}",https://openreview.net{'value': '/pdf/8e00bfdb35ddb6904618129cf345ad37ed301c43.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=prMTSnjVuR,{'value': 'PCA-based Multi-Task Learning: a Random Matrix Approach'},Malik Tiomoko; Romain Couillet; Frederic Pascal,~Malik_Tiomoko1; ~Romain_Couillet1; ~Frederic_Pascal1,,"{'value': 'The article proposes and theoretically analyses a *computationally efficient* multi-task learning (MTL) extension of popular principal component analysis (PCA)-based supervised learning schemes. The analysis reveals that (i) by default, learning may dramatically fail by suffering from *negative transfer*, but that (ii) simple counter-measures on data labels avert negative transfer and necessarily result in improved performances. Supporting experiments on synthetic and real data benchmarks show that the proposed method achieves comparable performance with state-of-the-art MTL methods but at a *significantly reduced computational cost*.'}",https://openreview.net{'value': '/pdf/9933919ce38adfb31205a1877f377eef6bd52aae.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=pLky79p1Ne,{'value': 'Parallel Online Clustering of Bandits via Hedonic Game'},Xiaotong Cheng; Cheng Pan; Setareh Maghsudi,~Xiaotong_Cheng1; ~Cheng_Pan3; ~Setareh_Maghsudi1,,"{'value': ""Contextual bandit algorithms appear in several applications, such as online advertisement and recommendation systems like personalized education or personalized medicine. Individually-tailored recommendations boost the performance of the underlying application; nevertheless, providing individual suggestions becomes costly and even implausible as the number of users grows. As such, to efficiently serve the demands of several users in modern applications, it is imperative to identify the underlying users' clusters, i.e., the groups of users for which a single recommendation might be (near-)optimal. We propose CLUB-HG, a novel algorithm that integrates a game-theoretic approach into clustering inference. Our algorithm achieves Nash equilibrium at each inference step and discovers the underlying clusters. We also provide regret analysis within a standard linear stochastic noise setting. Finally, experiments on synthetic and real-world datasets show the superior performance of our proposed algorithm compared to the state-of-the-art algorithms.""}",https://openreview.net{'value': '/pdf/8d5f08954b3ec6640ec8e62be0c06da4ff8c2d47.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=pLQoqbUTue,{'value': 'Context-Aware Bayesian Network Actor-Critic Methods for Cooperative Multi-Agent Reinforcement Learning'},Dingyang Chen; Qi Zhang,~Dingyang_Chen1; ~Qi_Zhang12,,"{'value': ""Executing actions in a correlated manner is a common strategy for human coordination that often leads to better cooperation, which is also potentially beneficial for cooperative multi-agent reinforcement learning (MARL). However, the recent success of MARL relies heavily on the convenient paradigm of purely decentralized execution, where there is no action correlation among agents for scalability considerations. In this work, we introduce a Bayesian network to inaugurate correlations between agents' action selections in their joint policy. Theoretically, we establish a theoretical justification for why action dependencies are beneficial by deriving the multi-agent policy gradient formula under such a Bayesian network joint policy and proving its global convergence to Nash equilibria under tabular softmax policy parameterization in cooperative Markov games. Further, by equipping existing MARL algorithms with a recent method of differentiable directed acyclic graphs (DAGs), we develop practical algorithms to learn the context-aware Bayesian network policies in scenarios with partial observability and various difficulty. We also dynamically decrease the sparsity of the learned DAG throughout the training process, which leads to weakly or even purely independent policies for decentralized execution. Empirical results on a range of MARL benchmarks show the benefits of our approach.""}",https://openreview.net{'value': '/pdf/6504bfbff2b8df19705512b87746d77d7413d3fd.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=oke1MUPK2l,{'value': 'Learning Control-Oriented Dynamical Structure from Data'},Spencer M. Richards; Jean-Jacques Slotine; Navid Azizan; Marco Pavone,~Spencer_M._Richards1; ~Jean-Jacques_Slotine1; ~Navid_Azizan1; ~Marco_Pavone1,,"{'value': 'Even for known nonlinear dynamical systems, feedback controller synthesis is a difficult problem that often requires leveraging the particular structure of the dynamics to induce a stable closed-loop system. For general nonlinear models, including those fit to data, there may not be enough known structure to reliably synthesize a stabilizing feedback controller. In this paper, we discuss a state-dependent nonlinear tracking controller formulation based on a state-dependent Riccati equation for general nonlinear control-affine systems. This formulation depends on a nonlinear factorization of the system of vector fields defining the control-affine dynamics, which always exists under mild smoothness assumptions. We propose a method for learning this factorization from a finite set of data. On a variety of simulated nonlinear dynamical systems, we empirically demonstrate the efficacy of learned versions of this controller in stable trajectory tracking. Alongside our learning method, we evaluate recent ideas in jointly learning a controller and stabilizability certificate for known dynamical systems; we show experimentally that such methods can be frail in comparison.'}",https://openreview.net{'value': '/pdf/1636b554cf381f8f5b9e6ef96da0c9f988c0edae.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=oUeo2uG1AZ,{'value': 'N$\\text{A}^\\text{2}$Q: Neural Attention Additive Model for Interpretable Multi-Agent Q-Learning'},Zichuan Liu; Yuanyang Zhu; Chunlin Chen,~Zichuan_Liu3; ~Yuanyang_Zhu1; ~Chunlin_Chen1,,"{'value': 'Value decomposition is widely used in cooperative multi-agent reinforcement learning, however, its implicit credit assignment mechanism is not yet fully understood due to black-box networks. In this work, we study an interpretable value decomposition framework via the family of generalized additive models. We present a novel method, named Neural Attention Additive Q-learning (N$\\text{A}^\\text{2}$Q), providing inherent intelligibility of collaboration behavior. N$\\text{A}^\\text{2}$Q can explicitly factorize the optimal joint policy induced by enriching shape functions to model all possible coalition of agents into individual policies. Moreover, we construct the identity semantics to promote estimating credits together with the global state and individual value functions, where local semantic masks help us diagnose whether each agent captures the relevant-task information. Extensive experiments show that N$\\text{A}^\\text{2}$Q consistently achieves superior performance compared to different state-of-the-art methods on all challenging tasks, while yielding human-like interpretability.'}",https://openreview.net{'value': '/pdf/e057ff6a1a1a9684f7645b07efbdaeda28873680.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=oR2IsISm1X,{'value': 'Differentiable Multi-Target Causal Bayesian Experimental Design'},Panagiotis Tigas; Yashas Annadani; Desi R. Ivanova; Andrew Jesson; Yarin Gal; Adam Foster; Stefan Bauer,~Panagiotis_Tigas1; ~Yashas_Annadani1; ~Desi_R._Ivanova1; ~Andrew_Jesson1; ~Yarin_Gal1; ~Adam_Foster1; ~Stefan_Bauer1,,"{'value': 'We introduce a gradient-based approach for the problem of Bayesian optimal experimental design to learn causal models in a batch setting --- a critical component for causal discovery from finite data where interventions can be costly or risky. Existing methods rely on greedy approximations to construct a batch of experiments while using black-box methods to optimize over a *single target-state* pair to intervene with. In this work, we completely dispose of the black-box optimization techniques and greedy heuristics and instead propose a conceptually simple end-to-end gradient-based optimization procedure to acquire a set of optimal intervention target-value pairs. Such a procedure enables parameterization of the design space to efficiently optimize over a batch of *multi-target-state* interventions, a setting which has hitherto not been explored due to its complexity. We demonstrate that our proposed method outperforms baselines and existing acquisition strategies in both single-target and multi-target settings across a number of synthetic datasets.'}",https://openreview.net{'value': '/pdf/619b727a9e9cf2d63f5f93c0ecf1903e364dd326.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=o7BOzuqFi2,{'value': 'The Ideal Continual Learner: An Agent That Never Forgets'},Liangzu Peng; Paris Giampouras; Rene Vidal,~Liangzu_Peng2; ~Paris_Giampouras1; ~Rene_Vidal1,,"{'value': 'The goal of continual learning is to find a model that solves multiple learning tasks which are presented sequentially to the learner. A key challenge in this setting is that the learner may ""forget"" how to solve a previous task when learning a new task, a phenomenon known as catastrophic forgetting. To address this challenge, many practical methods have been proposed, including memory-based, regularization-based and expansion-based methods. However, a rigorous theoretical understanding of these methods remains elusive. This paper aims to bridge this gap between theory and practice by proposing a new continual learning framework called ""Ideal Continual Learner"" (ICL), which is guaranteed to avoid catastrophic forgetting by construction. We show that ICL unifies multiple well-established continual learning methods and gives new theoretical insights into the strengths and weaknesses of these methods. We also derive generalization bounds for ICL which allow us to theoretically quantify ""how rehearsal affects generalization"". Finally, we connect ICL to several classic subjects and research topics of modern interest, which allows us to make historical remarks and inspire future directions.'}",https://openreview.net{'value': '/pdf/b868e35d80ce46cc33b35af3ea51f9ef45936b03.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=nqvBUsnC5L,{'value': 'Invariance in Policy Optimisation and Partial Identifiability in Reward Learning'},Joar Max Viktor Skalse; Matthew Farrugia-Roberts; Stuart Russell; Alessandro Abate; Adam Gleave,~Joar_Max_Viktor_Skalse1; ~Matthew_Farrugia-Roberts1; ~Stuart_Russell1; ~Alessandro_Abate1; ~Adam_Gleave1,,"{'value': 'It is often very challenging to manually design reward functions for complex, real-world tasks. To solve this, one can instead use reward learning to infer a reward function from data. However, there are often multiple reward functions that fit the data equally well, even in the infinite-data limit. This means that the reward function is only partially identifiable. In this work, we formally characterise the partial identifiability of the reward function given several popular reward learning data sources, including expert demonstrations and trajectory comparisons. We also analyse the impact of this partial identifiability for several downstream tasks, such as policy optimisation. We unify our results in a framework for comparing data sources and downstream tasks by their invariances, with implications for the design and selection of data sources for reward learning.'}",https://openreview.net{'value': '/pdf/4470d159a5e3ef29b7f92cdf28aa41b14a871885.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=nmVOTsQGR9,{'value': 'Personalized Federated Learning under Mixture of Distributions'},Yue Wu; SHUAICHENG ZHANG; Wenchao Yu; Yanchi Liu; Quanquan Gu; Dawei Zhou; Haifeng Chen; Wei Cheng,~Yue_Wu12; ~SHUAICHENG_ZHANG1; ~Wenchao_Yu1; ~Yanchi_Liu1; ~Quanquan_Gu1; ~Dawei_Zhou1; ~Haifeng_Chen1; ~Wei_Cheng1,,"{'value': 'The recent trend towards Personalized Federated Learning (PFL) has garnered significant attention as it allows for the training of models that are tailored to each client while maintaining data privacy. However, current PFL techniques primarily focus on modeling the conditional distribution heterogeneity (i.e. concept shift), which can result in suboptimal performance when the distribution of input data across clients diverges (i.e. covariate shift). Additionally, these techniques often lack the ability to adapt to unseen data, further limiting their effectiveness in real-world scenarios. To address these limitations, we propose a novel approach, FedGMM, which utilizes Gaussian mixture models (GMM) to effectively fit the input data distributions across diverse clients. The model parameters are estimated by maximum likelihood estimation utilizing a federated Expectation-Maximization algorithm, which is solved in closed form and does not assume gradient similarity. Furthermore, FedGMM possesses an additional advantage of adapting to new clients with minimal overhead, and it also enables uncertainty quantification. Empirical evaluations on synthetic and benchmark datasets demonstrate the superior performance of our method in both PFL classification and novel sample detection.'}",https://openreview.net{'value': '/pdf/920a84d1c61ef5e8445ed463c68160eec49ef278.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=nHCfIQu2tV,{'value': 'RACE: Improve Multi-Agent Reinforcement Learning with Representation Asymmetry and Collaborative Evolution'},Pengyi Li; Jianye HAO; Hongyao Tang; YAN ZHENG; Xian Fu,~Pengyi_Li1; ~Jianye_HAO1; ~Hongyao_Tang1; ~YAN_ZHENG1; ~Xian_Fu1,,"{'value': 'Multi-Agent Reinforcement Learning (MARL) has demonstrated its effectiveness in learning collaboration, but it often struggles with low-quality reward signals and high non-stationarity. In contrast, Evolutionary Algorithm (EA) has shown better convergence, robustness, and signal quality insensitivity. This paper introduces a hybrid framework, Representation Asymmetry and Collaboration Evolution (RACE), which combines EA and MARL for efficient collaboration. RACE maintains a MARL team and a population of EA teams. To enable efficient knowledge sharing and policy exploration, RACE decomposes the policies of different teams controlling the same agent into a shared nonlinear observation representation encoder and individual linear policy representations. To address the partial observation issue, we introduce Value-Aware Mutual Information Maximization to enhance the shared representation with useful information about superior global states. EA evolves the population using novel agent-level crossover and mutation operators, offering diverse experiences for MARL. Concurrently, MARL optimizes its policies and injects them into the population for evolution. The experiments on challenging continuous and discrete tasks demonstrate that RACE significantly improves the basic algorithms, consistently outperforming other algorithms. Our code is available at https://github.com/yeshenpy/RACE.'}",https://openreview.net{'value': '/pdf/96aa8ae5c2cd877335f152e4a77a44520cb347b9.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=mjYZd6SgZS,{'value': 'On the Statistical Benefits of Temporal Difference Learning'},David Cheikhi; Daniel Russo,~David_Cheikhi1; ~Daniel_Russo1,,"{'value': ""Given a dataset on actions and resulting long-term rewards, a direct estimation approach fits value functions that minimize prediction error on the training data. Temporal difference learning (TD) methods instead fit value functions by minimizing the degree of temporal inconsistency between estimates made at successive time-steps. Focusing on finite state Markov chains, we provide a crisp asymptotic theory of the statistical advantages of this approach. First, we show that an intuitive inverse trajectory pooling coefficient completely characterizes the percent reduction in mean-squared error of value estimates. Depending on problem structure, the reduction could be enormous or nonexistent. Next, we prove that there can be dramatic improvements in estimates of the difference in value-to-go for two states: TD's errors are bounded in terms of a novel measure -- the problem's trajectory crossing time -- which can be much smaller than the problem's time horizon.""}",https://openreview.net{'value': '/pdf/a9bc8e97a916eb93f7a2be1ef9ff504844cf7d50.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=mGUJMqjDwE,{'value': 'Provably Learning Object-Centric Representations'},Jack Brady; Roland S. Zimmermann; Yash Sharma; Bernhard Schölkopf; Julius von Kügelgen; Wieland Brendel,~Jack_Brady1; ~Roland_S._Zimmermann1; ~Yash_Sharma1; ~Bernhard_Schölkopf1; ~Julius_von_Kügelgen2; ~Wieland_Brendel1,,"{'value': ""Learning structured representations of the visual world in terms of objects promises to significantly improve the generalization abilities of current machine learning models. While recent efforts to this end have shown promising empirical progress, a theoretical account of when unsupervised object-centric representation learning is possible is still lacking. Consequently, understanding the reasons for the success of existing object-centric methods as well as designing new theoretically grounded methods remains challenging. In the present work, we analyze when object-centric representations can provably be learned without supervision. To this end, we first introduce two assumptions on the generative process for scenes comprised of several objects, which we call compositionality and irreducibility. Under this generative process, we prove that the ground-truth object representations can be identified by an invertible and compositional inference model, even in the presence of dependencies between objects. We empirically validate our results through experiments on synthetic data. Finally, we provide evidence that our theory holds predictive power for existing object-centric models by showing a close correspondence between models' compositionality and invertibility and their empirical identifiability.""}",https://openreview.net{'value': '/pdf/efa54b0c0d41f86b280d7fd2e2363774cde24952.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=m21SgZnBWZ,{'value': 'Investigating the Role of Model-Based Learning in Exploration and Transfer'},Jacob C Walker; Eszter Vértes; Yazhe Li; Gabriel Dulac-Arnold; Ankesh Anand; Theophane Weber; Jessica B Hamrick,~Jacob_C_Walker1; ~Eszter_Vértes1; ~Yazhe_Li2; ~Gabriel_Dulac-Arnold1; ~Ankesh_Anand1; ~Theophane_Weber1; ~Jessica_B_Hamrick1,,"{'value': 'State of the art reinforcement learning has enabled training agents on tasks of ever increasing complexity. However, the current paradigm tends to favor training agents from scratch on every new task or on collections of tasks with a view towards generalizing to novel task configurations. The former suffers from poor data efficiency while the latter is difficult when test tasks are out-of-distribution. Agents that can effectively transfer their knowledge about the world pose a potential solution to these issues. In this paper, we investigate transfer learning in the context of model-based agents. Specifically, we aim to understand where exactly environment models have an advantage and why. We find that a model-based approach outperforms controlled model-free baselines for transfer learning. Through ablations, we show that both the policy and dynamics model learnt through exploration matter for successful transfer. We demonstrate our results across three domains which vary in their requirements for transfer: in-distribution procedural (Crafter), in-distribution identical (RoboDesk), and out-of-distribution (Meta-World). Our results show that intrinsic exploration combined with environment models present a viable direction towards agents that are self-supervised and able to generalize to novel reward functions.'}",https://openreview.net{'value': '/pdf/bfabb21ed814d1095bdb59d6b9e77be5aa8af19d.pdf'},{'abstract_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=lwodnXJzu6,{'value': 'Are Neurons Actually Collapsed? On the Fine-Grained Structure in Neural Representations'},Yongyi Yang; Jacob Steinhardt; Wei Hu,~Yongyi_Yang1; ~Jacob_Steinhardt1; ~Wei_Hu1,,"{'value': 'Recent work has observed an intriguing ""Neural Collapse\'\' phenomenon in well-trained neural networks, where the last-layer representations of training samples with the same label collapse into each other. This appears to suggest that the last-layer representations are completely determined by the labels, and do not depend on the intrinsic structure of input distribution. We provide evidence that this is not a complete description, and that the apparent collapse hides important fine-grained structure in the representations. Specifically, even when representations apparently collapse, the small amount of remaining variation can still faithfully and accurately captures the intrinsic structure of input distribution. As an example, if we train on CIFAR-10 using only 5 coarse-grained labels (by combining two classes into one super-class) until convergence, we can reconstruct the original 10-class labels from the learned representations via unsupervised clustering. The reconstructed labels achieve 93% accuracy on the CIFAR-10 test set, nearly matching the normal CIFAR-10 accuracy for the same architecture. We also provide an initial theoretical result showing the fine-grained representation structure in a simplified synthetic setting. Our results show concretely how the structure of input data can play a significant role in determining the fine-grained structure of neural representations, going beyond what Neural Collapse predicts.'}",https://openreview.net{'value': '/pdf/f1beb437e9c06f6bf03bebe5689d97a666613ebc.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=laR6abCxIu,{'value': 'A Coupled Flow Approach to Imitation Learning'},Gideon Joseph Freund; Elad Sarafian; Sarit Kraus,~Gideon_Joseph_Freund1; ~Elad_Sarafian1; ~Sarit_Kraus1,,"{'value': 'In reinforcement learning and imitation learning, an object of central importance is the state distribution induced by the policy. It plays a crucial role in the policy gradient theorem, and references to it--along with the related state-action distribution--can be found all across the literature. Despite its importance, the state distribution is mostly discussed indirectly and theoretically, rather than being modeled explicitly. The reason being an absence of appropriate density estimation tools. In this work, we investigate applications of a normalizing flow based model for the aforementioned distributions. In particular, we use a pair of flows coupled through the optimality point of the Donsker-Varadhan representation of the Kullback-Leibler (KL) divergence, for distribution matching based imitation learning. Our algorithm, Coupled Flow Imitation Learning (CFIL), achieves state-of-the-art performance on benchmark tasks with a single expert trajectory and extends naturally to a variety of other settings, including the subsampled and state-only regimes.'}",https://openreview.net{'value': '/pdf/1b6d266c7c9f1a02aa65e7508e7359b1dae2e4a3.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=lJaAPdXgxL,{'value': 'Comparison of meta-learners for estimating multi-valued treatment heterogeneous effects'},Naoufal Acharki; Ramiro Lugo; Antoine Bertoncello; Josselin Garnier,~Naoufal_Acharki1; r.lugocasados.17@aberdeen.ac.uk; antoine.bertoncello@totalenergies.com; ~Josselin_Garnier1,,"{'value': 'Conditional Average Treatment Effects (CATE) estimation is one of the main challenges in causal inference with observational data. In addition to Machine Learning based-models, nonparametric estimators called meta-learners have been developed to estimate the CATE with the main advantage of not restraining the estimation to a specific supervised learning method. This task becomes, however, more complicated when the treatment is not binary as some limitations of the naive extensions emerge. This paper looks into meta-learners for estimating the heterogeneous effects of multi-valued treatments. We consider different meta-learners, and we carry out a theoretical analysis of their error upper bounds as functions of important parameters such as the number of treatment levels, showing that the naive extensions do not always provide satisfactory results. We introduce and discuss meta-learners that perform well as the number of treatments increases. We empirically confirm the strengths and weaknesses of those methods with synthetic and semi-synthetic datasets.'}",https://openreview.net{'value': '/pdf/90233234cc53e3e87ddeefc15ccb0b3e966091ef.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=kgxO5itnvU,{'value': 'Stochastic Policy Gradient Methods: Improved Sample Complexity for Fisher-non-degenerate Policies'},Ilyas Fatkhullin; Anas Barakat; Anastasia Kireeva; Niao He,~Ilyas_Fatkhullin1; ~Anas_Barakat1; ~Anastasia_Kireeva1; ~Niao_He3,,"{'value': 'Recently, the impressive empirical success of policy gradient (PG) methods has catalyzed the development of their theoretical foundations. Despite the huge efforts directed at the design of efficient stochastic PG-type algorithms, the understanding of their convergence to a globally optimal policy is still limited. In this work, we develop improved global convergence guarantees for a general class of Fisher-non-degenerate parameterized policies which allows to address the case of continuous state action spaces. First, we propose a Normalized Policy Gradient method with Implicit Gradient Transport (N-PG-IGT) and derive a $\\tilde{\\mathcal{O}}(\\varepsilon^{-2.5})$ sample complexity of this method for finding a global $\\varepsilon$-optimal policy. Improving over the previously known $\\tilde{\\mathcal{O}}(\\varepsilon^{-3})$ complexity, this algorithm does not require the use of importance sampling or second-order information and samples only one trajectory per iteration. Second, we further improve this complexity to $\\tilde{ \\mathcal{\\mathcal{O}} }(\\varepsilon^{-2})$ by considering a Hessian-Aided Recursive Policy Gradient ((N)-HARPG) algorithm enhanced with a correction based on a Hessian-vector product. Interestingly, both algorithms are $(i)$ simple and easy to implement: single-loop, do not require large batches of trajectories and sample at most two trajectories per iteration; $(ii)$ computationally and memory efficient: they do not require expensive subroutines at each iteration and can be implemented with memory linear in the dimension of parameters.'}",https://openreview.net{'value': '/pdf/042d0637681e238f7103a26b57724a0c7a1376b3.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=kWS8mpioS9,{'value': 'Efficient RL via Disentangled Environment and Agent Representations'},Kevin Gmelin; Shikhar Bahl; Russell Mendonca; Deepak Pathak,~Kevin_Gmelin1; ~Shikhar_Bahl1; ~Russell_Mendonca1; ~Deepak_Pathak1,,"{'value': 'Agents that are aware of the separation between the environments and themselves can leverage this understanding to form effective representations of visual input. We propose an approach for learning such structured representations for RL algorithms, using visual knowledge of the agent, which is often inexpensive to obtain, such as its shape or mask. This is incorporated into the RL objective using a simple auxiliary loss. We show that our method, SEAR (Structured Environment-Agent Representations), outperforms state-of-the-art model-free approaches over 18 different challenging visual simulation environments spanning 5 different robots.'}",https://openreview.net{'value': '/pdf/06ab7aa959437088fc7431901b98b4d52ef41123.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=kP2p67F4G7,{'value': 'Neural Algorithmic Reasoning with Causal Regularisation'},Beatrice Bevilacqua; Kyriacos Nikiforou; Borja Ibarz; Ioana Bica; Michela Paganini; Charles Blundell; Jovana Mitrovic; Petar Veličković,~Beatrice_Bevilacqua1; ~Kyriacos_Nikiforou1; ~Borja_Ibarz1; ~Ioana_Bica1; ~Michela_Paganini1; ~Charles_Blundell1; ~Jovana_Mitrovic1; ~Petar_Veličković1,,"{'value': ""Recent work on neural algorithmic reasoning has investigated the reasoning capabilities of neural networks, effectively demonstrating they can learn to execute classical algorithms on unseen data coming from the train distribution. However, the performance of existing neural reasoners significantly degrades on out-of-distribution (OOD) test data, where inputs have larger sizes. In this work, we make an important observation: there are many different inputs for which an algorithm will perform certain intermediate computations identically. This insight allows us to develop data augmentation procedures that, given an algorithm's intermediate trajectory, produce inputs for which the target algorithm would have exactly the same next trajectory step. We ensure invariance in the next-step prediction across such inputs, by employing a self-supervised objective derived by our observation, formalised in a causal graph. We prove that the resulting method, which we call Hint-ReLIC, improves the OOD generalisation capabilities of the reasoner. We evaluate our method on the CLRS algorithmic reasoning benchmark, where we show up to 3x improvements on the OOD test data.""}",https://openreview.net{'value': '/pdf/4f8bb50b7e82104814da4e1c7312991c9e84534f.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=kEnDJdTM9A,{'value': 'DiscoBAX - Discovery of optimal intervention sets in genomic experiment design'},Clare Lyle; Arash Mehrjou; Pascal Notin; Andrew Jesson; Stefan Bauer; Yarin Gal; Patrick Schwab,~Clare_Lyle1; ~Arash_Mehrjou1; ~Pascal_Notin1; ~Andrew_Jesson1; ~Stefan_Bauer1; ~Yarin_Gal1; ~Patrick_Schwab1,,"{'value': 'The discovery of therapeutics to treat genetically-driven pathologies relies on identifying genes involved in the underlying disease mechanism. Existing approaches search over the billions of potential interventions to maximize the expected influence on the target phenotype. However, to reduce the risk of failure in future stages of trials, practical experiment design aims to find a set of interventions that maximally change a target phenotype via diverse mechanisms. We propose DiscoBAX - a sample-efficient method for maximizing the rate of significant discoveries per experiment while simultaneously probing for a wide range of diverse mechanisms during a genomic experiment campaign. We provide theoretical guarantees of optimality under standard assumptions, and conduct a comprehensive experimental evaluation covering both synthetic as well as real-world experimental design tasks. DiscoBAX outperforms existing state-of-the-art methods for experimental design, selecting effective and diverse perturbations in biological systems.'}",https://openreview.net{'value': '/pdf/715d857c31dd7cbb9a0f36725ebd810b1157c065.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=k24luy3Azi,{'value': 'Performative Recommendation: Diversifying Content via Strategic Incentives'},Itay Eilat; Nir Rosenfeld,~Itay_Eilat1; ~Nir_Rosenfeld2,,"{'value': 'The primary goal in recommendation is to suggest relevant content to users, but optimizing for accuracy often results in recommendations that lack diversity. To remedy this, conventional approaches such as re-ranking improve diversity by *presenting* more diverse items. Here we argue that to promote inherent and prolonged diversity, the system must encourage its *creation*. Towards this, we harness the performative nature of recommendation, and show how learning can incentivize strategic content creators to create diverse content. Our approach relies on a novel form of regularization that anticipates strategic changes to content, and penalizes for content homogeneity. We provide analytic and empirical results that demonstrate when and how diversity can be incentivized, and experimentally demonstrate the utility of our approach on synthetic and semi-synthetic data.'}",https://openreview.net{'value': '/pdf/09b2bf3224e3fd04362d1e6c572cee69ee888dc6.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=jrYVLd3wqk,{'value': 'Safe Offline Reinforcement Learning with Real-Time Budget Constraints'},Qian Lin; Bo Tang; Zifan Wu; Chao Yu; Shangqin Mao; Qianlong Xie; Xingxing Wang; Dong Wang,~Qian_Lin3; ~Bo_Tang3; ~Zifan_Wu2; ~Chao_Yu2; maoshangqin@meituan.com; xieqianlong@meituan.com; wangxingxing04@meituan.com; wangdong07@meituan.com,,"{'value': 'Aiming at promoting the safe real-world deployment of Reinforcement Learning (RL), research on safe RL has made significant progress in recent years. However, most existing works in the literature still focus on the online setting where risky violations of the safety budget are likely to be incurred during training. Besides, in many realworld applications, the learned policy is required to respond to dynamically determined safety budgets (i.e., constraint threshold) in real time. In this paper, we target at the above real-time budget constraint problem under the offline setting, and propose Trajectory-based REal-time Budget Inference (TREBI) as a novel solution that approaches this problem from the perspective of trajectory distribution. Theoretically, we prove an error bound of the estimation on the episodic reward and cost under the offline setting and thus provide a performance guarantee for TREBI. Empirical results on a wide range of simulation tasks and a real-world large-scale advertising application demonstrate the capability of TREBI in solving real-time budget constraint problems under offline settings.'}",https://openreview.net{'value': '/pdf/6eb5b8a52967348636d768351f8c59450136f554.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=jjpsFetXJp,{'value': 'Neural Collapse in Deep Linear Networks: From Balanced to Imbalanced Data'},Hien Dang; Tho Tran Huu; Stanley Osher; Hung Tran-The; Nhat Ho; Tan Minh Nguyen,~Hien_Dang1; ~Tho_Tran_Huu1; ~Stanley_Osher1; ~Hung_Tran-The1; ~Nhat_Ho1; ~Tan_Minh_Nguyen1,,"{'value': ""Modern deep neural networks have achieved impressive performance on tasks from image classification to natural language processing. Surprisingly, these complex systems with massive amounts of parameters exhibit the same structural properties in their last-layer features and classifiers across canonical datasets when training until convergence. In particular, it has been observed that the last-layer features collapse to their class-means, and those class-means are the vertices of a simplex Equiangular Tight Frame (ETF). This phenomenon is known as Neural Collapse (NC). Recent papers have theoretically shown that NC emerges in the global minimizers of training problems with the simplified ``unconstrained feature model''. In this context, we take a step further and prove the NC occurrences in deep linear networks for the popular mean squared error (MSE) and cross entropy (CE) losses, showing that global solutions exhibit NC properties across the linear layers. Furthermore, we extend our study to imbalanced data for MSE loss and present the first geometric analysis of NC under bias-free setting. Our results demonstrate the convergence of the last-layer features and classifiers to a geometry consisting of orthogonal vectors, whose lengths depend on the amount of data in their corresponding classes. Finally, we empirically validate our theoretical analyses on synthetic and practical network architectures with both balanced and imbalanced scenarios.""}",https://openreview.net{'value': '/pdf/dd14ca985efae65a50116586f61397c970104066.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=jbAjEhBuOZ,{'value': 'Tuning Language Models as Training Data Generators for Augmentation-Enhanced Few-Shot Learning'},Yu Meng; Martin Michalski; Jiaxin Huang; Yu Zhang; Tarek Abdelzaher; Jiawei Han,~Yu_Meng1; ~Martin_Michalski1; ~Jiaxin_Huang1; ~Yu_Zhang26; ~Tarek_Abdelzaher1; ~Jiawei_Han1,,"{'value': 'Recent studies have revealed the intriguing few-shot learning ability of pretrained language models (PLMs): They can quickly adapt to a new task when fine-tuned on a small amount of labeled data formulated as prompts, without requiring abundant task-specific annotations. Despite their promising performance, most existing few-shot approaches that only learn from the small training set still underperform fully supervised training by nontrivial margins. In this work, we study few-shot learning with PLMs from a different perspective: We first tune an autoregressive PLM on the few-shot samples and then use it as a generator to synthesize a large amount of novel training samples which augment the original training set. To encourage the generator to produce label-discriminative samples, we train it via weighted maximum likelihood where the weight of each token is automatically adjusted based on a discriminative meta-learning objective. A classification PLM can then be fine-tuned on both the few-shot and the synthetic samples with regularization for better generalization and stability. Our approach FewGen achieves an overall better result across seven classification tasks of the GLUE benchmark than existing few-shot learning methods, improving no-augmentation methods by 5+ average points, and outperforming augmentation methods by 3+ average points.'}",https://openreview.net{'value': '/pdf/d875c9abb7150e2ddcfd416370d61dcc50822f34.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=jVR2fF8x8x,{'value': 'Improved Techniques for Maximum Likelihood Estimation for Diffusion ODEs'},Kaiwen Zheng; Cheng Lu; Jianfei Chen; Jun Zhu,~Kaiwen_Zheng2; ~Cheng_Lu5; ~Jianfei_Chen1; ~Jun_Zhu2,,"{'value': 'Diffusion models have exhibited excellent performance in various domains. The probability flow ordinary differential equation (ODE) of diffusion models (i.e., diffusion ODEs) is a particular case of continuous normalizing flows (CNFs), which enables deterministic inference and exact likelihood evaluation. However, the likelihood estimation results by diffusion ODEs are still far from those of the state-of-the-art likelihood-based generative models. In this work, we propose several improved techniques for maximum likelihood estimation for diffusion ODEs, including both training and evaluation perspectives. For training, we propose velocity parameterization and explore variance reduction techniques for faster convergence. We also derive an error-bounded high-order flow matching objective for finetuning, which improves the ODE likelihood and smooths its trajectory. For evaluation, we propose a novel training-free truncated-normal dequantization to fill the training-evaluation gap commonly existing in diffusion ODEs. Building upon these techniques, we achieve state-of-the-art likelihood estimation results on image datasets (2.56 on CIFAR-10, 3.43/3.69 on ImageNet-32) without variational dequantization or data augmentation.'}",https://openreview.net{'value': '/pdf/58cdc024f9e2f20abc6cd89400d7becb70dd0939.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=jTcRlAAO01,{'value': 'Principled Offline RL in the Presence of Rich Exogenous Information'},Riashat Islam; Manan Tomar; Alex Lamb; Yonathan Efroni; Hongyu Zang; Aniket Rajiv Didolkar; Dipendra Misra; Xin Li; Harm van Seijen; Remi Tachet des Combes; John Langford,~Riashat_Islam1; ~Manan_Tomar1; ~Alex_Lamb1; ~Yonathan_Efroni2; ~Hongyu_Zang1; ~Aniket_Rajiv_Didolkar1; ~Dipendra_Misra1; ~Xin_Li31; ~Harm_van_Seijen1; ~Remi_Tachet_des_Combes1; ~John_Langford1,,"{'value': 'Learning to control an agent from offline data collected in a rich pixel-based visual observation space is vital for real-world applications of reinforcement learning (RL). A major challenge in this setting is the presence of input information that is hard to model and irrelevant to controlling the agent. This problem has been approached by the theoretical RL community through the lens of *exogenous information*, i.e., any control-irrelevant information contained in observations. For example, a robot navigating in busy streets needs to ignore irrelevant information, such as other people walking in the background, textures of objects, or birds in the sky. In this paper, we focus on the setting with visually detailed exogenous information and introduce new offline RL benchmarks that offer the ability to study this problem. We find that contemporary representation learning techniques can fail on datasets where the noise is a complex and time-dependent process, which is prevalent in practical applications. To address these, we propose to use multi-step inverse models to learn Agent-Centric Representations for Offline-RL (ACRO). Despite being simple and reward-free, we show theoretically and empirically that the representation created by this objective greatly outperforms baselines.'}",https://openreview.net{'value': '/pdf/2ba1b01e4ccf4959e2866a148fb6cf05f726c67e.pdf'},{'abstract_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=jFPdftHG4F,{'value': 'Probabilistic Attention-to-Influence Neural Models for Event Sequences'},Xiao Shou; Debarun Bhattacharjya; Tian Gao; Dharmashankar Subramanian; Oktie Hassanzadeh; Kristin Bennett,~Xiao_Shou2; ~Debarun_Bhattacharjya1; ~Tian_Gao1; ~Dharmashankar_Subramanian1; ~Oktie_Hassanzadeh1; ~Kristin_Bennett1,,"{'value': 'Discovering knowledge about which types of events influence others, using datasets of event sequences without time stamps, has several practical applications. While neural sequence models are able to capture complex and potentially long-range historical dependencies, they often lack the interpretability of simpler models for event sequence dynamics. We provide a novel neural framework in such a setting - a probabilistic attention-to-influence neural model - which not only captures complex instance-wise interactions between events but also learns influencers for each event type of interest. Given event sequence data and a prior distribution on type-wise influence, we efficiently learn an approximate posterior for type-wise influence by an attention-to-influence transformation using variational inference. Our method subsequently models the conditional likelihood of sequences by sampling the above posterior to focus attention on influencing event types. We motivate our general framework and show improved performance in experiments compared to existing baselines on synthetic data as well as real-world benchmarks, for tasks involving prediction and influencing set identification.'}",https://openreview.net{'value': '/pdf/88bfc47a549979ce4a0dfd899bb7ff9ed99ce3d1.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=j5PYwPsNci,{'value': 'B-Learner: Quasi-Oracle Bounds on Heterogeneous Causal Effects Under Hidden Confounding'},Miruna Oprescu; Jacob Dorn; Marah Ghoummaid; Andrew Jesson; Nathan Kallus; Uri Shalit,~Miruna_Oprescu1; ~Jacob_Dorn1; ~Marah_Ghoummaid1; ~Andrew_Jesson1; ~Nathan_Kallus1; ~Uri_Shalit1,,"{'value': 'Estimating heterogeneous treatment effects from observational data is a crucial task across many fields, helping policy and decision-makers take better actions. There has been recent progress on robust and efficient methods for estimating the conditional average treatment effect (CATE) function, but these methods often do not take into account the risk of hidden confounding, which could arbitrarily and unknowingly bias any causal estimate based on observational data. We propose a meta-learner called the B-Learner, which can efficiently learn sharp bounds on the CATE function under limits on the level of hidden confounding. We derive the B-Learner by adapting recent results for sharp and valid bounds of the average treatment effect (Dorn et al., 2021) into the framework given by Kallus & Oprescu (2023) for robust and model-agnostic learning of conditional distributional treatment effects. The B-Learner can use any function estimator such as random forests and deep neural networks, and we prove its estimates are valid, sharp, efficient, and have a quasi-oracle property with respect to the constituent estimators under more general conditions than existing methods. Semi-synthetic experimental comparisons validate the theoretical findings, and we use real-world data demonstrate how the method might be used in practice.'}",https://openreview.net{'value': '/pdf/c61c7feb36c0a101f92350f162e6781cdf946623.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=iRBKUnIjR2,{'value': 'Approximate Causal Effect Identification under Weak Confounding'},Ziwei Jiang; Lai Wei; Murat Kocaoglu,~Ziwei_Jiang1; wei429@purdue.edu; ~Murat_Kocaoglu1,,"{'value': 'Causal effect estimation has been studied by many researchers when only observational data is available. Sound and complete algorithms have been developed for pointwise estimation of identifiable causal queries. For non-identifiable causal queries, researchers developed polynomial programs to estimate tight bounds on causal effect. However, these are computationally difficult to optimize for variables with large support sizes. In this paper, we analyze the effect of ""weak confounding\'"" on causal estimands. More specifically, under the assumption that the unobserved confounders that render a query non-identifiable have small entropy, we propose an efficient linear program to derive the upper and lower bounds of the causal effect. We show that our bounds are consistent in the sense that as the entropy of unobserved confounders goes to zero, the gap between the upper and lower bound vanishes. Finally, we conduct synthetic and real data simulations to compare our bounds with the bounds obtained by the existing work that cannot incorporate such entropy constraints and show that our bounds are tighter for the setting with weak confounders.'}",https://openreview.net{'value': '/pdf/4c70ff5f5acdb475d37249b3fcc560e3f36cb014.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=iEPLOBHHnh,{'value': 'Evaluating Unsupervised Denoising Requires Unsupervised Metrics'},Adria Marcos Morales; Matan Leibovich; Sreyas Mohan; Joshua Lawrence Vincent; Piyush Haluai; Mai Tan; Peter Crozier; Carlos Fernandez-Granda,~Adria_Marcos_Morales1; ~Matan_Leibovich1; ~Sreyas_Mohan1; ~Joshua_Lawrence_Vincent1; ~Piyush_Haluai1; ~Mai_Tan2; ~Peter_Crozier1; ~Carlos_Fernandez-Granda1,,"{'value': 'Unsupervised denoising is a crucial challenge in real-world imaging applications. Unsupervised deep-learning methods have demonstrated impressive performance on benchmarks based on synthetic noise. However, no metrics exist to evaluate these methods in an unsupervised fashion. This is highly problematic for the many practical applications where ground-truth clean images are not available. In this work, we propose two novel metrics: the unsupervised mean squared error (MSE) and the unsupervised peak signal-to-noise ratio (PSNR), which are computed using only noisy data. We provide a theoretical analysis of these metrics, showing that they are asymptotically consistent estimators of the supervised MSE and PSNR. Controlled numerical experiments with synthetic noise confirm that they provide accurate approximations in practice. We validate our approach on real-world data from two imaging modalities: videos in raw format and transmission electron microscopy. Our results demonstrate that the proposed metrics enable unsupervised evaluation of denoising methods based exclusively on noisy data.'}",https://openreview.net{'value': '/pdf/aa21ac970076566ad9bc9c24d0927b1bac6841dc.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=hvEwJ3xYxx,{'value': 'Matrix Estimation for Individual Fairness'},Cindy Zhang; Sarah Huiyi Cen; Devavrat Shah,~Cindy_Zhang1; ~Sarah_Huiyi_Cen1; ~Devavrat_Shah1,,"{'value': ""In recent years, multiple notions of algorithmic fairness have arisen. One such notion is individual fairness (IF), which requires that individuals who are similar receive similar treatment. In parallel, matrix estimation (ME) has emerged as a natural paradigm for handling noisy data with missing values. In this work, we connect the two concepts. We show that pre-processing data using ME can improve an algorithm's IF without sacrificing performance. Specifically, we show that using a popular ME method known as singular value thresholding (SVT) to pre-process the data provides a strong IF guarantee under appropriate conditions. We then show that, under analogous conditions, SVT pre-processing also yields estimates that are consistent and approximately minimax optimal. As such, the ME pre-processing step does not, under the stated conditions, increase the prediction error of the base algorithm, i.e., does not impose a fairness-performance trade-off. We verify these results on synthetic and real data.""}",https://openreview.net{'value': '/pdf/6625457895110d8310a8dfcd62a3de11038a330c.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=h3GBd13xVv,{'value': 'Global Optimization with Parametric Function Approximation'},Chong Liu; Yu-Xiang Wang,~Chong_Liu1; ~Yu-Xiang_Wang1,,"{'value': 'We consider the problem of global optimization with noisy zeroth order oracles — a well-motivated problem useful for various applications ranging from hyper-parameter tuning for deep learning to new material design. Existing work relies on Gaussian processes or other non-parametric family, which suffers from the curse of dimensionality. In this paper, we propose a new algorithm GO-UCB that leverages a parametric family of functions (e.g., neural networks) instead. Under a realizable assumption and a few other mild geometric conditions, we show that GO-UCB achieves a cumulative regret of $\\tilde{O}(\\sqrt{T})$ where $T$ is the time horizon. At the core of GO-UCB is a carefully designed uncertainty set over parameters based on gradients that allows optimistic exploration. Synthetic and real-world experiments illustrate GO-UCB works better than popular Bayesian optimization approaches, even if the model is misspecified.'}",https://openreview.net{'value': '/pdf/012133faf95c9469c174facbf2135af11ae3555a.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=gWC3Q3pyHe,{'value': 'Fast Sampling of Diffusion Models via Operator Learning'},Hongkai Zheng; Weili Nie; Arash Vahdat; Kamyar Azizzadenesheli; Anima Anandkumar,~Hongkai_Zheng1; ~Weili_Nie1; ~Arash_Vahdat3; ~Kamyar_Azizzadenesheli1; ~Anima_Anandkumar1,,"{'value': 'Diffusion models have found widespread adoption in various areas. However, their sampling process is slow because it requires hundreds to thousands of network evaluations to emulate a continuous process defined by differential equations. In this work, we use neural operators, an efficient method to solve the probability flow differential equations, to accelerate the sampling process of diffusion models. Compared to other fast sampling methods that have a sequential nature, we are the first to propose a parallel decoding method that generates images with only one model forward pass. We propose *diffusion model sampling with neural operator* (DSNO) that maps the initial condition, i.e., Gaussian distribution, to the continuous-time solution trajectory of the reverse diffusion process. To model the temporal correlations along the trajectory, we introduce temporal convolution layers that are parameterized in the Fourier space into the given diffusion model backbone. We show our method achieves state-of-the-art FID of 3.78 for CIFAR-10 and 7.83 for ImageNet-64 in the one-model-evaluation setting.'}",https://openreview.net{'value': '/pdf/9e7263c6d98947b273d790acf29c3ff6182ae894.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=gTGFxnBymb,{'value': 'Regions of Reliability in the Evaluation of Multivariate Probabilistic Forecasts'},Étienne Marcotte; Valentina Zantedeschi; Alexandre Drouin; Nicolas Chapados,~Étienne_Marcotte1; ~Valentina_Zantedeschi2; ~Alexandre_Drouin2; ~Nicolas_Chapados1,,"{'value': ""Multivariate probabilistic time series forecasts are commonly evaluated via proper scoring rules, i.e., functions that are minimal in expectation for the ground-truth distribution. However, this property is not sufficient to guarantee good discrimination in the non-asymptotic regime. In this paper, we provide the first systematic finite-sample study of proper scoring rules for time series forecasting evaluation. Through a power analysis, we identify the ``region of reliability'' of a scoring rule, i.e., the set of practical conditions where it can be relied on to identify forecasting errors. We carry out our analysis on a comprehensive synthetic benchmark, specifically designed to test several key discrepancies between ground-truth and forecast distributions, and we gauge the generalizability of our findings to real-world tasks with an application to an electricity production problem. Our results reveal critical shortcomings in the evaluation of multivariate probabilistic forecasts as commonly performed in the literature.""}",https://openreview.net{'value': '/pdf/376ddeb79745f03eb70ebe94fbefefb8c745764c.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=fZFNPf1QiF,{'value': 'Beyond the Universal Law of Robustness: Sharper Laws for Random Features and Neural Tangent Kernels'},Simone Bombari; Shayan Kiyani; Marco Mondelli,~Simone_Bombari1; ~Shayan_Kiyani2; ~Marco_Mondelli1,,"{'value': 'Machine learning models are vulnerable to adversarial perturbations, and a thought-provoking paper by Bubeck and Sellke has analyzed this phenomenon through the lens of over-parameterization: interpolating smoothly the data requires significantly more parameters than simply memorizing it. However, this ""universal"" law provides only a necessary condition for robustness, and it is unable to discriminate between models. In this paper, we address these gaps by focusing on empirical risk minimization in two prototypical settings, namely, random features and the neural tangent kernel (NTK). We prove that, for random features, the model is not robust for any degree of over-parameterization, even when the necessary condition coming from the universal law of robustness is satisfied. In contrast, for even activations, the NTK model meets the universal lower bound, and it is robust as soon as the necessary condition on over-parameterization is fulfilled. This also addresses a conjecture in prior work by Bubeck, Li and Nagaraj. Our analysis decouples the effect of the kernel of the model from an ""interaction matrix"", which describes the interaction with the test data and captures the effect of the activation. Our theoretical results are corroborated by numerical evidence on both synthetic and standard datasets (MNIST, CIFAR-10).'}",https://openreview.net{'value': '/pdf/79a662cf119d0c70b63ab4437bc73d78cc0d2fb4.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=fXBjFPL5HD,{'value': 'Entity Divider with Language Grounding in Multi-Agent Reinforcement Learning'},Ziluo Ding; Wanpeng Zhang; Junpeng Yue; Xiangjun Wang; Tiejun Huang; Zongqing Lu,~Ziluo_Ding1; ~Wanpeng_Zhang1; ~Junpeng_Yue1; ~Xiangjun_Wang1; ~Tiejun_Huang1; ~Zongqing_Lu2,,"{'value': 'We investigate the use of natural language to drive the generalization of policies in multi-agent settings. Unlike single-agent settings, the generalization of policies should also consider the influence of other agents. Besides, with the increasing number of entities in multi-agent settings, more agent-entity interactions are needed for language grounding, and the enormous search space could impede the learning process. Moreover, given a simple general instruction, e.g., beating all enemies, agents are required to decompose it into multiple subgoals and figure out the right one to focus on. Inspired by previous work, we try to address these issues at the entity level and propose a novel framework for language grounding in multi-agent reinforcement learning, entity divider (EnDi). EnDi enables agents to independently learn subgoal division at the entity level and act in the environment based on the associated entities. The subgoal division is regularized by agent modeling to avoid subgoal conflicts and promote coordinated strategies. Empirically, EnDi demonstrates the strong generalization ability to unseen games with new dynamics and expresses the superiority over existing methods. The code is available at https://github.com/PKU-RL/EnDi.'}",https://openreview.net{'value': '/pdf/35c54c4b1aa115c45a77c44327ff1605da462170.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=fKnw2yYXpK,{'value': 'Structural Re-weighting Improves Graph Domain Adaptation'},Shikun Liu; Tianchun Li; Yongbin Feng; Nhan Tran; Han Zhao; Qiang Qiu; Pan Li,~Shikun_Liu3; ~Tianchun_Li1; yfeng@fnal.gov; ~Nhan_Tran1; ~Han_Zhao1; ~Qiang_Qiu1; ~Pan_Li2,,"{'value': 'In many real-world applications, graph-structured data used for training and testing have differences in distribution, such as in high energy physics (HEP) where simulation data used for training may not match real experiments. Graph domain adaptation (GDA) is a method used to address these differences. However, current GDA primarily works by aligning the distributions of node representations output by a single graph neural network encoder shared across the training and testing domains, which may often yield sub-optimal solutions. This work examines different impacts of distribution shifts caused by either graph structure or node attributes and identifies a new type of shift, named conditional structure shift (CSS), which current GDA approaches are provably sub-optimal to deal with. A novel approach, called structural reweighting (StruRW), is proposed to address this issue and is tested on synthetic graphs, four benchmark datasets, and a new application in HEP. StruRW has shown significant performance improvement over the baselines in the settings with large graph structure shifts, and reasonable performance improvement when node attribute shift dominates.'}",https://openreview.net{'value': '/pdf/20bbc8bea38bc73bf53142ff3044046529895f14.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=elL6uw9qOX,{'value': 'GEAR: A GPU-Centric Experience Replay System for Large Reinforcement Learning Models'},Hanjing Wang; Man-Kit Sit; Congjie He; Ying Wen; Weinan Zhang; Jun Wang; Yaodong Yang; Luo Mai,~Hanjing_Wang1; ~Man-Kit_Sit1; congjie.he@ed.ac.uk; ~Ying_Wen1; ~Weinan_Zhang1; ~Jun_Wang2; ~Yaodong_Yang1; ~Luo_Mai1,,"{'value': 'This paper introduces a distributed, GPU-centric experience replay system, GEAR, designed to perform scalable reinforcement learning (RL) with large sequence models (such as transformers). With such models, existing systems such as Reverb face considerable bottlenecks in memory, computation, and communication. GEAR, however, optimizes memory efficiency by enabling the memory resources on GPU servers (including host memory and device memory) to manage trajectory data. Furthermore, it facilitates decentralized GPU devices to expedite various trajectory selection strategies, circumventing computational bottlenecks. GEAR is equipped with GPU kernels capable of collecting trajectories using zero-copy access to host memory, along with remote-directed-memory access over InfiniBand, improving communication efficiency. Cluster experiments have shown that GEAR can achieve performance levels up to 6× greater than Reverb when training state-of-the-art large RL models. GEAR is open-sourced at https:// github.com/bigrl-team/gear.'}",https://openreview.net{'value': '/pdf/86cd7170eaa066b79d29caf0a4ea22eb84eca89b.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=dopVDyZSEW,{'value': 'Learning to Suggest Breaks: Sustainable Optimization of Long-Term User Engagement'},Eden Saig; Nir Rosenfeld,~Eden_Saig1; ~Nir_Rosenfeld2,,"{'value': 'Optimizing user engagement is a key goal for modern recommendation systems, but blindly pushing users towards increased consumption risks burn-out, churn, or even addictive habits. To promote digital well-being, most platforms now offer a service that periodically prompts users to take breaks. These, however, must be set up manually, and so may be suboptimal for both users and the system. In this paper, we study the role of breaks in recommendation, and propose a framework for learning optimal breaking policies that promote and sustain long-term engagement. Based on the notion that recommendation dynamics are susceptible to both positive and negative feedback, we cast recommendation as a Lotka-Volterra dynamical system, where breaking reduces to a problem of optimal control. We then give an efficient learning algorithm, provide theoretical guarantees, and empirically demonstrate the utility of our approach on semi-synthetic data.'}",https://openreview.net{'value': '/pdf/c43a90f7811db98320be931a624c5fca9cee2e14.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=dA6biC3XgO,{'value': 'RLang: A Declarative Language for Describing Partial World Knowledge to Reinforcement Learning Agents'},Rafael Rodriguez-Sanchez; Benjamin Adin Spiegel; Jennifer Wang; Roma Patel; Stefanie Tellex; George Konidaris,~Rafael_Rodriguez-Sanchez1; ~Benjamin_Adin_Spiegel1; jennifer_wang2@brown.edu; ~Roma_Patel1; ~Stefanie_Tellex1; ~George_Konidaris1,,"{'value': 'We introduce RLang, a domain-specific language (DSL) for communicating domain knowledge to an RL agent. Unlike existing RL DSLs that ground to $\\textit{single}$ elements of a decision-making formalism (e.g., the reward function or policy), RLang can specify information about every element of a Markov decision process. We define precise syntax and grounding semantics for RLang, and provide a parser that grounds RLang programs to an algorithm-agnostic $\\textit{partial}$ world model and policy that can be exploited by an RL agent. We provide a series of example RLang programs demonstrating how different RL methods can exploit the resulting knowledge, encompassing model-free and model-based tabular algorithms, policy gradient and value-based methods, hierarchical approaches, and deep methods.'}",https://openreview.net{'value': '/pdf/0b31bbae582e202c9146f85c258a445e4ea00856.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=cnILy0dQUr,{'value': 'FusionRetro: Molecule Representation Fusion via In-Context Learning for Retrosynthetic Planning'},Songtao Liu; Zhengkai Tu; Minkai Xu; Zuobai Zhang; Lu Lin; Zhitao Ying; Jian Tang; Peilin Zhao; Dinghao Wu,~Songtao_Liu2; ~Zhengkai_Tu1; ~Minkai_Xu1; ~Zuobai_Zhang1; ~Lu_Lin2; ~Zhitao_Ying1; ~Jian_Tang1; ~Peilin_Zhao2; ~Dinghao_Wu1,,"{'value': 'Retrosynthetic planning aims to devise a complete multi-step synthetic route from starting materials to a target molecule. Current strategies use a decoupled approach of single-step retrosynthesis models and search algorithms, taking only the product as the input to predict the reactants for each planning step and ignoring valuable context information along the synthetic route. In this work, we propose a novel framework that utilizes context information for improved retrosynthetic planning. We view synthetic routes as reaction graphs and propose to incorporate context through three principled steps: encode molecules into embeddings, aggregate information over routes, and readout to predict reactants. Our approach is the first attempt to utilize in-context learning for retrosynthesis prediction in retrosynthetic planning. The entire framework can be efficiently optimized in an end-to-end fashion and produce more practical and accurate predictions. Comprehensive experiments demonstrate that by fusing in the context information over routes, our model significantly improves the performance of retrosynthetic planning over baselines that are not context-aware, especially for long synthetic routes. Code is available at https://github.com/SongtaoLiu0823/FusionRetro.'}",https://openreview.net{'value': '/pdf/adf10ff2f0471fcc5b2c025086f413d8663042ec.pdf'},{'title_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=cnGgsXpf2H,{'value': 'From Temporal to Contemporaneous Iterative Causal Discovery in the Presence of Latent Confounders'},Raanan Yehezkel Rohekar; Shami Nisimov; Yaniv Gurwicz; Gal Novik,~Raanan_Yehezkel_Rohekar1; ~Shami_Nisimov3; ~Yaniv_Gurwicz1; ~Gal_Novik1,,"{'value': 'We present a constraint-based algorithm for learning causal structures from observational time-series data, in the presence of latent confounders. We assume a discrete-time, stationary structural vector autoregressive process, with both temporal and contemporaneous causal relations. One may ask if temporal and contemporaneous relations should be treated differently. The presented algorithm gradually refines a causal graph by learning long-term temporal relations before short-term ones, where contemporaneous relations are learned last. This ordering of causal relations to be learnt leads to a reduction in the required number of statistical tests. We validate this reduction empirically and demonstrate that it leads to higher accuracy for synthetic data and more plausible causal graphs for real-world data compared to state-of-the-art algorithms.'}",https://openreview.net{'value': '/pdf/d985b4307d2ff5d743b09a465fdbc9ed0124d6ef.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=cfUDirIjOd,{'value': 'Learning to Optimize Differentiable Games'},Xuxi Chen; Nelson Vadori; Tianlong Chen; Zhangyang Wang,~Xuxi_Chen1; ~Nelson_Vadori1; ~Tianlong_Chen1; ~Zhangyang_Wang1,,"{'value': 'Many machine learning problems can be abstracted in solving game theory formulations and boil down to optimizing nested objectives, such as generative adversarial networks (GANs) and multi-agent reinforcement learning. Solving these games requires finding their stable fixed points or Nash equilibrium. However, existing algorithms for solving games suffer from empirical instability, hence demanding heavy ad-hoc tuning in practice. To tackle these challenges, we resort to the emerging scheme of Learning to Optimize (L2O), which discovers problem-specific efficient optimization algorithms through data-driven training. Our customized L2O framework for differentiable game theory problems, dubbed ``Learning to Play Games"" (L2PG), seeks a stable fixed point solution, by predicting the fast update direction from the past trajectory, with a novel gradient stability-aware, sign-based loss function. We further incorporate curriculum learning and self-learning to strengthen the empirical training stability and generalization of L2PG. On test problems including quadratic games and GANs, L2PG can substantially accelerate the convergence, and demonstrates a remarkably more stable trajectory. Codes are available at https://github.com/VITA-Group/L2PG.'}",https://openreview.net{'value': '/pdf/1fc1502d30f5da7f522225f644992f002d11993f.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=ccwSdYv1GI,{'value': 'Scaling Up Dataset Distillation to ImageNet-1K with Constant Memory'},Justin Cui; Ruochen Wang; Si Si; Cho-Jui Hsieh,~Justin_Cui1; ~Ruochen_Wang2; ~Si_Si1; ~Cho-Jui_Hsieh1,,"{'value': 'Dataset Distillation is a newly emerging area that aims to distill large datasets into much smaller and highly informative synthetic ones to accelerate training and reduce storage. Among various dataset distillation methods, trajectory-matching-based methods (MTT) have achieved SOTA performance in many tasks, e.g., on CIFAR-10/100. However, due to exorbitant memory consumption when unrolling optimization through SGD steps, MTT fails to scale to large-scale datasets such as ImageNet-1K. Can we scale this SOTA method to ImageNet-1K and does its effectiveness on CIFAR transfer to ImageNet-1K? To answer these questions, we first propose a procedure to exactly compute the unrolled gradient with constant memory complexity, which allows us to scale MTT to ImageNet-1K seamlessly with $\\sim 6$x reduction in memory footprint. We further discover that it is challenging for MTT to handle datasets with a large number of classes, and propose a novel soft label assignment that drastically improves its convergence. The resulting algorithm sets new SOTA on ImageNet-1K: we can scale up to 50 IPCs (Image Per Class) on ImageNet-1K on a single GPU (all previous methods can only scale to 2 IPCs on ImageNet-1K), leading to the best accuracy (only 5.9% accuracy drop against full dataset training) while utilizing only 4.2% of the number of data points - an 18.2% absolute gain over prior SOTA.'}",https://openreview.net{'value': '/pdf/3651ead0d5a41f78c3932928bc730c5d78e1f9e7.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=c8DEV8h93W,{'value': 'Contextual Combinatorial Bandits with Probabilistically Triggered Arms'},Xutong Liu; Jinhang Zuo; Siwei Wang; John C.S. Lui; Mohammad Hajiesmaili; Adam Wierman; Wei Chen,~Xutong_Liu1; ~Jinhang_Zuo1; ~Siwei_Wang2; ~John_C.S._Lui2; ~Mohammad_Hajiesmaili1; ~Adam_Wierman1; ~Wei_Chen10,,"{'value': 'We study contextual combinatorial bandits with probabilistically triggered arms (C$^2$MAB-T) under a variety of smoothness conditions that capture a wide range of applications, such as contextual cascading bandits and contextual influence maximization bandits. Under the triggering probability modulated (TPM) condition, we devise the C$^2$-UCB-T algorithm and propose a novel analysis that achieves an $\\tilde{O}(d\\sqrt{KT})$ regret bound, removing a potentially exponentially large factor $O(1/p_{\\min})$, where $d$ is the dimension of contexts, $p_{\\min}$ is the minimum positive probability that any arm can be triggered, and batch-size $K$ is the maximum number of arms that can be triggered per round. Under the variance modulated (VM) or triggering probability and variance modulated (TPVM) conditions, we propose a new variance-adaptive algorithm VAC$^2$-UCB and derive a regret bound $\\tilde{O}(d\\sqrt{T})$, which is independent of the batch-size $K$. As a valuable by-product, our analysis technique and variance-adaptive algorithm can be applied to the CMAB-T and C$^2$MAB setting, improving existing results there as well. We also include experiments that demonstrate the improved performance of our algorithms compared with benchmark algorithms on synthetic and real-world datasets.'}",https://openreview.net{'value': '/pdf/8940ebdcc5ee05021c354acabaef0e647515bbc7.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=beHp3L9KXc,{'value': 'Better Training of GFlowNets with Local Credit and Incomplete Trajectories'},Ling Pan; Nikolay Malkin; Dinghuai Zhang; Yoshua Bengio,~Ling_Pan1; ~Nikolay_Malkin1; ~Dinghuai_Zhang1; ~Yoshua_Bengio1,,"{'value': 'Generative Flow Networks or GFlowNets are related to Monte-Carlo Markov chain methods (as they sample from a distribution specified by an energy function), reinforcement learning (as they learn a policy to sample composed objects through a sequence of steps), generative models (as they learn to represent and sample from a distribution) and amortized variational methods (as they can be used to learn to approximate and sample from an otherwise intractable posterior, given a prior and a likelihood). They are trained to generate an object $x$ through a sequence of steps with probability proportional to some reward function $R(x)$ (or $\\exp(-\\mathcal{E}(x))$ with $\\mathcal{E}(x)$ denoting the energy function), given at the end of the generative trajectory. Like for other RL settings where the reward is only given at the end, the efficiency of training and credit assignment may suffer when those trajectories are longer. With previous GFlowNet work, no learning was possible from incomplete trajectories (lacking a terminal state and the computation of the associated reward). In this paper, we consider the case where the energy function can be applied not just to terminal states but also to intermediate states. This is for example achieved when the energy function is additive, with terms available along the trajectory. We show how to reparameterize the GFlowNet state flow function to take advantage of the partial reward already accrued at each state. This enables a training objective that can be applied to update parameters even with incomplete trajectories. Even when complete trajectories are available, being able to obtain more localized credit and gradients is found to speed up training convergence, as demonstrated across many simulations.'}",https://openreview.net{'value': '/pdf/bc6b60545823fd6d7354e0f44e2b767f5205adce.pdf'},{'title_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=bbKEGbS7aN,{'value': 'Optimal Shrinkage for Distributed Second-Order Optimization'},Fangzhao Zhang; Mert Pilanci,~Fangzhao_Zhang1; ~Mert_Pilanci3,,"{'value': ""In this work, we address the problem of Hessian inversion bias in distributed second-order optimization algorithms. We introduce a novel shrinkage-based estimator for the resolvent of gram matrices which is asymptotically unbiased, and characterize its non-asymptotic convergence rate in the isotropic case. We apply this estimator to bias correction of Newton steps in distributed second-order optimization algorithms, as well as randomized sketching based methods. We examine the bias present in the naive averaging-based distributed Newton's method using analytical expressions and contrast it with our proposed biasfree approach. Our approach leads to significant improvements in convergence rate compared to standard baselines and recent proposals, as shown through experiments on both real and synthetic datasets.""}",https://openreview.net{'value': '/pdf/fafb59fd0c77d7bf2ec130bf95edccfffa2fe4e3.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=bBLjms8nZE,{'value': 'Scaling Laws for Reward Model Overoptimization'},Leo Gao; John Schulman; Jacob Hilton,~Leo_Gao1; ~John_Schulman1; ~Jacob_Hilton1,,"{'value': ""In reinforcement learning from human feedback, it is common to optimize against a reward model trained to predict human preferences. Because the reward model is an imperfect proxy, optimizing its value too much can hinder ground truth performance, in accordance with Goodhart's law. This effect has been frequently observed, but not carefully measured due to the expense of collecting human preference data. In this work, we use a synthetic setup in which a fixed ``gold-standard'' reward model plays the role of humans, providing labels used to train a proxy reward model. We study how the gold reward model score changes as we optimize against the proxy reward model using either reinforcement learning or best-of-$n$ sampling. We find that this relationship follows a different functional form depending on the method of optimization, and that in both cases its coefficients scale smoothly with the number of reward model parameters. We also study the effect on this relationship of the size of the reward model dataset, the number of reward model and policy parameters, and the coefficient of the KL penalty added to the reward in the reinforcement learning setup. We explore the implications of these empirical results for theoretical considerations in AI alignment.""}",https://openreview.net{'value': '/pdf/5922fc32f0d360192fe9d51e1b5cc92663ef4e22.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=agPrVQdnxT,{'value': 'The Impact of Exploration on Convergence and Performance of Multi-Agent Q-Learning Dynamics'},Aamal Hussain; Francesco Belardinelli; Dario Paccagnan,~Aamal_Hussain1; ~Francesco_Belardinelli1; ~Dario_Paccagnan1,,"{'value': 'Understanding the impact of exploration on the behaviour of multi-agent learning has, so far, benefited from the restriction to potential, or network zero-sum games in which convergence to an equilibrium can be shown. Outside of these classes, learning dynamics rarely converge and little is known about the effect of exploration in the face of non-convergence. To progress this front, we study the smooth Q- Learning dynamics. We show that, in any network game, exploration by agents results in the convergence of Q-Learning to a neighbourhood of an equilibrium. This holds independently of whether the dynamics reach the equilibrium or display complex behaviours. We show that increasing the exploration rate decreases the size of this neighbourhood and also decreases the ability of all agents to improve their payoffs. Furthermore, in a broad class of games, the payoff performance of Q-Learning dynamics, measured by Social Welfare, decreases when the exploration rate increases. Our experiments show this to be a general phenomenon, namely that exploration leads to improved convergence of Q-Learning, at the cost of payoff performance.'}",https://openreview.net{'value': '/pdf/ba84304a16e0bff4a5f56e800a79764d39169557.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=aX9jtC2lfS,{'value': 'Hypervolume Knowledge Gradient: A Lookahead Approach for Multi-Objective Bayesian Optimization with Partial Information'},Sam Daulton; Maximilian Balandat; Eytan Bakshy,~Sam_Daulton1; ~Maximilian_Balandat1; ~Eytan_Bakshy1,,"{'value': 'Bayesian optimization is a popular method for sample efficient multi-objective optimization. However, existing Bayesian optimization techniques fail to effectively exploit common and often-neglected problem structure such as decoupled evaluations, where objectives can be queried independently from one another and each may consume different resources, or multi-fidelity evaluations, where lower fidelity-proxies of the objectives can be evaluated at lower cost. In this work, we propose a general one-step lookahead acquisition function based on the Knowledge Gradient that addresses the complex question of what to evaluate when and at which design points in a principled Bayesian decision-theoretic fashion. Hence, our approach naturally addresses decoupled, multi-fidelity, and standard multi-objective optimization settings in a unified Bayesian decision making framework. By construction, our method is the one-step Bayes-optimal policy for hypervolume maximization. Empirically, we demonstrate that our method improves sample efficiency in a wide variety of synthetic and real-world problems. Furthermore, we show that our method is general-purpose and yields competitive performance in standard (potentially noisy) multi-objective optimization.'}",https://openreview.net{'value': '/pdf/f5a9e56c3e1395b8deea110e756201378063e0fa.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=aAGrNFHmVd,{'value': 'Minimizing Trajectory Curvature of ODE-based Generative Models'},Sangyun Lee; Beomsu Kim; Jong Chul Ye,~Sangyun_Lee1; ~Beomsu_Kim1; ~Jong_Chul_Ye1,,"{'value': 'Recent ODE/SDE-based generative models, such as diffusion models, rectified flows, and flow matching, define a generative process as a time reversal of a fixed forward process. Even though these models show impressive performance on large-scale datasets, numerical simulation requires multiple evaluations of a neural network, leading to a slow sampling speed. We attribute the reason to the high curvature of the learned generative trajectories, as it is directly related to the truncation error of a numerical solver. Based on the relationship between the forward process and the curvature, here we present an efficient method of training the forward process to minimize the curvature of generative trajectories without any ODE/SDE simulation. Experiments show that our method achieves a lower curvature than previous models and, therefore, decreased sampling costs while maintaining competitive performance. Code is available at https://github.com/sangyun884/fast-ode.'}",https://openreview.net{'value': '/pdf/ce0e80995484de8ec6c593ad3c3010a335b502c1.pdf'},{'title_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=a6PvWIHFsF,{'value': 'Learning Deductive Reasoning from Synthetic Corpus based on Formal Logic'},Terufumi Morishita; Gaku Morio; Atsuki Yamaguchi; Yasuhiro Sogawa,~Terufumi_Morishita1; ~Gaku_Morio1; ~Atsuki_Yamaguchi1; ~Yasuhiro_Sogawa1,,"{'value': 'We study a synthetic corpus based approach for language models (LMs) to acquire logical deductive reasoning ability. The previous studies generated deduction examples using specific sets of deduction rules. However, these rules were limited or otherwise arbitrary. This can limit the generalizability of acquired deductive reasoning ability. We rethink this and adopt a well-grounded set of deduction rules based on formal logic theory, which can derive any other deduction rules when combined in a multistep way. We empirically verify that LMs trained on the proposed corpora, which we name $\\textbf{FLD}$ ($\\textbf{F}$ormal $\\textbf{L}$ogic $\\textbf{D}$eduction), acquire more generalizable deductive reasoning ability. Furthermore, we identify the aspects of deductive reasoning ability on which deduction corpora can enhance LMs and those on which they cannot. Finally, on the basis of these results, we discuss the future directions for applying deduction corpora or other approaches for each aspect. We release the code, data, and models.'}",https://openreview.net{'value': '/pdf/b0ac16166c8c3dcbfd0e487ba7a5a16760f4d777.pdf'},{'title_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=ZtvnhohkVk,{'value': 'Neural Markov Jump Processes'},Patrick Seifner; Ramses J Sanchez,~Patrick_Seifner1; ~Ramses_J_Sanchez1,,"{'value': 'Markov jump processes are continuous-time stochastic processes with a wide range of applications in both natural and social sciences. Despite their widespread use, inference in these models is highly non-trivial and typically proceeds via either Monte Carlo or expectation-maximization methods. In this work we introduce an alternative, variational inference algorithm for Markov jump processes which relies on neural ordinary differential equations, and is trainable via back-propagation. Our methodology learns neural, continuous-time representations of the observed data, that are used to approximate the initial distribution and time-dependent transition probability rates of the posterior Markov jump process. The time-independent rates of the prior process are in contrast trained akin to generative adversarial networks. We test our approach on synthetic data sampled from ground-truth Markov jump processes, experimental switching ion channel data and molecular dynamics simulations. Source code to reproduce our experiments is available online.'}",https://openreview.net{'value': '/pdf/b74c0c12136e5c7343ee0d0f450575663f5a311b.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=ZXeTCRZJp9,{'value': 'Invariant Slot Attention: Object Discovery with Slot-Centric Reference Frames'},Ondrej Biza; Sjoerd van Steenkiste; Mehdi S. M. Sajjadi; Gamaleldin Fathy Elsayed; Aravindh Mahendran; Thomas Kipf,~Ondrej_Biza1; ~Sjoerd_van_Steenkiste1; ~Mehdi_S._M._Sajjadi1; ~Gamaleldin_Fathy_Elsayed1; ~Aravindh_Mahendran2; ~Thomas_Kipf2,,"{'value': 'Automatically discovering composable abstractions from raw perceptual data is a long-standing challenge in machine learning. Recent slot-based neural networks that learn about objects in a self-supervised manner have made exciting progress in this direction. However, they typically fall short at adequately capturing spatial symmetries present in the visual world, which leads to sample inefficiency, such as when entangling object appearance and pose. In this paper, we present a simple yet highly effective method for incorporating spatial symmetries via slot-centric reference frames. We incorporate equivariance to per-object pose transformations into the attention and generation mechanism of Slot Attention by translating, scaling, and rotating position encodings. These changes result in little computational overhead, are easy to implement, and can result in large gains in terms of data efficiency and overall improvements to object discovery. We evaluate our method on a wide range of synthetic object discovery benchmarks namely CLEVR, Tetrominoes, CLEVRTex, Objects Room and MultiShapeNet, and show promising improvements on the challenging real-world Waymo Open dataset.'}",https://openreview.net{'value': '/pdf/9d3b5881d325fcfa1dd499fe3097d407a3a8d26c.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=ZXXPQ8GptX,{'value': 'Online Platt Scaling with Calibeating'},Chirag Gupta; Aaditya Ramdas,~Chirag_Gupta1; ~Aaditya_Ramdas2,,"{'value': 'We present an online post-hoc calibration method, called Online Platt Scaling (OPS), which combines the Platt scaling technique with online logistic regression. We demonstrate that OPS smoothly adapts between i.i.d. and non-i.i.d. settings with distribution drift. Further, in scenarios where the best Platt scaling model is itself miscalibrated, we enhance OPS by incorporating a recently developed technique called calibeating to make it more robust. Theoretically, our resulting OPS+calibeating method is guaranteed to be calibrated for adversarial outcome sequences. Empirically, it is effective on a range of synthetic and real-world datasets, with and without distribution drifts, achieving superior performance without hyperparameter tuning. Finally, we extend all OPS ideas to the beta scaling method.'}",https://openreview.net{'value': '/pdf/ef8c3d22379a675d403a2f8b29d36e342755afe6.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=ZMDv1Mo89E,{'value': 'Are Diffusion Models Vulnerable to Membership Inference Attacks?'},Jinhao Duan; Fei Kong; Shiqi Wang; Xiaoshuang Shi; Kaidi Xu,~Jinhao_Duan1; ~Fei_Kong1; ~Shiqi_Wang2; ~Xiaoshuang_Shi2; ~Kaidi_Xu1,,"{'value': 'Diffusion-based generative models have shown great potential for image synthesis, but there is a lack of research on the security and privacy risks they may pose. In this paper, we investigate the vulnerability of diffusion models to Membership Inference Attacks (MIAs), a common privacy concern. Our results indicate that existing MIAs designed for GANs or VAE are largely ineffective on diffusion models, either due to inapplicable scenarios (e.g., requiring the discriminator of GANs) or inappropriate assumptions (e.g., closer distances between synthetic samples and member samples). To address this gap, we propose Step-wise Error Comparing Membership Inference (SecMI), a query-based MIA that infers memberships by assessing the matching of forward process posterior estimation at each timestep. SecMI follows the common overfitting assumption in MIA where member samples normally have smaller estimation errors, compared with hold-out samples. We consider both the standard diffusion models, e.g., DDPM, and the text-to-image diffusion models, e.g., Latent Diffusion Models and Stable Diffusion. Experimental results demonstrate that our methods precisely infer the membership with high confidence on both of the two scenarios across multiple different datasets. Code is available at https://github.com/jinhaoduan/SecMI.'}",https://openreview.net{'value': '/pdf/8e4384a6e2298ca30bb514e212e7b9e93f1728c2.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=YxpkGn5Oly,{'value': 'Tilted Sparse Additive Models'},Yingjie Wang; Hong Chen; Weifeng Liu; Fengxiang He; Tieliang Gong; Youcheng Fu; Dacheng Tao,~Yingjie_Wang1; ~Hong_Chen1; ~Weifeng_Liu1; ~Fengxiang_He1; ~Tieliang_Gong2; ~Youcheng_Fu2; ~Dacheng_Tao1,,"{'value': 'Additive models have been burgeoning in data analysis due to their flexible representation and desirable interpretability. However, most existing approaches are constructed under empirical risk minimization (ERM), and thus perform poorly in situations where average performance is not a suitable criterion for the problems of interest, e.g., data with complex non-Gaussian noise, imbalanced labels or both of them. In this paper, a novel class of sparse additive models is proposed under tilted empirical risk minimization (TERM), which addresses the deficiencies in ERM by imposing tilted impact on individual losses, and is flexibly capable of achieving a variety of learning objectives, e.g., variable selection, robust estimation, imbalanced classification and multiobjective learning. On the theoretical side, a learning theory analysis which is centered around the generalization bound and function approximation error bound (under some specific data distributions) is conducted rigorously. On the practical side, an accelerated optimization algorithm is designed by integrating Prox-SVRG and random Fourier acceleration technique. The empirical assessments verify the competitive performance of our approach on both synthetic and real data.'}",https://openreview.net{'value': '/pdf/fbeb18ae7795aefc5ba2d0d5d572f197831ff25b.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=YhRsYVwTHv,{'value': 'Revisiting Data-Free Knowledge Distillation with Poisoned Teachers'},Junyuan Hong; Yi Zeng; Shuyang Yu; Lingjuan Lyu; Ruoxi Jia; Jiayu Zhou,~Junyuan_Hong1; ~Yi_Zeng3; ~Shuyang_Yu1; ~Lingjuan_Lyu1; ~Ruoxi_Jia1; ~Jiayu_Zhou1,,"{'value': 'Data-free knowledge distillation (KD) helps transfer knowledge from a pre-trained model (known as the teacher model) to a smaller model (known as the student model) without access to the original training data used for training the teacher model. However, the security of the synthetic or out-of-distribution (OOD) data required in data-free KD is largely unknown and under-explored. In this work, we make the first effort to uncover the security risk of data-free KD w.r.t. untrusted pre-trained models. We then propose Anti-Backdoor Data-Free KD (ABD), the first plug-in defensive method for data-free KD methods to mitigate the chance of potential backdoors being transferred. We empirically evaluate the effectiveness of our proposed ABD in diminishing transferred backdoor knowledge while maintaining compatible downstream performances as the vanilla KD. We envision this work as a milestone for alarming and mitigating the potential backdoors in data-free KD. Codes are released at https://github.com/illidanlab/ABD .'}",https://openreview.net{'value': '/pdf/730f2615395af86b0e8a6902ca1a2d3d602249b2.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=YeTYJz7th5,{'value': 'Learning Temporally AbstractWorld Models without Online Experimentation'},Benjamin Freed; Siddarth Venkatraman; Guillaume Adrien Sartoretti; Jeff Schneider; Howie Choset,~Benjamin_Freed1; ~Siddarth_Venkatraman1; ~Guillaume_Adrien_Sartoretti1; ~Jeff_Schneider1; ~Howie_Choset1,,"{'value': 'Agents that can build temporally abstract representations of their environment are better able to understand their world and make plans on extended time scales, with limited computational power and modeling capacity. However, existing methods for automatically learning temporally abstract world models usually require millions of online environmental interactions and incentivize agents to reach every accessible environmental state, which is infeasible for most real-world robots both in terms of data efficiency and hardware safety. In this paper, we present an approach for simultaneously learning sets of skills and temporally abstract, skill-conditioned world models purely from offline data, enabling agents to perform zero-shot online planning of skill sequences for new tasks. We show that our approach performs comparably to or better than a wide array of state-of-the-art offline RL algorithms on a number of simulated robotics locomotion and manipulation benchmarks, while offering a higher degree of adaptability to new goals. Finally, we show that our approach offers a much higher degree of robustness to perturbations in environmental dynamics, compared to policy-based methods.'}",https://openreview.net{'value': '/pdf/2dce3d5ae98c6eea25ade5258561c7723d60ba65.pdf'},{'abstract_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=YZoYYaawO2,{'value': 'Differentiable Tree Operations Promote Compositional Generalization'},Paul Soulos; Edward J Hu; Kate McCurdy; Yunmo Chen; Roland Fernandez; Paul Smolensky; Jianfeng Gao,~Paul_Soulos1; ~Edward_J_Hu1; ~Kate_McCurdy1; ~Yunmo_Chen1; ~Roland_Fernandez1; ~Paul_Smolensky1; ~Jianfeng_Gao1,,"{'value': 'In the context of structure-to-structure transformation tasks, learning sequences of discrete symbolic operations poses significant challenges due to their non-differentiability. To facilitate the learning of these symbolic sequences, we introduce a differentiable tree interpreter that compiles high-level symbolic tree operations into subsymbolic matrix operations on tensors. We present a novel Differentiable Tree Machine (DTM) architecture that integrates our interpreter with an external memory and an agent that learns to sequentially select tree operations to execute the target transformation in an end-to-end manner. With respect to out-of-distribution compositional generalization on synthetic semantic parsing and language generation tasks, DTM achieves 100% while existing baselines such as Transformer, Tree Transformer, LSTM, and Tree2Tree LSTM achieve less than 30%. DTM remains highly interpretable in addition to its perfect performance.'}",https://openreview.net{'value': '/pdf/075cab9bac0c5038698762311e1aae907f5c2c25.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=YIWtM3GdZc,{'value': 'A Closer Look at the Intervention Procedure of Concept Bottleneck Models'},Sungbin Shin; Yohan Jo; Sungsoo Ahn; Namhoon Lee,~Sungbin_Shin1; ~Yohan_Jo1; ~Sungsoo_Ahn1; ~Namhoon_Lee1,,"{'value': 'Concept bottleneck models (CBMs) are a class of interpretable neural network models that predict the target response of a given input based on its high-level concepts. Unlike the standard end-to-end models, CBMs enable domain experts to intervene on the predicted concepts and rectify any mistakes at test time, so that more accurate task predictions can be made at the end. While such intervenability provides a powerful avenue of control, many aspects of the intervention procedure remain rather unexplored. In this work, we develop various ways of selecting intervening concepts to improve the intervention effectiveness and conduct an array of in-depth analyses as to how they evolve under different circumstances. Specifically, we find that an informed intervention strategy can reduce the task error more than ten times compared to the current baseline under the same amount of intervention counts in realistic settings, and yet, this can vary quite significantly when taking into account different intervention granularity. We verify our findings through comprehensive evaluations, not only on the standard real datasets, but also on synthetic datasets that we generate based on a set of different causal graphs. We further discover some major pitfalls of the current practices which, without a proper addressing, raise concerns on reliability and fairness of the intervention procedure.'}",https://openreview.net{'value': '/pdf/0f1de16b363e669c11c75cc99a59048a76488c53.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=XyzhpYy2G4,{'value': 'Dynamical Linear Bandits'},Marco Mussi; Alberto Maria Metelli; Marcello Restelli,~Marco_Mussi1; ~Alberto_Maria_Metelli2; ~Marcello_Restelli1,,"{'value': 'In many real-world sequential decision-making problems, an action does not immediately reflect on the feedback and spreads its effects over a long time frame. For instance, in online advertising, investing in a platform produces an instantaneous increase of awareness, but the actual reward, i.e., a conversion, might occur far in the future. Furthermore, whether a conversion takes place depends on: how fast the awareness grows, its vanishing effects, and the synergy or interference with other advertising platforms. Previous work has investigated the Multi-Armed Bandit framework with the possibility of delayed and aggregated feedback, without a particular structure on how an action propagates in the future, disregarding possible dynamical effects. In this paper, we introduce a novel setting, the Dynamical Linear Bandits (DLB), an extension of the linear bandits characterized by a hidden state. When an action is performed, the learner observes a noisy reward whose mean is a linear function of the hidden state and of the action. Then, the hidden state evolves according to linear dynamics, affected by the performed action too. We start by introducing the setting, discussing the notion of optimal policy, and deriving an expected regret lower bound. Then, we provide an optimistic regret minimization algorithm, Dynamical Linear Upper Confidence Bound (DynLin-UCB), that suffers an expected regret of order $\\widetilde{\\mathcal{O}} \\Big( \\frac{d \\sqrt{T}}{(1-\\overline{\\rho})^{3/2}} \\Big)$, where $\\overline{\\rho}$ is a measure of the stability of the system, and $d$ is the dimension of the action vector. Finally, we conduct a numerical validation on a synthetic environment and on real-world data to show the effectiveness of DynLin-UCB in comparison with several baselines.'}",https://openreview.net{'value': '/pdf/fde7a7d1d2197ead45bfda7e5ff036d4d03f8054.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=Xqedp0Iu1S,{'value': 'Constant Matters: Fine-grained Error Bound on Differentially Private Continual Observation'},Hendrik Fichtenberger; Monika Henzinger; Jalaj Upadhyay,~Hendrik_Fichtenberger1; ~Monika_Henzinger1; ~Jalaj_Upadhyay1,,"{'value': 'We study fine-grained error bounds for differentially private algorithms for counting under continual observation. Our main insight is that the matrix mechanism when using lower-triangular matrices can be used in the continual observation model. More specifically, we give an explicit factorization for the counting matrix $M_\\mathsf{count}$ and upper bound the error explicitly. We also give a fine-grained analysis, specifying the exact constant in the upper bound. Our analysis is based on upper and lower bounds of the *completely bounded norm* (cb-norm) of $M_\\mathsf{count}$. Along the way, we improve the best-known bound of 28 years by Mathias (SIAM Journal on Matrix Analysis and Applications, 1993) on the cb-norm of $M_\\mathsf{count}$ for a large range of the dimension of $M_\\mathsf{count}$. Furthermore, we are the first to give concrete error bounds for various problems under continual observation such as binary counting, maintaining a histogram, releasing an approximately cut-preserving synthetic graph, many graph-based statistics, and substring and episode counting. Finally, we note that our result can be used to get a fine-grained error bound for non-interactive local learning and the first lower bounds on the additive error for $(\\epsilon,\\delta)$-differentially-private counting under continual observation. Subsequent to this work, Henzinger et al. (SODA, 2023) showed that our factorization also achieves fine-grained mean-squared error.'}",https://openreview.net{'value': '/pdf/1a3267e64796bda5b3b1be8455c32ecf96c7e80f.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=X8h8wLjog7,{'value': 'Learning the Right Layers a Data-Driven Layer-Aggregation Strategy for Semi-Supervised Learning on Multilayer Graphs'},Sara Venturini; Andrea Cristofari; Francesco Rinaldi; Francesco Tudisco,~Sara_Venturini1; andrea.cristofari@uniroma2.it; rinaldi@math.unipd.it; ~Francesco_Tudisco1,,"{'value': 'Clustering (or community detection) on multilayer graphs poses several additional complications with respect to standard graphs as different layers may be characterized by different structures and types of information. One of the major challenges is to establish the extent to which each layer contributes to the cluster assignment in order to effectively take advantage of the multilayer structure and improve upon the classification obtained using the individual layers or their union. However, making an informed a-priori assessment about the clustering information content of the layers can be very complicated. In this work, we assume a semi-supervised learning setting, where the class of a small percentage of nodes is initially provided, and we propose a parameter-free Laplacian-regularized model that learns an optimal nonlinear combination of the different layers from the available input labels. The learning algorithm is based on a Frank-Wolfe optimization scheme with inexact gradient, combined with a modified Label Propagation iteration. We provide a detailed convergence analysis of the algorithm and extensive experiments on synthetic and real-world datasets, showing that the proposed method compares favourably with a variety of baselines and outperforms each individual layer when used in isolation.'}",https://openreview.net{'value': '/pdf/8c2146cc33d9dbb02f2960057c71a096203c4aec.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=WlIJAlWou5,{'value': 'Double-Weighting for Covariate Shift Adaptation'},Jose Ignacio Segovia; Santiago Mazuelas; Anqi Liu,~Jose_Ignacio_Segovia1; ~Santiago_Mazuelas1; ~Anqi_Liu2,,"{'value': 'Supervised learning is often affected by a covariate shift in which the marginal distributions of instances (covariates $x$) of training and testing samples $p_\\text{tr}(x)$ and $p_\\text{te}(x)$ are different but the label conditionals coincide. Existing approaches address such covariate shift by either using the ratio $p_\\text{te}(x)/p_\\text{tr}(x)$ to weight training samples (reweighted methods) or using the ratio $p_\\text{tr}(x)/p_\\text{te}(x)$ to weight testing samples (robust methods). However, the performance of such approaches can be poor under support mismatch or when the above ratios take large values. We propose a minimax risk classification (MRC) approach for covariate shift adaptation that avoids such limitations by weighting both training and testing samples. In addition, we develop effective techniques that obtain both sets of weights and generalize the conventional kernel mean matching method. We provide novel generalization bounds for our method that show a significant increase in the effective sample size compared with reweighted methods. The proposed method also achieves enhanced classification performance in both synthetic and empirical experiments.'}",https://openreview.net{'value': '/pdf/ecaa11e62c1387173056935860dcd2c1bf0e7a3c.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=WT70GgYdLI,{'value': 'Training Deep Surrogate Models with Large Scale Online Learning'},Lucas Thibaut Meyer; Marc Schouler; Robert Alexander Caulk; Alejandro Ribes; Bruno Raffin,~Lucas_Thibaut_Meyer1; marc.schouler@inria.fr; ~Robert_Alexander_Caulk1; alejandro.ribes@edf.fr; ~Bruno_Raffin1,,"{'value': ""The spatiotemporal resolution of Partial Differential Equations (PDEs) plays important roles in the mathematical description of the world's physical phenomena. In general, scientists and engineers solve PDEs numerically by the use of computationally demanding solvers. Recently, deep learning algorithms have emerged as a viable alternative for obtaining fast solutions for PDEs. Models are usually trained on synthetic data generated by solvers, stored on disk and read back for training. This paper advocates that relying on a traditional static dataset to train these models does not allow the full benefit of the solver to be used as a data generator. It proposes an open source online training framework for deep surrogate models. The framework implements several levels of parallelism focused on simultaneously generating numerical simulations and training deep neural networks. This approach suppresses the I/O and storage bottleneck associated with disk-loaded datasets, and opens the way to training on significantly larger datasets. Experiments compare the offline and online training of four surrogate models, including state-of-the-art architectures. Results indicate that exposing deep surrogate models to more dataset diversity, up to hundreds of GB, can increase model generalization capabilities. Fully connected neural networks, Fourier Neural Operator (FNO), and Message Passing PDE Solver prediction accuracy is improved by 68%, 16% and 7%, respectively.""}",https://openreview.net{'value': '/pdf/72aa08b91d30bccce9ddb82c1c90c4e00bddd8fc.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=WIvyzQAaPP,{'value': 'Nonlinear Causal Discovery with Latent Confounders'},David Kaltenpoth; Jilles Vreeken,~David_Kaltenpoth1; ~Jilles_Vreeken2,,"{'value': 'Causal discovery, the task of discovering the causal graph over a set of observed variables $X_1,\\ldots,X_m$, is a challenging problem. One of the cornerstone assumptions is that of causal sufficiency: that *all* common causes of *all* measured variables have been observed. When it does not hold, causal discovery algorithms making this assumption return networks with many spurious edges. In this paper, we propose a nonlinear causal model involving hidden confounders. We show that it is identifiable from only the observed data and propose an efficient method for recovering this causal model. At the heart of our approach is a variational autoencoder which parametrizes both the causal interactions between observed variables as well as the influence of the unobserved confounders. Empirically we show that it outperforms other state-of-the-art methods for causal discovery under latent confounding on synthetic and real-world data.'}",https://openreview.net{'value': '/pdf/a00b3ca09faf26621b51ee31f76bdd8e5af63a28.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=Vv8vyf3RtU,{'value': 'On the Occupancy Measure of Non-Markovian Policies in Continuous MDPs'},Romain Laroche; Remi Tachet des Combes,~Romain_Laroche1; ~Remi_Tachet_des_Combes1,,"{'value': 'The state-action occupancy measure of a policy is the expected (discounted or undiscounted) number of times a state-action couple is visited in a trajectory. For decades, RL books have been reporting the occupancy equivalence between Markovian and non-Markovian policies in countable state-action spaces under mild conditions. This equivalence states that the occupancy of any non-Markovian policy can be equivalently obtained by a Markovian policy, i.e. a memoryless probability distribution, conditioned only on its current state. While expected, for technical reasons, the translation of this result to continuous state space has resisted until now. Our main contribution is to fill this gap and to provide a general measure-theoretic treatment of the problem, permitting, in particular, its extension to continuous MDPs. Furthermore, we show that when the occupancy is infinite, we may encounter some non-trivial cases where the result does not hold anymore.'}",https://openreview.net{'value': '/pdf/8ea72c273be1564480c59fec69e1e9ccd7b4b19b.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=VTkBZayJos,{'value': 'Learning Noisy OR Bayesian Networks with Max-Product Belief Propagation'},Antoine Dedieu; Guangyao Zhou; Dileep George; Miguel Lazaro-Gredilla,~Antoine_Dedieu1; ~Guangyao_Zhou1; ~Dileep_George1; ~Miguel_Lazaro-Gredilla1,,"{'value': 'Noisy-OR Bayesian Networks (BNs) are a family of probabilistic graphical models which express rich statistical dependencies in binary data. Variational inference (VI) has been the main method proposed to learn noisy-OR BNs with complex latent structures (Jaakkola & Jordan, 1999; Ji et al., 2020; Buhai et al., 2020). However, the proposed VI approaches either (a) use a recognition network with standard amortized inference that cannot induce ""explaining-away""; or (b) assume a simple mean-field (MF) posterior which is vulnerable to bad local optima. Existing MF VI methods also update the MF parameters sequentially which makes them inherently slow. In this paper, we propose parallel max-product as an alternative algorithm for learning noisy-OR BNs with complex latent structures and we derive a fast stochastic training scheme that scales to large datasets. We evaluate both approaches on several benchmarks where VI is the state-of-the-art and show that our method (a) achieves better test performance than Ji et al. (2020) for learning noisy-OR BNs with hierarchical latent structures on large sparse real datasets; (b) recovers a higher number of ground truth parameters than Buhai et al. (2020) from cluttered synthetic scenes; and (c) solves the 2D blind deconvolution problem from Lazaro-Gredilla et al. (2021) and variants - including binary matrix factorization - while VI catastrophically fails and is up to two orders of magnitude slower.'}",https://openreview.net{'value': '/pdf/4bc2b88b74cf08cc0af14739c50089f8198e26c7.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=VLoypBbG3t,{'value': 'MANSA: Learning Fast and Slow in Multi-Agent Systems'},David Henry Mguni; Haojun Chen; Taher Jafferjee; Jianhong Wang; Longfei Yue; Xidong Feng; Stephen Marcus McAleer; Feifei Tong; Jun Wang; Yaodong Yang,~David_Henry_Mguni1; ~Haojun_Chen2; ~Taher_Jafferjee1; ~Jianhong_Wang1; ~Longfei_Yue2; ~Xidong_Feng1; ~Stephen_Marcus_McAleer1; ~Feifei_Tong1; ~Jun_Wang2; ~Yaodong_Yang1,,"{'value': 'In multi-agent reinforcement learning (MARL), independent learning (IL) often shows remarkable performance and easily scales with the number of agents. Yet, using IL can be inefficient and runs the risk of failing to successfully train, particularly in scenarios that require agents to coordinate their actions. Using centralised learning (CL) enables MARL agents to quickly learn how to coordinate their behaviour but employing CL everywhere is often prohibitively expensive in real-world applications. Besides, using CL in value-based methods often needs strong representational constraints (e.g. individual-global-max condition) that can lead to poor performance if violated. In this paper, we introduce a novel plug & play IL framework named Multi-Agent Network Selection Algorithm (MANSA) which selectively employs CL only at states that require coordination. At its core, MANSA has an additional agent that uses switching controls to quickly learn the best states to activate CL during training, using CL only where necessary and vastly reducing the computational burden of CL. Our theory proves MANSA preserves cooperative MARL convergence properties, boosts IL performance and can optimally make use of a fixed budget on the number CL calls. We show empirically in Level-based Foraging (LBF) and StarCraft Multi-agent Challenge (SMAC) that MANSA achieves fast, superior and more reliable performance while making 40% fewer CL calls in SMAC and using CL at only 1% CL calls in LBF.'}",https://openreview.net{'value': '/pdf/4d8d107406ad6d80478f2ae9537c0a74e1990ab5.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=V4jD1KmnQz,{'value': 'Local Optimization Achieves Global Optimality in Multi-Agent Reinforcement Learning'},Yulai Zhao; Zhuoran Yang; Zhaoran Wang; Jason D. Lee,~Yulai_Zhao1; ~Zhuoran_Yang1; ~Zhaoran_Wang1; ~Jason_D._Lee1,,"{'value': 'Policy optimization methods with function approximation are widely used in multi-agent reinforcement learning. However, it remains elusive how to design such algorithms with statistical guarantees. Leveraging a multi-agent performance difference lemma that characterizes the landscape of multi-agent policy optimization, we find that the localized action value function serves as an ideal descent direction for each local policy. Motivated by the observation, we present a multi-agent PPO algorithm in which the local policy of each agent is updated similarly to vanilla PPO. We prove that with standard regularity conditions on the Markov game and problem-dependent quantities, our algorithm converges to the globally optimal policy at a sublinear rate. We extend our algorithm to the off-policy setting and introduce pessimism to policy evaluation, which aligns with experiments. To our knowledge, this is the first provably convergent multi-agent PPO algorithm in cooperative Markov games.'}",https://openreview.net{'value': '/pdf/53cbced07597bf30f212ff35398e24d59c701dfa.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=V1YbiqUsMi,{'value': 'Coupled Variational Autoencoder'},Xiaoran Hao; Patrick Shafto,~Xiaoran_Hao1; ~Patrick_Shafto2,,"{'value': 'Variational auto-encoders are powerful probabilistic models in generative tasks but suffer from generating low-quality samples which are caused by the holes in the prior. We propose the Coupled Variational Auto-Encoder (C-VAE), which formulates the VAE problem as one of Optimal Transport (OT) between the prior and data distributions. The C-VAE allows greater flexibility in priors and natural resolution of the prior hole problem by enforcing coupling between the prior and the data distribution and enables flexible optimization through the primal, dual, and semi-dual formulations of entropic OT. Simulations on synthetic and real data show that the C-VAE outperforms alternatives including VAE, WAE, and InfoVAE in fidelity to the data, quality of the latent representation, and in quality of generated samples.'}",https://openreview.net{'value': '/pdf/c3139a0efa93d44e9f7043aeed088b222ac26ace.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=USiX9gmGRx,{'value': 'Adaptive Estimation of Graphical Models under Total Positivity'},Jiaxi Ying; José Vinícius De Miranda Cardoso; Daniel P. Palomar,~Jiaxi_Ying1; ~José_Vinícius_De_Miranda_Cardoso1; ~Daniel_P._Palomar1,,"{'value': 'We consider the problem of estimating (diagonally dominant) M-matrices as precision matrices in Gaussian graphical models. Such models have shown interesting properties, e.g., the maximum likelihood estimator exists with as little as two observations in the case of M-matrices, and exists even with one observation in the case of diagonally dominant M-matrices. We propose an adaptive multiple-stage estimation method, which refines the estimate by solving a weighted $\\ell_1$-regularized problem in each stage. We further design a unified framework based on gradient projection method to solve the regularized problem, equipped with different projections to handle the constraints of M-matrices and diagonally dominant M-matrices. Theoretical analysis of the estimation error is established. The proposed method outperforms state-of-the-art methods in estimating precision matrices and identifying graph edges, as evidenced by synthetic and financial time-series data sets.'}",https://openreview.net{'value': '/pdf/f526799e3356f1b89443a9634d76126161280c89.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=UDzgqDZc7Q,{'value': 'Cooperative Multi-Agent Reinforcement Learning: Asynchronous Communication and Linear Function Approximation'},Yifei Min; Jiafan He; Tianhao Wang; Quanquan Gu,~Yifei_Min1; ~Jiafan_He1; ~Tianhao_Wang1; ~Quanquan_Gu1,,"{'value': 'We study multi-agent reinforcement learning in the setting of episodic Markov decision processes, where many agents cooperate via communication through a central server. We propose a provably efficient algorithm based on value iteration that can simultaneously allow asynchronous communication and guarantee the benefit of cooperation with low communication complexity. Under linear function approximation, we prove that our algorithm enjoys a $\\tilde{\\mathcal{O}}(d^{3/2}H^2\\sqrt{K})$ regret upper bound with $\\tilde{\\mathcal{O}}(dHM^2)$ communication complexity, where $d$ is the feature dimension, $H$ is the horizon length, $M$ is the total number of agents, and $K$ is the total number of episodes. We also provide a lower bound showing that an $\\Omega(dM)$ communication complexity is necessary to improve the performance through collaboration.'}",https://openreview.net{'value': '/pdf/dd2c086336baca50a15f8bd8533117951f091db9.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=T27zdeulEK,{'value': 'Multi-Agent Best Arm Identification with Private Communications'},Alexandre Rio; Merwan Barlier; Igor Colin; Marta Soare,~Alexandre_Rio1; ~Merwan_Barlier1; ~Igor_Colin1; ~Marta_Soare1,,"{'value': 'We address multi-agent best arm identification with privacy guarantees. In this setting, agents collaborate by communicating to find the optimal arm. To avoid leaking sensitive data through messages, we consider two notions of privacy withholding different kinds of information: differential privacy and $(\\epsilon, \\eta)$-privacy. For each privacy definition, we propose an algorithm based on a two-level successive elimination scheme. We provide theoretical guarantees for the privacy level, accuracy and sample complexity of our algorithms. Experiments on various settings support our theoretical findings.'}",https://openreview.net{'value': '/pdf/a720152e90ebbb6ddea5e1c967840c3970d0814b.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=SryTYOIGJx,{'value': 'Abstract-to-Executable Trajectory Translation for One-Shot Task Generalization'},Stone Tao; Xiaochen Li; Tongzhou Mu; Zhiao Huang; Yuzhe Qin; Hao Su,~Stone_Tao1; ~Xiaochen_Li1; ~Tongzhou_Mu1; ~Zhiao_Huang1; ~Yuzhe_Qin1; ~Hao_Su1,,"{'value': 'Training long-horizon robotic policies in complex physical environments is essential for many applications, such as robotic manipulation. However, learning a policy that can generalize to unseen tasks is challenging. In this work, we propose to achieve one-shot task generalization by decoupling plan generation and plan execution. Specifically, our method solves complex long-horizon tasks in three steps: build a paired abstract environment by simplifying geometry and physics, generate abstract trajectories, and solve the original task by an abstract-to-executable trajectory translator. In the abstract environment, complex dynamics such as physical manipulation are removed, making abstract trajectories easier to generate. However, this introduces a large domain gap between abstract trajectories and the actual executed trajectories as abstract trajectories lack low-level details and are not aligned frame-to-frame with the executed trajectory. In a manner reminiscent of language translation, our approach leverages a seq-to-seq model to overcome the large domain gap between the abstract and executable trajectories, enabling the low-level policy to follow the abstract trajectory. Experimental results on various unseen long-horizon tasks with different robot embodiments demonstrate the practicability of our methods to achieve one-shot task generalization.'}",https://openreview.net{'value': '/pdf/13f414d4cc77938ba1a9ff6fd88cb299f0f26393.pdf'},{'title_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=SpA7YFu02k,{'value': 'Graph Generative Model for Benchmarking Graph Neural Networks'},Minji Yoon; Yue Wu; John Palowitch; Bryan Perozzi; Russ Salakhutdinov,~Minji_Yoon1; ~Yue_Wu17; ~John_Palowitch1; ~Bryan_Perozzi1; ~Russ_Salakhutdinov1,,"{'value': 'As the field of Graph Neural Networks (GNN) continues to grow, it experiences a corresponding increase in the need for large, real-world datasets to train and test new GNN models on challenging, realistic problems. Unfortunately, such graph datasets are often generated from online, highly privacy-restricted ecosystems, which makes research and development on these datasets hard, if not impossible. This greatly reduces the amount of benchmark graphs available to researchers, causing the field to rely only on a handful of publicly-available datasets. To address this problem, we introduce a novel graph generative model, Computation Graph Transformer (CGT) that learns and reproduces the distribution of real-world graphs in a privacy-controlled way. More specifically, CGT (1) generates effective benchmark graphs on which GNNs show similar task performance as on the source graphs, (2) scales to process large-scale graphs, (3) incorporates off-the-shelf privacy modules to guarantee end-user privacy of the generated graph. Extensive experiments across a vast body of graph generative models show that only our model can successfully generate privacy-controlled, synthetic substitutes of large-scale real-world graphs that can be effectively used to benchmark GNN models.'}",https://openreview.net{'value': '/pdf/30e394bdc8cd861b9d4be284c98572f3d404bf6f.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=SdOn9JSyTx,{'value': 'Learning GFlowNets From Partial Episodes For Improved Convergence And Stability'},Kanika Madan; Jarrid Rector-Brooks; Maksym Korablyov; Emmanuel Bengio; Moksh Jain; Andrei Cristian Nica; Tom Bosc; Yoshua Bengio; Nikolay Malkin,~Kanika_Madan3; ~Jarrid_Rector-Brooks2; ~Maksym_Korablyov1; ~Emmanuel_Bengio1; ~Moksh_Jain1; ~Andrei_Cristian_Nica1; ~Tom_Bosc1; ~Yoshua_Bengio1; ~Nikolay_Malkin1,,"{'value': 'Generative flow networks (GFlowNets) are a family of algorithms for training a sequential sampler of discrete objects under an unnormalized target density and have been successfully used for various probabilistic modeling tasks. Existing training objectives for GFlowNets are either local to states or transitions, or propagate a reward signal over an entire sampling trajectory. We argue that these alternatives represent opposite ends of a gradient bias-variance tradeoff and propose a way to exploit this tradeoff to mitigate its harmful effects. Inspired by the TD($\\lambda$) algorithm in reinforcement learning, we introduce *subtrajectory balance* or SubTB($\\lambda$), a GFlowNet training objective that can learn from partial action subsequences of varying lengths. We show that SubTB($\\lambda$) accelerates sampler convergence in previously studied and new environments and enables training GFlowNets in environments with longer action sequences and sparser reward landscapes than what was possible before. We also perform a comparative analysis of stochastic gradient dynamics, shedding light on the bias-variance tradeoff in GFlowNet training and the advantages of subtrajectory balance.'}",https://openreview.net{'value': '/pdf/b385be827f4f645e57b1423196bd3c4ec7997ccc.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=SaZvBUk2q4,{'value': 'Scalable Multi-Agent Reinforcement Learning through Intelligent Information Aggregation'},Siddharth Nayak; Kenneth Choi; Wenqi Ding; Sydney Dolan; Karthik Gopalakrishnan; Hamsa Balakrishnan,~Siddharth_Nayak1; kenchoi@mit.edu; wenqi22@mit.edu; ~Sydney_Dolan1; ~Karthik_Gopalakrishnan3; ~Hamsa_Balakrishnan1,,"{'value': 'We consider the problem of multi-agent navigation and collision avoidance when observations are limited to the local neighborhood of each agent. We propose InforMARL, a novel architecture for multi-agent reinforcement learning (MARL) which uses local information intelligently to compute paths for all the agents in a decentralized manner. Specifically, InforMARL aggregates information about the local neighborhood of agents for both the actor and the critic using a graph neural network and can be used in conjunction with any standard MARL algorithm. We show that (1) in training, InforMARL has better sample efficiency and performance than baseline approaches, despite using less information, and (2) in testing, it scales well to environments with arbitrary numbers of agents and obstacles. We illustrate these results using four task environments, including one with predetermined goals for each agent, and one in which the agents collectively try to cover all goals.'}",https://openreview.net{'value': '/pdf/b18722dfdac26e1edb2a82a1ba9696fbbf54c6bf.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=SP01yVIC2o,{'value': 'ReDi: Efficient Learning-Free Diffusion Inference via Trajectory Retrieval'},Kexun Zhang; Xianjun Yang; William Yang Wang; Lei Li,~Kexun_Zhang1; ~Xianjun_Yang1; ~William_Yang_Wang2; ~Lei_Li11,,"{'value': 'Diffusion models show promising generation capability for a variety of data. Despite their high generation quality, the inference for diffusion models is still time-consuming due to the numerous sampling iterations required. To accelerate the inference, we propose ReDi, a simple yet learning-free Retrieval-based Diffusion sampling framework. From a precomputed knowledge base, ReDi retrieves a trajectory similar to the partially generated trajectory at an early stage of generation, skips a large portion of intermediate steps, and continues sampling from a later step in the retrieved trajectory. We theoretically prove that the generation performance of ReDi is guaranteed. Our experiments demonstrate that ReDi improves the model inference efficiency by 2$\\times$ speedup. Furthermore, ReDi is able to generalize well in zero-shot cross-domain image generation such as image stylization. The code and demo for ReDi is available at https://github.com/zkx06111/ReDiffusion.'}",https://openreview.net{'value': '/pdf/052d344ff7dff4f3368b009868ffec9eb87fe009.pdf'},{'title_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=S1QzeJR9yE,{'value': 'Learning to Decouple Complex Systems'},Zihan Zhou; Tianshu Yu,~Zihan_Zhou7; ~Tianshu_Yu2,,"{'value': 'A complex system with cluttered observations may be a coupled mixture of multiple simple sub-systems corresponding to latent entities. Such sub-systems may hold distinct dynamics in the continuous-time domain; therein, complicated interactions between sub-systems also evolve over time. This setting is fairly common in the real world but has been less considered. In this paper, we propose a sequential learning approach under this setting by decoupling a complex system for handling irregularly sampled and cluttered sequential observations. Such decoupling brings about not only subsystems describing the dynamics of each latent entity but also a meta-system capturing the interaction between entities over time. Specifically, we argue that the meta-system evolving within a simplex is governed by projected differential equations (ProjDEs). We further analyze and provide neural-friendly projection operators in the context of Bregman divergence. Experimental results on synthetic and real-world datasets show the advantages of our approach when facing complex and cluttered sequential data compared to the state-of-the-art.'}",https://openreview.net{'value': '/pdf/13ae85483bb260eadaa940f14fb584d11ff10591.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=RnZhB7kNl0,{'value': 'Continuous Spatiotemporal Transformer'},Antonio Henrique de Oliveira Fonseca; Emanuele Zappala; Josue Ortega Caro; David van Dijk,~Antonio_Henrique_de_Oliveira_Fonseca1; ~Emanuele_Zappala1; ~Josue_Ortega_Caro1; ~David_van_Dijk1,,"{'value': 'Modeling spatiotemporal dynamical systems is a fundamental challenge in machine learning. Transformer models have been very successful in NLP and computer vision where they provide interpretable representations of data. However, a limitation of transformers in modeling continuous dynamical systems is that they are fundamentally discrete time and space models and thus have no guarantees regarding continuous sampling. To address this challenge, we present the Continuous Spatiotemporal Transformer (CST), a new transformer architecture that is designed for modeling of continuous systems. This new framework guarantees a continuous and smooth output via optimization in Sobolev space. We benchmark CST against traditional transformers as well as other spatiotemporal dynamics modeling methods and achieve superior performance in a number of tasks on synthetic and real systems, including learning brain dynamics from calcium imaging data.'}",https://openreview.net{'value': '/pdf/1227977aecf57a3393bf141de64235124df3a54f.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=Rm5Qi57C5I,{'value': 'Do Embodied Agents Dream of Pixelated Sheep: Embodied Decision Making using Language Guided World Modelling'},Kolby Nottingham; Prithviraj Ammanabrolu; Alane Suhr; Yejin Choi; Hannaneh Hajishirzi; Sameer Singh; Roy Fox,~Kolby_Nottingham1; ~Prithviraj_Ammanabrolu1; ~Alane_Suhr1; ~Yejin_Choi1; ~Hannaneh_Hajishirzi1; ~Sameer_Singh1; ~Roy_Fox1,,"{'value': 'Reinforcement learning (RL) agents typically learn tabula rasa, without prior knowledge of the world. However, if initialized with knowledge of high-level subgoals and transitions between subgoals, RL agents could utilize this Abstract World Model (AWM) for planning and exploration. We propose using few-shot large language models (LLMs) to hypothesize an AWM, that will be verified through world experience, to improve sample efficiency of RL agents. Our DECKARD agent applies LLM-guided exploration to item crafting in Minecraft in two phases: (1) the Dream phase where the agent uses an LLM to decompose a task into a sequence of subgoals, the hypothesized AWM; and (2) the Wake phase where the agent learns a modular policy for each subgoal and verifies or corrects the hypothesized AWM. Our method of hypothesizing an AWM with LLMs and then verifying the AWM based on agent experience not only increases sample efficiency over contemporary methods by an order of magnitude but is also robust to and corrects errors in the LLM, successfully blending noisy internet-scale information from LLMs with knowledge grounded in environment dynamics.'}",https://openreview.net{'value': '/pdf/b1744cf1a99a0c2af88dfa47a5d4fe628bfd278d.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=Rg5CRU2M4Z,{'value': 'Meta-learning Parameterized Skills'},Haotian Fu; Shangqun Yu; Saket Tiwari; Michael Littman; George Konidaris,~Haotian_Fu3; ~Shangqun_Yu1; ~Saket_Tiwari2; ~Michael_Littman1; ~George_Konidaris1,,{'value': 'We propose a novel parameterized skill-learning algorithm that aims to learn transferable parameterized skills and synthesize them into a new action space that supports efficient learning in long-horizon tasks. We propose to leverage off-policy Meta-RL combined with a trajectory-centric smoothness term to learn a set of parameterized skills. Our agent can use these learned skills to construct a three-level hierarchical framework that models a Temporally-extended Parameterized Action Markov Decision Process. We empirically demonstrate that the proposed algorithms enable an agent to solve a set of highly difficult long-horizon (obstacle-course and robot manipulation) tasks.'},https://openreview.net{'value': '/pdf/2c9ab2d527e6ab513c3e698e40f2e41f032fe168.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=RYD1UMgTdk,{'value': 'Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models'},Zhihong Shao; Yeyun Gong; yelong shen; Minlie Huang; Nan Duan; Weizhu Chen,~Zhihong_Shao1; ~Yeyun_Gong2; ~yelong_shen1; ~Minlie_Huang1; ~Nan_Duan1; ~Weizhu_Chen1,,"{'value': 'Large language models can perform various reasoning tasks by using chain-of-thought prompting, which guides them to find answers through step-by-step demonstrations. However, the quality of the prompts depends on the demonstrations given to the models, and creating many of them by hand is costly. We introduce Synthetic prompting, a method that leverages a few handcrafted examples to prompt the model to generate more examples by itself, and selects effective demonstrations to elicit better reasoning. Our method alternates between a backward and forward process to generate new examples. The backward process generates a question that match a sampled reasoning chain, so that the question is solvable and clear. The forward process produces a more detailed reasoning chain for the question, improving the quality of the example. We evaluate our method on numerical, symbolic, and algorithmic reasoning tasks, and show that it outperforms existing prompting techniques.'}",https://openreview.net{'value': '/pdf/fd0cdcb658a3ade0fd8e41688e84aa4460f05756.pdf'},{'title_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=RUiWyj6fhN,{'value': 'Collaborative Multi-Agent Heterogeneous Multi-Armed Bandits'},Ronshee Chawla; Daniel Vial; Sanjay Shakkottai; R. Srikant,~Ronshee_Chawla1; ~Daniel_Vial1; ~Sanjay_Shakkottai1; ~R._Srikant1,,"{'value': 'The study of collaborative multi-agent bandits has attracted significant attention recently. In light of this, we initiate the study of a new collaborative setting, consisting of $N$ agents such that each agent is learning one of $M$ stochastic multi-armed bandits to minimize their group cumulative regret. We develop decentralized algorithms which facilitate collaboration between the agents under two scenarios. We characterize the performance of these algorithms by deriving the per agent cumulative regret and group regret upper bounds. We also prove lower bounds for the group regret in this setting, which demonstrates the near-optimal behavior of the proposed algorithms.'}",https://openreview.net{'value': '/pdf/51a2acd0c2980bf7850168f3c8c362a1b5044df6.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=R3d0HoKznc,{'value': 'Causal Strategic Classification: A Tale of Two Shifts'},Guy Horowitz; Nir Rosenfeld,~Guy_Horowitz1; ~Nir_Rosenfeld2,,"{'value': 'When users can benefit from certain predictive outcomes, they may be prone to act to achieve those outcome, e.g., by strategically modifying their features. The goal in strategic classification is therefore to train predictive models that are robust to such behavior. However, the conventional framework assumes that changing features does not change actual outcomes, which depicts users as ""gaming"" the system. Here we remove this assumption, and study learning in a causal strategic setting where true outcomes do change. Focusing on accuracy as our primary objective, we show how strategic behavior and causal effects underlie two complementing forms of distribution shift. We characterize these shifts, and propose a learning algorithm that balances between these two forces and over time, and permits end-to-end training. Experiments on synthetic and semi-synthetic data demonstrate the utility of our approach.'}",https://openreview.net{'value': '/pdf/cd1969699712d7d09f95fdfaa8a6de890a4b9270.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=QwFkJ3QVii,{'value': 'Synthetic data for model selection'},Alon Shoshan; Nadav Bhonker; Igor Kviatkovsky; Matan Fintz; Gerard Medioni,~Alon_Shoshan1; ~Nadav_Bhonker1; ~Igor_Kviatkovsky2; ~Matan_Fintz1; ~Gerard_Medioni1,,"{'value': 'Recent breakthroughs in synthetic data generation approaches made it possible to produce highly photorealistic images which are hardly distinguishable from real ones. Furthermore, synthetic generation pipelines have the potential to generate an unlimited number of images. The combination of high photorealism and scale turn synthetic data into a promising candidate for improving various machine learning (ML) pipelines. Thus far, a large body of research in this field has focused on using synthetic images for training, by augmenting and enlarging training data. In contrast to using synthetic data for training, in this work we explore whether synthetic data can be beneficial for model selection. Considering the task of image classification, we demonstrate that when data is scarce, synthetic data can be used to replace the held out validation set, thus allowing to train on a larger dataset. We also introduce a novel method to calibrate the synthetic error estimation to fit that of the real domain. We show that such calibration significantly improves the usefulness of synthetic data for model selection.'}",https://openreview.net{'value': '/pdf/88c9588208734f17a0eb3b680e5bab742f4273cf.pdf'},{'title_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=Qtix8HLmDx,{'value': 'Gaussian processes at the Helm(holtz): A more fluid model for ocean currents'},Renato Berlinghieri; Brian L. Trippe; David R. Burt; Ryan James Giordano; Kaushik Srinivasan; Tamay Özgökmen; Junfei Xia; Tamara Broderick,~Renato_Berlinghieri1; ~Brian_L._Trippe1; ~David_R._Burt1; ~Ryan_James_Giordano1; kaushiks@ucla.edu; tozgokmen@miami.edu; junfei.xia@earth.miami.edu; ~Tamara_Broderick2,,"{'value': 'Oceanographers are interested in predicting ocean currents and identifying divergences in a current vector field based on sparse observations of buoy velocities. Since we expect current dynamics to be smooth but highly non-linear, Gaussian processes (GPs) offer an attractive model. But we show that applying a GP with a standard stationary kernel directly to buoy data can struggle at both current prediction and divergence identification -- due to some physically unrealistic prior assumptions. To better reflect known physical properties of currents, we propose to instead put a standard stationary kernel on the divergence and curl-free components of a vector field obtained through a Helmholtz decomposition. We show that, because this decomposition relates to the original vector field just via mixed partial derivatives, we can still perform inference given the original data with only a small constant multiple of additional computational expense. We illustrate the benefits of our method on synthetic and real oceans data.'}",https://openreview.net{'value': '/pdf/4a086682f6220a410c4d3e3f7a10479f2665bcaf.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=Qh0Gbq3lkh,"{'value': 'Masked Trajectory Models for Prediction, Representation, and Control'}",Philipp Wu; Arjun Majumdar; Kevin Stone; Yixin Lin; Igor Mordatch; Pieter Abbeel; Aravind Rajeswaran,~Philipp_Wu1; ~Arjun_Majumdar2; ~Kevin_Stone1; ~Yixin_Lin1; ~Igor_Mordatch5; ~Pieter_Abbeel2; ~Aravind_Rajeswaran1,,"{'value': 'We introduce Masked Trajectory Models (MTM) as a generic abstraction for sequential decision making. MTM takes a trajectory, such as a state-action sequence, and aims to reconstruct the trajectory conditioned on random subsets of the same trajectory. By training with a highly randomized masking pattern, MTM learns versatile networks that can take on different roles or capabilities, by simply choosing appropriate masks at inference time. For example, the same MTM network can be used as a forward dynamics model, inverse dynamics model, or even an offline RL agent. Through extensive experiments in several continuous control tasks, we show that the same MTM network -- i.e. same weights -- can match or outperform specialized networks trained for the aforementioned capabilities. Additionally, we find that state representations learned by MTM can significantly accelerate the learning speed of traditional RL algorithms. Finally, in offline RL benchmarks, we find that MTM is competitive with specialized offline RL algorithms, despite MTM being a generic self-supervised learning method without any explicit RL components. Code is available at https://github.com/facebookresearch/mtm.'}",https://openreview.net{'value': '/pdf/a1b57ff7f7c5da89cc08659e6df0c48bb651879c.pdf'},{'title_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=Q3Rmfuj4vf,{'value': 'Returning The Favour: When Regression Benefits From Probabilistic Causal Knowledge'},Shahine Bouabid; Jake Fawkes; Dino Sejdinovic,~Shahine_Bouabid1; ~Jake_Fawkes1; ~Dino_Sejdinovic1,,"{'value': 'A directed acyclic graph (DAG) provides valuable prior knowledge that is often discarded in regression tasks in machine learning. We show that the independences arising from the presence of collider structures in DAGs provide meaningful inductive biases, which constrain the regression hypothesis space and improve predictive performance. We introduce collider regression, a framework to incorporate probabilistic causal knowledge from a collider in a regression problem. When the hypothesis space is a reproducing kernel Hilbert space, we prove a strictly positive generalisation benefit under mild assumptions and provide closed-form estimators of the empirical risk minimiser. Experiments on synthetic and climate model data demonstrate performance gains of the proposed methodology.'}",https://openreview.net{'value': '/pdf/67d0f5b54bca4929ed83f7a7a7f626f1c888cad3.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=PvaPDkAbaL,{'value': 'Improving Fair Training under Correlation Shifts'},Yuji Roh; Kangwook Lee; Steven Euijong Whang; Changho Suh,~Yuji_Roh1; ~Kangwook_Lee1; ~Steven_Euijong_Whang1; ~Changho_Suh1,,"{'value': 'Model fairness is an essential element for Trustworthy AI. While many techniques for model fairness have been proposed, most of them assume that the training and deployment data distributions are identical, which is often not true in practice. In particular, when the bias between labels and sensitive groups changes, the fairness of the trained model is directly influenced and can worsen. We make two contributions for solving this problem. First, we analytically show that existing in-processing fair algorithms have fundamental limits in accuracy and group fairness. We utilize the notion of correlation shifts between labels and groups, which can explicitly capture the change of the above bias. Second, we propose a novel pre-processing step that samples the input data to reduce correlation shifts and thus enables the in-processing approaches to overcome their limitations. We formulate an optimization problem for adjusting the data ratio among labels and sensitive groups to reflect the shifted correlation. A key benefit of our approach lies in decoupling the roles of pre- and in-processing approaches: correlation adjustment via pre-processing and unfairness mitigation on the processed data via in-processing. Experiments show that our framework effectively improves existing in-processing fair algorithms w.r.t. accuracy and fairness, both on synthetic and real datasets.'}",https://openreview.net{'value': '/pdf/6914f0cdc264d7d4c1a38670be4d7a66fb985b02.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=PlFBOnVOFg,{'value': 'Towards Omni-generalizable Neural Methods for Vehicle Routing Problems'},Jianan Zhou; Yaoxin Wu; Wen Song; Zhiguang Cao; Jie Zhang,~Jianan_Zhou1; ~Yaoxin_Wu2; ~Wen_Song1; ~Zhiguang_Cao1; ~Jie_Zhang9,,"{'value': 'Learning heuristics for vehicle routing problems (VRPs) has gained much attention due to the less reliance on hand-crafted rules. However, existing methods are typically trained and tested on the same task with a fixed size and distribution (of nodes), and hence suffer from limited generalization performance. This paper studies a challenging yet realistic setting, which considers generalization across both size and distribution in VRPs. We propose a generic meta-learning framework, which enables effective training of an initialized model with the capability of fast adaptation to new tasks during inference. We further develop a simple yet efficient approximation method to reduce the training overhead. Extensive experiments on both synthetic and benchmark instances of the traveling salesman problem (TSP) and capacitated vehicle routing problem (CVRP) demonstrate the effectiveness of our method. The code is available at: https://github.com/RoyalSkye/Omni-VRP.'}",https://openreview.net{'value': '/pdf/072093147e0ab0813d7fbe6873b0ccf0a4d09738.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=Pckxn5T0PV,{'value': 'The Catalog Problem: Clustering and Ordering Variable-Sized Sets'},Mateusz Maria Jurewicz; Graham W. Taylor; Leon Derczynski,~Mateusz_Maria_Jurewicz1; ~Graham_W._Taylor1; ~Leon_Derczynski1,,"{'value': ""Prediction of a $\\textbf{varying number}$ of $\\textbf{ordered clusters}$ from sets of $\\textbf{any cardinality}$ is a challenging task for neural networks, combining elements of set representation, clustering and learning to order. This task arises in many diverse areas, ranging from medical triage and early discharge, through machine part management and multi-channel signal analysis for petroleum exploration to product catalog structure prediction. This paper focuses on that last area, which exemplifies a number of challenges inherent to adaptive ordered clustering, referred to further as the eponymous $\\textit{Catalog Problem}$. These include learning variable cluster constraints, exhibiting relational reasoning and managing combinatorial complexity. Despite progress in both neural clustering and set-to-sequence methods, no joint, fully differentiable model exists to-date. We develop such a modular architecture, referred to further as Neural Ordered Clusters (NOC), enhance it with a specific mechanism for learning cluster-level cardinality constraints, and provide a robust comparison of its performance in relation to alternative models. We test our method on three datasets, including synthetic catalog structures and PROCAT, a dataset of real-world catalogs consisting of over 1.5M products, achieving state-of-the-art results on a new, more challenging formulation of the underlying problem, which has not been addressed before. Additionally, we examine the network's ability to learn higher-order interactions.""}",https://openreview.net{'value': '/pdf/e2d16a87b151657dd8ab03bf1a38af945964f8fc.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=PWRIIwBJFo,{'value': 'TIDE: Time Derivative Diffusion for Deep Learning on Graphs'},Maysam Behmanesh; Maximilian Krahn; Maks Ovsjanikov,~Maysam_Behmanesh1; ~Maximilian_Krahn1; ~Maks_Ovsjanikov1,,"{'value': 'A prominent paradigm for graph neural networks is based on the message-passing framework. In this framework, information communication is realized only between neighboring nodes. The challenge of approaches that use this paradigm is to ensure efficient and accurate long-distance communication between nodes, as deep convolutional networks are prone to over smoothing. In this paper, we present a novel method based on time derivative graph diffusion (TIDE) to overcome these structural limitations of the message-passing framework. Our approach allows for optimizing the spatial extent of diffusion across various tasks and network channels, thus enabling medium and long-distance communication efficiently. Furthermore, we show that our architecture design also enables local message-passing and thus inherits from the capabilities of local message-passing approaches. We show that on both widely used graph benchmarks and synthetic mesh and graph datasets, the proposed framework outperforms state-of-the-art methods by a significant margin.'}",https://openreview.net{'value': '/pdf/f8ae8be73bfb75a3cd88c40e29e363800668a3f5.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=P78iqH28ni,{'value': 'Coordinated Dynamic Bidding in Repeated Second-Price Auctions with Budgets'},Yurong Chen; Qian Wang; Zhijian Duan; Haoran Sun; Zhaohua Chen; Xiang Yan; Xiaotie Deng,~Yurong_Chen3; ~Qian_Wang22; ~Zhijian_Duan1; ~Haoran_Sun6; ~Zhaohua_Chen1; ~Xiang_Yan2; ~Xiaotie_Deng1,,"{'value': ""In online ad markets, a rising number of advertisers are employing bidding agencies to participate in ad auctions. These agencies are specialized in designing online algorithms and bidding on behalf of their clients. Typically, an agency usually has information on multiple advertisers, so she can potentially coordinate bids to help her clients achieve higher utilities than those under independent bidding. In this paper, we study coordinated online bidding algorithms in repeated second-price auctions with budgets. We propose algorithms that guarantee every client a higher utility than the best she can get under independent bidding. We show that these algorithms achieve maximal social welfare and discuss bidders' incentives to misreport their budgets, in symmetric cases. Our proofs combine the techniques of online learning and equilibrium analysis, overcoming the difficulty of competing with a multi-dimensional benchmark. The performance of our algorithms is further evaluated by experiments on both synthetic and real data. To the best of our knowledge, we are the first to consider bidder coordination in online repeated auctions with constraints.""}",https://openreview.net{'value': '/pdf/2ca9b88241f79907c617104f71545f4aa8956cce.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=OUicoKgvtc,{'value': 'Simple Embodied Language Learning as a Byproduct of Meta-Reinforcement Learning'},Evan Zheran Liu; Sahaana Suri; Tong Mu; Allan Zhou; Chelsea Finn,~Evan_Zheran_Liu1; ~Sahaana_Suri1; ~Tong_Mu1; ~Allan_Zhou1; ~Chelsea_Finn1,,"{'value': 'Whereas machine learning models typically learn language by directly training on language tasks (e.g., next-word prediction), language emerges in human children as a byproduct of solving non-language tasks (e.g., acquiring food). Motivated by this observation, we ask: can embodied reinforcement learning (RL) agents also indirectly learn language from non-language tasks? Learning to associate language with its meaning requires a dynamic environment with varied language. Therefore, we investigate this question in a multi-task environment with language that varies across the different tasks. Specifically, we design an office navigation environment, where the agent’s goal is to find a particular office, and office locations differ in different buildings (i.e., tasks). Each building includes a floor plan with a simple language description of the goal office’s location, which can be visually read as an RGB image when visited. We find RL agents indeed are able to indirectly learn language. Agents trained with current meta-RL algorithms successfully generalize to reading floor plans with held-out layouts and language phrases, and quickly navigate to the correct office, despite receiving no direct language supervision.'}",https://openreview.net{'value': '/pdf/28326b784751f5e243bb184ba2a405030db73fce.pdf'},{'abstract_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=O1j4uFuSVW,{'value': 'Adapting to game trees in zero-sum imperfect information games'},Côme Fiegel; Pierre MENARD; Tadashi Kozuno; Remi Munos; Vianney Perchet; Michal Valko,~Côme_Fiegel1; ~Pierre_MENARD1; ~Tadashi_Kozuno1; ~Remi_Munos1; ~Vianney_Perchet3; ~Michal_Valko1,,"{'value': 'Imperfect information games (IIG) are games in which each player only partially observes the current game state. We study how to learn $\\epsilon$-optimal strategies in a zero-sum IIG through self-play with trajectory feedback. We give a problem-independent lower bound $\\widetilde{\\mathcal{O}}(H(A_{\\mathcal{X}}+B_{\\mathcal{Y}})/\\epsilon^2)$ on the required number of realizations to learn these strategies with high probability, where $H$ is the length of the game, $A_{\\mathcal{X}}$ and $B_{\\mathcal{Y}}$ are the total number of actions for the two players. We also propose two Follow the Regularized leader (FTRL) algorithms for this setting: Balanced FTRL which matches this lower bound, but requires the knowledge of the information set structure beforehand to define the regularization; and Adaptive FTRL which needs $\\widetilde{\\mathcal{O}}(H^2(A_{\\mathcal{X}}+B_{\\mathcal{Y}})/\\epsilon^2)$ realizations without this requirement by progressively adapting the regularization to the observations.'}",https://openreview.net{'value': '/pdf/5eae52f717399458e1365d0f39947a20d4d64682.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=NwICIHHpKf,{'value': 'A Flexible Diffusion Model'},weitao Du; He Zhang; Tao Yang; Yuanqi Du,~weitao_Du1; ~He_Zhang1; ~Tao_Yang9; ~Yuanqi_Du1,,"{'value': 'Denoising diffusion (score-based) generative models have become a popular choice for modeling complex data. Recently, a deep connection between forward-backward stochastic differential equations (SDEs) and diffusion-based models has been established, leading to the development of new SDE variants such as sub-VP and critically-damped Langevin. Despite the empirical success of some hand-crafted forward SDEs, many potentially promising forward SDEs remain unexplored. In this work, we propose a general framework for parameterizing diffusion models, particularly the spatial part of forward SDEs, by leveraging the symplectic and Riemannian geometry of the data manifold. We introduce a systematic formalism with theoretical guarantees and connect it with previous diffusion models. Finally, we demonstrate the theoretical advantages of our method from a variational optimization perspective. We present numerical experiments on synthetic datasets, MNIST and CIFAR10 to validate the effectiveness of our framework.'}",https://openreview.net{'value': '/pdf/bef86ac8385f30929570865e0dc8d295faebf976.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=MocsSAUKlk,{'value': 'Rethinking Explaining Graph Neural Networks via Non-parametric Subgraph Matching'},Fang Wu; Siyuan Li; Xurui Jin; Yinghui Jiang; Dragomir Radev; Zhangming Niu; Stan Z. Li,~Fang_Wu1; ~Siyuan_Li6; ~Xurui_Jin1; yinghui@mindrank.ai; ~Dragomir_Radev2; ~Zhangming_Niu1; ~Stan_Z._Li2,,"{'value': ""The success of graph neural networks (GNNs) provokes the question about explainability: ``Which fraction of the input graph is the most determinant of the prediction?'' Particularly, parametric explainers prevail in existing approaches because of their more robust capability to decipher the black-box (i.e., target GNNs). In this paper, based on the observation that graphs typically share some common motif patterns, we propose a novel non-parametric subgraph matching framework, dubbed MatchExplainer, to explore explanatory subgraphs. It couples the target graph with other counterpart instances and identifies the most crucial joint substructure by minimizing the node corresponding-based distance. Moreover, we note that present graph sampling or node-dropping methods usually suffer from the false positive sampling problem. To alleviate this issue, we design a new augmentation paradigm named MatchDrop. It takes advantage of MatchExplainer to fix the most informative portion of the graph and merely operates graph augmentations on the rest less informative part. Extensive experiments on synthetic and real-world datasets show the effectiveness of our MatchExplainer by outperforming all state-of-the-art parametric baselines with significant margins. Results also demonstrate that MatchDrop is a general scheme to be equipped with GNNs for enhanced performance. The code is available at https://github.com/smiles724/MatchExplainer.""}",https://openreview.net{'value': '/pdf/8b7da3ce0da1d4ed0872daf0f48c25b2b19d49df.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=MP7HOGfLf3,{'value': 'An Adaptive Entropy-Regularization Framework for Multi-Agent Reinforcement Learning'},Woojun Kim; Youngchul Sung,~Woojun_Kim1; ~Youngchul_Sung1,,"{'value': 'In this paper, we propose an adaptive entropy-regularization framework (ADER) for multi-agent reinforcement learning (RL) to learn the adequate amount of exploration of each agent for entropy-based exploration. In order to derive a metric for the proper level of exploration entropy for each agent, we disentangle the soft value function into two types: one for pure return and the other for entropy. By applying multi-agent value factorization to the disentangled value function of pure return, we obtain a metric to determine the relevant level of exploration entropy for each agent, given by the partial derivative of the pure-return value function with respect to (w.r.t.) the policy entropy of each agent. Based on this metric, we propose the ADER algorithm based on maximum entropy RL, which controls the necessary level of exploration across agents over time by learning the proper target entropy for each agent. Experimental results show that the proposed scheme significantly outperforms current state-of-the-art multi-agent RL algorithms.'}",https://openreview.net{'value': '/pdf/17ddf6a7c13bf50176accb589f983aaf66d6b0ba.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=MGDYQNXjCg,{'value': 'A Game-Theoretic Framework for Managing Risk in Multi-Agent Systems'},Oliver Slumbers; David Henry Mguni; Stefano B Blumberg; Stephen Marcus McAleer; Yaodong Yang; Jun Wang,~Oliver_Slumbers1; ~David_Henry_Mguni1; ~Stefano_B_Blumberg1; ~Stephen_Marcus_McAleer1; ~Yaodong_Yang1; ~Jun_Wang2,,"{'value': 'In order for agents in multi-agent systems (MAS) to be safe, they need to take into account the risks posed by the actions of other agents. However, the dominant paradigm in game theory (GT) assumes that agents are not affected by risk from other agents and only strive to maximise their expected utility. For example, in hybrid human-AI driving systems, it is necessary to limit large deviations in reward resulting from car crashes. Although there are equilibrium concepts in game theory that take into account risk aversion, they either assume that agents are risk-neutral with respect to the uncertainty caused by the actions of other agents, or they are not guaranteed to exist. We introduce a new GT-based Risk-Averse Equilibrium (RAE) that always produces a solution that minimises the potential variance in reward accounting for the strategy of other agents. Theoretically and empirically, we show RAE shares many properties with a Nash Equilibrium (NE), establishing convergence properties and generalising to risk-dominant NE in certain cases. To tackle large-scale problems, we extend RAE to the PSRO multi-agent reinforcement learning (MARL) framework. We empirically demonstrate the minimum reward variance benefits of RAE in matrix games with high-risk outcomes. Results on MARL experiments show RAE generalises to risk-dominant NE in a trust dilemma game and that it reduces instances of crashing by 7x in an autonomous driving setting versus the best performing baseline.'}",https://openreview.net{'value': '/pdf/c58a9d2f39410c248719cff7e0c4da08dd04d5a1.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=M3IX2zAIdi,{'value': 'Learning Controllable Degradation for Real-World Super-Resolution via Constrained Flows'},Seobin Park; Dongjin Kim; Sungyong Baik; Tae Hyun Kim,~Seobin_Park1; ~Dongjin_Kim3; ~Sungyong_Baik1; ~Tae_Hyun_Kim2,,"{'value': 'Recent deep-learning-based super-resolution (SR) methods have been successful in recovering high-resolution (HR) images from their low-resolution (LR) counterparts, albeit on the synthetic and simple degradation setting: bicubic downscaling. On the other hand, super-resolution on real-world images demands the capability to handle complex downscaling mechanism which produces different artifacts (e.g., noise, blur, color distortion) upon downscaling factors. To account for complex downscaling mechanism in real-world LR images, there have been a few efforts in constructing datasets consisting of LR images with real-world downsampling degradation. However, making such datasets entails a tremendous amount of time and effort, thereby resorting to very few number of downscaling factors (e.g., $\\times$2, $\\times$3, $\\times$4). To remedy the issue, we propose to generate realistic SR datasets for unseen degradation levels by exploring the latent space of real LR images and thereby producing more diverse yet realistic LR images with complex real-world artifacts. Our quantitative and qualitative experiments demonstrate the accuracy of the generated LR images, and we show that the various conventional SR networks trained with our newly generated SR datasets can produce much better HR images.'}",https://openreview.net{'value': '/pdf/26a8ce480eb3f6cb83b7f575f38b15ef86e49b0e.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=LztkK0UZxS,{'value': 'Predicting Ordinary Differential Equations with Transformers'},Sören Becker; Michal Klein; Alexander Neitz; Giambattista Parascandolo; Niki Kilbertus,~Sören_Becker2; ~Michal_Klein1; ~Alexander_Neitz1; ~Giambattista_Parascandolo1; ~Niki_Kilbertus1,,"{'value': 'We develop a transformer-based sequence-to-sequence model that recovers scalar ordinary differential equations (ODEs) in symbolic form from irregularly sampled and noisy observations of a single solution trajectory. We demonstrate in extensive empirical evaluations that our model performs better or on par with existing methods in terms of accurate recovery across various settings. Moreover, our method is efficiently scalable: after one-time pretraining on a large set of ODEs, we can infer the governing law of a new observed solution in a few forward passes of the model.'}",https://openreview.net{'value': '/pdf/1adef285e073c2ee7ce8aa0cc6813f0b1e371e95.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=LxohF7Id88,{'value': 'Mechanistic Mode Connectivity'},Ekdeep Singh Lubana; Eric J Bigelow; Robert P. Dick; David Krueger; Hidenori Tanaka,~Ekdeep_Singh_Lubana1; ~Eric_J_Bigelow1; ~Robert_P._Dick1; ~David_Krueger1; ~Hidenori_Tanaka1,,"{'value': ""We study neural network loss landscapes through the lens of mode connectivity, the observation that minimizers of neural networks retrieved via training on a dataset are connected via simple paths of low loss. Specifically, we ask the following question: are minimizers that rely on different mechanisms for making their predictions connected via simple paths of low loss? We provide a definition of mechanistic similarity as shared invariances to input transformations and demonstrate that lack of linear connectivity between two models implies they use dissimilar mechanisms for making their predictions. Relevant to practice, this result helps us demonstrate that naive fine-tuning on a downstream dataset can fail to alter a model's mechanisms, e.g., fine-tuning can fail to eliminate a model's reliance on spurious attributes. Our analysis also motivates a method for targeted alteration of a model's mechanisms, named connectivity-based fine-tuning (CBFT), which we analyze using several synthetic datasets for the task of reducing a model's reliance on spurious attributes.""}",https://openreview.net{'value': '/pdf/d8120a9e5f68a06d7218d7d1b58765f532296665.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=LwSKljRST0,"{'value': '""Why did the Model Fail?"": Attributing Model Performance Changes to Distribution Shifts'}",Haoran Zhang; Harvineet Singh; Marzyeh Ghassemi; Shalmali Joshi,~Haoran_Zhang4; ~Harvineet_Singh1; ~Marzyeh_Ghassemi2; ~Shalmali_Joshi1,,"{'value': 'Machine learning models frequently experience performance drops under distribution shifts. The underlying cause of such shifts may be multiple simultaneous factors such as changes in data quality, differences in specific covariate distributions, or changes in the relationship between label and features. When a model does fail during deployment, attributing performance change to these factors is critical for the model developer to identify the root cause and take mitigating actions. In this work, we introduce the problem of attributing performance differences between environments to distribution shifts in the underlying data generating mechanisms. We formulate the problem as a cooperative game where the players are distributions. We define the value of a set of distributions to be the change in model performance when only this set of distributions has changed between environments, and derive an importance weighting method for computing the value of an arbitrary set of distributions. The contribution of each distribution to the total performance change is then quantified as its Shapley value. We demonstrate the correctness and utility of our method on synthetic, semi-synthetic, and real-world case studies, showing its effectiveness in attributing performance changes to a wide range of distribution shifts.'}",https://openreview.net{'value': '/pdf/6ec0e2ef7e9eeb70422ebe2b2b34d3d0f6dc9589.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=LVluQl5lAk,{'value': 'Multi-Agent Learning from Learners'},Mine Melodi Caliskan; Francesco Chini; Setareh Maghsudi,~Mine_Melodi_Caliskan1; ~Francesco_Chini1; setareh.maghsudi@uni-tuebingen.de,,"{'value': 'A large body of the ""Inverse Reinforcement Learning"" (IRL) literature focuses on recovering the reward function from a set of demonstrations of an expert agent who acts optimally or noisily optimally. Nevertheless, some recent works move away from the optimality assumption to study the ""Learning from a Learner (LfL)"" problem, where the challenge is inferring the reward function of a learning agent from a sequence of demonstrations produced by progressively improving policies. In this work, we take one of the initial steps in addressing the multi-agent version of this problem and propose a new algorithm, MA-LfL (Multiagent Learning from a Learner). Unlike the state-of-the-art literature, which recovers the reward functions from trajectories produced by agents in some equilibrium, we study the problem of inferring the reward functions of interacting agents in a general sum stochastic game without assuming any equilibrium state. The MA-LfL algorithm is rigorously built on a theoretical result that ensures its validity in the case of agents learning according to a multi-agent soft policy iteration scheme. We empirically test MA-LfL and we observe high positive correlation between the recovered reward functions and the ground truth.'}",https://openreview.net{'value': '/pdf/9ac92324dafc36e72e3edbbe641484e11ccf8579.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=LVARH5wXM9,{'value': 'Feature Programming for Multivariate Time Series Prediction'},Alex Daniel Reneau; Jerry Yao-Chieh Hu; Ammar Gilani; Han Liu,~Alex_Daniel_Reneau1; ~Jerry_Yao-Chieh_Hu1; ~Ammar_Gilani1; ~Han_Liu4,,"{'value': 'We introduce the concept of programmable feature engineering for time series modeling and propose a feature programming framework. This framework generates large amounts of predictive features for noisy multivariate time series while allowing users to incorporate their inductive bias with minimal effort. The key motivation of our framework is to view any multivariate time series as a cumulative sum of fine-grained trajectory increments, with each increment governed by a novel spin-gas dynamical Ising model. This fine-grained perspective motivates the development of a parsimonious set of operators that summarize multivariate time series in an abstract fashion, serving as the foundation for large-scale automated feature engineering. Numerically, we validate the efficacy of our method on several synthetic and real-world noisy time series datasets.'}",https://openreview.net{'value': '/pdf/aab44d08b4698cfcf73dff2536c9be955de6f3fc.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=LMay53U4ke,{'value': 'GREAD: Graph Neural Reaction-Diffusion Networks'},Jeongwhan Choi; Seoyoung Hong; Noseong Park; Sung-Bae Cho,~Jeongwhan_Choi1; ~Seoyoung_Hong1; ~Noseong_Park1; ~Sung-Bae_Cho1,,"{'value': 'Graph neural networks (GNNs) are one of the most popular research topics for deep learning. GNN methods typically have been designed on top of the graph signal processing theory. In particular, diffusion equations have been widely used for designing the core processing layer of GNNs, and therefore they are inevitably vulnerable to the notorious oversmoothing problem. Recently, a couple of papers paid attention to reaction equations in conjunctions with diffusion equations. However, they all consider limited forms of reaction equations. To this end, we present a reaction-diffusion equation-based GNN method that considers all popular types of reaction equations in addition to one special reaction equation designed by us. To our knowledge, our paper is one of the most comprehensive studies on reaction-diffusion equation-based GNNs. In our experiments with 9 datasets and 28 baselines, our method, called GREAD, outperforms them in a majority of cases. Further synthetic data experiments show that it mitigates the oversmoothing problem and works well for various homophily rates.'}",https://openreview.net{'value': '/pdf/9048cbaccc84e9977a22f448d58fea6070563276.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=LMXgU4zrq6,{'value': 'How Do Transformers Learn Topic Structure: Towards a Mechanistic Understanding'},Yuchen Li; Yuanzhi Li; Andrej Risteski,~Yuchen_Li5; ~Yuanzhi_Li1; ~Andrej_Risteski2,,"{'value': ""While the successes of transformers across many domains are indisputable, accurate understanding of the learning mechanics is still largely lacking. Their capabilities have been probed on benchmarks which include a variety of structured and reasoning tasks---but mathematical understanding is lagging substantially behind. Recent lines of work have begun studying representational aspects of this question: that is, the size/depth/complexity of attention-based networks to perform certain tasks. However, there is no guarantee the learning dynamics will converge to the constructions proposed. In our paper, we provide fine-grained mechanistic understanding of how transformers learn ``semantic structure'', understood as capturing co-occurrence structure of words. Precisely, we show, through a combination of mathematical analysis and experiments on Wikipedia data and synthetic data modeled by Latent Dirichlet Allocation (LDA), that the embedding layer and the self-attention layer encode the topical structure. In the former case, this manifests as higher average inner product of embeddings between same-topic words. In the latter, it manifests as higher average pairwise attention between same-topic words. The mathematical results involve several assumptions to make the analysis tractable, which we verify on data, and might be of independent interest as well.""}",https://openreview.net{'value': '/pdf/6513b976812ed78990056c8316d885f76fe815c9.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=Kw90j2pNSt,{'value': 'Generative Causal Representation Learning for Out-of-Distribution Motion Forecasting'},Shayan Shirahmad Gale Bagi; Zahra Gharaee; Oliver Schulte; Mark Crowley,~Shayan_Shirahmad_Gale_Bagi1; ~Zahra_Gharaee1; ~Oliver_Schulte1; ~Mark_Crowley1,,"{'value': 'Conventional supervised learning methods typically assume i.i.d samples and are found to be sensitive to out-of-distribution (OOD) data. We propose Generative Causal Representation Learning (GCRL) which leverages causality to facilitate knowledge transfer under distribution shifts. While we evaluate the effectiveness of our proposed method in human trajectory prediction models, GCRL can be applied to other domains as well. First, we propose a novel causal model that explains the generative factors in motion forecasting datasets using features that are common across all environments and with features that are specific to each environment. Selection variables are used to determine which parts of the model can be directly transferred to a new environment without fine-tuning. Second, we propose an end-to-end variational learning paradigm to learn the causal mechanisms that generate observations from features. GCRL is supported by strong theoretical results that imply identifiability of the causal model under certain assumptions. Experimental results on synthetic and real-world motion forecasting datasets show the robustness and effectiveness of our proposed method for knowledge transfer under zero-shot and low-shot settings by substantially outperforming the prior motion forecasting models on out-of-distribution prediction.'}",https://openreview.net{'value': '/pdf/f61a767c4034111970e73908a6ba9a3b62b8bc6d.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=KhizXcNnY6,{'value': 'Learning Control by Iterative Inversion'},Gal Leibovich; Guy Jacob; Or Avner; Gal Novik; Aviv Tamar,~Gal_Leibovich1; ~Guy_Jacob1; ~Or_Avner1; ~Gal_Novik1; ~Aviv_Tamar2,,"{'value': 'We propose *iterative inversion* - an algorithm for learning an inverse function without input-output pairs, but only with samples from the desired output distribution and access to the forward function. The key challenge is a *distribution shift* between the desired outputs and the outputs of an initial random guess, and we prove that iterative inversion can steer the learning correctly, under rather strict conditions on the function. We apply iterative inversion to learn control. Our input is a set of demonstrations of desired behavior, given as video embeddings of trajectories (without actions), and our method iteratively learns to imitate trajectories generated by the current policy, perturbed by random exploration noise. Our approach does not require rewards, and only employs supervised learning, which can be easily scaled to use state-of-the-art trajectory embedding techniques and policy representations. Indeed, with a VQ-VAE embedding, and a transformer-based policy, we demonstrate non-trivial continuous control on several tasks (videos available at https://sites.google.com/view/iter-inver). Further, we report an improved performance on imitating diverse behaviors compared to reward based methods.'}",https://openreview.net{'value': '/pdf/23bf50d966796af6de16a091df40a4c0f353283d.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=KQaMjvlUE6,{'value': 'Competing for Shareable Arms in Multi-Player Multi-Armed Bandits'},Renzhe Xu; Haotian Wang; Xingxuan Zhang; Bo Li; Peng Cui,~Renzhe_Xu1; ~Haotian_Wang2; ~Xingxuan_Zhang1; ~Bo_Li29; ~Peng_Cui1,,"{'value': ""Competitions for shareable and limited resources have long been studied with strategic agents. In reality, agents often have to learn and maximize the rewards of the resources at the same time. To design an individualized competing policy, we model the competition between agents in a novel multi-player multi-armed bandit (MPMAB) setting where players are selfish and aim to maximize their own rewards. In addition, when several players pull the same arm, we assume that these players averagely share the arms' rewards by expectation. Under this setting, we first analyze the Nash equilibrium when arms' rewards are known. Subsequently, we propose a novel Selfish MPMAB with Averaging Allocation (SMAA) approach based on the equilibrium. We theoretically demonstrate that SMAA could achieve a good regret guarantee for each player when all players follow the algorithm. Additionally, we establish that no single selfish player can significantly increase their rewards through deviation, nor can they detrimentally affect other players' rewards without incurring substantial losses for themselves. We finally validate the effectiveness of the method in extensive synthetic experiments.""}",https://openreview.net{'value': '/pdf/ae9370e0f15c0f7f9e83f797a669085c840e021f.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=KKaTURYcKG,{'value': 'Pairwise Ranking Losses of Click-Through Rates Prediction for Welfare Maximization in Ad Auctions'},Boxiang Lyu; Zhe Feng; Zachary Robertson; Oluwasanmi O Koyejo,~Boxiang_Lyu1; ~Zhe_Feng3; ~Zachary_Robertson1; ~Oluwasanmi_O_Koyejo1,,"{'value': ""We study the design of loss functions for click-through rates (CTR) to optimize (social) welfare in advertising auctions. Existing works either only focus on CTR predictions without consideration of business objectives (e.g., welfare) in auctions or assume that the distribution over the participants' expected cost-per-impression (eCPM) is known a priori, then use various additional assumptions on the parametric form of the distribution to derive loss functions for predicting CTRs. In this work, we bring back the welfare objectives of ad auctions into CTR predictions and propose a novel weighted rankloss to train the CTR model. Compared to existing literature, our approach provides a provable guarantee on welfare but without assumptions on the eCPMs' distribution while also avoiding the intractability of naively applying existing learning-to-rank methods. Further, we propose a theoretically justifiable technique for calibrating the losses using labels generated from a teacher network, only assuming that the teacher network has bounded $\\ell_2$ generalization error. Finally, we demonstrate the advantages of the proposed loss on synthetic and real-world data.""}",https://openreview.net{'value': '/pdf/888023efc8146db641b913a3e1471f01fe4fcc71.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=K26zQKvXiR,{'value': 'Target-Aware Generative Augmentations for Single-Shot Adaptation'},Kowshik Thopalli; Rakshith Subramanyam; Pavan K. Turaga; Jayaraman J. Thiagarajan,~Kowshik_Thopalli1; ~Rakshith_Subramanyam1; ~Pavan_K._Turaga1; ~Jayaraman_J._Thiagarajan3,,"{'value': 'In this paper, we address the problem of adapting models from a source domain to a target domain, a task that has become increasingly important due to the brittle generalization of deep neural networks. While several test-time adaptation techniques have emerged, they typically rely on synthetic toolbox data augmentations in cases of limited target data availability. We consider the challenging setting of single-shot adaptation and explore the design of augmentation strategies. We argue that augmentations utilized by existing methods are insufficient to handle large distribution shifts, and hence propose a new approach SiSTA, which first fine-tunes a generative model from the source domain using a single-shot target, and then employs novel sampling strategies for curating synthetic target data. Using experiments on a variety of benchmarks, distribution shifts and image corruptions, we find that SiSTA produces significantly improved generalization over existing baselines in face attribute detection and multi-class object recognition. Furthermore, SiSTA performs competitively to models obtained by training on larger target datasets. Our codes can be accessed at https://github.com/Rakshith-2905/SiSTA'}",https://openreview.net{'value': '/pdf/2edce30f859161b9d42e8d17d5358f17ac1a7eae.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=K1sJiHvy02,{'value': 'Label differential privacy and private training data release'},Robert Istvan Busa-Fekete; Andres Munoz medina; Umar Syed; Sergei Vassilvitskii,~Robert_Istvan_Busa-Fekete1; ~Andres_Munoz_medina1; ~Umar_Syed1; ~Sergei_Vassilvitskii2,,"{'value': ""We study differentially private mechanisms for sharing training data in machine learning settings. Our goal is to enable learning of an accurate predictive model while protecting the privacy of each user's label. Previous work established privacy guarantees that assumed the features are public and given exogenously, a setting known as label differential privacy. In some scenarios, this can be a strong assumption that removes the interplay between features and labels from the privacy analysis. We relax this approach and instead assume the features are drawn from a distribution that depends on the private labels. We first show that simply adding noise to the label, as in previous work, can lead to an arbitrarily weak privacy guarantee, and also present methods for estimating this privacy loss from data. We then present a new mechanism that replaces some training examples with synthetically generated data, and show that our mechanism has a much better privacy-utility tradeoff if the synthetic data is ‘realistic’, in a certain quantifiable sense. Finally, we empirically validate our theoretical analysis.""}",https://openreview.net{'value': '/pdf/119b500c23686f8cfb872f02b117adb41aa8a232.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=K0InBsKODr,{'value': 'Low-Variance Gradient Estimation in Unrolled Computation Graphs with ES-Single'},Paul Vicol,~Paul_Vicol1,,"{'value': 'We propose an evolution strategies-based algorithm for estimating gradients in unrolled computation graphs, called ES-Single. Similarly to the recently-proposed Persistent Evolution Strategies (PES), ES-Single is unbiased, and overcomes chaos arising from recursive function applications by smoothing the meta-loss landscape. ES-Single samples a single perturbation per particle, that is kept fixed over the course of an inner problem (e.g., perturbations are not re-sampled for each partial unroll). Compared to PES, ES-Single is simpler to implement and has lower variance: the variance of ES-Single is constant with respect to the number of truncated unrolls, removing a key barrier in applying ES to long inner problems using short truncations. We show that ES-Single is unbiased for quadratic inner problems, and demonstrate empirically that its variance can be substantially lower than that of PES. ES-Single consistently outperforms PES on a variety of tasks, including a synthetic benchmark task, hyperparameter optimization, training recurrent neural networks, and training learned optimizers.'}",https://openreview.net{'value': '/pdf/478f1eca12f53253d943f86bcad71e72b425db06.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=K07XAlzh5i,{'value': 'From Relational Pooling to Subgraph GNNs: A Universal Framework for More Expressive Graph Neural Networks'},Cai Zhou; Xiyuan Wang; Muhan Zhang,~Cai_Zhou2; ~Xiyuan_Wang1; ~Muhan_Zhang1,,"{'value': 'Relational pooling is a framework for building more expressive and permutation-invariant graph neural networks. However, there is limited understanding of the exact enhancement in the expressivity of RP and its connection with the Weisfeiler-Lehman hierarchy. Starting from RP, we propose to explicitly assign labels to nodes as additional features to improve graph isomorphism distinguishing power of message passing neural networks. The method is then extended to higher-dimensional WL, leading to a novel $k,l$-WL algorithm, a more general framework than $k$-WL. We further introduce the subgraph concept into our hierarchy and propose a localized $k,l$-WL framework, incorporating a wide range of existing work, including many subgraph GNNs. Theoretically, we analyze the expressivity of $k,l$-WL w.r.t. $k$ and $l$ and compare it with the traditional $k$-WL. Complexity reduction methods are also systematically discussed to build powerful and practical $k,l$-GNN instances. We theoretically and experimentally prove that our method is universally compatible and capable of improving the expressivity of any base GNN model. Our $k,l$-GNNs achieve superior performance on many synthetic and real-world datasets, which verifies the effectiveness of our framework.'}",https://openreview.net{'value': '/pdf/6096afc27dd9cc64de0bbe01a76cc5bb17c03a91.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=JzZ2xAvCs8,{'value': 'Loss-Guided Diffusion Models for Plug-and-Play Controllable Generation'},Jiaming Song; Qinsheng Zhang; Hongxu Yin; Morteza Mardani; Ming-Yu Liu; Jan Kautz; Yongxin Chen; Arash Vahdat,~Jiaming_Song1; ~Qinsheng_Zhang1; ~Hongxu_Yin2; ~Morteza_Mardani1; ~Ming-Yu_Liu1; ~Jan_Kautz1; ~Yongxin_Chen1; ~Arash_Vahdat3,,"{'value': 'We consider guiding denoising diffusion models with general differentiable loss functions in a plug-and-play fashion, enabling controllable generation without additional training. This paradigm, termed Loss-Guided Diffusion (LGD), can easily be integrated into all diffusion models and leverage various efficient samplers. Despite the benefits, the resulting guidance term is, unfortunately, an intractable integral and needs to be approximated. Existing methods compute the guidance term based on a point estimate. However, we show that such approaches have significant errors over the scale of the approximations. To address this issue, we propose a Monte Carlo method that uses multiple samples from a suitable distribution to reduce bias. Our method is effective in various synthetic and real-world settings, including image super-resolution, text or label-conditional image generation, and controllable motion synthesis. Notably, we show how our method can be applied to control a pretrained motion diffusion model to follow certain paths and avoid obstacles that are proven challenging to prior methods.'}",https://openreview.net{'value': '/pdf/5b5abfd63adb98adfd25a87d3df1d4a16192aa9f.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=JrSWhb7dzp,{'value': 'DRCFS: Doubly Robust Causal Feature Selection'},Francesco Quinzan; Ashkan Soleymani; Patrick Jaillet; Cristian R. Rojas; Stefan Bauer,~Francesco_Quinzan1; ~Ashkan_Soleymani1; ~Patrick_Jaillet1; ~Cristian_R._Rojas2; ~Stefan_Bauer1,,"{'value': 'Knowing the features of a complex system that are highly relevant to a particular target variable is of fundamental interest in many areas of science. Existing approaches are often limited to linear settings, sometimes lack guarantees, and in most cases, do not scale to the problem at hand, in particular to images. We propose DRCFS, a doubly robust feature selection method for identifying the causal features even in nonlinear and high dimensional settings. We provide theoretical guarantees, illustrate necessary conditions for our assumptions, and perform extensive experiments across a wide range of simulated and semi-synthetic datasets. DRCFS significantly outperforms existing state-of-the-art methods, selecting robust features even in challenging highly non-linear and high-dimensional problems.'}",https://openreview.net{'value': '/pdf/7ef28637d0c0229850be510ee8c7c3e7b68eab9e.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=Jpbyykdtmt,{'value': 'PAC-Bayesian Generalization Bounds for Adversarial Generative Models'},Sokhna Diarra Mbacke; Florence Clerc; Pascal Germain,~Sokhna_Diarra_Mbacke1; ~Florence_Clerc1; ~Pascal_Germain1,,"{'value': 'We extend PAC-Bayesian theory to generative models and develop generalization bounds for models based on the Wasserstein distance and the total variation distance. Our first result on the Wasserstein distance assumes the instance space is bounded, while our second result takes advantage of dimensionality reduction. Our results naturally apply to Wasserstein GANs and Energy-Based GANs, and our bounds provide new training objectives for these two. Although our work is mainly theoretical, we perform numerical experiments showing non-vacuous generalization bounds for Wasserstein GANs on synthetic datasets.'}",https://openreview.net{'value': '/pdf/211d20a40ff43e74edbda87c67cc4e527cb14f98.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=JK0hiktaFV,{'value': 'Beam Tree Recursive Cells'},Jishnu Ray Chowdhury; Cornelia Caragea,~Jishnu_Ray_Chowdhury2; ~Cornelia_Caragea2,,"{'value': 'We propose Beam Tree Recursive Cell (BT-Cell) - a backpropagation-friendly framework to extend Recursive Neural Networks (RvNNs) with beam search for latent structure induction. We further extend this framework by proposing a relaxation of the hard top-$k$ operators in beam search for better propagation of gradient signals. We evaluate our proposed models in different out-of-distribution splits in both synthetic and realistic data. Our experiments show that BT-Cell achieves near-perfect performance on several challenging structure-sensitive synthetic tasks like ListOps and logical inference while maintaining comparable performance in realistic data against other RvNN-based models. Additionally, we identify a previously unknown failure case for neural models in generalization to unseen number of arguments in ListOps. The code is available at: https://github.com/JRC1995/BeamTreeRecursiveCells.'}",https://openreview.net{'value': '/pdf/76453ccf0474f0a8c3e5433df8b52149e906b7fe.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=Iwt7oI9cNb,{'value': 'Inferring Relational Potentials in Interacting Systems'},Armand Comas; Yilun Du; Christian Fernandez Lopez; Sandesh Ghimire; Mario Sznaier; Joshua B. Tenenbaum; Octavia Camps,~Armand_Comas1; ~Yilun_Du1; ~Christian_Fernandez_Lopez1; ~Sandesh_Ghimire2; ~Mario_Sznaier1; ~Joshua_B._Tenenbaum1; ~Octavia_Camps1,,"{'value': 'Systems consisting of interacting agents are prevalent in the world, ranging from dynamical systems in physics to complex biological networks. To build systems which can interact robustly in the real world, it is thus important to be able to infer the precise interactions governing such systems. Existing approaches typically discover such interactions by explicitly modeling the feed-forward dynamics of the trajectories. In this work, we propose Neural Interaction Inference with Potentials (NIIP) as an alternative approach to discover such interactions that enables greater flexibility in trajectory modeling: it discovers a set of relational potentials, represented as energy functions, which when minimized reconstruct the original trajectory. NIIP assigns low energy to the subset of trajectories which respect the relational constraints observed. We illustrate that with these representations NIIP displays unique capabilities in test-time. First, it allows trajectory manipulation, such as interchanging interaction types across separately trained models, as well as trajectory forecasting. Additionally, it allows adding external hand-crafted potentials at test-time. Finally, NIIP enables the detection of out-of-distribution samples and anomalies without explicit training.'}",https://openreview.net{'value': '/pdf/cc369e2dfdc541d6798be36a358ec26488f7352c.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=ImQC3p9wlm,{'value': 'Mirror Sinkhorn: Fast Online Optimization on Transport Polytopes'},Marin Ballu; Quentin Berthet,marin.ballu@gmail.com; ~Quentin_Berthet2,,"{'value': 'Optimal transport is an important tool in machine learning, allowing to capture geometric properties of the data through a linear program on transport polytopes. We present a single-loop optimization algorithm for minimizing general convex objectives on these domains, utilizing the principles of Sinkhorn matrix scaling and mirror descent. The proposed algorithm is robust to noise, and can be used in an online setting. We provide theoretical guarantees for convex objectives and experimental results showcasing it effectiveness on both synthetic and real-world data.'}",https://openreview.net{'value': '/pdf/e4b217b8f76c4f9fa80da32860688647b1b57959.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=IOVYTyoqVz,{'value': 'Image Restoration with Mean-Reverting Stochastic Differential Equations'},Ziwei Luo; Fredrik K. Gustafsson; Zheng Zhao; Jens Sjölund; Thomas B. Schön,~Ziwei_Luo1; ~Fredrik_K._Gustafsson1; ~Zheng_Zhao1; ~Jens_Sjölund1; ~Thomas_B._Schön1,,"{'value': 'This paper presents a stochastic differential equation (SDE) approach for general-purpose image restoration. The key construction consists in a mean-reverting SDE that transforms a high-quality image into a degraded counterpart as a mean state with fixed Gaussian noise. Then, by simulating the corresponding reverse-time SDE, we are able to restore the origin of the low-quality image without relying on any task-specific prior knowledge. Crucially, the proposed mean-reverting SDE has a closed-form solution, allowing us to compute the ground truth time-dependent score and learn it with a neural network. Moreover, we propose a maximum likelihood objective to learn an optimal reverse trajectory that stabilizes the training and improves the restoration results. The experiments show that our proposed method achieves highly competitive performance in quantitative comparisons on image deraining, deblurring, and denoising, setting a new state-of-the-art on two deraining datasets. Finally, the general applicability of our approach is further demonstrated via qualitative results on image super-resolution, inpainting, and dehazing. Code is available at https://github.com/Algolzw/image-restoration-sde.'}",https://openreview.net{'value': '/pdf/e0e76a5fc2a8f87a1e5a569e57a9b04108c45308.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=IKCk6th595,{'value': 'MetaDiffuser: Diffusion Model as Conditional Planner for Offline Meta-RL'},Fei Ni; Jianye HAO; Yao Mu; Yifu Yuan; YAN ZHENG; Bin Wang; Zhixuan Liang,~Fei_Ni1; ~Jianye_HAO1; ~Yao_Mu1; ~Yifu_Yuan1; ~YAN_ZHENG1; ~Bin_Wang12; ~Zhixuan_Liang2,,"{'value': 'Recently, diffusion model shines as a promising backbone for the sequence modeling paradigm in offline reinforcement learning(RL). However, these works mostly lack the generalization ability across tasks with reward or dynamics change. To tackle this challenge, in this paper we propose a task-oriented conditioned diffusion planner for offline meta-RL(MetaDiffuser), which considers the generalization problem as conditional trajectory generation task with contextual representation. The key is to learn a context conditioned diffusion model which can generate task-oriented trajectories for planning across diverse tasks. To enhance the dynamics consistency of the generated trajectories while encouraging trajectories to achieve high returns, we further design a dual-guided module in the sampling process of the diffusion model. The proposed framework enjoys the robustness to the quality of collected warm-start data from the testing task and the flexibility to incorporate with different task representation method. The experiment results on MuJoCo benchmarks show that MetaDiffuser outperforms other strong offline meta-RL baselines, demonstrating the outstanding conditional generation ability of diffusion architecture.'}",https://openreview.net{'value': '/pdf/3faf1298dd5d51972dde54304a7c0050e3745173.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=IJffiJTLhI,{'value': 'Oracles & Followers: Stackelberg Equilibria in Deep Multi-Agent Reinforcement Learning'},Matthias Gerstgrasser; David C. Parkes,~Matthias_Gerstgrasser1; ~David_C._Parkes1,,"{'value': 'Stackelberg equilibria arise naturally in a range of popular learning problems, such as in security games or indirect mechanism design, and have received increasing attention in the reinforcement learning literature. We present a general framework for implementing Stackelberg equilibria search as a multi-agent RL problem, allowing a wide range of algorithmic design choices. We discuss how previous approaches can be seen as specific instantiations of this framework. As a key insight, we note that the design space allows for approaches not previously seen in the literature, for instance by leveraging multitask and meta-RL techniques for follower convergence. We propose one such approach using contextual policies, and evaluate it experimentally on both standard and novel benchmark domains, showing greatly improved sample efficiency compared to previous approaches. Finally, we explore the effect of adopting algorithm designs outside the borders of our framework.'}",https://openreview.net{'value': '/pdf/cfc6eed4113312f4747d36f4564673dd09290793.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=IGfmSM7siu,{'value': 'Model Transferability with Responsive Decision Subjects'},Yatong Chen; Zeyu Tang; Kun Zhang; Yang Liu,~Yatong_Chen1; ~Zeyu_Tang1; ~Kun_Zhang1; ~Yang_Liu3,,"{'value': 'Given an algorithmic predictor that is accurate on some source population consisting of strategic human decision subjects, will it remain accurate if the population respond to it? In our setting, an agent or a user corresponds to a sample $(X,Y)$ drawn from a distribution $\\cal{D}$ and will face a model $h$ and its classification result $h(X)$. Agents can modify $X$ to adapt to $h$, which will incur a distribution shift on $(X,Y)$. Our formulation is motivated by applications where the deployed machine learning models are subjected to human agents, and will ultimately face responsive and interactive data distributions. We formalize the discussions of the transferability of a model by studying how the performance of the model trained on the available source distribution (data) would translate to the performance on its induced domain. We provide both upper bounds for the performance gap due to the induced domain shift, as well as lower bounds for the trade-offs that a classifier has to suffer on either the source training distribution or the induced target distribution. We provide further instantiated analysis for two popular domain adaptation settings, including covariate shift and target shift.'}",https://openreview.net{'value': '/pdf/117185ac5487b045d7e08aeb8584dbf03384bcc5.pdf'},{'abstract_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=I5kywOUcl7,"{'value': 'Synthetic Data, Real Errors: How (Not) to Publish and Use Synthetic Data'}",Boris van Breugel; Zhaozhi Qian; Mihaela van der Schaar,~Boris_van_Breugel2; ~Zhaozhi_Qian1; ~Mihaela_van_der_Schaar2,,"{'value': 'Generating synthetic data through generative models is gaining interest in the ML community and beyond, promising a future where datasets can be tailored to individual needs. Unfortunately, synthetic data is usually not perfect, resulting in potential errors in downstream tasks. In this work we explore how the generative process affects the downstream ML task. We show that the naive synthetic data approach---using synthetic data as if it is real---leads to downstream models and analyses that do not generalize well to real data. As a first step towards better ML in the synthetic data regime, we introduce Deep Generative Ensemble (DGE)---a framework inspired by Deep Ensembles that aims to implicitly approximate the posterior distribution over the generative process model parameters. DGE improves downstream model training, evaluation, and uncertainty quantification, vastly outperforming the naive approach on average. The largest improvements are achieved for minority classes and low-density regions of the original data, for which the generative uncertainty is largest.'}",https://openreview.net{'value': '/pdf/238137bbfb33d6abc927eab93e65b9400c41c2b9.pdf'},{'title_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=HlpBeHoeUA,{'value': 'Regularizing Towards Soft Equivariance Under Mixed Symmetries'},Hyunsu Kim; Hyungi Lee; Hongseok Yang; Juho Lee,~Hyunsu_Kim2; ~Hyungi_Lee1; ~Hongseok_Yang2; ~Juho_Lee2,,"{'value': 'Datasets often have their intrinsic symmetries, and particular deep-learning models called equivariant or invariant models have been developed to exploit these symmetries. However, if some or all of these symmetries are only approximate, which frequently happens in practice, these models may be suboptimal due to the architectural restrictions imposed on them. We tackle this issue of approximate symmetries in a setup where symmetries are mixed, i.e., they are symmetries of not single but multiple different types and the degree of approximation varies across these types. Instead of proposing a new architectural restriction as in most of the previous approaches, we present a regularizer-based method for building a model for a dataset with mixed approximate symmetries. The key component of our method is what we call equivariance regularizer for a given type of symmetries, which measures how much a model is equivariant with respect to the symmetries of the type. Our method is trained with these regularizers, one per each symmetry type, and the strength of the regularizers is automatically tuned during training, leading to the discovery of the approximation levels of some candidate symmetry types without explicit supervision. Using synthetic function approximation and motion forecasting tasks, we demonstrate that our method achieves better accuracy than prior approaches while discovering the approximate symmetry levels correctly.'}",https://openreview.net{'value': '/pdf/7002c6eed6957700017aea7267984c7da3f5fcab.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=HKfSTYLJh7,{'value': 'On Many-Actions Policy Gradient'},Michal Nauman; Marek Cygan,~Michal_Nauman1; ~Marek_Cygan1,,"{'value': 'We study the variance of stochastic policy gradients (SPGs) with many action samples per state. We derive a many-actions optimality condition, which determines when many-actions SPG yields lower variance as compared to a single-action agent with proportionally extended trajectory. We propose Model-Based Many-Actions (MBMA), an approach leveraging dynamics models for many-actions sampling in the context of SPG. MBMA addresses issues associated with existing implementations of many-actions SPG and yields lower bias and comparable variance to SPG estimated from states in model-simulated rollouts. We find that MBMA bias and variance structure matches that predicted by theory. As a result, MBMA achieves improved sample efficiency and higher returns on a range of continuous action environments as compared to model-free, many-actions, and model-based on-policy SPG baselines.'}",https://openreview.net{'value': '/pdf/e6bd552b91d2e96445e670ef16fdb777f48c4e15.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=H01CJWHAmw,{'value': 'One-sided Matrix Completion from Two Observations Per Row'},Steven Cao; Percy Liang; Gregory Valiant,~Steven_Cao1; ~Percy_Liang1; ~Gregory_Valiant1,,"{'value': ""Given only a few observed entries from a low-rank matrix $X$, matrix completion is the problem of imputing the missing entries, and it formalizes a wide range of real-world settings that involve estimating missing data. However, when there are too few observed entries to complete the matrix, what other aspects of the underlying matrix can be reliably recovered? We study one such problem setting, that of ``one-sided'' matrix completion, where our goal is to recover the right singular vectors of $X$, even in the regime where recovering the left singular vectors is impossible, which arises when there are more rows than columns and very few observations. We propose a natural algorithm that involves imputing the missing values of the matrix $X^TX$ and show that even with only two observations per row in $X$, we can provably recover $X^TX$ as long as we have at least $\\Omega(r^2 d \\log d)$ rows, where $r$ is the rank and $d$ is the number of columns. We evaluate our algorithm on one-sided recovery of synthetic data and low-coverage genome sequencing. In these settings, our algorithm substantially outperforms standard matrix completion and a variety of direct factorization methods.""}",https://openreview.net{'value': '/pdf/0269d053fdca5b62008bd2cc72a815b5b39bea75.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=GDVczeyqFa,{'value': 'Truncating Trajectories in Monte Carlo Reinforcement Learning'},Riccardo Poiani; Alberto Maria Metelli; Marcello Restelli,~Riccardo_Poiani3; ~Alberto_Maria_Metelli2; ~Marcello_Restelli1,,"{'value': 'In Reinforcement Learning (RL), an agent acts in an unknown environment to maximize the expected cumulative discounted sum of an external reward signal, i.e., the expected return. In practice, in many tasks of interest, such as policy optimization, the agent usually spends its interaction budget by collecting episodes of *fixed length* within a simulator (i.e., Monte Carlo simulation). However, given the discounted nature of the RL objective, this data collection strategy might not be the best option. Indeed, the rewards taken in early simulation steps weigh exponentially more than future rewards. Taking a cue from this intuition, in this paper, we design an a-priori budget allocation strategy that leads to the collection of trajectories of different lengths, i.e., *truncated*. The proposed approach provably minimizes the width of the confidence intervals around the empirical estimates of the expected return of a policy. After discussing the theoretical properties of our method, we make use of our trajectory truncation mechanism to extend Policy Optimization via Importance Sampling (POIS, Metelli et al., 2018) algorithm. Finally, we conduct a numerical comparison between our algorithm and POIS: the results are consistent with our theory and show that an appropriate truncation of the trajectories can succeed in improving performance.'}",https://openreview.net{'value': '/pdf/c229c8c8a25e461800cb37cc67086e22d4337381.pdf'},{'title_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=GBmL22Gx9X,{'value': 'Training Normalizing Flows from Dependent Data'},Matthias Kirchler; Christoph Lippert; Marius Kloft,~Matthias_Kirchler1; ~Christoph_Lippert1; ~Marius_Kloft1,,"{'value': 'Normalizing flows are powerful non-parametric statistical models that function as a hybrid between density estimators and generative models. Current learning algorithms for normalizing flows assume that data points are sampled independently, an assumption that is frequently violated in practice, which may lead to erroneous density estimation and data generation. We propose a likelihood objective of normalizing flows incorporating dependencies between the data points, for which we derive a flexible and efficient learning algorithm suitable for different dependency structures. We show that respecting dependencies between observations can improve empirical results on both synthetic and real-world data, and leads to higher statistical power in a downstream application to genome-wide association studies.'}",https://openreview.net{'value': '/pdf/e9607268d50e629ea006adf0d5a37cbbf9c3e9ca.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=FjOB0g7iRf,{'value': 'Doubly Adversarial Federated Bandits'},Jialin Yi; Milan Vojnovic,~Jialin_Yi1; ~Milan_Vojnovic1,,"{'value': 'We study a new non-stochastic federated multiarmed bandit problem with multiple agents collaborating via a communication network. The losses of the arms are assigned by an oblivious adversary that specifies the loss of each arm not only for each time step but also for each agent, which we call doubly adversarial. In this setting, different agents may choose the same arm in the same time step but observe different feedback. The goal of each agent is to find a globally best arm in hindsight that has the lowest cumulative loss averaged over all agents, which necessities the communication among agents. We provide regret lower bounds for any federated bandit algorithm under different settings, when agents have access to full-information feedback, or the bandit feedback. For the bandit feedback setting, we propose a near-optimal federated bandit algorithm called FEDEXP3. Our algorithm gives a positive answer to an open question proposed in (Cesa-Bianchi et al., 2016): FEDEXP3 can guarantee a sub-linear regret without exchanging sequences of selected arm identities or loss sequences among agents. We also provide numerical evaluations of our algorithm to validate our theoretical results and demonstrate its effectiveness on synthetic and real-world datasets.'}",https://openreview.net{'value': '/pdf/66f23e9f9aca8f37fe7b2670cd7f89c514a637a1.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=FdCeFHTXrS,{'value': 'Difference-in-Differences Meets Tree-based Methods: Heterogeneous Treatment Effects Estimation with Unmeasured Confounding'},Caizhi Tang; Huiyuan Wang; Xinyu Li; Qing Cui; Longfei Li; JUN ZHOU,~Caizhi_Tang1; ~Huiyuan_Wang1; ~Xinyu_Li6; ~Qing_Cui1; ~Longfei_Li1; ~JUN_ZHOU6,,"{'value': 'This study considers the estimation of conditional causal effects in the presence of unmeasured confounding for a balanced panel with treatment imposed at the last time point. To address this, we combine Difference-in-differences (DiD) and tree-based methods and propose a new identification assumption that allows for the violation of the (conditional) parallel trends assumption adopted by most existing DiD methods. Under this new assumption, we prove partial identifiability of the conditional average treatment effect on the treated group (CATT). Our proposed method estimates CATT through a tree-based causal approach, guided by a novel splitting rule that avoids model misspecification and unnecessary auxiliary parameter estimation. The splitting rule measures both the error of fitting observed data and the violation of conditional parallel trends simultaneously. We also develop an ensemble of multiple trees via gradient boosting to further enhance performance. Experimental results on both synthetic and real-world datasets validate the effectiveness of our proposed method.'}",https://openreview.net{'value': '/pdf/1cd3dc56200def5a50840b5f7d65f218f90de48f.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=FREvWGzoRu,{'value': 'Universal Physics-Informed Neural Networks: Symbolic Differential Operator Discovery with Sparse Data'},Lena Podina; Brydon Eastman; Mohammad Kohandel,~Lena_Podina1; ~Brydon_Eastman1; ~Mohammad_Kohandel1,,"{'value': 'In this work we perform symbolic discovery of differential operators in a situation where there is sparse experimental data. This small data regime in machine learning can be made tractable by providing our algorithms with prior information about the underlying dynamics. Physics Informed Neural Networks (PINNs) have been very successful in this regime (reconstructing entire ODE solutions using only a single point or entire PDE solutions with very few measurements of the initial condition). The Universal PINN approach (UPINN) adds a neural network that learns a representation of unknown hidden terms in the differential equation. The algorithm yields both a surrogate solution to the differential equation and a black-box representation of the hidden terms. These hidden term neural networks can then be converted into symbolic equations using symbolic regression techniques like AI Feynman. In order to achieve convergence of the neural networks, we provide our algorithms with (noisy) measurements of both the initial condition as well as (synthetic) experimental data obtained at later times. We demonstrate strong performance of UPINNs even when provided with very few measurements of noisy data in both the ODE and PDE regime.'}",https://openreview.net{'value': '/pdf/7bde53a679a12dc8b54fbb3056041b92ce8fcadd.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=FR2F4QzWFp,{'value': 'Two Losses Are Better Than One: Faster Optimization Using a Cheaper Proxy'},Blake Woodworth; Konstantin Mishchenko; Francis Bach,~Blake_Woodworth2; ~Konstantin_Mishchenko1; ~Francis_Bach1,,"{'value': 'We present an algorithm for minimizing an objective with hard-to-compute gradients by using a related, easier-to-access function as a proxy. Our algorithm is based on approximate proximal-point iterations on the proxy combined with relatively few stochastic gradients from the objective. When the difference between the objective and the proxy is $\\delta$-smooth, our algorithm guarantees convergence at a rate matching stochastic gradient descent on a $\\delta$-smooth objective, which can lead to substantially better sample efficiency. Our algorithm has many potential applications in machine learning, and provides a principled means of leveraging synthetic data, physics simulators, mixed public and private data, and more.'}",https://openreview.net{'value': '/pdf/0098f7642b2d329c0584119e6cebceebc18ea7ad.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=EuUeVUS6UV,{'value': 'Extrapolative Controlled Sequence Generation via Iterative Refinement'},Vishakh Padmakumar; Richard Yuanzhe Pang; He He; Ankur P Parikh,~Vishakh_Padmakumar1; ~Richard_Yuanzhe_Pang1; ~He_He2; ~Ankur_P_Parikh1,,"{'value': 'We study the problem of extrapolative controlled generation, i.e., generating sequences with attribute values beyond the range seen in training. This task is of significant importance in automated design, especially drug discovery, where the goal is to design novel proteins that are better (e.g., more stable) than existing sequences. Thus, by definition the target sequences and their attribute values are out of the training distribution, posing challenges to existing methods that aim to directly generate the target sequence. Instead, in this work, we propose Iterative Controlled Extrapolation (ICE) which iteratively makes local edits to a sequence to enable extrapolation. We train the model on synthetically generated sequence pairs that demonstrate small improvement in the attribute value. Results on one natural language task (sentiment analysis) and two protein engineering tasks (ACE2 stability and AAV fitness) show that ICE outperforms state-of-the-art approaches despite its simplicity.'}",https://openreview.net{'value': '/pdf/c40ca872a95faa7d472e9958124fe7ce9f744b19.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=EqHTMU4YbA,{'value': 'Divide and Conquer Dynamic Programming: An Almost Linear Time Change Point Detection Methodology in High Dimensions'},Wanshan Li; Daren Wang; Alessandro Rinaldo,~Wanshan_Li1; ~Daren_Wang3; ~Alessandro_Rinaldo1,,"{'value': 'We develop a novel, general and computationally efficient framework, called Divide and Conquer Dynamic Programming (DCDP), for localizing change points in time series data with high-dimensional features. DCDP deploys a class of greedy algorithms that are applicable to a broad variety of high-dimensional statistical models and can enjoy almost linear computational complexity. We investigate the performance of DCDP in three commonly studied change point settings in high dimensions: the mean model, the Gaussian graphical model, and the linear regression model. In all three cases, we derive non-asymptotic bounds for the accuracy of the DCDP change point estimators. We demonstrate that the DCDP procedures consistently estimate the change points with sharp, and in some cases, optimal rates while incurring significantly smaller computational costs than the best available algorithms. Our findings are supported by extensive numerical experiments on both synthetic and real data.'}",https://openreview.net{'value': '/pdf/ed4bd3d470cca5736ea5e60ef8e76c99d0638d5c.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=EM1HUyzWV0,{'value': 'Recovering Top-Two Answers and Confusion Probability in Multi-Choice Crowdsourcing'},Hyeonsu Jeong; Hye Won Chung,~Hyeonsu_Jeong1; ~Hye_Won_Chung2,,"{'value': 'Crowdsourcing has emerged as an effective platform for labeling large amounts of data in a cost- and time-efficient manner. Most previous work has focused on designing an efficient algorithm to recover only the ground-truth labels of the data. In this paper, we consider multi-choice crowdsourcing tasks with the goal of recovering not only the ground truth, but also the most confusing answer and the confusion probability. The most confusing answer provides useful information about the task by revealing the most plausible answer other than the ground truth and how plausible it is. To theoretically analyze such scenarios, we propose a model in which there are the top two plausible answers for each task, distinguished from the rest of the choices. Task difficulty is quantified by the probability of confusion between the top two, and worker reliability is quantified by the probability of giving an answer among the top two. Under this model, we propose a two-stage inference algorithm to infer both the top two answers and the confusion probability. We show that our algorithm achieves the minimax optimal convergence rate. We conduct both synthetic and real data experiments and demonstrate that our algorithm outperforms other recent algorithms. We also show the applicability of our algorithms in inferring the difficulty of tasks and in training neural networks with top-two soft labels.'}",https://openreview.net{'value': '/pdf/a84e9fb43891c4d6fb10f9f32bb116256d7807d6.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=DdQTP1yFLQ,{'value': 'Nearly-Optimal Hierarchical Clustering for Well-Clustered Graphs'},Steinar Laenen; Bogdan Adrian Manghiuc; He Sun,~Steinar_Laenen1; ~Bogdan_Adrian_Manghiuc1; ~He_Sun5,,"{'value': ""This paper presents two efficient hierarchical clustering (HC) algorithms with respect to Dasgupta's cost function. For any input graph $G$ with a clear cluster-structure, our designed algorithms run in nearly-linear time in the input size of $G$, and return an $O(1)$-approximate HC tree with respect to Dasgupta's cost function. We compare the performance of our algorithm against the previous state-of-the-art on synthetic and real-world datasets and show that our designed algorithm produces comparable or better HC trees with much lower running time.""}",https://openreview.net{'value': '/pdf/3ed43716c400e01db12cf5d87d563040afad2961.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=DRu5BlRqrn,{'value': 'Lazy Agents: A New Perspective on Solving Sparse Reward Problem in Multi-agent Reinforcement Learning'},Boyin Liu; Zhiqiang Pu; Yi Pan; Jianqiang Yi; Yanyan Liang; Du Zhang,~Boyin_Liu2; ~Zhiqiang_Pu1; ~Yi_Pan4; ~Jianqiang_Yi1; ~Yanyan_Liang1; duzhang@must.edu.mo,,"{'value': 'Sparse reward remains a valuable and challenging problem in multi-agent reinforcement learning (MARL). This paper addresses this issue from a new perspective, i.e., lazy agents. We empirically illustrate how lazy agents damage learning from both exploration and exploitation. Then, we propose a novel MARL framework called Lazy Agents Avoidance through Influencing External States (LAIES). Firstly, we examine the causes and types of lazy agents in MARL using a causal graph of the interaction between agents and their environment. Then, we mathematically define the concept of fully lazy agents and teams by calculating the causal effect of their actions on external states using the do-calculus process. Based on definitions, we provide two intrinsic rewards to motivate agents, i.e., individual diligence intrinsic motivation (IDI) and collaborative diligence intrinsic motivation (CDI). IDI and CDI employ counterfactual reasoning based on the external states transition model (ESTM) we developed. Empirical results demonstrate that our proposed method achieves state-of-the-art performance on various tasks, including the sparse-reward version of StarCraft multi-agent challenge (SMAC) and Google Research Football (GRF). Our code is open-source and available at https://github.com/liuboyin/LAIES.'}",https://openreview.net{'value': '/pdf/e7f077397d14de9a9cc683961e096661928dbf95.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=DGSmVHmOrv,{'value': 'Special Properties of Gradient Descent with Large Learning Rates'},Amirkeivan Mohtashami; Martin Jaggi; Sebastian U Stich,~Amirkeivan_Mohtashami1; ~Martin_Jaggi1; ~Sebastian_U_Stich1,,"{'value': 'When training neural networks, it has been widely observed that a large step size is essential in stochastic gradient descent (SGD) for obtaining superior models. However, the effect of large step sizes on the success of SGD is not well understood theoretically. Several previous works have attributed this success to the stochastic noise present in SGD. However, we show through a novel set of experiments that the stochastic noise is not sufficient to explain good non-convex training, and that instead the effect of a large learning rate itself is essential for obtaining best performance.We demonstrate the same effects also in the noise-less case, i.e. for full-batch GD. We formally prove that GD with large step size ---on certain non-convex function classes --- follows a different trajectory than GD with a small step size, which can lead to convergence to a global minimum instead of a local one. Our settings provide a framework for future analysis which allows comparing algorithms based on behaviors that can not be observed in the traditional settings.'}",https://openreview.net{'value': '/pdf/f34cb65a637b8fb4e1d6b976b867fd75b8b6ea2c.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=ChniRIfpRR,{'value': 'In or Out? Fixing ImageNet Out-of-Distribution Detection Evaluation'},Julian Bitterwolf; Maximilian Müller; Matthias Hein,~Julian_Bitterwolf1; ~Maximilian_Müller1; ~Matthias_Hein2,,"{'value': ""Out-of-distribution (OOD) detection is the problem of identifying inputs which are unrelated to the in-distribution task. The OOD detection performance when the in-distribution (ID) is ImageNet-1K is commonly being tested on a small range of test OOD datasets. We find that most of the currently used test OOD datasets, including datasets from the open set recognition (OSR) literature, have severe issues: In some cases more than 50$\\%$ of the dataset contains objects belonging to one of the ID classes. These erroneous samples heavily distort the evaluation of OOD detectors. As a solution, we introduce with NINCO a novel test OOD dataset, each sample checked to be ID free, which with its fine-grained range of OOD classes allows for a detailed analysis of an OOD detector's strengths and failure modes, particularly when paired with a number of synthetic “OOD unit-tests”. We provide detailed evaluations across a large set of architectures and OOD detection methods on NINCO and the unit-tests, revealing new insights about model weaknesses and the effects of pretraining on OOD detection performance. We provide code and data at https://github.com/j-cb/NINCO.""}",https://openreview.net{'value': '/pdf/71cf7c62728887df456ac8c814eea5234bd2d19a.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=CgB7wCExOF,{'value': 'Transformers as Algorithms: Generalization and Stability in In-context Learning'},Yingcong Li; Muhammed Emrullah Ildiz; Dimitris Papailiopoulos; Samet Oymak,~Yingcong_Li1; mildi001@ucr.edu; ~Dimitris_Papailiopoulos1; ~Samet_Oymak2,,"{'value': 'In-context learning (ICL) is a type of prompting where a transformer model operates on a sequence of (input, output) examples and performs inference on-the-fly. In this work, we formalize in-context learning as an algorithm learning problem where a transformer model implicitly constructs a hypothesis function at inference-time. We first explore the statistical aspects of this abstraction through the lens of multitask learning: We obtain generalization bounds for ICL when the input prompt is (1) a sequence of i.i.d. (input, label) pairs or (2) a trajectory arising from a dynamical system. The crux of our analysis is relating the excess risk to the stability of the algorithm implemented by the transformer. We characterize when transformer/attention architecture provably obeys the stability condition and also provide empirical verification. For generalization on unseen tasks, we identify an inductive bias phenomenon in which the transfer learning risk is governed by the task complexity and the number of MTL tasks in a highly predictable manner. Finally, we provide numerical evaluations that (1) demonstrate transformers can indeed implement near-optimal algorithms on classical regression problems with i.i.d. and dynamic data, (2) provide insights on stability, and (3) verify our theoretical predictions.'}",https://openreview.net{'value': '/pdf/bc5b80bba3992e0a0d658c015dfa7a51778a7d58.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=CPKMwyiyDv,{'value': 'Neural networks trained with SGD learn distributions of increasing complexity'},Maria Refinetti; Alessandro Ingrosso; Sebastian Goldt,~Maria_Refinetti1; ~Alessandro_Ingrosso1; ~Sebastian_Goldt1,,"{'value': 'The uncanny ability of over-parameterised neural networks to generalise well has been explained using various ""simplicity biases"". These theories postulate that neural networks avoid overfitting by first fitting simple, linear classifiers before learning more complex, non-linear functions. Meanwhile, data structure is also recognised as a key ingredient for good generalisation, yet its role in simplicity biases is not yet understood. Here, we show that neural networks trained using stochastic gradient descent initially classify their inputs using lower-order input statistics, like mean and covariance, and exploit higher-order statistics only later during training. We first demonstrate this **distributional simplicity bias** (DSB) in a solvable model of a single neuron trained on synthetic data. We then demonstrate DSB empirically in a range of deep convolutional networks and visual transformers trained on CIFAR10, and show that it even holds in networks pre-trained on ImageNet. We discuss the relation of DSB to other simplicity biases and consider its implications for the principle of Gaussian universality in learning.'}",https://openreview.net{'value': '/pdf/e28616d0d931203554021ce94b0f082e89a181ec.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=BZDqjqbJmg,{'value': 'Iterative Approximate Cross-Validation'},Yuetian Luo; Zhimei Ren; Rina Barber,~Yuetian_Luo2; ~Zhimei_Ren1; ~Rina_Barber1,,"{'value': 'Cross-validation (CV) is one of the most popular tools for assessing and selecting predictive models. However, standard CV suffers from high computational cost when the number of folds is large. Recently, under the empirical risk minimization (ERM) framework, a line of works proposed efficient methods to approximate CV based on the solution of the ERM problem trained on the full dataset. However, in large-scale problems, it can be hard to obtain the exact solution of the ERM problem, either due to limited computational resources or due to early stopping as a way of preventing overfitting. In this paper, we propose a new paradigm to efficiently approximate CV when the ERM problem is solved via an iterative first-order algorithm, without running until convergence. Our new method extends existing guarantees for CV approximation to hold along the whole trajectory of the algorithm, including at convergence, thus generalizing existing CV approximation methods. Finally, we illustrate the accuracy and computational efficiency of our method through a range of empirical studies.'}",https://openreview.net{'value': '/pdf/8c1419707918fa9519f0a41628d4061e5e587dc1.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=BUv0BLrosh,{'value': 'Conformal Prediction with Missing Values'},Margaux Zaffran; Aymeric Dieuleveut; Julie Josse; Yaniv Romano,~Margaux_Zaffran1; ~Aymeric_Dieuleveut1; ~Julie_Josse1; ~Yaniv_Romano1,,"{'value': 'Conformal prediction is a theoretically grounded framework for constructing predictive intervals. We study conformal prediction with missing values in the covariates -- a setting that brings new challenges to uncertainty quantification. We first show that the marginal coverage guarantee of conformal prediction holds on imputed data for any missingness distribution and almost all imputation functions. However, we emphasize that the average coverage varies depending on the pattern of missing values: conformal methods tend to construct prediction intervals that under-cover the response conditionally to some missing patterns. This motivates our novel generalized conformalized quantile regression framework, missing data augmentation, which yields prediction intervals that are valid conditionally to the patterns of missing values, despite their exponential number. We then show that a universally consistent quantile regression algorithm trained on the imputed data is Bayes optimal for the pinball risk, thus achieving valid coverage conditionally to any given data point. Moreover, we examine the case of a linear model, which demonstrates the importance of our proposal in overcoming the heteroskedasticity induced by missing values. Using synthetic and data from critical care, we corroborate our theory and report improved performance of our methods.'}",https://openreview.net{'value': '/pdf/28807c79273e0c06cfd6fd5e69e122e725015723.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=B9R1uLC1B1,{'value': 'Generating Private Synthetic Data with Genetic Algorithms'},Terrance Liu; Jingwu Tang; Giuseppe Vietri; Steven Wu,~Terrance_Liu1; ~Jingwu_Tang1; ~Giuseppe_Vietri1; ~Steven_Wu1,,"{'value': ""We study the problem of efficiently generating differentially private synthetic data that approximate the statistical properties of an underlying sensitive dataset. In recent years, there has been a growing line of work that approaches this problem using first-order optimization techniques. However, such techniques are restricted to optimizing differentiable objectives only, severely limiting the types of analyses that can be conducted. For example, first-order mechanisms have been primarily successful in approximating statistical queries only in the form of marginals for discrete data domains. In some cases, one can circumvent such issues by relaxing the task's objective to maintain differentiability. However, even when possible, these approaches impose a fundamental limitation in which modifications to the minimization problem become additional sources of error. Therefore, we propose Private-GSD, a private genetic algorithm based on *zeroth*-order optimization heuristics that do not require modifying the original objective; thus, it avoids the aforementioned limitations of first-order optimization. We demonstrate empirically that on data with both discrete and real-valued attributes, Private-GSD outperforms the state-of-the-art methods on non-differential queries while matching accuracy in approximating differentiable ones.""}",https://openreview.net{'value': '/pdf/495e0c112b2cf9219eff751d56339e39948dd256.pdf'},{'title_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=AzFq5HxVlg,{'value': 'Best Arm Identification in Multi-Agent Multi-Armed Bandits'},Filippo Vannella; Alexandre Proutiere; Jaeseong Jeong,~Filippo_Vannella1; ~Alexandre_Proutiere1; jaeseong.jeong@ericsson.com,,"{'value': 'We investigate the problem of best arm identification in Multi-Agent Multi-Armed Bandits (MAMABs) where the rewards are defined through a factor graph. The objective is to find an optimal global action with a prescribed level of confidence and minimal sample complexity. We derive a tight instance-specific lower bound of the sample complexity and characterize the corresponding optimal sampling strategy. Unfortunately, this bound is obtained by solving a combinatorial optimization problem with a number of variables and constraints exponentially growing with the number of agents. We leverage Mean Field (MF) techniques to obtain, in a computationally efficient manner, an approximation of the lower bound. The approximation scales at most as $\\rho K^d$ (where $\\rho$, $K$, and $d$ denote the number of factors in the graph, the number of possible actions per agent, and the maximal degree of the factor graph). We devise MF-TaS (Mean-Field-Track-and-Stop), an algorithm whose sample complexity provably matches our approximated lower bound. We illustrate the performance of MF-TaS numerically using both synthetic and real-world experiments (e.g., to solve the antenna tilt optimization problem in radio communication networks).'}",https://openreview.net{'value': '/pdf/d532bc7f8fe76bb1fe71dbd05345f4e3c85d7667.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=AwxfYvdPZV,{'value': 'Policy Mirror Ascent for Efficient and Independent Learning in Mean Field Games'},Batuhan Yardim; Semih Cayci; Matthieu Geist; Niao He,~Batuhan_Yardim1; ~Semih_Cayci1; ~Matthieu_Geist1; ~Niao_He3,,"{'value': ""Mean-field games have been used as a theoretical tool to obtain an approximate Nash equilibrium for symmetric and anonymous $N$-player games. However, limiting applicability, existing theoretical results assume variations of a ``population generative model'', which allows arbitrary modifications of the population distribution by the learning algorithm. Moreover, learning algorithms typically work on abstract simulators with population instead of the $N$-player game. Instead, we show that $N$ agents running policy mirror ascent converge to the Nash equilibrium of the regularized game within $\\widetilde{\\mathcal{O}}(\\varepsilon^{-2})$ samples from a single sample trajectory without a population generative model, up to a standard $\\mathcal{O}(\\frac{1}{\\sqrt{N}})$ error due to the mean field. Taking a divergent approach from the literature, instead of working with the best-response map we first show that a policy mirror ascent map can be used to construct a contractive operator having the Nash equilibrium as its fixed point. We analyze single-path TD learning for $N$-agent games, proving sample complexity guarantees by only using a sample path from the $N$-agent simulator without a population generative model. Furthermore, we demonstrate that our methodology allows for independent learning by $N$ agents with finite sample guarantees.""}",https://openreview.net{'value': '/pdf/d8d5393b3658313bfc0e9ef2ca86e989e33c39be.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=Asrg2we3dP,{'value': 'MABe22: A Multi-Species Multi-Task Benchmark for Learned Representations of Behavior'},Jennifer J. Sun; Markus Marks; Andrew Wesley Ulmer; Dipam Chakraborty; Brian Geuther; Edward Hayes; Heng Jia; Vivek Kumar; Sebastian Oleszko; Zachary Partridge; Milan Peelman; Alice Robie; Catherine E Schretter; Keith Sheppard; Chao Sun; Param Uttarwar; Julian Morgan Wagner; Erik Werner; Joseph Parker; Pietro Perona; Yisong Yue; Kristin Branson; Ann Kennedy,~Jennifer_J._Sun1; ~Markus_Marks1; ~Andrew_Wesley_Ulmer1; ~Dipam_Chakraborty1; ~Brian_Geuther1; ~Edward_Hayes1; ~Heng_Jia1; ~Vivek_Kumar4; ~Sebastian_Oleszko1; ~Zachary_Partridge1; ~Milan_Peelman1; ~Alice_Robie1; ~Catherine_E_Schretter1; ~Keith_Sheppard2; ~Chao_Sun3; ~Param_Uttarwar1; ~Julian_Morgan_Wagner1; ~Erik_Werner1; ~Joseph_Parker1; ~Pietro_Perona1; ~Yisong_Yue1; ~Kristin_Branson1; ~Ann_Kennedy1,,"{'value': 'We introduce MABe22, a large-scale, multi-agent video and trajectory benchmark to assess the quality of learned behavior representations. This dataset is collected from a variety of biology experiments, and includes triplets of interacting mice (4.7 million frames video+pose tracking data, 10 million frames pose only), symbiotic beetle-ant interactions (10 million frames video data), and groups of interacting flies (4.4 million frames of pose tracking data). Accompanying these data, we introduce a panel of real-life downstream analysis tasks to assess the quality of learned representations by evaluating how well they preserve information about the experimental conditions (e.g. strain, time of day, optogenetic stimulation) and animal behavior. We test multiple state-of-the-art self-supervised video and trajectory representation learning methods to demonstrate the use of our benchmark, revealing that methods developed using human action datasets do not fully translate to animal datasets. We hope that our benchmark and dataset encourage a broader exploration of behavior representation learning methods across species and settings.'}",https://openreview.net{'value': '/pdf/54b15ea0e20e60fb121c5eca6baeb5ae0a88143a.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=9xqrSeujqc,"{'value': 'Extending Kernel PCA through Dualization: Sparsity, Robustness and Fast Algorithms'}",Francesco Tonin; Alex Lambert; Panagiotis Patrinos; Johan Suykens,~Francesco_Tonin1; ~Alex_Lambert1; ~Panagiotis_Patrinos1; ~Johan_Suykens1,,"{'value': 'The goal of this paper is to revisit Kernel Principal Component Analysis (KPCA) through dualization of a difference of convex functions. This allows to naturally extend KPCA to multiple objective functions and leads to efficient gradient-based algorithms avoiding the expensive SVD of the Gram matrix. Particularly, we consider objective functions that can be written as Moreau envelopes, demonstrating how to promote robustness and sparsity within the same framework. The proposed method is evaluated on synthetic and realworld benchmarks, showing significant speedup in KPCA training time as well as highlighting the benefits in terms of robustness and sparsity.'}",https://openreview.net{'value': '/pdf/de7ca91419a0f158e682d672c53f6282bef6860c.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=9iNScYEBWZ,{'value': 'Improving Adversarial Robustness Through the Contrastive-Guided Diffusion Process'},Yidong Ouyang; Liyan Xie; Guang Cheng,~Yidong_Ouyang1; ~Liyan_Xie2; ~Guang_Cheng1,,"{'value': 'Synthetic data generation has become an emerging tool to help improve the adversarial robustness in classification tasks, since robust learning requires a significantly larger amount of training samples compared with standard classification. Among various deep generative models, the diffusion model has been shown to produce high-quality synthetic images and has achieved good performance in improving the adversarial robustness. However, diffusion-type methods are generally slower in data generation as compared with other generative models. Although different acceleration techniques have been proposed recently, it is also of great importance to study how to improve the sample efficiency of synthetic data for the downstream task. In this paper, we first analyze the optimality condition of synthetic distribution for achieving improved robust accuracy. We show that enhancing the distinguishability among the generated data is critical for improving adversarial robustness. Thus, we propose the Contrastive-Guided Diffusion Process (Contrastive-DP), which incorporates the contrastive loss to guide the diffusion model in data generation. We validate our theoretical results using simulations and demonstrate the good performance of Contrastive-DP on image datasets.'}",https://openreview.net{'value': '/pdf/061227d2e1340c6147c942cce8f8f767ffcf515c.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=9WJsVG58YO,{'value': 'Improving Graph Generation by Restricting Graph Bandwidth'},Nathaniel Lee Diamant; Alex Tseng; Kangway V Chuang; Tommaso Biancalani; Gabriele Scalia,~Nathaniel_Lee_Diamant1; ~Alex_Tseng1; ~Kangway_V_Chuang1; ~Tommaso_Biancalani1; ~Gabriele_Scalia1,,"{'value': 'Deep graph generative modeling has proven capable of learning the distribution of complex, multi-scale structures characterizing real-world graphs. However, one of the main limitations of existing methods is their large output space, which limits generation scalability and hinders accurate modeling of the underlying distribution. To overcome these limitations, we propose a novel approach that significantly reduces the output space of existing graph generative models. Specifically, starting from the observation that many real-world graphs have low graph bandwidth, we restrict graph bandwidth during training and generation. Our strategy improves both generation scalability and quality without increasing architectural complexity or reducing expressiveness. Our approach is compatible with existing graph generative methods, and we describe its application to both autoregressive and one-shot models. We extensively validate our strategy on synthetic and real datasets, including molecular graphs. Our experiments show that, in addition to improving generation efficiency, our approach consistently improves generation quality and reconstruction accuracy. The implementation is made available.'}",https://openreview.net{'value': '/pdf/324f2238d659c77c487250f363ee63ef337d34a7.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=9UCTB84L6e,"{'value': 'Same Pre-training Loss, Better Downstream: Implicit Bias Matters for Language Models'}",Hong Liu; Sang Michael Xie; Zhiyuan Li; Tengyu Ma,~Hong_Liu5; ~Sang_Michael_Xie1; ~Zhiyuan_Li2; ~Tengyu_Ma1,,"{'value': 'Language modeling on large-scale datasets improves performance of various downstream tasks. The validation pre-training loss is often used as the evaluation metric for language models since the pre-training loss tends to be well-correlated with downstream performance (which is itself hard to evaluate comprehensively). Contrary to the conventional wisdom, this paper shows that 1) pre-training loss cannot fully explain downstream performance and 2) flatness of the model is well-correlated with downstream performance where pre-training loss is not. We identify three ways to produce models with the same pre-training loss but different downstream performance: continue pre-training after convergence, increasing the model size, and changing the pre-training algorithms. These experiments demonstrate the existence of implicit bias of pre-training algorithms---among models with the same minimal pre-training loss, they implicitly prefer more transferable ones. Toward understanding this implicit bias, we prove that SGD with standard mini-batch noise implicitly prefers flatter minima of pre-training loss in language models, and empirically observe a strong correlation between flatness (measured by the trace of Hessian) and downstream performance among models with the same pre-training loss. We also prove in a synthetic language setting that among models with the minimal pre-training loss, the flattest model transfers to downstream tasks.'}",https://openreview.net{'value': '/pdf/6d9b4d4d83f765a05ac05914f9857a4abdbd7ba5.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=8Lww9LXokZ,{'value': 'Trajectory-Aware Eligibility Traces for Off-Policy Reinforcement Learning'},Brett Daley; Martha White; Christopher Amato; Marlos C. Machado,~Brett_Daley1; ~Martha_White1; ~Christopher_Amato1; ~Marlos_C._Machado1,,"{'value': 'Off-policy learning from multistep returns is crucial for sample-efficient reinforcement learning, but counteracting off-policy bias without exacerbating variance is challenging. Classically, off-policy bias is corrected in a per-decision manner: past temporal-difference errors are re-weighted by the instantaneous Importance Sampling (IS) ratio after each action via eligibility traces. Many off-policy algorithms rely on this mechanism, along with differing protocols for cutting the IS ratios (traces) to combat the variance of the IS estimator. Unfortunately, once a trace has been cut, the effect cannot be easily reversed. This has led to the development of credit-assignment strategies that account for multiple past experiences at a time. These trajectory-aware methods have not been extensively analyzed, and their theoretical justification remains uncertain. In this paper, we propose a multistep operator that unifies per-decision and trajectory-aware methods. We prove convergence conditions for our operator in the tabular setting, establishing the first guarantees for several existing methods as well as many new ones. Finally, we introduce Recency-Bounded Importance Sampling (RBIS), which leverages trajectory awareness to perform robustly across $\\lambda$-values in an off-policy control task.'}",https://openreview.net{'value': '/pdf/7f409a24c0de00067975ca050a5426209e6a0172.pdf'},{'title_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=8Ln8Ai9kq1,{'value': 'Semi-Supervised Offline Reinforcement Learning with Action-Free Trajectories'},Qinqing Zheng; Mikael Henaff; Brandon Amos; Aditya Grover,~Qinqing_Zheng1; ~Mikael_Henaff1; ~Brandon_Amos1; ~Aditya_Grover1,,"{'value': 'Natural agents can effectively learn from multiple data sources that differ in size, quality, and types of measurements. We study this heterogeneity in the context of offline reinforcement learning (RL) by introducing a new, practically motivated semi-supervised setting. Here, an agent has access to two sets of trajectories: labelled trajectories containing state, action and reward triplets at every timestep, along with unlabelled trajectories that contain only state and reward information. For this setting, we develop and study a simple meta-algorithmic pipeline that learns an inverse dynamics model on the labelled data to obtain proxy-labels for the unlabelled data, followed by the use of any offline RL algorithm on the true and proxy-labelled trajectories. Empirically, we find this simple pipeline to be highly successful --- on several D4RL benchmarks (Fu et al., 2020), certain offline RL algorithms can match the performance of variants trained on a fully labelled dataset even when we label only 10% of trajectories which are highly suboptimal. To strengthen our understanding, we perform a large-scale controlled empirical study investigating the interplay of data-centric properties of the labelled and unlabelled datasets, with algorithmic design choices (e.g., choice of inverse dynamics, offline RL algorithm) to identify general trends and best practices for training RL agents on semi-supervised offline datasets.'}",https://openreview.net{'value': '/pdf/734a0d93f0a5c9997fdb6aeb06bed843264b1fa7.pdf'},{'title_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=8LdBTjylEw,{'value': 'A Kernelized Stein Discrepancy for Biological Sequences'},Alan Nawzad Amin; Eli N Weinstein; Debora Susan Marks,~Alan_Nawzad_Amin1; ~Eli_N_Weinstein1; ~Debora_Susan_Marks1,,"{'value': ""Generative models of biological sequences are a powerful tool for learning from complex sequence data, predicting the effects of mutations, and designing novel biomolecules with desired properties. To evaluate generative models it is important to accurately measure differences between high-dimensional distributions. In this paper we propose the ``KSD-B'', a novel divergence measure for distributions over biological sequences that is based on the kernelized Stein discrepancy (KSD). The KSD-B can be evaluated even when the normalizing constant of the model is unknown; it allows for variable length sequences and can take into account biological notions of sequence distance. Unlike previous KSDs over discrete spaces the KSD-B (a) is theoretically guaranteed to detect convergence and non-convergence of distributions over sequence space and (b) can be efficiently estimated in practice. We demonstrate the advantages of the KSD-B on problems with synthetic and real data, and apply it to measure the fit of state-of-the-art machine learning models. Overall, the KSD-B enables rigorous evaluation of generative biological sequence models, allowing the accuracy of models, sampling procedures, and library designs to be checked reliably.""}",https://openreview.net{'value': '/pdf/5d1d725dd17f760baff5ae5c9b56919c39231406.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=8D3SsQlRbY,{'value': 'The Value of Out-of-Distribution Data'},Ashwin De Silva; Rahul Ramesh; Carey Priebe; Pratik Chaudhari; Joshua T Vogelstein,~Ashwin_De_Silva1; ~Rahul_Ramesh2; ~Carey_Priebe1; ~Pratik_Chaudhari1; ~Joshua_T_Vogelstein1,,"{'value': ""Generalization error always improves with more in-distribution data. However, it is an open question what happens as we add out-of-distribution (OOD) data. Intuitively, if the OOD data is quite different, it seems more data would harm generalization error, though if the OOD data are sufficiently similar, much empirical evidence suggests that OOD data can actually improve generalization error. We show a counter-intuitive phenomenon: the generalization error of a task can be a non-monotonic function of the amount of OOD data. Specifically, we prove that generalization error can improve with small amounts of OOD data, and then get worse than no OOD data with larger amounts. In other words, there is value in training on small amounts of OOD data. We analytically demonstrate these results via Fisher's Linear Discriminant on synthetic datasets, and empirically demonstrate them via deep networks on computer vision benchmarks such as MNIST, CIFAR-10, CINIC-10, PACS and DomainNet. In the idealistic setting where we know which samples are OOD, we show that these non-monotonic trends can be exploited using an appropriately weighted objective of the target and OOD empirical risk. While its practical utility is limited, this does suggest that if we can detect OOD samples, then there may be ways to benefit from them. When we do not know which samples are OOD, we show how a number of go-to strategies such as data-augmentation, hyper-parameter optimization and pre-training are not enough to ensure that the target generalization error does not deteriorate with the number of OOD samples in the dataset.""}",https://openreview.net{'value': '/pdf/9f364acc3abf64a468727d4cc0af5bb349c3e1f7.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=7p7YakZP2H,{'value': 'Curious Replay for Model-based Adaptation'},Isaac Kauvar; Chris Doyle; Linqi Zhou; Nick Haber,~Isaac_Kauvar1; crd@stanford.edu; ~Linqi_Zhou1; ~Nick_Haber1,,"{'value': 'Agents must be able to adapt quickly as an environment changes. We find that existing model-based reinforcement learning agents are unable to do this well, in part because of how they use past experiences to train their world model. Here, we present Curious Replay---a form of prioritized experience replay tailored to model-based agents through use of a curiosity-based priority signal. Agents using Curious Replay exhibit improved performance in an exploration paradigm inspired by animal behavior and on the Crafter benchmark. DreamerV3 with Curious Replay surpasses state-of-the-art performance on Crafter, achieving a mean score of 19.4 that substantially improves on the previous high score of 14.5 by DreamerV3 with uniform replay, while also maintaining similar performance on the Deepmind Control Suite. Code for Curious Replay is available at github.com/AutonomousAgentsLab/curiousreplay.'}",https://openreview.net{'value': '/pdf/ceabed26d13f9ce9bd1890637f89195b7c58d5e7.pdf'},{'abstract_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=7maTHA7zua,{'value': 'Future-conditioned Unsupervised Pretraining for Decision Transformer'},Zhihui Xie; Zichuan Lin; Deheng Ye; QIANG FU; Yang Wei; Shuai Li,~Zhihui_Xie2; ~Zichuan_Lin2; ~Deheng_Ye1; ~QIANG_FU8; ~Yang_Wei2; ~Shuai_Li3,,"{'value': ""Recent research in offline reinforcement learning (RL) has demonstrated that return-conditioned supervised learning is a powerful paradigm for decision-making problems. While promising, return conditioning is limited to training data labeled with rewards and therefore faces challenges in learning from unsupervised data. In this work, we aim to utilize generalized future conditioning to enable efficient unsupervised pretraining from reward-free and sub-optimal offline data. We propose Pretrained Decision Transformer (PDT), a conceptually simple approach for unsupervised RL pretraining. PDT leverages future trajectory information as a privileged context to predict actions during training. The ability to make decisions based on both present and future factors enhances PDT's capability for generalization. Besides, this feature can be easily incorporated into a return-conditioned framework for online finetuning, by assigning return values to possible futures and sampling future embeddings based on their respective values. Empirically, PDT outperforms or performs on par with its supervised pretraining counterpart, especially when dealing with sub-optimal data. Further analysis reveals that PDT can extract diverse behaviors from offline data and controllably sample high-return behaviors by online finetuning. Code is available at here.""}",https://openreview.net{'value': '/pdf/ed8eaa1c8cb26ea8494b533f5a7a29792a88094f.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=7GD5BMI3km,{'value': 'Learning Neural Constitutive Laws from Motion Observations for Generalizable PDE Dynamics'},Pingchuan Ma; Peter Yichen Chen; Bolei Deng; Joshua B. Tenenbaum; Tao Du; Chuang Gan; Wojciech Matusik,~Pingchuan_Ma3; ~Peter_Yichen_Chen1; ~Bolei_Deng1; ~Joshua_B._Tenenbaum1; ~Tao_Du1; ~Chuang_Gan1; ~Wojciech_Matusik2,,"{'value': 'We propose a hybrid neural network (NN) and PDE approach for learning generalizable PDE dynamics from motion observations. Many NN approaches learn an end-to-end model that implicitly models both the governing PDE and constitutive models (or material models). Without explicit PDE knowledge, these approaches cannot guarantee physical correctness and have limited generalizability. We argue that the governing PDEs are often well-known and should be explicitly enforced rather than learned. Instead, constitutive models are particularly suitable for learning due to their data-fitting nature. To this end, we introduce a new framework termed ""Neural Constitutive Laws"" (NCLaw), which utilizes a network architecture that strictly guarantees standard constitutive priors, including rotation equivariance and undeformed state equilibrium. We embed this network inside a differentiable simulation and train the model by minimizing a loss function based on the difference between the simulation and the motion observation. We validate NCLaw on various large-deformation dynamical systems, ranging from solids to fluids. After training on a single motion trajectory, our method generalizes to new geometries, initial/boundary conditions, temporal ranges, and even multi-physics systems. On these extremely out-of-distribution generalization tasks, NCLaw is orders-of-magnitude more accurate than previous NN approaches. Real-world experiments demonstrate our method\'s ability to learn constitutive laws from videos.'}",https://openreview.net{'value': '/pdf/f4dc943300fd0603ef68f1c93a97a91622d29d53.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=79icaL3Wan,{'value': 'SOM-CPC: Unsupervised Contrastive Learning with Self-Organizing Maps for Structured Representations of High-Rate Time Series'},Iris A.M. Huijben; Arthur Andreas Nijdam; Sebastiaan Overeem; Merel M Van Gilst; Ruud Van Sloun,~Iris_A.M._Huijben1; ~Arthur_Andreas_Nijdam1; ~Sebastiaan_Overeem1; ~Merel_M_Van_Gilst1; ~Ruud_Van_Sloun1,,"{'value': 'Continuous monitoring with an ever-increasing number of sensors has become ubiquitous across many application domains. However, acquired time series are typically high-dimensional and difficult to interpret. Expressive deep learning (DL) models have gained popularity for dimensionality reduction, but the resulting latent space often remains difficult to interpret. In this work we propose SOM-CPC, a model that visualizes data in an organized 2D manifold, while preserving higher-dimensional information. We address a largely unexplored and challenging set of scenarios comprising high-rate time series, and show on both synthetic and real-life data (physiological data and audio recordings) that SOM-CPC outperforms strong baselines like DL-based feature extraction, followed by conventional dimensionality reduction techniques, and models that jointly optimize a DL model and a Self-Organizing Map (SOM). SOM-CPC has great potential to acquire a better understanding of latent patterns in high-rate data streams.'}",https://openreview.net{'value': '/pdf/d78d856d17cdc5ac611cae6b94fade41e7aa2403.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=6vVkGnEpP7,{'value': 'Distilling Internet-Scale Vision-Language Models into Embodied Agents'},Theodore Sumers; Kenneth Marino; Arun Ahuja; Rob Fergus; Ishita Dasgupta,~Theodore_Sumers1; ~Kenneth_Marino1; ~Arun_Ahuja1; ~Rob_Fergus1; ~Ishita_Dasgupta1,,"{'value': ""Instruction-following agents must ground language into their observation and action spaces. Learning to ground language is challenging, typically requiring domain-specific engineering or large quantities of human interaction data. To address this challenge, we propose using pretrained vision-language models (VLMs) to supervise embodied agents. We combine ideas from model distillation and hindsight experience replay (HER), using a VLM to retroactively generate language describing the agent's behavior. Simple prompting allows us to control the supervision signal, teaching an agent to interact with novel objects based on their names (e.g., planes) or their features (e.g., colors) in a 3D rendered environment. Fewshot prompting lets us teach abstract category membership, including pre-existing categories (food vs toys) and ad-hoc ones (arbitrary preferences over objects). Our work outlines a new and effective way to use internet-scale VLMs, repurposing the generic language grounding acquired by such models to teach task-relevant groundings to embodied agents.""}",https://openreview.net{'value': '/pdf/9a03afb416c242a16a45572b8a0f032865c5c37e.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=6rlGbYv4bT,{'value': 'Weighted Flow Diffusion for Local Graph Clustering with Node Attributes: an Algorithm and Statistical Guarantees'},Shenghao Yang; Kimon Fountoulakis,~Shenghao_Yang1; ~Kimon_Fountoulakis1,,"{'value': 'Local graph clustering methods aim to detect small clusters in very large graphs without the need to process the whole graph. They are fundamental and scalable tools for a wide range of tasks such as local community detection, node ranking and node embedding. While prior work on local graph clustering mainly focuses on graphs without node attributes, modern real-world graph datasets typically come with node attributes that provide valuable additional information. We present a simple local graph clustering algorithm for graphs with node attributes, based on the idea of diffusing mass locally in the graph while accounting for both structural and attribute proximities. Using high-dimensional concentration results, we provide statistical guarantees on the performance of the algorithm for the recovery of a target cluster with a single seed node. We give conditions under which a target cluster generated from a fairly general contextual random graph model, which includes both the stochastic block model and the planted cluster model as special cases, can be fully recovered with bounded false positives. Empirically, we validate all theoretical claims using synthetic data, and we show that incorporating node attributes leads to superior local clustering performances using real-world graph datasets.'}",https://openreview.net{'value': '/pdf/d6407e5af5b22fd94410bfec07818799d4b1f6f1.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=6bBla9LAJ2,{'value': 'Generative Adversarial Symmetry Discovery'},Jianke Yang; Robin Walters; Nima Dehmamy; Rose Yu,~Jianke_Yang2; ~Robin_Walters1; ~Nima_Dehmamy1; ~Rose_Yu1,,"{'value': 'Despite the success of equivariant neural networks in scientific applications, they require knowing the symmetry group a priori. However, it may be difficult to know which symmetry to use as an inductive bias in practice. Enforcing the wrong symmetry could even hurt the performance. In this paper, we propose a framework, LieGAN, to *automatically discover equivariances* from a dataset using a paradigm akin to generative adversarial training. Specifically, a generator learns a group of transformations applied to the data, which preserve the original distribution and fool the discriminator. LieGAN represents symmetry as interpretable Lie algebra basis and can discover various symmetries such as the rotation group $\\mathrm{SO}(n)$, restricted Lorentz group $\\mathrm{SO}(1,3)^+$ in trajectory prediction and top-quark tagging tasks. The learned symmetry can also be readily used in several existing equivariant neural networks to improve accuracy and generalization in prediction.'}",https://openreview.net{'value': '/pdf/bf47f67833c1b4fc4d3b518a4637436093a28f91.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=6aB43K50T0,{'value': 'Learning Regions of Interest for Bayesian Optimization with Adaptive Level-Set Estimation'},Fengxue Zhang; Jialin Song; James C Bowden; Alexander Ladd; Yisong Yue; Thomas Desautels; Yuxin Chen,~Fengxue_Zhang1; ~Jialin_Song1; ~James_C_Bowden1; ~Alexander_Ladd1; ~Yisong_Yue1; ~Thomas_Desautels1; ~Yuxin_Chen1,,"{'value': 'We study Bayesian optimization (BO) in high-dimensional and non-stationary scenarios. Existing algorithms for such scenarios typically require extensive hyperparameter tuning, which limits their practical effectiveness. We propose a framework, called BALLET, which adaptively filters for a high-confidence region of interest (ROI) as a superlevel-set of a nonparametric probabilistic model such as a Gaussian process (GP). Our approach is easy to tune, and is able to focus on local region of the optimization space that can be tackled by existing BO methods. The key idea is to use two probabilistic models: a coarse GP to identify the ROI, and a localized GP for optimization within the ROI. We show theoretically that BALLET can efficiently shrink the search space, and can exhibit a tighter regret bound than standard BO without ROI filtering. We demonstrate empirically the effectiveness of BALLET on both synthetic and real-world optimization tasks.'}",https://openreview.net{'value': '/pdf/a86603a7610661526b950e51a8cfe9b5aaf3256f.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=6LZNpFqDHB,{'value': 'Speed-Oblivious Online Scheduling: Knowing (Precise) Speeds is not Necessary'},Alexander Lindermayr; Nicole Megow; Martin Rapp,~Alexander_Lindermayr1; ~Nicole_Megow1; ~Martin_Rapp1,,"{'value': 'We consider online scheduling on unrelated (heterogeneous) machines in a speed-oblivious setting, where an algorithm is unaware of the exact job-dependent processing speeds. We show strong impossibility results for clairvoyant and non-clairvoyant algorithms and overcome them in models inspired by practical settings: (i) we provide competitive learning-augmented algorithms, assuming that (possibly erroneous) predictions on the speeds are given, and (ii) we provide competitive algorithms for the speed-ordered model, where a single global order of machines according to their unknown job-dependent speeds is known. We prove strong theoretical guarantees and evaluate our findings on a representative heterogeneous multi-core processor. These seem to be the first empirical results for scheduling algorithms with predictions that are evaluated in a non-synthetic hardware environment.'}",https://openreview.net{'value': '/pdf/706d5a35678e2576918ebefed04c6dadfcf92dd1.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=6LJvlAiD9z,{'value': 'ConCerNet: A Contrastive Learning Based Framework for Automated Conservation Law Discovery and Trustworthy Dynamical System Prediction'},Wang Zhang; Tsui-Wei Weng; Subhro Das; Alexandre Megretski; Luca Daniel; Lam M. Nguyen,~Wang_Zhang2; ~Tsui-Wei_Weng1; ~Subhro_Das1; ~Alexandre_Megretski1; ~Luca_Daniel1; ~Lam_M._Nguyen1,,"{'value': 'Deep neural networks (DNN) have shown great capacity of modeling a dynamical system; nevertheless, they usually do not obey physics constraints such as conservation laws. This paper proposes a new learning framework named $\\textbf{ConCerNet}$ to improve the trustworthiness of the DNN based dynamics modeling to endow the invariant properties. $\\textbf{ConCerNet}$ consists of two steps: (i) a contrastive learning method to automatically capture the system invariants (i.e. conservation properties) along the trajectory observations; (ii) a neural projection layer to guarantee that the learned dynamics models preserve the learned invariants. We theoretically prove the functional relationship between the learned latent representation and the unknown system invariant function. Experiments show that our method consistently outperforms the baseline neural networks in both coordinate error and conservation metrics by a large margin. With neural network based parameterization and no dependence on prior knowledge, our method can be extended to complex and large-scale dynamics by leveraging an autoencoder.'}",https://openreview.net{'value': '/pdf/1d6586135d4a2e288ab135d8f4f24ac0ccb5826d.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=6Ed3gchl9L,{'value': 'On the Expressive Power of Geometric Graph Neural Networks'},Chaitanya K. Joshi; Cristian Bodnar; Simon V Mathis; Taco Cohen; Pietro Lio,~Chaitanya_K._Joshi1; ~Cristian_Bodnar1; ~Simon_V_Mathis1; ~Taco_Cohen1; ~Pietro_Lio1,,"{'value': ""The expressive power of Graph Neural Networks (GNNs) has been studied extensively through the Weisfeiler-Leman (WL) graph isomorphism test. However, standard GNNs and the WL framework are inapplicable for geometric graphs embedded in Euclidean space, such as biomolecules, materials, and other physical systems. In this work, we propose a geometric version of the WL test (GWL) for discriminating geometric graphs while respecting the underlying physical symmetries: permutations, rotation, reflection, and translation. We use GWL to characterise the expressive power of geometric GNNs that are invariant or equivariant to physical symmetries in terms of distinguishing geometric graphs. GWL unpacks how key design choices influence geometric GNN expressivity: (1) Invariant layers have limited expressivity as they cannot distinguish one-hop identical geometric graphs; (2) Equivariant layers distinguish a larger class of graphs by propagating geometric information beyond local neighbourhoods; (3) Higher order tensors and scalarisation enable maximally powerful geometric GNNs; and (4) GWL's discrimination-based perspective is equivalent to universal approximation. Synthetic experiments supplementing our results are available at https://github.com/chaitjo/geometric-gnn-dojo""}",https://openreview.net{'value': '/pdf/d860f5be65d9368dc088a4c8eac4b94b37fc28a3.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=68wSAeijsB,{'value': 'Instrumental Variable Estimation of Average Partial Causal Effects'},Yuta Kawakami; manabu kuroki; Jin Tian,~Yuta_Kawakami1; ~manabu_kuroki1; ~Jin_Tian1,,"{'value': 'Instrumental variable (IV) analysis is a powerful tool widely used to elucidate causal relationships. We study the problem of estimating the average partial causal effect (APCE) of a continuous treatment in an IV setting. Specifically, we develop new methods for estimating APCE based on a recent identification condition via an integral equation. We develop two families of methods, nonparametric and parametric - the former uses the Picard iteration to solve the integral equation; the latter parameterizes APCE using a linear basis function model. We analyze the statistical and computational properties of the proposed methods and illustrate them on synthetic and real data.'}",https://openreview.net{'value': '/pdf/57fe1f7109665aabc513cdd5a6a98b6666c31df7.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=63rNiH4mgG,{'value': 'On the Convergence of Gradient Flow on Multi-layer Linear Models'},Hancheng Min; Rene Vidal; Enrique Mallada,~Hancheng_Min1; ~Rene_Vidal1; ~Enrique_Mallada1,,"{'value': 'In this paper, we analyze the convergence of gradient flow on a multi-layer linear model with a loss function of the form $f(W_1W_2\\cdots W_L)$. We show that when $f$ satisfies the gradient dominance property, proper weight initialization leads to exponential convergence of the gradient flow to a global minimum of the loss. Moreover, the convergence rate depends on two trajectory-specific quantities that are controlled by the weight initialization: the *imbalance matrices*, which measure the difference between the weights of adjacent layers, and the least singular value of the *weight product* $W=W_1W_2\\cdots W_L$. Our analysis exploits the fact that the gradient of the overparameterized loss can be written as the composition of the non-overparametrized gradient with a time-varying (weight-dependent) linear operator whose smallest eigenvalue controls the convergence rate. The key challenge we address is to derive a uniform lower bound for this time-varying eigenvalue that lead to improved rates for several multi-layer network models studied in the literature.'}",https://openreview.net{'value': '/pdf/63dd4457fbcf9d89eba5872332f971bb2f8b859f.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=631FTQB0UB,{'value': 'The Power of Learned Locally Linear Models for Nonlinear Policy Optimization'},Daniel Pfrommer; Max Simchowitz; Tyler Westenbroek; Nikolai Matni; Stephen Tu,~Daniel_Pfrommer1; ~Max_Simchowitz1; ~Tyler_Westenbroek1; ~Nikolai_Matni2; ~Stephen_Tu1,,"{'value': 'A common pipeline in learning-based control is to iteratively estimate a model of system dynamics, and apply a trajectory optimization algorithm - e.g. $\\mathtt{iLQR}$ - on the learned model to minimize a target cost. This paper conducts a rigorous analysis of a simplified variant of this strategy for general nonlinear systems. We analyze an algorithm which iterates between estimating local linear models of nonlinear system dynamics and performing $\\mathtt{iLQR}$-like policy updates. We demonstrate that this algorithm attains sample complexity polynomial in relevant problem parameters, and, by synthesizing locally stabilizing gains, overcomes exponential dependence in problem horizon. Experimental results validate the performance of our algorithm, and compare to natural deep-learning baselines.'}",https://openreview.net{'value': '/pdf/1aff4ef954acf407e5b14e93c56da31fb4babb02.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=5YAP9Ntq3L,{'value': 'SAM operates far from home: eigenvalue regularization as a dynamical phenomenon'},Atish Agarwala; Yann Dauphin,~Atish_Agarwala1; ~Yann_Dauphin1,,"{'value': 'The Sharpness Aware Minimization (SAM) optimization algorithm has been shown to control large eigenvalues of the loss Hessian and provide generalization benefits in a variety of settings. The original motivation for SAM was a modified loss function which penalized sharp minima; subsequent analyses have also focused on the behavior near minima. However, our work reveals that SAM provides a strong regularization of the eigenvalues throughout the learning trajectory. We show that in a simplified setting, SAM dynamically induces a stabilization related to the edge of stability (EOS) phenomenon observed in large learning rate gradient descent. Our theory predicts the largest eigenvalue as a function of the learning rate and SAM radius parameters. Finally, we show that practical models can also exhibit this EOS stabilization, and that understanding SAM must account for these dynamics far away from any minima.'}",https://openreview.net{'value': '/pdf/30fe391ef408dc4d65d18705130a6896324631d8.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=5Akrk9Ln6N,{'value': 'Reparameterized Policy Learning for Multimodal Trajectory Optimization'},Zhiao Huang; Litian Liang; Zhan Ling; Xuanlin Li; Chuang Gan; Hao Su,~Zhiao_Huang1; ~Litian_Liang1; ~Zhan_Ling2; ~Xuanlin_Li1; ~Chuang_Gan1; ~Hao_Su1,,"{'value': 'We investigate the challenge of parametrizing policies for reinforcement learning (RL) in high-dimensional continuous action spaces. Our objective is to develop a multimodal policy that overcomes limitations inherent in the commonly-used Gaussian parameterization. To achieve this, we propose a principled framework that models the continuous RL policy as a generative model of optimal trajectories. By conditioning the policy on a latent variable, we derive a novel variational bound as the optimization objective, which promotes exploration of the environment. We then present a practical model-based RL method, called Reparameterized Policy Gradient (RPG), which leverages the multimodal policy parameterization and learned world model to achieve strong exploration capabilities and high data efficiency. Empirical results demonstrate that our method can help agents evade local optima in tasks with dense rewards and solve challenging sparse-reward environments by incorporating an object-centric intrinsic reward. Our method consistently outperforms previous approaches across a range of tasks. Code and supplementary materials are available on the project page https://haosulab.github.io/RPG/'}",https://openreview.net{'value': '/pdf/01ca6c794fb3c60cec707bca29c019b57bfaadde.pdf'},{'title_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=55kLa7tH9o,{'value': 'Hierarchical Diffusion for Offline Decision Making'},Wenhao Li; Xiangfeng Wang; Bo Jin; Hongyuan Zha,~Wenhao_Li2; ~Xiangfeng_Wang1; ~Bo_Jin1; ~Hongyuan_Zha1,,"{'value': 'Offline reinforcement learning typically introduces a hierarchical structure to solve the long-horizon problem so as to address its thorny issue of variance accumulation. Problems of deadly triad, limited data and reward sparsity, however, still remain, rendering the design of effective, hierarchical offline RL algorithms for general-purpose policy learning a formidable challenge. In this paper, we first formulate the problem of offline long-horizon decision-$\\mathbf{M}$ak$\\mathbf{I}$ng from the perspective of conditional generative modeling by incorporating goals into the control-as-inference graphic models. A $\\mathbf{H}$ierarchical trajectory-level $\\mathbf{D}$iffusion probabilistic model is then proposed with classifier-free guidance. HDMI employs a cascade framework that utilizes the reward-conditional goal diffuser for the subgoal discovery and the goal-conditional trajectory diffuser for generating the corresponding action sequence of subgoals. Planning-based subgoal extraction and transformer-based diffusion are employed to deal with the sub-optimal data pollution and long-range subgoal dependencies in the goal diffusion. Numerical experiments verify the advantages of HDMI on long-horizon decision-making compared to SOTA offline RL methods and conditional generative models.'}",https://openreview.net{'value': '/pdf/d443ae50559128b8c714fd72bb753a687caa6e5e.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=4k8cvbQJh8,{'value': 'Deep Graph Representation Learning and Optimization for Influence Maximization'},Chen Ling; Junji Jiang; Junxiang Wang; My Thai; Lukas Xue; James Song; Meikang Qiu; Liang Zhao,~Chen_Ling3; ~Junji_Jiang1; ~Junxiang_Wang1; ~My_Thai1; lukas.xue@emory.edu; james.song2@emory.edu; qiumeikang@yahoo.com; ~Liang_Zhao6,,"{'value': 'Influence maximization (IM) is formulated as selecting a set of initial users from a social network to maximize the expected number of influenced users. Researchers have made great progresses to design various traditional methods, yet both theoretical design and performance gain are close to their limits. In the past few years, learning-based IM methods have emerged to achieve stronger generalization ability to unknown graphs than traditional ones. However, the development of learning-based IM methods is still limited by fundamental obstacles, including 1) the difficulty of effectively solving the objective function; 2) the difficulty of characterizing the diversified and underlying diffusion patterns; and 3) the difficulty of adapting the solution under various node-centrality-constrained IM variants. To cope with the above challenges, we design a novel framework DeepIM to generatively characterize the latent representation of seed sets, and we propose to learn the diversified information diffusion pattern in a data-driven and end-to-end manner. Finally, we design a novel objective function to infer optimal seed sets under flexible node-centrality-based budget constraints. Extensive analyses are conducted over both synthetic and real-world datasets to demonstrate the overall performance of DeepIM.'}",https://openreview.net{'value': '/pdf/486977c60e4a9282d2b901b5dd24f885c65c60de.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=4EINAXMptc,{'value': 'Emergent Agentic Transformer from Chain of Hindsight Experience'},Hao Liu; Pieter Abbeel,~Hao_Liu1; ~Pieter_Abbeel2,,"{'value': 'Large transformer models powered by diverse data and model scale have dominated natural language modeling and computer vision and pushed the frontier of multiple AI areas. In reinforcement learning (RL), despite many efforts into transformer-based policies, a key limitation, however, is that current transformer-based policies cannot learn by directly combining information from multiple sub-optimal trials. In this work, we address this issue using recently proposed chain of hindsight to relabel experience, where we train a transformer on a sequence of trajectory experience ascending sorted according to their total rewards. Our method consists of relabelling target return of each trajectory to the maximum total reward among in sequence of trajectories and training an autoregressive model to predict actions conditioning on past states, actions, rewards, target returns, and task completion tokens, the resulting model, Agentic Transformer (AT), can learn to improve upon itself both at training and test time. As we show on D4RL and ExoRL benchmarks, to the best our knowledge, this is the first time that a simple transformer-based model performs competitively with both temporal-difference and imitation-learning-based approaches, even from sub-optimal data. Our Agentic Transformer also shows a promising scaling trend that bigger models consistently improve results.'}",https://openreview.net{'value': '/pdf/203774497318d60994d65179c8f6cbe796968df1.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=47kHz7I8lJ,{'value': 'Monotonicity and Double Descent in Uncertainty Estimation with Gaussian Processes'},Liam Hodgkinson; Chris van der Heide; Fred Roosta; Michael W. Mahoney,~Liam_Hodgkinson1; ~Chris_van_der_Heide1; ~Fred_Roosta1; ~Michael_W._Mahoney1,,"{'value': 'Despite their importance for assessing reliability of predictions, uncertainty quantification (UQ) measures in machine learning models have only recently begun to be rigorously characterized. One prominent issue is the *curse of dimensionality*: it is commonly believed that the marginal likelihood should be reminiscent of cross-validation metrics and both should deteriorate with larger input dimensions. However, we prove that by tuning hyperparameters to maximize marginal likelihood (the empirical Bayes procedure), performance, as measured by the marginal likelihood, *improves monotonically* with the input dimension. On the other hand, cross-validation metrics exhibit qualitatively different behavior that is characteristic of double descent. Cold posteriors, which have recently attracted interest due to their improved performance in certain settings, appear to exacerbate these phenomena. We verify empirically that our results hold for real data, beyond our considered assumptions, and we explore consequences involving synthetic covariates.'}",https://openreview.net{'value': '/pdf/61c1fd5703c80aef5a7717d70ef5e5f6619616b9.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=3aauzk8QUl,{'value': 'Understanding the Impact of Adversarial Robustness on Accuracy Disparity'},Yuzheng Hu; Fan Wu; Hongyang Zhang; Han Zhao,~Yuzheng_Hu1; ~Fan_Wu6; ~Hongyang_Zhang1; ~Han_Zhao1,,"{'value': 'While it has long been empirically observed that adversarial robustness may be at odds with standard accuracy and may have further disparate impacts on different classes, it remains an open question to what extent such observations hold and how the class imbalance plays a role within. In this paper, we attempt to understand this question of accuracy disparity by taking a closer look at linear classifiers under a Gaussian mixture model. We decompose the impact of adversarial robustness into two parts: an inherent effect that will degrade the standard accuracy on all classes due to the robustness constraint, and the other caused by the class imbalance ratio, which will increase the accuracy disparity compared to standard training. Furthermore, we also show that such effects extend beyond the Gaussian mixture model, by generalizing our data model to the general family of stable distributions. More specifically, we demonstrate that while the constraint of adversarial robustness consistently degrades the standard accuracy in the balanced class setting, the class imbalance ratio plays a fundamentally different role in accuracy disparity compared to the Gaussian case, due to the heavy tail of the stable distribution. We additionally perform experiments on both synthetic and real-world datasets to corroborate our theoretical findings. Our empirical results also suggest that the implications may extend to nonlinear models over real-world datasets. Our code is publicly available on GitHub at https://github.com/Accuracy-Disparity/AT-on-AD.'}",https://openreview.net{'value': '/pdf/d72262b8adf30993ec84b49b9285b5bf662b48d6.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=3ETNXs54HB,{'value': 'AdaptDiffuser: Diffusion Models as Adaptive Self-evolving Planners'},Zhixuan Liang; Yao Mu; Mingyu Ding; Fei Ni; Masayoshi Tomizuka; Ping Luo,~Zhixuan_Liang2; ~Yao_Mu1; ~Mingyu_Ding1; ~Fei_Ni1; ~Masayoshi_Tomizuka1; ~Ping_Luo2,,"{'value': 'Diffusion models have demonstrated their powerful generative capability in many tasks, with great potential to serve as a paradigm for offline reinforcement learning. However, the quality of the diffusion model is limited by the insufficient diversity of training data, which hinders the performance of planning and the generalizability to new tasks. This paper introduces AdaptDiffuser, an evolutionary planning method with diffusion that can self-evolve to improve the diffusion model hence a better planner, not only for seen tasks but can also adapt to unseen tasks. AdaptDiffuser enables the generation of rich synthetic expert data for goal-conditioned tasks using guidance from reward gradients. It then selects high-quality data via a discriminator to finetune the diffusion model, which improves the generalization ability to unseen tasks. Empirical experiments on two benchmark environments and two carefully designed unseen tasks in KUKA industrial robot arm and Maze2D environments demonstrate the effectiveness of AdaptDiffuser. For example, AdaptDiffuser not only outperforms the previous art Diffuser by 20.8% on Maze2D and 7.5% on MuJoCo locomotion, but also adapts better to new tasks, e.g., KUKA pick-and-place, by 27.9% without requiring additional expert data. More visualization results and demo videos could be found on our project page.'}",https://openreview.net{'value': '/pdf/18713cbce5faf7d8bdeaa82c584d78d6126325e2.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=2WEMW6rGgG,{'value': 'Algorithms for bounding contribution for histogram estimation under user-level privacy'},Yuhan Liu; Ananda Theertha Suresh; Wennan Zhu; Peter Kairouz; Marco Gruteser,~Yuhan_Liu4; ~Ananda_Theertha_Suresh1; ~Wennan_Zhu1; ~Peter_Kairouz1; ~Marco_Gruteser1,,"{'value': 'We study the problem of histogram estimation under user-level differential privacy, where the goal is to preserve the privacy of *all* entries of any single user. We consider the heterogeneous scenario where the quantity of data can be different for each user. In this scenario, the amount of noise injected into the histogram to obtain differential privacy is proportional to the maximum user contribution, which can be amplified by few outliers. One approach to circumvent this would be to bound (or limit) the contribution of each user to the histogram. However, if users are limited to small contributions, a significant amount of data will be discarded. In this work, we propose algorithms to choose the best user contribution bound for histogram estimation under both bounded and unbounded domain settings. When the size of the domain is bounded, we propose a user contribution bounding strategy that almost achieves a two-approximation with respect to the best contribution bound in hindsight. For unbounded domain histogram estimation, we propose an algorithm that is logarithmic-approximation with respect to the best contribution bound in hindsight. This result holds without any distribution assumptions on the data. Experiments on both real and synthetic datasets verify our theoretical findings and demonstrate the effectiveness of our algorithms. We also show that clipping bias introduced by bounding user contribution may be reduced under mild distribution assumptions, which can be of independent interest.'}",https://openreview.net{'value': '/pdf/5114abf028f29494923d3138e75e9aa0c9d2fa03.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=23uOLxPd34,{'value': 'Attention-Based Recurrence for Multi-Agent Reinforcement Learning under Stochastic Partial Observability'},Thomy Phan; Fabian Ritz; Philipp Altmann; Maximilian Zorn; Jonas Nüßlein; Michael Kölle; Thomas Gabor; Claudia Linnhoff-Popien,~Thomy_Phan1; ~Fabian_Ritz1; ~Philipp_Altmann1; ~Maximilian_Zorn1; ~Jonas_Nüßlein1; ~Michael_Kölle1; ~Thomas_Gabor1; ~Claudia_Linnhoff-Popien1,,"{'value': 'Stochastic partial observability poses a major challenge for decentralized coordination in multi-agent reinforcement learning but is largely neglected in state-of-the-art research due to a strong focus on state-based centralized training for decentralized execution (CTDE) and benchmarks that lack sufficient stochasticity like StarCraft Multi-Agent Challenge (SMAC). In this paper, we propose Attention-based Embeddings of Recurrence In multi-Agent Learning (AERIAL) to approximate value functions under stochastic partial observability. AERIAL replaces the true state with a learned representation of multi-agent recurrence, considering more accurate information about decentralized agent decisions than state-based CTDE. We then introduce MessySMAC, a modified version of SMAC with stochastic observations and higher variance in initial states, to provide a more general and configurable benchmark regarding stochastic partial observability. We evaluate AERIAL in Dec-Tiger as well as in a variety of SMAC and MessySMAC maps, and compare the results with state-based CTDE. Furthermore, we evaluate the robustness of AERIAL and state-based CTDE against various stochasticity configurations in MessySMAC.'}",https://openreview.net{'value': '/pdf/cccb49229bbc80c1d19d54ba71ca541624bdcc52.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=1s3P1SjAsF,{'value': 'K-SHAP: Policy Clustering Algorithm for Anonymous Multi-Agent State-Action Pairs'},Andrea Coletta; Svitlana Vyetrenko; Tucker Balch,~Andrea_Coletta1; ~Svitlana_Vyetrenko1; ~Tucker_Balch2,,"{'value': 'Learning agent behaviors from observational data has shown to improve our understanding of their decision-making processes, advancing our ability to explain their interactions with the environment and other agents. While multiple learning techniques have been proposed in the literature, there is one particular setting that has not been explored yet: multi agent systems where agent identities remain anonymous. For instance, in financial markets labeled data that identifies market participant strategies is typically proprietary, and only the anonymous state-action pairs that result from the interaction of multiple market participants are publicly available. As a result, sequences of agent actions are not observable, restricting the applicability of existing work. In this paper, we propose a Policy Clustering algorithm, called K-SHAP, that learns to group anonymous state-action pairs according to the agent policies. We frame the problem as an Imitation Learning (IL) task, and we learn a world-policy able to mimic all the agent behaviors upon different environmental states. We leverage the world-policy to explain each anonymous observation through an additive feature attribution method called SHAP (SHapley Additive exPlanations). Finally, by clustering the explanations we show that we are able to identify different agent policies and group observations accordingly. We evaluate our approach on simulated synthetic market data and a real-world financial dataset. We show that our proposal significantly and consistently outperforms the existing methods, identifying different agent strategies.'}",https://openreview.net{'value': '/pdf/0eacafe450b84e3ca3180f28ef879609dd496513.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=1hWB5XEUMa,{'value': 'Linear Time GPs for Inferring Latent Trajectories from Neural Spike Trains'},Matthew Dowling; Yuan Zhao; Il Memming Park,~Matthew_Dowling2; ~Yuan_Zhao1; ~Il_Memming_Park1,,"{'value': 'Latent Gaussian process (GP) models are widely used in neuroscience to uncover hidden state evolutions from sequential observations, mainly in neural activity recordings. While latent GP models provide a principled and powerful solution in theory, the intractable posterior in non-conjugate settings necessitates approximate inference schemes, which may lack scalability. In this work, we propose cvHM, a general inference framework for latent GP models leveraging Hida-Matérn kernels and conjugate computation variational inference (CVI). With cvHM, we are able to perform variational inference of latent neural trajectories with linear time complexity for arbitrary likelihoods. The reparameterization of stationary kernels using Hida-Matérn GPs helps us connect the latent variable models that encode prior assumptions through dynamical systems to those that encode trajectory assumptions through GPs. In contrast to previous work, we use bidirectional information filtering, leading to a more concise implementation. Furthermore, we employ the Whittle approximate likelihood to achieve highly efficient hyperparameter learning.'}",https://openreview.net{'value': '/pdf/4a432a206b604e11a3d5747134cf766d343f0a43.pdf'},{'title_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=1VDuHddxtA,{'value': 'Linear Causal Disentanglement via Interventions'},Chandler Squires; Anna Seigal; Salil S Bhate; Caroline Uhler,~Chandler_Squires1; aseigal@math.harvard.edu; ~Salil_S_Bhate1; ~Caroline_Uhler1,,"{'value': 'Causal disentanglement seeks a representation of data involving latent variables that are related via a causal model. A representation is identifiable if both the latent model and the transformation from latent to observed variables are unique. In this paper, we study observed variables that are a linear transformation of a linear latent causal model. Data from interventions are necessary for identifiability: if one latent variable is missing an intervention, we show that there exist distinct models that cannot be distinguished. Conversely, we show that a single intervention on each latent variable is sufficient for identifiability. Our proof uses a generalization of the RQ decomposition of a matrix that replaces the usual orthogonal and upper triangular conditions with analogues depending on a partial order on the rows of the matrix, with partial order determined by a latent causal model. We corroborate our theoretical results with a method for causal disentanglement. We show that the method accurately recovers a latent causal model on synthetic and semi-synthetic data and we illustrate a use case on a dataset of single-cell RNA sequencing measurements.'}",https://openreview.net{'value': '/pdf/5086c2b45a668c12d9e56431366d311459447e5b.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=0e2DfXKbwE,{'value': 'Causal Structure Learning for Latent Intervened Non-stationary Data'},Chenxi Liu; Kun Kuang,~Chenxi_Liu3; ~Kun_Kuang1,,"{'value': 'Causal structure learning can reveal the causal mechanism behind natural systems. It is well studied that the multiple domain data consisting of observational and interventional samples benefit causal identifiability. However, for non-stationary time series data, domain indexes are often unavailable, making it difficult to distinguish observational samples from interventional samples. To address these issues, we propose a novel Latent Intervened Non-stationary learning (LIN) method to make the domain indexes recovery process and the causal structure learning process mutually promote each other. We characterize and justify a possible faithfulness condition to guarantee the identifiability of the proposed LIN method. Extensive experiments on both synthetic and real-world datasets demonstrate that our method outperforms the baselines on causal structure learning for latent intervened non-stationary data.'}",https://openreview.net{'value': '/pdf/350ff7f3845949fe6016d942468ff74256e65fc3.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=0VeyziIEcJ,{'value': 'Fast Online Value-Maximizing Prediction Sets with Conformal Cost Control'},Zhen Lin; Shubhendu Trivedi; Cao Xiao; Jimeng Sun,~Zhen_Lin2; ~Shubhendu_Trivedi2; ~Cao_Xiao2; ~Jimeng_Sun3,,"{'value': 'Many real-world multi-label prediction problems involve set-valued predictions that must satisfy specific requirements dictated by downstream usage. We focus on a typical scenario where such requirements, separately encoding *value* and *cost*, compete with each other. For instance, a hospital might expect a smart diagnosis system to capture as many severe, often co-morbid, diseases as possible (the value), while maintaining strict control over incorrect predictions (the cost). We present a general pipeline, dubbed as FavMac, to maximize the value while controlling the cost in such scenarios. FavMac can be combined with almost any multi-label classifier, affording distribution-free theoretical guarantees on cost control. Moreover, unlike prior works, FavMac can handle real-world large-scale applications via a carefully designed online update mechanism, which is of independent interest. Our methodological and theoretical contributions are supported by experiments on several healthcare tasks and synthetic datasets - FavMac furnishes higher value compared with several variants and baselines while maintaining strict cost control.'}",https://openreview.net{'value': '/pdf/fdc1cceb5b2e56751a5bbd365d2dbc8b82d02c30.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=0TJgsYhgGg,{'value': 'Towards Understanding and Improving GFlowNet Training'},Max W Shen; Emmanuel Bengio; Ehsan Hajiramezanali; Andreas Loukas; Kyunghyun Cho; Tommaso Biancalani,~Max_W_Shen1; ~Emmanuel_Bengio1; ~Ehsan_Hajiramezanali1; ~Andreas_Loukas1; ~Kyunghyun_Cho1; ~Tommaso_Biancalani1,,"{'value': 'Generative flow networks (GFlowNets) are a family of algorithms that learn a generative policy to sample discrete objects $x$ with non-negative reward $R(x)$. Learning objectives guarantee the GFlowNet samples $x$ from the target distribution $p^*(x) \\propto R(x)$ when loss is globally minimized over all states or trajectories, but it is unclear how well they perform with practical limits on training resources. We introduce an efficient evaluation strategy to compare the learned sampling distribution to the target reward distribution. As flows can be underdetermined given training data, we clarify the importance of learned flows to generalization and matching $p^*(x)$ in practice. We investigate how to learn better flows, and propose (i) prioritized replay training of high-reward $x$, (ii) relative edge flow policy parametrization, and (iii) a novel guided trajectory balance objective, and show how it can solve a substructure credit assignment problem. We substantially improve sample efficiency on biochemical design tasks.'}",https://openreview.net{'value': '/pdf/88597d45cc5a17966e153a71991454ff055d4657.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=0O7b2Y198V,{'value': 'STEP: Learning N:M Structured Sparsity Masks from Scratch with Precondition'},Yucheng Lu; Shivani Agrawal; Suvinay Subramanian; Oleg Rybakov; Christopher De Sa; Amir Yazdanbakhsh,~Yucheng_Lu1; ~Shivani_Agrawal1; suvinay@google.com; rybakov@google.com; ~Christopher_De_Sa2; ~Amir_Yazdanbakhsh1,,"{'value': 'Recent innovations on hardware (e.g. Nvidia A100) have motivated learning N:M structured sparsity masks from scratch for fast model inference. However, state-of-the-art learning recipes in this regime (e.g. SR-STE) are proposed for non-adaptive optimizers like momentum SGD, while incurring non-trivial accuracy drop for Adam-trained models like attention-based LLMs. In this paper, we first demonstrate such gap origins from poorly estimated second moment (i.e. variance) in Adam states given by the masked weights. We conjecture that learning N:M masks with Adam should take the critical regime of variance estimation into account. In light of this, we propose STEP, an Adam-aware recipe that learns N:M masks with two phases: first, STEP calculates a reliable variance estimate (*precondition phase*) and subsequently, the variance remains fixed and is used as a precondition to learn N:M masks (*mask-learning phase*). STEP automatically identifies the switching point of two phases by dynamically sampling variance changes over the training trajectory and testing the sample concentration. Empirically, we evaluate STEP and other baselines such as ASP and SR-STE on multiple tasks including CIFAR classification, machine translation and LLM fine-tuning (BERT-Base, GPT-2). We show STEP mitigates the accuracy drop of baseline recipes and is robust to aggressive structured sparsity ratios.'}",https://openreview.net{'value': '/pdf/217237f537e4f7b12ae7286d2bb3a711abff5040.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=zodnF0pqK7,{'value': 'Semi-Dual Unbalanced Quadratic Optimal Transport: fast statistical rates and convergent algorithm.'},Adrien Vacher; François-Xavier Vialard,~Adrien_Vacher1; ~François-Xavier_Vialard2,,"{'value': 'In this paper, we derive a semi-dual formulation for the problem of unbalanced quadratic optimal transport and we study its stability properties, namely we give upper and lower bounds for the Bregman divergence of the new objective that hold globally. We observe that the new objective gains even more convexity than in the balanced case. We use this formulation to prove the first results on statistical estimation of UOT potentials and we leverage the extra convexity to recover super-parametric rates. Interestingly, unlike in the balanced case, we do not require the potentials to be smooth. Then, use variable metric descent to solve the semi-dual problem for which we prove convergence at a $1/k$ rate for strongly convex potentials and exponential convergence in the balanced case when potentials are also smooth. We emphasize that our convergence results has an interest on its own as it generalizes previous convergence results to non-equivalent metrics. Last, we instantiate a proof-of-concept tractable version of our theoretical algorithm that we benchmark on a 2D experiment in the balanced case and on a medium dimension synthetic experiment in the unbalanced case.'}",https://openreview.net{'value': '/pdf/da802a84cb724bb3c34440fa22e5b6727d786fa9.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=zkdHgAKedJ,{'value': 'An Effective Meaningful Way to Evaluate Survival Models'},Shi-ang Qi; Neeraj Kumar; Mahtab Farrokh; Weijie Sun; Li-Hao Kuan; Rajesh Ranganath; Ricardo Henao; Russell Greiner,~Shi-ang_Qi1; ~Neeraj_Kumar5; farrokn@ualberta.ca; weijie2@ualberta.ca; lihao@ualberta.ca; ~Rajesh_Ranganath2; ~Ricardo_Henao1; ~Russell_Greiner2,,"{'value': 'One straightforward metric to evaluate a survival prediction model is based on the Mean Absolute Error (MAE) – the average of the absolute difference between the time predicted by the model and the true event time, over all subjects. Unfortunately, this is challenging because, in practice, the test set includes (right) censored individuals, meaning we do not know when a censored individual actually experienced the event. In this paper, we explore various metrics to estimate MAE for survival datasets that include (many) censored individuals. Moreover, we introduce a novel and effective approach for generating realistic semi-synthetic survival datasets to facilitate the evaluation of metrics. Our findings, based on the analysis of the semi-synthetic datasets, reveal that our proposed metric (MAE using pseudo-observations) is able to rank models accurately based on their performance, and often closely matches the true MAE – in particular, is better than several alternative methods.'}",https://openreview.net{'value': '/pdf/1bf41d10e72903081168a308b51d0d04731ed740.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=zIVu5Yidhm,{'value': 'Trading-Off Payments and Accuracy in Online Classification with Paid Stochastic Experts'},Dirk van der Hoeven; Ciara Pike-Burke; Hao Qiu; Nicolò Cesa-Bianchi,~Dirk_van_der_Hoeven1; ~Ciara_Pike-Burke2; ~Hao_Qiu2; ~Nicolò_Cesa-Bianchi1,,"{'value': ""We investigate online classification with paid stochastic experts. Here, before making their prediction, each expert must be paid. The amount that we pay each expert directly influences the accuracy of their prediction through some unknown Lipschitz ``productivity'' function. In each round, the learner must decide how much to pay each expert and then make a prediction. They incur a cost equal to a weighted sum of the prediction error and upfront payments for all experts. We introduce an online learning algorithm whose total cost after $T$ rounds exceeds that of a predictor which knows the productivity of all experts in advance by at most $\\mathcal{O}\\big(K^2(\\ln T)\\sqrt{T}\\big)$ where $K$ is the number of experts. In order to achieve this result, we combine Lipschitz bandits and online classification with surrogate losses. These tools allow us to improve upon the bound of order $T^{2/3}$ one would obtain in the standard Lipschitz bandit setting. Our algorithm is empirically evaluated on synthetic data.""}",https://openreview.net{'value': '/pdf/01513ab984971ad1592f91e18e38224e2bc2a41e.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=yu3Q5iU9hi,{'value': 'Multi-Objective GFlowNets'},Moksh Jain; Sharath Chandra Raparthy; Alex Hernández-García; Jarrid Rector-Brooks; Yoshua Bengio; Santiago Miret; Emmanuel Bengio,~Moksh_Jain1; ~Sharath_Chandra_Raparthy3; ~Alex_Hernández-García1; ~Jarrid_Rector-Brooks2; ~Yoshua_Bengio1; ~Santiago_Miret1; ~Emmanuel_Bengio1,,"{'value': 'We study the problem of generating *diverse* candidates in the context of Multi-Objective Optimization. In many applications of machine learning such as drug discovery and material design, the goal is to generate candidates which simultaneously optimize a set of potentially conflicting objectives. Moreover, these objectives are often imperfect evaluations of some underlying property of interest, making it important to generate diverse candidates to have multiple options for expensive downstream evaluations. We propose Multi-Objective GFlowNets (MOGFNs), a novel method for generating diverse Pareto optimal solutions, based on GFlowNets. We introduce two variants of MOGFNs: MOGFN-PC, which models a family of independent sub-problems defined by a scalarization function, with reward-conditional GFlowNets, and MOGFN-AL, which solves a sequence of sub-problems defined by an acquisition function in an active learning loop. Our experiments on wide variety of synthetic and benchmark tasks demonstrate advantages of the proposed methods in terms of the Pareto performance and importantly, improved candidate diversity, which is the main contribution of this work.'}",https://openreview.net{'value': '/pdf/71f05ad2a4afb8322d27dbe681c2c64b5910f0ed.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=ybl9lzdZw7,{'value': 'Taxonomy-Structured Domain Adaptation'},Tianyi Liu; Zihao Xu; Hao He; Guang-Yuan Hao; Guang-He Lee; Hao Wang,~Tianyi_Liu4; ~Zihao_Xu2; ~Hao_He1; ~Guang-Yuan_Hao1; ~Guang-He_Lee1; ~Hao_Wang3,,"{'value': ""Domain adaptation aims to mitigate distribution shifts among different domains. However, traditional formulations are mostly limited to categorical domains, greatly simplifying nuanced domain relationships in the real world. In this work, we tackle a generalization with taxonomy-structured domains, which formalizes domains with nested, hierarchical similarity structures such as animal species and product catalogs. We build on the classic adversarial framework and introduce a novel *taxonomist*, which competes with the adversarial discriminator to preserve the taxonomy information. The equilibrium recovers the classic adversarial domain adaptation's solution if given a non-informative domain taxonomy (e.g., a flat taxonomy where all leaf nodes connect to the root node) while yielding non-trivial results with other taxonomies. Empirically, our method achieves state-of-the-art performance on both synthetic and real-world datasets with successful adaptation.""}",https://openreview.net{'value': '/pdf/55d1fefadeff43b3d9743776af06fa3b476fc0b0.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=xDIppoiFrA,{'value': 'Learning to Incentivize Information Acquisition: Proper Scoring Rules Meet Principal-Agent Model'},Siyu Chen; Jibang Wu; Yifan Wu; Zhuoran Yang,~Siyu_Chen2; ~Jibang_Wu1; ~Yifan_Wu5; ~Zhuoran_Yang1,,"{'value': ""We study the incentivized information acquisition problem, where a principal hires an agent to gather information on her behalf. Such a problem is modeled as a Stackelberg game between the principal and the agent, where the principal announces a scoring rule that specifies the payment, and then the agent then chooses an effort level that maximizes her own profit and reports the information. We study the online setting of such a problem from the principal's perspective, i.e., designing the optimal scoring rule by repeatedly interacting with the strategic agent. We design a provably sample efficient algorithm that tailors the UCB algorithm (Auer et al., 2002) to our model, which achieves a $\\mathcal{O} (K^2\\cdot T^{2/3})$ regret after $T$ iterations, where $K$ is the number of effort levels of the agent. Our algorithm features a delicate estimation procedure for the optimal profit of the principal, and a conservative correction scheme that ensures the desired agent's actions are incentivized. Furthermore, a key feature of our regret bound is that it is independent of the number of states of the environment.""}",https://openreview.net{'value': '/pdf/cfc9196c4bdfc93919c066f054350ef0a64e7de6.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=wcUppxYfLH,{'value': 'Fast Rates for Maximum Entropy Exploration'},Daniil Tiapkin; Denis Belomestny; Daniele Calandriello; Eric Moulines; Remi Munos; Alexey Naumov; pierre perrault; Yunhao Tang; Michal Valko; Pierre MENARD,~Daniil_Tiapkin1; ~Denis_Belomestny1; ~Daniele_Calandriello1; ~Eric_Moulines1; ~Remi_Munos1; ~Alexey_Naumov1; ~pierre_perrault2; ~Yunhao_Tang1; ~Michal_Valko1; ~Pierre_MENARD1,,"{'value': 'We address the challenge of exploration in reinforcement learning (RL) when the agent operates in an unknown environment with sparse or no rewards. In this work, we study the maximum entropy exploration problem of two different types. The first type is visitation entropy maximization previously considered by Hazan et al. (2019) in the discounted setting. For this type of exploration, we propose a game-theoretic algorithm that has $\\widetilde{\\mathcal{O}}(H^3S^2A/\\varepsilon^2)$ sample complexity thus improving the $\\varepsilon$-dependence upon existing results, where $S$ is a number of states, $A$ is a number of actions, $H$ is an episode length, and $\\varepsilon$ is a desired accuracy. The second type of entropy we study is the trajectory entropy. This objective function is closely related to the entropy-regularized MDPs, and we propose a simple algorithm that has a sample complexity of order $\\widetilde{\\mathcal{O}}(\\mathrm{poly}(S,A,H)/\\varepsilon)$. Interestingly, it is the first theoretical result in RL literature that establishes the potential statistical advantage of regularized MDPs for exploration. Finally, we apply developed regularization techniques to reduce sample complexity of visitation entropy maximization to $\\widetilde{\\mathcal{O}}(H^2SA/\\varepsilon^2)$, yielding a statistical separation between maximum entropy exploration and reward-free exploration.'}",https://openreview.net{'value': '/pdf/0c14f6937cb92e902920030591ec61664d69fd5e.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=wVGreJ2338,{'value': 'Featured Graph Coarsening with Similarity Guarantees'},Manoj Kumar; Anurag Sharma; Shashwat Saxena; Sandeep Kumar,~Manoj_Kumar4; ~Anurag_Sharma1; ~Shashwat_Saxena1; ~Sandeep_Kumar8,,"{'value': ""Graph coarsening is a dimensionality reduction technique that aims to learn a smaller-tractable graph while preserving the properties of the original input graph. However, many real-world graphs also have features or contexts associated with each node. The existing graph coarsening methods do not consider the node features and rely solely on a graph matrix(e.g., adjacency and Laplacian) to coarsen graphs. However, some recent deep learning-based graph coarsening methods are designed for specific tasks considering both node features and graph matrix. In this paper, we introduce a novel optimization-based framework for graph coarsening that takes both the graph matrix and the node features as the input and jointly learns the coarsened graph matrix and the coarsened feature matrix while ensuring desired properties. To the best of our knowledge, this is the first work that guarantees that the learned coarsened graph is $\\epsilon\\in[0,1)$ similar to the original graph. Extensive experiments with both real and synthetic benchmark datasets elucidate the proposed framework's efficacy and applicability for numerous graph-based applications, including graph clustering, node classification, stochastic block model identification, and graph summarization.""}",https://openreview.net{'value': '/pdf/91cc907a19f3d29670a505150dabe44fc1a4d4cd.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=vDMHusV7J0,{'value': 'Deep Generative Symbolic Regression with Monte-Carlo-Tree-Search'},Pierre-Alexandre Kamienny; Guillaume Lample; sylvain lamprier; Marco Virgolin,~Pierre-Alexandre_Kamienny1; ~Guillaume_Lample1; ~sylvain_lamprier1; ~Marco_Virgolin1,,"{'value': 'Symbolic regression (SR) is the problem of learning a symbolic expression from numerical data. Recently, deep neural models trained on procedurally-generated synthetic datasets showed competitive performance compared to more classical Genetic Programming (GP) ones. Unlike their GP counterparts, these neural approaches are trained to generate expressions from datasets given as context. This allows them to produce accurate expressions in a single forward pass at test time. However, they usually do not benefit from search abilities, which result in low performance compared to GP on out-of-distribution datasets. In this paper, we propose a novel method which provides the best of both worlds, based on a Monte-Carlo Tree Search procedure using a context-aware neural mutation model, which is initially pre-trained to learn promising mutations, and further refined from successful experiences in an online fashion. The approach demonstrates state-of-the-art performance on the well-known SRBench benchmark.'}",https://openreview.net{'value': '/pdf/313427c55bc0b547903e24fa2de5a384f09dc0e4.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=v6izzusLDO,{'value': 'Sampling-Based Accuracy Testing of Posterior Estimators for General Inference'},Pablo Lemos; Adam Coogan; Yashar Hezaveh; Laurence Perreault-Levasseur,~Pablo_Lemos1; ~Adam_Coogan1; hezaveh@astro.umontreal.ca; llevasseur@astro.umontreal.ca,,"{'value': 'Parameter inference, i.e. inferring the posterior distribution of the parameters of a statistical model given some data, is a central problem to many scientific disciplines. Posterior inference with generative models is an alternative to methods such as Markov Chain Monte Carlo, both for likelihood-based and simulation-based inference. However, assessing the accuracy of posteriors encoded in generative models is not straightforward. In this paper, we introduce ""Tests of Accuracy with Random Points"" (TARP) coverage testing as a method to estimate coverage probabilities of generative posterior estimators. Our method differs from previously-existing coverage-based methods, which require posterior evaluations. We prove that our approach is necessary and sufficient to show that a posterior estimator is accurate. We demonstrate the method on a variety of synthetic examples, and show that TARP can be used to test the results of posterior inference analyses in high-dimensional spaces. We also show that our method can detect inaccurate inferences in cases where existing methods fail.'}",https://openreview.net{'value': '/pdf/738d17e17025ef82f39b206c6d7febdac4294613.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=uSJP34JCTu,{'value': 'Predicting Rare Events by Shrinking Towards Proportional Odds'},Gregory Faletto; Jacob Bien,~Gregory_Faletto1; jbien@usc.edu,,"{'value': 'Training classifiers is difficult with severe class imbalance, but many rare events are the culmination of a sequence with much more common intermediate outcomes. For example, in online marketing a user first sees an ad, then may click on it, and finally may make a purchase; estimating the probability of purchases is difficult because of their rarity. We show both theoretically and through data experiments that the more abundant data in earlier steps may be leveraged to improve estimation of probabilities of rare events. We present PRESTO, a relaxation of the proportional odds model for ordinal regression. Instead of estimating weights for one separating hyperplane that is shifted by separate intercepts for each of the estimated Bayes decision boundaries between adjacent pairs of categorical responses, we estimate separate weights for each of these transitions. We impose an L1 penalty on the differences between weights for the same feature in adjacent weight vectors in order to shrink towards the proportional odds model. We prove that PRESTO consistently estimates the decision boundary weights under a sparsity assumption. Synthetic and real data experiments show that our method can estimate rare probabilities in this setting better than both logistic regression on the rare category, which fails to borrow strength from more abundant categories, and the proportional odds model, which is too inflexible.'}",https://openreview.net{'value': '/pdf/80360174c19ae6c349cf0158a2d1caee22a8333b.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=uP5xXIULdH,{'value': 'On the Estimation of Gaussian Mixture Copula Models'},ASHUTOSH TEWARI,~ASHUTOSH_TEWARI1,,"{'value': 'This paper revisits Gaussian Mixture Copula Model (GMCM), a more expressive alternative to the widely used Gaussian Mixture Model (GMM), with the goal to make its parameter estimation tractable. Both the Expectation Maximization and the direct Likelihood Maximization frameworks for GMCM have to grapple with a likelihood function that lacks a closed form. This has led to a few approximation schemes that alleviate the problem, nonetheless leaving the issue still unresolved. Additionally, past works have alluded to an additional challenge of parameter non-identifiability, but none has offered a rigorous treatment and a commensurate solution framework to overcome the same. This work offers solutions to each of these issues in an attempt to help GMCM realize its full potential. The source of non-identifiability is not only proven but also suitable priors are proposed that eliminate the problem. Additionally, an efficient numerical framework is proposed to evaluate the intractable likelihood function, while also providing its analytical derivatives. Finally, a view of GMCM as a series of bijective mappings from a base distribution is presented, which paves the way to synthesize GMCM using modern, probabilistic programming languages (PPLs). The main claims of this work are supported by empirical evidence gathered on synthetic and real-world datasets.'}",https://openreview.net{'value': '/pdf/afe98b5c6059fbe4aa68683841e38ac547d43653.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=uDeP2vJmho,{'value': 'Which Invariance Should We Transfer? A Causal Minimax Learning Approach'},Mingzhou Liu; Xiangyu Zheng; Xinwei Sun; Fang Fang; Yizhou Wang,~Mingzhou_Liu1; ~Xiangyu_Zheng1; ~Xinwei_Sun1; ~Fang_Fang1; ~Yizhou_Wang1,,"{'value': ""A major barrier to deploying current machine learning models lies in their non-reliability to dataset shifts. To resolve this problem, most existing studies attempted to transfer stable information to unseen environments. Particularly, independent causal mechanisms-based methods proposed to remove mutable causal mechanisms via the do-operator. Compared to previous methods, the obtained stable predictors are more effective in identifying stable information. However, a key question remains: which subset of this whole stable information should the model transfer, in order to achieve optimal generalization ability? To answer this question, we present a comprehensive minimax analysis from a causal perspective. Specifically, we first provide a graphical condition for the whole stable set to be optimal. When this condition fails, we surprisingly find with an example that this whole stable set, although can fully exploit stable information, is not the optimal one to transfer. To identify the optimal subset under this case, we propose to estimate the worst-case risk with a novel optimization scheme over the intervention functions on mutable causal mechanisms. We then propose an efficient algorithm to search for the subset with minimal worst-case risk, based on a newly defined equivalence relation between stable subsets. Compared to the exponential cost of exhaustively searching over all subsets, our searching strategy enjoys a polynomial complexity. The effectiveness and efficiency of our methods are demonstrated on synthetic data and the diagnosis of Alzheimer's disease.""}",https://openreview.net{'value': '/pdf/2193bf59d0935f062a7581127e5acf34f5593e46.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=u1fhtP15l5,{'value': 'Conformalization of Sparse Generalized Linear Models'},Etash Kumar Guha; Eugene Ndiaye; Xiaoming Huo,~Etash_Kumar_Guha1; ~Eugene_Ndiaye1; ~Xiaoming_Huo1,,"{'value': 'Given a sequence of observable variables $\\{(x_1, y_1), \\ldots, (x_n, y_n)\\}$, the conformal prediction method estimates a confidence set for $y_{n+1}$ given $x_{n+1}$ that is valid for any finite sample size by merely assuming that the joint distribution of the data is permutation invariant. Although attractive, computing such a set is computationally infeasible in most regression problems. Indeed, in these cases, the unknown variable $y_{n+1}$ can take an infinite number of possible candidate values, and generating conformal sets requires retraining a predictive model for each candidate. In this paper, we focus on a sparse linear model with only a subset of variables for prediction and use numerical continuation techniques to approximate the solution path efficiently. The critical property we exploit is that the set of selected variables is invariant under a small perturbation of the input data. Therefore, it is sufficient to enumerate and refit the model only at the change points of the set of active features and smoothly interpolate the rest of the solution via a Predictor-Corrector mechanism. We show how our path-following algorithm accurately approximates conformal prediction sets and illustrate its performance using synthetic and real data examples.'}",https://openreview.net{'value': '/pdf/a8aec617b3ad8c8a95ea360273d45eaca1075bd4.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=tgm43aFDXD,{'value': 'Improving Expert Predictions with Conformal Prediction'},Eleni Straitouri; Lequn Wang; Nastaran Okati; Manuel Gomez Rodriguez,~Eleni_Straitouri1; ~Lequn_Wang1; ~Nastaran_Okati2; ~Manuel_Gomez_Rodriguez1,,"{'value': 'Automated decision support systems promise to help human experts solve multiclass classification tasks more efficiently and accurately. However, existing systems typically require experts to understand when to cede agency to the system or when to exercise their own agency. Otherwise, the experts may be better off solving the classification tasks on their own. In this work, we develop an automated decision support system that, by design, does not require experts to understand when to trust the system to improve performance. Rather than providing (single) label predictions and letting experts decide when to trust these predictions, our system provides sets of label predictions constructed using conformal prediction---prediction sets---and forcefully asks experts to predict labels from these sets. By using conformal prediction, our system can precisely trade-off the probability that the true label is not in the prediction set, which determines how frequently our system will mislead the experts, and the size of the prediction set, which determines the difficulty of the classification task the experts need to solve using our system. In addition, we develop an efficient and near-optimal search method to find the conformal predictor under which the experts benefit the most from using our system. Simulation experiments using synthetic and real expert predictions demonstrate that our system may help experts make more accurate predictions and is robust to the accuracy of the classifier the conformal predictor relies on.'}",https://openreview.net{'value': '/pdf/c9c62c0750eb86cd54fd61f347d6f5899ab9060f.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=tNRyU4Plfl,{'value': 'On the Interplay Between Misspecification and Sub-optimality Gap in Linear Contextual Bandits'},Weitong Zhang; Jiafan He; Zhiyuan Fan; Quanquan Gu,~Weitong_Zhang2; ~Jiafan_He1; ~Zhiyuan_Fan1; ~Quanquan_Gu1,,"{'value': 'We study linear contextual bandits in the misspecified setting, where the expected reward function can be approximated by a linear function class up to a bounded misspecification level $\\zeta>0$. We propose an algorithm based on a novel data selection scheme, which only selects the contextual vectors with large uncertainty for online regression. We show that, when the misspecification level $\\zeta$ is dominated by $\\tilde O(\\Delta / \\sqrt{d})$ with $\\Delta$ being the minimal sub-optimality gap and $d$ being the dimension of the contextual vectors, our algorithm enjoys the same gap-dependent regret bound $\\tilde O ({d^2} /{\\Delta})$ as in the well-specified setting up to logarithmic factors. Given this result, we show that the existing SupLinUCB algorithm (Chu et al., 2011) can also achieve a gap-dependent constant regret bound without the knowledge of sub-optimality gap $\\Delta$. Together with a lower bound adapted from Lattimore et al. (2020), our result suggests an interplay between the misspecification level and the sub-optimality gap: (1) the linear contextual bandit model is efficiently learnable when $\\zeta \\leq \\tilde O({\\Delta} / \\sqrt{d})$; and (2) it is not efficiently learnable when $\\zeta \\geq \\tilde \\Omega({\\Delta} / {\\sqrt{d}})$. Experiments on both synthetic and real-world datasets corroborate our theoretical results.'}",https://openreview.net{'value': '/pdf/8826314293c1da10457c2296e0b5a984e9a3b8a7.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=tIJMebbcRF,{'value': 'Intrinsic Sliced Wasserstein Distances for Comparing Collections of Probability Distributions on Manifolds and Graphs'},Raif M. Rustamov; Subhabrata Majumdar,~Raif_M._Rustamov1; ~Subhabrata_Majumdar2,,"{'value': 'Collections of probability distributions arise in a variety of applications ranging from user activity pattern analysis to brain connectomics. In practice these distributions can be defined over diverse domain types including finite intervals, circles, cylinders, spheres, other manifolds, and graphs. This paper introduces an approach for detecting differences between two collections of distributions over such general domains. To this end, we propose the intrinsic slicing construction that yields a novel class of Wasserstein distances on manifolds and graphs. These distances are Hilbert embeddable, allowing us to reduce the distribution collection comparison problem to a more familiar mean testing problem in a Hilbert space. We provide two testing procedures one based on resampling and another on combining p-values from coordinate-wise tests. Our experiments in various synthetic and real data settings show that the resulting tests are powerful and the p-values are well-calibrated.'}",https://openreview.net{'value': '/pdf/5fab317e9845085687add141c0d2db5f49afe6e4.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=tE3BMOyUl5,{'value': 'Infusing Lattice Symmetry Priors in Attention Mechanisms for Sample-Efficient Abstract Geometric Reasoning'},Mattia Atzeni; Mrinmaya Sachan; Andreas Loukas,~Mattia_Atzeni1; ~Mrinmaya_Sachan3; ~Andreas_Loukas1,,"{'value': 'The Abstraction and Reasoning Corpus (ARC) (Chollet, 2019) and its most recent language-complete instantiation (LARC) has been postulated as an important step towards general AI. Yet, even state-of-the-art machine learning models struggle to achieve meaningful performance on these problems, falling behind non-learning based approaches. We argue that solving these tasks requires extreme generalization that can only be achieved by proper accounting for core knowledge priors. As a step towards this goal, we focus on geometry priors and introduce LatFormer, a model that incorporates lattice symmetry priors in attention masks. We show that, for any transformation of the hypercubic lattice, there exists a binary attention mask that implements that group action. Hence, our study motivates a modification to the standard attention mechanism, where attention weights are scaled using soft masks generated by a convolutional network. Experiments on synthetic geometric reasoning show that LatFormer requires 2 orders of magnitude fewer data than standard attention and transformers. Moreover, our results on ARC and LARC tasks that incorporate geometric priors provide preliminary evidence that these complex datasets do not lie out of the reach of deep learning models.'}",https://openreview.net{'value': '/pdf/891b91d3b11346d2b8149b02ad0587ed7c9b5e71.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=sy9oDku9Lu,{'value': 'CoDi: Co-evolving Contrastive Diffusion Models for Mixed-type Tabular Synthesis'},Chaejeong Lee; Jayoung Kim; Noseong Park,~Chaejeong_Lee1; ~Jayoung_Kim1; ~Noseong_Park1,,"{'value': 'With growing attention to tabular data these days, the attempt to apply a synthetic table to various tasks has been expanded toward various scenarios. Owing to the recent advances in generative modeling, fake data generated by tabular data synthesis models become sophisticated and realistic. However, there still exists a difficulty in modeling discrete variables (columns) of tabular data. In this work, we propose to process continuous and discrete variables separately (but being conditioned on each other) by two diffusion models. The two diffusion models are co-evolved during training by reading conditions from each other. In order to further bind the diffusion models, moreover, we introduce a contrastive learning method with a negative sampling method. In our experiments with 11 real-world tabular datasets and 8 baseline methods, we prove the efficacy of the proposed method, called $\\texttt{CoDi}$. Our code is available at https://github.com/ChaejeongLee/CoDi.'}",https://openreview.net{'value': '/pdf/75966f66c170a6919f12ec35a965ea973b849b2a.pdf'},{'abstract_filter': 'Data Synthesis'},ICML.cc,2023,Conference
https://openreview.net/forum?id=srcA0Dzooj,{'value': 'End-to-End Learning for Stochastic Optimization: A Bayesian Perspective'},Yves Rychener; Daniel Kuhn; Tobias Sutter,~Yves_Rychener1; ~Daniel_Kuhn2; ~Tobias_Sutter1,,"{'value': 'We develop a principled approach to end-to-end learning in stochastic optimization. First, we show that the standard end-to-end learning algorithm admits a Bayesian interpretation and trains a posterior Bayes action map. Building on the insights of this analysis, we then propose new end-to-end learning algorithms for training decision maps that output solutions of empirical risk minimization and distributionally robust optimization problems, two dominant modeling paradigms in optimization under uncertainty. Numerical results for a synthetic newsvendor problem illustrate the key differences between alternative training schemes. We also investigate an economic dispatch problem based on real data to showcase the impact of the neural network architecture of the decision maps on their test performance.'}",https://openreview.net{'value': '/pdf/93aeea0fcbe3c32553f0e201893b00a1ba60ad7b.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=smrYWkIV9J,{'value': 'Effectively Using Public Data in Privacy Preserving Machine Learning'},Milad Nasr; Saeed Mahloujifar; Xinyu Tang; Prateek Mittal; Amir Houmansadr,~Milad_Nasr2; ~Saeed_Mahloujifar1; ~Xinyu_Tang1; ~Prateek_Mittal1; ~Amir_Houmansadr1,,"{'value': 'Differentially private (DP) machine learning techniques are notorious for their degradation of model utility (e.g., they degrade classification accuracy). A recent line of work has demonstrated that leveraging *public data* can improve the trade-off between privacy and utility when training models with DP guaranteed. In this work, we further explore the potential of using public data in DP models, showing that utility gains can in fact be significantly higher than what shown in prior works. Specifically, we introduce DOPE-SGD, a modified DP-SGD algorithm that leverages public data during its training. DOPE-SGD uses public data in two complementary ways: (1) it uses advance augmentation techniques that leverages public data to generate synthetic data that is effectively embedded in multiple steps of the training pipeline; (2) it uses a modified gradient clipping mechanism (which is a standard technique in DP training) to change the *origin* of gradient vectors using the information inferred from available public and synthetic data, therefore boosting utility. We also introduce a technique to ensemble intermediate DP models by leveraging the post processing property of differential privacy to further improve the accuracy of the predictions. Our experimental results demonstrate the effectiveness of our approach in improving the state-of-the-art in DP machine learning across multiple datasets, network architectures, and application domains. For instance, assuming access to $2,000$ public images, and for a privacy budget of $\\varepsilon=2,\\delta=10^{-5}$, our technique achieves an accuracy of $75.1\\%$ on CIFAR10, significantly higher than $68.1\\%$ achieved by the state of the art.'}",https://openreview.net{'value': '/pdf/c0e6beab93f95442c51ca026aeacc30a3501c43f.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=sag7iLqPvC,{'value': 'SeedGNN: Graph Neural Network for Supervised Seeded Graph Matching'},Liren Yu; Jiaming Xu; Xiaojun Lin,~Liren_Yu1; ~Jiaming_Xu4; ~Xiaojun_Lin1,,"{'value': 'There is a growing interest in designing Graph Neural Networks (GNNs) for seeded graph matching, which aims to match two unlabeled graphs using only topological information and a small set of seed nodes. However, most previous GNNs for this task use a semi-supervised approach, which requires a large number of seeds and cannot learn knowledge that is transferable to unseen graphs. In contrast, this paper proposes a new supervised approach that can learn from a training set how to match unseen graphs with only a few seeds. Our SeedGNN architecture incorporates several novel designs, inspired by theoretical studies of seeded graph matching: 1) it can learn to compute and use witness-like information from different hops, in a way that can be generalized to graphs of different sizes; 2) it can use easily-matched node-pairs as new seeds to improve the matching in subsequent layers. We evaluate SeedGNN on synthetic and real-world graphs and demonstrate significant performance improvements over both non-learning and learning algorithms in the existing literature. Furthermore, our experiments confirm that the knowledge learned by SeedGNN from training graphs can be generalized to test graphs of different sizes and categories.'}",https://openreview.net{'value': '/pdf/68c5ee0bdb156c24f867c0307bfc9be4feb4d2c1.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=sGvHRYUPeA,{'value': 'Reliable Measures of Spread in High Dimensional Latent Spaces'},Anna Marbut; Katy McKinney-Bock; Travis J Wheeler,~Anna_Marbut1; katymck@gmail.com; twheeler@arizona.edu,,"{'value': ""Understanding geometric properties of the latent spaces of natural language processing models allows the manipulation of these properties for improved performance on downstream tasks. One such property is the amount of data spread in a model's latent space, or how fully the available latent space is being used. We demonstrate that the commonly used measures of data spread, average cosine similarity and a partition function min/max ratio I(V), do not provide reliable metrics to compare the use of latent space across data distributions. We propose and examine six alternative measures of data spread, all of which improve over these current metrics when applied to seven synthetic data distributions. Of our proposed measures, we recommend one principal component-based measure and one entropy-based measure that provide reliable, relative measures of spread and can be used to compare models of different sizes and dimensionalities.""}",https://openreview.net{'value': '/pdf/767c652ab6956f2c1638a94b5916a17821f1a439.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=rxT5EVRNEu,{'value': 'GraphCleaner: Detecting Mislabelled Samples in Popular Graph Learning Benchmarks'},Yuwen Li; Miao Xiong; Bryan Hooi,~Yuwen_Li2; ~Miao_Xiong2; ~Bryan_Hooi1,,"{'value': 'Label errors have been found to be prevalent in popular text, vision, and audio datasets, which heavily influence the safe development and evaluation of machine learning algorithms. Despite increasing efforts towards improving the quality of generic data types, such as images and texts, the problem of mislabel detection in graph data remains underexplored. To bridge the gap, we explore mislabelling issues in popular real-world graph datasets and propose GraphCleaner, a post-hoc method to detect and correct these mislabelled nodes in graph datasets. GraphCleaner combines the novel ideas of 1) Synthetic Mislabel Dataset Generation, which seeks to generate realistic mislabels; and 2) Neighborhood-Aware Mislabel Detection, where neighborhood dependency is exploited in both labels and base classifier predictions. Empirical evaluations on 6 datasets and 6 experimental settings demonstrate that GraphCleaner outperforms the closest baseline, with an average improvement of $0.14$ in F1 score, and $0.16$ in MCC. On real-data case studies, GraphCleaner detects real and previously unknown mislabels in popular graph benchmarks: PubMed, Cora, CiteSeer and OGB-arxiv; we find that at least 6.91% of PubMed data is mislabelled or ambiguous, and simply removing these mislabelled data can boost evaluation performance from 86.71% to 89.11%.'}",https://openreview.net{'value': '/pdf/2954802bff9716b5a5ede11f2a6b92a113a1fed2.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=rSOMtDM1mB,{'value': 'Stable Estimation of Heterogeneous Treatment Effects'},Anpeng Wu; Kun Kuang; Ruoxuan Xiong; Bo Li; Fei Wu,~Anpeng_Wu1; ~Kun_Kuang1; ~Ruoxuan_Xiong1; ~Bo_Li29; ~Fei_Wu1,,"{'value': 'Estimating heterogeneous treatment effects (HTE) is crucial for identifying the variation of treatment effects across individuals or subgroups. Most existing methods estimate HTE by removing the confounding bias from imbalanced treatment assignments. However, these methods may produce unreliable estimates of treatment effects and potentially allocate suboptimal treatment arms for underrepresented populations. To improve the estimation accuracy of HTE for underrepresented populations, we propose a novel Stable CounterFactual Regression (StableCFR) to smooth the population distribution and upsample the underrepresented subpopulations, while balancing confounders between treatment and control groups. Specifically, StableCFR upsamples the underrepresented data using uniform sampling, where each disjoint subpopulation is weighted proportional to the Lebesgue measure of its support. Moreover, StableCFR balances covariates by using an epsilon-greedy matching approach. Empirical results on both synthetic and real-world datasets demonstrate the superior performance of our StableCFR on estimating HTE for underrepresented populations.'}",https://openreview.net{'value': '/pdf/9b91315196306e979446dd87ae9e5d2a35c498eb.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=qszhULcjUh,{'value': 'Retrosynthetic Planning with Dual Value Networks'},Guoqing Liu; Di Xue; Shufang Xie; Yingce Xia; Austin Tripp; Krzysztof Maziarz; Marwin Segler; Tao Qin; Zongzhang Zhang; Tie-Yan Liu,~Guoqing_Liu3; ~Di_Xue1; ~Shufang_Xie1; ~Yingce_Xia1; ~Austin_Tripp1; ~Krzysztof_Maziarz1; ~Marwin_Segler2; ~Tao_Qin1; ~Zongzhang_Zhang1; ~Tie-Yan_Liu1,,"{'value': 'Retrosynthesis, which aims to find a route to synthesize a target molecule from commercially available starting materials, is a critical task in drug discovery and materials design. Recently, the combination of ML-based single-step reaction predictors with multi-step planners has led to promising results. However, the single-step predictors are mostly trained offline to optimize the single-step accuracy, without considering complete routes. Here, we leverage reinforcement learning (RL) to improve the single-step predictor, by using a tree-shaped MDP to optimize complete routes. Specifically, we propose a novel online training algorithm, called Planning with Dual Value Networks (PDVN), which alternates between the planning phase and updating phase. In PDVN, we construct two separate value networks to predict the synthesizability and cost of molecules, respectively. To maintain the single-step accuracy, we design a two-branch network structure for the single-step predictor. On the widely-used USPTO dataset, our PDVN algorithm improves the search success rate of existing multi-step planners (e.g., increasing the success rate from 85.79% to 98.95% for Retro$^{\\ast}$, and reducing the number of model calls by half while solving 99.47% molecules for RetroGraph). Additionally, PDVN helps find shorter synthesis routes (e.g., reducing the average route length from 5.76 to 4.83 for Retro$^{\\ast}$, and from 5.63 to 4.78 for RetroGraph).'}",https://openreview.net{'value': '/pdf/c743bbcd81cc196d2e640d68d0599581de16a6ba.pdf'},{'title_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=qorOnDor89,{'value': 'On the Role of Attention in Prompt-tuning'},Samet Oymak; Ankit Singh Rawat; Mahdi Soltanolkotabi; Christos Thrampoulidis,~Samet_Oymak2; ~Ankit_Singh_Rawat1; ~Mahdi_Soltanolkotabi1; ~Christos_Thrampoulidis1,,"{'value': 'Prompt-tuning is an emerging strategy to adapt large language models (LLM) to downstream tasks by learning a (soft-)prompt parameter from data. Despite its success in LLMs, there is limited theoretical understanding of the power of prompt-tuning and the role of the attention mechanism in prompting. In this work, we explore prompt-tuning for one-layer attention architectures and study contextual mixture-models where each input token belongs to a context-relevant or -irrelevant set. We isolate the role of prompt-tuning through a self-contained prompt-attention model. Our contributions are as follows: (1) We show that softmax-prompt-attention is provably more expressive than softmax-self-attention and linear-prompt-attention under our contextual data model. (2) We analyze the initial trajectory of gradient descent and show that it learns the prompt and prediction head with near-optimal sample complexity and demonstrate how the prompt can provably attend to sparse context-relevant tokens. (3) Assuming a known prompt but an unknown prediction head, we characterize the exact finite sample performance of prompt-attention which reveals the fundamental performance limits and the precise benefit of the context information. We also provide experiments that verify our theoretical insights on real datasets and demonstrate how prompt-tuning enables the model to attend to context-relevant information.'}",https://openreview.net{'value': '/pdf/42c357eb17ba824c308e6f9b38652d2531151f6a.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=qn9ZWZ3Pg7,{'value': 'Nested Elimination: A Simple Algorithm for Best-Item Identification From Choice-Based Feedback'},Junwen Yang; Yifan Feng,~Junwen_Yang1; ~Yifan_Feng2,,"{'value': 'We study the problem of best-item identification from choice-based feedback. In this problem, a company sequentially and adaptively shows display sets to a population of customers and collects their choices. The objective is to identify the most preferred item with the least number of samples and at a high confidence level. We propose an elimination-based algorithm, namely Nested Elimination (NE), which is inspired by the nested structure implied by the information-theoretic lower bound. NE is simple in structure, easy to implement, and has a strong theoretical guarantee for sample complexity. Specifically, NE utilizes an innovative elimination criterion and circumvents the need to solve any complex combinatorial optimization problem. We provide an instance-specific and non-asymptotic bound on the expected sample complexity of NE. We also show NE achieves high-order worst-case asymptotic optimality. Finally, numerical experiments from both synthetic and real data corroborate our theoretical findings.'}",https://openreview.net{'value': '/pdf/a76c5b58e5ab85d5b601f9c689835e8368e67f40.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=qmwtMuRh1j,{'value': 'Benign Overfitting in Two-layer ReLU Convolutional Neural Networks'},Yiwen Kou; Zixiang Chen; Yuanzhou Chen; Quanquan Gu,~Yiwen_Kou1; ~Zixiang_Chen1; ~Yuanzhou_Chen1; ~Quanquan_Gu1,,"{'value': 'Modern deep learning models with great expressive power can be trained to overfit the training data but still generalize well. This phenomenon is referred to as benign overfitting. Recently, a few studies have attempted to theoretically understand benign overfitting in neural networks. However, these works are either limited to neural networks with smooth activation functions or to the neural tangent kernel regime. How and when benign overfitting can occur in ReLU neural networks remains an open problem. In this work, we seek to answer this question by establishing algorithm-dependent risk bounds for learning two-layer ReLU convolutional neural networks with label-flipping noise. We show that, under mild conditions, the neural network trained by gradient descent can achieve near-zero training loss and Bayes optimal test risk. Our result also reveals a sharp transition between benign and harmful overfitting under different conditions on data distribution in terms of test risk. Experiments on synthetic data back up our theory.'}",https://openreview.net{'value': '/pdf/26b1e832d7003698f407d1d83c8abc93544d6cd9.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=qEcJpq2Kjr,{'value': 'Complementary Attention for Multi-Agent Reinforcement Learning'},Jianzhun Shao; Hongchang Zhang; Yun Qu; Chang Liu; Shuncheng He; Yuhang Jiang; Xiangyang Ji,~Jianzhun_Shao1; ~Hongchang_Zhang1; ~Yun_Qu2; ~Chang_Liu9; ~Shuncheng_He1; ~Yuhang_Jiang3; ~Xiangyang_Ji1,,"{'value': 'In cooperative multi-agent reinforcement learning, centralized training with decentralized execution (CTDE) shows great promise for a trade-off between independent Q-learning and joint action learning. However, vanilla CTDE methods assumed a fixed number of agents could hardly adapt to real-world scenarios where dynamic team compositions typically suffer from dramatically variant partial observability. Specifically, agents with extensive sight ranges are prone to be affected by trivial environmental substrates, dubbed the ""distracted attention"" issue; ones with limited observation can hardly sense their teammates, degrading the cooperation quality. In this paper, we propose Complementary Attention for Multi-Agent reinforcement learning (CAMA), which applies a divide-and-conquer strategy on input entities accompanied with the complementary attention of enhancement and replenishment. Concretely, to tackle the distracted attention issue, highly contributed entities\' attention is enhanced by the execution-related representation extracted via action prediction with an inverse model. For better out-of-sight-range cooperation, the lowly contributed ones are compressed to brief messages with a conditional mutual information estimator. Our CAMA facilitates stable and sustainable teamwork, which is justified by the impressive results reported on the challenging StarCraftII, MPE, and Traffic Junction benchmarks.'}",https://openreview.net{'value': '/pdf/918014d3e2c7c01d11c8b77f7bc80773cd1198d7.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=q7hlNyetZ2,{'value': 'Causal Modeling of Policy Interventions From Treatment–Outcome Sequences'},Çağlar Hızlı; S. T. John; Anne Tuulikki Juuti; Tuure Tapani Saarinen; Kirsi Hannele Pietiläinen; Pekka Marttinen,~Çağlar_Hızlı1; ~S._T._John1; ~Anne_Tuulikki_Juuti1; ~Tuure_Tapani_Saarinen1; ~Kirsi_Hannele_Pietiläinen1; ~Pekka_Marttinen1,,"{'value': 'A *treatment policy* defines when and what treatments are applied to affect some outcome of interest. Data-driven decision-making requires the ability to predict *what happens if a policy is changed*. Existing methods that predict how the outcome evolves under different scenarios assume that the tentative sequences of future treatments are fixed in advance, while in practice the treatments are determined stochastically by a policy and may depend, for example, on the efficiency of previous treatments. Therefore, the current methods are not applicable if the treatment policy is unknown or a counterfactual analysis is needed. To handle these limitations, we model the treatments and outcomes jointly in continuous time, by combining Gaussian processes and point processes. Our model enables the estimation of a treatment policy from observational sequences of treatments and outcomes, and it can predict the interventional and counterfactual progression of the outcome *after an intervention on the treatment policy* (in contrast with the causal effect of a single treatment). We show with real-world and semi-synthetic data on blood glucose progression that our method can answer causal queries more accurately than existing alternatives.'}",https://openreview.net{'value': '/pdf/708ad217223c7e9981ef0a75743e52fc1fe6d123.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=q2L5r7WEHT,{'value': 'Topological Point Cloud Clustering'},Vincent Peter Grande; Michael T Schaub,~Vincent_Peter_Grande1; ~Michael_T_Schaub1,,"{'value': 'We present Topological Point Cloud Clustering (TPCC), a new method to cluster points in an arbitrary point cloud based on their contribution to global topological features. TPCC synthesizes desirable features from spectral clustering and topological data analysis and is based on considering the spectral properties of a simplicial complex associated to the considered point cloud. As it is based on considering sparse eigenvector computations, TPCC is similarly easy to interpret and implement as spectral clustering. However, by focusing not just on a single matrix associated to a graph created from the point cloud data, but on a whole set of Hodge-Laplacians associated to an appropriately constructed simplicial complex, we can leverage a far richer set of topological features to characterize the data points within the point cloud and benefit from the relative robustness of topological techniques against noise. We test the performance of TPCC on both synthetic and real-world data and compare it with classical spectral clustering.'}",https://openreview.net{'value': '/pdf/75c683d614bb32c46f28615c6bfcc57daed6fde6.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=priTMs7n6e,{'value': 'Improved Policy Evaluation for Randomized Trials of Algorithmic Resource Allocation'},Aditya Mate; Bryan Wilder; Aparna Taneja; Milind Tambe,~Aditya_Mate1; ~Bryan_Wilder2; ~Aparna_Taneja3; ~Milind_Tambe1,,"{'value': 'We consider the task of evaluating policies of algorithmic resource allocation through randomized controlled trials (RCTs). Such policies are tasked with optimizing the utilization of limited intervention resources, with the goal of maximizing the benefits derived. Evaluation of such allocation policies through RCTs proves difficult, notwithstanding the scale of the trial, because the individuals’ outcomes are inextricably interlinked through resource constraints controlling the policy decisions. Our key contribution is to present a new estimator leveraging our proposed novel concept, that involves retrospective reshuffling of participants across experimental arms at the end of an RCT. We identify conditions under which such reassignments are permissible and can be leveraged to construct counterfactual trials, whose outcomes can be accurately ascertained, for free. We prove theoretically that such an estimator is more accurate than common estimators based on sample means -- we show that it returns an unbiased estimate and simultaneously reduces variance. We demonstrate the value of our approach through empirical experiments on synthetic, semisynthetic as well as real case study data and show improved estimation accuracy across the board.'}",https://openreview.net{'value': '/pdf/8e00bfdb35ddb6904618129cf345ad37ed301c43.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=prMTSnjVuR,{'value': 'PCA-based Multi-Task Learning: a Random Matrix Approach'},Malik Tiomoko; Romain Couillet; Frederic Pascal,~Malik_Tiomoko1; ~Romain_Couillet1; ~Frederic_Pascal1,,"{'value': 'The article proposes and theoretically analyses a *computationally efficient* multi-task learning (MTL) extension of popular principal component analysis (PCA)-based supervised learning schemes. The analysis reveals that (i) by default, learning may dramatically fail by suffering from *negative transfer*, but that (ii) simple counter-measures on data labels avert negative transfer and necessarily result in improved performances. Supporting experiments on synthetic and real data benchmarks show that the proposed method achieves comparable performance with state-of-the-art MTL methods but at a *significantly reduced computational cost*.'}",https://openreview.net{'value': '/pdf/9933919ce38adfb31205a1877f377eef6bd52aae.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=pLky79p1Ne,{'value': 'Parallel Online Clustering of Bandits via Hedonic Game'},Xiaotong Cheng; Cheng Pan; Setareh Maghsudi,~Xiaotong_Cheng1; ~Cheng_Pan3; ~Setareh_Maghsudi1,,"{'value': ""Contextual bandit algorithms appear in several applications, such as online advertisement and recommendation systems like personalized education or personalized medicine. Individually-tailored recommendations boost the performance of the underlying application; nevertheless, providing individual suggestions becomes costly and even implausible as the number of users grows. As such, to efficiently serve the demands of several users in modern applications, it is imperative to identify the underlying users' clusters, i.e., the groups of users for which a single recommendation might be (near-)optimal. We propose CLUB-HG, a novel algorithm that integrates a game-theoretic approach into clustering inference. Our algorithm achieves Nash equilibrium at each inference step and discovers the underlying clusters. We also provide regret analysis within a standard linear stochastic noise setting. Finally, experiments on synthetic and real-world datasets show the superior performance of our proposed algorithm compared to the state-of-the-art algorithms.""}",https://openreview.net{'value': '/pdf/8d5f08954b3ec6640ec8e62be0c06da4ff8c2d47.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=pLQoqbUTue,{'value': 'Context-Aware Bayesian Network Actor-Critic Methods for Cooperative Multi-Agent Reinforcement Learning'},Dingyang Chen; Qi Zhang,~Dingyang_Chen1; ~Qi_Zhang12,,"{'value': ""Executing actions in a correlated manner is a common strategy for human coordination that often leads to better cooperation, which is also potentially beneficial for cooperative multi-agent reinforcement learning (MARL). However, the recent success of MARL relies heavily on the convenient paradigm of purely decentralized execution, where there is no action correlation among agents for scalability considerations. In this work, we introduce a Bayesian network to inaugurate correlations between agents' action selections in their joint policy. Theoretically, we establish a theoretical justification for why action dependencies are beneficial by deriving the multi-agent policy gradient formula under such a Bayesian network joint policy and proving its global convergence to Nash equilibria under tabular softmax policy parameterization in cooperative Markov games. Further, by equipping existing MARL algorithms with a recent method of differentiable directed acyclic graphs (DAGs), we develop practical algorithms to learn the context-aware Bayesian network policies in scenarios with partial observability and various difficulty. We also dynamically decrease the sparsity of the learned DAG throughout the training process, which leads to weakly or even purely independent policies for decentralized execution. Empirical results on a range of MARL benchmarks show the benefits of our approach.""}",https://openreview.net{'value': '/pdf/6504bfbff2b8df19705512b87746d77d7413d3fd.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=oke1MUPK2l,{'value': 'Learning Control-Oriented Dynamical Structure from Data'},Spencer M. Richards; Jean-Jacques Slotine; Navid Azizan; Marco Pavone,~Spencer_M._Richards1; ~Jean-Jacques_Slotine1; ~Navid_Azizan1; ~Marco_Pavone1,,"{'value': 'Even for known nonlinear dynamical systems, feedback controller synthesis is a difficult problem that often requires leveraging the particular structure of the dynamics to induce a stable closed-loop system. For general nonlinear models, including those fit to data, there may not be enough known structure to reliably synthesize a stabilizing feedback controller. In this paper, we discuss a state-dependent nonlinear tracking controller formulation based on a state-dependent Riccati equation for general nonlinear control-affine systems. This formulation depends on a nonlinear factorization of the system of vector fields defining the control-affine dynamics, which always exists under mild smoothness assumptions. We propose a method for learning this factorization from a finite set of data. On a variety of simulated nonlinear dynamical systems, we empirically demonstrate the efficacy of learned versions of this controller in stable trajectory tracking. Alongside our learning method, we evaluate recent ideas in jointly learning a controller and stabilizability certificate for known dynamical systems; we show experimentally that such methods can be frail in comparison.'}",https://openreview.net{'value': '/pdf/1636b554cf381f8f5b9e6ef96da0c9f988c0edae.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=oUeo2uG1AZ,{'value': 'N$\\text{A}^\\text{2}$Q: Neural Attention Additive Model for Interpretable Multi-Agent Q-Learning'},Zichuan Liu; Yuanyang Zhu; Chunlin Chen,~Zichuan_Liu3; ~Yuanyang_Zhu1; ~Chunlin_Chen1,,"{'value': 'Value decomposition is widely used in cooperative multi-agent reinforcement learning, however, its implicit credit assignment mechanism is not yet fully understood due to black-box networks. In this work, we study an interpretable value decomposition framework via the family of generalized additive models. We present a novel method, named Neural Attention Additive Q-learning (N$\\text{A}^\\text{2}$Q), providing inherent intelligibility of collaboration behavior. N$\\text{A}^\\text{2}$Q can explicitly factorize the optimal joint policy induced by enriching shape functions to model all possible coalition of agents into individual policies. Moreover, we construct the identity semantics to promote estimating credits together with the global state and individual value functions, where local semantic masks help us diagnose whether each agent captures the relevant-task information. Extensive experiments show that N$\\text{A}^\\text{2}$Q consistently achieves superior performance compared to different state-of-the-art methods on all challenging tasks, while yielding human-like interpretability.'}",https://openreview.net{'value': '/pdf/e057ff6a1a1a9684f7645b07efbdaeda28873680.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=oR2IsISm1X,{'value': 'Differentiable Multi-Target Causal Bayesian Experimental Design'},Panagiotis Tigas; Yashas Annadani; Desi R. Ivanova; Andrew Jesson; Yarin Gal; Adam Foster; Stefan Bauer,~Panagiotis_Tigas1; ~Yashas_Annadani1; ~Desi_R._Ivanova1; ~Andrew_Jesson1; ~Yarin_Gal1; ~Adam_Foster1; ~Stefan_Bauer1,,"{'value': 'We introduce a gradient-based approach for the problem of Bayesian optimal experimental design to learn causal models in a batch setting --- a critical component for causal discovery from finite data where interventions can be costly or risky. Existing methods rely on greedy approximations to construct a batch of experiments while using black-box methods to optimize over a *single target-state* pair to intervene with. In this work, we completely dispose of the black-box optimization techniques and greedy heuristics and instead propose a conceptually simple end-to-end gradient-based optimization procedure to acquire a set of optimal intervention target-value pairs. Such a procedure enables parameterization of the design space to efficiently optimize over a batch of *multi-target-state* interventions, a setting which has hitherto not been explored due to its complexity. We demonstrate that our proposed method outperforms baselines and existing acquisition strategies in both single-target and multi-target settings across a number of synthetic datasets.'}",https://openreview.net{'value': '/pdf/619b727a9e9cf2d63f5f93c0ecf1903e364dd326.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=o7BOzuqFi2,{'value': 'The Ideal Continual Learner: An Agent That Never Forgets'},Liangzu Peng; Paris Giampouras; Rene Vidal,~Liangzu_Peng2; ~Paris_Giampouras1; ~Rene_Vidal1,,"{'value': 'The goal of continual learning is to find a model that solves multiple learning tasks which are presented sequentially to the learner. A key challenge in this setting is that the learner may ""forget"" how to solve a previous task when learning a new task, a phenomenon known as catastrophic forgetting. To address this challenge, many practical methods have been proposed, including memory-based, regularization-based and expansion-based methods. However, a rigorous theoretical understanding of these methods remains elusive. This paper aims to bridge this gap between theory and practice by proposing a new continual learning framework called ""Ideal Continual Learner"" (ICL), which is guaranteed to avoid catastrophic forgetting by construction. We show that ICL unifies multiple well-established continual learning methods and gives new theoretical insights into the strengths and weaknesses of these methods. We also derive generalization bounds for ICL which allow us to theoretically quantify ""how rehearsal affects generalization"". Finally, we connect ICL to several classic subjects and research topics of modern interest, which allows us to make historical remarks and inspire future directions.'}",https://openreview.net{'value': '/pdf/b868e35d80ce46cc33b35af3ea51f9ef45936b03.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=nqvBUsnC5L,{'value': 'Invariance in Policy Optimisation and Partial Identifiability in Reward Learning'},Joar Max Viktor Skalse; Matthew Farrugia-Roberts; Stuart Russell; Alessandro Abate; Adam Gleave,~Joar_Max_Viktor_Skalse1; ~Matthew_Farrugia-Roberts1; ~Stuart_Russell1; ~Alessandro_Abate1; ~Adam_Gleave1,,"{'value': 'It is often very challenging to manually design reward functions for complex, real-world tasks. To solve this, one can instead use reward learning to infer a reward function from data. However, there are often multiple reward functions that fit the data equally well, even in the infinite-data limit. This means that the reward function is only partially identifiable. In this work, we formally characterise the partial identifiability of the reward function given several popular reward learning data sources, including expert demonstrations and trajectory comparisons. We also analyse the impact of this partial identifiability for several downstream tasks, such as policy optimisation. We unify our results in a framework for comparing data sources and downstream tasks by their invariances, with implications for the design and selection of data sources for reward learning.'}",https://openreview.net{'value': '/pdf/4470d159a5e3ef29b7f92cdf28aa41b14a871885.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=nmVOTsQGR9,{'value': 'Personalized Federated Learning under Mixture of Distributions'},Yue Wu; SHUAICHENG ZHANG; Wenchao Yu; Yanchi Liu; Quanquan Gu; Dawei Zhou; Haifeng Chen; Wei Cheng,~Yue_Wu12; ~SHUAICHENG_ZHANG1; ~Wenchao_Yu1; ~Yanchi_Liu1; ~Quanquan_Gu1; ~Dawei_Zhou1; ~Haifeng_Chen1; ~Wei_Cheng1,,"{'value': 'The recent trend towards Personalized Federated Learning (PFL) has garnered significant attention as it allows for the training of models that are tailored to each client while maintaining data privacy. However, current PFL techniques primarily focus on modeling the conditional distribution heterogeneity (i.e. concept shift), which can result in suboptimal performance when the distribution of input data across clients diverges (i.e. covariate shift). Additionally, these techniques often lack the ability to adapt to unseen data, further limiting their effectiveness in real-world scenarios. To address these limitations, we propose a novel approach, FedGMM, which utilizes Gaussian mixture models (GMM) to effectively fit the input data distributions across diverse clients. The model parameters are estimated by maximum likelihood estimation utilizing a federated Expectation-Maximization algorithm, which is solved in closed form and does not assume gradient similarity. Furthermore, FedGMM possesses an additional advantage of adapting to new clients with minimal overhead, and it also enables uncertainty quantification. Empirical evaluations on synthetic and benchmark datasets demonstrate the superior performance of our method in both PFL classification and novel sample detection.'}",https://openreview.net{'value': '/pdf/920a84d1c61ef5e8445ed463c68160eec49ef278.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=nHCfIQu2tV,{'value': 'RACE: Improve Multi-Agent Reinforcement Learning with Representation Asymmetry and Collaborative Evolution'},Pengyi Li; Jianye HAO; Hongyao Tang; YAN ZHENG; Xian Fu,~Pengyi_Li1; ~Jianye_HAO1; ~Hongyao_Tang1; ~YAN_ZHENG1; ~Xian_Fu1,,"{'value': 'Multi-Agent Reinforcement Learning (MARL) has demonstrated its effectiveness in learning collaboration, but it often struggles with low-quality reward signals and high non-stationarity. In contrast, Evolutionary Algorithm (EA) has shown better convergence, robustness, and signal quality insensitivity. This paper introduces a hybrid framework, Representation Asymmetry and Collaboration Evolution (RACE), which combines EA and MARL for efficient collaboration. RACE maintains a MARL team and a population of EA teams. To enable efficient knowledge sharing and policy exploration, RACE decomposes the policies of different teams controlling the same agent into a shared nonlinear observation representation encoder and individual linear policy representations. To address the partial observation issue, we introduce Value-Aware Mutual Information Maximization to enhance the shared representation with useful information about superior global states. EA evolves the population using novel agent-level crossover and mutation operators, offering diverse experiences for MARL. Concurrently, MARL optimizes its policies and injects them into the population for evolution. The experiments on challenging continuous and discrete tasks demonstrate that RACE significantly improves the basic algorithms, consistently outperforming other algorithms. Our code is available at https://github.com/yeshenpy/RACE.'}",https://openreview.net{'value': '/pdf/96aa8ae5c2cd877335f152e4a77a44520cb347b9.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=mjYZd6SgZS,{'value': 'On the Statistical Benefits of Temporal Difference Learning'},David Cheikhi; Daniel Russo,~David_Cheikhi1; ~Daniel_Russo1,,"{'value': ""Given a dataset on actions and resulting long-term rewards, a direct estimation approach fits value functions that minimize prediction error on the training data. Temporal difference learning (TD) methods instead fit value functions by minimizing the degree of temporal inconsistency between estimates made at successive time-steps. Focusing on finite state Markov chains, we provide a crisp asymptotic theory of the statistical advantages of this approach. First, we show that an intuitive inverse trajectory pooling coefficient completely characterizes the percent reduction in mean-squared error of value estimates. Depending on problem structure, the reduction could be enormous or nonexistent. Next, we prove that there can be dramatic improvements in estimates of the difference in value-to-go for two states: TD's errors are bounded in terms of a novel measure -- the problem's trajectory crossing time -- which can be much smaller than the problem's time horizon.""}",https://openreview.net{'value': '/pdf/a9bc8e97a916eb93f7a2be1ef9ff504844cf7d50.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=mGUJMqjDwE,{'value': 'Provably Learning Object-Centric Representations'},Jack Brady; Roland S. Zimmermann; Yash Sharma; Bernhard Schölkopf; Julius von Kügelgen; Wieland Brendel,~Jack_Brady1; ~Roland_S._Zimmermann1; ~Yash_Sharma1; ~Bernhard_Schölkopf1; ~Julius_von_Kügelgen2; ~Wieland_Brendel1,,"{'value': ""Learning structured representations of the visual world in terms of objects promises to significantly improve the generalization abilities of current machine learning models. While recent efforts to this end have shown promising empirical progress, a theoretical account of when unsupervised object-centric representation learning is possible is still lacking. Consequently, understanding the reasons for the success of existing object-centric methods as well as designing new theoretically grounded methods remains challenging. In the present work, we analyze when object-centric representations can provably be learned without supervision. To this end, we first introduce two assumptions on the generative process for scenes comprised of several objects, which we call compositionality and irreducibility. Under this generative process, we prove that the ground-truth object representations can be identified by an invertible and compositional inference model, even in the presence of dependencies between objects. We empirically validate our results through experiments on synthetic data. Finally, we provide evidence that our theory holds predictive power for existing object-centric models by showing a close correspondence between models' compositionality and invertibility and their empirical identifiability.""}",https://openreview.net{'value': '/pdf/efa54b0c0d41f86b280d7fd2e2363774cde24952.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=m21SgZnBWZ,{'value': 'Investigating the Role of Model-Based Learning in Exploration and Transfer'},Jacob C Walker; Eszter Vértes; Yazhe Li; Gabriel Dulac-Arnold; Ankesh Anand; Theophane Weber; Jessica B Hamrick,~Jacob_C_Walker1; ~Eszter_Vértes1; ~Yazhe_Li2; ~Gabriel_Dulac-Arnold1; ~Ankesh_Anand1; ~Theophane_Weber1; ~Jessica_B_Hamrick1,,"{'value': 'State of the art reinforcement learning has enabled training agents on tasks of ever increasing complexity. However, the current paradigm tends to favor training agents from scratch on every new task or on collections of tasks with a view towards generalizing to novel task configurations. The former suffers from poor data efficiency while the latter is difficult when test tasks are out-of-distribution. Agents that can effectively transfer their knowledge about the world pose a potential solution to these issues. In this paper, we investigate transfer learning in the context of model-based agents. Specifically, we aim to understand where exactly environment models have an advantage and why. We find that a model-based approach outperforms controlled model-free baselines for transfer learning. Through ablations, we show that both the policy and dynamics model learnt through exploration matter for successful transfer. We demonstrate our results across three domains which vary in their requirements for transfer: in-distribution procedural (Crafter), in-distribution identical (RoboDesk), and out-of-distribution (Meta-World). Our results show that intrinsic exploration combined with environment models present a viable direction towards agents that are self-supervised and able to generalize to novel reward functions.'}",https://openreview.net{'value': '/pdf/bfabb21ed814d1095bdb59d6b9e77be5aa8af19d.pdf'},{'abstract_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=lwodnXJzu6,{'value': 'Are Neurons Actually Collapsed? On the Fine-Grained Structure in Neural Representations'},Yongyi Yang; Jacob Steinhardt; Wei Hu,~Yongyi_Yang1; ~Jacob_Steinhardt1; ~Wei_Hu1,,"{'value': 'Recent work has observed an intriguing ""Neural Collapse\'\' phenomenon in well-trained neural networks, where the last-layer representations of training samples with the same label collapse into each other. This appears to suggest that the last-layer representations are completely determined by the labels, and do not depend on the intrinsic structure of input distribution. We provide evidence that this is not a complete description, and that the apparent collapse hides important fine-grained structure in the representations. Specifically, even when representations apparently collapse, the small amount of remaining variation can still faithfully and accurately captures the intrinsic structure of input distribution. As an example, if we train on CIFAR-10 using only 5 coarse-grained labels (by combining two classes into one super-class) until convergence, we can reconstruct the original 10-class labels from the learned representations via unsupervised clustering. The reconstructed labels achieve 93% accuracy on the CIFAR-10 test set, nearly matching the normal CIFAR-10 accuracy for the same architecture. We also provide an initial theoretical result showing the fine-grained representation structure in a simplified synthetic setting. Our results show concretely how the structure of input data can play a significant role in determining the fine-grained structure of neural representations, going beyond what Neural Collapse predicts.'}",https://openreview.net{'value': '/pdf/f1beb437e9c06f6bf03bebe5689d97a666613ebc.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=laR6abCxIu,{'value': 'A Coupled Flow Approach to Imitation Learning'},Gideon Joseph Freund; Elad Sarafian; Sarit Kraus,~Gideon_Joseph_Freund1; ~Elad_Sarafian1; ~Sarit_Kraus1,,"{'value': 'In reinforcement learning and imitation learning, an object of central importance is the state distribution induced by the policy. It plays a crucial role in the policy gradient theorem, and references to it--along with the related state-action distribution--can be found all across the literature. Despite its importance, the state distribution is mostly discussed indirectly and theoretically, rather than being modeled explicitly. The reason being an absence of appropriate density estimation tools. In this work, we investigate applications of a normalizing flow based model for the aforementioned distributions. In particular, we use a pair of flows coupled through the optimality point of the Donsker-Varadhan representation of the Kullback-Leibler (KL) divergence, for distribution matching based imitation learning. Our algorithm, Coupled Flow Imitation Learning (CFIL), achieves state-of-the-art performance on benchmark tasks with a single expert trajectory and extends naturally to a variety of other settings, including the subsampled and state-only regimes.'}",https://openreview.net{'value': '/pdf/1b6d266c7c9f1a02aa65e7508e7359b1dae2e4a3.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=lJaAPdXgxL,{'value': 'Comparison of meta-learners for estimating multi-valued treatment heterogeneous effects'},Naoufal Acharki; Ramiro Lugo; Antoine Bertoncello; Josselin Garnier,~Naoufal_Acharki1; r.lugocasados.17@aberdeen.ac.uk; antoine.bertoncello@totalenergies.com; ~Josselin_Garnier1,,"{'value': 'Conditional Average Treatment Effects (CATE) estimation is one of the main challenges in causal inference with observational data. In addition to Machine Learning based-models, nonparametric estimators called meta-learners have been developed to estimate the CATE with the main advantage of not restraining the estimation to a specific supervised learning method. This task becomes, however, more complicated when the treatment is not binary as some limitations of the naive extensions emerge. This paper looks into meta-learners for estimating the heterogeneous effects of multi-valued treatments. We consider different meta-learners, and we carry out a theoretical analysis of their error upper bounds as functions of important parameters such as the number of treatment levels, showing that the naive extensions do not always provide satisfactory results. We introduce and discuss meta-learners that perform well as the number of treatments increases. We empirically confirm the strengths and weaknesses of those methods with synthetic and semi-synthetic datasets.'}",https://openreview.net{'value': '/pdf/90233234cc53e3e87ddeefc15ccb0b3e966091ef.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=kgxO5itnvU,{'value': 'Stochastic Policy Gradient Methods: Improved Sample Complexity for Fisher-non-degenerate Policies'},Ilyas Fatkhullin; Anas Barakat; Anastasia Kireeva; Niao He,~Ilyas_Fatkhullin1; ~Anas_Barakat1; ~Anastasia_Kireeva1; ~Niao_He3,,"{'value': 'Recently, the impressive empirical success of policy gradient (PG) methods has catalyzed the development of their theoretical foundations. Despite the huge efforts directed at the design of efficient stochastic PG-type algorithms, the understanding of their convergence to a globally optimal policy is still limited. In this work, we develop improved global convergence guarantees for a general class of Fisher-non-degenerate parameterized policies which allows to address the case of continuous state action spaces. First, we propose a Normalized Policy Gradient method with Implicit Gradient Transport (N-PG-IGT) and derive a $\\tilde{\\mathcal{O}}(\\varepsilon^{-2.5})$ sample complexity of this method for finding a global $\\varepsilon$-optimal policy. Improving over the previously known $\\tilde{\\mathcal{O}}(\\varepsilon^{-3})$ complexity, this algorithm does not require the use of importance sampling or second-order information and samples only one trajectory per iteration. Second, we further improve this complexity to $\\tilde{ \\mathcal{\\mathcal{O}} }(\\varepsilon^{-2})$ by considering a Hessian-Aided Recursive Policy Gradient ((N)-HARPG) algorithm enhanced with a correction based on a Hessian-vector product. Interestingly, both algorithms are $(i)$ simple and easy to implement: single-loop, do not require large batches of trajectories and sample at most two trajectories per iteration; $(ii)$ computationally and memory efficient: they do not require expensive subroutines at each iteration and can be implemented with memory linear in the dimension of parameters.'}",https://openreview.net{'value': '/pdf/042d0637681e238f7103a26b57724a0c7a1376b3.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=kWS8mpioS9,{'value': 'Efficient RL via Disentangled Environment and Agent Representations'},Kevin Gmelin; Shikhar Bahl; Russell Mendonca; Deepak Pathak,~Kevin_Gmelin1; ~Shikhar_Bahl1; ~Russell_Mendonca1; ~Deepak_Pathak1,,"{'value': 'Agents that are aware of the separation between the environments and themselves can leverage this understanding to form effective representations of visual input. We propose an approach for learning such structured representations for RL algorithms, using visual knowledge of the agent, which is often inexpensive to obtain, such as its shape or mask. This is incorporated into the RL objective using a simple auxiliary loss. We show that our method, SEAR (Structured Environment-Agent Representations), outperforms state-of-the-art model-free approaches over 18 different challenging visual simulation environments spanning 5 different robots.'}",https://openreview.net{'value': '/pdf/06ab7aa959437088fc7431901b98b4d52ef41123.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=kP2p67F4G7,{'value': 'Neural Algorithmic Reasoning with Causal Regularisation'},Beatrice Bevilacqua; Kyriacos Nikiforou; Borja Ibarz; Ioana Bica; Michela Paganini; Charles Blundell; Jovana Mitrovic; Petar Veličković,~Beatrice_Bevilacqua1; ~Kyriacos_Nikiforou1; ~Borja_Ibarz1; ~Ioana_Bica1; ~Michela_Paganini1; ~Charles_Blundell1; ~Jovana_Mitrovic1; ~Petar_Veličković1,,"{'value': ""Recent work on neural algorithmic reasoning has investigated the reasoning capabilities of neural networks, effectively demonstrating they can learn to execute classical algorithms on unseen data coming from the train distribution. However, the performance of existing neural reasoners significantly degrades on out-of-distribution (OOD) test data, where inputs have larger sizes. In this work, we make an important observation: there are many different inputs for which an algorithm will perform certain intermediate computations identically. This insight allows us to develop data augmentation procedures that, given an algorithm's intermediate trajectory, produce inputs for which the target algorithm would have exactly the same next trajectory step. We ensure invariance in the next-step prediction across such inputs, by employing a self-supervised objective derived by our observation, formalised in a causal graph. We prove that the resulting method, which we call Hint-ReLIC, improves the OOD generalisation capabilities of the reasoner. We evaluate our method on the CLRS algorithmic reasoning benchmark, where we show up to 3x improvements on the OOD test data.""}",https://openreview.net{'value': '/pdf/4f8bb50b7e82104814da4e1c7312991c9e84534f.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=kEnDJdTM9A,{'value': 'DiscoBAX - Discovery of optimal intervention sets in genomic experiment design'},Clare Lyle; Arash Mehrjou; Pascal Notin; Andrew Jesson; Stefan Bauer; Yarin Gal; Patrick Schwab,~Clare_Lyle1; ~Arash_Mehrjou1; ~Pascal_Notin1; ~Andrew_Jesson1; ~Stefan_Bauer1; ~Yarin_Gal1; ~Patrick_Schwab1,,"{'value': 'The discovery of therapeutics to treat genetically-driven pathologies relies on identifying genes involved in the underlying disease mechanism. Existing approaches search over the billions of potential interventions to maximize the expected influence on the target phenotype. However, to reduce the risk of failure in future stages of trials, practical experiment design aims to find a set of interventions that maximally change a target phenotype via diverse mechanisms. We propose DiscoBAX - a sample-efficient method for maximizing the rate of significant discoveries per experiment while simultaneously probing for a wide range of diverse mechanisms during a genomic experiment campaign. We provide theoretical guarantees of optimality under standard assumptions, and conduct a comprehensive experimental evaluation covering both synthetic as well as real-world experimental design tasks. DiscoBAX outperforms existing state-of-the-art methods for experimental design, selecting effective and diverse perturbations in biological systems.'}",https://openreview.net{'value': '/pdf/715d857c31dd7cbb9a0f36725ebd810b1157c065.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=k24luy3Azi,{'value': 'Performative Recommendation: Diversifying Content via Strategic Incentives'},Itay Eilat; Nir Rosenfeld,~Itay_Eilat1; ~Nir_Rosenfeld2,,"{'value': 'The primary goal in recommendation is to suggest relevant content to users, but optimizing for accuracy often results in recommendations that lack diversity. To remedy this, conventional approaches such as re-ranking improve diversity by *presenting* more diverse items. Here we argue that to promote inherent and prolonged diversity, the system must encourage its *creation*. Towards this, we harness the performative nature of recommendation, and show how learning can incentivize strategic content creators to create diverse content. Our approach relies on a novel form of regularization that anticipates strategic changes to content, and penalizes for content homogeneity. We provide analytic and empirical results that demonstrate when and how diversity can be incentivized, and experimentally demonstrate the utility of our approach on synthetic and semi-synthetic data.'}",https://openreview.net{'value': '/pdf/09b2bf3224e3fd04362d1e6c572cee69ee888dc6.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=jrYVLd3wqk,{'value': 'Safe Offline Reinforcement Learning with Real-Time Budget Constraints'},Qian Lin; Bo Tang; Zifan Wu; Chao Yu; Shangqin Mao; Qianlong Xie; Xingxing Wang; Dong Wang,~Qian_Lin3; ~Bo_Tang3; ~Zifan_Wu2; ~Chao_Yu2; maoshangqin@meituan.com; xieqianlong@meituan.com; wangxingxing04@meituan.com; wangdong07@meituan.com,,"{'value': 'Aiming at promoting the safe real-world deployment of Reinforcement Learning (RL), research on safe RL has made significant progress in recent years. However, most existing works in the literature still focus on the online setting where risky violations of the safety budget are likely to be incurred during training. Besides, in many realworld applications, the learned policy is required to respond to dynamically determined safety budgets (i.e., constraint threshold) in real time. In this paper, we target at the above real-time budget constraint problem under the offline setting, and propose Trajectory-based REal-time Budget Inference (TREBI) as a novel solution that approaches this problem from the perspective of trajectory distribution. Theoretically, we prove an error bound of the estimation on the episodic reward and cost under the offline setting and thus provide a performance guarantee for TREBI. Empirical results on a wide range of simulation tasks and a real-world large-scale advertising application demonstrate the capability of TREBI in solving real-time budget constraint problems under offline settings.'}",https://openreview.net{'value': '/pdf/6eb5b8a52967348636d768351f8c59450136f554.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=jjpsFetXJp,{'value': 'Neural Collapse in Deep Linear Networks: From Balanced to Imbalanced Data'},Hien Dang; Tho Tran Huu; Stanley Osher; Hung Tran-The; Nhat Ho; Tan Minh Nguyen,~Hien_Dang1; ~Tho_Tran_Huu1; ~Stanley_Osher1; ~Hung_Tran-The1; ~Nhat_Ho1; ~Tan_Minh_Nguyen1,,"{'value': ""Modern deep neural networks have achieved impressive performance on tasks from image classification to natural language processing. Surprisingly, these complex systems with massive amounts of parameters exhibit the same structural properties in their last-layer features and classifiers across canonical datasets when training until convergence. In particular, it has been observed that the last-layer features collapse to their class-means, and those class-means are the vertices of a simplex Equiangular Tight Frame (ETF). This phenomenon is known as Neural Collapse (NC). Recent papers have theoretically shown that NC emerges in the global minimizers of training problems with the simplified ``unconstrained feature model''. In this context, we take a step further and prove the NC occurrences in deep linear networks for the popular mean squared error (MSE) and cross entropy (CE) losses, showing that global solutions exhibit NC properties across the linear layers. Furthermore, we extend our study to imbalanced data for MSE loss and present the first geometric analysis of NC under bias-free setting. Our results demonstrate the convergence of the last-layer features and classifiers to a geometry consisting of orthogonal vectors, whose lengths depend on the amount of data in their corresponding classes. Finally, we empirically validate our theoretical analyses on synthetic and practical network architectures with both balanced and imbalanced scenarios.""}",https://openreview.net{'value': '/pdf/dd14ca985efae65a50116586f61397c970104066.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=jbAjEhBuOZ,{'value': 'Tuning Language Models as Training Data Generators for Augmentation-Enhanced Few-Shot Learning'},Yu Meng; Martin Michalski; Jiaxin Huang; Yu Zhang; Tarek Abdelzaher; Jiawei Han,~Yu_Meng1; ~Martin_Michalski1; ~Jiaxin_Huang1; ~Yu_Zhang26; ~Tarek_Abdelzaher1; ~Jiawei_Han1,,"{'value': 'Recent studies have revealed the intriguing few-shot learning ability of pretrained language models (PLMs): They can quickly adapt to a new task when fine-tuned on a small amount of labeled data formulated as prompts, without requiring abundant task-specific annotations. Despite their promising performance, most existing few-shot approaches that only learn from the small training set still underperform fully supervised training by nontrivial margins. In this work, we study few-shot learning with PLMs from a different perspective: We first tune an autoregressive PLM on the few-shot samples and then use it as a generator to synthesize a large amount of novel training samples which augment the original training set. To encourage the generator to produce label-discriminative samples, we train it via weighted maximum likelihood where the weight of each token is automatically adjusted based on a discriminative meta-learning objective. A classification PLM can then be fine-tuned on both the few-shot and the synthetic samples with regularization for better generalization and stability. Our approach FewGen achieves an overall better result across seven classification tasks of the GLUE benchmark than existing few-shot learning methods, improving no-augmentation methods by 5+ average points, and outperforming augmentation methods by 3+ average points.'}",https://openreview.net{'value': '/pdf/d875c9abb7150e2ddcfd416370d61dcc50822f34.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=jVR2fF8x8x,{'value': 'Improved Techniques for Maximum Likelihood Estimation for Diffusion ODEs'},Kaiwen Zheng; Cheng Lu; Jianfei Chen; Jun Zhu,~Kaiwen_Zheng2; ~Cheng_Lu5; ~Jianfei_Chen1; ~Jun_Zhu2,,"{'value': 'Diffusion models have exhibited excellent performance in various domains. The probability flow ordinary differential equation (ODE) of diffusion models (i.e., diffusion ODEs) is a particular case of continuous normalizing flows (CNFs), which enables deterministic inference and exact likelihood evaluation. However, the likelihood estimation results by diffusion ODEs are still far from those of the state-of-the-art likelihood-based generative models. In this work, we propose several improved techniques for maximum likelihood estimation for diffusion ODEs, including both training and evaluation perspectives. For training, we propose velocity parameterization and explore variance reduction techniques for faster convergence. We also derive an error-bounded high-order flow matching objective for finetuning, which improves the ODE likelihood and smooths its trajectory. For evaluation, we propose a novel training-free truncated-normal dequantization to fill the training-evaluation gap commonly existing in diffusion ODEs. Building upon these techniques, we achieve state-of-the-art likelihood estimation results on image datasets (2.56 on CIFAR-10, 3.43/3.69 on ImageNet-32) without variational dequantization or data augmentation.'}",https://openreview.net{'value': '/pdf/58cdc024f9e2f20abc6cd89400d7becb70dd0939.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=jTcRlAAO01,{'value': 'Principled Offline RL in the Presence of Rich Exogenous Information'},Riashat Islam; Manan Tomar; Alex Lamb; Yonathan Efroni; Hongyu Zang; Aniket Rajiv Didolkar; Dipendra Misra; Xin Li; Harm van Seijen; Remi Tachet des Combes; John Langford,~Riashat_Islam1; ~Manan_Tomar1; ~Alex_Lamb1; ~Yonathan_Efroni2; ~Hongyu_Zang1; ~Aniket_Rajiv_Didolkar1; ~Dipendra_Misra1; ~Xin_Li31; ~Harm_van_Seijen1; ~Remi_Tachet_des_Combes1; ~John_Langford1,,"{'value': 'Learning to control an agent from offline data collected in a rich pixel-based visual observation space is vital for real-world applications of reinforcement learning (RL). A major challenge in this setting is the presence of input information that is hard to model and irrelevant to controlling the agent. This problem has been approached by the theoretical RL community through the lens of *exogenous information*, i.e., any control-irrelevant information contained in observations. For example, a robot navigating in busy streets needs to ignore irrelevant information, such as other people walking in the background, textures of objects, or birds in the sky. In this paper, we focus on the setting with visually detailed exogenous information and introduce new offline RL benchmarks that offer the ability to study this problem. We find that contemporary representation learning techniques can fail on datasets where the noise is a complex and time-dependent process, which is prevalent in practical applications. To address these, we propose to use multi-step inverse models to learn Agent-Centric Representations for Offline-RL (ACRO). Despite being simple and reward-free, we show theoretically and empirically that the representation created by this objective greatly outperforms baselines.'}",https://openreview.net{'value': '/pdf/2ba1b01e4ccf4959e2866a148fb6cf05f726c67e.pdf'},{'abstract_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=jFPdftHG4F,{'value': 'Probabilistic Attention-to-Influence Neural Models for Event Sequences'},Xiao Shou; Debarun Bhattacharjya; Tian Gao; Dharmashankar Subramanian; Oktie Hassanzadeh; Kristin Bennett,~Xiao_Shou2; ~Debarun_Bhattacharjya1; ~Tian_Gao1; ~Dharmashankar_Subramanian1; ~Oktie_Hassanzadeh1; ~Kristin_Bennett1,,"{'value': 'Discovering knowledge about which types of events influence others, using datasets of event sequences without time stamps, has several practical applications. While neural sequence models are able to capture complex and potentially long-range historical dependencies, they often lack the interpretability of simpler models for event sequence dynamics. We provide a novel neural framework in such a setting - a probabilistic attention-to-influence neural model - which not only captures complex instance-wise interactions between events but also learns influencers for each event type of interest. Given event sequence data and a prior distribution on type-wise influence, we efficiently learn an approximate posterior for type-wise influence by an attention-to-influence transformation using variational inference. Our method subsequently models the conditional likelihood of sequences by sampling the above posterior to focus attention on influencing event types. We motivate our general framework and show improved performance in experiments compared to existing baselines on synthetic data as well as real-world benchmarks, for tasks involving prediction and influencing set identification.'}",https://openreview.net{'value': '/pdf/88bfc47a549979ce4a0dfd899bb7ff9ed99ce3d1.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=j5PYwPsNci,{'value': 'B-Learner: Quasi-Oracle Bounds on Heterogeneous Causal Effects Under Hidden Confounding'},Miruna Oprescu; Jacob Dorn; Marah Ghoummaid; Andrew Jesson; Nathan Kallus; Uri Shalit,~Miruna_Oprescu1; ~Jacob_Dorn1; ~Marah_Ghoummaid1; ~Andrew_Jesson1; ~Nathan_Kallus1; ~Uri_Shalit1,,"{'value': 'Estimating heterogeneous treatment effects from observational data is a crucial task across many fields, helping policy and decision-makers take better actions. There has been recent progress on robust and efficient methods for estimating the conditional average treatment effect (CATE) function, but these methods often do not take into account the risk of hidden confounding, which could arbitrarily and unknowingly bias any causal estimate based on observational data. We propose a meta-learner called the B-Learner, which can efficiently learn sharp bounds on the CATE function under limits on the level of hidden confounding. We derive the B-Learner by adapting recent results for sharp and valid bounds of the average treatment effect (Dorn et al., 2021) into the framework given by Kallus & Oprescu (2023) for robust and model-agnostic learning of conditional distributional treatment effects. The B-Learner can use any function estimator such as random forests and deep neural networks, and we prove its estimates are valid, sharp, efficient, and have a quasi-oracle property with respect to the constituent estimators under more general conditions than existing methods. Semi-synthetic experimental comparisons validate the theoretical findings, and we use real-world data demonstrate how the method might be used in practice.'}",https://openreview.net{'value': '/pdf/c61c7feb36c0a101f92350f162e6781cdf946623.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=iRBKUnIjR2,{'value': 'Approximate Causal Effect Identification under Weak Confounding'},Ziwei Jiang; Lai Wei; Murat Kocaoglu,~Ziwei_Jiang1; wei429@purdue.edu; ~Murat_Kocaoglu1,,"{'value': 'Causal effect estimation has been studied by many researchers when only observational data is available. Sound and complete algorithms have been developed for pointwise estimation of identifiable causal queries. For non-identifiable causal queries, researchers developed polynomial programs to estimate tight bounds on causal effect. However, these are computationally difficult to optimize for variables with large support sizes. In this paper, we analyze the effect of ""weak confounding\'"" on causal estimands. More specifically, under the assumption that the unobserved confounders that render a query non-identifiable have small entropy, we propose an efficient linear program to derive the upper and lower bounds of the causal effect. We show that our bounds are consistent in the sense that as the entropy of unobserved confounders goes to zero, the gap between the upper and lower bound vanishes. Finally, we conduct synthetic and real data simulations to compare our bounds with the bounds obtained by the existing work that cannot incorporate such entropy constraints and show that our bounds are tighter for the setting with weak confounders.'}",https://openreview.net{'value': '/pdf/4c70ff5f5acdb475d37249b3fcc560e3f36cb014.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=iEPLOBHHnh,{'value': 'Evaluating Unsupervised Denoising Requires Unsupervised Metrics'},Adria Marcos Morales; Matan Leibovich; Sreyas Mohan; Joshua Lawrence Vincent; Piyush Haluai; Mai Tan; Peter Crozier; Carlos Fernandez-Granda,~Adria_Marcos_Morales1; ~Matan_Leibovich1; ~Sreyas_Mohan1; ~Joshua_Lawrence_Vincent1; ~Piyush_Haluai1; ~Mai_Tan2; ~Peter_Crozier1; ~Carlos_Fernandez-Granda1,,"{'value': 'Unsupervised denoising is a crucial challenge in real-world imaging applications. Unsupervised deep-learning methods have demonstrated impressive performance on benchmarks based on synthetic noise. However, no metrics exist to evaluate these methods in an unsupervised fashion. This is highly problematic for the many practical applications where ground-truth clean images are not available. In this work, we propose two novel metrics: the unsupervised mean squared error (MSE) and the unsupervised peak signal-to-noise ratio (PSNR), which are computed using only noisy data. We provide a theoretical analysis of these metrics, showing that they are asymptotically consistent estimators of the supervised MSE and PSNR. Controlled numerical experiments with synthetic noise confirm that they provide accurate approximations in practice. We validate our approach on real-world data from two imaging modalities: videos in raw format and transmission electron microscopy. Our results demonstrate that the proposed metrics enable unsupervised evaluation of denoising methods based exclusively on noisy data.'}",https://openreview.net{'value': '/pdf/aa21ac970076566ad9bc9c24d0927b1bac6841dc.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=hvEwJ3xYxx,{'value': 'Matrix Estimation for Individual Fairness'},Cindy Zhang; Sarah Huiyi Cen; Devavrat Shah,~Cindy_Zhang1; ~Sarah_Huiyi_Cen1; ~Devavrat_Shah1,,"{'value': ""In recent years, multiple notions of algorithmic fairness have arisen. One such notion is individual fairness (IF), which requires that individuals who are similar receive similar treatment. In parallel, matrix estimation (ME) has emerged as a natural paradigm for handling noisy data with missing values. In this work, we connect the two concepts. We show that pre-processing data using ME can improve an algorithm's IF without sacrificing performance. Specifically, we show that using a popular ME method known as singular value thresholding (SVT) to pre-process the data provides a strong IF guarantee under appropriate conditions. We then show that, under analogous conditions, SVT pre-processing also yields estimates that are consistent and approximately minimax optimal. As such, the ME pre-processing step does not, under the stated conditions, increase the prediction error of the base algorithm, i.e., does not impose a fairness-performance trade-off. We verify these results on synthetic and real data.""}",https://openreview.net{'value': '/pdf/6625457895110d8310a8dfcd62a3de11038a330c.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=h3GBd13xVv,{'value': 'Global Optimization with Parametric Function Approximation'},Chong Liu; Yu-Xiang Wang,~Chong_Liu1; ~Yu-Xiang_Wang1,,"{'value': 'We consider the problem of global optimization with noisy zeroth order oracles — a well-motivated problem useful for various applications ranging from hyper-parameter tuning for deep learning to new material design. Existing work relies on Gaussian processes or other non-parametric family, which suffers from the curse of dimensionality. In this paper, we propose a new algorithm GO-UCB that leverages a parametric family of functions (e.g., neural networks) instead. Under a realizable assumption and a few other mild geometric conditions, we show that GO-UCB achieves a cumulative regret of $\\tilde{O}(\\sqrt{T})$ where $T$ is the time horizon. At the core of GO-UCB is a carefully designed uncertainty set over parameters based on gradients that allows optimistic exploration. Synthetic and real-world experiments illustrate GO-UCB works better than popular Bayesian optimization approaches, even if the model is misspecified.'}",https://openreview.net{'value': '/pdf/012133faf95c9469c174facbf2135af11ae3555a.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=gWC3Q3pyHe,{'value': 'Fast Sampling of Diffusion Models via Operator Learning'},Hongkai Zheng; Weili Nie; Arash Vahdat; Kamyar Azizzadenesheli; Anima Anandkumar,~Hongkai_Zheng1; ~Weili_Nie1; ~Arash_Vahdat3; ~Kamyar_Azizzadenesheli1; ~Anima_Anandkumar1,,"{'value': 'Diffusion models have found widespread adoption in various areas. However, their sampling process is slow because it requires hundreds to thousands of network evaluations to emulate a continuous process defined by differential equations. In this work, we use neural operators, an efficient method to solve the probability flow differential equations, to accelerate the sampling process of diffusion models. Compared to other fast sampling methods that have a sequential nature, we are the first to propose a parallel decoding method that generates images with only one model forward pass. We propose *diffusion model sampling with neural operator* (DSNO) that maps the initial condition, i.e., Gaussian distribution, to the continuous-time solution trajectory of the reverse diffusion process. To model the temporal correlations along the trajectory, we introduce temporal convolution layers that are parameterized in the Fourier space into the given diffusion model backbone. We show our method achieves state-of-the-art FID of 3.78 for CIFAR-10 and 7.83 for ImageNet-64 in the one-model-evaluation setting.'}",https://openreview.net{'value': '/pdf/9e7263c6d98947b273d790acf29c3ff6182ae894.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=gTGFxnBymb,{'value': 'Regions of Reliability in the Evaluation of Multivariate Probabilistic Forecasts'},Étienne Marcotte; Valentina Zantedeschi; Alexandre Drouin; Nicolas Chapados,~Étienne_Marcotte1; ~Valentina_Zantedeschi2; ~Alexandre_Drouin2; ~Nicolas_Chapados1,,"{'value': ""Multivariate probabilistic time series forecasts are commonly evaluated via proper scoring rules, i.e., functions that are minimal in expectation for the ground-truth distribution. However, this property is not sufficient to guarantee good discrimination in the non-asymptotic regime. In this paper, we provide the first systematic finite-sample study of proper scoring rules for time series forecasting evaluation. Through a power analysis, we identify the ``region of reliability'' of a scoring rule, i.e., the set of practical conditions where it can be relied on to identify forecasting errors. We carry out our analysis on a comprehensive synthetic benchmark, specifically designed to test several key discrepancies between ground-truth and forecast distributions, and we gauge the generalizability of our findings to real-world tasks with an application to an electricity production problem. Our results reveal critical shortcomings in the evaluation of multivariate probabilistic forecasts as commonly performed in the literature.""}",https://openreview.net{'value': '/pdf/376ddeb79745f03eb70ebe94fbefefb8c745764c.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=fZFNPf1QiF,{'value': 'Beyond the Universal Law of Robustness: Sharper Laws for Random Features and Neural Tangent Kernels'},Simone Bombari; Shayan Kiyani; Marco Mondelli,~Simone_Bombari1; ~Shayan_Kiyani2; ~Marco_Mondelli1,,"{'value': 'Machine learning models are vulnerable to adversarial perturbations, and a thought-provoking paper by Bubeck and Sellke has analyzed this phenomenon through the lens of over-parameterization: interpolating smoothly the data requires significantly more parameters than simply memorizing it. However, this ""universal"" law provides only a necessary condition for robustness, and it is unable to discriminate between models. In this paper, we address these gaps by focusing on empirical risk minimization in two prototypical settings, namely, random features and the neural tangent kernel (NTK). We prove that, for random features, the model is not robust for any degree of over-parameterization, even when the necessary condition coming from the universal law of robustness is satisfied. In contrast, for even activations, the NTK model meets the universal lower bound, and it is robust as soon as the necessary condition on over-parameterization is fulfilled. This also addresses a conjecture in prior work by Bubeck, Li and Nagaraj. Our analysis decouples the effect of the kernel of the model from an ""interaction matrix"", which describes the interaction with the test data and captures the effect of the activation. Our theoretical results are corroborated by numerical evidence on both synthetic and standard datasets (MNIST, CIFAR-10).'}",https://openreview.net{'value': '/pdf/79a662cf119d0c70b63ab4437bc73d78cc0d2fb4.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=fXBjFPL5HD,{'value': 'Entity Divider with Language Grounding in Multi-Agent Reinforcement Learning'},Ziluo Ding; Wanpeng Zhang; Junpeng Yue; Xiangjun Wang; Tiejun Huang; Zongqing Lu,~Ziluo_Ding1; ~Wanpeng_Zhang1; ~Junpeng_Yue1; ~Xiangjun_Wang1; ~Tiejun_Huang1; ~Zongqing_Lu2,,"{'value': 'We investigate the use of natural language to drive the generalization of policies in multi-agent settings. Unlike single-agent settings, the generalization of policies should also consider the influence of other agents. Besides, with the increasing number of entities in multi-agent settings, more agent-entity interactions are needed for language grounding, and the enormous search space could impede the learning process. Moreover, given a simple general instruction, e.g., beating all enemies, agents are required to decompose it into multiple subgoals and figure out the right one to focus on. Inspired by previous work, we try to address these issues at the entity level and propose a novel framework for language grounding in multi-agent reinforcement learning, entity divider (EnDi). EnDi enables agents to independently learn subgoal division at the entity level and act in the environment based on the associated entities. The subgoal division is regularized by agent modeling to avoid subgoal conflicts and promote coordinated strategies. Empirically, EnDi demonstrates the strong generalization ability to unseen games with new dynamics and expresses the superiority over existing methods. The code is available at https://github.com/PKU-RL/EnDi.'}",https://openreview.net{'value': '/pdf/35c54c4b1aa115c45a77c44327ff1605da462170.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=fKnw2yYXpK,{'value': 'Structural Re-weighting Improves Graph Domain Adaptation'},Shikun Liu; Tianchun Li; Yongbin Feng; Nhan Tran; Han Zhao; Qiang Qiu; Pan Li,~Shikun_Liu3; ~Tianchun_Li1; yfeng@fnal.gov; ~Nhan_Tran1; ~Han_Zhao1; ~Qiang_Qiu1; ~Pan_Li2,,"{'value': 'In many real-world applications, graph-structured data used for training and testing have differences in distribution, such as in high energy physics (HEP) where simulation data used for training may not match real experiments. Graph domain adaptation (GDA) is a method used to address these differences. However, current GDA primarily works by aligning the distributions of node representations output by a single graph neural network encoder shared across the training and testing domains, which may often yield sub-optimal solutions. This work examines different impacts of distribution shifts caused by either graph structure or node attributes and identifies a new type of shift, named conditional structure shift (CSS), which current GDA approaches are provably sub-optimal to deal with. A novel approach, called structural reweighting (StruRW), is proposed to address this issue and is tested on synthetic graphs, four benchmark datasets, and a new application in HEP. StruRW has shown significant performance improvement over the baselines in the settings with large graph structure shifts, and reasonable performance improvement when node attribute shift dominates.'}",https://openreview.net{'value': '/pdf/20bbc8bea38bc73bf53142ff3044046529895f14.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=elL6uw9qOX,{'value': 'GEAR: A GPU-Centric Experience Replay System for Large Reinforcement Learning Models'},Hanjing Wang; Man-Kit Sit; Congjie He; Ying Wen; Weinan Zhang; Jun Wang; Yaodong Yang; Luo Mai,~Hanjing_Wang1; ~Man-Kit_Sit1; congjie.he@ed.ac.uk; ~Ying_Wen1; ~Weinan_Zhang1; ~Jun_Wang2; ~Yaodong_Yang1; ~Luo_Mai1,,"{'value': 'This paper introduces a distributed, GPU-centric experience replay system, GEAR, designed to perform scalable reinforcement learning (RL) with large sequence models (such as transformers). With such models, existing systems such as Reverb face considerable bottlenecks in memory, computation, and communication. GEAR, however, optimizes memory efficiency by enabling the memory resources on GPU servers (including host memory and device memory) to manage trajectory data. Furthermore, it facilitates decentralized GPU devices to expedite various trajectory selection strategies, circumventing computational bottlenecks. GEAR is equipped with GPU kernels capable of collecting trajectories using zero-copy access to host memory, along with remote-directed-memory access over InfiniBand, improving communication efficiency. Cluster experiments have shown that GEAR can achieve performance levels up to 6× greater than Reverb when training state-of-the-art large RL models. GEAR is open-sourced at https:// github.com/bigrl-team/gear.'}",https://openreview.net{'value': '/pdf/86cd7170eaa066b79d29caf0a4ea22eb84eca89b.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=dopVDyZSEW,{'value': 'Learning to Suggest Breaks: Sustainable Optimization of Long-Term User Engagement'},Eden Saig; Nir Rosenfeld,~Eden_Saig1; ~Nir_Rosenfeld2,,"{'value': 'Optimizing user engagement is a key goal for modern recommendation systems, but blindly pushing users towards increased consumption risks burn-out, churn, or even addictive habits. To promote digital well-being, most platforms now offer a service that periodically prompts users to take breaks. These, however, must be set up manually, and so may be suboptimal for both users and the system. In this paper, we study the role of breaks in recommendation, and propose a framework for learning optimal breaking policies that promote and sustain long-term engagement. Based on the notion that recommendation dynamics are susceptible to both positive and negative feedback, we cast recommendation as a Lotka-Volterra dynamical system, where breaking reduces to a problem of optimal control. We then give an efficient learning algorithm, provide theoretical guarantees, and empirically demonstrate the utility of our approach on semi-synthetic data.'}",https://openreview.net{'value': '/pdf/c43a90f7811db98320be931a624c5fca9cee2e14.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=dA6biC3XgO,{'value': 'RLang: A Declarative Language for Describing Partial World Knowledge to Reinforcement Learning Agents'},Rafael Rodriguez-Sanchez; Benjamin Adin Spiegel; Jennifer Wang; Roma Patel; Stefanie Tellex; George Konidaris,~Rafael_Rodriguez-Sanchez1; ~Benjamin_Adin_Spiegel1; jennifer_wang2@brown.edu; ~Roma_Patel1; ~Stefanie_Tellex1; ~George_Konidaris1,,"{'value': 'We introduce RLang, a domain-specific language (DSL) for communicating domain knowledge to an RL agent. Unlike existing RL DSLs that ground to $\\textit{single}$ elements of a decision-making formalism (e.g., the reward function or policy), RLang can specify information about every element of a Markov decision process. We define precise syntax and grounding semantics for RLang, and provide a parser that grounds RLang programs to an algorithm-agnostic $\\textit{partial}$ world model and policy that can be exploited by an RL agent. We provide a series of example RLang programs demonstrating how different RL methods can exploit the resulting knowledge, encompassing model-free and model-based tabular algorithms, policy gradient and value-based methods, hierarchical approaches, and deep methods.'}",https://openreview.net{'value': '/pdf/0b31bbae582e202c9146f85c258a445e4ea00856.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=cnILy0dQUr,{'value': 'FusionRetro: Molecule Representation Fusion via In-Context Learning for Retrosynthetic Planning'},Songtao Liu; Zhengkai Tu; Minkai Xu; Zuobai Zhang; Lu Lin; Zhitao Ying; Jian Tang; Peilin Zhao; Dinghao Wu,~Songtao_Liu2; ~Zhengkai_Tu1; ~Minkai_Xu1; ~Zuobai_Zhang1; ~Lu_Lin2; ~Zhitao_Ying1; ~Jian_Tang1; ~Peilin_Zhao2; ~Dinghao_Wu1,,"{'value': 'Retrosynthetic planning aims to devise a complete multi-step synthetic route from starting materials to a target molecule. Current strategies use a decoupled approach of single-step retrosynthesis models and search algorithms, taking only the product as the input to predict the reactants for each planning step and ignoring valuable context information along the synthetic route. In this work, we propose a novel framework that utilizes context information for improved retrosynthetic planning. We view synthetic routes as reaction graphs and propose to incorporate context through three principled steps: encode molecules into embeddings, aggregate information over routes, and readout to predict reactants. Our approach is the first attempt to utilize in-context learning for retrosynthesis prediction in retrosynthetic planning. The entire framework can be efficiently optimized in an end-to-end fashion and produce more practical and accurate predictions. Comprehensive experiments demonstrate that by fusing in the context information over routes, our model significantly improves the performance of retrosynthetic planning over baselines that are not context-aware, especially for long synthetic routes. Code is available at https://github.com/SongtaoLiu0823/FusionRetro.'}",https://openreview.net{'value': '/pdf/adf10ff2f0471fcc5b2c025086f413d8663042ec.pdf'},{'title_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=cnGgsXpf2H,{'value': 'From Temporal to Contemporaneous Iterative Causal Discovery in the Presence of Latent Confounders'},Raanan Yehezkel Rohekar; Shami Nisimov; Yaniv Gurwicz; Gal Novik,~Raanan_Yehezkel_Rohekar1; ~Shami_Nisimov3; ~Yaniv_Gurwicz1; ~Gal_Novik1,,"{'value': 'We present a constraint-based algorithm for learning causal structures from observational time-series data, in the presence of latent confounders. We assume a discrete-time, stationary structural vector autoregressive process, with both temporal and contemporaneous causal relations. One may ask if temporal and contemporaneous relations should be treated differently. The presented algorithm gradually refines a causal graph by learning long-term temporal relations before short-term ones, where contemporaneous relations are learned last. This ordering of causal relations to be learnt leads to a reduction in the required number of statistical tests. We validate this reduction empirically and demonstrate that it leads to higher accuracy for synthetic data and more plausible causal graphs for real-world data compared to state-of-the-art algorithms.'}",https://openreview.net{'value': '/pdf/d985b4307d2ff5d743b09a465fdbc9ed0124d6ef.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=cfUDirIjOd,{'value': 'Learning to Optimize Differentiable Games'},Xuxi Chen; Nelson Vadori; Tianlong Chen; Zhangyang Wang,~Xuxi_Chen1; ~Nelson_Vadori1; ~Tianlong_Chen1; ~Zhangyang_Wang1,,"{'value': 'Many machine learning problems can be abstracted in solving game theory formulations and boil down to optimizing nested objectives, such as generative adversarial networks (GANs) and multi-agent reinforcement learning. Solving these games requires finding their stable fixed points or Nash equilibrium. However, existing algorithms for solving games suffer from empirical instability, hence demanding heavy ad-hoc tuning in practice. To tackle these challenges, we resort to the emerging scheme of Learning to Optimize (L2O), which discovers problem-specific efficient optimization algorithms through data-driven training. Our customized L2O framework for differentiable game theory problems, dubbed ``Learning to Play Games"" (L2PG), seeks a stable fixed point solution, by predicting the fast update direction from the past trajectory, with a novel gradient stability-aware, sign-based loss function. We further incorporate curriculum learning and self-learning to strengthen the empirical training stability and generalization of L2PG. On test problems including quadratic games and GANs, L2PG can substantially accelerate the convergence, and demonstrates a remarkably more stable trajectory. Codes are available at https://github.com/VITA-Group/L2PG.'}",https://openreview.net{'value': '/pdf/1fc1502d30f5da7f522225f644992f002d11993f.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=ccwSdYv1GI,{'value': 'Scaling Up Dataset Distillation to ImageNet-1K with Constant Memory'},Justin Cui; Ruochen Wang; Si Si; Cho-Jui Hsieh,~Justin_Cui1; ~Ruochen_Wang2; ~Si_Si1; ~Cho-Jui_Hsieh1,,"{'value': 'Dataset Distillation is a newly emerging area that aims to distill large datasets into much smaller and highly informative synthetic ones to accelerate training and reduce storage. Among various dataset distillation methods, trajectory-matching-based methods (MTT) have achieved SOTA performance in many tasks, e.g., on CIFAR-10/100. However, due to exorbitant memory consumption when unrolling optimization through SGD steps, MTT fails to scale to large-scale datasets such as ImageNet-1K. Can we scale this SOTA method to ImageNet-1K and does its effectiveness on CIFAR transfer to ImageNet-1K? To answer these questions, we first propose a procedure to exactly compute the unrolled gradient with constant memory complexity, which allows us to scale MTT to ImageNet-1K seamlessly with $\\sim 6$x reduction in memory footprint. We further discover that it is challenging for MTT to handle datasets with a large number of classes, and propose a novel soft label assignment that drastically improves its convergence. The resulting algorithm sets new SOTA on ImageNet-1K: we can scale up to 50 IPCs (Image Per Class) on ImageNet-1K on a single GPU (all previous methods can only scale to 2 IPCs on ImageNet-1K), leading to the best accuracy (only 5.9% accuracy drop against full dataset training) while utilizing only 4.2% of the number of data points - an 18.2% absolute gain over prior SOTA.'}",https://openreview.net{'value': '/pdf/3651ead0d5a41f78c3932928bc730c5d78e1f9e7.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=c8DEV8h93W,{'value': 'Contextual Combinatorial Bandits with Probabilistically Triggered Arms'},Xutong Liu; Jinhang Zuo; Siwei Wang; John C.S. Lui; Mohammad Hajiesmaili; Adam Wierman; Wei Chen,~Xutong_Liu1; ~Jinhang_Zuo1; ~Siwei_Wang2; ~John_C.S._Lui2; ~Mohammad_Hajiesmaili1; ~Adam_Wierman1; ~Wei_Chen10,,"{'value': 'We study contextual combinatorial bandits with probabilistically triggered arms (C$^2$MAB-T) under a variety of smoothness conditions that capture a wide range of applications, such as contextual cascading bandits and contextual influence maximization bandits. Under the triggering probability modulated (TPM) condition, we devise the C$^2$-UCB-T algorithm and propose a novel analysis that achieves an $\\tilde{O}(d\\sqrt{KT})$ regret bound, removing a potentially exponentially large factor $O(1/p_{\\min})$, where $d$ is the dimension of contexts, $p_{\\min}$ is the minimum positive probability that any arm can be triggered, and batch-size $K$ is the maximum number of arms that can be triggered per round. Under the variance modulated (VM) or triggering probability and variance modulated (TPVM) conditions, we propose a new variance-adaptive algorithm VAC$^2$-UCB and derive a regret bound $\\tilde{O}(d\\sqrt{T})$, which is independent of the batch-size $K$. As a valuable by-product, our analysis technique and variance-adaptive algorithm can be applied to the CMAB-T and C$^2$MAB setting, improving existing results there as well. We also include experiments that demonstrate the improved performance of our algorithms compared with benchmark algorithms on synthetic and real-world datasets.'}",https://openreview.net{'value': '/pdf/8940ebdcc5ee05021c354acabaef0e647515bbc7.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=beHp3L9KXc,{'value': 'Better Training of GFlowNets with Local Credit and Incomplete Trajectories'},Ling Pan; Nikolay Malkin; Dinghuai Zhang; Yoshua Bengio,~Ling_Pan1; ~Nikolay_Malkin1; ~Dinghuai_Zhang1; ~Yoshua_Bengio1,,"{'value': 'Generative Flow Networks or GFlowNets are related to Monte-Carlo Markov chain methods (as they sample from a distribution specified by an energy function), reinforcement learning (as they learn a policy to sample composed objects through a sequence of steps), generative models (as they learn to represent and sample from a distribution) and amortized variational methods (as they can be used to learn to approximate and sample from an otherwise intractable posterior, given a prior and a likelihood). They are trained to generate an object $x$ through a sequence of steps with probability proportional to some reward function $R(x)$ (or $\\exp(-\\mathcal{E}(x))$ with $\\mathcal{E}(x)$ denoting the energy function), given at the end of the generative trajectory. Like for other RL settings where the reward is only given at the end, the efficiency of training and credit assignment may suffer when those trajectories are longer. With previous GFlowNet work, no learning was possible from incomplete trajectories (lacking a terminal state and the computation of the associated reward). In this paper, we consider the case where the energy function can be applied not just to terminal states but also to intermediate states. This is for example achieved when the energy function is additive, with terms available along the trajectory. We show how to reparameterize the GFlowNet state flow function to take advantage of the partial reward already accrued at each state. This enables a training objective that can be applied to update parameters even with incomplete trajectories. Even when complete trajectories are available, being able to obtain more localized credit and gradients is found to speed up training convergence, as demonstrated across many simulations.'}",https://openreview.net{'value': '/pdf/bc6b60545823fd6d7354e0f44e2b767f5205adce.pdf'},{'title_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=bbKEGbS7aN,{'value': 'Optimal Shrinkage for Distributed Second-Order Optimization'},Fangzhao Zhang; Mert Pilanci,~Fangzhao_Zhang1; ~Mert_Pilanci3,,"{'value': ""In this work, we address the problem of Hessian inversion bias in distributed second-order optimization algorithms. We introduce a novel shrinkage-based estimator for the resolvent of gram matrices which is asymptotically unbiased, and characterize its non-asymptotic convergence rate in the isotropic case. We apply this estimator to bias correction of Newton steps in distributed second-order optimization algorithms, as well as randomized sketching based methods. We examine the bias present in the naive averaging-based distributed Newton's method using analytical expressions and contrast it with our proposed biasfree approach. Our approach leads to significant improvements in convergence rate compared to standard baselines and recent proposals, as shown through experiments on both real and synthetic datasets.""}",https://openreview.net{'value': '/pdf/fafb59fd0c77d7bf2ec130bf95edccfffa2fe4e3.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=bBLjms8nZE,{'value': 'Scaling Laws for Reward Model Overoptimization'},Leo Gao; John Schulman; Jacob Hilton,~Leo_Gao1; ~John_Schulman1; ~Jacob_Hilton1,,"{'value': ""In reinforcement learning from human feedback, it is common to optimize against a reward model trained to predict human preferences. Because the reward model is an imperfect proxy, optimizing its value too much can hinder ground truth performance, in accordance with Goodhart's law. This effect has been frequently observed, but not carefully measured due to the expense of collecting human preference data. In this work, we use a synthetic setup in which a fixed ``gold-standard'' reward model plays the role of humans, providing labels used to train a proxy reward model. We study how the gold reward model score changes as we optimize against the proxy reward model using either reinforcement learning or best-of-$n$ sampling. We find that this relationship follows a different functional form depending on the method of optimization, and that in both cases its coefficients scale smoothly with the number of reward model parameters. We also study the effect on this relationship of the size of the reward model dataset, the number of reward model and policy parameters, and the coefficient of the KL penalty added to the reward in the reinforcement learning setup. We explore the implications of these empirical results for theoretical considerations in AI alignment.""}",https://openreview.net{'value': '/pdf/5922fc32f0d360192fe9d51e1b5cc92663ef4e22.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=agPrVQdnxT,{'value': 'The Impact of Exploration on Convergence and Performance of Multi-Agent Q-Learning Dynamics'},Aamal Hussain; Francesco Belardinelli; Dario Paccagnan,~Aamal_Hussain1; ~Francesco_Belardinelli1; ~Dario_Paccagnan1,,"{'value': 'Understanding the impact of exploration on the behaviour of multi-agent learning has, so far, benefited from the restriction to potential, or network zero-sum games in which convergence to an equilibrium can be shown. Outside of these classes, learning dynamics rarely converge and little is known about the effect of exploration in the face of non-convergence. To progress this front, we study the smooth Q- Learning dynamics. We show that, in any network game, exploration by agents results in the convergence of Q-Learning to a neighbourhood of an equilibrium. This holds independently of whether the dynamics reach the equilibrium or display complex behaviours. We show that increasing the exploration rate decreases the size of this neighbourhood and also decreases the ability of all agents to improve their payoffs. Furthermore, in a broad class of games, the payoff performance of Q-Learning dynamics, measured by Social Welfare, decreases when the exploration rate increases. Our experiments show this to be a general phenomenon, namely that exploration leads to improved convergence of Q-Learning, at the cost of payoff performance.'}",https://openreview.net{'value': '/pdf/ba84304a16e0bff4a5f56e800a79764d39169557.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=aX9jtC2lfS,{'value': 'Hypervolume Knowledge Gradient: A Lookahead Approach for Multi-Objective Bayesian Optimization with Partial Information'},Sam Daulton; Maximilian Balandat; Eytan Bakshy,~Sam_Daulton1; ~Maximilian_Balandat1; ~Eytan_Bakshy1,,"{'value': 'Bayesian optimization is a popular method for sample efficient multi-objective optimization. However, existing Bayesian optimization techniques fail to effectively exploit common and often-neglected problem structure such as decoupled evaluations, where objectives can be queried independently from one another and each may consume different resources, or multi-fidelity evaluations, where lower fidelity-proxies of the objectives can be evaluated at lower cost. In this work, we propose a general one-step lookahead acquisition function based on the Knowledge Gradient that addresses the complex question of what to evaluate when and at which design points in a principled Bayesian decision-theoretic fashion. Hence, our approach naturally addresses decoupled, multi-fidelity, and standard multi-objective optimization settings in a unified Bayesian decision making framework. By construction, our method is the one-step Bayes-optimal policy for hypervolume maximization. Empirically, we demonstrate that our method improves sample efficiency in a wide variety of synthetic and real-world problems. Furthermore, we show that our method is general-purpose and yields competitive performance in standard (potentially noisy) multi-objective optimization.'}",https://openreview.net{'value': '/pdf/f5a9e56c3e1395b8deea110e756201378063e0fa.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=aAGrNFHmVd,{'value': 'Minimizing Trajectory Curvature of ODE-based Generative Models'},Sangyun Lee; Beomsu Kim; Jong Chul Ye,~Sangyun_Lee1; ~Beomsu_Kim1; ~Jong_Chul_Ye1,,"{'value': 'Recent ODE/SDE-based generative models, such as diffusion models, rectified flows, and flow matching, define a generative process as a time reversal of a fixed forward process. Even though these models show impressive performance on large-scale datasets, numerical simulation requires multiple evaluations of a neural network, leading to a slow sampling speed. We attribute the reason to the high curvature of the learned generative trajectories, as it is directly related to the truncation error of a numerical solver. Based on the relationship between the forward process and the curvature, here we present an efficient method of training the forward process to minimize the curvature of generative trajectories without any ODE/SDE simulation. Experiments show that our method achieves a lower curvature than previous models and, therefore, decreased sampling costs while maintaining competitive performance. Code is available at https://github.com/sangyun884/fast-ode.'}",https://openreview.net{'value': '/pdf/ce0e80995484de8ec6c593ad3c3010a335b502c1.pdf'},{'title_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=a6PvWIHFsF,{'value': 'Learning Deductive Reasoning from Synthetic Corpus based on Formal Logic'},Terufumi Morishita; Gaku Morio; Atsuki Yamaguchi; Yasuhiro Sogawa,~Terufumi_Morishita1; ~Gaku_Morio1; ~Atsuki_Yamaguchi1; ~Yasuhiro_Sogawa1,,"{'value': 'We study a synthetic corpus based approach for language models (LMs) to acquire logical deductive reasoning ability. The previous studies generated deduction examples using specific sets of deduction rules. However, these rules were limited or otherwise arbitrary. This can limit the generalizability of acquired deductive reasoning ability. We rethink this and adopt a well-grounded set of deduction rules based on formal logic theory, which can derive any other deduction rules when combined in a multistep way. We empirically verify that LMs trained on the proposed corpora, which we name $\\textbf{FLD}$ ($\\textbf{F}$ormal $\\textbf{L}$ogic $\\textbf{D}$eduction), acquire more generalizable deductive reasoning ability. Furthermore, we identify the aspects of deductive reasoning ability on which deduction corpora can enhance LMs and those on which they cannot. Finally, on the basis of these results, we discuss the future directions for applying deduction corpora or other approaches for each aspect. We release the code, data, and models.'}",https://openreview.net{'value': '/pdf/b0ac16166c8c3dcbfd0e487ba7a5a16760f4d777.pdf'},{'title_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=ZtvnhohkVk,{'value': 'Neural Markov Jump Processes'},Patrick Seifner; Ramses J Sanchez,~Patrick_Seifner1; ~Ramses_J_Sanchez1,,"{'value': 'Markov jump processes are continuous-time stochastic processes with a wide range of applications in both natural and social sciences. Despite their widespread use, inference in these models is highly non-trivial and typically proceeds via either Monte Carlo or expectation-maximization methods. In this work we introduce an alternative, variational inference algorithm for Markov jump processes which relies on neural ordinary differential equations, and is trainable via back-propagation. Our methodology learns neural, continuous-time representations of the observed data, that are used to approximate the initial distribution and time-dependent transition probability rates of the posterior Markov jump process. The time-independent rates of the prior process are in contrast trained akin to generative adversarial networks. We test our approach on synthetic data sampled from ground-truth Markov jump processes, experimental switching ion channel data and molecular dynamics simulations. Source code to reproduce our experiments is available online.'}",https://openreview.net{'value': '/pdf/b74c0c12136e5c7343ee0d0f450575663f5a311b.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=ZXeTCRZJp9,{'value': 'Invariant Slot Attention: Object Discovery with Slot-Centric Reference Frames'},Ondrej Biza; Sjoerd van Steenkiste; Mehdi S. M. Sajjadi; Gamaleldin Fathy Elsayed; Aravindh Mahendran; Thomas Kipf,~Ondrej_Biza1; ~Sjoerd_van_Steenkiste1; ~Mehdi_S._M._Sajjadi1; ~Gamaleldin_Fathy_Elsayed1; ~Aravindh_Mahendran2; ~Thomas_Kipf2,,"{'value': 'Automatically discovering composable abstractions from raw perceptual data is a long-standing challenge in machine learning. Recent slot-based neural networks that learn about objects in a self-supervised manner have made exciting progress in this direction. However, they typically fall short at adequately capturing spatial symmetries present in the visual world, which leads to sample inefficiency, such as when entangling object appearance and pose. In this paper, we present a simple yet highly effective method for incorporating spatial symmetries via slot-centric reference frames. We incorporate equivariance to per-object pose transformations into the attention and generation mechanism of Slot Attention by translating, scaling, and rotating position encodings. These changes result in little computational overhead, are easy to implement, and can result in large gains in terms of data efficiency and overall improvements to object discovery. We evaluate our method on a wide range of synthetic object discovery benchmarks namely CLEVR, Tetrominoes, CLEVRTex, Objects Room and MultiShapeNet, and show promising improvements on the challenging real-world Waymo Open dataset.'}",https://openreview.net{'value': '/pdf/9d3b5881d325fcfa1dd499fe3097d407a3a8d26c.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=ZXXPQ8GptX,{'value': 'Online Platt Scaling with Calibeating'},Chirag Gupta; Aaditya Ramdas,~Chirag_Gupta1; ~Aaditya_Ramdas2,,"{'value': 'We present an online post-hoc calibration method, called Online Platt Scaling (OPS), which combines the Platt scaling technique with online logistic regression. We demonstrate that OPS smoothly adapts between i.i.d. and non-i.i.d. settings with distribution drift. Further, in scenarios where the best Platt scaling model is itself miscalibrated, we enhance OPS by incorporating a recently developed technique called calibeating to make it more robust. Theoretically, our resulting OPS+calibeating method is guaranteed to be calibrated for adversarial outcome sequences. Empirically, it is effective on a range of synthetic and real-world datasets, with and without distribution drifts, achieving superior performance without hyperparameter tuning. Finally, we extend all OPS ideas to the beta scaling method.'}",https://openreview.net{'value': '/pdf/ef8c3d22379a675d403a2f8b29d36e342755afe6.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=ZMDv1Mo89E,{'value': 'Are Diffusion Models Vulnerable to Membership Inference Attacks?'},Jinhao Duan; Fei Kong; Shiqi Wang; Xiaoshuang Shi; Kaidi Xu,~Jinhao_Duan1; ~Fei_Kong1; ~Shiqi_Wang2; ~Xiaoshuang_Shi2; ~Kaidi_Xu1,,"{'value': 'Diffusion-based generative models have shown great potential for image synthesis, but there is a lack of research on the security and privacy risks they may pose. In this paper, we investigate the vulnerability of diffusion models to Membership Inference Attacks (MIAs), a common privacy concern. Our results indicate that existing MIAs designed for GANs or VAE are largely ineffective on diffusion models, either due to inapplicable scenarios (e.g., requiring the discriminator of GANs) or inappropriate assumptions (e.g., closer distances between synthetic samples and member samples). To address this gap, we propose Step-wise Error Comparing Membership Inference (SecMI), a query-based MIA that infers memberships by assessing the matching of forward process posterior estimation at each timestep. SecMI follows the common overfitting assumption in MIA where member samples normally have smaller estimation errors, compared with hold-out samples. We consider both the standard diffusion models, e.g., DDPM, and the text-to-image diffusion models, e.g., Latent Diffusion Models and Stable Diffusion. Experimental results demonstrate that our methods precisely infer the membership with high confidence on both of the two scenarios across multiple different datasets. Code is available at https://github.com/jinhaoduan/SecMI.'}",https://openreview.net{'value': '/pdf/8e4384a6e2298ca30bb514e212e7b9e93f1728c2.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=YxpkGn5Oly,{'value': 'Tilted Sparse Additive Models'},Yingjie Wang; Hong Chen; Weifeng Liu; Fengxiang He; Tieliang Gong; Youcheng Fu; Dacheng Tao,~Yingjie_Wang1; ~Hong_Chen1; ~Weifeng_Liu1; ~Fengxiang_He1; ~Tieliang_Gong2; ~Youcheng_Fu2; ~Dacheng_Tao1,,"{'value': 'Additive models have been burgeoning in data analysis due to their flexible representation and desirable interpretability. However, most existing approaches are constructed under empirical risk minimization (ERM), and thus perform poorly in situations where average performance is not a suitable criterion for the problems of interest, e.g., data with complex non-Gaussian noise, imbalanced labels or both of them. In this paper, a novel class of sparse additive models is proposed under tilted empirical risk minimization (TERM), which addresses the deficiencies in ERM by imposing tilted impact on individual losses, and is flexibly capable of achieving a variety of learning objectives, e.g., variable selection, robust estimation, imbalanced classification and multiobjective learning. On the theoretical side, a learning theory analysis which is centered around the generalization bound and function approximation error bound (under some specific data distributions) is conducted rigorously. On the practical side, an accelerated optimization algorithm is designed by integrating Prox-SVRG and random Fourier acceleration technique. The empirical assessments verify the competitive performance of our approach on both synthetic and real data.'}",https://openreview.net{'value': '/pdf/fbeb18ae7795aefc5ba2d0d5d572f197831ff25b.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=YhRsYVwTHv,{'value': 'Revisiting Data-Free Knowledge Distillation with Poisoned Teachers'},Junyuan Hong; Yi Zeng; Shuyang Yu; Lingjuan Lyu; Ruoxi Jia; Jiayu Zhou,~Junyuan_Hong1; ~Yi_Zeng3; ~Shuyang_Yu1; ~Lingjuan_Lyu1; ~Ruoxi_Jia1; ~Jiayu_Zhou1,,"{'value': 'Data-free knowledge distillation (KD) helps transfer knowledge from a pre-trained model (known as the teacher model) to a smaller model (known as the student model) without access to the original training data used for training the teacher model. However, the security of the synthetic or out-of-distribution (OOD) data required in data-free KD is largely unknown and under-explored. In this work, we make the first effort to uncover the security risk of data-free KD w.r.t. untrusted pre-trained models. We then propose Anti-Backdoor Data-Free KD (ABD), the first plug-in defensive method for data-free KD methods to mitigate the chance of potential backdoors being transferred. We empirically evaluate the effectiveness of our proposed ABD in diminishing transferred backdoor knowledge while maintaining compatible downstream performances as the vanilla KD. We envision this work as a milestone for alarming and mitigating the potential backdoors in data-free KD. Codes are released at https://github.com/illidanlab/ABD .'}",https://openreview.net{'value': '/pdf/730f2615395af86b0e8a6902ca1a2d3d602249b2.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=YeTYJz7th5,{'value': 'Learning Temporally AbstractWorld Models without Online Experimentation'},Benjamin Freed; Siddarth Venkatraman; Guillaume Adrien Sartoretti; Jeff Schneider; Howie Choset,~Benjamin_Freed1; ~Siddarth_Venkatraman1; ~Guillaume_Adrien_Sartoretti1; ~Jeff_Schneider1; ~Howie_Choset1,,"{'value': 'Agents that can build temporally abstract representations of their environment are better able to understand their world and make plans on extended time scales, with limited computational power and modeling capacity. However, existing methods for automatically learning temporally abstract world models usually require millions of online environmental interactions and incentivize agents to reach every accessible environmental state, which is infeasible for most real-world robots both in terms of data efficiency and hardware safety. In this paper, we present an approach for simultaneously learning sets of skills and temporally abstract, skill-conditioned world models purely from offline data, enabling agents to perform zero-shot online planning of skill sequences for new tasks. We show that our approach performs comparably to or better than a wide array of state-of-the-art offline RL algorithms on a number of simulated robotics locomotion and manipulation benchmarks, while offering a higher degree of adaptability to new goals. Finally, we show that our approach offers a much higher degree of robustness to perturbations in environmental dynamics, compared to policy-based methods.'}",https://openreview.net{'value': '/pdf/2dce3d5ae98c6eea25ade5258561c7723d60ba65.pdf'},{'abstract_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=YZoYYaawO2,{'value': 'Differentiable Tree Operations Promote Compositional Generalization'},Paul Soulos; Edward J Hu; Kate McCurdy; Yunmo Chen; Roland Fernandez; Paul Smolensky; Jianfeng Gao,~Paul_Soulos1; ~Edward_J_Hu1; ~Kate_McCurdy1; ~Yunmo_Chen1; ~Roland_Fernandez1; ~Paul_Smolensky1; ~Jianfeng_Gao1,,"{'value': 'In the context of structure-to-structure transformation tasks, learning sequences of discrete symbolic operations poses significant challenges due to their non-differentiability. To facilitate the learning of these symbolic sequences, we introduce a differentiable tree interpreter that compiles high-level symbolic tree operations into subsymbolic matrix operations on tensors. We present a novel Differentiable Tree Machine (DTM) architecture that integrates our interpreter with an external memory and an agent that learns to sequentially select tree operations to execute the target transformation in an end-to-end manner. With respect to out-of-distribution compositional generalization on synthetic semantic parsing and language generation tasks, DTM achieves 100% while existing baselines such as Transformer, Tree Transformer, LSTM, and Tree2Tree LSTM achieve less than 30%. DTM remains highly interpretable in addition to its perfect performance.'}",https://openreview.net{'value': '/pdf/075cab9bac0c5038698762311e1aae907f5c2c25.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=YIWtM3GdZc,{'value': 'A Closer Look at the Intervention Procedure of Concept Bottleneck Models'},Sungbin Shin; Yohan Jo; Sungsoo Ahn; Namhoon Lee,~Sungbin_Shin1; ~Yohan_Jo1; ~Sungsoo_Ahn1; ~Namhoon_Lee1,,"{'value': 'Concept bottleneck models (CBMs) are a class of interpretable neural network models that predict the target response of a given input based on its high-level concepts. Unlike the standard end-to-end models, CBMs enable domain experts to intervene on the predicted concepts and rectify any mistakes at test time, so that more accurate task predictions can be made at the end. While such intervenability provides a powerful avenue of control, many aspects of the intervention procedure remain rather unexplored. In this work, we develop various ways of selecting intervening concepts to improve the intervention effectiveness and conduct an array of in-depth analyses as to how they evolve under different circumstances. Specifically, we find that an informed intervention strategy can reduce the task error more than ten times compared to the current baseline under the same amount of intervention counts in realistic settings, and yet, this can vary quite significantly when taking into account different intervention granularity. We verify our findings through comprehensive evaluations, not only on the standard real datasets, but also on synthetic datasets that we generate based on a set of different causal graphs. We further discover some major pitfalls of the current practices which, without a proper addressing, raise concerns on reliability and fairness of the intervention procedure.'}",https://openreview.net{'value': '/pdf/0f1de16b363e669c11c75cc99a59048a76488c53.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=XyzhpYy2G4,{'value': 'Dynamical Linear Bandits'},Marco Mussi; Alberto Maria Metelli; Marcello Restelli,~Marco_Mussi1; ~Alberto_Maria_Metelli2; ~Marcello_Restelli1,,"{'value': 'In many real-world sequential decision-making problems, an action does not immediately reflect on the feedback and spreads its effects over a long time frame. For instance, in online advertising, investing in a platform produces an instantaneous increase of awareness, but the actual reward, i.e., a conversion, might occur far in the future. Furthermore, whether a conversion takes place depends on: how fast the awareness grows, its vanishing effects, and the synergy or interference with other advertising platforms. Previous work has investigated the Multi-Armed Bandit framework with the possibility of delayed and aggregated feedback, without a particular structure on how an action propagates in the future, disregarding possible dynamical effects. In this paper, we introduce a novel setting, the Dynamical Linear Bandits (DLB), an extension of the linear bandits characterized by a hidden state. When an action is performed, the learner observes a noisy reward whose mean is a linear function of the hidden state and of the action. Then, the hidden state evolves according to linear dynamics, affected by the performed action too. We start by introducing the setting, discussing the notion of optimal policy, and deriving an expected regret lower bound. Then, we provide an optimistic regret minimization algorithm, Dynamical Linear Upper Confidence Bound (DynLin-UCB), that suffers an expected regret of order $\\widetilde{\\mathcal{O}} \\Big( \\frac{d \\sqrt{T}}{(1-\\overline{\\rho})^{3/2}} \\Big)$, where $\\overline{\\rho}$ is a measure of the stability of the system, and $d$ is the dimension of the action vector. Finally, we conduct a numerical validation on a synthetic environment and on real-world data to show the effectiveness of DynLin-UCB in comparison with several baselines.'}",https://openreview.net{'value': '/pdf/fde7a7d1d2197ead45bfda7e5ff036d4d03f8054.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=Xqedp0Iu1S,{'value': 'Constant Matters: Fine-grained Error Bound on Differentially Private Continual Observation'},Hendrik Fichtenberger; Monika Henzinger; Jalaj Upadhyay,~Hendrik_Fichtenberger1; ~Monika_Henzinger1; ~Jalaj_Upadhyay1,,"{'value': 'We study fine-grained error bounds for differentially private algorithms for counting under continual observation. Our main insight is that the matrix mechanism when using lower-triangular matrices can be used in the continual observation model. More specifically, we give an explicit factorization for the counting matrix $M_\\mathsf{count}$ and upper bound the error explicitly. We also give a fine-grained analysis, specifying the exact constant in the upper bound. Our analysis is based on upper and lower bounds of the *completely bounded norm* (cb-norm) of $M_\\mathsf{count}$. Along the way, we improve the best-known bound of 28 years by Mathias (SIAM Journal on Matrix Analysis and Applications, 1993) on the cb-norm of $M_\\mathsf{count}$ for a large range of the dimension of $M_\\mathsf{count}$. Furthermore, we are the first to give concrete error bounds for various problems under continual observation such as binary counting, maintaining a histogram, releasing an approximately cut-preserving synthetic graph, many graph-based statistics, and substring and episode counting. Finally, we note that our result can be used to get a fine-grained error bound for non-interactive local learning and the first lower bounds on the additive error for $(\\epsilon,\\delta)$-differentially-private counting under continual observation. Subsequent to this work, Henzinger et al. (SODA, 2023) showed that our factorization also achieves fine-grained mean-squared error.'}",https://openreview.net{'value': '/pdf/1a3267e64796bda5b3b1be8455c32ecf96c7e80f.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=X8h8wLjog7,{'value': 'Learning the Right Layers a Data-Driven Layer-Aggregation Strategy for Semi-Supervised Learning on Multilayer Graphs'},Sara Venturini; Andrea Cristofari; Francesco Rinaldi; Francesco Tudisco,~Sara_Venturini1; andrea.cristofari@uniroma2.it; rinaldi@math.unipd.it; ~Francesco_Tudisco1,,"{'value': 'Clustering (or community detection) on multilayer graphs poses several additional complications with respect to standard graphs as different layers may be characterized by different structures and types of information. One of the major challenges is to establish the extent to which each layer contributes to the cluster assignment in order to effectively take advantage of the multilayer structure and improve upon the classification obtained using the individual layers or their union. However, making an informed a-priori assessment about the clustering information content of the layers can be very complicated. In this work, we assume a semi-supervised learning setting, where the class of a small percentage of nodes is initially provided, and we propose a parameter-free Laplacian-regularized model that learns an optimal nonlinear combination of the different layers from the available input labels. The learning algorithm is based on a Frank-Wolfe optimization scheme with inexact gradient, combined with a modified Label Propagation iteration. We provide a detailed convergence analysis of the algorithm and extensive experiments on synthetic and real-world datasets, showing that the proposed method compares favourably with a variety of baselines and outperforms each individual layer when used in isolation.'}",https://openreview.net{'value': '/pdf/8c2146cc33d9dbb02f2960057c71a096203c4aec.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=WlIJAlWou5,{'value': 'Double-Weighting for Covariate Shift Adaptation'},Jose Ignacio Segovia; Santiago Mazuelas; Anqi Liu,~Jose_Ignacio_Segovia1; ~Santiago_Mazuelas1; ~Anqi_Liu2,,"{'value': 'Supervised learning is often affected by a covariate shift in which the marginal distributions of instances (covariates $x$) of training and testing samples $p_\\text{tr}(x)$ and $p_\\text{te}(x)$ are different but the label conditionals coincide. Existing approaches address such covariate shift by either using the ratio $p_\\text{te}(x)/p_\\text{tr}(x)$ to weight training samples (reweighted methods) or using the ratio $p_\\text{tr}(x)/p_\\text{te}(x)$ to weight testing samples (robust methods). However, the performance of such approaches can be poor under support mismatch or when the above ratios take large values. We propose a minimax risk classification (MRC) approach for covariate shift adaptation that avoids such limitations by weighting both training and testing samples. In addition, we develop effective techniques that obtain both sets of weights and generalize the conventional kernel mean matching method. We provide novel generalization bounds for our method that show a significant increase in the effective sample size compared with reweighted methods. The proposed method also achieves enhanced classification performance in both synthetic and empirical experiments.'}",https://openreview.net{'value': '/pdf/ecaa11e62c1387173056935860dcd2c1bf0e7a3c.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=WT70GgYdLI,{'value': 'Training Deep Surrogate Models with Large Scale Online Learning'},Lucas Thibaut Meyer; Marc Schouler; Robert Alexander Caulk; Alejandro Ribes; Bruno Raffin,~Lucas_Thibaut_Meyer1; marc.schouler@inria.fr; ~Robert_Alexander_Caulk1; alejandro.ribes@edf.fr; ~Bruno_Raffin1,,"{'value': ""The spatiotemporal resolution of Partial Differential Equations (PDEs) plays important roles in the mathematical description of the world's physical phenomena. In general, scientists and engineers solve PDEs numerically by the use of computationally demanding solvers. Recently, deep learning algorithms have emerged as a viable alternative for obtaining fast solutions for PDEs. Models are usually trained on synthetic data generated by solvers, stored on disk and read back for training. This paper advocates that relying on a traditional static dataset to train these models does not allow the full benefit of the solver to be used as a data generator. It proposes an open source online training framework for deep surrogate models. The framework implements several levels of parallelism focused on simultaneously generating numerical simulations and training deep neural networks. This approach suppresses the I/O and storage bottleneck associated with disk-loaded datasets, and opens the way to training on significantly larger datasets. Experiments compare the offline and online training of four surrogate models, including state-of-the-art architectures. Results indicate that exposing deep surrogate models to more dataset diversity, up to hundreds of GB, can increase model generalization capabilities. Fully connected neural networks, Fourier Neural Operator (FNO), and Message Passing PDE Solver prediction accuracy is improved by 68%, 16% and 7%, respectively.""}",https://openreview.net{'value': '/pdf/72aa08b91d30bccce9ddb82c1c90c4e00bddd8fc.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=WIvyzQAaPP,{'value': 'Nonlinear Causal Discovery with Latent Confounders'},David Kaltenpoth; Jilles Vreeken,~David_Kaltenpoth1; ~Jilles_Vreeken2,,"{'value': 'Causal discovery, the task of discovering the causal graph over a set of observed variables $X_1,\\ldots,X_m$, is a challenging problem. One of the cornerstone assumptions is that of causal sufficiency: that *all* common causes of *all* measured variables have been observed. When it does not hold, causal discovery algorithms making this assumption return networks with many spurious edges. In this paper, we propose a nonlinear causal model involving hidden confounders. We show that it is identifiable from only the observed data and propose an efficient method for recovering this causal model. At the heart of our approach is a variational autoencoder which parametrizes both the causal interactions between observed variables as well as the influence of the unobserved confounders. Empirically we show that it outperforms other state-of-the-art methods for causal discovery under latent confounding on synthetic and real-world data.'}",https://openreview.net{'value': '/pdf/a00b3ca09faf26621b51ee31f76bdd8e5af63a28.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=Vv8vyf3RtU,{'value': 'On the Occupancy Measure of Non-Markovian Policies in Continuous MDPs'},Romain Laroche; Remi Tachet des Combes,~Romain_Laroche1; ~Remi_Tachet_des_Combes1,,"{'value': 'The state-action occupancy measure of a policy is the expected (discounted or undiscounted) number of times a state-action couple is visited in a trajectory. For decades, RL books have been reporting the occupancy equivalence between Markovian and non-Markovian policies in countable state-action spaces under mild conditions. This equivalence states that the occupancy of any non-Markovian policy can be equivalently obtained by a Markovian policy, i.e. a memoryless probability distribution, conditioned only on its current state. While expected, for technical reasons, the translation of this result to continuous state space has resisted until now. Our main contribution is to fill this gap and to provide a general measure-theoretic treatment of the problem, permitting, in particular, its extension to continuous MDPs. Furthermore, we show that when the occupancy is infinite, we may encounter some non-trivial cases where the result does not hold anymore.'}",https://openreview.net{'value': '/pdf/8ea72c273be1564480c59fec69e1e9ccd7b4b19b.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=VTkBZayJos,{'value': 'Learning Noisy OR Bayesian Networks with Max-Product Belief Propagation'},Antoine Dedieu; Guangyao Zhou; Dileep George; Miguel Lazaro-Gredilla,~Antoine_Dedieu1; ~Guangyao_Zhou1; ~Dileep_George1; ~Miguel_Lazaro-Gredilla1,,"{'value': 'Noisy-OR Bayesian Networks (BNs) are a family of probabilistic graphical models which express rich statistical dependencies in binary data. Variational inference (VI) has been the main method proposed to learn noisy-OR BNs with complex latent structures (Jaakkola & Jordan, 1999; Ji et al., 2020; Buhai et al., 2020). However, the proposed VI approaches either (a) use a recognition network with standard amortized inference that cannot induce ""explaining-away""; or (b) assume a simple mean-field (MF) posterior which is vulnerable to bad local optima. Existing MF VI methods also update the MF parameters sequentially which makes them inherently slow. In this paper, we propose parallel max-product as an alternative algorithm for learning noisy-OR BNs with complex latent structures and we derive a fast stochastic training scheme that scales to large datasets. We evaluate both approaches on several benchmarks where VI is the state-of-the-art and show that our method (a) achieves better test performance than Ji et al. (2020) for learning noisy-OR BNs with hierarchical latent structures on large sparse real datasets; (b) recovers a higher number of ground truth parameters than Buhai et al. (2020) from cluttered synthetic scenes; and (c) solves the 2D blind deconvolution problem from Lazaro-Gredilla et al. (2021) and variants - including binary matrix factorization - while VI catastrophically fails and is up to two orders of magnitude slower.'}",https://openreview.net{'value': '/pdf/4bc2b88b74cf08cc0af14739c50089f8198e26c7.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=VLoypBbG3t,{'value': 'MANSA: Learning Fast and Slow in Multi-Agent Systems'},David Henry Mguni; Haojun Chen; Taher Jafferjee; Jianhong Wang; Longfei Yue; Xidong Feng; Stephen Marcus McAleer; Feifei Tong; Jun Wang; Yaodong Yang,~David_Henry_Mguni1; ~Haojun_Chen2; ~Taher_Jafferjee1; ~Jianhong_Wang1; ~Longfei_Yue2; ~Xidong_Feng1; ~Stephen_Marcus_McAleer1; ~Feifei_Tong1; ~Jun_Wang2; ~Yaodong_Yang1,,"{'value': 'In multi-agent reinforcement learning (MARL), independent learning (IL) often shows remarkable performance and easily scales with the number of agents. Yet, using IL can be inefficient and runs the risk of failing to successfully train, particularly in scenarios that require agents to coordinate their actions. Using centralised learning (CL) enables MARL agents to quickly learn how to coordinate their behaviour but employing CL everywhere is often prohibitively expensive in real-world applications. Besides, using CL in value-based methods often needs strong representational constraints (e.g. individual-global-max condition) that can lead to poor performance if violated. In this paper, we introduce a novel plug & play IL framework named Multi-Agent Network Selection Algorithm (MANSA) which selectively employs CL only at states that require coordination. At its core, MANSA has an additional agent that uses switching controls to quickly learn the best states to activate CL during training, using CL only where necessary and vastly reducing the computational burden of CL. Our theory proves MANSA preserves cooperative MARL convergence properties, boosts IL performance and can optimally make use of a fixed budget on the number CL calls. We show empirically in Level-based Foraging (LBF) and StarCraft Multi-agent Challenge (SMAC) that MANSA achieves fast, superior and more reliable performance while making 40% fewer CL calls in SMAC and using CL at only 1% CL calls in LBF.'}",https://openreview.net{'value': '/pdf/4d8d107406ad6d80478f2ae9537c0a74e1990ab5.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=V4jD1KmnQz,{'value': 'Local Optimization Achieves Global Optimality in Multi-Agent Reinforcement Learning'},Yulai Zhao; Zhuoran Yang; Zhaoran Wang; Jason D. Lee,~Yulai_Zhao1; ~Zhuoran_Yang1; ~Zhaoran_Wang1; ~Jason_D._Lee1,,"{'value': 'Policy optimization methods with function approximation are widely used in multi-agent reinforcement learning. However, it remains elusive how to design such algorithms with statistical guarantees. Leveraging a multi-agent performance difference lemma that characterizes the landscape of multi-agent policy optimization, we find that the localized action value function serves as an ideal descent direction for each local policy. Motivated by the observation, we present a multi-agent PPO algorithm in which the local policy of each agent is updated similarly to vanilla PPO. We prove that with standard regularity conditions on the Markov game and problem-dependent quantities, our algorithm converges to the globally optimal policy at a sublinear rate. We extend our algorithm to the off-policy setting and introduce pessimism to policy evaluation, which aligns with experiments. To our knowledge, this is the first provably convergent multi-agent PPO algorithm in cooperative Markov games.'}",https://openreview.net{'value': '/pdf/53cbced07597bf30f212ff35398e24d59c701dfa.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=V1YbiqUsMi,{'value': 'Coupled Variational Autoencoder'},Xiaoran Hao; Patrick Shafto,~Xiaoran_Hao1; ~Patrick_Shafto2,,"{'value': 'Variational auto-encoders are powerful probabilistic models in generative tasks but suffer from generating low-quality samples which are caused by the holes in the prior. We propose the Coupled Variational Auto-Encoder (C-VAE), which formulates the VAE problem as one of Optimal Transport (OT) between the prior and data distributions. The C-VAE allows greater flexibility in priors and natural resolution of the prior hole problem by enforcing coupling between the prior and the data distribution and enables flexible optimization through the primal, dual, and semi-dual formulations of entropic OT. Simulations on synthetic and real data show that the C-VAE outperforms alternatives including VAE, WAE, and InfoVAE in fidelity to the data, quality of the latent representation, and in quality of generated samples.'}",https://openreview.net{'value': '/pdf/c3139a0efa93d44e9f7043aeed088b222ac26ace.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=USiX9gmGRx,{'value': 'Adaptive Estimation of Graphical Models under Total Positivity'},Jiaxi Ying; José Vinícius De Miranda Cardoso; Daniel P. Palomar,~Jiaxi_Ying1; ~José_Vinícius_De_Miranda_Cardoso1; ~Daniel_P._Palomar1,,"{'value': 'We consider the problem of estimating (diagonally dominant) M-matrices as precision matrices in Gaussian graphical models. Such models have shown interesting properties, e.g., the maximum likelihood estimator exists with as little as two observations in the case of M-matrices, and exists even with one observation in the case of diagonally dominant M-matrices. We propose an adaptive multiple-stage estimation method, which refines the estimate by solving a weighted $\\ell_1$-regularized problem in each stage. We further design a unified framework based on gradient projection method to solve the regularized problem, equipped with different projections to handle the constraints of M-matrices and diagonally dominant M-matrices. Theoretical analysis of the estimation error is established. The proposed method outperforms state-of-the-art methods in estimating precision matrices and identifying graph edges, as evidenced by synthetic and financial time-series data sets.'}",https://openreview.net{'value': '/pdf/f526799e3356f1b89443a9634d76126161280c89.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=UDzgqDZc7Q,{'value': 'Cooperative Multi-Agent Reinforcement Learning: Asynchronous Communication and Linear Function Approximation'},Yifei Min; Jiafan He; Tianhao Wang; Quanquan Gu,~Yifei_Min1; ~Jiafan_He1; ~Tianhao_Wang1; ~Quanquan_Gu1,,"{'value': 'We study multi-agent reinforcement learning in the setting of episodic Markov decision processes, where many agents cooperate via communication through a central server. We propose a provably efficient algorithm based on value iteration that can simultaneously allow asynchronous communication and guarantee the benefit of cooperation with low communication complexity. Under linear function approximation, we prove that our algorithm enjoys a $\\tilde{\\mathcal{O}}(d^{3/2}H^2\\sqrt{K})$ regret upper bound with $\\tilde{\\mathcal{O}}(dHM^2)$ communication complexity, where $d$ is the feature dimension, $H$ is the horizon length, $M$ is the total number of agents, and $K$ is the total number of episodes. We also provide a lower bound showing that an $\\Omega(dM)$ communication complexity is necessary to improve the performance through collaboration.'}",https://openreview.net{'value': '/pdf/dd2c086336baca50a15f8bd8533117951f091db9.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=T27zdeulEK,{'value': 'Multi-Agent Best Arm Identification with Private Communications'},Alexandre Rio; Merwan Barlier; Igor Colin; Marta Soare,~Alexandre_Rio1; ~Merwan_Barlier1; ~Igor_Colin1; ~Marta_Soare1,,"{'value': 'We address multi-agent best arm identification with privacy guarantees. In this setting, agents collaborate by communicating to find the optimal arm. To avoid leaking sensitive data through messages, we consider two notions of privacy withholding different kinds of information: differential privacy and $(\\epsilon, \\eta)$-privacy. For each privacy definition, we propose an algorithm based on a two-level successive elimination scheme. We provide theoretical guarantees for the privacy level, accuracy and sample complexity of our algorithms. Experiments on various settings support our theoretical findings.'}",https://openreview.net{'value': '/pdf/a720152e90ebbb6ddea5e1c967840c3970d0814b.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=SryTYOIGJx,{'value': 'Abstract-to-Executable Trajectory Translation for One-Shot Task Generalization'},Stone Tao; Xiaochen Li; Tongzhou Mu; Zhiao Huang; Yuzhe Qin; Hao Su,~Stone_Tao1; ~Xiaochen_Li1; ~Tongzhou_Mu1; ~Zhiao_Huang1; ~Yuzhe_Qin1; ~Hao_Su1,,"{'value': 'Training long-horizon robotic policies in complex physical environments is essential for many applications, such as robotic manipulation. However, learning a policy that can generalize to unseen tasks is challenging. In this work, we propose to achieve one-shot task generalization by decoupling plan generation and plan execution. Specifically, our method solves complex long-horizon tasks in three steps: build a paired abstract environment by simplifying geometry and physics, generate abstract trajectories, and solve the original task by an abstract-to-executable trajectory translator. In the abstract environment, complex dynamics such as physical manipulation are removed, making abstract trajectories easier to generate. However, this introduces a large domain gap between abstract trajectories and the actual executed trajectories as abstract trajectories lack low-level details and are not aligned frame-to-frame with the executed trajectory. In a manner reminiscent of language translation, our approach leverages a seq-to-seq model to overcome the large domain gap between the abstract and executable trajectories, enabling the low-level policy to follow the abstract trajectory. Experimental results on various unseen long-horizon tasks with different robot embodiments demonstrate the practicability of our methods to achieve one-shot task generalization.'}",https://openreview.net{'value': '/pdf/13f414d4cc77938ba1a9ff6fd88cb299f0f26393.pdf'},{'title_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=SpA7YFu02k,{'value': 'Graph Generative Model for Benchmarking Graph Neural Networks'},Minji Yoon; Yue Wu; John Palowitch; Bryan Perozzi; Russ Salakhutdinov,~Minji_Yoon1; ~Yue_Wu17; ~John_Palowitch1; ~Bryan_Perozzi1; ~Russ_Salakhutdinov1,,"{'value': 'As the field of Graph Neural Networks (GNN) continues to grow, it experiences a corresponding increase in the need for large, real-world datasets to train and test new GNN models on challenging, realistic problems. Unfortunately, such graph datasets are often generated from online, highly privacy-restricted ecosystems, which makes research and development on these datasets hard, if not impossible. This greatly reduces the amount of benchmark graphs available to researchers, causing the field to rely only on a handful of publicly-available datasets. To address this problem, we introduce a novel graph generative model, Computation Graph Transformer (CGT) that learns and reproduces the distribution of real-world graphs in a privacy-controlled way. More specifically, CGT (1) generates effective benchmark graphs on which GNNs show similar task performance as on the source graphs, (2) scales to process large-scale graphs, (3) incorporates off-the-shelf privacy modules to guarantee end-user privacy of the generated graph. Extensive experiments across a vast body of graph generative models show that only our model can successfully generate privacy-controlled, synthetic substitutes of large-scale real-world graphs that can be effectively used to benchmark GNN models.'}",https://openreview.net{'value': '/pdf/30e394bdc8cd861b9d4be284c98572f3d404bf6f.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=SdOn9JSyTx,{'value': 'Learning GFlowNets From Partial Episodes For Improved Convergence And Stability'},Kanika Madan; Jarrid Rector-Brooks; Maksym Korablyov; Emmanuel Bengio; Moksh Jain; Andrei Cristian Nica; Tom Bosc; Yoshua Bengio; Nikolay Malkin,~Kanika_Madan3; ~Jarrid_Rector-Brooks2; ~Maksym_Korablyov1; ~Emmanuel_Bengio1; ~Moksh_Jain1; ~Andrei_Cristian_Nica1; ~Tom_Bosc1; ~Yoshua_Bengio1; ~Nikolay_Malkin1,,"{'value': 'Generative flow networks (GFlowNets) are a family of algorithms for training a sequential sampler of discrete objects under an unnormalized target density and have been successfully used for various probabilistic modeling tasks. Existing training objectives for GFlowNets are either local to states or transitions, or propagate a reward signal over an entire sampling trajectory. We argue that these alternatives represent opposite ends of a gradient bias-variance tradeoff and propose a way to exploit this tradeoff to mitigate its harmful effects. Inspired by the TD($\\lambda$) algorithm in reinforcement learning, we introduce *subtrajectory balance* or SubTB($\\lambda$), a GFlowNet training objective that can learn from partial action subsequences of varying lengths. We show that SubTB($\\lambda$) accelerates sampler convergence in previously studied and new environments and enables training GFlowNets in environments with longer action sequences and sparser reward landscapes than what was possible before. We also perform a comparative analysis of stochastic gradient dynamics, shedding light on the bias-variance tradeoff in GFlowNet training and the advantages of subtrajectory balance.'}",https://openreview.net{'value': '/pdf/b385be827f4f645e57b1423196bd3c4ec7997ccc.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=SaZvBUk2q4,{'value': 'Scalable Multi-Agent Reinforcement Learning through Intelligent Information Aggregation'},Siddharth Nayak; Kenneth Choi; Wenqi Ding; Sydney Dolan; Karthik Gopalakrishnan; Hamsa Balakrishnan,~Siddharth_Nayak1; kenchoi@mit.edu; wenqi22@mit.edu; ~Sydney_Dolan1; ~Karthik_Gopalakrishnan3; ~Hamsa_Balakrishnan1,,"{'value': 'We consider the problem of multi-agent navigation and collision avoidance when observations are limited to the local neighborhood of each agent. We propose InforMARL, a novel architecture for multi-agent reinforcement learning (MARL) which uses local information intelligently to compute paths for all the agents in a decentralized manner. Specifically, InforMARL aggregates information about the local neighborhood of agents for both the actor and the critic using a graph neural network and can be used in conjunction with any standard MARL algorithm. We show that (1) in training, InforMARL has better sample efficiency and performance than baseline approaches, despite using less information, and (2) in testing, it scales well to environments with arbitrary numbers of agents and obstacles. We illustrate these results using four task environments, including one with predetermined goals for each agent, and one in which the agents collectively try to cover all goals.'}",https://openreview.net{'value': '/pdf/b18722dfdac26e1edb2a82a1ba9696fbbf54c6bf.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=SP01yVIC2o,{'value': 'ReDi: Efficient Learning-Free Diffusion Inference via Trajectory Retrieval'},Kexun Zhang; Xianjun Yang; William Yang Wang; Lei Li,~Kexun_Zhang1; ~Xianjun_Yang1; ~William_Yang_Wang2; ~Lei_Li11,,"{'value': 'Diffusion models show promising generation capability for a variety of data. Despite their high generation quality, the inference for diffusion models is still time-consuming due to the numerous sampling iterations required. To accelerate the inference, we propose ReDi, a simple yet learning-free Retrieval-based Diffusion sampling framework. From a precomputed knowledge base, ReDi retrieves a trajectory similar to the partially generated trajectory at an early stage of generation, skips a large portion of intermediate steps, and continues sampling from a later step in the retrieved trajectory. We theoretically prove that the generation performance of ReDi is guaranteed. Our experiments demonstrate that ReDi improves the model inference efficiency by 2$\\times$ speedup. Furthermore, ReDi is able to generalize well in zero-shot cross-domain image generation such as image stylization. The code and demo for ReDi is available at https://github.com/zkx06111/ReDiffusion.'}",https://openreview.net{'value': '/pdf/052d344ff7dff4f3368b009868ffec9eb87fe009.pdf'},{'title_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=S1QzeJR9yE,{'value': 'Learning to Decouple Complex Systems'},Zihan Zhou; Tianshu Yu,~Zihan_Zhou7; ~Tianshu_Yu2,,"{'value': 'A complex system with cluttered observations may be a coupled mixture of multiple simple sub-systems corresponding to latent entities. Such sub-systems may hold distinct dynamics in the continuous-time domain; therein, complicated interactions between sub-systems also evolve over time. This setting is fairly common in the real world but has been less considered. In this paper, we propose a sequential learning approach under this setting by decoupling a complex system for handling irregularly sampled and cluttered sequential observations. Such decoupling brings about not only subsystems describing the dynamics of each latent entity but also a meta-system capturing the interaction between entities over time. Specifically, we argue that the meta-system evolving within a simplex is governed by projected differential equations (ProjDEs). We further analyze and provide neural-friendly projection operators in the context of Bregman divergence. Experimental results on synthetic and real-world datasets show the advantages of our approach when facing complex and cluttered sequential data compared to the state-of-the-art.'}",https://openreview.net{'value': '/pdf/13ae85483bb260eadaa940f14fb584d11ff10591.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=RnZhB7kNl0,{'value': 'Continuous Spatiotemporal Transformer'},Antonio Henrique de Oliveira Fonseca; Emanuele Zappala; Josue Ortega Caro; David van Dijk,~Antonio_Henrique_de_Oliveira_Fonseca1; ~Emanuele_Zappala1; ~Josue_Ortega_Caro1; ~David_van_Dijk1,,"{'value': 'Modeling spatiotemporal dynamical systems is a fundamental challenge in machine learning. Transformer models have been very successful in NLP and computer vision where they provide interpretable representations of data. However, a limitation of transformers in modeling continuous dynamical systems is that they are fundamentally discrete time and space models and thus have no guarantees regarding continuous sampling. To address this challenge, we present the Continuous Spatiotemporal Transformer (CST), a new transformer architecture that is designed for modeling of continuous systems. This new framework guarantees a continuous and smooth output via optimization in Sobolev space. We benchmark CST against traditional transformers as well as other spatiotemporal dynamics modeling methods and achieve superior performance in a number of tasks on synthetic and real systems, including learning brain dynamics from calcium imaging data.'}",https://openreview.net{'value': '/pdf/1227977aecf57a3393bf141de64235124df3a54f.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=Rm5Qi57C5I,{'value': 'Do Embodied Agents Dream of Pixelated Sheep: Embodied Decision Making using Language Guided World Modelling'},Kolby Nottingham; Prithviraj Ammanabrolu; Alane Suhr; Yejin Choi; Hannaneh Hajishirzi; Sameer Singh; Roy Fox,~Kolby_Nottingham1; ~Prithviraj_Ammanabrolu1; ~Alane_Suhr1; ~Yejin_Choi1; ~Hannaneh_Hajishirzi1; ~Sameer_Singh1; ~Roy_Fox1,,"{'value': 'Reinforcement learning (RL) agents typically learn tabula rasa, without prior knowledge of the world. However, if initialized with knowledge of high-level subgoals and transitions between subgoals, RL agents could utilize this Abstract World Model (AWM) for planning and exploration. We propose using few-shot large language models (LLMs) to hypothesize an AWM, that will be verified through world experience, to improve sample efficiency of RL agents. Our DECKARD agent applies LLM-guided exploration to item crafting in Minecraft in two phases: (1) the Dream phase where the agent uses an LLM to decompose a task into a sequence of subgoals, the hypothesized AWM; and (2) the Wake phase where the agent learns a modular policy for each subgoal and verifies or corrects the hypothesized AWM. Our method of hypothesizing an AWM with LLMs and then verifying the AWM based on agent experience not only increases sample efficiency over contemporary methods by an order of magnitude but is also robust to and corrects errors in the LLM, successfully blending noisy internet-scale information from LLMs with knowledge grounded in environment dynamics.'}",https://openreview.net{'value': '/pdf/b1744cf1a99a0c2af88dfa47a5d4fe628bfd278d.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=Rg5CRU2M4Z,{'value': 'Meta-learning Parameterized Skills'},Haotian Fu; Shangqun Yu; Saket Tiwari; Michael Littman; George Konidaris,~Haotian_Fu3; ~Shangqun_Yu1; ~Saket_Tiwari2; ~Michael_Littman1; ~George_Konidaris1,,{'value': 'We propose a novel parameterized skill-learning algorithm that aims to learn transferable parameterized skills and synthesize them into a new action space that supports efficient learning in long-horizon tasks. We propose to leverage off-policy Meta-RL combined with a trajectory-centric smoothness term to learn a set of parameterized skills. Our agent can use these learned skills to construct a three-level hierarchical framework that models a Temporally-extended Parameterized Action Markov Decision Process. We empirically demonstrate that the proposed algorithms enable an agent to solve a set of highly difficult long-horizon (obstacle-course and robot manipulation) tasks.'},https://openreview.net{'value': '/pdf/2c9ab2d527e6ab513c3e698e40f2e41f032fe168.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=RYD1UMgTdk,{'value': 'Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models'},Zhihong Shao; Yeyun Gong; yelong shen; Minlie Huang; Nan Duan; Weizhu Chen,~Zhihong_Shao1; ~Yeyun_Gong2; ~yelong_shen1; ~Minlie_Huang1; ~Nan_Duan1; ~Weizhu_Chen1,,"{'value': 'Large language models can perform various reasoning tasks by using chain-of-thought prompting, which guides them to find answers through step-by-step demonstrations. However, the quality of the prompts depends on the demonstrations given to the models, and creating many of them by hand is costly. We introduce Synthetic prompting, a method that leverages a few handcrafted examples to prompt the model to generate more examples by itself, and selects effective demonstrations to elicit better reasoning. Our method alternates between a backward and forward process to generate new examples. The backward process generates a question that match a sampled reasoning chain, so that the question is solvable and clear. The forward process produces a more detailed reasoning chain for the question, improving the quality of the example. We evaluate our method on numerical, symbolic, and algorithmic reasoning tasks, and show that it outperforms existing prompting techniques.'}",https://openreview.net{'value': '/pdf/fd0cdcb658a3ade0fd8e41688e84aa4460f05756.pdf'},{'title_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=RUiWyj6fhN,{'value': 'Collaborative Multi-Agent Heterogeneous Multi-Armed Bandits'},Ronshee Chawla; Daniel Vial; Sanjay Shakkottai; R. Srikant,~Ronshee_Chawla1; ~Daniel_Vial1; ~Sanjay_Shakkottai1; ~R._Srikant1,,"{'value': 'The study of collaborative multi-agent bandits has attracted significant attention recently. In light of this, we initiate the study of a new collaborative setting, consisting of $N$ agents such that each agent is learning one of $M$ stochastic multi-armed bandits to minimize their group cumulative regret. We develop decentralized algorithms which facilitate collaboration between the agents under two scenarios. We characterize the performance of these algorithms by deriving the per agent cumulative regret and group regret upper bounds. We also prove lower bounds for the group regret in this setting, which demonstrates the near-optimal behavior of the proposed algorithms.'}",https://openreview.net{'value': '/pdf/51a2acd0c2980bf7850168f3c8c362a1b5044df6.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=R3d0HoKznc,{'value': 'Causal Strategic Classification: A Tale of Two Shifts'},Guy Horowitz; Nir Rosenfeld,~Guy_Horowitz1; ~Nir_Rosenfeld2,,"{'value': 'When users can benefit from certain predictive outcomes, they may be prone to act to achieve those outcome, e.g., by strategically modifying their features. The goal in strategic classification is therefore to train predictive models that are robust to such behavior. However, the conventional framework assumes that changing features does not change actual outcomes, which depicts users as ""gaming"" the system. Here we remove this assumption, and study learning in a causal strategic setting where true outcomes do change. Focusing on accuracy as our primary objective, we show how strategic behavior and causal effects underlie two complementing forms of distribution shift. We characterize these shifts, and propose a learning algorithm that balances between these two forces and over time, and permits end-to-end training. Experiments on synthetic and semi-synthetic data demonstrate the utility of our approach.'}",https://openreview.net{'value': '/pdf/cd1969699712d7d09f95fdfaa8a6de890a4b9270.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=QwFkJ3QVii,{'value': 'Synthetic data for model selection'},Alon Shoshan; Nadav Bhonker; Igor Kviatkovsky; Matan Fintz; Gerard Medioni,~Alon_Shoshan1; ~Nadav_Bhonker1; ~Igor_Kviatkovsky2; ~Matan_Fintz1; ~Gerard_Medioni1,,"{'value': 'Recent breakthroughs in synthetic data generation approaches made it possible to produce highly photorealistic images which are hardly distinguishable from real ones. Furthermore, synthetic generation pipelines have the potential to generate an unlimited number of images. The combination of high photorealism and scale turn synthetic data into a promising candidate for improving various machine learning (ML) pipelines. Thus far, a large body of research in this field has focused on using synthetic images for training, by augmenting and enlarging training data. In contrast to using synthetic data for training, in this work we explore whether synthetic data can be beneficial for model selection. Considering the task of image classification, we demonstrate that when data is scarce, synthetic data can be used to replace the held out validation set, thus allowing to train on a larger dataset. We also introduce a novel method to calibrate the synthetic error estimation to fit that of the real domain. We show that such calibration significantly improves the usefulness of synthetic data for model selection.'}",https://openreview.net{'value': '/pdf/88c9588208734f17a0eb3b680e5bab742f4273cf.pdf'},{'title_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=Qtix8HLmDx,{'value': 'Gaussian processes at the Helm(holtz): A more fluid model for ocean currents'},Renato Berlinghieri; Brian L. Trippe; David R. Burt; Ryan James Giordano; Kaushik Srinivasan; Tamay Özgökmen; Junfei Xia; Tamara Broderick,~Renato_Berlinghieri1; ~Brian_L._Trippe1; ~David_R._Burt1; ~Ryan_James_Giordano1; kaushiks@ucla.edu; tozgokmen@miami.edu; junfei.xia@earth.miami.edu; ~Tamara_Broderick2,,"{'value': 'Oceanographers are interested in predicting ocean currents and identifying divergences in a current vector field based on sparse observations of buoy velocities. Since we expect current dynamics to be smooth but highly non-linear, Gaussian processes (GPs) offer an attractive model. But we show that applying a GP with a standard stationary kernel directly to buoy data can struggle at both current prediction and divergence identification -- due to some physically unrealistic prior assumptions. To better reflect known physical properties of currents, we propose to instead put a standard stationary kernel on the divergence and curl-free components of a vector field obtained through a Helmholtz decomposition. We show that, because this decomposition relates to the original vector field just via mixed partial derivatives, we can still perform inference given the original data with only a small constant multiple of additional computational expense. We illustrate the benefits of our method on synthetic and real oceans data.'}",https://openreview.net{'value': '/pdf/4a086682f6220a410c4d3e3f7a10479f2665bcaf.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=Qh0Gbq3lkh,"{'value': 'Masked Trajectory Models for Prediction, Representation, and Control'}",Philipp Wu; Arjun Majumdar; Kevin Stone; Yixin Lin; Igor Mordatch; Pieter Abbeel; Aravind Rajeswaran,~Philipp_Wu1; ~Arjun_Majumdar2; ~Kevin_Stone1; ~Yixin_Lin1; ~Igor_Mordatch5; ~Pieter_Abbeel2; ~Aravind_Rajeswaran1,,"{'value': 'We introduce Masked Trajectory Models (MTM) as a generic abstraction for sequential decision making. MTM takes a trajectory, such as a state-action sequence, and aims to reconstruct the trajectory conditioned on random subsets of the same trajectory. By training with a highly randomized masking pattern, MTM learns versatile networks that can take on different roles or capabilities, by simply choosing appropriate masks at inference time. For example, the same MTM network can be used as a forward dynamics model, inverse dynamics model, or even an offline RL agent. Through extensive experiments in several continuous control tasks, we show that the same MTM network -- i.e. same weights -- can match or outperform specialized networks trained for the aforementioned capabilities. Additionally, we find that state representations learned by MTM can significantly accelerate the learning speed of traditional RL algorithms. Finally, in offline RL benchmarks, we find that MTM is competitive with specialized offline RL algorithms, despite MTM being a generic self-supervised learning method without any explicit RL components. Code is available at https://github.com/facebookresearch/mtm.'}",https://openreview.net{'value': '/pdf/a1b57ff7f7c5da89cc08659e6df0c48bb651879c.pdf'},{'title_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=Q3Rmfuj4vf,{'value': 'Returning The Favour: When Regression Benefits From Probabilistic Causal Knowledge'},Shahine Bouabid; Jake Fawkes; Dino Sejdinovic,~Shahine_Bouabid1; ~Jake_Fawkes1; ~Dino_Sejdinovic1,,"{'value': 'A directed acyclic graph (DAG) provides valuable prior knowledge that is often discarded in regression tasks in machine learning. We show that the independences arising from the presence of collider structures in DAGs provide meaningful inductive biases, which constrain the regression hypothesis space and improve predictive performance. We introduce collider regression, a framework to incorporate probabilistic causal knowledge from a collider in a regression problem. When the hypothesis space is a reproducing kernel Hilbert space, we prove a strictly positive generalisation benefit under mild assumptions and provide closed-form estimators of the empirical risk minimiser. Experiments on synthetic and climate model data demonstrate performance gains of the proposed methodology.'}",https://openreview.net{'value': '/pdf/67d0f5b54bca4929ed83f7a7a7f626f1c888cad3.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=PvaPDkAbaL,{'value': 'Improving Fair Training under Correlation Shifts'},Yuji Roh; Kangwook Lee; Steven Euijong Whang; Changho Suh,~Yuji_Roh1; ~Kangwook_Lee1; ~Steven_Euijong_Whang1; ~Changho_Suh1,,"{'value': 'Model fairness is an essential element for Trustworthy AI. While many techniques for model fairness have been proposed, most of them assume that the training and deployment data distributions are identical, which is often not true in practice. In particular, when the bias between labels and sensitive groups changes, the fairness of the trained model is directly influenced and can worsen. We make two contributions for solving this problem. First, we analytically show that existing in-processing fair algorithms have fundamental limits in accuracy and group fairness. We utilize the notion of correlation shifts between labels and groups, which can explicitly capture the change of the above bias. Second, we propose a novel pre-processing step that samples the input data to reduce correlation shifts and thus enables the in-processing approaches to overcome their limitations. We formulate an optimization problem for adjusting the data ratio among labels and sensitive groups to reflect the shifted correlation. A key benefit of our approach lies in decoupling the roles of pre- and in-processing approaches: correlation adjustment via pre-processing and unfairness mitigation on the processed data via in-processing. Experiments show that our framework effectively improves existing in-processing fair algorithms w.r.t. accuracy and fairness, both on synthetic and real datasets.'}",https://openreview.net{'value': '/pdf/6914f0cdc264d7d4c1a38670be4d7a66fb985b02.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=PlFBOnVOFg,{'value': 'Towards Omni-generalizable Neural Methods for Vehicle Routing Problems'},Jianan Zhou; Yaoxin Wu; Wen Song; Zhiguang Cao; Jie Zhang,~Jianan_Zhou1; ~Yaoxin_Wu2; ~Wen_Song1; ~Zhiguang_Cao1; ~Jie_Zhang9,,"{'value': 'Learning heuristics for vehicle routing problems (VRPs) has gained much attention due to the less reliance on hand-crafted rules. However, existing methods are typically trained and tested on the same task with a fixed size and distribution (of nodes), and hence suffer from limited generalization performance. This paper studies a challenging yet realistic setting, which considers generalization across both size and distribution in VRPs. We propose a generic meta-learning framework, which enables effective training of an initialized model with the capability of fast adaptation to new tasks during inference. We further develop a simple yet efficient approximation method to reduce the training overhead. Extensive experiments on both synthetic and benchmark instances of the traveling salesman problem (TSP) and capacitated vehicle routing problem (CVRP) demonstrate the effectiveness of our method. The code is available at: https://github.com/RoyalSkye/Omni-VRP.'}",https://openreview.net{'value': '/pdf/072093147e0ab0813d7fbe6873b0ccf0a4d09738.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=Pckxn5T0PV,{'value': 'The Catalog Problem: Clustering and Ordering Variable-Sized Sets'},Mateusz Maria Jurewicz; Graham W. Taylor; Leon Derczynski,~Mateusz_Maria_Jurewicz1; ~Graham_W._Taylor1; ~Leon_Derczynski1,,"{'value': ""Prediction of a $\\textbf{varying number}$ of $\\textbf{ordered clusters}$ from sets of $\\textbf{any cardinality}$ is a challenging task for neural networks, combining elements of set representation, clustering and learning to order. This task arises in many diverse areas, ranging from medical triage and early discharge, through machine part management and multi-channel signal analysis for petroleum exploration to product catalog structure prediction. This paper focuses on that last area, which exemplifies a number of challenges inherent to adaptive ordered clustering, referred to further as the eponymous $\\textit{Catalog Problem}$. These include learning variable cluster constraints, exhibiting relational reasoning and managing combinatorial complexity. Despite progress in both neural clustering and set-to-sequence methods, no joint, fully differentiable model exists to-date. We develop such a modular architecture, referred to further as Neural Ordered Clusters (NOC), enhance it with a specific mechanism for learning cluster-level cardinality constraints, and provide a robust comparison of its performance in relation to alternative models. We test our method on three datasets, including synthetic catalog structures and PROCAT, a dataset of real-world catalogs consisting of over 1.5M products, achieving state-of-the-art results on a new, more challenging formulation of the underlying problem, which has not been addressed before. Additionally, we examine the network's ability to learn higher-order interactions.""}",https://openreview.net{'value': '/pdf/e2d16a87b151657dd8ab03bf1a38af945964f8fc.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=PWRIIwBJFo,{'value': 'TIDE: Time Derivative Diffusion for Deep Learning on Graphs'},Maysam Behmanesh; Maximilian Krahn; Maks Ovsjanikov,~Maysam_Behmanesh1; ~Maximilian_Krahn1; ~Maks_Ovsjanikov1,,"{'value': 'A prominent paradigm for graph neural networks is based on the message-passing framework. In this framework, information communication is realized only between neighboring nodes. The challenge of approaches that use this paradigm is to ensure efficient and accurate long-distance communication between nodes, as deep convolutional networks are prone to over smoothing. In this paper, we present a novel method based on time derivative graph diffusion (TIDE) to overcome these structural limitations of the message-passing framework. Our approach allows for optimizing the spatial extent of diffusion across various tasks and network channels, thus enabling medium and long-distance communication efficiently. Furthermore, we show that our architecture design also enables local message-passing and thus inherits from the capabilities of local message-passing approaches. We show that on both widely used graph benchmarks and synthetic mesh and graph datasets, the proposed framework outperforms state-of-the-art methods by a significant margin.'}",https://openreview.net{'value': '/pdf/f8ae8be73bfb75a3cd88c40e29e363800668a3f5.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=P78iqH28ni,{'value': 'Coordinated Dynamic Bidding in Repeated Second-Price Auctions with Budgets'},Yurong Chen; Qian Wang; Zhijian Duan; Haoran Sun; Zhaohua Chen; Xiang Yan; Xiaotie Deng,~Yurong_Chen3; ~Qian_Wang22; ~Zhijian_Duan1; ~Haoran_Sun6; ~Zhaohua_Chen1; ~Xiang_Yan2; ~Xiaotie_Deng1,,"{'value': ""In online ad markets, a rising number of advertisers are employing bidding agencies to participate in ad auctions. These agencies are specialized in designing online algorithms and bidding on behalf of their clients. Typically, an agency usually has information on multiple advertisers, so she can potentially coordinate bids to help her clients achieve higher utilities than those under independent bidding. In this paper, we study coordinated online bidding algorithms in repeated second-price auctions with budgets. We propose algorithms that guarantee every client a higher utility than the best she can get under independent bidding. We show that these algorithms achieve maximal social welfare and discuss bidders' incentives to misreport their budgets, in symmetric cases. Our proofs combine the techniques of online learning and equilibrium analysis, overcoming the difficulty of competing with a multi-dimensional benchmark. The performance of our algorithms is further evaluated by experiments on both synthetic and real data. To the best of our knowledge, we are the first to consider bidder coordination in online repeated auctions with constraints.""}",https://openreview.net{'value': '/pdf/2ca9b88241f79907c617104f71545f4aa8956cce.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=OUicoKgvtc,{'value': 'Simple Embodied Language Learning as a Byproduct of Meta-Reinforcement Learning'},Evan Zheran Liu; Sahaana Suri; Tong Mu; Allan Zhou; Chelsea Finn,~Evan_Zheran_Liu1; ~Sahaana_Suri1; ~Tong_Mu1; ~Allan_Zhou1; ~Chelsea_Finn1,,"{'value': 'Whereas machine learning models typically learn language by directly training on language tasks (e.g., next-word prediction), language emerges in human children as a byproduct of solving non-language tasks (e.g., acquiring food). Motivated by this observation, we ask: can embodied reinforcement learning (RL) agents also indirectly learn language from non-language tasks? Learning to associate language with its meaning requires a dynamic environment with varied language. Therefore, we investigate this question in a multi-task environment with language that varies across the different tasks. Specifically, we design an office navigation environment, where the agent’s goal is to find a particular office, and office locations differ in different buildings (i.e., tasks). Each building includes a floor plan with a simple language description of the goal office’s location, which can be visually read as an RGB image when visited. We find RL agents indeed are able to indirectly learn language. Agents trained with current meta-RL algorithms successfully generalize to reading floor plans with held-out layouts and language phrases, and quickly navigate to the correct office, despite receiving no direct language supervision.'}",https://openreview.net{'value': '/pdf/28326b784751f5e243bb184ba2a405030db73fce.pdf'},{'abstract_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=O1j4uFuSVW,{'value': 'Adapting to game trees in zero-sum imperfect information games'},Côme Fiegel; Pierre MENARD; Tadashi Kozuno; Remi Munos; Vianney Perchet; Michal Valko,~Côme_Fiegel1; ~Pierre_MENARD1; ~Tadashi_Kozuno1; ~Remi_Munos1; ~Vianney_Perchet3; ~Michal_Valko1,,"{'value': 'Imperfect information games (IIG) are games in which each player only partially observes the current game state. We study how to learn $\\epsilon$-optimal strategies in a zero-sum IIG through self-play with trajectory feedback. We give a problem-independent lower bound $\\widetilde{\\mathcal{O}}(H(A_{\\mathcal{X}}+B_{\\mathcal{Y}})/\\epsilon^2)$ on the required number of realizations to learn these strategies with high probability, where $H$ is the length of the game, $A_{\\mathcal{X}}$ and $B_{\\mathcal{Y}}$ are the total number of actions for the two players. We also propose two Follow the Regularized leader (FTRL) algorithms for this setting: Balanced FTRL which matches this lower bound, but requires the knowledge of the information set structure beforehand to define the regularization; and Adaptive FTRL which needs $\\widetilde{\\mathcal{O}}(H^2(A_{\\mathcal{X}}+B_{\\mathcal{Y}})/\\epsilon^2)$ realizations without this requirement by progressively adapting the regularization to the observations.'}",https://openreview.net{'value': '/pdf/5eae52f717399458e1365d0f39947a20d4d64682.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=NwICIHHpKf,{'value': 'A Flexible Diffusion Model'},weitao Du; He Zhang; Tao Yang; Yuanqi Du,~weitao_Du1; ~He_Zhang1; ~Tao_Yang9; ~Yuanqi_Du1,,"{'value': 'Denoising diffusion (score-based) generative models have become a popular choice for modeling complex data. Recently, a deep connection between forward-backward stochastic differential equations (SDEs) and diffusion-based models has been established, leading to the development of new SDE variants such as sub-VP and critically-damped Langevin. Despite the empirical success of some hand-crafted forward SDEs, many potentially promising forward SDEs remain unexplored. In this work, we propose a general framework for parameterizing diffusion models, particularly the spatial part of forward SDEs, by leveraging the symplectic and Riemannian geometry of the data manifold. We introduce a systematic formalism with theoretical guarantees and connect it with previous diffusion models. Finally, we demonstrate the theoretical advantages of our method from a variational optimization perspective. We present numerical experiments on synthetic datasets, MNIST and CIFAR10 to validate the effectiveness of our framework.'}",https://openreview.net{'value': '/pdf/bef86ac8385f30929570865e0dc8d295faebf976.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=MocsSAUKlk,{'value': 'Rethinking Explaining Graph Neural Networks via Non-parametric Subgraph Matching'},Fang Wu; Siyuan Li; Xurui Jin; Yinghui Jiang; Dragomir Radev; Zhangming Niu; Stan Z. Li,~Fang_Wu1; ~Siyuan_Li6; ~Xurui_Jin1; yinghui@mindrank.ai; ~Dragomir_Radev2; ~Zhangming_Niu1; ~Stan_Z._Li2,,"{'value': ""The success of graph neural networks (GNNs) provokes the question about explainability: ``Which fraction of the input graph is the most determinant of the prediction?'' Particularly, parametric explainers prevail in existing approaches because of their more robust capability to decipher the black-box (i.e., target GNNs). In this paper, based on the observation that graphs typically share some common motif patterns, we propose a novel non-parametric subgraph matching framework, dubbed MatchExplainer, to explore explanatory subgraphs. It couples the target graph with other counterpart instances and identifies the most crucial joint substructure by minimizing the node corresponding-based distance. Moreover, we note that present graph sampling or node-dropping methods usually suffer from the false positive sampling problem. To alleviate this issue, we design a new augmentation paradigm named MatchDrop. It takes advantage of MatchExplainer to fix the most informative portion of the graph and merely operates graph augmentations on the rest less informative part. Extensive experiments on synthetic and real-world datasets show the effectiveness of our MatchExplainer by outperforming all state-of-the-art parametric baselines with significant margins. Results also demonstrate that MatchDrop is a general scheme to be equipped with GNNs for enhanced performance. The code is available at https://github.com/smiles724/MatchExplainer.""}",https://openreview.net{'value': '/pdf/8b7da3ce0da1d4ed0872daf0f48c25b2b19d49df.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=MP7HOGfLf3,{'value': 'An Adaptive Entropy-Regularization Framework for Multi-Agent Reinforcement Learning'},Woojun Kim; Youngchul Sung,~Woojun_Kim1; ~Youngchul_Sung1,,"{'value': 'In this paper, we propose an adaptive entropy-regularization framework (ADER) for multi-agent reinforcement learning (RL) to learn the adequate amount of exploration of each agent for entropy-based exploration. In order to derive a metric for the proper level of exploration entropy for each agent, we disentangle the soft value function into two types: one for pure return and the other for entropy. By applying multi-agent value factorization to the disentangled value function of pure return, we obtain a metric to determine the relevant level of exploration entropy for each agent, given by the partial derivative of the pure-return value function with respect to (w.r.t.) the policy entropy of each agent. Based on this metric, we propose the ADER algorithm based on maximum entropy RL, which controls the necessary level of exploration across agents over time by learning the proper target entropy for each agent. Experimental results show that the proposed scheme significantly outperforms current state-of-the-art multi-agent RL algorithms.'}",https://openreview.net{'value': '/pdf/17ddf6a7c13bf50176accb589f983aaf66d6b0ba.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=MGDYQNXjCg,{'value': 'A Game-Theoretic Framework for Managing Risk in Multi-Agent Systems'},Oliver Slumbers; David Henry Mguni; Stefano B Blumberg; Stephen Marcus McAleer; Yaodong Yang; Jun Wang,~Oliver_Slumbers1; ~David_Henry_Mguni1; ~Stefano_B_Blumberg1; ~Stephen_Marcus_McAleer1; ~Yaodong_Yang1; ~Jun_Wang2,,"{'value': 'In order for agents in multi-agent systems (MAS) to be safe, they need to take into account the risks posed by the actions of other agents. However, the dominant paradigm in game theory (GT) assumes that agents are not affected by risk from other agents and only strive to maximise their expected utility. For example, in hybrid human-AI driving systems, it is necessary to limit large deviations in reward resulting from car crashes. Although there are equilibrium concepts in game theory that take into account risk aversion, they either assume that agents are risk-neutral with respect to the uncertainty caused by the actions of other agents, or they are not guaranteed to exist. We introduce a new GT-based Risk-Averse Equilibrium (RAE) that always produces a solution that minimises the potential variance in reward accounting for the strategy of other agents. Theoretically and empirically, we show RAE shares many properties with a Nash Equilibrium (NE), establishing convergence properties and generalising to risk-dominant NE in certain cases. To tackle large-scale problems, we extend RAE to the PSRO multi-agent reinforcement learning (MARL) framework. We empirically demonstrate the minimum reward variance benefits of RAE in matrix games with high-risk outcomes. Results on MARL experiments show RAE generalises to risk-dominant NE in a trust dilemma game and that it reduces instances of crashing by 7x in an autonomous driving setting versus the best performing baseline.'}",https://openreview.net{'value': '/pdf/c58a9d2f39410c248719cff7e0c4da08dd04d5a1.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=M3IX2zAIdi,{'value': 'Learning Controllable Degradation for Real-World Super-Resolution via Constrained Flows'},Seobin Park; Dongjin Kim; Sungyong Baik; Tae Hyun Kim,~Seobin_Park1; ~Dongjin_Kim3; ~Sungyong_Baik1; ~Tae_Hyun_Kim2,,"{'value': 'Recent deep-learning-based super-resolution (SR) methods have been successful in recovering high-resolution (HR) images from their low-resolution (LR) counterparts, albeit on the synthetic and simple degradation setting: bicubic downscaling. On the other hand, super-resolution on real-world images demands the capability to handle complex downscaling mechanism which produces different artifacts (e.g., noise, blur, color distortion) upon downscaling factors. To account for complex downscaling mechanism in real-world LR images, there have been a few efforts in constructing datasets consisting of LR images with real-world downsampling degradation. However, making such datasets entails a tremendous amount of time and effort, thereby resorting to very few number of downscaling factors (e.g., $\\times$2, $\\times$3, $\\times$4). To remedy the issue, we propose to generate realistic SR datasets for unseen degradation levels by exploring the latent space of real LR images and thereby producing more diverse yet realistic LR images with complex real-world artifacts. Our quantitative and qualitative experiments demonstrate the accuracy of the generated LR images, and we show that the various conventional SR networks trained with our newly generated SR datasets can produce much better HR images.'}",https://openreview.net{'value': '/pdf/26a8ce480eb3f6cb83b7f575f38b15ef86e49b0e.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=LztkK0UZxS,{'value': 'Predicting Ordinary Differential Equations with Transformers'},Sören Becker; Michal Klein; Alexander Neitz; Giambattista Parascandolo; Niki Kilbertus,~Sören_Becker2; ~Michal_Klein1; ~Alexander_Neitz1; ~Giambattista_Parascandolo1; ~Niki_Kilbertus1,,"{'value': 'We develop a transformer-based sequence-to-sequence model that recovers scalar ordinary differential equations (ODEs) in symbolic form from irregularly sampled and noisy observations of a single solution trajectory. We demonstrate in extensive empirical evaluations that our model performs better or on par with existing methods in terms of accurate recovery across various settings. Moreover, our method is efficiently scalable: after one-time pretraining on a large set of ODEs, we can infer the governing law of a new observed solution in a few forward passes of the model.'}",https://openreview.net{'value': '/pdf/1adef285e073c2ee7ce8aa0cc6813f0b1e371e95.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=LxohF7Id88,{'value': 'Mechanistic Mode Connectivity'},Ekdeep Singh Lubana; Eric J Bigelow; Robert P. Dick; David Krueger; Hidenori Tanaka,~Ekdeep_Singh_Lubana1; ~Eric_J_Bigelow1; ~Robert_P._Dick1; ~David_Krueger1; ~Hidenori_Tanaka1,,"{'value': ""We study neural network loss landscapes through the lens of mode connectivity, the observation that minimizers of neural networks retrieved via training on a dataset are connected via simple paths of low loss. Specifically, we ask the following question: are minimizers that rely on different mechanisms for making their predictions connected via simple paths of low loss? We provide a definition of mechanistic similarity as shared invariances to input transformations and demonstrate that lack of linear connectivity between two models implies they use dissimilar mechanisms for making their predictions. Relevant to practice, this result helps us demonstrate that naive fine-tuning on a downstream dataset can fail to alter a model's mechanisms, e.g., fine-tuning can fail to eliminate a model's reliance on spurious attributes. Our analysis also motivates a method for targeted alteration of a model's mechanisms, named connectivity-based fine-tuning (CBFT), which we analyze using several synthetic datasets for the task of reducing a model's reliance on spurious attributes.""}",https://openreview.net{'value': '/pdf/d8120a9e5f68a06d7218d7d1b58765f532296665.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=LwSKljRST0,"{'value': '""Why did the Model Fail?"": Attributing Model Performance Changes to Distribution Shifts'}",Haoran Zhang; Harvineet Singh; Marzyeh Ghassemi; Shalmali Joshi,~Haoran_Zhang4; ~Harvineet_Singh1; ~Marzyeh_Ghassemi2; ~Shalmali_Joshi1,,"{'value': 'Machine learning models frequently experience performance drops under distribution shifts. The underlying cause of such shifts may be multiple simultaneous factors such as changes in data quality, differences in specific covariate distributions, or changes in the relationship between label and features. When a model does fail during deployment, attributing performance change to these factors is critical for the model developer to identify the root cause and take mitigating actions. In this work, we introduce the problem of attributing performance differences between environments to distribution shifts in the underlying data generating mechanisms. We formulate the problem as a cooperative game where the players are distributions. We define the value of a set of distributions to be the change in model performance when only this set of distributions has changed between environments, and derive an importance weighting method for computing the value of an arbitrary set of distributions. The contribution of each distribution to the total performance change is then quantified as its Shapley value. We demonstrate the correctness and utility of our method on synthetic, semi-synthetic, and real-world case studies, showing its effectiveness in attributing performance changes to a wide range of distribution shifts.'}",https://openreview.net{'value': '/pdf/6ec0e2ef7e9eeb70422ebe2b2b34d3d0f6dc9589.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=LVluQl5lAk,{'value': 'Multi-Agent Learning from Learners'},Mine Melodi Caliskan; Francesco Chini; Setareh Maghsudi,~Mine_Melodi_Caliskan1; ~Francesco_Chini1; setareh.maghsudi@uni-tuebingen.de,,"{'value': 'A large body of the ""Inverse Reinforcement Learning"" (IRL) literature focuses on recovering the reward function from a set of demonstrations of an expert agent who acts optimally or noisily optimally. Nevertheless, some recent works move away from the optimality assumption to study the ""Learning from a Learner (LfL)"" problem, where the challenge is inferring the reward function of a learning agent from a sequence of demonstrations produced by progressively improving policies. In this work, we take one of the initial steps in addressing the multi-agent version of this problem and propose a new algorithm, MA-LfL (Multiagent Learning from a Learner). Unlike the state-of-the-art literature, which recovers the reward functions from trajectories produced by agents in some equilibrium, we study the problem of inferring the reward functions of interacting agents in a general sum stochastic game without assuming any equilibrium state. The MA-LfL algorithm is rigorously built on a theoretical result that ensures its validity in the case of agents learning according to a multi-agent soft policy iteration scheme. We empirically test MA-LfL and we observe high positive correlation between the recovered reward functions and the ground truth.'}",https://openreview.net{'value': '/pdf/9ac92324dafc36e72e3edbbe641484e11ccf8579.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=LVARH5wXM9,{'value': 'Feature Programming for Multivariate Time Series Prediction'},Alex Daniel Reneau; Jerry Yao-Chieh Hu; Ammar Gilani; Han Liu,~Alex_Daniel_Reneau1; ~Jerry_Yao-Chieh_Hu1; ~Ammar_Gilani1; ~Han_Liu4,,"{'value': 'We introduce the concept of programmable feature engineering for time series modeling and propose a feature programming framework. This framework generates large amounts of predictive features for noisy multivariate time series while allowing users to incorporate their inductive bias with minimal effort. The key motivation of our framework is to view any multivariate time series as a cumulative sum of fine-grained trajectory increments, with each increment governed by a novel spin-gas dynamical Ising model. This fine-grained perspective motivates the development of a parsimonious set of operators that summarize multivariate time series in an abstract fashion, serving as the foundation for large-scale automated feature engineering. Numerically, we validate the efficacy of our method on several synthetic and real-world noisy time series datasets.'}",https://openreview.net{'value': '/pdf/aab44d08b4698cfcf73dff2536c9be955de6f3fc.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=LMay53U4ke,{'value': 'GREAD: Graph Neural Reaction-Diffusion Networks'},Jeongwhan Choi; Seoyoung Hong; Noseong Park; Sung-Bae Cho,~Jeongwhan_Choi1; ~Seoyoung_Hong1; ~Noseong_Park1; ~Sung-Bae_Cho1,,"{'value': 'Graph neural networks (GNNs) are one of the most popular research topics for deep learning. GNN methods typically have been designed on top of the graph signal processing theory. In particular, diffusion equations have been widely used for designing the core processing layer of GNNs, and therefore they are inevitably vulnerable to the notorious oversmoothing problem. Recently, a couple of papers paid attention to reaction equations in conjunctions with diffusion equations. However, they all consider limited forms of reaction equations. To this end, we present a reaction-diffusion equation-based GNN method that considers all popular types of reaction equations in addition to one special reaction equation designed by us. To our knowledge, our paper is one of the most comprehensive studies on reaction-diffusion equation-based GNNs. In our experiments with 9 datasets and 28 baselines, our method, called GREAD, outperforms them in a majority of cases. Further synthetic data experiments show that it mitigates the oversmoothing problem and works well for various homophily rates.'}",https://openreview.net{'value': '/pdf/9048cbaccc84e9977a22f448d58fea6070563276.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=LMXgU4zrq6,{'value': 'How Do Transformers Learn Topic Structure: Towards a Mechanistic Understanding'},Yuchen Li; Yuanzhi Li; Andrej Risteski,~Yuchen_Li5; ~Yuanzhi_Li1; ~Andrej_Risteski2,,"{'value': ""While the successes of transformers across many domains are indisputable, accurate understanding of the learning mechanics is still largely lacking. Their capabilities have been probed on benchmarks which include a variety of structured and reasoning tasks---but mathematical understanding is lagging substantially behind. Recent lines of work have begun studying representational aspects of this question: that is, the size/depth/complexity of attention-based networks to perform certain tasks. However, there is no guarantee the learning dynamics will converge to the constructions proposed. In our paper, we provide fine-grained mechanistic understanding of how transformers learn ``semantic structure'', understood as capturing co-occurrence structure of words. Precisely, we show, through a combination of mathematical analysis and experiments on Wikipedia data and synthetic data modeled by Latent Dirichlet Allocation (LDA), that the embedding layer and the self-attention layer encode the topical structure. In the former case, this manifests as higher average inner product of embeddings between same-topic words. In the latter, it manifests as higher average pairwise attention between same-topic words. The mathematical results involve several assumptions to make the analysis tractable, which we verify on data, and might be of independent interest as well.""}",https://openreview.net{'value': '/pdf/6513b976812ed78990056c8316d885f76fe815c9.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=Kw90j2pNSt,{'value': 'Generative Causal Representation Learning for Out-of-Distribution Motion Forecasting'},Shayan Shirahmad Gale Bagi; Zahra Gharaee; Oliver Schulte; Mark Crowley,~Shayan_Shirahmad_Gale_Bagi1; ~Zahra_Gharaee1; ~Oliver_Schulte1; ~Mark_Crowley1,,"{'value': 'Conventional supervised learning methods typically assume i.i.d samples and are found to be sensitive to out-of-distribution (OOD) data. We propose Generative Causal Representation Learning (GCRL) which leverages causality to facilitate knowledge transfer under distribution shifts. While we evaluate the effectiveness of our proposed method in human trajectory prediction models, GCRL can be applied to other domains as well. First, we propose a novel causal model that explains the generative factors in motion forecasting datasets using features that are common across all environments and with features that are specific to each environment. Selection variables are used to determine which parts of the model can be directly transferred to a new environment without fine-tuning. Second, we propose an end-to-end variational learning paradigm to learn the causal mechanisms that generate observations from features. GCRL is supported by strong theoretical results that imply identifiability of the causal model under certain assumptions. Experimental results on synthetic and real-world motion forecasting datasets show the robustness and effectiveness of our proposed method for knowledge transfer under zero-shot and low-shot settings by substantially outperforming the prior motion forecasting models on out-of-distribution prediction.'}",https://openreview.net{'value': '/pdf/f61a767c4034111970e73908a6ba9a3b62b8bc6d.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=KhizXcNnY6,{'value': 'Learning Control by Iterative Inversion'},Gal Leibovich; Guy Jacob; Or Avner; Gal Novik; Aviv Tamar,~Gal_Leibovich1; ~Guy_Jacob1; ~Or_Avner1; ~Gal_Novik1; ~Aviv_Tamar2,,"{'value': 'We propose *iterative inversion* - an algorithm for learning an inverse function without input-output pairs, but only with samples from the desired output distribution and access to the forward function. The key challenge is a *distribution shift* between the desired outputs and the outputs of an initial random guess, and we prove that iterative inversion can steer the learning correctly, under rather strict conditions on the function. We apply iterative inversion to learn control. Our input is a set of demonstrations of desired behavior, given as video embeddings of trajectories (without actions), and our method iteratively learns to imitate trajectories generated by the current policy, perturbed by random exploration noise. Our approach does not require rewards, and only employs supervised learning, which can be easily scaled to use state-of-the-art trajectory embedding techniques and policy representations. Indeed, with a VQ-VAE embedding, and a transformer-based policy, we demonstrate non-trivial continuous control on several tasks (videos available at https://sites.google.com/view/iter-inver). Further, we report an improved performance on imitating diverse behaviors compared to reward based methods.'}",https://openreview.net{'value': '/pdf/23bf50d966796af6de16a091df40a4c0f353283d.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=KQaMjvlUE6,{'value': 'Competing for Shareable Arms in Multi-Player Multi-Armed Bandits'},Renzhe Xu; Haotian Wang; Xingxuan Zhang; Bo Li; Peng Cui,~Renzhe_Xu1; ~Haotian_Wang2; ~Xingxuan_Zhang1; ~Bo_Li29; ~Peng_Cui1,,"{'value': ""Competitions for shareable and limited resources have long been studied with strategic agents. In reality, agents often have to learn and maximize the rewards of the resources at the same time. To design an individualized competing policy, we model the competition between agents in a novel multi-player multi-armed bandit (MPMAB) setting where players are selfish and aim to maximize their own rewards. In addition, when several players pull the same arm, we assume that these players averagely share the arms' rewards by expectation. Under this setting, we first analyze the Nash equilibrium when arms' rewards are known. Subsequently, we propose a novel Selfish MPMAB with Averaging Allocation (SMAA) approach based on the equilibrium. We theoretically demonstrate that SMAA could achieve a good regret guarantee for each player when all players follow the algorithm. Additionally, we establish that no single selfish player can significantly increase their rewards through deviation, nor can they detrimentally affect other players' rewards without incurring substantial losses for themselves. We finally validate the effectiveness of the method in extensive synthetic experiments.""}",https://openreview.net{'value': '/pdf/ae9370e0f15c0f7f9e83f797a669085c840e021f.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=KKaTURYcKG,{'value': 'Pairwise Ranking Losses of Click-Through Rates Prediction for Welfare Maximization in Ad Auctions'},Boxiang Lyu; Zhe Feng; Zachary Robertson; Oluwasanmi O Koyejo,~Boxiang_Lyu1; ~Zhe_Feng3; ~Zachary_Robertson1; ~Oluwasanmi_O_Koyejo1,,"{'value': ""We study the design of loss functions for click-through rates (CTR) to optimize (social) welfare in advertising auctions. Existing works either only focus on CTR predictions without consideration of business objectives (e.g., welfare) in auctions or assume that the distribution over the participants' expected cost-per-impression (eCPM) is known a priori, then use various additional assumptions on the parametric form of the distribution to derive loss functions for predicting CTRs. In this work, we bring back the welfare objectives of ad auctions into CTR predictions and propose a novel weighted rankloss to train the CTR model. Compared to existing literature, our approach provides a provable guarantee on welfare but without assumptions on the eCPMs' distribution while also avoiding the intractability of naively applying existing learning-to-rank methods. Further, we propose a theoretically justifiable technique for calibrating the losses using labels generated from a teacher network, only assuming that the teacher network has bounded $\\ell_2$ generalization error. Finally, we demonstrate the advantages of the proposed loss on synthetic and real-world data.""}",https://openreview.net{'value': '/pdf/888023efc8146db641b913a3e1471f01fe4fcc71.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=K26zQKvXiR,{'value': 'Target-Aware Generative Augmentations for Single-Shot Adaptation'},Kowshik Thopalli; Rakshith Subramanyam; Pavan K. Turaga; Jayaraman J. Thiagarajan,~Kowshik_Thopalli1; ~Rakshith_Subramanyam1; ~Pavan_K._Turaga1; ~Jayaraman_J._Thiagarajan3,,"{'value': 'In this paper, we address the problem of adapting models from a source domain to a target domain, a task that has become increasingly important due to the brittle generalization of deep neural networks. While several test-time adaptation techniques have emerged, they typically rely on synthetic toolbox data augmentations in cases of limited target data availability. We consider the challenging setting of single-shot adaptation and explore the design of augmentation strategies. We argue that augmentations utilized by existing methods are insufficient to handle large distribution shifts, and hence propose a new approach SiSTA, which first fine-tunes a generative model from the source domain using a single-shot target, and then employs novel sampling strategies for curating synthetic target data. Using experiments on a variety of benchmarks, distribution shifts and image corruptions, we find that SiSTA produces significantly improved generalization over existing baselines in face attribute detection and multi-class object recognition. Furthermore, SiSTA performs competitively to models obtained by training on larger target datasets. Our codes can be accessed at https://github.com/Rakshith-2905/SiSTA'}",https://openreview.net{'value': '/pdf/2edce30f859161b9d42e8d17d5358f17ac1a7eae.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=K1sJiHvy02,{'value': 'Label differential privacy and private training data release'},Robert Istvan Busa-Fekete; Andres Munoz medina; Umar Syed; Sergei Vassilvitskii,~Robert_Istvan_Busa-Fekete1; ~Andres_Munoz_medina1; ~Umar_Syed1; ~Sergei_Vassilvitskii2,,"{'value': ""We study differentially private mechanisms for sharing training data in machine learning settings. Our goal is to enable learning of an accurate predictive model while protecting the privacy of each user's label. Previous work established privacy guarantees that assumed the features are public and given exogenously, a setting known as label differential privacy. In some scenarios, this can be a strong assumption that removes the interplay between features and labels from the privacy analysis. We relax this approach and instead assume the features are drawn from a distribution that depends on the private labels. We first show that simply adding noise to the label, as in previous work, can lead to an arbitrarily weak privacy guarantee, and also present methods for estimating this privacy loss from data. We then present a new mechanism that replaces some training examples with synthetically generated data, and show that our mechanism has a much better privacy-utility tradeoff if the synthetic data is ‘realistic’, in a certain quantifiable sense. Finally, we empirically validate our theoretical analysis.""}",https://openreview.net{'value': '/pdf/119b500c23686f8cfb872f02b117adb41aa8a232.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=K0InBsKODr,{'value': 'Low-Variance Gradient Estimation in Unrolled Computation Graphs with ES-Single'},Paul Vicol,~Paul_Vicol1,,"{'value': 'We propose an evolution strategies-based algorithm for estimating gradients in unrolled computation graphs, called ES-Single. Similarly to the recently-proposed Persistent Evolution Strategies (PES), ES-Single is unbiased, and overcomes chaos arising from recursive function applications by smoothing the meta-loss landscape. ES-Single samples a single perturbation per particle, that is kept fixed over the course of an inner problem (e.g., perturbations are not re-sampled for each partial unroll). Compared to PES, ES-Single is simpler to implement and has lower variance: the variance of ES-Single is constant with respect to the number of truncated unrolls, removing a key barrier in applying ES to long inner problems using short truncations. We show that ES-Single is unbiased for quadratic inner problems, and demonstrate empirically that its variance can be substantially lower than that of PES. ES-Single consistently outperforms PES on a variety of tasks, including a synthetic benchmark task, hyperparameter optimization, training recurrent neural networks, and training learned optimizers.'}",https://openreview.net{'value': '/pdf/478f1eca12f53253d943f86bcad71e72b425db06.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=K07XAlzh5i,{'value': 'From Relational Pooling to Subgraph GNNs: A Universal Framework for More Expressive Graph Neural Networks'},Cai Zhou; Xiyuan Wang; Muhan Zhang,~Cai_Zhou2; ~Xiyuan_Wang1; ~Muhan_Zhang1,,"{'value': 'Relational pooling is a framework for building more expressive and permutation-invariant graph neural networks. However, there is limited understanding of the exact enhancement in the expressivity of RP and its connection with the Weisfeiler-Lehman hierarchy. Starting from RP, we propose to explicitly assign labels to nodes as additional features to improve graph isomorphism distinguishing power of message passing neural networks. The method is then extended to higher-dimensional WL, leading to a novel $k,l$-WL algorithm, a more general framework than $k$-WL. We further introduce the subgraph concept into our hierarchy and propose a localized $k,l$-WL framework, incorporating a wide range of existing work, including many subgraph GNNs. Theoretically, we analyze the expressivity of $k,l$-WL w.r.t. $k$ and $l$ and compare it with the traditional $k$-WL. Complexity reduction methods are also systematically discussed to build powerful and practical $k,l$-GNN instances. We theoretically and experimentally prove that our method is universally compatible and capable of improving the expressivity of any base GNN model. Our $k,l$-GNNs achieve superior performance on many synthetic and real-world datasets, which verifies the effectiveness of our framework.'}",https://openreview.net{'value': '/pdf/6096afc27dd9cc64de0bbe01a76cc5bb17c03a91.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=JzZ2xAvCs8,{'value': 'Loss-Guided Diffusion Models for Plug-and-Play Controllable Generation'},Jiaming Song; Qinsheng Zhang; Hongxu Yin; Morteza Mardani; Ming-Yu Liu; Jan Kautz; Yongxin Chen; Arash Vahdat,~Jiaming_Song1; ~Qinsheng_Zhang1; ~Hongxu_Yin2; ~Morteza_Mardani1; ~Ming-Yu_Liu1; ~Jan_Kautz1; ~Yongxin_Chen1; ~Arash_Vahdat3,,"{'value': 'We consider guiding denoising diffusion models with general differentiable loss functions in a plug-and-play fashion, enabling controllable generation without additional training. This paradigm, termed Loss-Guided Diffusion (LGD), can easily be integrated into all diffusion models and leverage various efficient samplers. Despite the benefits, the resulting guidance term is, unfortunately, an intractable integral and needs to be approximated. Existing methods compute the guidance term based on a point estimate. However, we show that such approaches have significant errors over the scale of the approximations. To address this issue, we propose a Monte Carlo method that uses multiple samples from a suitable distribution to reduce bias. Our method is effective in various synthetic and real-world settings, including image super-resolution, text or label-conditional image generation, and controllable motion synthesis. Notably, we show how our method can be applied to control a pretrained motion diffusion model to follow certain paths and avoid obstacles that are proven challenging to prior methods.'}",https://openreview.net{'value': '/pdf/5b5abfd63adb98adfd25a87d3df1d4a16192aa9f.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=JrSWhb7dzp,{'value': 'DRCFS: Doubly Robust Causal Feature Selection'},Francesco Quinzan; Ashkan Soleymani; Patrick Jaillet; Cristian R. Rojas; Stefan Bauer,~Francesco_Quinzan1; ~Ashkan_Soleymani1; ~Patrick_Jaillet1; ~Cristian_R._Rojas2; ~Stefan_Bauer1,,"{'value': 'Knowing the features of a complex system that are highly relevant to a particular target variable is of fundamental interest in many areas of science. Existing approaches are often limited to linear settings, sometimes lack guarantees, and in most cases, do not scale to the problem at hand, in particular to images. We propose DRCFS, a doubly robust feature selection method for identifying the causal features even in nonlinear and high dimensional settings. We provide theoretical guarantees, illustrate necessary conditions for our assumptions, and perform extensive experiments across a wide range of simulated and semi-synthetic datasets. DRCFS significantly outperforms existing state-of-the-art methods, selecting robust features even in challenging highly non-linear and high-dimensional problems.'}",https://openreview.net{'value': '/pdf/7ef28637d0c0229850be510ee8c7c3e7b68eab9e.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=Jpbyykdtmt,{'value': 'PAC-Bayesian Generalization Bounds for Adversarial Generative Models'},Sokhna Diarra Mbacke; Florence Clerc; Pascal Germain,~Sokhna_Diarra_Mbacke1; ~Florence_Clerc1; ~Pascal_Germain1,,"{'value': 'We extend PAC-Bayesian theory to generative models and develop generalization bounds for models based on the Wasserstein distance and the total variation distance. Our first result on the Wasserstein distance assumes the instance space is bounded, while our second result takes advantage of dimensionality reduction. Our results naturally apply to Wasserstein GANs and Energy-Based GANs, and our bounds provide new training objectives for these two. Although our work is mainly theoretical, we perform numerical experiments showing non-vacuous generalization bounds for Wasserstein GANs on synthetic datasets.'}",https://openreview.net{'value': '/pdf/211d20a40ff43e74edbda87c67cc4e527cb14f98.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=JK0hiktaFV,{'value': 'Beam Tree Recursive Cells'},Jishnu Ray Chowdhury; Cornelia Caragea,~Jishnu_Ray_Chowdhury2; ~Cornelia_Caragea2,,"{'value': 'We propose Beam Tree Recursive Cell (BT-Cell) - a backpropagation-friendly framework to extend Recursive Neural Networks (RvNNs) with beam search for latent structure induction. We further extend this framework by proposing a relaxation of the hard top-$k$ operators in beam search for better propagation of gradient signals. We evaluate our proposed models in different out-of-distribution splits in both synthetic and realistic data. Our experiments show that BT-Cell achieves near-perfect performance on several challenging structure-sensitive synthetic tasks like ListOps and logical inference while maintaining comparable performance in realistic data against other RvNN-based models. Additionally, we identify a previously unknown failure case for neural models in generalization to unseen number of arguments in ListOps. The code is available at: https://github.com/JRC1995/BeamTreeRecursiveCells.'}",https://openreview.net{'value': '/pdf/76453ccf0474f0a8c3e5433df8b52149e906b7fe.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=Iwt7oI9cNb,{'value': 'Inferring Relational Potentials in Interacting Systems'},Armand Comas; Yilun Du; Christian Fernandez Lopez; Sandesh Ghimire; Mario Sznaier; Joshua B. Tenenbaum; Octavia Camps,~Armand_Comas1; ~Yilun_Du1; ~Christian_Fernandez_Lopez1; ~Sandesh_Ghimire2; ~Mario_Sznaier1; ~Joshua_B._Tenenbaum1; ~Octavia_Camps1,,"{'value': 'Systems consisting of interacting agents are prevalent in the world, ranging from dynamical systems in physics to complex biological networks. To build systems which can interact robustly in the real world, it is thus important to be able to infer the precise interactions governing such systems. Existing approaches typically discover such interactions by explicitly modeling the feed-forward dynamics of the trajectories. In this work, we propose Neural Interaction Inference with Potentials (NIIP) as an alternative approach to discover such interactions that enables greater flexibility in trajectory modeling: it discovers a set of relational potentials, represented as energy functions, which when minimized reconstruct the original trajectory. NIIP assigns low energy to the subset of trajectories which respect the relational constraints observed. We illustrate that with these representations NIIP displays unique capabilities in test-time. First, it allows trajectory manipulation, such as interchanging interaction types across separately trained models, as well as trajectory forecasting. Additionally, it allows adding external hand-crafted potentials at test-time. Finally, NIIP enables the detection of out-of-distribution samples and anomalies without explicit training.'}",https://openreview.net{'value': '/pdf/cc369e2dfdc541d6798be36a358ec26488f7352c.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=ImQC3p9wlm,{'value': 'Mirror Sinkhorn: Fast Online Optimization on Transport Polytopes'},Marin Ballu; Quentin Berthet,marin.ballu@gmail.com; ~Quentin_Berthet2,,"{'value': 'Optimal transport is an important tool in machine learning, allowing to capture geometric properties of the data through a linear program on transport polytopes. We present a single-loop optimization algorithm for minimizing general convex objectives on these domains, utilizing the principles of Sinkhorn matrix scaling and mirror descent. The proposed algorithm is robust to noise, and can be used in an online setting. We provide theoretical guarantees for convex objectives and experimental results showcasing it effectiveness on both synthetic and real-world data.'}",https://openreview.net{'value': '/pdf/e4b217b8f76c4f9fa80da32860688647b1b57959.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=IOVYTyoqVz,{'value': 'Image Restoration with Mean-Reverting Stochastic Differential Equations'},Ziwei Luo; Fredrik K. Gustafsson; Zheng Zhao; Jens Sjölund; Thomas B. Schön,~Ziwei_Luo1; ~Fredrik_K._Gustafsson1; ~Zheng_Zhao1; ~Jens_Sjölund1; ~Thomas_B._Schön1,,"{'value': 'This paper presents a stochastic differential equation (SDE) approach for general-purpose image restoration. The key construction consists in a mean-reverting SDE that transforms a high-quality image into a degraded counterpart as a mean state with fixed Gaussian noise. Then, by simulating the corresponding reverse-time SDE, we are able to restore the origin of the low-quality image without relying on any task-specific prior knowledge. Crucially, the proposed mean-reverting SDE has a closed-form solution, allowing us to compute the ground truth time-dependent score and learn it with a neural network. Moreover, we propose a maximum likelihood objective to learn an optimal reverse trajectory that stabilizes the training and improves the restoration results. The experiments show that our proposed method achieves highly competitive performance in quantitative comparisons on image deraining, deblurring, and denoising, setting a new state-of-the-art on two deraining datasets. Finally, the general applicability of our approach is further demonstrated via qualitative results on image super-resolution, inpainting, and dehazing. Code is available at https://github.com/Algolzw/image-restoration-sde.'}",https://openreview.net{'value': '/pdf/e0e76a5fc2a8f87a1e5a569e57a9b04108c45308.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=IKCk6th595,{'value': 'MetaDiffuser: Diffusion Model as Conditional Planner for Offline Meta-RL'},Fei Ni; Jianye HAO; Yao Mu; Yifu Yuan; YAN ZHENG; Bin Wang; Zhixuan Liang,~Fei_Ni1; ~Jianye_HAO1; ~Yao_Mu1; ~Yifu_Yuan1; ~YAN_ZHENG1; ~Bin_Wang12; ~Zhixuan_Liang2,,"{'value': 'Recently, diffusion model shines as a promising backbone for the sequence modeling paradigm in offline reinforcement learning(RL). However, these works mostly lack the generalization ability across tasks with reward or dynamics change. To tackle this challenge, in this paper we propose a task-oriented conditioned diffusion planner for offline meta-RL(MetaDiffuser), which considers the generalization problem as conditional trajectory generation task with contextual representation. The key is to learn a context conditioned diffusion model which can generate task-oriented trajectories for planning across diverse tasks. To enhance the dynamics consistency of the generated trajectories while encouraging trajectories to achieve high returns, we further design a dual-guided module in the sampling process of the diffusion model. The proposed framework enjoys the robustness to the quality of collected warm-start data from the testing task and the flexibility to incorporate with different task representation method. The experiment results on MuJoCo benchmarks show that MetaDiffuser outperforms other strong offline meta-RL baselines, demonstrating the outstanding conditional generation ability of diffusion architecture.'}",https://openreview.net{'value': '/pdf/3faf1298dd5d51972dde54304a7c0050e3745173.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=IJffiJTLhI,{'value': 'Oracles & Followers: Stackelberg Equilibria in Deep Multi-Agent Reinforcement Learning'},Matthias Gerstgrasser; David C. Parkes,~Matthias_Gerstgrasser1; ~David_C._Parkes1,,"{'value': 'Stackelberg equilibria arise naturally in a range of popular learning problems, such as in security games or indirect mechanism design, and have received increasing attention in the reinforcement learning literature. We present a general framework for implementing Stackelberg equilibria search as a multi-agent RL problem, allowing a wide range of algorithmic design choices. We discuss how previous approaches can be seen as specific instantiations of this framework. As a key insight, we note that the design space allows for approaches not previously seen in the literature, for instance by leveraging multitask and meta-RL techniques for follower convergence. We propose one such approach using contextual policies, and evaluate it experimentally on both standard and novel benchmark domains, showing greatly improved sample efficiency compared to previous approaches. Finally, we explore the effect of adopting algorithm designs outside the borders of our framework.'}",https://openreview.net{'value': '/pdf/cfc6eed4113312f4747d36f4564673dd09290793.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=IGfmSM7siu,{'value': 'Model Transferability with Responsive Decision Subjects'},Yatong Chen; Zeyu Tang; Kun Zhang; Yang Liu,~Yatong_Chen1; ~Zeyu_Tang1; ~Kun_Zhang1; ~Yang_Liu3,,"{'value': 'Given an algorithmic predictor that is accurate on some source population consisting of strategic human decision subjects, will it remain accurate if the population respond to it? In our setting, an agent or a user corresponds to a sample $(X,Y)$ drawn from a distribution $\\cal{D}$ and will face a model $h$ and its classification result $h(X)$. Agents can modify $X$ to adapt to $h$, which will incur a distribution shift on $(X,Y)$. Our formulation is motivated by applications where the deployed machine learning models are subjected to human agents, and will ultimately face responsive and interactive data distributions. We formalize the discussions of the transferability of a model by studying how the performance of the model trained on the available source distribution (data) would translate to the performance on its induced domain. We provide both upper bounds for the performance gap due to the induced domain shift, as well as lower bounds for the trade-offs that a classifier has to suffer on either the source training distribution or the induced target distribution. We provide further instantiated analysis for two popular domain adaptation settings, including covariate shift and target shift.'}",https://openreview.net{'value': '/pdf/117185ac5487b045d7e08aeb8584dbf03384bcc5.pdf'},{'abstract_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=I5kywOUcl7,"{'value': 'Synthetic Data, Real Errors: How (Not) to Publish and Use Synthetic Data'}",Boris van Breugel; Zhaozhi Qian; Mihaela van der Schaar,~Boris_van_Breugel2; ~Zhaozhi_Qian1; ~Mihaela_van_der_Schaar2,,"{'value': 'Generating synthetic data through generative models is gaining interest in the ML community and beyond, promising a future where datasets can be tailored to individual needs. Unfortunately, synthetic data is usually not perfect, resulting in potential errors in downstream tasks. In this work we explore how the generative process affects the downstream ML task. We show that the naive synthetic data approach---using synthetic data as if it is real---leads to downstream models and analyses that do not generalize well to real data. As a first step towards better ML in the synthetic data regime, we introduce Deep Generative Ensemble (DGE)---a framework inspired by Deep Ensembles that aims to implicitly approximate the posterior distribution over the generative process model parameters. DGE improves downstream model training, evaluation, and uncertainty quantification, vastly outperforming the naive approach on average. The largest improvements are achieved for minority classes and low-density regions of the original data, for which the generative uncertainty is largest.'}",https://openreview.net{'value': '/pdf/238137bbfb33d6abc927eab93e65b9400c41c2b9.pdf'},{'title_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=HlpBeHoeUA,{'value': 'Regularizing Towards Soft Equivariance Under Mixed Symmetries'},Hyunsu Kim; Hyungi Lee; Hongseok Yang; Juho Lee,~Hyunsu_Kim2; ~Hyungi_Lee1; ~Hongseok_Yang2; ~Juho_Lee2,,"{'value': 'Datasets often have their intrinsic symmetries, and particular deep-learning models called equivariant or invariant models have been developed to exploit these symmetries. However, if some or all of these symmetries are only approximate, which frequently happens in practice, these models may be suboptimal due to the architectural restrictions imposed on them. We tackle this issue of approximate symmetries in a setup where symmetries are mixed, i.e., they are symmetries of not single but multiple different types and the degree of approximation varies across these types. Instead of proposing a new architectural restriction as in most of the previous approaches, we present a regularizer-based method for building a model for a dataset with mixed approximate symmetries. The key component of our method is what we call equivariance regularizer for a given type of symmetries, which measures how much a model is equivariant with respect to the symmetries of the type. Our method is trained with these regularizers, one per each symmetry type, and the strength of the regularizers is automatically tuned during training, leading to the discovery of the approximation levels of some candidate symmetry types without explicit supervision. Using synthetic function approximation and motion forecasting tasks, we demonstrate that our method achieves better accuracy than prior approaches while discovering the approximate symmetry levels correctly.'}",https://openreview.net{'value': '/pdf/7002c6eed6957700017aea7267984c7da3f5fcab.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=HKfSTYLJh7,{'value': 'On Many-Actions Policy Gradient'},Michal Nauman; Marek Cygan,~Michal_Nauman1; ~Marek_Cygan1,,"{'value': 'We study the variance of stochastic policy gradients (SPGs) with many action samples per state. We derive a many-actions optimality condition, which determines when many-actions SPG yields lower variance as compared to a single-action agent with proportionally extended trajectory. We propose Model-Based Many-Actions (MBMA), an approach leveraging dynamics models for many-actions sampling in the context of SPG. MBMA addresses issues associated with existing implementations of many-actions SPG and yields lower bias and comparable variance to SPG estimated from states in model-simulated rollouts. We find that MBMA bias and variance structure matches that predicted by theory. As a result, MBMA achieves improved sample efficiency and higher returns on a range of continuous action environments as compared to model-free, many-actions, and model-based on-policy SPG baselines.'}",https://openreview.net{'value': '/pdf/e6bd552b91d2e96445e670ef16fdb777f48c4e15.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=H01CJWHAmw,{'value': 'One-sided Matrix Completion from Two Observations Per Row'},Steven Cao; Percy Liang; Gregory Valiant,~Steven_Cao1; ~Percy_Liang1; ~Gregory_Valiant1,,"{'value': ""Given only a few observed entries from a low-rank matrix $X$, matrix completion is the problem of imputing the missing entries, and it formalizes a wide range of real-world settings that involve estimating missing data. However, when there are too few observed entries to complete the matrix, what other aspects of the underlying matrix can be reliably recovered? We study one such problem setting, that of ``one-sided'' matrix completion, where our goal is to recover the right singular vectors of $X$, even in the regime where recovering the left singular vectors is impossible, which arises when there are more rows than columns and very few observations. We propose a natural algorithm that involves imputing the missing values of the matrix $X^TX$ and show that even with only two observations per row in $X$, we can provably recover $X^TX$ as long as we have at least $\\Omega(r^2 d \\log d)$ rows, where $r$ is the rank and $d$ is the number of columns. We evaluate our algorithm on one-sided recovery of synthetic data and low-coverage genome sequencing. In these settings, our algorithm substantially outperforms standard matrix completion and a variety of direct factorization methods.""}",https://openreview.net{'value': '/pdf/0269d053fdca5b62008bd2cc72a815b5b39bea75.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=GDVczeyqFa,{'value': 'Truncating Trajectories in Monte Carlo Reinforcement Learning'},Riccardo Poiani; Alberto Maria Metelli; Marcello Restelli,~Riccardo_Poiani3; ~Alberto_Maria_Metelli2; ~Marcello_Restelli1,,"{'value': 'In Reinforcement Learning (RL), an agent acts in an unknown environment to maximize the expected cumulative discounted sum of an external reward signal, i.e., the expected return. In practice, in many tasks of interest, such as policy optimization, the agent usually spends its interaction budget by collecting episodes of *fixed length* within a simulator (i.e., Monte Carlo simulation). However, given the discounted nature of the RL objective, this data collection strategy might not be the best option. Indeed, the rewards taken in early simulation steps weigh exponentially more than future rewards. Taking a cue from this intuition, in this paper, we design an a-priori budget allocation strategy that leads to the collection of trajectories of different lengths, i.e., *truncated*. The proposed approach provably minimizes the width of the confidence intervals around the empirical estimates of the expected return of a policy. After discussing the theoretical properties of our method, we make use of our trajectory truncation mechanism to extend Policy Optimization via Importance Sampling (POIS, Metelli et al., 2018) algorithm. Finally, we conduct a numerical comparison between our algorithm and POIS: the results are consistent with our theory and show that an appropriate truncation of the trajectories can succeed in improving performance.'}",https://openreview.net{'value': '/pdf/c229c8c8a25e461800cb37cc67086e22d4337381.pdf'},{'title_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=GBmL22Gx9X,{'value': 'Training Normalizing Flows from Dependent Data'},Matthias Kirchler; Christoph Lippert; Marius Kloft,~Matthias_Kirchler1; ~Christoph_Lippert1; ~Marius_Kloft1,,"{'value': 'Normalizing flows are powerful non-parametric statistical models that function as a hybrid between density estimators and generative models. Current learning algorithms for normalizing flows assume that data points are sampled independently, an assumption that is frequently violated in practice, which may lead to erroneous density estimation and data generation. We propose a likelihood objective of normalizing flows incorporating dependencies between the data points, for which we derive a flexible and efficient learning algorithm suitable for different dependency structures. We show that respecting dependencies between observations can improve empirical results on both synthetic and real-world data, and leads to higher statistical power in a downstream application to genome-wide association studies.'}",https://openreview.net{'value': '/pdf/e9607268d50e629ea006adf0d5a37cbbf9c3e9ca.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=FjOB0g7iRf,{'value': 'Doubly Adversarial Federated Bandits'},Jialin Yi; Milan Vojnovic,~Jialin_Yi1; ~Milan_Vojnovic1,,"{'value': 'We study a new non-stochastic federated multiarmed bandit problem with multiple agents collaborating via a communication network. The losses of the arms are assigned by an oblivious adversary that specifies the loss of each arm not only for each time step but also for each agent, which we call doubly adversarial. In this setting, different agents may choose the same arm in the same time step but observe different feedback. The goal of each agent is to find a globally best arm in hindsight that has the lowest cumulative loss averaged over all agents, which necessities the communication among agents. We provide regret lower bounds for any federated bandit algorithm under different settings, when agents have access to full-information feedback, or the bandit feedback. For the bandit feedback setting, we propose a near-optimal federated bandit algorithm called FEDEXP3. Our algorithm gives a positive answer to an open question proposed in (Cesa-Bianchi et al., 2016): FEDEXP3 can guarantee a sub-linear regret without exchanging sequences of selected arm identities or loss sequences among agents. We also provide numerical evaluations of our algorithm to validate our theoretical results and demonstrate its effectiveness on synthetic and real-world datasets.'}",https://openreview.net{'value': '/pdf/66f23e9f9aca8f37fe7b2670cd7f89c514a637a1.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=FdCeFHTXrS,{'value': 'Difference-in-Differences Meets Tree-based Methods: Heterogeneous Treatment Effects Estimation with Unmeasured Confounding'},Caizhi Tang; Huiyuan Wang; Xinyu Li; Qing Cui; Longfei Li; JUN ZHOU,~Caizhi_Tang1; ~Huiyuan_Wang1; ~Xinyu_Li6; ~Qing_Cui1; ~Longfei_Li1; ~JUN_ZHOU6,,"{'value': 'This study considers the estimation of conditional causal effects in the presence of unmeasured confounding for a balanced panel with treatment imposed at the last time point. To address this, we combine Difference-in-differences (DiD) and tree-based methods and propose a new identification assumption that allows for the violation of the (conditional) parallel trends assumption adopted by most existing DiD methods. Under this new assumption, we prove partial identifiability of the conditional average treatment effect on the treated group (CATT). Our proposed method estimates CATT through a tree-based causal approach, guided by a novel splitting rule that avoids model misspecification and unnecessary auxiliary parameter estimation. The splitting rule measures both the error of fitting observed data and the violation of conditional parallel trends simultaneously. We also develop an ensemble of multiple trees via gradient boosting to further enhance performance. Experimental results on both synthetic and real-world datasets validate the effectiveness of our proposed method.'}",https://openreview.net{'value': '/pdf/1cd3dc56200def5a50840b5f7d65f218f90de48f.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=FREvWGzoRu,{'value': 'Universal Physics-Informed Neural Networks: Symbolic Differential Operator Discovery with Sparse Data'},Lena Podina; Brydon Eastman; Mohammad Kohandel,~Lena_Podina1; ~Brydon_Eastman1; ~Mohammad_Kohandel1,,"{'value': 'In this work we perform symbolic discovery of differential operators in a situation where there is sparse experimental data. This small data regime in machine learning can be made tractable by providing our algorithms with prior information about the underlying dynamics. Physics Informed Neural Networks (PINNs) have been very successful in this regime (reconstructing entire ODE solutions using only a single point or entire PDE solutions with very few measurements of the initial condition). The Universal PINN approach (UPINN) adds a neural network that learns a representation of unknown hidden terms in the differential equation. The algorithm yields both a surrogate solution to the differential equation and a black-box representation of the hidden terms. These hidden term neural networks can then be converted into symbolic equations using symbolic regression techniques like AI Feynman. In order to achieve convergence of the neural networks, we provide our algorithms with (noisy) measurements of both the initial condition as well as (synthetic) experimental data obtained at later times. We demonstrate strong performance of UPINNs even when provided with very few measurements of noisy data in both the ODE and PDE regime.'}",https://openreview.net{'value': '/pdf/7bde53a679a12dc8b54fbb3056041b92ce8fcadd.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=FR2F4QzWFp,{'value': 'Two Losses Are Better Than One: Faster Optimization Using a Cheaper Proxy'},Blake Woodworth; Konstantin Mishchenko; Francis Bach,~Blake_Woodworth2; ~Konstantin_Mishchenko1; ~Francis_Bach1,,"{'value': 'We present an algorithm for minimizing an objective with hard-to-compute gradients by using a related, easier-to-access function as a proxy. Our algorithm is based on approximate proximal-point iterations on the proxy combined with relatively few stochastic gradients from the objective. When the difference between the objective and the proxy is $\\delta$-smooth, our algorithm guarantees convergence at a rate matching stochastic gradient descent on a $\\delta$-smooth objective, which can lead to substantially better sample efficiency. Our algorithm has many potential applications in machine learning, and provides a principled means of leveraging synthetic data, physics simulators, mixed public and private data, and more.'}",https://openreview.net{'value': '/pdf/0098f7642b2d329c0584119e6cebceebc18ea7ad.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=EuUeVUS6UV,{'value': 'Extrapolative Controlled Sequence Generation via Iterative Refinement'},Vishakh Padmakumar; Richard Yuanzhe Pang; He He; Ankur P Parikh,~Vishakh_Padmakumar1; ~Richard_Yuanzhe_Pang1; ~He_He2; ~Ankur_P_Parikh1,,"{'value': 'We study the problem of extrapolative controlled generation, i.e., generating sequences with attribute values beyond the range seen in training. This task is of significant importance in automated design, especially drug discovery, where the goal is to design novel proteins that are better (e.g., more stable) than existing sequences. Thus, by definition the target sequences and their attribute values are out of the training distribution, posing challenges to existing methods that aim to directly generate the target sequence. Instead, in this work, we propose Iterative Controlled Extrapolation (ICE) which iteratively makes local edits to a sequence to enable extrapolation. We train the model on synthetically generated sequence pairs that demonstrate small improvement in the attribute value. Results on one natural language task (sentiment analysis) and two protein engineering tasks (ACE2 stability and AAV fitness) show that ICE outperforms state-of-the-art approaches despite its simplicity.'}",https://openreview.net{'value': '/pdf/c40ca872a95faa7d472e9958124fe7ce9f744b19.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=EqHTMU4YbA,{'value': 'Divide and Conquer Dynamic Programming: An Almost Linear Time Change Point Detection Methodology in High Dimensions'},Wanshan Li; Daren Wang; Alessandro Rinaldo,~Wanshan_Li1; ~Daren_Wang3; ~Alessandro_Rinaldo1,,"{'value': 'We develop a novel, general and computationally efficient framework, called Divide and Conquer Dynamic Programming (DCDP), for localizing change points in time series data with high-dimensional features. DCDP deploys a class of greedy algorithms that are applicable to a broad variety of high-dimensional statistical models and can enjoy almost linear computational complexity. We investigate the performance of DCDP in three commonly studied change point settings in high dimensions: the mean model, the Gaussian graphical model, and the linear regression model. In all three cases, we derive non-asymptotic bounds for the accuracy of the DCDP change point estimators. We demonstrate that the DCDP procedures consistently estimate the change points with sharp, and in some cases, optimal rates while incurring significantly smaller computational costs than the best available algorithms. Our findings are supported by extensive numerical experiments on both synthetic and real data.'}",https://openreview.net{'value': '/pdf/ed4bd3d470cca5736ea5e60ef8e76c99d0638d5c.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=EM1HUyzWV0,{'value': 'Recovering Top-Two Answers and Confusion Probability in Multi-Choice Crowdsourcing'},Hyeonsu Jeong; Hye Won Chung,~Hyeonsu_Jeong1; ~Hye_Won_Chung2,,"{'value': 'Crowdsourcing has emerged as an effective platform for labeling large amounts of data in a cost- and time-efficient manner. Most previous work has focused on designing an efficient algorithm to recover only the ground-truth labels of the data. In this paper, we consider multi-choice crowdsourcing tasks with the goal of recovering not only the ground truth, but also the most confusing answer and the confusion probability. The most confusing answer provides useful information about the task by revealing the most plausible answer other than the ground truth and how plausible it is. To theoretically analyze such scenarios, we propose a model in which there are the top two plausible answers for each task, distinguished from the rest of the choices. Task difficulty is quantified by the probability of confusion between the top two, and worker reliability is quantified by the probability of giving an answer among the top two. Under this model, we propose a two-stage inference algorithm to infer both the top two answers and the confusion probability. We show that our algorithm achieves the minimax optimal convergence rate. We conduct both synthetic and real data experiments and demonstrate that our algorithm outperforms other recent algorithms. We also show the applicability of our algorithms in inferring the difficulty of tasks and in training neural networks with top-two soft labels.'}",https://openreview.net{'value': '/pdf/a84e9fb43891c4d6fb10f9f32bb116256d7807d6.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=DdQTP1yFLQ,{'value': 'Nearly-Optimal Hierarchical Clustering for Well-Clustered Graphs'},Steinar Laenen; Bogdan Adrian Manghiuc; He Sun,~Steinar_Laenen1; ~Bogdan_Adrian_Manghiuc1; ~He_Sun5,,"{'value': ""This paper presents two efficient hierarchical clustering (HC) algorithms with respect to Dasgupta's cost function. For any input graph $G$ with a clear cluster-structure, our designed algorithms run in nearly-linear time in the input size of $G$, and return an $O(1)$-approximate HC tree with respect to Dasgupta's cost function. We compare the performance of our algorithm against the previous state-of-the-art on synthetic and real-world datasets and show that our designed algorithm produces comparable or better HC trees with much lower running time.""}",https://openreview.net{'value': '/pdf/3ed43716c400e01db12cf5d87d563040afad2961.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=DRu5BlRqrn,{'value': 'Lazy Agents: A New Perspective on Solving Sparse Reward Problem in Multi-agent Reinforcement Learning'},Boyin Liu; Zhiqiang Pu; Yi Pan; Jianqiang Yi; Yanyan Liang; Du Zhang,~Boyin_Liu2; ~Zhiqiang_Pu1; ~Yi_Pan4; ~Jianqiang_Yi1; ~Yanyan_Liang1; duzhang@must.edu.mo,,"{'value': 'Sparse reward remains a valuable and challenging problem in multi-agent reinforcement learning (MARL). This paper addresses this issue from a new perspective, i.e., lazy agents. We empirically illustrate how lazy agents damage learning from both exploration and exploitation. Then, we propose a novel MARL framework called Lazy Agents Avoidance through Influencing External States (LAIES). Firstly, we examine the causes and types of lazy agents in MARL using a causal graph of the interaction between agents and their environment. Then, we mathematically define the concept of fully lazy agents and teams by calculating the causal effect of their actions on external states using the do-calculus process. Based on definitions, we provide two intrinsic rewards to motivate agents, i.e., individual diligence intrinsic motivation (IDI) and collaborative diligence intrinsic motivation (CDI). IDI and CDI employ counterfactual reasoning based on the external states transition model (ESTM) we developed. Empirical results demonstrate that our proposed method achieves state-of-the-art performance on various tasks, including the sparse-reward version of StarCraft multi-agent challenge (SMAC) and Google Research Football (GRF). Our code is open-source and available at https://github.com/liuboyin/LAIES.'}",https://openreview.net{'value': '/pdf/e7f077397d14de9a9cc683961e096661928dbf95.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=DGSmVHmOrv,{'value': 'Special Properties of Gradient Descent with Large Learning Rates'},Amirkeivan Mohtashami; Martin Jaggi; Sebastian U Stich,~Amirkeivan_Mohtashami1; ~Martin_Jaggi1; ~Sebastian_U_Stich1,,"{'value': 'When training neural networks, it has been widely observed that a large step size is essential in stochastic gradient descent (SGD) for obtaining superior models. However, the effect of large step sizes on the success of SGD is not well understood theoretically. Several previous works have attributed this success to the stochastic noise present in SGD. However, we show through a novel set of experiments that the stochastic noise is not sufficient to explain good non-convex training, and that instead the effect of a large learning rate itself is essential for obtaining best performance.We demonstrate the same effects also in the noise-less case, i.e. for full-batch GD. We formally prove that GD with large step size ---on certain non-convex function classes --- follows a different trajectory than GD with a small step size, which can lead to convergence to a global minimum instead of a local one. Our settings provide a framework for future analysis which allows comparing algorithms based on behaviors that can not be observed in the traditional settings.'}",https://openreview.net{'value': '/pdf/f34cb65a637b8fb4e1d6b976b867fd75b8b6ea2c.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=ChniRIfpRR,{'value': 'In or Out? Fixing ImageNet Out-of-Distribution Detection Evaluation'},Julian Bitterwolf; Maximilian Müller; Matthias Hein,~Julian_Bitterwolf1; ~Maximilian_Müller1; ~Matthias_Hein2,,"{'value': ""Out-of-distribution (OOD) detection is the problem of identifying inputs which are unrelated to the in-distribution task. The OOD detection performance when the in-distribution (ID) is ImageNet-1K is commonly being tested on a small range of test OOD datasets. We find that most of the currently used test OOD datasets, including datasets from the open set recognition (OSR) literature, have severe issues: In some cases more than 50$\\%$ of the dataset contains objects belonging to one of the ID classes. These erroneous samples heavily distort the evaluation of OOD detectors. As a solution, we introduce with NINCO a novel test OOD dataset, each sample checked to be ID free, which with its fine-grained range of OOD classes allows for a detailed analysis of an OOD detector's strengths and failure modes, particularly when paired with a number of synthetic “OOD unit-tests”. We provide detailed evaluations across a large set of architectures and OOD detection methods on NINCO and the unit-tests, revealing new insights about model weaknesses and the effects of pretraining on OOD detection performance. We provide code and data at https://github.com/j-cb/NINCO.""}",https://openreview.net{'value': '/pdf/71cf7c62728887df456ac8c814eea5234bd2d19a.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=CgB7wCExOF,{'value': 'Transformers as Algorithms: Generalization and Stability in In-context Learning'},Yingcong Li; Muhammed Emrullah Ildiz; Dimitris Papailiopoulos; Samet Oymak,~Yingcong_Li1; mildi001@ucr.edu; ~Dimitris_Papailiopoulos1; ~Samet_Oymak2,,"{'value': 'In-context learning (ICL) is a type of prompting where a transformer model operates on a sequence of (input, output) examples and performs inference on-the-fly. In this work, we formalize in-context learning as an algorithm learning problem where a transformer model implicitly constructs a hypothesis function at inference-time. We first explore the statistical aspects of this abstraction through the lens of multitask learning: We obtain generalization bounds for ICL when the input prompt is (1) a sequence of i.i.d. (input, label) pairs or (2) a trajectory arising from a dynamical system. The crux of our analysis is relating the excess risk to the stability of the algorithm implemented by the transformer. We characterize when transformer/attention architecture provably obeys the stability condition and also provide empirical verification. For generalization on unseen tasks, we identify an inductive bias phenomenon in which the transfer learning risk is governed by the task complexity and the number of MTL tasks in a highly predictable manner. Finally, we provide numerical evaluations that (1) demonstrate transformers can indeed implement near-optimal algorithms on classical regression problems with i.i.d. and dynamic data, (2) provide insights on stability, and (3) verify our theoretical predictions.'}",https://openreview.net{'value': '/pdf/bc5b80bba3992e0a0d658c015dfa7a51778a7d58.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=CPKMwyiyDv,{'value': 'Neural networks trained with SGD learn distributions of increasing complexity'},Maria Refinetti; Alessandro Ingrosso; Sebastian Goldt,~Maria_Refinetti1; ~Alessandro_Ingrosso1; ~Sebastian_Goldt1,,"{'value': 'The uncanny ability of over-parameterised neural networks to generalise well has been explained using various ""simplicity biases"". These theories postulate that neural networks avoid overfitting by first fitting simple, linear classifiers before learning more complex, non-linear functions. Meanwhile, data structure is also recognised as a key ingredient for good generalisation, yet its role in simplicity biases is not yet understood. Here, we show that neural networks trained using stochastic gradient descent initially classify their inputs using lower-order input statistics, like mean and covariance, and exploit higher-order statistics only later during training. We first demonstrate this **distributional simplicity bias** (DSB) in a solvable model of a single neuron trained on synthetic data. We then demonstrate DSB empirically in a range of deep convolutional networks and visual transformers trained on CIFAR10, and show that it even holds in networks pre-trained on ImageNet. We discuss the relation of DSB to other simplicity biases and consider its implications for the principle of Gaussian universality in learning.'}",https://openreview.net{'value': '/pdf/e28616d0d931203554021ce94b0f082e89a181ec.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=BZDqjqbJmg,{'value': 'Iterative Approximate Cross-Validation'},Yuetian Luo; Zhimei Ren; Rina Barber,~Yuetian_Luo2; ~Zhimei_Ren1; ~Rina_Barber1,,"{'value': 'Cross-validation (CV) is one of the most popular tools for assessing and selecting predictive models. However, standard CV suffers from high computational cost when the number of folds is large. Recently, under the empirical risk minimization (ERM) framework, a line of works proposed efficient methods to approximate CV based on the solution of the ERM problem trained on the full dataset. However, in large-scale problems, it can be hard to obtain the exact solution of the ERM problem, either due to limited computational resources or due to early stopping as a way of preventing overfitting. In this paper, we propose a new paradigm to efficiently approximate CV when the ERM problem is solved via an iterative first-order algorithm, without running until convergence. Our new method extends existing guarantees for CV approximation to hold along the whole trajectory of the algorithm, including at convergence, thus generalizing existing CV approximation methods. Finally, we illustrate the accuracy and computational efficiency of our method through a range of empirical studies.'}",https://openreview.net{'value': '/pdf/8c1419707918fa9519f0a41628d4061e5e587dc1.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=BUv0BLrosh,{'value': 'Conformal Prediction with Missing Values'},Margaux Zaffran; Aymeric Dieuleveut; Julie Josse; Yaniv Romano,~Margaux_Zaffran1; ~Aymeric_Dieuleveut1; ~Julie_Josse1; ~Yaniv_Romano1,,"{'value': 'Conformal prediction is a theoretically grounded framework for constructing predictive intervals. We study conformal prediction with missing values in the covariates -- a setting that brings new challenges to uncertainty quantification. We first show that the marginal coverage guarantee of conformal prediction holds on imputed data for any missingness distribution and almost all imputation functions. However, we emphasize that the average coverage varies depending on the pattern of missing values: conformal methods tend to construct prediction intervals that under-cover the response conditionally to some missing patterns. This motivates our novel generalized conformalized quantile regression framework, missing data augmentation, which yields prediction intervals that are valid conditionally to the patterns of missing values, despite their exponential number. We then show that a universally consistent quantile regression algorithm trained on the imputed data is Bayes optimal for the pinball risk, thus achieving valid coverage conditionally to any given data point. Moreover, we examine the case of a linear model, which demonstrates the importance of our proposal in overcoming the heteroskedasticity induced by missing values. Using synthetic and data from critical care, we corroborate our theory and report improved performance of our methods.'}",https://openreview.net{'value': '/pdf/28807c79273e0c06cfd6fd5e69e122e725015723.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=B9R1uLC1B1,{'value': 'Generating Private Synthetic Data with Genetic Algorithms'},Terrance Liu; Jingwu Tang; Giuseppe Vietri; Steven Wu,~Terrance_Liu1; ~Jingwu_Tang1; ~Giuseppe_Vietri1; ~Steven_Wu1,,"{'value': ""We study the problem of efficiently generating differentially private synthetic data that approximate the statistical properties of an underlying sensitive dataset. In recent years, there has been a growing line of work that approaches this problem using first-order optimization techniques. However, such techniques are restricted to optimizing differentiable objectives only, severely limiting the types of analyses that can be conducted. For example, first-order mechanisms have been primarily successful in approximating statistical queries only in the form of marginals for discrete data domains. In some cases, one can circumvent such issues by relaxing the task's objective to maintain differentiability. However, even when possible, these approaches impose a fundamental limitation in which modifications to the minimization problem become additional sources of error. Therefore, we propose Private-GSD, a private genetic algorithm based on *zeroth*-order optimization heuristics that do not require modifying the original objective; thus, it avoids the aforementioned limitations of first-order optimization. We demonstrate empirically that on data with both discrete and real-valued attributes, Private-GSD outperforms the state-of-the-art methods on non-differential queries while matching accuracy in approximating differentiable ones.""}",https://openreview.net{'value': '/pdf/495e0c112b2cf9219eff751d56339e39948dd256.pdf'},{'title_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=AzFq5HxVlg,{'value': 'Best Arm Identification in Multi-Agent Multi-Armed Bandits'},Filippo Vannella; Alexandre Proutiere; Jaeseong Jeong,~Filippo_Vannella1; ~Alexandre_Proutiere1; jaeseong.jeong@ericsson.com,,"{'value': 'We investigate the problem of best arm identification in Multi-Agent Multi-Armed Bandits (MAMABs) where the rewards are defined through a factor graph. The objective is to find an optimal global action with a prescribed level of confidence and minimal sample complexity. We derive a tight instance-specific lower bound of the sample complexity and characterize the corresponding optimal sampling strategy. Unfortunately, this bound is obtained by solving a combinatorial optimization problem with a number of variables and constraints exponentially growing with the number of agents. We leverage Mean Field (MF) techniques to obtain, in a computationally efficient manner, an approximation of the lower bound. The approximation scales at most as $\\rho K^d$ (where $\\rho$, $K$, and $d$ denote the number of factors in the graph, the number of possible actions per agent, and the maximal degree of the factor graph). We devise MF-TaS (Mean-Field-Track-and-Stop), an algorithm whose sample complexity provably matches our approximated lower bound. We illustrate the performance of MF-TaS numerically using both synthetic and real-world experiments (e.g., to solve the antenna tilt optimization problem in radio communication networks).'}",https://openreview.net{'value': '/pdf/d532bc7f8fe76bb1fe71dbd05345f4e3c85d7667.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=AwxfYvdPZV,{'value': 'Policy Mirror Ascent for Efficient and Independent Learning in Mean Field Games'},Batuhan Yardim; Semih Cayci; Matthieu Geist; Niao He,~Batuhan_Yardim1; ~Semih_Cayci1; ~Matthieu_Geist1; ~Niao_He3,,"{'value': ""Mean-field games have been used as a theoretical tool to obtain an approximate Nash equilibrium for symmetric and anonymous $N$-player games. However, limiting applicability, existing theoretical results assume variations of a ``population generative model'', which allows arbitrary modifications of the population distribution by the learning algorithm. Moreover, learning algorithms typically work on abstract simulators with population instead of the $N$-player game. Instead, we show that $N$ agents running policy mirror ascent converge to the Nash equilibrium of the regularized game within $\\widetilde{\\mathcal{O}}(\\varepsilon^{-2})$ samples from a single sample trajectory without a population generative model, up to a standard $\\mathcal{O}(\\frac{1}{\\sqrt{N}})$ error due to the mean field. Taking a divergent approach from the literature, instead of working with the best-response map we first show that a policy mirror ascent map can be used to construct a contractive operator having the Nash equilibrium as its fixed point. We analyze single-path TD learning for $N$-agent games, proving sample complexity guarantees by only using a sample path from the $N$-agent simulator without a population generative model. Furthermore, we demonstrate that our methodology allows for independent learning by $N$ agents with finite sample guarantees.""}",https://openreview.net{'value': '/pdf/d8d5393b3658313bfc0e9ef2ca86e989e33c39be.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=Asrg2we3dP,{'value': 'MABe22: A Multi-Species Multi-Task Benchmark for Learned Representations of Behavior'},Jennifer J. Sun; Markus Marks; Andrew Wesley Ulmer; Dipam Chakraborty; Brian Geuther; Edward Hayes; Heng Jia; Vivek Kumar; Sebastian Oleszko; Zachary Partridge; Milan Peelman; Alice Robie; Catherine E Schretter; Keith Sheppard; Chao Sun; Param Uttarwar; Julian Morgan Wagner; Erik Werner; Joseph Parker; Pietro Perona; Yisong Yue; Kristin Branson; Ann Kennedy,~Jennifer_J._Sun1; ~Markus_Marks1; ~Andrew_Wesley_Ulmer1; ~Dipam_Chakraborty1; ~Brian_Geuther1; ~Edward_Hayes1; ~Heng_Jia1; ~Vivek_Kumar4; ~Sebastian_Oleszko1; ~Zachary_Partridge1; ~Milan_Peelman1; ~Alice_Robie1; ~Catherine_E_Schretter1; ~Keith_Sheppard2; ~Chao_Sun3; ~Param_Uttarwar1; ~Julian_Morgan_Wagner1; ~Erik_Werner1; ~Joseph_Parker1; ~Pietro_Perona1; ~Yisong_Yue1; ~Kristin_Branson1; ~Ann_Kennedy1,,"{'value': 'We introduce MABe22, a large-scale, multi-agent video and trajectory benchmark to assess the quality of learned behavior representations. This dataset is collected from a variety of biology experiments, and includes triplets of interacting mice (4.7 million frames video+pose tracking data, 10 million frames pose only), symbiotic beetle-ant interactions (10 million frames video data), and groups of interacting flies (4.4 million frames of pose tracking data). Accompanying these data, we introduce a panel of real-life downstream analysis tasks to assess the quality of learned representations by evaluating how well they preserve information about the experimental conditions (e.g. strain, time of day, optogenetic stimulation) and animal behavior. We test multiple state-of-the-art self-supervised video and trajectory representation learning methods to demonstrate the use of our benchmark, revealing that methods developed using human action datasets do not fully translate to animal datasets. We hope that our benchmark and dataset encourage a broader exploration of behavior representation learning methods across species and settings.'}",https://openreview.net{'value': '/pdf/54b15ea0e20e60fb121c5eca6baeb5ae0a88143a.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=9xqrSeujqc,"{'value': 'Extending Kernel PCA through Dualization: Sparsity, Robustness and Fast Algorithms'}",Francesco Tonin; Alex Lambert; Panagiotis Patrinos; Johan Suykens,~Francesco_Tonin1; ~Alex_Lambert1; ~Panagiotis_Patrinos1; ~Johan_Suykens1,,"{'value': 'The goal of this paper is to revisit Kernel Principal Component Analysis (KPCA) through dualization of a difference of convex functions. This allows to naturally extend KPCA to multiple objective functions and leads to efficient gradient-based algorithms avoiding the expensive SVD of the Gram matrix. Particularly, we consider objective functions that can be written as Moreau envelopes, demonstrating how to promote robustness and sparsity within the same framework. The proposed method is evaluated on synthetic and realworld benchmarks, showing significant speedup in KPCA training time as well as highlighting the benefits in terms of robustness and sparsity.'}",https://openreview.net{'value': '/pdf/de7ca91419a0f158e682d672c53f6282bef6860c.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=9iNScYEBWZ,{'value': 'Improving Adversarial Robustness Through the Contrastive-Guided Diffusion Process'},Yidong Ouyang; Liyan Xie; Guang Cheng,~Yidong_Ouyang1; ~Liyan_Xie2; ~Guang_Cheng1,,"{'value': 'Synthetic data generation has become an emerging tool to help improve the adversarial robustness in classification tasks, since robust learning requires a significantly larger amount of training samples compared with standard classification. Among various deep generative models, the diffusion model has been shown to produce high-quality synthetic images and has achieved good performance in improving the adversarial robustness. However, diffusion-type methods are generally slower in data generation as compared with other generative models. Although different acceleration techniques have been proposed recently, it is also of great importance to study how to improve the sample efficiency of synthetic data for the downstream task. In this paper, we first analyze the optimality condition of synthetic distribution for achieving improved robust accuracy. We show that enhancing the distinguishability among the generated data is critical for improving adversarial robustness. Thus, we propose the Contrastive-Guided Diffusion Process (Contrastive-DP), which incorporates the contrastive loss to guide the diffusion model in data generation. We validate our theoretical results using simulations and demonstrate the good performance of Contrastive-DP on image datasets.'}",https://openreview.net{'value': '/pdf/061227d2e1340c6147c942cce8f8f767ffcf515c.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=9WJsVG58YO,{'value': 'Improving Graph Generation by Restricting Graph Bandwidth'},Nathaniel Lee Diamant; Alex Tseng; Kangway V Chuang; Tommaso Biancalani; Gabriele Scalia,~Nathaniel_Lee_Diamant1; ~Alex_Tseng1; ~Kangway_V_Chuang1; ~Tommaso_Biancalani1; ~Gabriele_Scalia1,,"{'value': 'Deep graph generative modeling has proven capable of learning the distribution of complex, multi-scale structures characterizing real-world graphs. However, one of the main limitations of existing methods is their large output space, which limits generation scalability and hinders accurate modeling of the underlying distribution. To overcome these limitations, we propose a novel approach that significantly reduces the output space of existing graph generative models. Specifically, starting from the observation that many real-world graphs have low graph bandwidth, we restrict graph bandwidth during training and generation. Our strategy improves both generation scalability and quality without increasing architectural complexity or reducing expressiveness. Our approach is compatible with existing graph generative methods, and we describe its application to both autoregressive and one-shot models. We extensively validate our strategy on synthetic and real datasets, including molecular graphs. Our experiments show that, in addition to improving generation efficiency, our approach consistently improves generation quality and reconstruction accuracy. The implementation is made available.'}",https://openreview.net{'value': '/pdf/324f2238d659c77c487250f363ee63ef337d34a7.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=9UCTB84L6e,"{'value': 'Same Pre-training Loss, Better Downstream: Implicit Bias Matters for Language Models'}",Hong Liu; Sang Michael Xie; Zhiyuan Li; Tengyu Ma,~Hong_Liu5; ~Sang_Michael_Xie1; ~Zhiyuan_Li2; ~Tengyu_Ma1,,"{'value': 'Language modeling on large-scale datasets improves performance of various downstream tasks. The validation pre-training loss is often used as the evaluation metric for language models since the pre-training loss tends to be well-correlated with downstream performance (which is itself hard to evaluate comprehensively). Contrary to the conventional wisdom, this paper shows that 1) pre-training loss cannot fully explain downstream performance and 2) flatness of the model is well-correlated with downstream performance where pre-training loss is not. We identify three ways to produce models with the same pre-training loss but different downstream performance: continue pre-training after convergence, increasing the model size, and changing the pre-training algorithms. These experiments demonstrate the existence of implicit bias of pre-training algorithms---among models with the same minimal pre-training loss, they implicitly prefer more transferable ones. Toward understanding this implicit bias, we prove that SGD with standard mini-batch noise implicitly prefers flatter minima of pre-training loss in language models, and empirically observe a strong correlation between flatness (measured by the trace of Hessian) and downstream performance among models with the same pre-training loss. We also prove in a synthetic language setting that among models with the minimal pre-training loss, the flattest model transfers to downstream tasks.'}",https://openreview.net{'value': '/pdf/6d9b4d4d83f765a05ac05914f9857a4abdbd7ba5.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=8Lww9LXokZ,{'value': 'Trajectory-Aware Eligibility Traces for Off-Policy Reinforcement Learning'},Brett Daley; Martha White; Christopher Amato; Marlos C. Machado,~Brett_Daley1; ~Martha_White1; ~Christopher_Amato1; ~Marlos_C._Machado1,,"{'value': 'Off-policy learning from multistep returns is crucial for sample-efficient reinforcement learning, but counteracting off-policy bias without exacerbating variance is challenging. Classically, off-policy bias is corrected in a per-decision manner: past temporal-difference errors are re-weighted by the instantaneous Importance Sampling (IS) ratio after each action via eligibility traces. Many off-policy algorithms rely on this mechanism, along with differing protocols for cutting the IS ratios (traces) to combat the variance of the IS estimator. Unfortunately, once a trace has been cut, the effect cannot be easily reversed. This has led to the development of credit-assignment strategies that account for multiple past experiences at a time. These trajectory-aware methods have not been extensively analyzed, and their theoretical justification remains uncertain. In this paper, we propose a multistep operator that unifies per-decision and trajectory-aware methods. We prove convergence conditions for our operator in the tabular setting, establishing the first guarantees for several existing methods as well as many new ones. Finally, we introduce Recency-Bounded Importance Sampling (RBIS), which leverages trajectory awareness to perform robustly across $\\lambda$-values in an off-policy control task.'}",https://openreview.net{'value': '/pdf/7f409a24c0de00067975ca050a5426209e6a0172.pdf'},{'title_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=8Ln8Ai9kq1,{'value': 'Semi-Supervised Offline Reinforcement Learning with Action-Free Trajectories'},Qinqing Zheng; Mikael Henaff; Brandon Amos; Aditya Grover,~Qinqing_Zheng1; ~Mikael_Henaff1; ~Brandon_Amos1; ~Aditya_Grover1,,"{'value': 'Natural agents can effectively learn from multiple data sources that differ in size, quality, and types of measurements. We study this heterogeneity in the context of offline reinforcement learning (RL) by introducing a new, practically motivated semi-supervised setting. Here, an agent has access to two sets of trajectories: labelled trajectories containing state, action and reward triplets at every timestep, along with unlabelled trajectories that contain only state and reward information. For this setting, we develop and study a simple meta-algorithmic pipeline that learns an inverse dynamics model on the labelled data to obtain proxy-labels for the unlabelled data, followed by the use of any offline RL algorithm on the true and proxy-labelled trajectories. Empirically, we find this simple pipeline to be highly successful --- on several D4RL benchmarks (Fu et al., 2020), certain offline RL algorithms can match the performance of variants trained on a fully labelled dataset even when we label only 10% of trajectories which are highly suboptimal. To strengthen our understanding, we perform a large-scale controlled empirical study investigating the interplay of data-centric properties of the labelled and unlabelled datasets, with algorithmic design choices (e.g., choice of inverse dynamics, offline RL algorithm) to identify general trends and best practices for training RL agents on semi-supervised offline datasets.'}",https://openreview.net{'value': '/pdf/734a0d93f0a5c9997fdb6aeb06bed843264b1fa7.pdf'},{'title_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=8LdBTjylEw,{'value': 'A Kernelized Stein Discrepancy for Biological Sequences'},Alan Nawzad Amin; Eli N Weinstein; Debora Susan Marks,~Alan_Nawzad_Amin1; ~Eli_N_Weinstein1; ~Debora_Susan_Marks1,,"{'value': ""Generative models of biological sequences are a powerful tool for learning from complex sequence data, predicting the effects of mutations, and designing novel biomolecules with desired properties. To evaluate generative models it is important to accurately measure differences between high-dimensional distributions. In this paper we propose the ``KSD-B'', a novel divergence measure for distributions over biological sequences that is based on the kernelized Stein discrepancy (KSD). The KSD-B can be evaluated even when the normalizing constant of the model is unknown; it allows for variable length sequences and can take into account biological notions of sequence distance. Unlike previous KSDs over discrete spaces the KSD-B (a) is theoretically guaranteed to detect convergence and non-convergence of distributions over sequence space and (b) can be efficiently estimated in practice. We demonstrate the advantages of the KSD-B on problems with synthetic and real data, and apply it to measure the fit of state-of-the-art machine learning models. Overall, the KSD-B enables rigorous evaluation of generative biological sequence models, allowing the accuracy of models, sampling procedures, and library designs to be checked reliably.""}",https://openreview.net{'value': '/pdf/5d1d725dd17f760baff5ae5c9b56919c39231406.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=8D3SsQlRbY,{'value': 'The Value of Out-of-Distribution Data'},Ashwin De Silva; Rahul Ramesh; Carey Priebe; Pratik Chaudhari; Joshua T Vogelstein,~Ashwin_De_Silva1; ~Rahul_Ramesh2; ~Carey_Priebe1; ~Pratik_Chaudhari1; ~Joshua_T_Vogelstein1,,"{'value': ""Generalization error always improves with more in-distribution data. However, it is an open question what happens as we add out-of-distribution (OOD) data. Intuitively, if the OOD data is quite different, it seems more data would harm generalization error, though if the OOD data are sufficiently similar, much empirical evidence suggests that OOD data can actually improve generalization error. We show a counter-intuitive phenomenon: the generalization error of a task can be a non-monotonic function of the amount of OOD data. Specifically, we prove that generalization error can improve with small amounts of OOD data, and then get worse than no OOD data with larger amounts. In other words, there is value in training on small amounts of OOD data. We analytically demonstrate these results via Fisher's Linear Discriminant on synthetic datasets, and empirically demonstrate them via deep networks on computer vision benchmarks such as MNIST, CIFAR-10, CINIC-10, PACS and DomainNet. In the idealistic setting where we know which samples are OOD, we show that these non-monotonic trends can be exploited using an appropriately weighted objective of the target and OOD empirical risk. While its practical utility is limited, this does suggest that if we can detect OOD samples, then there may be ways to benefit from them. When we do not know which samples are OOD, we show how a number of go-to strategies such as data-augmentation, hyper-parameter optimization and pre-training are not enough to ensure that the target generalization error does not deteriorate with the number of OOD samples in the dataset.""}",https://openreview.net{'value': '/pdf/9f364acc3abf64a468727d4cc0af5bb349c3e1f7.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=7p7YakZP2H,{'value': 'Curious Replay for Model-based Adaptation'},Isaac Kauvar; Chris Doyle; Linqi Zhou; Nick Haber,~Isaac_Kauvar1; crd@stanford.edu; ~Linqi_Zhou1; ~Nick_Haber1,,"{'value': 'Agents must be able to adapt quickly as an environment changes. We find that existing model-based reinforcement learning agents are unable to do this well, in part because of how they use past experiences to train their world model. Here, we present Curious Replay---a form of prioritized experience replay tailored to model-based agents through use of a curiosity-based priority signal. Agents using Curious Replay exhibit improved performance in an exploration paradigm inspired by animal behavior and on the Crafter benchmark. DreamerV3 with Curious Replay surpasses state-of-the-art performance on Crafter, achieving a mean score of 19.4 that substantially improves on the previous high score of 14.5 by DreamerV3 with uniform replay, while also maintaining similar performance on the Deepmind Control Suite. Code for Curious Replay is available at github.com/AutonomousAgentsLab/curiousreplay.'}",https://openreview.net{'value': '/pdf/ceabed26d13f9ce9bd1890637f89195b7c58d5e7.pdf'},{'abstract_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=7maTHA7zua,{'value': 'Future-conditioned Unsupervised Pretraining for Decision Transformer'},Zhihui Xie; Zichuan Lin; Deheng Ye; QIANG FU; Yang Wei; Shuai Li,~Zhihui_Xie2; ~Zichuan_Lin2; ~Deheng_Ye1; ~QIANG_FU8; ~Yang_Wei2; ~Shuai_Li3,,"{'value': ""Recent research in offline reinforcement learning (RL) has demonstrated that return-conditioned supervised learning is a powerful paradigm for decision-making problems. While promising, return conditioning is limited to training data labeled with rewards and therefore faces challenges in learning from unsupervised data. In this work, we aim to utilize generalized future conditioning to enable efficient unsupervised pretraining from reward-free and sub-optimal offline data. We propose Pretrained Decision Transformer (PDT), a conceptually simple approach for unsupervised RL pretraining. PDT leverages future trajectory information as a privileged context to predict actions during training. The ability to make decisions based on both present and future factors enhances PDT's capability for generalization. Besides, this feature can be easily incorporated into a return-conditioned framework for online finetuning, by assigning return values to possible futures and sampling future embeddings based on their respective values. Empirically, PDT outperforms or performs on par with its supervised pretraining counterpart, especially when dealing with sub-optimal data. Further analysis reveals that PDT can extract diverse behaviors from offline data and controllably sample high-return behaviors by online finetuning. Code is available at here.""}",https://openreview.net{'value': '/pdf/ed8eaa1c8cb26ea8494b533f5a7a29792a88094f.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=7GD5BMI3km,{'value': 'Learning Neural Constitutive Laws from Motion Observations for Generalizable PDE Dynamics'},Pingchuan Ma; Peter Yichen Chen; Bolei Deng; Joshua B. Tenenbaum; Tao Du; Chuang Gan; Wojciech Matusik,~Pingchuan_Ma3; ~Peter_Yichen_Chen1; ~Bolei_Deng1; ~Joshua_B._Tenenbaum1; ~Tao_Du1; ~Chuang_Gan1; ~Wojciech_Matusik2,,"{'value': 'We propose a hybrid neural network (NN) and PDE approach for learning generalizable PDE dynamics from motion observations. Many NN approaches learn an end-to-end model that implicitly models both the governing PDE and constitutive models (or material models). Without explicit PDE knowledge, these approaches cannot guarantee physical correctness and have limited generalizability. We argue that the governing PDEs are often well-known and should be explicitly enforced rather than learned. Instead, constitutive models are particularly suitable for learning due to their data-fitting nature. To this end, we introduce a new framework termed ""Neural Constitutive Laws"" (NCLaw), which utilizes a network architecture that strictly guarantees standard constitutive priors, including rotation equivariance and undeformed state equilibrium. We embed this network inside a differentiable simulation and train the model by minimizing a loss function based on the difference between the simulation and the motion observation. We validate NCLaw on various large-deformation dynamical systems, ranging from solids to fluids. After training on a single motion trajectory, our method generalizes to new geometries, initial/boundary conditions, temporal ranges, and even multi-physics systems. On these extremely out-of-distribution generalization tasks, NCLaw is orders-of-magnitude more accurate than previous NN approaches. Real-world experiments demonstrate our method\'s ability to learn constitutive laws from videos.'}",https://openreview.net{'value': '/pdf/f4dc943300fd0603ef68f1c93a97a91622d29d53.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=79icaL3Wan,{'value': 'SOM-CPC: Unsupervised Contrastive Learning with Self-Organizing Maps for Structured Representations of High-Rate Time Series'},Iris A.M. Huijben; Arthur Andreas Nijdam; Sebastiaan Overeem; Merel M Van Gilst; Ruud Van Sloun,~Iris_A.M._Huijben1; ~Arthur_Andreas_Nijdam1; ~Sebastiaan_Overeem1; ~Merel_M_Van_Gilst1; ~Ruud_Van_Sloun1,,"{'value': 'Continuous monitoring with an ever-increasing number of sensors has become ubiquitous across many application domains. However, acquired time series are typically high-dimensional and difficult to interpret. Expressive deep learning (DL) models have gained popularity for dimensionality reduction, but the resulting latent space often remains difficult to interpret. In this work we propose SOM-CPC, a model that visualizes data in an organized 2D manifold, while preserving higher-dimensional information. We address a largely unexplored and challenging set of scenarios comprising high-rate time series, and show on both synthetic and real-life data (physiological data and audio recordings) that SOM-CPC outperforms strong baselines like DL-based feature extraction, followed by conventional dimensionality reduction techniques, and models that jointly optimize a DL model and a Self-Organizing Map (SOM). SOM-CPC has great potential to acquire a better understanding of latent patterns in high-rate data streams.'}",https://openreview.net{'value': '/pdf/d78d856d17cdc5ac611cae6b94fade41e7aa2403.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=6vVkGnEpP7,{'value': 'Distilling Internet-Scale Vision-Language Models into Embodied Agents'},Theodore Sumers; Kenneth Marino; Arun Ahuja; Rob Fergus; Ishita Dasgupta,~Theodore_Sumers1; ~Kenneth_Marino1; ~Arun_Ahuja1; ~Rob_Fergus1; ~Ishita_Dasgupta1,,"{'value': ""Instruction-following agents must ground language into their observation and action spaces. Learning to ground language is challenging, typically requiring domain-specific engineering or large quantities of human interaction data. To address this challenge, we propose using pretrained vision-language models (VLMs) to supervise embodied agents. We combine ideas from model distillation and hindsight experience replay (HER), using a VLM to retroactively generate language describing the agent's behavior. Simple prompting allows us to control the supervision signal, teaching an agent to interact with novel objects based on their names (e.g., planes) or their features (e.g., colors) in a 3D rendered environment. Fewshot prompting lets us teach abstract category membership, including pre-existing categories (food vs toys) and ad-hoc ones (arbitrary preferences over objects). Our work outlines a new and effective way to use internet-scale VLMs, repurposing the generic language grounding acquired by such models to teach task-relevant groundings to embodied agents.""}",https://openreview.net{'value': '/pdf/9a03afb416c242a16a45572b8a0f032865c5c37e.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=6rlGbYv4bT,{'value': 'Weighted Flow Diffusion for Local Graph Clustering with Node Attributes: an Algorithm and Statistical Guarantees'},Shenghao Yang; Kimon Fountoulakis,~Shenghao_Yang1; ~Kimon_Fountoulakis1,,"{'value': 'Local graph clustering methods aim to detect small clusters in very large graphs without the need to process the whole graph. They are fundamental and scalable tools for a wide range of tasks such as local community detection, node ranking and node embedding. While prior work on local graph clustering mainly focuses on graphs without node attributes, modern real-world graph datasets typically come with node attributes that provide valuable additional information. We present a simple local graph clustering algorithm for graphs with node attributes, based on the idea of diffusing mass locally in the graph while accounting for both structural and attribute proximities. Using high-dimensional concentration results, we provide statistical guarantees on the performance of the algorithm for the recovery of a target cluster with a single seed node. We give conditions under which a target cluster generated from a fairly general contextual random graph model, which includes both the stochastic block model and the planted cluster model as special cases, can be fully recovered with bounded false positives. Empirically, we validate all theoretical claims using synthetic data, and we show that incorporating node attributes leads to superior local clustering performances using real-world graph datasets.'}",https://openreview.net{'value': '/pdf/d6407e5af5b22fd94410bfec07818799d4b1f6f1.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=6bBla9LAJ2,{'value': 'Generative Adversarial Symmetry Discovery'},Jianke Yang; Robin Walters; Nima Dehmamy; Rose Yu,~Jianke_Yang2; ~Robin_Walters1; ~Nima_Dehmamy1; ~Rose_Yu1,,"{'value': 'Despite the success of equivariant neural networks in scientific applications, they require knowing the symmetry group a priori. However, it may be difficult to know which symmetry to use as an inductive bias in practice. Enforcing the wrong symmetry could even hurt the performance. In this paper, we propose a framework, LieGAN, to *automatically discover equivariances* from a dataset using a paradigm akin to generative adversarial training. Specifically, a generator learns a group of transformations applied to the data, which preserve the original distribution and fool the discriminator. LieGAN represents symmetry as interpretable Lie algebra basis and can discover various symmetries such as the rotation group $\\mathrm{SO}(n)$, restricted Lorentz group $\\mathrm{SO}(1,3)^+$ in trajectory prediction and top-quark tagging tasks. The learned symmetry can also be readily used in several existing equivariant neural networks to improve accuracy and generalization in prediction.'}",https://openreview.net{'value': '/pdf/bf47f67833c1b4fc4d3b518a4637436093a28f91.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=6aB43K50T0,{'value': 'Learning Regions of Interest for Bayesian Optimization with Adaptive Level-Set Estimation'},Fengxue Zhang; Jialin Song; James C Bowden; Alexander Ladd; Yisong Yue; Thomas Desautels; Yuxin Chen,~Fengxue_Zhang1; ~Jialin_Song1; ~James_C_Bowden1; ~Alexander_Ladd1; ~Yisong_Yue1; ~Thomas_Desautels1; ~Yuxin_Chen1,,"{'value': 'We study Bayesian optimization (BO) in high-dimensional and non-stationary scenarios. Existing algorithms for such scenarios typically require extensive hyperparameter tuning, which limits their practical effectiveness. We propose a framework, called BALLET, which adaptively filters for a high-confidence region of interest (ROI) as a superlevel-set of a nonparametric probabilistic model such as a Gaussian process (GP). Our approach is easy to tune, and is able to focus on local region of the optimization space that can be tackled by existing BO methods. The key idea is to use two probabilistic models: a coarse GP to identify the ROI, and a localized GP for optimization within the ROI. We show theoretically that BALLET can efficiently shrink the search space, and can exhibit a tighter regret bound than standard BO without ROI filtering. We demonstrate empirically the effectiveness of BALLET on both synthetic and real-world optimization tasks.'}",https://openreview.net{'value': '/pdf/a86603a7610661526b950e51a8cfe9b5aaf3256f.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=6LZNpFqDHB,{'value': 'Speed-Oblivious Online Scheduling: Knowing (Precise) Speeds is not Necessary'},Alexander Lindermayr; Nicole Megow; Martin Rapp,~Alexander_Lindermayr1; ~Nicole_Megow1; ~Martin_Rapp1,,"{'value': 'We consider online scheduling on unrelated (heterogeneous) machines in a speed-oblivious setting, where an algorithm is unaware of the exact job-dependent processing speeds. We show strong impossibility results for clairvoyant and non-clairvoyant algorithms and overcome them in models inspired by practical settings: (i) we provide competitive learning-augmented algorithms, assuming that (possibly erroneous) predictions on the speeds are given, and (ii) we provide competitive algorithms for the speed-ordered model, where a single global order of machines according to their unknown job-dependent speeds is known. We prove strong theoretical guarantees and evaluate our findings on a representative heterogeneous multi-core processor. These seem to be the first empirical results for scheduling algorithms with predictions that are evaluated in a non-synthetic hardware environment.'}",https://openreview.net{'value': '/pdf/706d5a35678e2576918ebefed04c6dadfcf92dd1.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=6LJvlAiD9z,{'value': 'ConCerNet: A Contrastive Learning Based Framework for Automated Conservation Law Discovery and Trustworthy Dynamical System Prediction'},Wang Zhang; Tsui-Wei Weng; Subhro Das; Alexandre Megretski; Luca Daniel; Lam M. Nguyen,~Wang_Zhang2; ~Tsui-Wei_Weng1; ~Subhro_Das1; ~Alexandre_Megretski1; ~Luca_Daniel1; ~Lam_M._Nguyen1,,"{'value': 'Deep neural networks (DNN) have shown great capacity of modeling a dynamical system; nevertheless, they usually do not obey physics constraints such as conservation laws. This paper proposes a new learning framework named $\\textbf{ConCerNet}$ to improve the trustworthiness of the DNN based dynamics modeling to endow the invariant properties. $\\textbf{ConCerNet}$ consists of two steps: (i) a contrastive learning method to automatically capture the system invariants (i.e. conservation properties) along the trajectory observations; (ii) a neural projection layer to guarantee that the learned dynamics models preserve the learned invariants. We theoretically prove the functional relationship between the learned latent representation and the unknown system invariant function. Experiments show that our method consistently outperforms the baseline neural networks in both coordinate error and conservation metrics by a large margin. With neural network based parameterization and no dependence on prior knowledge, our method can be extended to complex and large-scale dynamics by leveraging an autoencoder.'}",https://openreview.net{'value': '/pdf/1d6586135d4a2e288ab135d8f4f24ac0ccb5826d.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=6Ed3gchl9L,{'value': 'On the Expressive Power of Geometric Graph Neural Networks'},Chaitanya K. Joshi; Cristian Bodnar; Simon V Mathis; Taco Cohen; Pietro Lio,~Chaitanya_K._Joshi1; ~Cristian_Bodnar1; ~Simon_V_Mathis1; ~Taco_Cohen1; ~Pietro_Lio1,,"{'value': ""The expressive power of Graph Neural Networks (GNNs) has been studied extensively through the Weisfeiler-Leman (WL) graph isomorphism test. However, standard GNNs and the WL framework are inapplicable for geometric graphs embedded in Euclidean space, such as biomolecules, materials, and other physical systems. In this work, we propose a geometric version of the WL test (GWL) for discriminating geometric graphs while respecting the underlying physical symmetries: permutations, rotation, reflection, and translation. We use GWL to characterise the expressive power of geometric GNNs that are invariant or equivariant to physical symmetries in terms of distinguishing geometric graphs. GWL unpacks how key design choices influence geometric GNN expressivity: (1) Invariant layers have limited expressivity as they cannot distinguish one-hop identical geometric graphs; (2) Equivariant layers distinguish a larger class of graphs by propagating geometric information beyond local neighbourhoods; (3) Higher order tensors and scalarisation enable maximally powerful geometric GNNs; and (4) GWL's discrimination-based perspective is equivalent to universal approximation. Synthetic experiments supplementing our results are available at https://github.com/chaitjo/geometric-gnn-dojo""}",https://openreview.net{'value': '/pdf/d860f5be65d9368dc088a4c8eac4b94b37fc28a3.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=68wSAeijsB,{'value': 'Instrumental Variable Estimation of Average Partial Causal Effects'},Yuta Kawakami; manabu kuroki; Jin Tian,~Yuta_Kawakami1; ~manabu_kuroki1; ~Jin_Tian1,,"{'value': 'Instrumental variable (IV) analysis is a powerful tool widely used to elucidate causal relationships. We study the problem of estimating the average partial causal effect (APCE) of a continuous treatment in an IV setting. Specifically, we develop new methods for estimating APCE based on a recent identification condition via an integral equation. We develop two families of methods, nonparametric and parametric - the former uses the Picard iteration to solve the integral equation; the latter parameterizes APCE using a linear basis function model. We analyze the statistical and computational properties of the proposed methods and illustrate them on synthetic and real data.'}",https://openreview.net{'value': '/pdf/57fe1f7109665aabc513cdd5a6a98b6666c31df7.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=63rNiH4mgG,{'value': 'On the Convergence of Gradient Flow on Multi-layer Linear Models'},Hancheng Min; Rene Vidal; Enrique Mallada,~Hancheng_Min1; ~Rene_Vidal1; ~Enrique_Mallada1,,"{'value': 'In this paper, we analyze the convergence of gradient flow on a multi-layer linear model with a loss function of the form $f(W_1W_2\\cdots W_L)$. We show that when $f$ satisfies the gradient dominance property, proper weight initialization leads to exponential convergence of the gradient flow to a global minimum of the loss. Moreover, the convergence rate depends on two trajectory-specific quantities that are controlled by the weight initialization: the *imbalance matrices*, which measure the difference between the weights of adjacent layers, and the least singular value of the *weight product* $W=W_1W_2\\cdots W_L$. Our analysis exploits the fact that the gradient of the overparameterized loss can be written as the composition of the non-overparametrized gradient with a time-varying (weight-dependent) linear operator whose smallest eigenvalue controls the convergence rate. The key challenge we address is to derive a uniform lower bound for this time-varying eigenvalue that lead to improved rates for several multi-layer network models studied in the literature.'}",https://openreview.net{'value': '/pdf/63dd4457fbcf9d89eba5872332f971bb2f8b859f.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=631FTQB0UB,{'value': 'The Power of Learned Locally Linear Models for Nonlinear Policy Optimization'},Daniel Pfrommer; Max Simchowitz; Tyler Westenbroek; Nikolai Matni; Stephen Tu,~Daniel_Pfrommer1; ~Max_Simchowitz1; ~Tyler_Westenbroek1; ~Nikolai_Matni2; ~Stephen_Tu1,,"{'value': 'A common pipeline in learning-based control is to iteratively estimate a model of system dynamics, and apply a trajectory optimization algorithm - e.g. $\\mathtt{iLQR}$ - on the learned model to minimize a target cost. This paper conducts a rigorous analysis of a simplified variant of this strategy for general nonlinear systems. We analyze an algorithm which iterates between estimating local linear models of nonlinear system dynamics and performing $\\mathtt{iLQR}$-like policy updates. We demonstrate that this algorithm attains sample complexity polynomial in relevant problem parameters, and, by synthesizing locally stabilizing gains, overcomes exponential dependence in problem horizon. Experimental results validate the performance of our algorithm, and compare to natural deep-learning baselines.'}",https://openreview.net{'value': '/pdf/1aff4ef954acf407e5b14e93c56da31fb4babb02.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=5YAP9Ntq3L,{'value': 'SAM operates far from home: eigenvalue regularization as a dynamical phenomenon'},Atish Agarwala; Yann Dauphin,~Atish_Agarwala1; ~Yann_Dauphin1,,"{'value': 'The Sharpness Aware Minimization (SAM) optimization algorithm has been shown to control large eigenvalues of the loss Hessian and provide generalization benefits in a variety of settings. The original motivation for SAM was a modified loss function which penalized sharp minima; subsequent analyses have also focused on the behavior near minima. However, our work reveals that SAM provides a strong regularization of the eigenvalues throughout the learning trajectory. We show that in a simplified setting, SAM dynamically induces a stabilization related to the edge of stability (EOS) phenomenon observed in large learning rate gradient descent. Our theory predicts the largest eigenvalue as a function of the learning rate and SAM radius parameters. Finally, we show that practical models can also exhibit this EOS stabilization, and that understanding SAM must account for these dynamics far away from any minima.'}",https://openreview.net{'value': '/pdf/30fe391ef408dc4d65d18705130a6896324631d8.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=5Akrk9Ln6N,{'value': 'Reparameterized Policy Learning for Multimodal Trajectory Optimization'},Zhiao Huang; Litian Liang; Zhan Ling; Xuanlin Li; Chuang Gan; Hao Su,~Zhiao_Huang1; ~Litian_Liang1; ~Zhan_Ling2; ~Xuanlin_Li1; ~Chuang_Gan1; ~Hao_Su1,,"{'value': 'We investigate the challenge of parametrizing policies for reinforcement learning (RL) in high-dimensional continuous action spaces. Our objective is to develop a multimodal policy that overcomes limitations inherent in the commonly-used Gaussian parameterization. To achieve this, we propose a principled framework that models the continuous RL policy as a generative model of optimal trajectories. By conditioning the policy on a latent variable, we derive a novel variational bound as the optimization objective, which promotes exploration of the environment. We then present a practical model-based RL method, called Reparameterized Policy Gradient (RPG), which leverages the multimodal policy parameterization and learned world model to achieve strong exploration capabilities and high data efficiency. Empirical results demonstrate that our method can help agents evade local optima in tasks with dense rewards and solve challenging sparse-reward environments by incorporating an object-centric intrinsic reward. Our method consistently outperforms previous approaches across a range of tasks. Code and supplementary materials are available on the project page https://haosulab.github.io/RPG/'}",https://openreview.net{'value': '/pdf/01ca6c794fb3c60cec707bca29c019b57bfaadde.pdf'},{'title_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=55kLa7tH9o,{'value': 'Hierarchical Diffusion for Offline Decision Making'},Wenhao Li; Xiangfeng Wang; Bo Jin; Hongyuan Zha,~Wenhao_Li2; ~Xiangfeng_Wang1; ~Bo_Jin1; ~Hongyuan_Zha1,,"{'value': 'Offline reinforcement learning typically introduces a hierarchical structure to solve the long-horizon problem so as to address its thorny issue of variance accumulation. Problems of deadly triad, limited data and reward sparsity, however, still remain, rendering the design of effective, hierarchical offline RL algorithms for general-purpose policy learning a formidable challenge. In this paper, we first formulate the problem of offline long-horizon decision-$\\mathbf{M}$ak$\\mathbf{I}$ng from the perspective of conditional generative modeling by incorporating goals into the control-as-inference graphic models. A $\\mathbf{H}$ierarchical trajectory-level $\\mathbf{D}$iffusion probabilistic model is then proposed with classifier-free guidance. HDMI employs a cascade framework that utilizes the reward-conditional goal diffuser for the subgoal discovery and the goal-conditional trajectory diffuser for generating the corresponding action sequence of subgoals. Planning-based subgoal extraction and transformer-based diffusion are employed to deal with the sub-optimal data pollution and long-range subgoal dependencies in the goal diffusion. Numerical experiments verify the advantages of HDMI on long-horizon decision-making compared to SOTA offline RL methods and conditional generative models.'}",https://openreview.net{'value': '/pdf/d443ae50559128b8c714fd72bb753a687caa6e5e.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=4k8cvbQJh8,{'value': 'Deep Graph Representation Learning and Optimization for Influence Maximization'},Chen Ling; Junji Jiang; Junxiang Wang; My Thai; Lukas Xue; James Song; Meikang Qiu; Liang Zhao,~Chen_Ling3; ~Junji_Jiang1; ~Junxiang_Wang1; ~My_Thai1; lukas.xue@emory.edu; james.song2@emory.edu; qiumeikang@yahoo.com; ~Liang_Zhao6,,"{'value': 'Influence maximization (IM) is formulated as selecting a set of initial users from a social network to maximize the expected number of influenced users. Researchers have made great progresses to design various traditional methods, yet both theoretical design and performance gain are close to their limits. In the past few years, learning-based IM methods have emerged to achieve stronger generalization ability to unknown graphs than traditional ones. However, the development of learning-based IM methods is still limited by fundamental obstacles, including 1) the difficulty of effectively solving the objective function; 2) the difficulty of characterizing the diversified and underlying diffusion patterns; and 3) the difficulty of adapting the solution under various node-centrality-constrained IM variants. To cope with the above challenges, we design a novel framework DeepIM to generatively characterize the latent representation of seed sets, and we propose to learn the diversified information diffusion pattern in a data-driven and end-to-end manner. Finally, we design a novel objective function to infer optimal seed sets under flexible node-centrality-based budget constraints. Extensive analyses are conducted over both synthetic and real-world datasets to demonstrate the overall performance of DeepIM.'}",https://openreview.net{'value': '/pdf/486977c60e4a9282d2b901b5dd24f885c65c60de.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=4EINAXMptc,{'value': 'Emergent Agentic Transformer from Chain of Hindsight Experience'},Hao Liu; Pieter Abbeel,~Hao_Liu1; ~Pieter_Abbeel2,,"{'value': 'Large transformer models powered by diverse data and model scale have dominated natural language modeling and computer vision and pushed the frontier of multiple AI areas. In reinforcement learning (RL), despite many efforts into transformer-based policies, a key limitation, however, is that current transformer-based policies cannot learn by directly combining information from multiple sub-optimal trials. In this work, we address this issue using recently proposed chain of hindsight to relabel experience, where we train a transformer on a sequence of trajectory experience ascending sorted according to their total rewards. Our method consists of relabelling target return of each trajectory to the maximum total reward among in sequence of trajectories and training an autoregressive model to predict actions conditioning on past states, actions, rewards, target returns, and task completion tokens, the resulting model, Agentic Transformer (AT), can learn to improve upon itself both at training and test time. As we show on D4RL and ExoRL benchmarks, to the best our knowledge, this is the first time that a simple transformer-based model performs competitively with both temporal-difference and imitation-learning-based approaches, even from sub-optimal data. Our Agentic Transformer also shows a promising scaling trend that bigger models consistently improve results.'}",https://openreview.net{'value': '/pdf/203774497318d60994d65179c8f6cbe796968df1.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=47kHz7I8lJ,{'value': 'Monotonicity and Double Descent in Uncertainty Estimation with Gaussian Processes'},Liam Hodgkinson; Chris van der Heide; Fred Roosta; Michael W. Mahoney,~Liam_Hodgkinson1; ~Chris_van_der_Heide1; ~Fred_Roosta1; ~Michael_W._Mahoney1,,"{'value': 'Despite their importance for assessing reliability of predictions, uncertainty quantification (UQ) measures in machine learning models have only recently begun to be rigorously characterized. One prominent issue is the *curse of dimensionality*: it is commonly believed that the marginal likelihood should be reminiscent of cross-validation metrics and both should deteriorate with larger input dimensions. However, we prove that by tuning hyperparameters to maximize marginal likelihood (the empirical Bayes procedure), performance, as measured by the marginal likelihood, *improves monotonically* with the input dimension. On the other hand, cross-validation metrics exhibit qualitatively different behavior that is characteristic of double descent. Cold posteriors, which have recently attracted interest due to their improved performance in certain settings, appear to exacerbate these phenomena. We verify empirically that our results hold for real data, beyond our considered assumptions, and we explore consequences involving synthetic covariates.'}",https://openreview.net{'value': '/pdf/61c1fd5703c80aef5a7717d70ef5e5f6619616b9.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=3aauzk8QUl,{'value': 'Understanding the Impact of Adversarial Robustness on Accuracy Disparity'},Yuzheng Hu; Fan Wu; Hongyang Zhang; Han Zhao,~Yuzheng_Hu1; ~Fan_Wu6; ~Hongyang_Zhang1; ~Han_Zhao1,,"{'value': 'While it has long been empirically observed that adversarial robustness may be at odds with standard accuracy and may have further disparate impacts on different classes, it remains an open question to what extent such observations hold and how the class imbalance plays a role within. In this paper, we attempt to understand this question of accuracy disparity by taking a closer look at linear classifiers under a Gaussian mixture model. We decompose the impact of adversarial robustness into two parts: an inherent effect that will degrade the standard accuracy on all classes due to the robustness constraint, and the other caused by the class imbalance ratio, which will increase the accuracy disparity compared to standard training. Furthermore, we also show that such effects extend beyond the Gaussian mixture model, by generalizing our data model to the general family of stable distributions. More specifically, we demonstrate that while the constraint of adversarial robustness consistently degrades the standard accuracy in the balanced class setting, the class imbalance ratio plays a fundamentally different role in accuracy disparity compared to the Gaussian case, due to the heavy tail of the stable distribution. We additionally perform experiments on both synthetic and real-world datasets to corroborate our theoretical findings. Our empirical results also suggest that the implications may extend to nonlinear models over real-world datasets. Our code is publicly available on GitHub at https://github.com/Accuracy-Disparity/AT-on-AD.'}",https://openreview.net{'value': '/pdf/d72262b8adf30993ec84b49b9285b5bf662b48d6.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=3ETNXs54HB,{'value': 'AdaptDiffuser: Diffusion Models as Adaptive Self-evolving Planners'},Zhixuan Liang; Yao Mu; Mingyu Ding; Fei Ni; Masayoshi Tomizuka; Ping Luo,~Zhixuan_Liang2; ~Yao_Mu1; ~Mingyu_Ding1; ~Fei_Ni1; ~Masayoshi_Tomizuka1; ~Ping_Luo2,,"{'value': 'Diffusion models have demonstrated their powerful generative capability in many tasks, with great potential to serve as a paradigm for offline reinforcement learning. However, the quality of the diffusion model is limited by the insufficient diversity of training data, which hinders the performance of planning and the generalizability to new tasks. This paper introduces AdaptDiffuser, an evolutionary planning method with diffusion that can self-evolve to improve the diffusion model hence a better planner, not only for seen tasks but can also adapt to unseen tasks. AdaptDiffuser enables the generation of rich synthetic expert data for goal-conditioned tasks using guidance from reward gradients. It then selects high-quality data via a discriminator to finetune the diffusion model, which improves the generalization ability to unseen tasks. Empirical experiments on two benchmark environments and two carefully designed unseen tasks in KUKA industrial robot arm and Maze2D environments demonstrate the effectiveness of AdaptDiffuser. For example, AdaptDiffuser not only outperforms the previous art Diffuser by 20.8% on Maze2D and 7.5% on MuJoCo locomotion, but also adapts better to new tasks, e.g., KUKA pick-and-place, by 27.9% without requiring additional expert data. More visualization results and demo videos could be found on our project page.'}",https://openreview.net{'value': '/pdf/18713cbce5faf7d8bdeaa82c584d78d6126325e2.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=2WEMW6rGgG,{'value': 'Algorithms for bounding contribution for histogram estimation under user-level privacy'},Yuhan Liu; Ananda Theertha Suresh; Wennan Zhu; Peter Kairouz; Marco Gruteser,~Yuhan_Liu4; ~Ananda_Theertha_Suresh1; ~Wennan_Zhu1; ~Peter_Kairouz1; ~Marco_Gruteser1,,"{'value': 'We study the problem of histogram estimation under user-level differential privacy, where the goal is to preserve the privacy of *all* entries of any single user. We consider the heterogeneous scenario where the quantity of data can be different for each user. In this scenario, the amount of noise injected into the histogram to obtain differential privacy is proportional to the maximum user contribution, which can be amplified by few outliers. One approach to circumvent this would be to bound (or limit) the contribution of each user to the histogram. However, if users are limited to small contributions, a significant amount of data will be discarded. In this work, we propose algorithms to choose the best user contribution bound for histogram estimation under both bounded and unbounded domain settings. When the size of the domain is bounded, we propose a user contribution bounding strategy that almost achieves a two-approximation with respect to the best contribution bound in hindsight. For unbounded domain histogram estimation, we propose an algorithm that is logarithmic-approximation with respect to the best contribution bound in hindsight. This result holds without any distribution assumptions on the data. Experiments on both real and synthetic datasets verify our theoretical findings and demonstrate the effectiveness of our algorithms. We also show that clipping bias introduced by bounding user contribution may be reduced under mild distribution assumptions, which can be of independent interest.'}",https://openreview.net{'value': '/pdf/5114abf028f29494923d3138e75e9aa0c9d2fa03.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=23uOLxPd34,{'value': 'Attention-Based Recurrence for Multi-Agent Reinforcement Learning under Stochastic Partial Observability'},Thomy Phan; Fabian Ritz; Philipp Altmann; Maximilian Zorn; Jonas Nüßlein; Michael Kölle; Thomas Gabor; Claudia Linnhoff-Popien,~Thomy_Phan1; ~Fabian_Ritz1; ~Philipp_Altmann1; ~Maximilian_Zorn1; ~Jonas_Nüßlein1; ~Michael_Kölle1; ~Thomas_Gabor1; ~Claudia_Linnhoff-Popien1,,"{'value': 'Stochastic partial observability poses a major challenge for decentralized coordination in multi-agent reinforcement learning but is largely neglected in state-of-the-art research due to a strong focus on state-based centralized training for decentralized execution (CTDE) and benchmarks that lack sufficient stochasticity like StarCraft Multi-Agent Challenge (SMAC). In this paper, we propose Attention-based Embeddings of Recurrence In multi-Agent Learning (AERIAL) to approximate value functions under stochastic partial observability. AERIAL replaces the true state with a learned representation of multi-agent recurrence, considering more accurate information about decentralized agent decisions than state-based CTDE. We then introduce MessySMAC, a modified version of SMAC with stochastic observations and higher variance in initial states, to provide a more general and configurable benchmark regarding stochastic partial observability. We evaluate AERIAL in Dec-Tiger as well as in a variety of SMAC and MessySMAC maps, and compare the results with state-based CTDE. Furthermore, we evaluate the robustness of AERIAL and state-based CTDE against various stochasticity configurations in MessySMAC.'}",https://openreview.net{'value': '/pdf/cccb49229bbc80c1d19d54ba71ca541624bdcc52.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=1s3P1SjAsF,{'value': 'K-SHAP: Policy Clustering Algorithm for Anonymous Multi-Agent State-Action Pairs'},Andrea Coletta; Svitlana Vyetrenko; Tucker Balch,~Andrea_Coletta1; ~Svitlana_Vyetrenko1; ~Tucker_Balch2,,"{'value': 'Learning agent behaviors from observational data has shown to improve our understanding of their decision-making processes, advancing our ability to explain their interactions with the environment and other agents. While multiple learning techniques have been proposed in the literature, there is one particular setting that has not been explored yet: multi agent systems where agent identities remain anonymous. For instance, in financial markets labeled data that identifies market participant strategies is typically proprietary, and only the anonymous state-action pairs that result from the interaction of multiple market participants are publicly available. As a result, sequences of agent actions are not observable, restricting the applicability of existing work. In this paper, we propose a Policy Clustering algorithm, called K-SHAP, that learns to group anonymous state-action pairs according to the agent policies. We frame the problem as an Imitation Learning (IL) task, and we learn a world-policy able to mimic all the agent behaviors upon different environmental states. We leverage the world-policy to explain each anonymous observation through an additive feature attribution method called SHAP (SHapley Additive exPlanations). Finally, by clustering the explanations we show that we are able to identify different agent policies and group observations accordingly. We evaluate our approach on simulated synthetic market data and a real-world financial dataset. We show that our proposal significantly and consistently outperforms the existing methods, identifying different agent strategies.'}",https://openreview.net{'value': '/pdf/0eacafe450b84e3ca3180f28ef879609dd496513.pdf'},{'title_filter': 'Agent'},ICML.cc,2023,Conference
https://openreview.net/forum?id=1hWB5XEUMa,{'value': 'Linear Time GPs for Inferring Latent Trajectories from Neural Spike Trains'},Matthew Dowling; Yuan Zhao; Il Memming Park,~Matthew_Dowling2; ~Yuan_Zhao1; ~Il_Memming_Park1,,"{'value': 'Latent Gaussian process (GP) models are widely used in neuroscience to uncover hidden state evolutions from sequential observations, mainly in neural activity recordings. While latent GP models provide a principled and powerful solution in theory, the intractable posterior in non-conjugate settings necessitates approximate inference schemes, which may lack scalability. In this work, we propose cvHM, a general inference framework for latent GP models leveraging Hida-Matérn kernels and conjugate computation variational inference (CVI). With cvHM, we are able to perform variational inference of latent neural trajectories with linear time complexity for arbitrary likelihoods. The reparameterization of stationary kernels using Hida-Matérn GPs helps us connect the latent variable models that encode prior assumptions through dynamical systems to those that encode trajectory assumptions through GPs. In contrast to previous work, we use bidirectional information filtering, leading to a more concise implementation. Furthermore, we employ the Whittle approximate likelihood to achieve highly efficient hyperparameter learning.'}",https://openreview.net{'value': '/pdf/4a432a206b604e11a3d5747134cf766d343f0a43.pdf'},{'title_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=1VDuHddxtA,{'value': 'Linear Causal Disentanglement via Interventions'},Chandler Squires; Anna Seigal; Salil S Bhate; Caroline Uhler,~Chandler_Squires1; aseigal@math.harvard.edu; ~Salil_S_Bhate1; ~Caroline_Uhler1,,"{'value': 'Causal disentanglement seeks a representation of data involving latent variables that are related via a causal model. A representation is identifiable if both the latent model and the transformation from latent to observed variables are unique. In this paper, we study observed variables that are a linear transformation of a linear latent causal model. Data from interventions are necessary for identifiability: if one latent variable is missing an intervention, we show that there exist distinct models that cannot be distinguished. Conversely, we show that a single intervention on each latent variable is sufficient for identifiability. Our proof uses a generalization of the RQ decomposition of a matrix that replaces the usual orthogonal and upper triangular conditions with analogues depending on a partial order on the rows of the matrix, with partial order determined by a latent causal model. We corroborate our theoretical results with a method for causal disentanglement. We show that the method accurately recovers a latent causal model on synthetic and semi-synthetic data and we illustrate a use case on a dataset of single-cell RNA sequencing measurements.'}",https://openreview.net{'value': '/pdf/5086c2b45a668c12d9e56431366d311459447e5b.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=0e2DfXKbwE,{'value': 'Causal Structure Learning for Latent Intervened Non-stationary Data'},Chenxi Liu; Kun Kuang,~Chenxi_Liu3; ~Kun_Kuang1,,"{'value': 'Causal structure learning can reveal the causal mechanism behind natural systems. It is well studied that the multiple domain data consisting of observational and interventional samples benefit causal identifiability. However, for non-stationary time series data, domain indexes are often unavailable, making it difficult to distinguish observational samples from interventional samples. To address these issues, we propose a novel Latent Intervened Non-stationary learning (LIN) method to make the domain indexes recovery process and the causal structure learning process mutually promote each other. We characterize and justify a possible faithfulness condition to guarantee the identifiability of the proposed LIN method. Extensive experiments on both synthetic and real-world datasets demonstrate that our method outperforms the baselines on causal structure learning for latent intervened non-stationary data.'}",https://openreview.net{'value': '/pdf/350ff7f3845949fe6016d942468ff74256e65fc3.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=0VeyziIEcJ,{'value': 'Fast Online Value-Maximizing Prediction Sets with Conformal Cost Control'},Zhen Lin; Shubhendu Trivedi; Cao Xiao; Jimeng Sun,~Zhen_Lin2; ~Shubhendu_Trivedi2; ~Cao_Xiao2; ~Jimeng_Sun3,,"{'value': 'Many real-world multi-label prediction problems involve set-valued predictions that must satisfy specific requirements dictated by downstream usage. We focus on a typical scenario where such requirements, separately encoding *value* and *cost*, compete with each other. For instance, a hospital might expect a smart diagnosis system to capture as many severe, often co-morbid, diseases as possible (the value), while maintaining strict control over incorrect predictions (the cost). We present a general pipeline, dubbed as FavMac, to maximize the value while controlling the cost in such scenarios. FavMac can be combined with almost any multi-label classifier, affording distribution-free theoretical guarantees on cost control. Moreover, unlike prior works, FavMac can handle real-world large-scale applications via a carefully designed online update mechanism, which is of independent interest. Our methodological and theoretical contributions are supported by experiments on several healthcare tasks and synthetic datasets - FavMac furnishes higher value compared with several variants and baselines while maintaining strict cost control.'}",https://openreview.net{'value': '/pdf/fdc1cceb5b2e56751a5bbd365d2dbc8b82d02c30.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2023,Conference
https://openreview.net/forum?id=0TJgsYhgGg,{'value': 'Towards Understanding and Improving GFlowNet Training'},Max W Shen; Emmanuel Bengio; Ehsan Hajiramezanali; Andreas Loukas; Kyunghyun Cho; Tommaso Biancalani,~Max_W_Shen1; ~Emmanuel_Bengio1; ~Ehsan_Hajiramezanali1; ~Andreas_Loukas1; ~Kyunghyun_Cho1; ~Tommaso_Biancalani1,,"{'value': 'Generative flow networks (GFlowNets) are a family of algorithms that learn a generative policy to sample discrete objects $x$ with non-negative reward $R(x)$. Learning objectives guarantee the GFlowNet samples $x$ from the target distribution $p^*(x) \\propto R(x)$ when loss is globally minimized over all states or trajectories, but it is unclear how well they perform with practical limits on training resources. We introduce an efficient evaluation strategy to compare the learned sampling distribution to the target reward distribution. As flows can be underdetermined given training data, we clarify the importance of learned flows to generalization and matching $p^*(x)$ in practice. We investigate how to learn better flows, and propose (i) prioritized replay training of high-reward $x$, (ii) relative edge flow policy parametrization, and (iii) a novel guided trajectory balance objective, and show how it can solve a substructure credit assignment problem. We substantially improve sample efficiency on biochemical design tasks.'}",https://openreview.net{'value': '/pdf/88597d45cc5a17966e153a71991454ff055d4657.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
https://openreview.net/forum?id=0O7b2Y198V,{'value': 'STEP: Learning N:M Structured Sparsity Masks from Scratch with Precondition'},Yucheng Lu; Shivani Agrawal; Suvinay Subramanian; Oleg Rybakov; Christopher De Sa; Amir Yazdanbakhsh,~Yucheng_Lu1; ~Shivani_Agrawal1; suvinay@google.com; rybakov@google.com; ~Christopher_De_Sa2; ~Amir_Yazdanbakhsh1,,"{'value': 'Recent innovations on hardware (e.g. Nvidia A100) have motivated learning N:M structured sparsity masks from scratch for fast model inference. However, state-of-the-art learning recipes in this regime (e.g. SR-STE) are proposed for non-adaptive optimizers like momentum SGD, while incurring non-trivial accuracy drop for Adam-trained models like attention-based LLMs. In this paper, we first demonstrate such gap origins from poorly estimated second moment (i.e. variance) in Adam states given by the masked weights. We conjecture that learning N:M masks with Adam should take the critical regime of variance estimation into account. In light of this, we propose STEP, an Adam-aware recipe that learns N:M masks with two phases: first, STEP calculates a reliable variance estimate (*precondition phase*) and subsequently, the variance remains fixed and is used as a precondition to learn N:M masks (*mask-learning phase*). STEP automatically identifies the switching point of two phases by dynamically sampling variance changes over the training trajectory and testing the sample concentration. Empirically, we evaluate STEP and other baselines such as ASP and SR-STE on multiple tasks including CIFAR classification, machine translation and LLM fine-tuning (BERT-Base, GPT-2). We show STEP mitigates the accuracy drop of baseline recipes and is robust to aggressive structured sparsity ratios.'}",https://openreview.net{'value': '/pdf/217237f537e4f7b12ae7286d2bb3a711abff5040.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2023,Conference
