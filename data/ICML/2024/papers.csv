forum,title,authors,authorids,keywords,abstract,pdf,match,venue,year,type
https://openreview.net/forum?id=zdNTiTs5gU,{'value': 'TIC-TAC: A Framework For Improved Covariance Estimation In Deep Heteroscedastic Regression'},Megh Shukla; Mathieu Salzmann; Alexandre Alahi,~Megh_Shukla1; ~Mathieu_Salzmann1; ~Alexandre_Alahi3,,"{'value': 'Deep heteroscedastic regression involves jointly optimizing the mean and covariance of the predicted distribution using the negative log-likelihood. However, recent works show that this may result in sub-optimal convergence due to the challenges associated with covariance estimation. While the literature addresses this by proposing alternate formulations to mitigate the impact of the predicted covariance, we focus on improving the predicted covariance itself. We study two questions: (1) Does the predicted covariance truly capture the randomness of the predicted mean? (2) In the absence of supervision, how can we quantify the accuracy of covariance estimation? We address (1) with a _Taylor Induced Covariance (TIC)_, which captures the randomness of the predicted mean by incorporating its gradient and curvature through the second order Taylor polynomial. Furthermore, we tackle (2) by introducing a _Task Agnostic Correlations (TAC)_ metric, which combines the notion of correlations and absolute error to evaluate the covariance. We evaluate TIC-TAC across multiple experiments spanning synthetic and real-world datasets. Our results show that not only does TIC accurately learn the covariance, it additionally facilitates an improved convergence of the negative log-likelihood. Our code is available at [https://github.com/vita-epfl/TIC-TAC](https://github.com/vita-epfl/TIC-TAC)'}",https://openreview.net{'value': '/pdf/f4f6afe3515d9a18668fc0e5440959a1962def17.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=zc3bAEI5lp,{'value': 'Differentially Private Sum-Product Networks'},Xenia Heilmann; Mattia Cerrato; Ernst Althaus,~Xenia_Heilmann1; ~Mattia_Cerrato1; ernst.althaus@uni-mainz.de,,"{'value': 'Differentially private ML approaches seek to learn models which may be publicly released while guaranteeing that the input data is kept private. One issue with this construction is that further model releases based on the same training data (e.g. for a new task) incur a further privacy budget cost. Privacy-preserving synthetic data generation is one possible solution to this conundrum. However, models trained on synthetic private data struggle to approach the performance of private, ad-hoc models. In this paper, we present a novel method based on sum-product networks that is able to perform both privacy-preserving classification and privacy-preserving data generation with a single model. To the best of our knowledge, ours is the first approach that provides both discriminative and generative capabilities to differentially private ML. We show that our approach outperforms the state of the art in terms of stability (i.e. number of training runs required for convergence) and utility of the generated data.'}",https://openreview.net{'value': '/pdf/7f1c50d0458286933868611ae657128c5c7b5874.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=zMwFvxr6CV,{'value': 'Agent Instructs Large Language Models to be General Zero-Shot Reasoners'},Nicholas Crispino; Kyle Montgomery; Fankun Zeng; Dawn Song; Chenguang Wang,~Nicholas_Crispino1; ~Kyle_Montgomery1; ~Fankun_Zeng1; ~Dawn_Song1; ~Chenguang_Wang1,,"{'value': 'We introduce a method to improve the zero-shot reasoning abilities of large language models on general language understanding tasks. Specifically, we build an autonomous agent to instruct the reasoning process of large language models. To enable this, our agent only needs to generate a single set of instructions for each task. These instructions turn out to be extremely effective for improving the reasoning process of different large language models across all task instances. We show this approach further unleashes the zero-shot reasoning abilities of large language models to more tasks. We study the performance of our method on a wide set of datasets spanning generation, classification, and reasoning. We show that our method generalizes to most tasks and obtains state-of-the-art zero-shot performance on 20 of the 29 datasets that we evaluate. For instance, our method boosts the performance of state-of-the-art large language models by a large margin, including Vicuna-13b, Llama-2-70b-chat, and GPT-3.5 Turbo. Compared to zero-shot chain of thought, our improvement in reasoning is striking. With our method, Llama-2-70b-chat outperforms zero-shot GPT-3.5 Turbo significantly.'}",https://openreview.net{'value': '/pdf/712ce06fef1f61ef5246bb1724c3692c9937bc59.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=z8sYc334fU,{'value': 'What is Dataset Distillation Learning?'},William Yang; Ye Zhu; Zhiwei Deng; Olga Russakovsky,~William_Yang1; ~Ye_Zhu3; ~Zhiwei_Deng3; ~Olga_Russakovsky1,,"{'value': 'Dataset distillation has emerged as a strategy to overcome the hurdles associated with large datasets by learning a compact set of synthetic data that retains essential information from the original dataset. While distilled data can be used to train high performing models, little is understood about how the information is stored. In this study, we posit and answer three questions about the behavior, representativeness, and point-wise information content of distilled data. We reveal distilled data cannot serve as a substitute for real data during training outside the standard evaluation setting for dataset distillation. Additionally, the distillation process retains high task performance by compressing information related to the early training dynamics of real models. Finally, we provide an framework for interpreting distilled data and reveal that individual distilled data points contain meaningful semantic information. This investigation sheds light on the intricate nature of distilled data, providing a better understanding on how they can be effectively utilized.'}",https://openreview.net{'value': '/pdf/669e281d2ba6dc21143c18dc1499fad671681c14.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=ykgZk6vFrh,{'value': 'Incentivized Learning in Principal-Agent Bandit Games'},Antoine Scheid; Daniil Tiapkin; Etienne Boursier; Aymeric Capitaine; Eric Moulines; Michael Jordan; El-Mahdi El-Mhamdi; Alain Oliviero Durmus,~Antoine_Scheid1; ~Daniil_Tiapkin1; ~Etienne_Boursier1; ~Aymeric_Capitaine1; ~Eric_Moulines1; ~Michael_Jordan1; ~El-Mahdi_El-Mhamdi1; ~Alain_Oliviero_Durmus1,,"{'value': ""This work considers a repeated principal-agent bandit game, where the principal can only interact with her environment through the agent. The principal and the agent have misaligned objectives and the choice of action is only left to the agent. However, the principal can influence the agent's decisions by offering incentives which add up to his rewards. The principal aims to iteratively learn an incentive policy to maximize her own total utility. This framework extends usual bandit problems and is motivated by several practical applications, such as healthcare or ecological taxation, where traditionally used mechanism design theories often overlook the learning aspect of the problem. We present nearly optimal (with respect to a horizon $T$) learning algorithms for the principal's regret in both multi-armed and linear contextual settings. Finally, we support our theoretical guarantees through numerical experiments.""}",https://openreview.net{'value': '/pdf/30769721594d4ad896d36dda1636489629802123.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=ykZYLBcA9g,{'value': 'Learning with Complementary Labels Revisited: The Selected-Completely-at-Random Setting Is More Practical'},Wei Wang; Takashi Ishida; Yu-Jie Zhang; Gang Niu; Masashi Sugiyama,~Wei_Wang68; ~Takashi_Ishida1; ~Yu-Jie_Zhang1; ~Gang_Niu1; ~Masashi_Sugiyama1,,"{'value': 'Complementary-label learning is a weakly supervised learning problem in which each training example is associated with one or multiple complementary labels indicating the classes to which it does not belong. Existing consistent approaches have relied on the uniform distribution assumption to model the generation of complementary labels, or on an ordinary-label training set to estimate the transition matrix in non-uniform cases. However, either condition may not be satisfied in real-world scenarios. In this paper, we propose a novel consistent approach that does not rely on these conditions. Inspired by the positive-unlabeled (PU) learning literature, we propose an unbiased risk estimator based on the Selected-Completely-at-Random assumption for complementary-label learning. We then introduce a risk-correction approach to address overfitting problems. Furthermore, we find that complementary-label learning can be expressed as a set of negative-unlabeled binary classification problems when using the one-versus-rest strategy. Extensive experimental results on both synthetic and real-world benchmark datasets validate the superiority of our proposed approach over state-of-the-art methods.'}",https://openreview.net{'value': '/pdf/e66aab8b3dc4b9ab443603123959980477e1f765.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=yShA4VPYZB,{'value': '${\\rm E}(3)$-Equivariant Actor-Critic Methods for Cooperative Multi-Agent Reinforcement Learning'},Dingyang Chen; Qi Zhang,~Dingyang_Chen1; ~Qi_Zhang12,,"{'value': 'Identification and analysis of symmetrical patterns in the natural world have led to significant discoveries across various scientific fields, such as the formulation of gravitational laws in physics and advancements in the study of chemical structures. In this paper, we focus on exploiting Euclidean symmetries inherent in certain cooperative multi-agent reinforcement learning (MARL) problems and prevalent in many applications. We begin by formally characterizing a subclass of Markov games with a general notion of symmetries that admits the existence of symmetric optimal values and policies. Motivated by these properties, we design neural network architectures with symmetric constraints embedded as an inductive bias for multi-agent actor-critic methods. This inductive bias results in superior performance in various cooperative MARL benchmarks and impressive generalization capabilities such as zero-shot learning and transfer learning in unseen scenarios with repeated symmetric patterns.'}",https://openreview.net{'value': '/pdf/694e33b8df6d1b84e2a807b48756faa1dad6637d.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=y8YovS0lOg,{'value': 'On the Implicit Bias of Adam'},Matias D. Cattaneo; Jason Matthew Klusowski; Boris Shigida,~Matias_D._Cattaneo1; ~Jason_Matthew_Klusowski1; ~Boris_Shigida1,,"{'value': 'In previous literature, backward error analysis was used to find ordinary differential equations (ODEs) approximating the gradient descent trajectory. It was found that finite step sizes implicitly regularize solutions because terms appearing in the ODEs penalize the two-norm of the loss gradients. We prove that the existence of similar implicit regularization in RMSProp and Adam depends on their hyperparameters and the training stage, but with a different ""norm"" involved: the corresponding ODE terms either penalize the (perturbed) one-norm of the loss gradients or, conversely, impede its reduction (the latter case being typical). We also conduct numerical experiments and discuss how the proven facts can influence generalization.'}",https://openreview.net{'value': '/pdf/6bff9b7039e4b14ba3a6ae32b21943bc25129a2a.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2024,Conference
https://openreview.net/forum?id=xye7iNsgXn,{'value': 'Actions Speak Louder than Words: Trillion-Parameter Sequential Transducers for Generative Recommendations'},Jiaqi Zhai; Lucy Liao; Xing Liu; Yueming Wang; Rui Li; Xuan Cao; Leon Gao; Zhaojie Gong; Fangda Gu; Jiayuan He; Yinghai Lu; Yu Shi,~Jiaqi_Zhai1; ~Lucy_Liao1; ~Xing_Liu5; ~Yueming_Wang4; ~Rui_Li32; ~Xuan_Cao2; ~Leon_Gao1; ~Zhaojie_Gong1; ~Fangda_Gu1; ~Jiayuan_He2; ~Yinghai_Lu1; ~Yu_Shi1,,"{'value': ""Large-scale recommendation systems are characterized by their reliance on high cardinality, heterogeneous features and the need to handle tens of billions of user actions on a daily basis. Despite being trained on huge volume of data with thousands of features, most Deep Learning Recommendation Models (DLRMs) in industry fail to scale with compute. Inspired by success achieved by Transformers in language and vision domains, we revisit fundamental design choices in recommendation systems. We reformulate recommendation problems as sequential transduction tasks within a generative modeling framework (``Generative Recommenders''), and propose a new architecture, HSTU, designed for high cardinality, non-stationary streaming recommendation data. HSTU outperforms baselines over synthetic and public datasets by up to 65.8% in NDCG, and is 5.3x to 15.2x faster than FlashAttention2-based Transformers on 8192 length sequences. HSTU-based Generative Recommenders, with 1.5 trillion parameters, improve metrics in online A/B tests by 12.4% and have been deployed on multiple surfaces of a large internet platform with billions of users. More importantly, the model quality of Generative Recommenders empirically scales as a power-law of training compute across three orders of magnitude, up to GPT-3/LLaMa-2 scale, which reduces carbon footprint needed for future model developments, and further paves the way for the first foundation models in recommendations.""}",https://openreview.net{'value': '/pdf/bb47081b90b48b580e77f6a8f3e7ba940022b0ba.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=xW79geE0RA,{'value': 'Model-based Reinforcement Learning for Parameterized Action Spaces'},Renhao Zhang; Haotian Fu; Yilin Miao; George Konidaris,~Renhao_Zhang1; ~Haotian_Fu3; ~Yilin_Miao1; ~George_Konidaris1,,{'value': 'We propose a novel model-based reinforcement learning algorithm---Dynamics Learning and predictive control with Parameterized Actions (DLPA)---for Parameterized Action Markov Decision Processes (PAMDPs). The agent learns a parameterized-action-conditioned dynamics model and plans with a modified Model Predictive Path Integral control. We theoretically quantify the difference between the generated trajectory and the optimal trajectory during planning in terms of the value they achieved through the lens of Lipschitz Continuity. Our empirical results on several standard benchmarks show that our algorithm achieves superior sample efficiency and asymptotic performance than state-of-the-art PAMDP methods.'},https://openreview.net{'value': '/pdf/e252b7f6920dbad3c944f7473abb07e3c10d70c8.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2024,Conference
https://openreview.net/forum?id=xS2YKQlBIZ,{'value': 'Achieving Margin Maximization Exponentially Fast via Progressive Norm Rescaling'},Mingze Wang; Zeping Min; Lei Wu,~Mingze_Wang2; ~Zeping_Min1; ~Lei_Wu1,,"{'value': 'In this work, we investigate the margin-maximization bias exhibited by gradient-based algorithms in classifying linearly separable data. We present an in-depth analysis of the specific properties of the velocity field associated with (normalized) gradients, focusing on their role in margin maximization. Inspired by this analysis, we propose a novel algorithm called Progressive Rescaling Gradient Descent (PRGD) and show that PRGD can maximize the margin at an *exponential rate*. This stands in stark contrast to all existing algorithms, which maximize the margin at a slow *polynomial rate*. Specifically, we identify mild conditions on data distribution under which existing algorithms such as gradient descent (GD) and normalized gradient descent (NGD) *provably fail* in maximizing the margin efficiently. To validate our theoretical findings, we present both synthetic and real-world experiments. Notably, PRGD also shows promise in enhancing the generalization performance when applied to linearly non-separable datasets and deep neural networks.'}",https://openreview.net{'value': '/pdf/dd764b95da8e4b798389cdae9450bbd8532a212d.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=wwItuHdus6,{'value': 'A Computational Framework for Solving Wasserstein Lagrangian Flows'},Kirill Neklyudov; Rob Brekelmans; Alexander Tong; Lazar Atanackovic; qiang liu; Alireza Makhzani,~Kirill_Neklyudov1; ~Rob_Brekelmans1; ~Alexander_Tong1; ~Lazar_Atanackovic1; ~qiang_liu4; ~Alireza_Makhzani1,,"{'value': 'The dynamical formulation of the optimal transport can be extended through various choices of the underlying geometry (*kinetic energy*), and the regularization of density paths (*potential energy*). These combinations yield different variational problems (*Lagrangians*), encompassing many variations of the optimal transport problem such as the Schrödinger bridge, unbalanced optimal transport, and optimal transport with physical constraints, among others. In general, the optimal density path is unknown, and solving these variational problems can be computationally challenging. We propose a novel deep learning based framework approaching all of these problems from a unified perspective. Leveraging the dual formulation of the Lagrangians, our method does not require simulating or backpropagating through the trajectories of the learned dynamics, and does not need access to optimal couplings. We showcase the versatility of the proposed framework by outperforming previous approaches for the single-cell trajectory inference, where incorporating prior knowledge into the dynamics is crucial for correct predictions.'}",https://openreview.net{'value': '/pdf/42682419dcf8ccd70865f968ab4156975e19dcfa.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2024,Conference
https://openreview.net/forum?id=wmljUnbjy6,{'value': 'Unsupervised Parameter-free Simplicial Representation Learning with Scattering Transforms'},Hiren Madhu; Sravanthi Gurugubelli; Sundeep Prabhakar Chepuri,~Hiren_Madhu1; ~Sravanthi_Gurugubelli1; ~Sundeep_Prabhakar_Chepuri1,,"{'value': 'Simplicial neural network models are becoming popular for processing and analyzing higher-order graph data, but they suffer from high training complexity and dependence on task-specific labels. To address these challenges, we propose simplicial scattering networks (SSNs), a parameter-free model inspired by scattering transforms designed to extract task-agnostic features from simplicial complex data without labels in a principled manner. Specifically, we propose a simplicial scattering transform based on random walk matrices for various adjacencies underlying a simplicial complex. We then use the simplicial scattering transform to construct a deep filter bank network that captures high-frequency information at multiple scales. The proposed simplicial scattering transform possesses properties such as permutation invariance, robustness to perturbations, and expressivity. We theoretically prove that including higher-order information improves the robustness of SSNs to perturbations. Empirical evaluations demonstrate that SSNs outperform existing simplicial or graph neural models in many tasks like node classification, simplicial closure, graph classification, trajectory prediction, and simplex prediction while being computationally efficient.'}",https://openreview.net{'value': '/pdf/c86519c899c3ac54e7702b9fdcbb438886ce2c8c.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2024,Conference
https://openreview.net/forum?id=wlBtHP8KqS,{'value': 'Better Locally Private Sparse Estimation Given Multiple Samples Per User'},Yuheng Ma; Ke Jia; Hanfang Yang,~Yuheng_Ma1; ~Ke_Jia1; ~Hanfang_Yang2,,"{'value': 'Previous studies yielded discouraging results for item-level locally differentially private linear regression with $s$-sparsity assumption, where the minimax rate for $nm$ samples is $\\mathcal{O}(sd / nm\\varepsilon^2)$. This can be challenging for high-dimensional data, where the dimension $d$ is extremely large. In this work, we investigate user-level locally differentially private sparse linear regression. We show that with $n$ users each contributing $m$ samples, the linear dependency of dimension $d$ can be eliminated, yielding an error upper bound of $\\mathcal{O}(s/ nm\\varepsilon^2)$. We propose a framework that first selects candidate variables and then conducts estimation in the narrowed low-dimensional space, which is extendable to general sparse estimation problems with tight error bounds. Experiments on both synthetic and real datasets demonstrate the superiority of the proposed methods. Both the theoretical and empirical results suggest that, with the same number of samples, locally private sparse estimation is better conducted when multiple samples per user are available.'}",https://openreview.net{'value': '/pdf/64ce4a5e3f521f1c87173c2e69e4e1b7f60678ac.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=wUgTnf918v,{'value': 'An Interpretable Evaluation of Entropy-based Novelty of Generative Models'},Jingwei Zhang; Cheuk Ting Li; Farzan Farnia,~Jingwei_Zhang9; ~Cheuk_Ting_Li1; ~Farzan_Farnia1,,"{'value': ""The massive developments of generative model frameworks require principled methods for the evaluation of a model's novelty compared to a reference dataset. While the literature has extensively studied the evaluation of the quality, diversity, and generalizability of generative models, the assessment of a model's novelty compared to a reference model has not been adequately explored in the machine learning community. In this work, we focus on the novelty assessment for multi-modal distributions and attempt to address the following differential clustering task: Given samples of a generative model $P_\\mathcal{G}$ and a reference model $P_\\mathrm{ref}$, how can we discover the sample types expressed by $P_\\mathcal{G}$ more frequently than in $P_\\mathrm{ref}$? We introduce a spectral approach to the differential clustering task and propose the Kernel-based Entropic Novelty (KEN) score to quantify the mode-based novelty of $P_\\mathcal{G}$ with respect to $P_\\mathrm{ref}$. We analyze the KEN score for mixture distributions with well-separable components and develop a kernel-based method to compute the KEN score from empirical data. We support the KEN framework by presenting numerical results on synthetic and real image datasets, indicating the framework's effectiveness in detecting novel modes and comparing generative models. The paper's code is available at: github.com/buyeah1109/KEN.""}",https://openreview.net{'value': '/pdf/ff03f436bd71ad60fbea5ce27c17b825bb084b9b.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=wK9RvVmi7u,{'value': 'Understanding Heterophily for Graph Neural Networks'},Junfu Wang; Yuanfang Guo; Liang Yang; Yunhong Wang,~Junfu_Wang1; ~Yuanfang_Guo1; ~Liang_Yang2; ~Yunhong_Wang1,,"{'value': 'Graphs with heterophily have been regarded as challenging scenarios for Graph Neural Networks (GNNs), where nodes are connected with dissimilar neighbors through various patterns. In this paper, we present theoretical understandings of heterophily for GNNs by incorporating the graph convolution (GC) operations into fully connected networks via the proposed Heterophilous Stochastic Block Models (HSBM), a general random graph model that can accommodate diverse heterophily patterns. Our theoretical investigation comprehensively analyze the impact of heterophily from three critical aspects. Firstly, for the impact of different heterophily patterns, we show that the separability gains are determined by two factors, i.e., the Euclidean distance of the neighborhood distributions and $\\sqrt{\\mathbb{E}\\left[\\operatorname{deg}\\right]}$, where $\\mathbb{E}\\left[\\operatorname{deg}\\right]$ is the averaged node degree. Secondly, we show that the neighborhood inconsistency has a detrimental impact on separability, which is similar to degrading $\\mathbb{E}\\left[\\operatorname{deg}\\right]$ by a specific factor. Finally, for the impact of stacking multiple layers, we show that the separability gains are determined by the normalized distance of the $l$-powered neighborhood distributions, indicating that nodes still possess separability in various regimes, even when over-smoothing occurs. Extensive experiments on both synthetic and real-world data verify the effectiveness of our theory.'}",https://openreview.net{'value': '/pdf/68c120cfe22dd50929357ff8d83e3f3fa6b76be9.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=wGtzp4ZT1n,{'value': 'CompeteAI: Understanding the Competition Dynamics of Large Language Model-based Agents'},Qinlin Zhao; Jindong Wang; Yixuan Zhang; Yiqiao Jin; Kaijie Zhu; Hao Chen; Xing Xie,~Qinlin_Zhao1; ~Jindong_Wang1; ~Yixuan_Zhang7; ~Yiqiao_Jin1; ~Kaijie_Zhu1; ~Hao_Chen15; ~Xing_Xie3,,"{'value': 'Large language models (LLMs) have been widely used as agents to complete different tasks, such as personal assistance or event planning. Although most of the work has focused on cooperation and collaboration between agents, little work explores *competition*, another important mechanism that promotes the development of society and economy. In this paper, we seek to examine the competition dynamics in LLM-based agents. We first propose a general framework for studying the competition between agents. Then, we implement a practical competitive environment using GPT-4 to simulate a virtual town with two types of agents, including restaurant agents and customer agents. Specifically, the restaurant agents compete with each other to attract more customers, where competition encourages them to transform, such as cultivating new operating strategies. Simulation experiments reveal several interesting findings at the micro and macro levels, which align well with existing market and sociological theories. We hope that the framework and environment can be a promising testbed to study the competition that fosters understanding of society. Code is available at: https://github.com/microsoft/competeai.'}",https://openreview.net{'value': '/pdf/7930d0c9c7497349a28b9c5bffaa761f8a66bd60.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=w5oUo0LhO1,{'value': 'Kernel Semi-Implicit Variational Inference'},Ziheng Cheng; Longlin Yu; Tianyu Xie; Shiyue Zhang; Cheng Zhang,~Ziheng_Cheng4; ~Longlin_Yu1; ~Tianyu_Xie1; ~Shiyue_Zhang3; ~Cheng_Zhang3,,"{'value': 'Semi-implicit variational inference (SIVI) extends traditional variational families with semi-implicit distributions defined in a hierarchical manner. Due to the intractable densities of semi-implicit distributions, classical SIVI often resorts to surrogates of evidence lower bound (ELBO) that would introduce biases for training. A recent advancement in SIVI, named SIVI-SM, utilizes an alternative score matching objective made tractable via a minimax formulation, albeit requiring an additional lower-level optimization. In this paper, we propose kernel SIVI (KSIVI), a variant of SIVI-SM that eliminates the need for the lower-level optimization through kernel tricks. Specifically, we show that when optimizing over a reproducing kernel Hilbert space (RKHS), the lower-level problem has an explicit solution. This way, the upper-level objective becomes the kernel Stein discrepancy (KSD), which is readily computable for stochastic gradient descent due to the hierarchical structure of semi-implicit variational distributions. An upper bound for the variance of the Monte Carlo gradient estimators of the KSD objective is derived, which allows us to establish novel convergence guarantees of KSIVI. We demonstrate the effectiveness and efficiency of KSIVI on both synthetic distributions and a variety of real data Bayesian inference tasks.'}",https://openreview.net{'value': '/pdf/c20460d5d8a1d3e228e5fa1bb684e36fa3bd7161.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=usUPvQH3XK,{'value': 'Language Agents with Reinforcement Learning for Strategic Play in the Werewolf Game'},Zelai Xu; Chao Yu; Fei Fang; Yu Wang; Yi Wu,~Zelai_Xu1; ~Chao_Yu1; ~Fei_Fang1; ~Yu_Wang3; ~Yi_Wu1,,"{'value': ""Agents built with large language models (LLMs) have shown great potential across a wide range of domains. However, in complex decision-making tasks, pure LLM-based agents tend to exhibit intrinsic bias in their choice of actions, which is inherited from the model's training data and results in suboptimal performance. To develop *strategic language agents*, i.e., agents that generate flexible language actions and possess strong decision-making abilities, we propose a novel framework that powers LLM-based agents with reinforcement learning (RL). We consider Werewolf, a popular social deduction game, as a challenging testbed that emphasizes versatile communication and strategic gameplay. To mitigate the intrinsic bias in language actions, our agents use an LLM to perform deductive reasoning and generate a diverse set of action candidates. Then an RL policy trained to optimize the decision-making ability chooses an action from the candidates to play in the game. Extensive experiments show that our agents overcome the intrinsic bias and outperform existing LLM-based agents in the Werewolf game. We also conduct human-agent experiments and find that our agents achieve human-level performance and demonstrate strong strategic play.""}",https://openreview.net{'value': '/pdf/e7e781c805471c273082bc2ba56bdb41fe20df24.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=udFZhUgtkI,{'value': 'Learning Scale-Aware Spatio-temporal Implicit Representation for Event-based Motion Deblurring'},Wei Yu; Jianing Li; Shengping Zhang; Xiangyang Ji,~Wei_Yu14; ~Jianing_Li4; ~Shengping_Zhang1; ~Xiangyang_Ji1,,"{'value': 'Existing event-based motion deblurring methods mostly focus on restoring images with the same spatial and temporal scales as events. However, the unknown scales of images and events in the real world pose great challenges and have rarely been explored. To address this gap, we propose a novel Scale-Aware Spatio-temporal Network (SASNet) to flexibly restore blurred images with event streams at arbitrary scales. The core idea is to implicitly aggregate both spatial and temporal correspondence features of images and events to generalize at continuous scales. To restore highly blurred local areas, we develop a Spatial Implicit Representation Module (SIRM) to aggregate spatial correlation at any resolution through event encoding sampling. To tackle global motion blur, a Temporal Implicit Representation Module (TIRM) is presented to learn temporal correlation via temporal shift operations with long-term aggregation. Additionally, we build a High-resolution Hybrid Deblur (H2D) dataset using a new-generation hybrid event-based sensor, which comprises images with naturally spatially aligned and temporally synchronized events at various scales. Experiments demonstrate that our SASNet outperforms state-of-the-art methods on both synthetic GoPro and real H2D datasets, especially in high-speed motion scenarios. Code and dataset are available at https://github.com/aipixel/SASNet.'}",https://openreview.net{'value': '/pdf/5ae0b198f90c71bb4773dba0baf14c51bd0d9c5c.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=uYIFQOtb58,{'value': 'Graph-based Forecasting with Missing Data through Spatiotemporal Downsampling'},Ivan Marisca; Cesare Alippi; Filippo Maria Bianchi,~Ivan_Marisca1; ~Cesare_Alippi1; ~Filippo_Maria_Bianchi1,,"{'value': 'Given a set of synchronous time series, each associated with a sensor-point in space and characterized by inter-series relationships, the problem of spatiotemporal forecasting consists of predicting future observations for each point. Spatiotemporal graph neural networks achieve striking results by representing the relationships across time series as a graph. Nonetheless, most existing methods rely on the often unrealistic assumption that inputs are always available and fail to capture hidden spatiotemporal dynamics when part of the data is missing. In this work, we tackle this problem through hierarchical spatiotemporal downsampling. The input time series are progressively coarsened over time and space, obtaining a pool of representations that capture heterogeneous temporal and spatial dynamics. Conditioned on observations and missing data patterns, such representations are combined by an interpretable attention mechanism to generate the forecasts. Our approach outperforms state-of-the-art methods on synthetic and real-world benchmarks under different missing data distributions, particularly in the presence of contiguous blocks of missing values.'}",https://openreview.net{'value': '/pdf/e6317618bb945b804535aba5533a2047db4a3685.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=uTC9AFXIhg,{'value': 'GPTSwarm: Language Agents as Optimizable Graphs'},Mingchen Zhuge; Wenyi Wang; Louis Kirsch; Francesco Faccio; Dmitrii Khizbullin; Jürgen Schmidhuber,~Mingchen_Zhuge2; ~Wenyi_Wang1; ~Louis_Kirsch1; ~Francesco_Faccio1; ~Dmitrii_Khizbullin2; ~Jürgen_Schmidhuber1,,"{'value': 'Various human-designed prompt engineering techniques have been proposed to improve problem solvers based on Large Language Models (LLMs), yielding many disparate code bases. We unify these approaches by describing LLM-based agents as computational graphs. The nodes implement functions to process multimodal data or query LLMs, and the edges describe the information flow between operations. Graphs can be recursively combined into larger composite graphs representing hierarchies of inter-agent collaboration (where edges connect operations of different agents). Our novel automatic graph optimizers (1) refine node-level LLM prompts (node optimization) and (2) improve agent orchestration by changing graph connectivity (edge optimization). Experiments demonstrate that our framework can be used to efficiently develop, integrate, and automatically improve various LLM agents. Our code is public.'}",https://openreview.net{'value': '/pdf/fcd7b79c216e39b694d44951f287447276351249.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=uQiFsBil3p,{'value': 'Random matrix theory improved Fréchet mean of symmetric positive definite matrices'},Florent Bouchard; Ammar Mian; Malik Tiomoko; Guillaume Ginolhac; Frederic Pascal,florent.bouchard@centralesupelec.fr; ammar.mian@univ-smb.fr; ~Malik_Tiomoko1; ~Guillaume_Ginolhac1; ~Frederic_Pascal1,,"{'value': 'In this study, we consider the realm of covariance matrices in machine learning, particularly focusing on computing Fréchet means on the manifold of symmetric positive definite matrices, commonly referred to as Karcher or geometric means. Such means are leveraged in numerous machine learning tasks. Relying on advanced statistical tools, we introduce a random matrix theory based method that estimates Fréchet means, which is particularly beneficial when dealing with low sample support and a high number of matrices to average. Our experimental evaluation, involving both synthetic and real-world EEG and hyperspectral datasets, shows that we largely outperform state-of-the-art methods.'}",https://openreview.net{'value': '/pdf/48b011edae588c6521cf355f2b6248ffc18ebb02.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=u9qmjV2khT,{'value': 'A Global Geometric Analysis of Maximal Coding Rate Reduction'},Peng Wang; Huikang Liu; Druv Pai; Yaodong Yu; Zhihui Zhu; Qing Qu; Yi Ma,~Peng_Wang23; ~Huikang_Liu2; ~Druv_Pai1; ~Yaodong_Yu4; ~Zhihui_Zhu1; ~Qing_Qu2; ~Yi_Ma4,,"{'value': 'The maximal coding rate reduction (MCR$^2$) objective for learning structured and compact deep representations is drawing increasing attention, especially after its recent usage in the derivation of fully explainable and highly effective deep network architectures. However, it lacks a complete theoretical justification: only the properties of its global optima are known, and its global landscape has not been studied. In this work, we give a complete characterization of the properties of all its local and global optima as well as other types of critical points. Specifically, we show that each (local or global) maximizer of the MCR$^2$ problem corresponds to a low-dimensional, discriminative, and diverse representation, and furthermore, each critical point of the objective is either a local maximizer or a strict saddle point. Such a favorable landscape makes MCR$^2$ a natural choice of objective for learning diverse and discriminative representations via first-order optimization. To further verify our theoretical findings, we illustrate these properties with extensive experiments on both synthetic and real data sets.'}",https://openreview.net{'value': '/pdf/a58ea744bff591d06d40a85fafa1704bc25d399e.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=u9oSQtujCF,{'value': 'Empowering Graph Invariance Learning with Deep Spurious Infomax'},Tianjun Yao; Yongqiang Chen; Zhenhao Chen; Kai Hu; Zhiqiang Shen; Kun Zhang,~Tianjun_Yao1; ~Yongqiang_Chen1; ~Zhenhao_Chen1; ~Kai_Hu2; ~Zhiqiang_Shen1; ~Kun_Zhang1,,"{'value': 'Recently, there has been a surge of interest in developing graph neural networks that utilize the invariance principle on graphs to generalize the out-of-distribution (OOD) data. Due to the limited knowledge about OOD data, existing approaches often pose assumptions about the correlation strengths of the underlying spurious features and the target labels. However, this prior is often unavailable and will change arbitrarily in the real-world scenarios, which may lead to severe failures of the existing graph invariance learning methods. To bridge this gap, we introduce a novel graph invariance learning paradigm, which induces a robust and general inductive bias, which is built upon the observation that the infomax principle encourages learning spurious features regardless of spurious correlation strengths. We further propose the EQuAD framework that realizes this learning paradigm and employs tailored learning objectives that provably elicit invariant features by disentangling them from the spurious features learned through infomax. Notably, EQuAD shows stable and enhanced performance across different degrees of bias in synthetic datasets and challenging real-world datasets up to 31.76%.'}",https://openreview.net{'value': '/pdf/6349de57527b94236f45391c55624b5e225f7508.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=tya725xlZ3,{'value': 'Masked Face Recognition with Generative-to-Discriminative Representations'},Shiming Ge; Weijia Guo; Chenyu Li; Zhang Junzheng; Yong Li; Dan Zeng,~Shiming_Ge1; guoweijia@iie.ac.cn; lichenyu@iie.ac.cn; ~Zhang_Junzheng1; liyong@iie.ac.cn; ~Dan_Zeng2,,"{'value': ""Masked face recognition is important for social good but challenged by diverse occlusions that cause insufficient or inaccurate representations. In this work, we propose a unified deep network to learn generative-to-discriminative representations for facilitating masked face recognition. To this end, we split the network into three modules and learn them on synthetic masked faces in a greedy module-wise pretraining manner. First, we leverage a generative encoder pretrained for face inpainting and finetune it to represent masked faces into category-aware descriptors. Attribute to the generative encoder's ability in recovering context information, the resulting descriptors can provide occlusion-robust representations for masked faces, mitigating the effect of diverse masks. Then, we incorporate a multi-layer convolutional network as a discriminative reformer and learn it to convert the category-aware descriptors into identity-aware vectors, where the learning is effectively supervised by distilling relation knowledge from off-the-shelf face recognition model. In this way, the discriminative reformer together with the generative encoder serves as the pretrained backbone, providing general and discriminative representations towards masked faces. Finally, we cascade one fully-connected layer following by one softmax layer into a feature classifier and finetune it to identify the reformed identity-aware vectors. Extensive experiments on synthetic and realistic datasets demonstrate the effectiveness of our approach in recognizing masked faces.""}",https://openreview.net{'value': '/pdf/20c99ca6900657ad7e4d8868386fe546b50d56ad.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=ttnbM598vZ,{'value': 'Pairwise Alignment Improves Graph Domain Adaptation'},Shikun Liu; Deyu Zou; Han Zhao; Pan Li,~Shikun_Liu3; ~Deyu_Zou1; ~Han_Zhao1; ~Pan_Li2,,"{'value': 'Graph-based methods, pivotal for label inference over interconnected objects in many real-world applications, often encounter generalization challenges, if the graph used for model training differs significantly from the graph used for testing. This work delves into Graph Domain Adaptation (GDA) to address the unique complexities of distribution shifts over graph data, where interconnected data points experience shifts in features, labels, and in particular, connecting patterns. We propose a novel, theoretically principled method, Pairwise Alignment (Pair-Align) to counter graph structure shift by mitigating conditional structure shift (CSS) and label shift (LS). Pair-Align uses edge weights to recalibrate the influence among neighboring nodes to handle CSS and adjusts the classification loss with label weights to handle LS. Our method demonstrates superior performance in real-world applications, including node classification with region shift in social networks, and the pileup mitigation task in particle colliding experiments. For the first application, we also curate the largest dataset by far for GDA studies. Our method shows strong performance in synthetic and other existing benchmark datasets.'}",https://openreview.net{'value': '/pdf/4c9116a68aafa23dc6ee6c493cb74e4f80bcfbf2.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=t6dBpwkbea,{'value': 'TimeX++: Learning Time-Series Explanations with Information Bottleneck'},Zichuan Liu; Tianchun Wang; Jimeng Shi; Xu Zheng; Zhuomin Chen; Lei Song; Wenqian Dong; Jayantha  Obeysekera; Farhad Shirani; Dongsheng Luo,~Zichuan_Liu3; ~Tianchun_Wang1; ~Jimeng_Shi1; ~Xu_Zheng3; ~Zhuomin_Chen1; ~Lei_Song3; ~Wenqian_Dong2; jobeysek@fiu.edu; ~Farhad_Shirani1; ~Dongsheng_Luo1,,"{'value': 'Explaining deep learning models operating on time series data is crucial in various applications of interest which require interpretable and transparent insights from time series signals. In this work, we investigate this problem from an information theoretic perspective and show that most existing measures of explainability may suffer from trivial solutions and distributional shift issues. To address these issues, we introduce a simple yet practical objective function for time series explainable learning. The design of the objective function builds upon the principle of information bottleneck (IB), and modifies the IB objective function to avoid trivial solutions and distributional shift issues. We further present TimeX++, a novel explanation framework that leverages a parametric network to produce explanation-embedded instances that are both in-distributed and label-preserving. We evaluate TimeX++ on both synthetic and real-world datasets comparing its performance against leading baselines, and validate its practical efficacy through case studies in a real-world environmental application. Quantitative and qualitative evaluations show that TimeX++ outperforms baselines across all datasets, demonstrating a substantial improvement in explanation quality for time series data. The source code is available at https://github.com/zichuan-liu/TimeXplusplus.'}",https://openreview.net{'value': '/pdf/fc79ee62d9f5de5355d771af5880f3c004e2aa7c.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=scMAQ3mFAA,{'value': 'Bayesian Optimization of Function Networks with Partial Evaluations'},Poompol Buathong; Jiayue Wan; Raul Astudillo; Sam Daulton; Maximilian Balandat; Peter I. Frazier,~Poompol_Buathong1; ~Jiayue_Wan1; ~Raul_Astudillo1; ~Sam_Daulton1; ~Maximilian_Balandat1; ~Peter_I._Frazier1,,"{'value': 'Bayesian optimization is a powerful framework for optimizing functions that are expensive or time-consuming to evaluate. Recent work has considered Bayesian optimization of function networks (BOFN), where the objective function is given by a network of functions, each taking as input the output of previous nodes in the network as well as additional parameters. Leveraging this network structure has been shown to yield significant performance improvements. Existing BOFN algorithms for general-purpose networks evaluate the full network at each iteration. However, many real-world applications allow for evaluating nodes individually. To exploit this, we propose a novel knowledge gradient acquisition function that chooses which node and corresponding inputs to evaluate in a cost-aware manner, thereby reducing query costs by evaluating only on a part of the network at each step. We provide an efficient approach to optimizing our acquisition function and show that it outperforms existing BOFN methods and other benchmarks across several synthetic and real-world problems. Our acquisition function is the first to enable cost-aware optimization of a broad class of function networks.'}",https://openreview.net{'value': '/pdf/775910f8f90d320c3bc7b05ed983d16aaaa396a8.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=scFlbJQdm1,{'value': 'Projecting Molecules into Synthesizable Chemical Spaces'},Shitong Luo; Wenhao Gao; Zuofan Wu; Jian Peng; Connor W. Coley; Jianzhu Ma,~Shitong_Luo1; ~Wenhao_Gao1; ~Zuofan_Wu1; ~Jian_Peng1; ~Connor_W._Coley1; ~Jianzhu_Ma2,,"{'value': ""Discovering new drug molecules is a pivotal yet challenging process due to the near-infinitely large chemical space and notorious demands on time and resources. Numerous generative models have recently been introduced to accelerate the drug discovery process, but their progression to experimental validation remains limited, largely due to a lack of consideration for synthetic accessibility in practical settings. In this work, we introduce a novel framework that is capable of generating new chemical structures while ensuring synthetic accessibility. Specifically, we introduce a postfix notation of synthetic pathways to represent molecules in chemical space. Then, we design a transformer-based model to translate molecular graphs into postfix notations of synthesis. We highlight the model's ability to: (a) perform bottom-up synthesis planning more accurately, (b) generate structurally similar, synthesizable analogs for unsynthesizable molecules proposed by generative models with their properties preserved, and (c) explore the local synthesizable chemical space around hit molecules.""}",https://openreview.net{'value': '/pdf/9d20f3ac0f7213f8b02926c4d58e6590a803fc7e.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=sLZzFTMWSt,{'value': 'CaRiNG: Learning Temporal Causal Representation under Non-Invertible Generation Process'},Guangyi Chen; Yifan Shen; Zhenhao Chen; Xiangchen Song; Yuewen Sun; Weiran Yao; Xiao Liu; Kun Zhang,~Guangyi_Chen1; ~Yifan_Shen4; ~Zhenhao_Chen1; ~Xiangchen_Song1; ~Yuewen_Sun1; ~Weiran_Yao1; ~Xiao_Liu23; ~Kun_Zhang1,,"{'value': 'Identifying the underlying time-delayed latent causal processes in sequential data is vital for grasping temporal dynamics and making downstream reasoning. While some recent methods can robustly identify these latent causal variables, they rely on strict assumptions about the invertible generation process from latent variables to observed data. However, these assumptions are often hard to satisfy in real-world applications containing information loss. For instance, the visual perception process translates a 3D space into 2D images, or the phenomenon of persistence of vision incorporates historical data into current perceptions. To address this challenge, we establish an identifiability theory that allows for the recovery of independent latent components even when they come from a nonlinear and non-invertible mix. Using this theory as a foundation, we propose a principled approach, CaRiNG, to learn the Causal Representation of Non-invertible Generative temporal data with identifiability guarantees. Specifically, we utilize temporal context to recover lost latent information and apply the conditions in our theory to guide the training process. Through experiments conducted on synthetic datasets, we validate that our CaRiNG method reliably identifies the causal process, even when the generation process is non-invertible. Moreover, we demonstrate that our approach considerably improves temporal understanding and reasoning in practical applications.'}",https://openreview.net{'value': '/pdf/f52d0669a645415a995d4591423202ed2da4be60.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=s4Hy0L4mml,{'value': 'MS-TIP: Imputation Aware Pedestrian Trajectory Prediction'},Pranav singh chib; Achintya Nath; Paritosh Kabra; Ishu Gupta; Pravendra Singh,~Pranav_singh_chib1; ~Achintya_Nath1; ~Paritosh_Kabra1; ~Ishu_Gupta1; ~Pravendra_Singh1,,"{'value': 'Pedestrian trajectory prediction aims to predict future trajectories based on observed trajectories. Current state-of-the-art methods often assume that the observed sequences of agents are complete, which is a strong assumption that overlooks inherent uncertainties. Understanding pedestrian behavior when dealing with missing values in the observed sequence is crucial for enhancing the performance of predictive models. In this work, we propose the MultiScale hypergraph for Trajectory Imputation and Prediction (MS-TIP), a novel approach that simultaneously addresses the imputation of missing observations and the prediction of future trajectories. Specifically, we leverage transformers with diagonal masked self-attention to impute incomplete observations. Further, our approach promotes complex interaction modeling through multi-scale hypergraphs, optimizing our trajectory prediction module to capture different types of interactions. With the inclusion of scenic attention, we learn contextual scene information, instead of sole reliance on coordinates. Additionally, our approach utilizes an intermediate control point and refinement module to infer future trajectories accurately. Extensive experiments validate the efficacy of MS-TIP in precisely predicting pedestrian future trajectories. Code is publicly available at https://github.com/Pranav-chib/MS-TIP.'}",https://openreview.net{'value': '/pdf/1d8e4c1deb5aa09684e661e39df6dfe8bba15611.pdf'},{'title_filter': 'Trajectory'},ICML.cc,2024,Conference
https://openreview.net/forum?id=rvaN2P1rvC,{'value': 'Differentiable Annealed Importance Sampling Minimizes The Jensen-Shannon Divergence Between Initial and Target Distribution'},Johannes Zenn; Robert Bamler,~Johannes_Zenn1; ~Robert_Bamler1,,"{'value': 'Differentiable annealed importance sampling (DAIS), proposed by Geffner & Domke (2021) and Zhang et al. (2021), allows optimizing, among others, over the initial distribution of AIS. In this paper, we show that, in the limit of many transitions, DAIS minimizes the symmetrized KL divergence (Jensen-Shannon divergence) between the initial and target distribution. Thus, DAIS can be seen as a form of variational inference (VI) in that its initial distribution is a parametric fit to an intractable target distribution. We empirically evaluate the usefulness of the initial distribution as a variational distribution on synthetic and real-world data, observing that it often provides more accurate uncertainty estimates than standard VI (optimizing the reverse KL divergence), importance weighted VI, and Markovian score climbing (optimizing the forward KL divergence).'}",https://openreview.net{'value': '/pdf/8817fd7e635a4aff2b54f065666b4066f1297082.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=rZD9hV0Bc4,{'value': 'Moreau Envelope for Nonconvex Bi-Level Optimization: A Single-Loop and Hessian-Free Solution Strategy'},Risheng Liu; Zhu Liu; Wei Yao; Shangzhi Zeng; Jin Zhang,~Risheng_Liu1; ~Zhu_Liu3; ~Wei_Yao3; ~Shangzhi_Zeng1; ~Jin_Zhang8,,"{'value': ""This work focuses on addressing two major challenges in the context of large-scale nonconvex Bi-Level Optimization (BLO) problems, which are increasingly applied in machine learning due to their ability to model nested structures. These challenges involve ensuring computational efficiency and providing theoretical guarantees. While recent advances in scalable BLO algorithms have primarily relied on lower-level convexity simplification, our work specifically tackles large-scale BLO problems involving nonconvexity in both the upper and lower levels. We simultaneously address computational and theoretical challenges by introducing an innovative single-loop gradient-based algorithm, utilizing the Moreau envelope-based reformulation, and providing non-asymptotic convergence analysis for general nonconvex BLO problems. Notably, our algorithm relies solely on first-order gradient information, enhancing its practicality and efficiency, especially for large-scale BLO learning tasks. We validate our approach's effectiveness through experiments on various synthetic problems, two typical hyper-parameter learning tasks, and a real-world neural architecture search application, collectively demonstrating its superior performance.""}",https://openreview.net{'value': '/pdf/70ffd793caf45a0505186d5b5f748c3922393e3e.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=rPm5cKb1VB,{'value': 'Expressivity and Generalization: Fragment-Biases for Molecular GNNs'},Tom Wollschläger; Niklas Kemper; Leon Hetzel; Johanna Sommer; Stephan Günnemann,~Tom_Wollschläger1; ~Niklas_Kemper1; ~Leon_Hetzel1; ~Johanna_Sommer1; ~Stephan_Günnemann1,,"{'value': 'Although recent advances in higher-order Graph Neural Networks (GNNs) improve the theoretical expressiveness and molecular property predictive performance, they often fall short of the empirical performance of models that explicitly use fragment information as inductive bias. However, for these approaches, there exists no theoretic expressivity study. In this work, we propose the *Fragment-WL* test, an extension to the well-known Weisfeiler & Leman (WL) test, which enables the theoretic analysis of these fragment-biased GNNs. Building on the insights gained from the Fragment-WL test, we develop a new GNN architecture and a fragmentation with infinite vocabulary that significantly boosts expressiveness. We show the effectiveness of our model on synthetic and real-world data where we outperform all GNNs on Peptides and have $12$% lower error than all GNNs on ZINC and $34$% lower error than other fragment-biased models. Furthermore, we show that our model exhibits superior generalization capabilities compared to the latest transformer-based architectures, positioning it as a robust solution for a range of molecular modeling tasks.'}",https://openreview.net{'value': '/pdf/cb994f1137c451928777b282dc02441aeefa9d56.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=r9XICONppE,{'value': 'Reweighted Solutions for Weighted Low Rank Approximation'},David Woodruff; Taisuke Yasuda,~David_Woodruff1; ~Taisuke_Yasuda1,,"{'value': 'Weighted low rank approximation (WLRA) is an important yet computationally challenging primitive with applications ranging from statistical analysis, model compression, and signal processing. To cope with the NP-hardness of this problem, prior work considers heuristics, bicriteria, or parameterized tractable algorithms to solve this problem. In this work, we introduce a new relaxed solution to WLRA which outputs a matrix that is not necessarily low rank, but can be stored using very few parameters and gives provable approximation guarantees when the weight matrix has low rank. Our central idea is to use the weight matrix itself to reweight a low rank solution, which gives an extremely simple algorithm with remarkable empirical performance in applications to model compression and on synthetic datasets. Our algorithm also gives nearly optimal communication complexity bounds for a natural distributed problem associated with this problem, for which we show matching communication lower bounds. Together, our communication complexity bounds show that the rank of the weight matrix provably parameterizes the communication complexity of WLRA. We also obtain the first relative error guarantees for feature selection with a weighted objective.'}",https://openreview.net{'value': '/pdf/ef239b8b39f579d241a60448a5ebfd19fb25ec05.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=qwKSTLbati,{'value': 'Multi-Agent Reinforcement Learning Meets Leaf Sequencing in Radiotherapy'},Riqiang Gao; Florin-Cristian Ghesu; Simon Arberet; Shahab Basiri; Esa Kuusela; Martin Kraus; Dorin Comaniciu; Ali Kamen,~Riqiang_Gao1; ~Florin-Cristian_Ghesu1; simon.arberet@siemens-healthineers.com; shahab.basiri@varian.com; esa.kuusela@varian.com; martin_kraus@siemens-healthineers.com; ~Dorin_Comaniciu1; ~Ali_Kamen2,,"{'value': 'In contemporary radiotherapy planning (RTP), a key module leaf sequencing is predominantly addressed by optimization-based approaches. In this paper, we propose a novel deep reinforcement learning (DRL) model termed as *Reinforced Leaf Sequencer* (RLS) in a multi-agent framework for leaf sequencing. The RLS model offers improvements to time-consuming iterative optimization steps via large-scale training and can control movement patterns through the design of reward mechanisms. We have conducted experiments on four datasets with four metrics and compared our model with a leading optimization sequencer. Our findings reveal that the proposed RLS model can achieve reduced fluence reconstruction errors, and potential faster convergence when integrated in an optimization planner. Additionally, RLS has shown promising results in a full artificial intelligence RTP pipeline. We hope this pioneer multi-agent RL leaf sequencer can foster future research on machine learning for RTP.'}",https://openreview.net{'value': '/pdf/4fe9133be6feac20222786a61413cbefc518e177.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=qmUbSAgz08,{'value': 'Multi-Source Conformal Inference Under Distribution Shift'},Yi Liu; Alexander Levis; Sharon-Lise Normand; Larry Han,~Yi_Liu49; alevis@cmu.edu; larryhan@fas.harvard.edu; ~Larry_Han1,,"{'value': 'Recent years have experienced increasing utilization of complex machine learning models across multiple sources of data to inform more generalizable decision-making. However, distribution shifts across data sources and privacy concerns related to sharing individual-level data, coupled with a lack of uncertainty quantification from machine learning predictions, make it challenging to achieve valid inferences in multi-source environments. In this paper, we consider the problem of obtaining distribution-free prediction intervals for a target population, leveraging multiple potentially biased data sources. We derive the efficient influence functions for the quantiles of unobserved outcomes in the target and source populations, and show that one can incorporate machine learning prediction algorithms in the estimation of nuisance functions while still achieving parametric rates of convergence to nominal coverage probabilities. Moreover, when conditional outcome invariance is violated, we propose a data-adaptive strategy to upweight informative data sources for efficiency gain and downweight non-informative data sources for bias reduction. We highlight the robustness and efficiency of our proposals for a variety of conformal scores and data-generating mechanisms via extensive synthetic experiments. Hospital length of stay prediction intervals for pediatric patients undergoing a high-risk cardiac surgical procedure between 2016-2022 in the U.S. illustrate the utility of our methodology.'}",https://openreview.net{'value': '/pdf/51c041c23d9f05d3628449da4489b21f37bdf172.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=qQjUgItPq4,{'value': 'Controlling Behavioral Diversity in Multi-Agent Reinforcement Learning'},Matteo Bettini; Ryan Kortvelesy; Amanda Prorok,~Matteo_Bettini1; ~Ryan_Kortvelesy1; ~Amanda_Prorok1,,"{'value': ""The study of behavioral diversity in Multi-Agent Reinforcement Learning (MARL) is a nascent yet promising field. In this context, the present work deals with the question of how to control the diversity of a multi-agent system. With no existing approaches to control diversity to a set value, current solutions focus on blindly promoting it via intrinsic rewards or additional loss functions, effectively changing the learning objective and lacking a principled measure for it. To address this, we introduce Diversity Control (DiCo), a method able to control diversity to an exact value of a given metric by representing policies as the sum of a parameter-shared component and dynamically scaled per-agent components. By applying constraints directly to the policy architecture, DiCo leaves the learning objective unchanged, enabling its applicability to any actor-critic MARL algorithm. We theoretically prove that DiCo achieves the desired diversity, and we provide several experiments, both in cooperative and competitive tasks, that show how DiCo can be employed as a novel paradigm to increase performance and sample efficiency in MARL. Multimedia results are available on the paper's website: https://sites.google.com/view/dico-marl""}",https://openreview.net{'value': '/pdf/0ee6b48362637d1329e7f8914d89b5d155acd7f9.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=qFILbkTQWw,"{'value': 'AnyTool: Self-Reflective, Hierarchical Agents for Large-Scale API Calls'}",Yu Du; Fangyun Wei; Hongyang Zhang,~Yu_Du9; ~Fangyun_Wei1; ~Hongyang_Zhang1,,"{'value': 'We introduce AnyTool, a large language model agent designed to revolutionize the utilization of a vast array of tools in addressing user queries. We utilize over 16,000 APIs from Rapid API, operating under the assumption that a subset of these APIs could potentially resolve the queries. AnyTool primarily incorporates three elements: an API retriever with a hierarchical structure, a solver aimed at resolving user queries using a selected set of API candidates, and a self-reflection mechanism, which re-activates AnyTool if the initial solution proves impracticable. AnyTool is powered by the function calling feature of GPT-4, eliminating the need for training external modules. We also revisit the evaluation protocol introduced by previous works and identify a limitation in this protocol that leads to an artificially high pass rate. By revising the evaluation protocol to better reflect practical application scenarios, we introduce an additional benchmark, termed AnyToolBench. Experiments across various datasets demonstrate the superiority of our AnyTool over strong baselines such as ToolLLM and a GPT-4 variant tailored for tool utilization. For instance, AnyTool outperforms ToolLLM by +35.5% in terms of average pass rate on ToolBench.'}",https://openreview.net{'value': '/pdf/5a8a45716f71b14b14413e97e1ee1a2ac221081b.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=qDw4FxMubj,{'value': 'Sample-Efficient Robust Multi-Agent Reinforcement Learning in the Face of Environmental Uncertainty'},Laixi Shi; Eric Mazumdar; Yuejie Chi; Adam Wierman,~Laixi_Shi1; ~Eric_Mazumdar1; ~Yuejie_Chi1; ~Adam_Wierman1,,"{'value': 'To overcome the sim-to-real gap in reinforcement learning (RL), learned policies must maintain robustness against environmental uncertainties. While robust RL has been widely studied in single-agent regimes, in multi-agent environments, the problem remains understudied---despite the fact that the problems posed by environmental uncertainties are often exacerbated by strategic interactions. This work focuses on learning in distributionally robust Markov games (RMGs), a robust variant of standard Markov games, wherein each agent aims to learn a policy that maximizes its own worst-case performance when the deployed environment deviates within its own prescribed uncertainty set. This results in a set of robust equilibrium strategies for all agents that align with classic notions of game-theoretic equilibria. Assuming a non-adaptive sampling mechanism from a generative model, we propose a sample-efficient model-based algorithm (DRNVI) with finite-sample complexity guarantees for learning robust variants of various notions of game-theoretic equilibria. We also establish an information-theoretic lower bound for solving RMGs, which confirms the near-optimal sample complexity of DRNVI with respect to problem-dependent factors such as the size of the state space, the target accuracy, and the horizon length.'}",https://openreview.net{'value': '/pdf/5f8cb933c922ccfd32a482a2f4aeec24bcea2e7b.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=pmncWWkGMz,{'value': 'Agent-Specific Effects: A Causal Effect Propagation Analysis in Multi-Agent MDPs'},Stelios Triantafyllou; Aleksa Sukovic; Debmalya Mandal; Goran Radanovic,~Stelios_Triantafyllou1; ~Aleksa_Sukovic1; ~Debmalya_Mandal2; ~Goran_Radanovic1,,"{'value': ""Establishing causal relationships between actions and outcomes is fundamental for accountable multi-agent decision-making. However, interpreting and quantifying agents' contributions to such relationships pose significant challenges. These challenges are particularly prominent in the context of multi-agent sequential decision-making, where the causal effect of an agent's action on the outcome depends on how other agents respond to that action. In this paper, our objective is to present a systematic approach for attributing the causal effects of agents' actions to the influence they exert on other agents. Focusing on multi-agent Markov decision processes, we introduce agent-specific effects (ASE), a novel causal quantity that measures the effect of an agent's action on the outcome that propagates through other agents. We then turn to the counterfactual counterpart of ASE (cf-ASE), provide a sufficient set of conditions for identifying cf-ASE, and propose a practical sampling-based algorithm for estimating it. Finally, we experimentally evaluate the utility of cf-ASE through a simulation-based testbed, which includes a sepsis management environment.""}",https://openreview.net{'value': '/pdf/4d081a80425c5affad7c399c93b0834e77c7c600.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=piecKJ2DlB,"{'value': 'GPT-4V(ision) is a Generalist Web Agent, if Grounded'}",Boyuan Zheng; Boyu Gou; Jihyung Kil; Huan Sun; Yu Su,~Boyuan_Zheng1; ~Boyu_Gou1; ~Jihyung_Kil1; ~Huan_Sun1; ~Yu_Su2,,"{'value': 'The recent development on large multimodal models (LMMs), especially GPT-4V(ision) and Gemini, has been quickly expanding the capability boundaries of multimodal models beyond traditional tasks like image captioning and visual question answering. In this work, we explore the potential of LMMs like GPT-4V as a generalist web agent that can follow natural language instructions to complete tasks on any given website. We propose SEEACT, a generalist web agent that harnesses the power of LMMs for integrated visual understanding and acting on the web. We evaluate on the recent MIND2WEB benchmark. In addition to standard offline evaluation on cached websites, we enable a new online evaluation setting by developing a tool that allows running web agents on live websites. We show that GPT-4V presents a great potential for web agents---it can successfully complete 51.1% of the tasks on live websites if we manually ground its textual plans into actions on the websites. This substantially outperforms text-only LLMs like GPT-4 or smaller models (FLAN-T5 and BLIP-2) specifically fine-tuned for web agents. However, grounding still remains a major challenge. Existing LMM grounding strategies like set-of-mark prompting turns out to be not effective for web agents, and the best grounding strategy we develop in this paper leverages both the HTML structure and visuals. Yet, there is still a substantial gap with oracle grounding, leaving ample room for further improvement. All code, data, and evaluation tools are available at https://github.com/OSU-NLP-Group/SeeAct.'}",https://openreview.net{'value': '/pdf/a318edcdacb4f16311098d66396ca1c58beaa1bc.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=phGHQOKmaU,{'value': 'DiffStitch: Boosting Offline Reinforcement Learning with Diffusion-based Trajectory Stitching'},Guanghe Li; Yixiang Shan; Zhengbang Zhu; Ting Long; Weinan Zhang,~Guanghe_Li1; ~Yixiang_Shan1; ~Zhengbang_Zhu1; ~Ting_Long1; ~Weinan_Zhang1,,"{'value': 'In offline reinforcement learning (RL), the performance of the learned policy highly depends on the quality of offline datasets. However, the offline dataset contains very limited optimal trajectories in many cases. This poses a challenge for offline RL algorithms, as agents must acquire the ability to transit to high-reward regions. To address this issue, we introduce Diffusionbased Trajectory Stitching (DiffStitch), a novel diffusion-based data augmentation pipeline that systematically generates stitching transitions between trajectories. DiffStitch effectively connects low-reward trajectories with high-reward trajectories, forming globally optimal trajectories and thereby mitigating the challenges faced by offline RL algorithms in learning trajectory stitching. Empirical experiments conducted on D4RL datasets demonstrate the effectiveness of our pipeline across RL methodologies. Notably, DiffStitch demonstrates substantial enhancements in the performance of one-step methods(IQL), imitation learning methods(TD3+BC) and trajectory optimization methods(DT). Our code is publicly available at https://github.com/guangheli12/DiffStitch'}",https://openreview.net{'value': '/pdf/bd3bd9e45e9be6f523f9686611c87f2916e7ecfc.pdf'},{'title_filter': 'Trajectory'},ICML.cc,2024,Conference
https://openreview.net/forum?id=pftXzp6Yn3,{'value': 'Translation Equivariant Transformer Neural Processes'},Matthew Ashman; Cristiana Diaconu; Junhyuck Kim; Lakee Sivaraya; Stratis Markou; James Requeima; Wessel P Bruinsma; Richard E. Turner,~Matthew_Ashman1; ~Cristiana_Diaconu1; ~Junhyuck_Kim1; ~Lakee_Sivaraya1; ~Stratis_Markou1; ~James_Requeima1; ~Wessel_P_Bruinsma1; ~Richard_E_Turner1,,"{'value': 'The effectiveness of neural processes (NPs) in modelling posterior prediction maps---the mapping from data to posterior predictive distributions---has significantly improved since their inception. This improvement can be attributed to two principal factors: (1) advancements in the architecture of permutation invariant set functions, which are intrinsic to all NPs; and (2) leveraging symmetries present in the true posterior predictive map, which are problem dependent. Transformers are a notable development in permutation invariant set functions, and their utility within NPs has been demonstrated through the family of models we refer to as TNPs. Despite significant interest in TNPs, little attention has been given to incorporating symmetries. Notably, the posterior prediction maps for data that are stationary---a common assumption in spatio-temporal modelling---exhibit translation equivariance. In this paper, we introduce of a new family of translation equivariant TNPs that incorporate *translation equivariance*. Through an extensive range of experiments on synthetic and real-world spatio-temporal data, we demonstrate the effectiveness of TE-TNPs relative to their non-translation-equivariant counterparts and other NP baselines.'}",https://openreview.net{'value': '/pdf/8615c15f008bc17f240307d930b9791960b85cc5.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=pTFud6SetK,{'value': 'SelMatch: Effectively Scaling Up Dataset Distillation via Selection-Based Initialization and Partial Updates by Trajectory Matching'},Yongmin Lee; Hye Won Chung,~Yongmin_Lee1; ~Hye_Won_Chung2,,"{'value': ""Dataset distillation aims to synthesize a small number of images per class (IPC) from a large dataset to approximate full dataset training with minimal performance loss. While effective in very small IPC ranges, many distillation methods become less effective, even underperforming random sample selection, as IPC increases. Our examination of state-of-the-art trajectory-matching based distillation methods across various IPC scales reveals that these methods struggle to incorporate the complex, rare features of harder samples into the synthetic dataset even with the increased IPC, resulting in a persistent coverage gap between easy and hard test samples. Motivated by such observations, we introduce SelMatch, a novel distillation method that effectively scales with IPC. SelMatch uses selection-based initialization and partial updates through trajectory matching to manage the synthetic dataset's desired difficulty level tailored to IPC scales. When tested on CIFAR-10/100 and TinyImageNet, SelMatch consistently outperforms leading selection-only and distillation-only methods across subset ratios from 5% to 30%.""}",https://openreview.net{'value': '/pdf/6a721456ad09a24586e60cced35638b2aa7235c5.pdf'},{'title_filter': 'Trajectory'},ICML.cc,2024,Conference
https://openreview.net/forum?id=pFWmHUdJE5,{'value': 'O$n$ Learning Deep O($n$)-Equivariant Hyperspheres'},Pavlo Melnyk; Michael Felsberg; Mårten Wadenbäck; Andreas Robinson; Cuong Le,~Pavlo_Melnyk1; ~Michael_Felsberg2; ~Mårten_Wadenbäck1; ~Andreas_Robinson1; ~Cuong_Le1,,"{'value': 'In this paper, we utilize hyperspheres and regular $n$-simplexes and propose an approach to learning deep features equivariant under the transformations of $n$D reflections and rotations, encompassed by the powerful group of O$(n)$. Namely, we propose O$(n)$-equivariant neurons with spherical decision surfaces that generalize to any dimension $n$, which we call Deep Equivariant Hyperspheres. We demonstrate how to combine them in a network that directly operates on the basis of the input points and propose an invariant operator based on the relation between two points and a sphere, which as we show, turns out to be a Gram matrix. Using synthetic and real-world data in $n$D, we experimentally verify our theoretical contributions and find that our approach is superior to the competing methods for O$(n)$-equivariant benchmark datasets (classification and regression), demonstrating a favorable speed/performance trade-off. The code is available on [GitHub](https://github.com/pavlo-melnyk/equivariant-hyperspheres).'}",https://openreview.net{'value': '/pdf/f3dd504e378d074005c5d034a4159ff2e83b8b85.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=pDoAjdrMf0,{'value': 'SF-DQN: Provable Knowledge Transfer using Successor Feature for Deep Reinforcement Learning'},Shuai Zhang; Heshan Devaka Fernando; Miao Liu; Keerthiram Murugesan; Songtao Lu; Pin-Yu Chen; Tianyi Chen; Meng Wang,~Shuai_Zhang6; ~Heshan_Devaka_Fernando1; ~Miao_Liu1; ~Keerthiram_Murugesan1; ~Songtao_Lu1; ~Pin-Yu_Chen1; ~Tianyi_Chen5; ~Meng_Wang4,,"{'value': 'This paper studies the transfer reinforcement learning (RL) problem where multiple RL problems have different reward functions but share the same underlying transition dynamics. In this setting, the Q-function of each RL problem (task) can be decomposed into a successor feature (SF) and a reward mapping: the former characterizes the transition dynamics, and the latter characterizes the task-specific reward function. This Q-function decomposition, coupled with a policy improvement operator known as generalized policy improvement (GPI), reduces the sample complexity of finding the optimal Q-function, and thus the SF & GPI framework exhibits promising empirical performance compared to traditional RL methods like Q-learning. However, its theoretical foundations remain largely unestablished, especially when learning the successor features using deep neural networks (SF-DQN). This paper studies the provable knowledge transfer using SFs-DQN in transfer RL problems. We establish the first convergence analysis with provable generalization guarantees for SF-DQN with GPI. The theory reveals that SF-DQN with GPI outperforms conventional RL approaches, such as deep Q-network, in terms of both faster convergence rate and better generalization. Numerical experiments on real and synthetic RL tasks support the superior performance of SF-DQN & GPI, aligning with our theoretical findings.'}",https://openreview.net{'value': '/pdf/80482a3dd1cf43876b1aee4af7cfd724ce9d32e9.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=ojtddicekd,{'value': 'Q-value Regularized Transformer for Offline Reinforcement Learning'},Shengchao Hu; Ziqing Fan; Chaoqin Huang; Li Shen; Ya Zhang; Yanfeng Wang; Dacheng Tao,~Shengchao_Hu1; ~Ziqing_Fan1; ~Chaoqin_Huang1; ~Li_Shen1; ~Ya_Zhang1; ~Yanfeng_Wang1; ~Dacheng_Tao1,,"{'value': 'Recent advancements in offline reinforcement learning (RL) have underscored the capabilities of Conditional Sequence Modeling (CSM), a paradigm that learns the action distribution based on history trajectory and target returns for each state. However, these methods often struggle with stitching together optimal trajectories from sub-optimal ones due to the inconsistency between the sampled returns within individual trajectories and the optimal returns across multiple trajectories. Fortunately, Dynamic Programming (DP) methods offer a solution by leveraging a value function to approximate optimal future returns for each state, while these techniques are prone to unstable learning behaviors, particularly in long-horizon and sparse-reward scenarios. Building upon these insights, we propose the Q-value regularized Transformer (QT), which combines the trajectory modeling ability of the Transformer with the predictability of optimal future returns from DP methods. QT learns an action-value function and integrates a term maximizing action-values into the training loss of CSM, which aims to seek optimal actions that align closely with the behavior policy. Empirical evaluations on D4RL benchmark datasets demonstrate the superiority of QT over traditional DP and CSM methods, highlighting the potential of QT to enhance the state-of-the-art in offline RL.'}",https://openreview.net{'value': '/pdf/67bdcb299881a5e617a84ab6913e95c66dc57c6a.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2024,Conference
https://openreview.net/forum?id=oiY7yhyi6W,{'value': 'Off-policy Evaluation Beyond Overlap: Sharp Partial Identification Under Smoothness'},Samir Khan; Martin Saveski; Johan Ugander,~Samir_Khan1; ~Martin_Saveski1; ~Johan_Ugander1,,"{'value': 'Off-policy evaluation, and the complementary problem of policy learning, use historical data collected under a logging policy to estimate and/or optimize the value of a target policy. Methods for these tasks typically assume overlap between the target and logging policy, enabling solutions based on importance weighting and/or imputation. Absent such an overlap assumption, existing work either relies on a well-specified model or optimizes needlessly conservative bounds. In this work, we develop methods for no-overlap policy evaluation without a well-specified model, relying instead on non-parametric assumptions on the expected outcome, with a particular focus on Lipschitz smoothness. Under such assumptions we are able to provide sharp bounds on the off-policy value, along with optimal estimators of those bounds. For Lipschitz smoothness, we construct a pair of linear programs that upper and lower bound the contribution of the no-overlap region to the off-policy value. We show that these programs have a concise closed form solution, and that their solutions converge under the Lipschitz assumption to the sharp partial identification bounds at a minimax optimal rate, up to log factors. We demonstrate the effectiveness our methods on two semi-synthetic examples, and obtain informative and valid bounds that are tighter than those possible without smoothness assumptions.'}",https://openreview.net{'value': '/pdf/09432bbbe8521126560d63a5e7e493c340911ea1.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=oTD3WoQyFR,{'value': 'Learning to Explore in POMDPs with Informational Rewards'},Annie Xie; Logan Mondal Bhamidipaty; Evan Zheran Liu; Joey Hong; Sergey Levine; Chelsea Finn,~Annie_Xie1; ~Logan_Mondal_Bhamidipaty1; ~Evan_Zheran_Liu1; ~Joey_Hong2; ~Sergey_Levine1; ~Chelsea_Finn1,,"{'value': 'Standard exploration methods typically rely on random coverage of the state space or coverage-promoting exploration bonuses. However, in partially observed settings, the biggest exploration challenge is often posed by the need to discover information-gathering strategies---e.g., an agent that has to navigate to a location in traffic might learn to first check traffic conditions and then choose a route. In this work, we design a POMDP agent that gathers information about the hidden state, using ideas from the meta-exploration literature. Our approach provides an exploration bonus that rewards the agent for gathering information about the state that is relevant for completing the task. While this requires the agent to know what this information is during training, it can obtained in several ways: in the most general case, off-policy algorithms can leverage knowledge about the entire trajectory to determine such information in hindsight, but the user can also provide prior knowledge (e.g., privileged information) to help inform the training process. Through experiments in several partially-observed environments, we find that our approach is competitive with prior methods when minimal exploration is needed, but substantially outperforms them when more complex strategies are required. Our algorithm also shows the ability to learn without any privileged information, by reasoning about the entire trajectory in hindsight and and effectively using any information it reveals about the hidden state.'}",https://openreview.net{'value': '/pdf/5a9d9e1ca4c43c7df0e066184c860a0a981bd777.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2024,Conference
https://openreview.net/forum?id=oLfq1KKneW,{'value': 'Preference Optimization for Molecule Synthesis with Conditional Residual Energy-based Models'},Songtao Liu; Hanjun Dai; Yue Zhao; Peng Liu,~Songtao_Liu2; ~Hanjun_Dai1; ~Yue_Zhao13; ~Peng_Liu3,,"{'value': 'Molecule synthesis through machine learning is one of the fundamental problems in drug discovery. Current data-driven strategies employ one-step retrosynthesis models and search algorithms to predict synthetic routes in a top-bottom manner. Despite their effective performance, these strategies face limitations in the molecule synthetic route generation due to a greedy selection of the next molecule set without any lookahead. Furthermore, existing strategies cannot control the generation of synthetic routes based on possible criteria such as material costs, yields, and step count. In this work, we propose a general and principled framework via conditional residual energy-based models (EBMs), that focus on the quality of the entire synthetic route based on the specific criteria. By incorporating an additional energy-based function into our probabilistic model, our proposed algorithm can enhance the quality of the most probable synthetic routes (with higher probabilities) generated by various strategies in a plug-and-play fashion. Extensive experiments demonstrate that our framework can consistently boost performance across various strategies and outperforms previous state-of-the-art top-1 accuracy by a margin of 2.5%. Code is available at https://github.com/SongtaoLiu0823/CREBM.'}",https://openreview.net{'value': '/pdf/0b5fa201f46d96620c932b5a1b69bb6aa160e14f.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=o8AaRKbP9K,{'value': 'Can Looped Transformers Learn to Implement Multi-step Gradient Descent for In-context Learning?'},Khashayar Gatmiry; Nikunj Saunshi; Sashank J. Reddi; Stefanie Jegelka; Sanjiv Kumar,~Khashayar_Gatmiry1; ~Nikunj_Saunshi1; ~Sashank_J._Reddi1; ~Stefanie_Jegelka3; ~Sanjiv_Kumar1,,"{'value': 'Transformers to do reasoning and few-shot learning, without any fine-tuning, is widely conjectured to stem from their ability to implicitly simulate a multi-step algorithms -- such as gradient descent -- with their weights in a single forward pass. Recently, there has been progress in understanding this complex phenomenon from an expressivity point of view, by demonstrating that Transformers can express such multi-step algorithms. However, our knowledge about the more fundamental aspect of its learnability, beyond single layer models, is very limited. In particular, *can training Transformers enable convergence to algorithmic solutions*? In this work we resolve this for in context linear regression with linear looped Transformers -- a multi-layer model with weight sharing that is conjectured to have an inductive bias to learn fix-point iterative algorithms. More specifically, for this setting we show that the global minimizer of the population training loss implements multi-step preconditioned gradient descent, with a preconditioner that adapts to the data distribution. Furthermore, we show a fast convergence for gradient flow on the regression loss, despite the non-convexity of the landscape, by proving a novel gradient dominance condition. To our knowledge, this is the first theoretical analysis for multi-layer Transformer in this setting. We further validate our theoretical findings through synthetic experiments.'}",https://openreview.net{'value': '/pdf/65f94d6355d2a69eaeabf88485e6104e8d041197.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=njwv9BsGHF,"{'value': 'Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models'}",Andy Zhou; Kai Yan; Michal Shlapentokh-Rothman; Haohan Wang; Yu-Xiong Wang,~Andy_Zhou2; ~Kai_Yan1; ~Michal_Shlapentokh-Rothman1; ~Haohan_Wang1; ~Yu-Xiong_Wang1,,"{'value': 'While language models (LMs) have shown potential across a range of decision-making tasks, their reliance on simple acting processes limits their broad deployment as autonomous agents. In this paper, we introduce Language Agent Tree Search (LATS) -- the first general framework that synergizes the capabilities of LMs in reasoning, acting, and planning. By leveraging the in-context learning ability of LMs, we integrate Monte Carlo Tree Search into LATS to enable LMs as agents, along with LM-powered value functions and self-reflections for proficient exploration and enhanced decision-making. A key feature of our approach is the incorporation of an environment for external feedback, which offers a more deliberate and adaptive problem-solving mechanism that surpasses the constraints of existing techniques. Our experimental evaluation across diverse domains, including programming, interactive question-answering (QA), web navigation, and math, validates the effectiveness and generality of LATS in decision-making while maintaining competitive or improved reasoning performance. Notably, LATS achieves state-of-the-art pass@1 accuracy (92.7%) for programming on HumanEval with GPT-4 and demonstrates gradient-free performance (average score of 75.9) comparable to gradient-based fine-tuning for web navigation on WebShop with GPT-3.5. Code can be found at https://github.com/lapisrocks/LanguageAgentTreeSearch'}",https://openreview.net{'value': '/pdf/de5bba6e7cb7567200cc824275f00ff93bebae45.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=ngcZhfXCBW,{'value': 'RLVF: Learning from Verbal Feedback without Overgeneralization'},Moritz Pascal Stephan; Alexander Khazatsky; Eric Mitchell; Annie S Chen; Sheryl Hsu; Archit Sharma; Chelsea Finn,~Moritz_Pascal_Stephan1; ~Alexander_Khazatsky1; ~Eric_Mitchell1; ~Annie_S_Chen1; ~Sheryl_Hsu1; ~Archit_Sharma1; ~Chelsea_Finn1,,"{'value': 'The diversity of contexts in which large language models (LLMs) are deployed requires the ability to modify or customize default model behaviors to incorporate nuanced requirements and preferences. A convenient interface to specify such model adjustments is high-level verbal feedback, such as “Don’t use emojis when drafting emails to my boss.” However, while writing high-level feedback is far simpler than collecting annotations for reinforcement learning from human feedback (RLHF), we find that simply prompting a model with such feedback leads to $\\textbf{overgeneralization}$–applying feedback in contexts where it is not relevant. We propose a new method Contextualized Critiques with Constrained Preference Optimization (C3PO) to learn from high-level verbal feedback while reducing overgeneralization compared to current work. C3PO uses a piece of high-level feedback to generate a small synthetic preference dataset to specify when and how the feedback should (and should not) be applied. It then fine-tunes the model in accordance with the synthetic preference data while minimizing the divergence from the original model for prompts where the feedback does not apply. Our experimental results indicate that our approach effectively applies verbal feedback to relevant scenarios while preserving existing behaviors for other contexts more than current methods. For both human- and GPT-4-generated high-level feedback, C3PO effectively adheres to the given feedback comparably to in-context baselines while reducing overgeneralization by 30%.'}",https://openreview.net{'value': '/pdf/3eca80fa9e6241aa713fc70320a1221e314fa8c6.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=nbpwNmXTTw,{'value': 'Conformalized Adaptive Forecasting of Heterogeneous Trajectories'},Yanfei Zhou; Lars Lindemann; Matteo Sesia,~Yanfei_Zhou1; ~Lars_Lindemann1; ~Matteo_Sesia1,,"{'value': 'This paper presents a new conformal method for generating *simultaneous* forecasting bands guaranteed to cover the *entire path* of a new random trajectory with sufficiently high probability. Prompted by the need for dependable uncertainty estimates in motion planning applications where the behavior of diverse objects may be more or less unpredictable, we blend different techniques from online conformal prediction of single and multiple time series, as well as ideas for addressing heteroscedasticity in regression. This solution is both principled, providing precise finite-sample guarantees, and effective, often leading to more informative predictions than prior methods.'}",https://openreview.net{'value': '/pdf/e6d49b8fa61d1e3a2501ff970569f41c8dd48cf1.pdf'},{'title_filter': 'Trajectory'},ICML.cc,2024,Conference
https://openreview.net/forum?id=nMN5hNZMQK,{'value': 'StableSSM: Alleviating the Curse of Memory in State-space Models through Stable Reparameterization'},Shida Wang; Qianxiao Li,~Shida_Wang1; ~Qianxiao_Li1,,"{'value': ""In this paper, we investigate the long-term memory learning capabilities of state-space models (SSMs) from the perspective of parameterization. We prove that state-space models without any reparameterization exhibit a memory limitation similar to that of traditional RNNs: the target relationships that can be stably approximated by state-space models must have an exponential decaying memory. Our analysis identifies this ``curse of memory'' as a result of the recurrent weights converging to a stability boundary, suggesting that a reparameterization technique can be effective. To this end, we introduce a class of reparameterization techniques for SSMs that effectively lift its memory limitations. Besides improving approximation capabilities, we further illustrate that a principled choice of reparameterization scheme can also enhance optimization stability. We validate our findings using synthetic datasets, language models and image classifications.""}",https://openreview.net{'value': '/pdf/5c72105deaa42e6ef62f292b271f30682b9069ee.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=nDps3Q8j2l,{'value': 'Fourier Controller Networks for Real-Time Decision-Making in Embodied Learning'},Hengkai Tan; Songming Liu; Kai Ma; Chengyang Ying; Xingxing Zhang; Hang Su; Jun Zhu,~Hengkai_Tan1; ~Songming_Liu1; ~Kai_Ma6; ~Chengyang_Ying1; ~Xingxing_Zhang3; ~Hang_Su3; ~Jun_Zhu2,,"{'value': ""Transformer has shown promise in reinforcement learning to model time-varying features for obtaining generalized low-level robot policies on diverse robotics datasets in embodied learning. However, it still suffers from the issues of low data efficiency and high inference latency. In this paper, we propose to investigate the task from a new perspective of the frequency domain. We first observe that the energy density in the frequency domain of a robot's trajectory is mainly concentrated in the low-frequency part. Then, we present the Fourier Controller Network (FCNet), a new network that uses Short-Time Fourier Transform (STFT) to extract and encode time-varying features through frequency domain interpolation. In order to do real-time decision-making, we further adopt FFT and Sliding DFT methods in the model architecture to achieve parallel training and efficient recurrent inference. Extensive results in both simulated (e.g., D4RL) and real-world environments (e.g., robot locomotion) demonstrate FCNet's substantial efficiency and effectiveness over existing methods such as Transformer, e.g., FCNet outperforms Transformer on multi-environmental robotics datasets of all types of sizes (from 1.9M to 120M). The project page and code can be found https://thkkk.github.io/fcnet.""}",https://openreview.net{'value': '/pdf/c4b23ea3b2a5c8b61db19feaa7ee3d7ec093de57.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2024,Conference
https://openreview.net/forum?id=nBGBzV4It3,{'value': 'Align Your Steps: Optimizing Sampling Schedules in Diffusion Models'},Amirmojtaba Sabour; Sanja Fidler; Karsten Kreis,~Amirmojtaba_Sabour1; ~Sanja_Fidler1; ~Karsten_Kreis1,,"{'value': 'Diffusion models (DMs) have established themselves as the state-of-the-art generative modeling approach in the visual domain and beyond. A crucial drawback of DMs is their slow sampling speed, relying on many sequential function evaluations through large neural networks. Sampling from DMs can be seen as solving a differential equation through a discretized set of noise levels known as the sampling schedule. While past works primarily focused on deriving efficient solvers, little attention has been given to finding optimal sampling schedules, and the entire literature relies on hand-crafted heuristics. In this work, for the first time, we propose a general and principled approach to optimizing the sampling schedules of DMs for high-quality outputs, called Align Your Steps. We leverage methods from stochastic calculus and find optimal schedules specific to different solvers, trained DMs and datasets. We evaluate our novel approach on several image, video as well as 2D toy data synthesis benchmarks, using a variety of different samplers, and observe that our optimized schedules outperform previous hand-crafted schedules in almost all experiments. Our method demonstrates the untapped potential of sampling schedule optimization, especially in the few-step synthesis regime.'}",https://openreview.net{'value': '/pdf/b0fad028f6d082856ca958783f057fb512624f62.pdf'},{'abstract_filter': 'Data Synthesis'},ICML.cc,2024,Conference
https://openreview.net/forum?id=mz55Ox0Igz,{'value': 'Bayesian Regret Minimization in Offline Bandits'},Marek Petrik; Guy Tennenholtz; Mohammad Ghavamzadeh,~Marek_Petrik2; ~Guy_Tennenholtz4; ~Mohammad_Ghavamzadeh2,,"{'value': 'We study how to make decisions that minimize Bayesian regret in offline linear bandits. Prior work suggests that one must take actions with maximum lower confidence bound (LCB) on their reward. We argue that reliance on LCB is inherently flawed in this setting and propose a new algorithm that directly minimizes upper-bounds on the Bayesian regret using efficient conic optimization solvers. Our bounds build heavily on new connections to monetary risk measures. Proving a matching lower-bound, we show that our upper-bounds are tight, and by minimizing them we are guaranteed to outperform the LCB approach. Our numerical results on synthetic domains confirm that our approach is superior to maximizing LCB.'}",https://openreview.net{'value': '/pdf/c4551c9c055611548005ec926baf8b13193118e5.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=mslTE1qgLa,{'value': 'Major-Minor Mean Field Multi-Agent Reinforcement Learning'},Kai Cui; Christian Fabian; Anam Tahir; Heinz Koeppl,~Kai_Cui3; ~Christian_Fabian1; ~Anam_Tahir1; ~Heinz_Koeppl1,,"{'value': 'Multi-agent reinforcement learning (MARL) remains difficult to scale to many agents. Recent MARL using Mean Field Control (MFC) provides a tractable and rigorous approach to otherwise difficult cooperative MARL. However, the strict MFC assumption of many independent, weakly-interacting agents is too inflexible in practice. We generalize MFC to instead simultaneously model many similar and few complex agents – as Major-Minor Mean Field Control (M3FC). Theoretically, we give approximation results for finite agent control, and verify the sufficiency of stationary policies for optimality together with a dynamic programming principle. Algorithmically, we propose Major-Minor Mean Field MARL (M3FMARL) for finite agent systems instead of the limiting system. The algorithm is shown to approximate the policy gradient of the underlying M3FC MDP. Finally, we demonstrate its capabilities experimentally in various scenarios. We observe a strong performance in comparison to state-of-the-art policy gradient MARL methods.'}",https://openreview.net{'value': '/pdf/b4a0c6945e1ae1b9da568edccabe15300b9f231a.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=mY93trX2Qz,{'value': 'Low-Rank Similarity Mining for Multimodal Dataset Distillation'},Yue Xu; Zhilin Lin; Yusong Qiu; Cewu Lu; Yong-Lu Li,~Yue_Xu4; ~Zhilin_Lin1; ~Yusong_Qiu1; ~Cewu_Lu3; ~Yong-Lu_Li1,,"{'value': 'Though dataset distillation has witnessed rapid development in recent years, the distillation of multimodal data, e.g., image-text pairs, poses unique and under-explored challenges. Unlike unimodal data, image-text contrastive learning (ITC) data lack inherent categorization and should instead place greater emphasis on modality correspondence. In this work, we propose **Lo**w-**R**ank **S**imilarity Mining (**LoRS**) for multimodal dataset distillation, that concurrently distills a ground truth similarity matrix with image-text pairs, and leverages low-rank factorization for efficiency and scalability. The proposed approach brings significant improvement to the existing algorithms, marking a significant contribution to the field of visual-language dataset distillation. We advocate adopting LoRS as a foundational synthetic data setup for image-text dataset distillation. Our code is available at https://github.com/silicx/LoRS_Distill.'}",https://openreview.net{'value': '/pdf/f963823ac44f58ef342e2334622a36eadb433a78.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=mUT1biz09t,{'value': 'Privacy-Preserving Instructions for Aligning Large Language Models'},Da Yu; Peter Kairouz; Sewoong Oh; Zheng Xu,~Da_Yu1; ~Peter_Kairouz1; ~Sewoong_Oh3; ~Zheng_Xu2,,"{'value': ""Service providers of large language model (LLM) applications collect user instructions in the wild and use them in further aligning LLMs with users' intentions. These instructions, which potentially contain sensitive information, are annotated by human workers in the process. This poses a new privacy risk not addressed by the typical private optimization. To this end, we propose using synthetic instructions to replace real instructions in data annotation and model fine-tuning. Formal differential privacy is guaranteed by generating those synthetic instructions using privately fine-tuned generators. Crucial in achieving the desired utility is our novel filtering algorithm that matches the distribution of the synthetic instructions to that of the real ones. In both supervised fine-tuning and reinforcement learning from human feedback, our extensive experiments demonstrate the high utility of the final set of synthetic instructions by showing comparable results to real instructions. In supervised fine-tuning, models trained with private synthetic instructions outperform leading open-source models such as Vicuna.""}",https://openreview.net{'value': '/pdf/230107aa6712a7ab31b71078ecf724f55a549192.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=mNzkumTSVL,{'value': 'Overcoming Data and Model heterogeneities in Decentralized Federated Learning via Synthetic Anchors'},Chun-Yin Huang; Kartik Srinivas; Xin Zhang; Xiaoxiao Li,~Chun-Yin_Huang1; ~Kartik_Srinivas1; ~Xin_Zhang16; ~Xiaoxiao_Li1,,"{'value': ""Conventional Federated Learning (FL) involves collaborative training of a global model while maintaining user data privacy. One of its branches, decentralized FL, is a serverless network that allows clients to own and optimize different local models separately, which results in saving management and communication resources. Despite the promising advancements in decentralized FL, it may reduce model generalizability due to lacking a global model. In this scenario, managing data and model heterogeneity among clients becomes a crucial problem, which poses a unique challenge that must be overcome: *How can every client's local model learn generalizable representation in a decentralized manner?* To address this challenge, we propose a novel **De**centralized FL technique by introducing **S**ynthetic **A**nchors, dubbed as DeSA. Based on the theory of domain adaptation and Knowledge Distillation (KD), we theoretically and empirically show that synthesizing global anchors based on raw data distribution facilitates mutual knowledge transfer. We further design two effective regularization terms for local training: *1) REG loss* that regularizes the distribution of the client's latent embedding with the anchors and *2) KD loss* that enables clients to learn from others. Through extensive experiments on diverse client data distributions, we showcase the effectiveness of DeSA in enhancing both inter- and intra-domain accuracy of each client. The implementation of DeSA can be found at: https://github.com/ubc-tea/DESA""}",https://openreview.net{'value': '/pdf/f1acd61fbf2249b2014a5fa78bd7500fba19b2ad.pdf'},{'title_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=mJhXlsZzzE,{'value': 'What Improves the Generalization of Graph Transformers? A Theoretical Dive into the Self-attention and Positional Encoding'},Hongkang Li; Meng Wang; Tengfei Ma; Sijia Liu; ZAIXI ZHANG; Pin-Yu Chen,~Hongkang_Li1; ~Meng_Wang4; ~Tengfei_Ma1; ~Sijia_Liu1; ~ZAIXI_ZHANG2; ~Pin-Yu_Chen1,,"{'value': 'Graph Transformers, which incorporate self-attention and positional encoding, have recently emerged as a powerful architecture for various graph learning tasks. Despite their impressive performance, the complex non-convex interactions across layers and the recursive graph structure have made it challenging to establish a theoretical foundation for learning and generalization. This study introduces the first theoretical investigation of a shallow Graph Transformer for semi-supervised node classification, comprising a self-attention layer with relative positional encoding and a two-layer perception. Focusing on a graph data model with discriminative nodes that determine node labels and non-discriminative nodes that are class-irrelevant, we characterize the sample complexity required to achieve a desirable generalization error by training with stochastic gradient descent (SGD). This paper provides the quantitative characterization of the sample complexity and number of iterations for convergence dependent on the fraction of discriminative nodes, the dominant patterns, and the initial model errors. Furthermore, we demonstrate that self-attention and positional encoding enhance generalization by making the attention map sparse and promoting the core neighborhood during training, which explains the superior feature representation of Graph Transformers. Our theoretical results are supported by empirical experiments on synthetic and real-world benchmarks.'}",https://openreview.net{'value': '/pdf/a8d6e4e455b611c173e6dd7bcb1b113b4c57d169.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=mGsF8Q0fGZ,{'value': 'On Hypothesis Transfer Learning of Functional Linear Models'},Haotian Lin; Matthew Reimherr,~Haotian_Lin1; ~Matthew_Reimherr1,,"{'value': 'We study the transfer learning (TL) for the functional linear regression (FLR) under the Reproducing Kernel Hilbert Space (RKHS) framework, observing the TL techniques in existing high-dimensional linear regression is not compatible with the truncation-based FLR methods as functional data are intrinsically infinite-dimensional and generated by smooth underlying processes. We measure the similarity across tasks using RKHS distance, allowing the type of information being transferred to be tied to the properties of the imposed RKHS. Building on the hypothesis offset transfer learning paradigm, two algorithms are proposed: one conducts the transfer when positive sources are known, while the other leverages aggregation techniques to achieve robust transfer without prior information about the sources. We establish asymptotic lower bounds for this learning problem and show the proposed algorithms enjoy a matching upper bound. These analyses provide statistical insights into factors that contribute to the dynamics of the transfer. We also extend the results to functional generalized linear models. The effectiveness of the proposed algorithms is demonstrated via extensive synthetic data as well as real-world data applications.'}",https://openreview.net{'value': '/pdf/fc64f792b5ed2d934b42479f269dc9fda21e54a2.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=mDw42ZanmE,{'value': 'A Multimodal Automated Interpretability Agent'},Tamar Rott Shaham; Sarah Schwettmann; Franklin Wang; Achyuta Rajaram; Evan Hernandez; Jacob Andreas; Antonio Torralba,~Tamar_Rott_Shaham1; ~Sarah_Schwettmann2; ~Franklin_Wang2; ~Achyuta_Rajaram1; ~Evan_Hernandez1; ~Jacob_Andreas1; ~Antonio_Torralba1,,"{'value': 'This paper describes MAIA, a Multimodal Automated Interpretability Agent. MAIA is a system that uses neural models to automate neural model understanding tasks like feature interpretation and failure mode discovery. It equips a pre-trained vision-language model with a set of tools that support iterative experimentation on subcomponents of other models to explain their behavior. These include tools commonly used by human interpretability researchers: for synthesizing and editing inputs, computing maximally activating exemplars from real-world datasets, and summarizing and describing experimental results. Interpretability experiments proposed by MAIA compose these tools to describe and explain system behavior. We evaluate applications of MAIA to computer vision models. We first characterize MAIA’s ability to describe (neuron-level) features in learned representations of images. Across several trained models and a novel dataset of synthetic vision neurons with paired ground-truth descriptions, MAIA produces descriptions comparable to those generated by expert human experimenters. We then show that MAIA can aid in two additional interpretability tasks: reducing sensitivity to spurious features, and automatically identifying inputs likely to be mis-classified.'}",https://openreview.net{'value': '/pdf/55846273c2c2431ffda58180c068483ccb4f99c8.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=mBc8Pestd5,{'value': 'Reinformer: Max-Return Sequence Modeling for Offline RL'},Zifeng Zhuang; Dengyun Peng; Jinxin Liu; Ziqi Zhang; Donglin Wang,~Zifeng_Zhuang1; ~Dengyun_Peng1; ~Jinxin_Liu1; ~Ziqi_Zhang7; ~Donglin_Wang1,,"{'value': 'As a data-driven paradigm, offline reinforcement learning (RL) has been formulated as sequence modeling that conditions on the hindsight information including returns, goal or future trajectory. Although promising, this supervised paradigm overlooks the core objective of RL that maximizes the return. This overlook directly leads to the lack of trajectory stitching capability that affects the sequence model learning from sub-optimal data. In this work, we introduce the concept of max-return sequence modeling which integrates the goal of maximizing returns into existing sequence models. We propose **Rein*for***ced Trans***for*mer** (**Rein*for*mer**), indicating the sequence model is reinforced by the RL objective. **Rein*for*mer** additionally incorporates the objective of maximizing returns in the training phase, aiming to predict the maximum future return within the distribution. During inference, this in-distribution maximum return will guide the selection of optimal actions. Empirically, **Rein*for*mer** is competitive with classical RL methods on the D4RL benchmark and outperforms state-of-the-art sequence model particularly in trajectory stitching ability. Code is public at https://github.com/Dragon-Zhuang/Reinformer.'}",https://openreview.net{'value': '/pdf/f9256ed6bd244f8cdf691c7d41dcfd3dbda4d8e9.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2024,Conference
https://openreview.net/forum?id=lrFwPeDdEQ,{'value': 'Federated Combinatorial Multi-Agent Multi-Armed Bandits'},Fares Fourati; Mohamed-Slim Alouini; Vaneet Aggarwal,~Fares_Fourati1; ~Mohamed-Slim_Alouini1; ~Vaneet_Aggarwal1,,"{'value': 'This paper introduces a federated learning framework tailored for online combinatorial optimization with bandit feedback. In this setting, agents select subsets of arms, observe noisy rewards for these subsets without accessing individual arm information, and can cooperate and share information at specific intervals. Our framework transforms any offline resilient single-agent $(\\alpha-\\epsilon)$-approximation algorithm—having a complexity of $\\tilde{\\mathcal{O}}\\left(\\frac{\\psi}{\\epsilon^\\beta}\\right)$, where the logarithm is omitted, for some function $\\psi$ and constant $\\beta$—into an online multi-agent algorithm with $m$ communicating agents and an $\\alpha$-regret of no more than $\\tilde{\\mathcal{O}}\\left(m^{-\\frac{1}{3+\\beta}} \\psi^\\frac{1}{3+\\beta} T^\\frac{2+\\beta}{3+\\beta}\\right)$. Our approach not only eliminates the $\\epsilon$ approximation error but also ensures sublinear growth with respect to the time horizon $T$ and demonstrates a linear speedup with an increasing number of communicating agents. Additionally, the algorithm is notably communication-efficient, requiring only a sublinear number of communication rounds, quantified as $\\tilde{\\mathcal{O}}\\left(\\psi T^\\frac{\\beta}{\\beta+1}\\right)$. Furthermore, the framework has been successfully applied to online stochastic submodular maximization using various offline algorithms, yielding the first results for both single-agent and multi-agent settings and recovering specialized single-agent theoretical guarantees. We empirically validate our approach to a stochastic data summarization problem, illustrating the effectiveness of the proposed framework, even in single-agent scenarios.'}",https://openreview.net{'value': '/pdf/413fbae1dbb59cd5de0a52db5072f30bf7dab4cc.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=lm04PyXoEl,{'value': 'Detecting Influence Structures in Multi-Agent Reinforcement Learning'},Fabian Raoul Pieroth; Katherine Fitch; Lenz Belzner,~Fabian_Raoul_Pieroth1; ~Katherine_Fitch1; ~Lenz_Belzner1,,"{'value': ""We consider the problem of quantifying the amount of influence one agent can exert on another in the setting of multi-agent reinforcement learning (MARL). As a step towards a unified approach to express agents' interdependencies, we introduce the total and state influence measurement functions. Both of these are valid for all common MARL systems, such as the discounted reward setting. Additionally, we propose novel quantities, called the total impact measurement (TIM) and state impact measurement (SIM), that characterize one agent's influence on another by the maximum impact it can have on the other agents' expected returns and represent instances of impact measurement functions in the average reward setting. Furthermore, we provide approximation algorithms for TIM and SIM with simultaneously learning approximations of agents' expected returns, error bounds, stability analyses under changes of the policies, and convergence guarantees. The approximation algorithm relies only on observing other agents' actions and is, other than that, fully decentralized. Through empirical studies, we validate our approach's effectiveness in identifying intricate influence structures in complex interactions. Our work appears to be the first study of determining influence structures in the multi-agent average reward setting with convergence guarantees.""}",https://openreview.net{'value': '/pdf/d262dee94a66b75568a786bed0ba576d7a89ed4a.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=lWy2lCTyJa,{'value': 'Revisiting Inexact Fixed-Point Iterations for Min-Max Problems: Stochasticity and Structured Nonconvexity'},Ahmet Alacaoglu; Donghwan Kim; Stephen Wright,~Ahmet_Alacaoglu2; ~Donghwan_Kim2; ~Stephen_Wright1,,"{'value': ""We focus on constrained, $L$-smooth, potentially stochastic and nonconvex-nonconcave min-max problems either satisfying $\\rho$-cohypomonotonicity or admitting a solution to the $\\rho$-weakly Minty Variational Inequality (MVI), where larger values of the parameter $\\rho>0$ correspond to a greater degree of nonconvexity. These problem classes include examples in two player reinforcement learning, interaction dominant min-max problems, and certain synthetic test problems on which classical min-max algorithms fail. It has been conjectured that first-order methods can tolerate a value of $\\rho$ no larger than $\\frac{1}{L}$, but existing results in the literature have stagnated at the tighter requirement $\\rho < \\frac{1}{2L}$. With a simple argument, we obtain optimal or best-known complexity guarantees with cohypomonotonicity or weak MVI conditions for $\\rho < \\frac{1}{L}$. First main insight for the improvements in the convergence analyses is to harness the recently proposed *conic nonexpansiveness* property of operators. Second, we provide a refined analysis for inexact Halpern iteration that relaxes the required inexactness level to improve some state-of-the-art complexity results even for constrained stochastic convex-concave min-max problems. Third, we analyze a stochastic inexact Krasnosel'skii-Mann iteration with a multilevel Monte Carlo estimator when the assumptions only hold with respect to a solution.""}",https://openreview.net{'value': '/pdf/fbd74bba6cac2b84ec4bbb4e5057d4e06faf6925.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=lVQ4FUZ6dp,{'value': 'Generalization to New Sequential Decision Making Tasks with In-Context Learning'},Sharath Chandra Raparthy; Eric Hambro; Robert Kirk; Mikael Henaff; Roberta Raileanu,~Sharath_Chandra_Raparthy3; ~Eric_Hambro1; ~Robert_Kirk1; ~Mikael_Henaff1; ~Roberta_Raileanu2,,"{'value': ""Training autonomous agents that can learn new tasks from only a handful of demonstrations is a long-standing problem in machine learning. Recently, transformers have been shown to learn new language or vision tasks without any weight updates from only a few examples, also referred to as in-context learning. However, the sequential decision making setting poses additional challenges having a lower tolerance for errors since the environment's stochasticity or the agent's actions can lead to unseen, and sometimes unrecoverable, states. In this paper, we use an illustrative example to show that naively applying transformers to sequential decision making problems does not enable in-context learning of new tasks. We then demonstrate how training on sequences of trajectories with certain distributional properties leads to in-context learning of new sequential decision making tasks. We investigate different design choices and find that larger model and dataset sizes, as well as more task diversity, environment stochasticity, and trajectory burstiness, all result in better in-context learning of new out-of-distribution tasks. By training on large diverse offline datasets, our model is able to learn new MiniHack and Procgen tasks without any weight updates from just a handful of demonstrations.""}",https://openreview.net{'value': '/pdf/b2ff38c3782fe3b7bfc720950bc4b61969be132d.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2024,Conference
https://openreview.net/forum?id=l9ga3iQuHt,{'value': 'Feel-Good Thompson Sampling for Contextual Dueling Bandits'},Xuheng Li; Heyang Zhao; Quanquan Gu,~Xuheng_Li1; ~Heyang_Zhao1; ~Quanquan_Gu1,,"{'value': 'Contextual dueling bandits, where a learner compares two options based on context and receives feedback indicating which was preferred, extends classic dueling bandits by incorporating contextual information for decision-making and preference learning. Several algorithms based on the upper confidence bound (UCB) have been proposed for linear contextual dueling bandits. However, no algorithm based on posterior sampling has been developed in this setting, despite the empirical success observed in traditional contextual bandits. In this paper, we propose a Thompson sampling algorithm, named FGTS.CDB, for linear contextual dueling bandits. At the core of our algorithm is a new Feel-Good exploration term specifically tailored for dueling bandits. This term leverages the independence of the two selected arms, thereby avoiding a cross term in the analysis. We show that our algorithm achieves nearly minimax-optimal regret, i.e., $\\tilde{\\mathcal{O}}(d\\sqrt T)$, where $d$ is the model dimension and $T$ is the time horizon. Finally, we evaluate our algorithm on synthetic data and observe that FGTS.CDB outperforms existing algorithms by a large margin.'}",https://openreview.net{'value': '/pdf/a1794ef0279fa455eda45afd966efc06575144fa.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=l5XQzNkAOe,{'value': 'TravelPlanner: A Benchmark for Real-World Planning with Language Agents'},Jian Xie; Kai Zhang; Jiangjie Chen; Tinghui Zhu; Renze Lou; Yuandong Tian; Yanghua Xiao; Yu Su,~Jian_Xie3; ~Kai_Zhang10; ~Jiangjie_Chen1; ~Tinghui_Zhu1; ~Renze_Lou1; ~Yuandong_Tian1; ~Yanghua_Xiao1; ~Yu_Su2,,"{'value': 'Planning has been part of the core pursuit for artificial intelligence since its conception, but earlier AI agents mostly focused on constrained settings because many of the cognitive substrates necessary for human-level planning have been lacking. Recently, language agents powered by large language models (LLMs) have shown interesting capabilities such as tool use and reasoning. Are these language agents capable of planning in more complex settings that are out of the reach of prior AI agents? To advance this investigation, we propose TravelPlanner, a new planning benchmark that focuses on travel planning, a common real-world planning scenario. It provides a rich sandbox environment, various tools for accessing nearly four million data records, and 1,225 meticulously curated planning intents and reference plans. Comprehensive evaluations show that the current language agents are not yet capable of handling such complex planning tasks—even GPT-4 only achieves a success rate of 0.6%. Language agents struggle to stay on task, use the right tools to collect information, or keep track of multiple constraints. However, we note that the mere possibility for language agents to tackle such a complex problem is in itself non-trivial progress. TravelPlanner provides a challenging yet meaningful testbed for future language agents.'}",https://openreview.net{'value': '/pdf/e9fe4b4f56f555d4eb81bfd90c1b9a501e7a57dd.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=l1YbS3qkdk,{'value': 'Causal Discovery via Conditional Independence Testing with Proxy Variables'},Mingzhou Liu; Xinwei Sun; Yu QIAO; Yizhou Wang,~Mingzhou_Liu1; ~Xinwei_Sun1; ~Yu_QIAO3; ~Yizhou_Wang1,,"{'value': 'Distinguishing causal connections from correlations is important in many scenarios. However, the presence of unobserved variables, such as the latent confounder, can introduce bias in conditional independence testing commonly employed in constraint-based causal discovery for identifying causal relations. To address this issue, existing methods introduced proxy variables to adjust for the bias caused by unobserveness. However, these methods were either limited to categorical variables or relied on strong parametric assumptions for identification. In this paper, we propose a novel hypothesis-testing procedure that can effectively examine the existence of the causal relationship over continuous variables, without any parametric constraint. Our procedure is based on discretization, which under completeness conditions, is able to asymptotically establish a linear equation whose coefficient vector is identifiable under the causal null hypothesis. Based on this, we introduce our test statistic and demonstrate its asymptotic level and power. We validate the effectiveness of our procedure using both synthetic and real-world data.'}",https://openreview.net{'value': '/pdf/7c6f3337842e886d79906439cc4a7b1501892970.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=kXHgEYFyf3,{'value': 'R2E: Turning any Github Repository into a Programming Agent Environment'},Naman Jain; Manish Shetty; Tianjun Zhang; King Han; Koushik Sen; Ion Stoica,~Naman_Jain2; ~Manish_Shetty1; ~Tianjun_Zhang1; kingh0730@berkeley.edu; ~Koushik_Sen2; ~Ion_Stoica1,,"{'value': 'While Large Language Models’ (LLMs) coding capabilities have advanced rapidly, corresponding evaluation benchmarks on real-world programming setups are yet to catch up. Building a scalable and interactive testbed for evaluating general-purpose AI coding agents for real-world code has been challenging, particularly due to a lack of high-quality test suites available. In this paper, we present Repository to Environment (R2E), a framework that can turn any GitHub repository into a test environment to evaluate the performance of code-generating systems, both static and interactive. R2E is powered by a synergistic combination of program analysis and LLMs to construct equivalence test harnesses for any GitHub function. We instantiate our framework to build the first large-scale benchmark, R2E-Eval1, for building realistic environments for AI coding assistants. Our results demonstrate that even when SOTA models cannot generate correct solutions with advanced prompting techniques, they can effectively use environment feedback highlighting the need to move from static functional coding to interactive programming paradigm. We hope that our framework (and the instantiated benchmark) can motivate research directions by providing web-scale open-ended coding environments. R2E code is available at https://r2e.dev/'}",https://openreview.net{'value': '/pdf/f25e213904933dd18b19a94d94f6e7bf513a1c6a.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=kUj9b2CezT,{'value': 'A Generative Approach for Treatment Effect Estimation under Collider Bias: From an Out-of-Distribution Perspective'},Baohong Li; Haoxuan Li; Anpeng Wu; Minqin Zhu; shiyuan Peng; Qingyu Cao; Kun Kuang,~Baohong_Li1; ~Haoxuan_Li6; ~Anpeng_Wu1; ~Minqin_Zhu1; ~shiyuan_Peng1; ~Qingyu_Cao1; ~Kun_Kuang1,,"{'value': 'Resulting from non-random sample selection caused by both the treatment and outcome, collider bias poses a unique challenge to treatment effect estimation using observational data whose distribution differs from that of the target population. In this paper, we rethink collider bias from an out-of-distribution (OOD) perspective, considering that the entire data space of the target population consists of two different environments: The observational data selected from the target population belongs to a seen environment labeled with $S=1$ and the missing unselected data belongs to another unseen environment labeled with $S=0$. Based on this OOD formulation, we utilize small-scale representative data from the entire data space with no environmental labels and propose a novel method, i.e., Coupled Counterfactual Generative Adversarial Model (C$^2$GAM), to simultaneously generate the missing $S=0$ samples in observational data and the missing $S$ labels in the small-scale representative data. With the help of C$^2$GAM, collider bias can be addressed by combining the generated $S=0$ samples and the observational data to estimate treatment effects. Extensive experiments on synthetic and real-world data demonstrate that plugging C$^2$GAM into existing treatment effect estimators achieves significant performance improvements.'}",https://openreview.net{'value': '/pdf/8275c9d5329dae1688108a7103fd4a7e8d610343.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=kKWjZoaRLv,{'value': 'Learning Latent Structures in Network Games via Data-Dependent Gated-Prior Graph Variational Autoencoders'},Xue Yu; Muchen Li; Yan Leng; Renjie Liao,~Xue_Yu2; ~Muchen_Li1; ~Yan_Leng1; ~Renjie_Liao1,,"{'value': 'In network games, individuals interact strategically within network environments to maximize their utilities. However, obtaining network structures is challenging. In this work, we propose an unsupervised learning model, called data-dependent gated-prior graph variational autoencoder (GPGVAE), that infers the underlying latent interaction type (strategic complement vs. substitute) among individuals and the latent network structure based on their observed actions. Specially, we propose a spectral graph neural network (GNN) based encoder to predict the interaction type and a data-dependent gated prior that models network structures conditioned on the interaction type. We further propose a Transformer based mixture of Bernoulli encoder of network structures and a GNN based decoder of game actions. We systematically study the Monte Carlo gradient estimation methods and effectively train our model in a stage-wise fashion. Extensive experiments across various synthetic and real-world network games demonstrate that our model achieves state-of-the-art performances in inferring network structures and well captures interaction types.'}",https://openreview.net{'value': '/pdf/19f55ea211446b319e7472e14bac0b5682666284.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=kIh7GJmRfD,{'value': 'ATraDiff: Accelerating Online Reinforcement Learning with Imaginary Trajectories'},Qianlan Yang; Yu-Xiong Wang,~Qianlan_Yang1; ~Yu-Xiong_Wang1,,"{'value': 'Training autonomous agents with sparse rewards is a long-standing problem in online reinforcement learning (RL), due to low data efficiency. Prior work overcomes this challenge by extracting useful knowledge from offline data, often accomplished through the learning of action distribution from offline data and utilizing the learned distribution to facilitate online RL. However, since the offline data are given and fixed, the extracted knowledge is inherently limited, making it difficult to generalize to new tasks. We propose a novel approach that leverages offline data to learn a generative diffusion model, coined as Adaptive Trajectory Diffuser (ATraDiff). This model generates synthetic trajectories, serving as a form of data augmentation and consequently enhancing the performance of online RL methods. The key strength of our diffuser lies in its adaptability, allowing it to effectively handle varying trajectory lengths and mitigate distribution shifts between online and offline data. Because of its simplicity, ATraDiff seamlessly integrates with a wide spectrum of RL methods. Empirical evaluation shows that ATraDiff consistently achieves state-of-the-art performance across a variety of environments, with particularly pronounced improvements in complicated settings. Our code and demo video are available at https://atradiff.github.io.'}",https://openreview.net{'value': '/pdf/4e43b8a7cd7fc5e0e8936bc770687d8a3a8e4df9.pdf'},{'title_filter': 'Trajectory'},ICML.cc,2024,Conference
https://openreview.net/forum?id=k2dVVIWWho,{'value': 'Differentially Private Decentralized Learning with Random Walks'},Edwige Cyffers; Aurélien Bellet; Jalaj Upadhyay,~Edwige_Cyffers1; ~Aurélien_Bellet1; ~Jalaj_Upadhyay1,,"{'value': 'The popularity of federated learning comes from the possibility of better scalability and the ability for participants to keep control of their data, improving data security and sovereignty. Unfortunately, sharing model updates also creates a new privacy attack surface. In this work, we characterize the privacy guarantees of decentralized learning with random walk algorithms, where a model is updated by traveling from one node to another along the edges of a communication graph. Using a recent variant of differential privacy tailored to the study of decentralized algorithms, namely Pairwise Network Differential Privacy, we derive closed-form expressions for the privacy loss between each pair of nodes where the impact of the communication topology is captured by graph theoretic quantities. Our results further reveal that random walk algorithms tends to yield better privacy guarantees than gossip algorithms for nodes close from each other. We supplement our theoretical results with empirical evaluation on synthetic and real-world graphs and datasets.'}",https://openreview.net{'value': '/pdf/9458ba6d072dc64e0045728db7d06bd3d2001d38.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=jzHmElqpPe,{'value': 'Position: Foundation Agents as the Paradigm Shift for Decision Making'},Xiaoqian Liu; Xingzhou Lou; Jianbin Jiao; Junge Zhang,~Xiaoqian_Liu1; ~Xingzhou_Lou1; ~Jianbin_Jiao1; ~Junge_Zhang1,,"{'value': 'Decision making demands intricate interplay between perception, memory, and reasoning to discern optimal policies. Conventional approaches to decision making face challenges related to low sample efficiency and poor generalization. In contrast, foundation models in language and vision have showcased rapid adaptation to diverse new tasks. Therefore, we advocate for the construction of foundation agents as a transformative shift in the learning paradigm of agents. This proposal is underpinned by the formulation of foundation agents with their fundamental characteristics and challenges motivated by the success of large language models (LLMs). Moreover, we specify the roadmap of foundation agents from large interactive data collection or generation, to self-supervised pretraining and adaptation, and knowledge and value alignment with LLMs. Lastly, we pinpoint critical research questions derived from the formulation and delineate trends for foundation agents supported by real-world use cases, addressing both technical and theoretical aspects to propel the field towards a more comprehensive and impactful future.'}",https://openreview.net{'value': '/pdf/2b3ab2672ab57d9d750d82c29a5a74d006e1c76d.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=jw2f9v59g0,{'value': 'Data-free Distillation of Diffusion Models with Bootstrapping'},Jiatao Gu; Chen Wang; Shuangfei Zhai; Yizhe Zhang; Lingjie Liu; Joshua M. Susskind,~Jiatao_Gu1; ~Chen_Wang13; ~Shuangfei_Zhai3; ~Yizhe_Zhang2; ~Lingjie_Liu1; ~Joshua_M._Susskind1,,"{'value': 'Diffusion models have demonstrated great potential for generating diverse images. However, their performance often suffers from slow generation due to iterative denoising. Knowledge distillation has been recently proposed as a remedy which can reduce the number of inference steps to one or a few, without significant quality degradation. However, existing distillation methods either require significant amounts of offline computation for generating synthetic training data from the teacher model, or need to perform expensive online learning with the help of real data. In this work, we present a novel technique called BOOT, that overcomes these limitations with an efficient data-free distillation algorithm. The core idea is to learn a time-conditioned model that predicts the output of a pre-trained diffusion model teacher given any time-step. Such a model can be efficiently trained based on bootstrapping from two consecutive sampled steps. Furthermore, our method can be easily adapted to large-scale text-to-image diffusion models, which are challenging for previous methods given the fact that the training sets are often large and difficult to access. We demonstrate the effectiveness of our approach on several benchmark datasets in the DDIM setting, achieving comparable generation quality while being orders of magnitude faster than the diffusion teacher. The text-to-image results show that the proposed approach is able to handle highly complex distributions, shedding light on more efficient generative modeling.'}",https://openreview.net{'value': '/pdf/91ce5baf1cb9a852eaf8a1706470b91358790b4a.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=jnps5YwNlU,{'value': 'Efficient Precision and Recall Metrics for Assessing Generative Models using Hubness-aware Sampling'},Yuanbang Liang; Jing Wu; Yu-Kun Lai; Yipeng Qin,~Yuanbang_Liang1; ~Jing_Wu3; ~Yu-Kun_Lai1; ~Yipeng_Qin1,,"{'value': 'Despite impressive results, deep generative models require massive datasets for training, and as dataset size increases, effective evaluation metrics like precision and recall (P&R) become computationally infeasible on commodity hardware. In this paper, we address this challenge by proposing efficient P&R (eP&R) metrics that give almost identical results as the original P&R but with much lower computational costs. Specifically, we identify two redundancies in the original P&R: i) redundancy in ratio computation and ii) redundancy in manifold inside/outside identification. We find both can be effectively removed via hubness-aware sampling, which extracts representative elements from synthetic/real image samples based on their hubness values, i.e., the number of times a sample becomes a k-nearest neighbor to others in the feature space. Thanks to the insensitivity of hubness-aware sampling to exact k-nearest neighbor (k-NN) results, we further improve the efficiency of our eP&R metrics by using approximate k-NN methods. Extensive experiments show that our eP&R matches the original P&R but is far more efficient in time and space. Our code is available at: https://github.com/Byronliang8/Hubness_Precision_Recall'}",https://openreview.net{'value': '/pdf/d8ce439134690e4e1facc75c1866dbeafda52212.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=jn2iTJas6h,{'value': 'A decoder-only foundation model for time-series forecasting'},Abhimanyu Das; Weihao Kong; Rajat Sen; Yichen Zhou,~Abhimanyu_Das2; ~Weihao_Kong1; ~Rajat_Sen1; ~Yichen_Zhou3,,"{'value': 'Motivated by recent advances in large language models for Natural Language Processing (NLP), we design a time-series foundation model for forecasting whose out-of-the-box zero-shot performance on a variety of public datasets comes close to the accuracy of state-of-the-art supervised forecasting models for each individual dataset. Our model is based on pretraining a decoder style attention model with input patching, using a large time-series corpus comprising both real-world and synthetic datasets. Experiments on a diverse set of previously unseen forecasting datasets suggests that the model can yield accurate zero-shot forecasts across different domains, forecasting horizons and temporal granularities.'}",https://openreview.net{'value': '/pdf/3f1cd31c9960cda3f8a2c9f8ead1337fed4692b3.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=jJ9BoXAfFa,{'value': 'Executable Code Actions Elicit Better LLM Agents'},Xingyao Wang; Yangyi Chen; Lifan Yuan; Yizhe Zhang; Yunzhu Li; Hao Peng; Heng Ji,~Xingyao_Wang1; ~Yangyi_Chen1; ~Lifan_Yuan1; ~Yizhe_Zhang2; ~Yunzhu_Li1; ~Hao_Peng4; ~Heng_Ji3,,"{'value': ""Large Language Model (LLM) agents, capable of performing a broad range of actions, such as invoking tools and controlling robots, show great potential in tackling real-world challenges. LLM agents are typically prompted to produce actions by generating JSON or text in a pre-defined format, which is usually limited by constrained action space (e.g., the scope of pre-defined tools) and restricted flexibility (e.g., inability to compose multiple tools). This work proposes to use executable Python **code** to consolidate LLM agents' **act**ions into a unified action space (**CodeAct**). Integrated with a Python interpreter, CodeAct can execute code actions and dynamically revise prior actions or emit new actions upon new observations through multi-turn interactions. Our extensive analysis of 17 LLMs on API-Bank and a newly curated benchmark shows that CodeAct outperforms widely used alternatives (up to 20% higher success rate). The encouraging performance of CodeAct motivates us to build an open-source LLM agent that interacts with environments by executing interpretable code and collaborates with users using natural language. To this end, we collect an instruction-tuning dataset CodeActInstruct that consists of 7k multi-turn interactions using CodeAct. We show that it can be used with existing data to improve models in agent-oriented tasks without compromising their general capability. CodeActAgent, finetuned from Llama2 and Mistral, is integrated with Python interpreter and uniquely tailored to perform sophisticated tasks (e.g., model training) using existing libraries and autonomously self-debug.""}",https://openreview.net{'value': '/pdf/77201ef17d3ec7f9b7079d50149857895613a953.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=j4HtfTqr0f,{'value': 'MILP-FBGen: LP/MILP Instance Generation with Feasibility/Boundedness'},Yahong Zhang; Chenchen Fan; Donghui Chen; Congrui Li; Wenli Ouyang; Mingda Zhu; Junchi Yan,~Yahong_Zhang2; ~Chenchen_Fan1; ~Donghui_Chen2; ~Congrui_Li1; ~Wenli_Ouyang1; ~Mingda_Zhu1; ~Junchi_Yan2,,"{'value': 'Machine learning (ML) has been actively adopted in Linear Programming (LP) and Mixed-Integer Linear Programming (MILP), whose potential is hindered by instance scarcity. Current synthetic instance generation methods often fall short in closely mirroring the distribution of original datasets or ensuring the feasibility and boundedness of the generated data — a critical requirement for obtaining reliable supervised labels in model training. In this paper, we present a diffusion-based LP/MILP instance generative framework called MILP-FBGen. It strikes a balance between structural similarity and novelty while maintaining feasibility/boundedness via a meticulously designed structure-preserving generation module and a feasibility/boundedness-constrained sampling module. Our method shows superiority on two fronts: 1) preservation of key properties (hardness, feasibility, and boundedness) of LP/MILP instances, and 2) enhanced performance on downstream tasks. Extensive studies show two-fold superiority that our method ensures higher distributional similarity and 100% feasibility in both easy and hard datasets, surpassing current state-of-the-art techniques.'}",https://openreview.net{'value': '/pdf/141cbfacf7f503d546ad4bd63d9d056806a6e639.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=igRAPavrrS,{'value': 'Private Gradient Descent for Linear Regression: Tighter Error Bounds and Instance-Specific Uncertainty Estimation'},Gavin R Brown; Krishnamurthy Dj Dvijotham; Georgina Evans; Daogao Liu; Adam Smith; Abhradeep Guha Thakurta,~Gavin_R_Brown1; ~Krishnamurthy_Dj_Dvijotham1; ~Georgina_Evans1; ~Daogao_Liu1; ~Adam_Smith1; ~Abhradeep_Guha_Thakurta1,,"{'value': ""We provide an improved analysis of standard differentially private gradient descent for linear regression under the squared error loss. Under modest assumptions on the input, we characterize the distribution of the iterate at each time step. Our analysis leads to new results on the algorithm's accuracy: for a proper fixed choice of hyperparameters, the sample complexity depends only linearly on the dimension of the data. This matches the dimension-dependence of the (non-private) ordinary least squares estimator as well as that of recent private algorithms that rely on sophisticated adaptive gradient-clipping schemes (Varshney et al., 2022; Liu et al., 2023). Our analysis of the iterates' distribution also allows us to construct confidence intervals for the empirical optimizer which adapt automatically to the variance of the algorithm on a particular data set. We validate our theorems through experiments on synthetic data.""}",https://openreview.net{'value': '/pdf/8f7a658b1ffa3c0978047a28dacb450d7a6e86c7.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=idyUNsoZ75,{'value': 'Evaluating Model Bias Requires Characterizing its Mistakes'},Isabela Albuquerque; Jessica Schrouff; David Warde-Farley; Ali Taylan Cemgil; Sven Gowal; Olivia Wiles,~Isabela_Albuquerque1; ~Jessica_Schrouff1; ~David_Warde-Farley1; ~Ali_Taylan_Cemgil2; ~Sven_Gowal2; ~Olivia_Wiles1,,"{'value': ""The ability to properly benchmark model performance in the face of spurious correlations is important to both build better predictors and increase confidence that models are operating as intended. We demonstrate that characterizing (as opposed to simply quantifying) model mistakes across subgroups is pivotal to properly reflect model biases, which are ignored by standard metrics such as worst-group accuracy or accuracy gap. Inspired by the hypothesis testing framework, we introduce SkewSize, a principled and flexible metric that captures bias from mistakes in a model's predictions. It can be used in multi-class settings or generalised to the open vocabulary setting of generative models. SkewSize is an aggregation of the effect size of the interaction between two categorical variables: the spurious variable representing the bias attribute the model's prediction. We demonstrate the utility of SkewSize in multiple settings including: standard vision models trained on synthetic data, vision models trained on ImageNet, and large scale vision-and-language models from the BLIP-2 family. In each case, the proposed SkewSize is able to highlight biases not captured by other metrics, while also providing insights on the impact of recently proposed techniques, such as instruction tuning.""}",https://openreview.net{'value': '/pdf/23a8eb66f7a1180920204621fc50ca54fd3e5d02.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=iYYA5zDoCm,{'value': 'Locally Interdependent Multi-Agent MDP: Theoretical Framework for Decentralized Agents with Dynamic Dependencies'},Alex DeWeese; Guannan Qu,~Alex_DeWeese2; ~Guannan_Qu1,,"{'value': ""Many multi-agent systems in practice are decentralized and have dynamically varying dependencies. There has been a lack of attempts in the literature to analyze these systems theoretically. In this paper, we propose and theoretically analyze a decentralized model with dynamically varying dependencies called the Locally Interdependent Multi-Agent MDP. This model can represent problems in many disparate domains such as cooperative navigation, obstacle avoidance, and formation control. Despite the intractability that general partially observable multi-agent systems suffer from, we propose three closed-form policies that are theoretically near-optimal in this setting and can be scalable to compute and store. Consequentially, we reveal a fundamental property of Locally Interdependent Multi-Agent MDP's that the partially observable decentralized solution is exponentially close to the fully observable solution with respect to the visibility radius. We then discuss extensions of our closed-form policies to further improve tractability. We conclude by providing simulations to investigate some long horizon behaviors of our closed-form policies.""}",https://openreview.net{'value': '/pdf/2ca698fae033b701eab86103feedd12986df07a0.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=i0nVanexij,{'value': 'Self-Correcting Self-Consuming Loops for Generative Model Training'},Nate Gillman; Michael Freeman; Daksh Aggarwal; Chia-Hong HSU; Calvin Luo; Yonglong Tian; Chen Sun,~Nate_Gillman1; michael_freeman@alumni.brown.edu; ~Daksh_Aggarwal1; ~Chia-Hong_HSU1; ~Calvin_Luo2; ~Yonglong_Tian1; ~Chen_Sun1,,"{'value': ""As synthetic data becomes higher quality and proliferates on the internet, machine learning models are increasingly trained on a mix of human- and machine-generated data. Despite the successful stories of using synthetic data for representation learning, using synthetic data for generative model training creates ``self-consuming loops'' which may lead to training instability or even collapse, unless certain conditions are met. Our paper aims to stabilize self-consuming generative model training. Our theoretical results demonstrate that by introducing an idealized correction function, which maps a data point to be more likely under the true data distribution, self-consuming loops can be made *exponentially* more stable. We then propose self-correction functions, which rely on expert knowledge (e.g. the laws of physics programmed in a simulator), and aim to approximate the idealized corrector automatically and at scale. We empirically validate the effectiveness of self-correcting self-consuming loops on the challenging human motion synthesis task, and observe that it successfully avoids model collapse, even when the ratio of synthetic data to real data is as high as 100%.""}",https://openreview.net{'value': '/pdf/1c7a965d64c9ec6e0e3e5e273526db7e18151abb.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=hz8cFsdz7P,{'value': 'LLM and Simulation as Bilevel Optimizers: A New Paradigm to Advance Physical Scientific Discovery'},Pingchuan Ma; Tsun-Hsuan Wang; Minghao Guo; Zhiqing Sun; Joshua B. Tenenbaum; Daniela Rus; Chuang Gan; Wojciech Matusik,~Pingchuan_Ma3; ~Tsun-Hsuan_Wang2; ~Minghao_Guo1; ~Zhiqing_Sun1; ~Joshua_B._Tenenbaum1; ~Daniela_Rus1; ~Chuang_Gan1; ~Wojciech_Matusik2,,"{'value': ""Large Language Models have recently gained significant attention in scientific discovery for their extensive knowledge and advanced reasoning capabilities. However, they encounter challenges in effectively simulating observational feedback and grounding it with language to propel advancements in physical scientific discovery. Conversely, human scientists undertake scientific discovery by formulating hypotheses, conducting experiments, and revising theories through observational analysis. Inspired by this, we propose to enhance the knowledge-driven, abstract reasoning abilities of LLMs with the computational strength of simulations. We introduce Scientific Generative Agent (SGA), a bilevel optimization framework: LLMs act as knowledgeable and versatile thinkers, proposing scientific hypotheses and reason about discrete components, such as physics equations or molecule structures; meanwhile, simulations function as experimental platforms, providing observational feedback and optimizing via differentiability for continuous parts, such as physical parameters. We conduct extensive experiments to demonstrate our framework's efficacy in constitutive law discovery and molecular design, unveiling novel solutions that differ from conventional human expectations yet remain coherent upon analysis.""}",https://openreview.net{'value': '/pdf/8e1aee641dee0dc2d14eb58b4c9d0f25392e7047.pdf'},{'abstract_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=hcASxFvmZ5,"{'value': 'Peeking with PEAK: Sequential, Nonparametric Composite Hypothesis Tests for Means of Multiple Data Streams'}",Brian M Cho; Kyra Gan; Nathan Kallus,~Brian_M_Cho1; ~Kyra_Gan1; ~Nathan_Kallus1,,"{'value': 'We propose a novel nonparametric sequential test for composite hypotheses for means of multiple data streams. Our proposed method, peeking with expectation-based averaged capital (PEAK), builds upon the testing-by-betting framework and provides a non-asymptotic $\\alpha$-level test across any stopping time. Our contributions are two-fold: (1) we propose a novel betting scheme and provide theoretical guarantees on type-I error control, power, and asymptotic growth rate/$e$-power in the setting of a single data stream; (2) we introduce PEAK, a generalization of this betting scheme to multiple streams, that (i) avoids using wasteful union bounds via averaging, (ii) is a test of power one under mild regularity conditions on the sampling scheme of the streams, and (iii) reduces computational overhead when applying the testing-as-betting approaches for pure-exploration bandit problems. We illustrate the practical benefits of PEAK using both synthetic and real-world HeartSteps datasets. Our experiments show that PEAK provides up to an 85% reduction in the number of samples before stopping compared to existing stopping rules for pure-exploration bandit problems, and matches the performance of state-of-the-art sequential tests while improving upon computational complexity.'}",https://openreview.net{'value': '/pdf/6d96e429dec9430edd146d5975e8a2a907c90f5d.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=hbsKxUEreL,{'value': 'Online Adaptive Anomaly Thresholding with Confidence Sequences'},Sophia Huiwen Sun; Abishek Sankararaman; Balakrishnan Murali Narayanaswamy,~Sophia_Huiwen_Sun1; ~Abishek_Sankararaman1; ~Balakrishnan_Murali_Narayanaswamy1,,"{'value': 'Selecting appropriate thresholds for anomaly detection in online, unsupervised settings is a challenging task, especially in the presence of data distribution shifts. Addressing these challenges is critical in many practical large scale systems, such as infrastructure monitoring and network intrusion detection. This paper proposes an algorithm that connects online thresholding with constructing confidence sequences achieving (1) adaptive online threshold selection robust to distribution shifts, (2) statistical guarantees on false positive and false negative rates without any distributional assumptions, and (3) improved performance when given relevant offline data to warm-start the online algorithm, while having bounded degradation if the offline data is irrelevant. We complement our theoretical results by empirical evidence that our method outperforms commonly used baselines across synthetic and real world datasets.'}",https://openreview.net{'value': '/pdf/ffcf5872b5d03642a1c13a5086947932f2a63a28.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=hTiNFCNxM1,{'value': 'From Biased Selective Labels to Pseudo-Labels: An Expectation-Maximization Framework for Learning from Biased Decisions'},Trenton Chang; Jenna Wiens,~Trenton_Chang1; ~Jenna_Wiens1,,"{'value': 'Selective labels occur when label observations are subject to a decision-making process; e.g., diagnoses that depend on the administration of laboratory tests. We study a clinically-inspired selective label problem called disparate censorship, where labeling biases vary across subgroups and unlabeled individuals are imputed as “negative” (i.e., no diagnostic test = no illness). Machine learning models naively trained on such labels could amplify labeling bias. Inspired by causal models of selective labels, we propose Disparate Censorship Expectation-Maximization (DCEM), an algorithm for learning in the presence of disparate censorship. We theoretically analyze how DCEM mitigates the effects of disparate censorship on model performance. We validate DCEM on synthetic data, showing that it improves bias mitigation (area between ROC curves) without sacrificing discriminative performance (AUC) compared to baselines. We achieve similar results in a sepsis classification task using clinical data.'}",https://openreview.net{'value': '/pdf/3cb8574cf4f0f76c6b17793e14d8c79216a60f4b.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=hLGxDYo0eF,{'value': 'Exploration-Driven Policy Optimization in RLHF: Theoretical Insights on Efficient Data Utilization'},Yihan Du; Anna Winnicki; Gal Dalal; Shie Mannor; R. Srikant,~Yihan_Du2; ~Anna_Winnicki1; ~Gal_Dalal2; ~Shie_Mannor2; ~R._Srikant1,,"{'value': 'Reinforcement Learning from Human Feedback (RLHF) has achieved impressive empirical successes while relying on a small amount of human feedback. However, there is limited theoretical justification for this phenomenon. Additionally, most recent studies focus on value-based algorithms despite the recent empirical successes of policy-based algorithms. In this work, we consider an RLHF algorithm based on policy optimization (PO-RLHF). The algorithm is based on the popular Policy Cover-Policy Gradient (PC-PG) algorithm, which assumes knowledge of the reward function. In PO-RLHF, knowledge of the reward function is not assumed and the algorithm relies on trajectory-based comparison feedback to infer the reward function. We provide performance bounds for PO-RLHF with low query complexity, which provides insight into why a small amount of human feedback may be sufficient to get good performance with RLHF. A key novelty is our trajectory-level elliptical potential analysis technique used to infer reward function parameters when comparison queries rather than reward observations are used. We provide and analyze algorithms in two settings: linear and neural function approximation, PG-RLHF and NN-PG-RLHF, respectively.'}",https://openreview.net{'value': '/pdf/708c2ef9aec62a3643d491e11bdc51d25695e701.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2024,Conference
https://openreview.net/forum?id=hKdJPMQvew,{'value': 'Hyperbolic Active Learning for Semantic Segmentation under Domain Shift'},Luca Franco; Paolo Mandica; Konstantinos Kallidromitis; Devin Guillory; Yu-Teng Li; Trevor Darrell; Fabio Galasso,~Luca_Franco1; ~Paolo_Mandica1; ~Konstantinos_Kallidromitis1; ~Devin_Guillory1; ~Yu-Teng_Li1; ~Trevor_Darrell2; ~Fabio_Galasso1,,"{'value': 'We introduce a hyperbolic neural network approach to pixel-level active learning for semantic segmentation. Analysis of the data statistics leads to a novel interpretation of the hyperbolic radius as an indicator of data scarcity. In HALO (Hyperbolic Active Learning Optimization), for the first time, we propose the use of epistemic uncertainty as a data acquisition strategy, following the intuition of selecting data points that are the least known. The hyperbolic radius, complemented by the widely-adopted prediction entropy, effectively approximates epistemic uncertainty. We perform extensive experimental analysis based on two established synthetic-to-real benchmarks, i.e. GTAV $\\rightarrow$ Cityscapes and SYNTHIA $\\rightarrow$ Cityscapes. Additionally, we test HALO on Cityscape $\\rightarrow$ ACDC for domain adaptation under adverse weather conditions, and we benchmark both convolutional and attention-based backbones. HALO sets a new state-of-the-art in active learning for semantic segmentation under domain shift and it is the first active learning approach that surpasses the performance of supervised domain adaptation while using only a small portion of labels (i.e., 1%).'}",https://openreview.net{'value': '/pdf/ac704a67f5d23e6fbea960ffbcf0e6d2e9211655.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=hJaWoU3Emh,{'value': 'Multiply Robust Estimation for Local Distribution Shifts with Multiple Domains'},Steven Wilkins-Reeves; Xu Chen; Qi Ma; christine agarwal; Aude Hofleitner,~Steven_Wilkins-Reeves1; ~Xu_Chen23; qima@meta.com; ~christine_agarwal1; ~Aude_Hofleitner1,,"{'value': 'Distribution shifts are ubiquitous in real-world machine learning applications, posing a challenge to the generalization of models trained on one data distribution to another. We focus on scenarios where data distributions vary across multiple segments of the entire population and only make local assumptions about the differences between training and test (deployment) distributions within each segment. We propose a two-stage multiply robust estimation method to improve model performance on each individual segment for tabular data analysis. The method involves fitting a linear combination of the based models, learned using clusters of training data from multiple segments, followed by a refinement step for each segment. Our method is designed to be implemented with commonly used off-the-shelf machine learning models. We establish theoretical guarantees on the generalization bound of the method on the test risk. With extensive experiments on synthetic and real datasets, we demonstrate that the proposed method substantially improves over existing alternatives in prediction accuracy and robustness on both regression and classification tasks. We also assess its effectiveness on a user city prediction dataset from Meta.'}",https://openreview.net{'value': '/pdf/b8d90f7e116a22422ca9230dc6c4776a2d08adbe.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=hFEgae0od4,{'value': 'Discovering Features with Synergistic Interactions in Multiple Views'},Chohee Kim; Mihaela van der Schaar; Changhee Lee,~Chohee_Kim1; ~Mihaela_van_der_Schaar2; ~Changhee_Lee1,,"{'value': 'Discovering features with synergistic interactions in multi-view data, that provide more information gain when considered together than when considered separately, is particularly valuable. This fosters a more comprehensive understanding of the target outcome from diverse perspectives (views). However, despite the increasing opportunities presented by multi-view data, surprisingly little attention has been paid to uncovering these crucial interactions. To address this gap, we formally define the problem of selecting synergistic and non-synergistic feature subsets in multi-view data, leveraging an information-theoretic concept known as interaction information. To this end, we introduce a novel deep learning-based feature selection method that identifies different interactions across multiple views, employing a Bernoulli relaxation technique to solve this intractable subset searching problem. Experiments on synthetic, semi-synthetic, and real-world multi-view datasets demonstrate that our model discovers relevant feature subsets with synergistic and non-synergistic interactions, achieving remarkable similarity to the ground truth. Furthermore, we corroborate the discovered features with supporting medical and scientific literature, underscoring its utility in elucidating complex dependencies and interactions in multi-view data.'}",https://openreview.net{'value': '/pdf/2f1eee115c5d960debbe220265b25979fa642d39.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=h8aTi32tul,{'value': 'SiBBlInGS: Similarity-driven Building-Block Inference using Graphs across States'},Noga Mudrik; Gal Mishne; Adam Shabti Charles,~Noga_Mudrik1; ~Gal_Mishne1; ~Adam_Shabti_Charles1,,"{'value': ""Time series data across scientific domains are often collected under distinct states (e.g., tasks), wherein latent processes (e.g., biological factors) create complex inter- and intra-state variability. A key approach to capture this complexity is to uncover fundamental interpretable units within the data, Building Blocks (BBs), which modulate their activity and adjust their structure across observations. Existing methods for identifying BBs in multi-way data often overlook inter- vs. intra-state variability, produce uninterpretable components, or do not align with properties of real-world data, such as missing samples and sessions of different duration. Here, we present a framework for Similarity-driven Building Block Inference using Graphs across States (SiBBlInGS). SiBBlInGS offers a graph-based dictionary learning approach for discovering sparse BBs along with their temporal traces, based on co-activity patterns and inter- vs. intra-state relationships. Moreover, SiBBlInGS captures per-trial temporal variability and controlled cross-state structural BB adaptations, identifies state-specific vs. state-invariant components, and accommodates variability in the number and duration of observed sessions across states. We demonstrate SiBBlInGS's ability to reveal insights into complex phenomena as well as its robustness to noise and missing samples through several synthetic and real-world examples, including web search and neural data.""}",https://openreview.net{'value': '/pdf/583acafd024d829f096cd8275f36b93636dc67df.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=gzis9n5r7e,{'value': 'Expert Proximity as Surrogate Rewards for Single Demonstration Imitation Learning'},Chia-Cheng Chiang; Li-Cheng Lan; Wei-Fang Sun; Chien Feng; Cho-Jui Hsieh; Chun-Yi Lee,~Chia-Cheng_Chiang1; ~Li-Cheng_Lan1; ~Wei-Fang_Sun1; ~Chien_Feng2; ~Cho-Jui_Hsieh1; ~Chun-Yi_Lee1,,"{'value': 'In this paper, we focus on single-demonstration imitation learning (IL), a practical approach for real-world applications where acquiring multiple expert demonstrations is costly or infeasible and the ground truth reward function is not available. In contrast to typical IL settings with multiple demonstrations, single-demonstration IL involves an agent having access to only one expert trajectory. We highlight the issue of sparse reward signals in this setting and propose to mitigate this issue through our proposed Transition Discriminator-based IL (TDIL) method. TDIL is an IRL method designed to address reward sparsity by introducing a denser surrogate reward function that considers environmental dynamics. This surrogate reward function encourages the agent to navigate towards states that are proximal to expert states. In practice, TDIL trains a transition discriminator to differentiate between valid and non-valid transitions in a given environment to compute the surrogate rewards. The experiments demonstrate that TDIL outperforms existing IL approaches and achieves expert-level performance in the single-demonstration IL setting across five widely adopted MuJoCo benchmarks as well as the ""Adroit Door"" robotic environment.'}",https://openreview.net{'value': '/pdf/a35f2b4966588d6fdc54ee81b86852cf3666b083.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2024,Conference
https://openreview.net/forum?id=gtYdvSGMYV,{'value': 'LAGMA: LAtent Goal-guided Multi-Agent Reinforcement Learning'},Hyungho Na; Il-chul Moon,~Hyungho_Na1; ~Il-chul_Moon1,,"{'value': 'In cooperative multi-agent reinforcement learning (MARL), agents collaborate to achieve common goals, such as defeating enemies and scoring a goal. However, learning goal-reaching paths toward such a semantic goal takes a considerable amount of time in complex tasks and the trained model often fails to find such paths. To address this, we present LAtent Goal-guided Multi-Agent reinforcement learning (LAGMA), which generates a goal-reaching trajectory in latent space and provides a latent goal-guided incentive to transitions toward this reference trajectory. LAGMA consists of three major components: (a) quantized latent space constructed via a modified VQ-VAE for efficient sample utilization, (b) goal-reaching trajectory generation via extended VQ codebook, and (c) latent goal-guided intrinsic reward generation to encourage transitions towards the sampled goal-reaching path. The proposed method is evaluated by StarCraft II with both dense and sparse reward settings and Google Research Football. Empirical results show further performance improvement over state-of-the-art baselines.'}",https://openreview.net{'value': '/pdf/b3a688c16379994dac9c57640ce4761c7399e7d3.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=ghYrfdJfjK,{'value': 'PolySketchFormer: Fast Transformers via Sketching Polynomial Kernels'},Praneeth Kacham; Vahab Mirrokni; Peilin Zhong,~Praneeth_Kacham1; ~Vahab_Mirrokni2; ~Peilin_Zhong1,,"{'value': 'The quadratic time and memory complexity inherent to self-attention mechanisms, with respect to sequence length, presents a critical computational bottleneck in the training and deployment of large-scale Transformer-based language models. Recent theoretical results indicate the intractability of sub-quadratic softmax attention approximation under reasonable complexity assumptions. This paper addresses this challenge by first demonstrating that polynomial attention with high degree can effectively replace softmax without sacrificing model quality. Next, we develop polynomial sketching techniques from numerical linear algebra to achieve linear-time polynomial attention with approximation guarantees. Crucially, our approach achieves this speedup without requiring the sparsification of attention matrices. We also present a block-based algorithm to apply causal masking efficiently. Combining these techniques, we provide *PolySketchFormer*, a practical linear-time Transformer architecture for language modeling that offers provable guarantees. We validate PolySketchFormer empirically by training language models capable of handling long contexts. These experiments utilize both synthetic and real-world datasets (PG19, Wikipedia and C4) on Google Cloud TPUs. For context lengths of 32k and GPT-2 style models, our model achieves 2x speedup in training compared to FlashAttention of the fastest configuration, with no observed degradation in quality across our experiments.'}",https://openreview.net{'value': '/pdf/c31152c57f5f0f721f79f67c58c9cd9607e5b509.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=geajNKab7g,{'value': 'First-Order Manifold Data Augmentation for Regression Learning'},Ilya Kaufman; Omri Azencot,~Ilya_Kaufman1; ~Omri_Azencot1,,"{'value': 'Data augmentation (DA) methods tailored to specific domains generate synthetic samples by applying transformations that are appropriate for the characteristics of the underlying data domain, such as rotations on images and time warping on time series data. In contrast, *domain-independent* approaches, e.g. *mixup*, are applicable to various data modalities, and as such they are general and versatile. While regularizing classification tasks via DA is a well-explored research topic, the effect of DA on regression problems received less attention. To bridge this gap, we study the problem of domain-independent augmentation for regression, and we introduce *FOMA*: a new data-driven domain-independent data augmentation method. Essentially, our approach samples new examples from the tangent planes of the train distribution. Augmenting data in this way aligns with the network tendency towards capturing the dominant features of its input signals. We evaluate *FOMA* on in-distribution generalization and out-of-distribution robustness benchmarks, and we show that it improves the generalization of several neural architectures. We also find that strong baselines based on *mixup* are less effective in comparison to our approach. Our code is publicly available at https://github.com/azencot-group/FOMA'}",https://openreview.net{'value': '/pdf/a592ba7491315e210828c16006295f4dc2d00591.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=gVjMwLDFoQ,{'value': 'Iterated Denoising Energy Matching for Sampling from Boltzmann Densities'},Tara Akhound-Sadegh; Jarrid Rector-Brooks; Joey Bose; Sarthak Mittal; Pablo Lemos; Cheng-Hao Liu; Marcin Sendera; Siamak Ravanbakhsh; Gauthier Gidel; Yoshua Bengio; Nikolay Malkin; Alexander Tong,~Tara_Akhound-Sadegh1; ~Jarrid_Rector-Brooks2; ~Joey_Bose1; ~Sarthak_Mittal1; ~Pablo_Lemos1; ~Cheng-Hao_Liu1; ~Marcin_Sendera1; ~Siamak_Ravanbakhsh1; ~Gauthier_Gidel1; ~Yoshua_Bengio1; ~Nikolay_Malkin1; ~Alexander_Tong1,,"{'value': 'Efficiently generating statistically independent samples from an unnormalized probability distribution, such as equilibrium samples of many-body systems, is a foundational problem in science. In this paper, we propose Iterated Denoising Energy Matching (iDEM), an iterative algorithm that uses a novel stochastic score matching objective leveraging solely the energy function and its gradient---and no data samples---to train a diffusion-based sampler. Specifically, iDEM alternates between (I) sampling regions of high model density from a diffusion-based sampler and (II) using these samples in our stochastic matching objective to further improve the sampler. iDEM is scalable to high dimensions as the inner matching objective, is *simulation-free*, and requires no MCMC samples. Moreover, by leveraging the fast mode mixing behavior of diffusion, iDEM smooths out the energy landscape enabling efficient exploration and learning of an amortized sampler. We evaluate iDEM on a suite of tasks ranging from standard synthetic energy functions to invariant $n$-body particle systems. We show that the proposed approach achieves state-of-the-art performance on all metrics and trains $2-5\\times$ faster, which allows it to be the first method to train using energy on the challenging $55$-particle Lennard-Jones system.'}",https://openreview.net{'value': '/pdf/89365bfb13ef6521fb74a30c75f85b100589a6b5.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=gVg8V9isul,{'value': 'Long Range Propagation on Continuous-Time Dynamic Graphs'},Alessio Gravina; Giulio Lovisotto; Claudio Gallicchio; Davide Bacciu; Claas Grohnfeldt,~Alessio_Gravina1; ~Giulio_Lovisotto2; ~Claudio_Gallicchio1; ~Davide_Bacciu1; ~Claas_Grohnfeldt1,,"{'value': 'Learning Continuous-Time Dynamic Graphs (C-TDGs) requires accurately modeling spatio-temporal information on streams of irregularly sampled events. While many methods have been proposed recently, we find that most message passing-, recurrent- or self-attention-based methods perform poorly on *long-range* tasks. These tasks require correlating information that occurred ""far"" away from the current event, either spatially (higher-order node information) or along the time dimension (events occurred in the past). To address long-range dependencies, we introduce Continuous-Time Graph Anti-Symmetric Network (CTAN). Grounded within the ordinary differential equations framework, our method is designed for efficient propagation of information. In this paper, we show how CTAN\'s (i) long-range modeling capabilities are substantiated by theoretical findings and how (ii) its empirical performance on synthetic long-range benchmarks and real-world benchmarks is superior to other methods. Our results motivate CTAN\'s ability to propagate long-range information in C-TDGs as well as the inclusion of long-range tasks as part of temporal graph models evaluation.'}",https://openreview.net{'value': '/pdf/56c98173a8da4fc72949d18bdf60439e036b244d.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=gE7qZurGH3,{'value': 'Navigating Complexity: Toward Lossless Graph Condensation via Expanding Window Matching'},Yuchen Zhang; Tianle Zhang; Kai Wang; Ziyao Guo; Yuxuan Liang; Xavier Bresson; Wei Jin; Yang You,~Yuchen_Zhang8; ~Tianle_Zhang4; ~Kai_Wang8; ~Ziyao_Guo1; ~Yuxuan_Liang1; ~Xavier_Bresson6; ~Wei_Jin4; ~Yang_You1,,"{'value': 'Graph condensation aims to reduce the size of a large-scale graph dataset by synthesizing a compact counterpart without sacrificing the performance of Graph Neural Networks (GNNs) trained on it, which has shed light on reducing the computational cost for training GNNs. Nevertheless, existing methods often fall short of accurately replicating the original graph for certain datasets, thereby failing to achieve the objective of lossless condensation. To understand this phenomenon, we investigate the potential reasons and reveal that the previous state-of-the-art trajectory matching method provides biased and restricted supervision signals from the original graph when optimizing the condensed one. This significantly limits both the scale and efficacy of the condensed graph. In this paper, we make the first attempt toward *lossless graph condensation* by bridging the previously neglected supervision signals. Specifically, we employ a curriculum learning strategy to train expert trajectories with more diverse supervision signals from the original graph, and then effectively transfer the information into the condensed graph with expanding window matching. Moreover, we design a loss function to further extract knowledge from the expert trajectories. Theoretical analysis justifies the design of our method and extensive experiments verify its superiority across different datasets. Code is released at https://github.com/NUS-HPC-AI-Lab/GEOM.'}",https://openreview.net{'value': '/pdf/04ae190be63e13f9f11d2d470a9ec877defe6044.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2024,Conference
https://openreview.net/forum?id=gAyzjHw2ml,{'value': 'SceneCraft: An LLM Agent for Synthesizing 3D Scenes as Blender Code'},Ziniu Hu; Ahmet Iscen; Aashi Jain; Thomas Kipf; Yisong Yue; David A Ross; Cordelia Schmid; Alireza Fathi,~Ziniu_Hu1; ~Ahmet_Iscen3; ~Aashi_Jain1; ~Thomas_Kipf2; ~Yisong_Yue1; ~David_A_Ross1; ~Cordelia_Schmid1; ~Alireza_Fathi1,,"{'value': 'This paper introduces SceneCraft, a Large Language Model (LLM) Agent converting text descriptions into Blender-executable Python scripts which render complex scenes with up to a hundred 3D assets. This process requires complex spatial planning and arrangement. We tackle these challenges through a combination of advanced abstraction, strategic planning, and library learning. SceneCraft first models a scene graph as a blueprint, detailing the spatial relationships among assets in the scene. SceneCraft then writes Python scripts based on this graph, translating relationships into numerical constraints for asset layout. Next, SceneCraft leverages the perceptual strengths of vision-language foundation models like GPT-V to analyze rendered images and iteratively refine the scene. On top of this process, SceneCraft features a library learning mechanism that compiles common script functions into a reusable library, facilitating continuous self-improvement without expensive LLM parameter tuning. Our evaluation demonstrates that SceneCraft surpasses existing LLM-based agents in rendering complex scenes, as shown by its adherence to constraints and favorable human assessments. We also showcase the broader application potential of SceneCraft by reconstructing detailed 3D scenes from the Sintel movie and guiding a video generative model with generated scenes as intermediary control signal.'}",https://openreview.net{'value': '/pdf/d85fff2e858b46f982dd07918337607cfe370cc6.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=g43yUNWX4V,{'value': 'Momentum for the Win: Collaborative Federated Reinforcement Learning across Heterogeneous Environments'},Han Wang; Sihong He; Zhili Zhang; Fei Miao; James Anderson,~Han_Wang14; ~Sihong_He1; ~Zhili_Zhang5; ~Fei_Miao1; ~James_Anderson6,,"{'value': 'We explore a Federated Reinforcement Learning (FRL) problem where $N$ agents collaboratively learn a common policy without sharing their trajectory data. To date, existing FRL work has primarily focused on agents operating in the same or ``similar"" environments. In contrast, our problem setup allows for arbitrarily large levels of environment heterogeneity. To obtain the optimal policy which maximizes the average performance across all *potentially completely different* environments, we propose two algorithms: FedSVRPG-M and FedHAPG-M. In contrast to existing results, we demonstrate that both FedSVRPG-M and FedHAPG-M, both of which leverage momentum mechanisms, can exactly converge to a stationary point of the average performance function, regardless of the magnitude of environment heterogeneity. Furthermore, by incorporating the benefits of variance-reduction techniques or Hessian approximation, both algorithms achieve state-of-the-art convergence results, characterized by a sample complexity of $\\mathcal{O}\\left(\\epsilon^{-\\frac{3}{2}}/N\\right)$. Notably, our algorithms enjoy linear convergence speedups with respect to the number of agents, highlighting the benefit of collaboration among agents in finding a common policy.'}",https://openreview.net{'value': '/pdf/e0ca4d4e064c626190b786d949f1f99a378a64fe.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2024,Conference
https://openreview.net/forum?id=ffLblkoCw8,{'value': 'MAGDi: Structured Distillation of Multi-Agent Interaction Graphs Improves Reasoning in Smaller Language Models'},Justin Chen; Swarnadeep Saha; Elias Stengel-Eskin; Mohit Bansal,~Justin_Chen1; ~Swarnadeep_Saha2; ~Elias_Stengel-Eskin1; ~Mohit_Bansal2,,"{'value': 'Multi-agent interactions between Large Language Model (LLM) agents have shown major improvements on diverse reasoning tasks. However, these involve long generations from multiple models across several rounds, making them expensive. Moreover, these multi-agent approaches fail to provide a final, single model for efficient inference. To address this, we introduce MAGDi, a new method for structured distillation of the reasoning interactions between multiple LLMs into smaller LMs. MAGDi teaches smaller models by representing multi-agent interactions as graphs, augmenting a base student model with a graph encoder, and distilling knowledge using three objective functions: next-token prediction, a contrastive loss between correct and incorrect reasoning, and a graph-based objective to model the interaction structure. Experiments on seven widely used commonsense and math reasoning benchmarks show that MAGDi improves the reasoning capabilities of smaller models, outperforming several methods that distill from a single teacher and multiple teachers. Moreover, MAGDi also demonstrates an order of magnitude higher efficiency over its teachers. We conduct extensive analyses to show that MAGDi (1) enhances the generalizability to out-of-domain tasks, (2) scales positively with the size and strength of the base student model, and (3) obtains larger improvements (via our multi-teacher training) when applying self-consistency – an inference technique that relies on model diversity.'}",https://openreview.net{'value': '/pdf/e9dae5adc73104ddcf0d4fb6d329bf3db7d4546c.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=fSnMqHZ8xr,{'value': 'Boundary Exploration for Bayesian Optimization With Unknown Physical Constraints'},Yunsheng Tian; Ane Zuniga; Xinwei Zhang; Johannes P. Dürholt; Payel Das; Jie Chen; Wojciech Matusik; Mina Konakovic Lukovic,~Yunsheng_Tian1; ~Ane_Zuniga1; ~Xinwei_Zhang1; ~Johannes_P._Dürholt1; ~Payel_Das1; ~Jie_Chen1; ~Wojciech_Matusik2; ~Mina_Konakovic_Lukovic1,,"{'value': 'Bayesian optimization has been successfully applied to optimize black-box functions where the number of evaluations is severely limited. However, in many real-world applications, it is hard or impossible to know in advance which designs are feasible due to some physical or system limitations. These issues lead to an even more challenging problem of optimizing an unknown function with unknown constraints. In this paper, we observe that in such scenarios optimal solution typically lies on the boundary between feasible and infeasible regions of the design space, making it considerably more difficult than that with interior optima. Inspired by this observation, we propose BE-CBO, a new Bayesian optimization method that efficiently explores the boundary between feasible and infeasible designs. To identify the boundary, we learn the constraints with an ensemble of neural networks that outperform the standard Gaussian Processes for capturing complex boundaries. Our method demonstrates superior performance against state-of-the-art methods through comprehensive experiments on synthetic and real-world benchmarks. Code available at: https://github.com/yunshengtian/BE-CBO'}",https://openreview.net{'value': '/pdf/04ac14b05f6e75edbaaf21fc2efff6976f33ca22.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=efzkSbpyRw,{'value': 'Conformal Predictions under Markovian Data'},Frédéric Zheng; Alexandre Proutiere,~Frédéric_Zheng1; ~Alexandre_Proutiere1,,"{'value': 'We study the split Conformal Prediction method when applied to Markovian data. We quantify the gap in terms of coverage induced by the correlations in the data (compared to exchangeable data). This gap strongly depends on the mixing properties of the underlying Markov chain, and we prove that it typically scales as $\\sqrt{t_\\mathrm{mix}\\ln(n)/n}$ (where $t_\\mathrm{mix}$ is the mixing time of the chain). We also derive upper bounds on the impact of the correlations on the size of the prediction set. Finally we present $K$-split CP, a method that consists in thinning the calibration dataset and that adapts to the mixing properties of the chain. Its coverage gap is reduced to $t_\\mathrm{mix}/(n\\ln(n))$ without really affecting the size of the prediction set. We finally test our algorithms on synthetic and real-world datasets.'}",https://openreview.net{'value': '/pdf/4ede722e1886229fc6e6237f90a97031da46d493.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=ecnpYYHjt9,{'value': 'Speech Self-Supervised Learning Using Diffusion Model Synthetic Data'},Heting Gao; Kaizhi Qian; Junrui Ni; Chuang Gan; Mark A. Hasegawa-Johnson; Shiyu Chang; Yang Zhang,~Heting_Gao1; ~Kaizhi_Qian1; ~Junrui_Ni1; ~Chuang_Gan1; ~Mark_A._Hasegawa-Johnson1; ~Shiyu_Chang2; ~Yang_Zhang3,,"{'value': 'While self-supervised learning (SSL) in speech has greatly reduced the reliance of speech processing systems on annotated corpora, the success of SSL still hinges on the availability of a large-scale unannotated corpus, which is still often impractical for many low-resource languages or under privacy concerns. Some existing work seeks to alleviate the problem by data augmentation, but most works are confined to introducing perturbations to real speech and do not introduce new variations in speech prosody, speakers, and speech content, which are important for SSL. Motivated by the recent finding that diffusion models have superior capabilities for modeling data distributions, we propose DiffS4L, a pretraining scheme that augments the limited unannotated data with synthetic data with different levels of variations, generated by a diffusion model trained on the limited unannotated data. Finally, an SSL model is pre-trained on the real and the synthetic speech. Our experiments show that DiffS4L can significantly improve the performance of SSL models, such as reducing the WER of the HuBERT pretrained model by 6.26 percentage points in the English ASR task. Notably, we find that the synthetic speech with all levels of variations, i.e. new prosody, new speakers, and even new content (despite the new content being mostly babble), accounts for significant performance improvement. The code is available at github.com/Hertin/DiffS4L.'}",https://openreview.net{'value': '/pdf/82e9974bbfc3ea8ba2e7a8d30f5045eeb89b5207.pdf'},{'title_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=eY4jrFe6Qc,{'value': 'Towards Theoretical Understanding of Learning Large-scale Dependent Data via Random Features'},Chao Wang; Xin Bing; Xin HE; Caixing Wang,~Chao_Wang39; ~Xin_Bing1; ~Xin_HE6; ~Caixing_Wang1,,"{'value': 'Random feature (RF) mapping is an attractive and powerful technique for solving large-scale nonparametric regression. Yet, the existing theoretical analysis crucially relies on the i.i.d. assumption that individuals in the data are independent and identically distributed. It is still unclear whether learning accuracy would be compromised when the i.i.d. assumption is violated. This paper aims to provide theoretical understanding of the kernel ridge regression (KRR) with RFs for large-scale dependent data. Specifically, we consider two types of data dependence structure, namely, the $\\tau$-mixing process with exponential decay coefficient, and that with polynomial decay coefficient. Theoretically, we prove that the kernel ridge estimator with RFs achieves the minimax optimality under the exponential decay scenario, but yields a sub-optimal result under the polynomial decay case. Our analysis further reveals how the decay rate of the $\\tau$-mixing coefficient impacts the learning accuracy of the kernel ridge estimator with RFs. Extensive numerical experiments on both synthetic and real examples further validate our theoretical findings and support the effectiveness of the KRR with RFs in dealing with dependent data.'}",https://openreview.net{'value': '/pdf/bcb46fd349c486459cb1bfe98ded8bf50aeb3b0e.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=eW0pZmziBH,{'value': 'Novel Spectral Algorithms for the Partial Credit Model'},Duc Nguyen; Anderson Ye Zhang,~Duc_Nguyen3; ~Anderson_Ye_Zhang1,,"{'value': 'The Partial Credit Model (PCM) of Andrich (1978) and Masters (1982) is a fundamental model within the psychometric literature with wide-ranging modern applications. It models the integer-valued response that a subject gives to an item where there is a natural notion of monotonic progress between consecutive response values, such as partial scores on a test and customer ratings of a product. In this paper, we introduce a novel, time-efficient and accurate statistical spectral algorithm for inference under the PCM model. We complement our algorithmic contribution with in-depth non-asymptotic statistical analysis, the first of its kind in the literature. We show that the spectral algorithm enjoys the optimal error guarantee under three different metrics, all under reasonable sampling assumptions. We leverage the efficiency of the spectral algorithm to propose a novel EM-based algorithm for learning mixtures of PCMs. We perform comprehensive experiments on synthetic and real-life datasets covering education testing, recommendation systems, and financial investment applications. We show that the proposed spectral algorithm is competitive with previously introduced algorithms in terms of accuracy while being orders of magnitude faster.'}",https://openreview.net{'value': '/pdf/a8961e6e51d604caab8d679c7b915fc2a8517bc7.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=eN1T7I7OpZ,"{'value': 'Advancing DRL Agents in Commercial Fighting Games: Training, Integration, and Agent-Human Alignment'}",Chen Zhang; Qiang He; Yuan Zhou; Elvis S. Liu; Hong Wang; Jian Zhao; Yang Wang,~Chen_Zhang22; ~Qiang_He1; ~Yuan_Zhou9; ~Elvis_S._Liu1; ~Hong_Wang8; ~Jian_Zhao7; ~Yang_Wang32,,"{'value': ""Deep Reinforcement Learning (DRL) agents have demonstrated impressive success in a wide range of game genres. However, existing research primarily focuses on optimizing DRL competence rather than addressing the challenge of prolonged player interaction. In this paper, we propose a practical DRL agent system for fighting games named _Shūkai_, which has been successfully deployed to Naruto Mobile, a popular fighting game with over 100 million registered users. _Shūkai_ quantifies the state to enhance generalizability, introducing Heterogeneous League Training (HELT) to achieve balanced competence, generalizability, and training efficiency. Furthermore, _Shūkai_ implements specific rewards to align the agent's behavior with human expectations. _Shūkai_'s ability to generalize is demonstrated by its consistent competence across all characters, even though it was trained on only 13% of them. Additionally, HELT exhibits a remarkable 22% improvement in sample efficiency. _Shūkai_ serves as a valuable training partner for players in Naruto Mobile, enabling them to enhance their abilities and skills.""}",https://openreview.net{'value': '/pdf/88f9458039250116c58a14b7688a3fe8ab0d47df.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=duRRoGeoQT,{'value': 'Repeat After Me: Transformers are Better than State Space Models at Copying'},Samy Jelassi; David Brandfonbrener; Sham M. Kakade; eran malach,~Samy_Jelassi1; ~David_Brandfonbrener1; ~Sham_M._Kakade1; ~eran_malach1,,"{'value': ""Transformers are the dominant architecture for sequence modeling, but there is growing interest in models that use a fixed-size latent state that does not depend on the sequence length, which we refer to as ''generalized state space models'' (GSSMs). In this paper we show that while GSSMs are promising in terms of inference-time efficiency, they are limited compared to transformer models on tasks that require copying from the input context. We start with a theoretical analysis of the simple task of string copying and prove that a two layer transformer can copy strings of exponential length while GSSMs are fundamentally limited by their fixed-size latent state. Empirically, we find that transformers outperform GSSMs in terms of efficiency and generalization on synthetic tasks that require copying the context. Finally, we evaluate pretrained large language models and find that transformer models dramatically outperform state space models at copying and retrieving information from context. Taken together, these results suggest a fundamental gap between transformers and GSSMs on tasks of practical interest.""}",https://openreview.net{'value': '/pdf/6883b3ec5476b0297fff682cb0356866340fd275.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=d5LURMSfTx,{'value': 'InfiAgent-DABench: Evaluating Agents on Data Analysis Tasks'},Xueyu Hu; Ziyu Zhao; Shuang Wei; Ziwei Chai; Qianli Ma; Guoyin Wang; Xuwu Wang; Jing Su; Jingjing Xu; Ming Zhu; Yao Cheng; Jianbo Yuan; Jiwei Li; Kun Kuang; Yang Yang; Hongxia Yang; Fei Wu,~Xueyu_Hu1; ~Ziyu_Zhao3; ~Shuang_Wei1; ~Ziwei_Chai1; ~Qianli_Ma4; ~Guoyin_Wang1; ~Xuwu_Wang2; ~Jing_Su2; ~Jingjing_Xu1; ~Ming_Zhu1; ~Yao_Cheng7; ~Jianbo_Yuan1; ~Jiwei_Li1; ~Kun_Kuang1; ~Yang_Yang35; ~Hongxia_Yang2; ~Fei_Wu1,,"{'value': 'In this paper, we introduce InfiAgent-DABench, the first benchmark specifically designed to evaluate LLM-based agents on data analysis tasks. Agents need to solve these tasks end-to-end by interacting with an execution environment. This benchmark contains DAEval, a dataset consisting of 603 data analysis questions derived from 124 CSV files, and an agent framework which incorporates LLMs to serve as data analysis agents for both serving and evaluating. Since data analysis questions are often open-ended and hard to evaluate without human supervision, we adopt a format-prompting technique to convert each question into a closed-form format so that they can be automatically evaluated. Our extensive benchmarking of 34 LLMs uncovers the current challenges encountered in data analysis tasks. In addition, building upon our agent framework, we develop a specialized agent, DAAgent, which surpasses GPT-3.5 by 3.9% on DABench. Evaluation datasets and toolkits for InfiAgent-DABench are released at https://github.com/InfiAgent/InfiAgent.'}",https://openreview.net{'value': '/pdf/88f4bddb3f68043e45ff47100bfcdbfaf890cc2d.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=d1P6GtRzuV,{'value': 'Neural Jump-Diffusion Temporal Point Processes'},Shuai Zhang; Chuan Zhou; Yang Aron Liu; Peng Zhang; Xixun Lin; Zhi-Ming Ma,~Shuai_Zhang23; ~Chuan_Zhou3; ~Yang_Aron_Liu1; ~Peng_Zhang55; ~Xixun_Lin3; ~Zhi-Ming_Ma1,,"{'value': 'We present a novel perspective on temporal point processes (TPPs) by reformulating their intensity processes as solutions to stochastic differential equations (SDEs). In particular, we first prove the equivalent SDE formulations of several classical TPPs, including Poisson processes, Hawkes processes, and self-correcting processes. Based on these proofs, we introduce a unified TPP framework called Neural Jump-Diffusion Temporal Point Process (NJDTPP), whose intensity process is governed by a neural jump-diffusion SDE (NJDSDE) where the drift, diffusion, and jump coefficient functions are parameterized by neural networks. Compared to previous works, NJDTPP exhibits model flexibility in capturing intensity dynamics without relying on any specific functional form, and provides theoretical guarantees regarding the existence and uniqueness of the solution to the proposed NJDSDE. Experiments on both synthetic and real-world datasets demonstrate that NJDTPP is capable of capturing the dynamics of intensity processes in different scenarios and significantly outperforms the state-of-the-art TPP models in prediction tasks.'}",https://openreview.net{'value': '/pdf/1345e93f422f204c2bc1ae968981d0ea53c11d40.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=coP4kPdhKr,{'value': 'Dynamic Spectral Clustering with Provable Approximation Guarantee'},Steinar Laenen; He Sun,~Steinar_Laenen1; ~He_Sun5,,"{'value': 'This paper studies clustering algorithms for dynamically evolving graphs $\\{G_t\\}$, in which new edges (and potential new vertices) are added into a graph, and the underlying cluster structure of the graph can gradually change. The paper proves that, under some mild condition on the cluster-structure, the clusters of the final graph $G_T$ of $n_T$ vertices at time $T$ can be well approximated by a dynamic variant of the spectral clustering algorithm. The algorithm runs in amortised update time $O(1)$ and query time $o(n_T)$. Experimental studies on both synthetic and real-world datasets further confirm the practicality of our designed algorithm.'}",https://openreview.net{'value': '/pdf/7fe9037dd2752862226e66cc3a16eee4daa94f58.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=cj5HbaX14p,{'value': 'BOtied: Multi-objective Bayesian optimization with tied multivariate ranks'},Ji Won Park; Natasa Tagasovska; Michael Maser; Stephen Ra; Kyunghyun Cho,~Ji_Won_Park1; ~Natasa_Tagasovska2; ~Michael_Maser1; ~Stephen_Ra1; ~Kyunghyun_Cho1,,"{'value': 'Many scientific and industrial applications require the joint optimization of multiple, potentially competing objectives. Multi-objective Bayesian optimization (MOBO) is a sample-efficient framework for identifying Pareto-optimal solutions. At the heart of MOBO is the acquisition function, which determines the next candidate to evaluate by navigating the best compromises among the objectives. Acquisition functions that rely on integrating over the objective space scale poorly to a large number of objectives. In this paper, we show a natural connection between the non-dominated solutions and the highest multivariate rank, which coincides with the extreme level line of the joint cumulative distribution function (CDF). Motivated by this link, we propose the CDF indicator, a Pareto-compliant metric for evaluating the quality of approximate Pareto sets, that can complement the popular hypervolume indicator. We then introduce an acquisition function based on the CDF indicator, called BOtied. BOtied can be implemented efficiently with copulas, a statistical tool for modeling complex, high-dimensional distributions. Our experiments on a variety of synthetic and real-world experiments demonstrate that BOtied outperforms state-of-the-art MOBO algorithms while being computationally efficient for many objectives.'}",https://openreview.net{'value': '/pdf/b39ca7bbd9d16c01b1a25a53007a8db30a707b60.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=cHJAUdam3i,{'value': 'Discovering Mixtures of Structural Causal Models from Time Series Data'},Sumanth Varambally; Yian Ma; Rose Yu,~Sumanth_Varambally1; ~Yian_Ma1; ~Rose_Yu1,,"{'value': 'Discovering causal relationships from time series data is significant in fields such as finance, climate science, and neuroscience. However, contemporary techniques rely on the simplifying assumption that data originates from the same causal model, while in practice, data is heterogeneous and can stem from different causal models. In this work, we relax this assumption and perform causal discovery from time series data originating from *a mixture of causal models*. We propose a general variational inference-based framework called MCD to infer the underlying causal models as well as the mixing probability of each sample. Our approach employs an end-to-end training process that maximizes an evidence-lower bound for the data likelihood. We present two variants: MCD-Linear for linear relationships and independent noise, and MCD-Nonlinear for nonlinear causal relationships and history-dependent noise. We demonstrate that our method surpasses state-of-the-art benchmarks in causal discovery tasks through extensive experimentation on synthetic and real-world datasets, particularly when the data emanates from diverse underlying causal graphs. Theoretically, we prove the identifiability of such a model under some mild assumptions. Implementation is available at [https://github.com/Rose-STL-Lab/MCD](https://github.com/Rose-STL-Lab/MCD).'}",https://openreview.net{'value': '/pdf/80abfd4be70ffb0dc728e9f4d56ac02fe61b5112.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=c2CKmP9l5X,{'value': 'Deep Neural Room Acoustics Primitive'},Yuhang He; Anoop Cherian; Gordon Wichern; Andrew Markham,~Yuhang_He3; ~Anoop_Cherian1; ~Gordon_Wichern1; ~Andrew_Markham2,,"{'value': 'The primary objective of room acoustics is to model the intricate sound propagation dynamics from any source to receiver position within enclosed 3D spaces. These dynamics are encapsulated in the form of a 1D room impulse response (RIR). Precisely measuring RIR is difficult due to the complexity of sound propagation encompassing reflection, diffraction, and absorption. In this work, we propose to learn a continuous neural room acoustics field that implicitly encodes all essential sound propagation primitives for each enclosed 3D space, so that we can infer the RIR corresponding to arbitrary source-receiver positions unseen in the training dataset. Our framework, dubbed DeepNeRAP, is trained in a self-supervised manner without requiring direct access to RIR ground truth that is often needed in prior methods. The key idea is to design two cooperative acoustic agents to actively probe a 3D space, one emitting and the other receiving sound at various locations. Analyzing this sound helps to inversely characterize the acoustic primitives. Our framework is well-grounded in the fundamental physical principles of sound propagation, including reciprocity and globality, and thus is acoustically interpretable and meaningful. We present experiments on both synthetic and real-world datasets, demonstrating superior quality in RIR estimation against closely related methods.'}",https://openreview.net{'value': '/pdf/30f02732020e8486361a1da413acbaa18932a113.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=bJbSbJskOS,{'value': 'Genie: Generative Interactive Environments'},Jake Bruce; Michael D Dennis; Ashley Edwards; Jack Parker-Holder; Yuge Shi; Edward Hughes; Matthew Lai; Aditi Mavalankar; Richie Steigerwald; Chris Apps; Yusuf Aytar; Sarah Maria Elisabeth Bechtle; Feryal Behbahani; Stephanie C.Y. Chan; Nicolas Heess; Lucy Gonzalez; Simon Osindero; Sherjil Ozair; Scott Reed; Jingwei Zhang; Konrad Zolna; Jeff Clune; Nando de Freitas; Satinder Singh; Tim Rocktäschel,~Jake_Bruce1; ~Michael_D_Dennis1; ~Ashley_Edwards1; ~Jack_Parker-Holder1; ~Yuge_Shi1; ~Edward_Hughes1; ~Matthew_Lai1; ~Aditi_Mavalankar1; ~Richie_Steigerwald1; capps@google.com; ~Yusuf_Aytar1; ~Sarah_Maria_Elisabeth_Bechtle1; ~Feryal_Behbahani1; ~Stephanie_C.Y._Chan1; ~Nicolas_Heess1; lucygps@google.com; ~Simon_Osindero1; ~Sherjil_Ozair1; ~Scott_Reed1; ~Jingwei_Zhang2; ~Konrad_Zolna1; ~Jeff_Clune3; ~Nando_de_Freitas1; ~Satinder_Singh2; ~Tim_Rocktäschel1,,"{'value': 'We introduce Genie, the first *generative interactive environment* trained in an unsupervised manner from unlabelled Internet videos. The model can be prompted to generate an endless variety of action-controllable virtual worlds described through text, synthetic images, photographs, and even sketches. At 11B parameters, Genie can be considered a *foundation world model*. It is comprised of a spatiotemporal video tokenizer, an autoregressive dynamics model, and a simple and scalable latent action model. Genie enables users to act in the generated environments on a frame-by-frame basis *despite training without any ground-truth action labels* or other domain specific requirements typically found in the world model literature. Further the resulting learned latent action space facilitates training agents to imitate behaviors from unseen videos, opening the path for training generalist agents of the future.'}",https://openreview.net{'value': '/pdf/f062c55b5c6cd307ff4a6c1ff4d0c0e1da7313b6.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=b6rA0kAHT1,{'value': 'ArCHer: Training Language Model Agents via Hierarchical Multi-Turn RL'},Yifei Zhou; Andrea Zanette; Jiayi Pan; Sergey Levine; Aviral Kumar,~Yifei_Zhou1; ~Andrea_Zanette1; ~Jiayi_Pan1; ~Sergey_Levine1; ~Aviral_Kumar2,,"{'value': ""Large language models (LLMs) have the potential to tackle sequential decision-making problems due to their generalist capabilities. Instead of optimizing ``myopic'' surrogate objectives such as human preferences within a single turn, in such problems, we wish to directly optimize long-term objectives, such as user satisfaction over an entire dialogue with an LLM or delayed success metrics in web navigation. Multi-turn reinforcement learning (RL) provides an appealing approach to directly optimize long-term objectives, but how can we design effective and efficient multi-turn RL algorithms for LLMs? In this work, we propose an algorithmic framework to multi-turn RL for LLMs that preserves the flexibility of token-by-token RL used in single-turn RL problems, while still accommodating long horizons and delayed rewards more effectively. Our framework, the **A**cto**r**-**C**ritic Framework with a **H**i**e**rarchical Structu**r**e (**ArCHer**), combines a high-level off-policy RL algorithm that trains a value function with a low-level RL algorithm that trains a token-by-token policy. While ArCHer can be instantiated with multiple RL algorithms, a particularly convenient instantiation is to use temporal difference (TD) learning at the high level and on-policy token-level policy gradient at the low level. Empirically, we show that ArCHer significantly improves efficiency and performance of multi-turn LLM tasks, attaining sample efficiency boosts of about **100x** over prior on-policy methods and converging to a much better performance than other off-policy methods.""}",https://openreview.net{'value': '/pdf/8b9154ec08b66b6d7e62ce601c5391009a1ce21f.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=awo5H10K6v,{'value': 'Language-guided Skill Learning with Temporal Variational Inference'},Haotian Fu; Pratyusha Sharma; Elias Stengel-Eskin; George Konidaris; Nicolas Le Roux; Marc-Alexandre Côté; Xingdi Yuan,~Haotian_Fu3; ~Pratyusha_Sharma1; ~Elias_Stengel-Eskin1; ~George_Konidaris1; ~Nicolas_Le_Roux2; ~Marc-Alexandre_Côté2; ~Xingdi_Yuan2,,"{'value': 'We present an algorithm for skill discovery from expert demonstrations. The algorithm first utilizes Large Language Models (LLMs) to propose an initial segmentation of the trajectories. Following that, a hierarchical variational inference framework incorporates the LLM-generated segmentation information to discover reusable skills by merging trajectory segments. To further control the trade-off between compression and reusability, we introduce a novel auxiliary objective based on the Minimum Description Length principle that helps guide this skill discovery process. Our results demonstrate that agents equipped with our method are able to discover skills that help accelerate learning and outperform baseline skill learning approaches on new long-horizon tasks in BabyAI, a grid world navigation environment, as well as ALFRED, a household simulation environment.'}",https://openreview.net{'value': '/pdf/9768706293ac10c39980eba49164ec08aeeda0b0.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2024,Conference
https://openreview.net/forum?id=aw6L8sB2Ts,{'value': 'Towards Theoretical Understandings of Self-Consuming Generative Models'},Shi Fu; Sen Zhang; Yingjie Wang; Xinmei Tian; Dacheng Tao,~Shi_Fu1; ~Sen_Zhang3; ~Yingjie_Wang1; ~Xinmei_Tian1; ~Dacheng_Tao1,,"{'value': 'This paper tackles the emerging challenge of training generative models within a self-consuming loop, wherein successive generations of models are recursively trained on mixtures of real and synthetic data from previous generations. We construct a theoretical framework to rigorously evaluate how this training procedure impacts the data distributions learned by future models, including parametric and non-parametric models. Specifically, we derive bounds on the total variation (TV) distance between the synthetic data distributions produced by future models and the original real data distribution under various mixed training scenarios for diffusion models with a one-hidden-layer neural network score function. Our analysis demonstrates that this distance can be effectively controlled under the condition that mixed training dataset sizes or proportions of real data are large enough. Interestingly, we further unveil a phase transition induced by expanding synthetic data amounts, proving theoretically that while the TV distance exhibits an initial ascent, it declines beyond a threshold point. Finally, we present results for kernel density estimation, delivering nuanced insights such as the impact of mixed data training on error propagation.'}",https://openreview.net{'value': '/pdf/e8f2ff719e623f947921d656f3b58f0340ef4d3c.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=apxON2uH4N,{'value': 'Privacy-Preserving Embedding via Look-up Table Evaluation with Fully Homomorphic Encryption'},Jae-yun Kim; Saerom Park; Joohee Lee; Jung Hee Cheon,~Jae-yun_Kim1; ~Saerom_Park1; ~Joohee_Lee2; ~Jung_Hee_Cheon2,,"{'value': 'In privacy-preserving machine learning (PPML), homomorphic encryption (HE) has emerged as a significant primitive, allowing the use of machine learning (ML) models while protecting the confidentiality of input data. Although extensive research has been conducted on implementing PPML with HE by developing the efficient construction of private counterparts to ML models, the efficient HE implementation of embedding layers for token inputs such as words remains inadequately addressed. Thus, our study proposes an efficient algorithm for privacy-preserving embedding via look-up table evaluation with HE(HELUT) by developing an encrypted indicator function (EIF) that assures high precision with the use of the approximate HE scheme(CKKS). Based on the proposed EIF, we propose the CodedHELUT algorithm to facilitate an encrypted embedding layer for the first time. CodedHELUT leverages coded inputs to improve overall efficiency and optimize memory usage. Our comprehensive empirical analysis encompasses both synthetic tables and real-world largescale word embedding models. CodedHELUT algorithm achieves amortized evaluation time of 0.018-0.242s for GloVe6B50d, 0.104-01.298s for GloVe42300d, 0.262-3.283s for GPT-2 and BERT embedding layers while maintaining high precision (16 bits)'}",https://openreview.net{'value': '/pdf/25d2ac3061fa30d44671a5b7d080b5fdcb503f58.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=amRSBdZlw9,{'value': 'Position: Why Tabular Foundation Models Should Be a Research Priority'},Boris van Breugel; Mihaela van der Schaar,~Boris_van_Breugel2; ~Mihaela_van_der_Schaar2,,"{'value': ""Recent text and image foundation models are incredibly impressive, and these models are attracting an ever-increasing portion of research resources. In this position piece we aim to shift the ML research community's priorities ever so slightly to a different modality: tabular data. Tabular data is the dominant modality in many fields, yet it is given hardly any research attention and significantly lags behind in terms of scale and power. **We believe the time is now to start developing tabular foundation models**, or what we coin a _Large Tabular Model_ (LTM). LTMs could revolutionise the way science and ML use tabular data: not as single datasets that are analyzed in a vacuum, but contextualized with respect to related datasets. The potential impact is far-reaching: from few-shot tabular models to automating data science; from out-of-distribution synthetic data to empowering multidisciplinary scientific discovery. We intend to excite reflections on the modalities we study, and convince some researchers to study Large Tabular Models.""}",https://openreview.net{'value': '/pdf/f16c8ef0aabe59658b58cc81b6fe1353e4d3a291.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=aiz79FxjaI,{'value': 'Exploiting Human-AI Dependence for Learning to Defer'},Zixi Wei; Yuzhou Cao; Lei Feng,~Zixi_Wei1; ~Yuzhou_Cao1; ~Lei_Feng1,,"{'value': 'The learning to defer (L2D) framework allows models to defer their decisions to human experts. For L2D, the Bayes optimality is the basic requirement of theoretical guarantees for the design of consistent surrogate loss functions, which requires the minimizer (i.e., learned classifier) by the surrogate loss to be the Bayes optimality. However, we find that the original form of Bayes optimality fails to consider the dependence between the model and the expert, and such a dependence could be further exploited to design a better consistent loss for L2D. In this paper, we provide a new formulation for the Bayes optimality called dependent Bayes optimality, which reveals the dependence pattern in determining whether to defer. Based on the dependent Bayes optimality, we further present a deferral principle for L2D. Following the guidance of the deferral principle, we propose a novel consistent surrogate loss. Comprehensive experimental results on both synthetic and real-world datasets demonstrate the superiority of our proposed method.'}",https://openreview.net{'value': '/pdf/0604526ec8454ae761a7def31f5c927446c0e682.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=aaeJpJw5Ur,{'value': 'Socialized Learning: Making Each Other Better Through Multi-Agent Collaboration'},Xinjie Yao; Yu Wang; Pengfei Zhu; Wanyu Lin; Jialu Li; Weihao Li; Qinghua Hu,~Xinjie_Yao1; ~Yu_Wang33; ~Pengfei_Zhu1; ~Wanyu_Lin1; ~Jialu_Li4; ~Weihao_Li3; ~Qinghua_Hu1,,"{'value': 'Learning new knowledge frequently occurs in our dynamically changing world, e.g., humans culturally evolve by continuously acquiring new abilities to sustain their survival, leveraging collective intelligence rather than a large number of individual attempts. The effective learning paradigm during cultural evolution is termed socialized learning (SL). Consequently, a straightforward question arises: Can multi-agent systems acquire more new abilities like humans? In contrast to most existing methods that address continual learning and multi-agent collaboration, our emphasis lies in a more challenging problem: we prioritize the knowledge in the original expert classes, and as we adeptly learn new ones, the accuracy in the original expert classes stays superior among all in a directional manner. Inspired by population genetics and cognitive science, leading to unique and complete development, we propose Multi-Agent Socialized Collaboration (MASC), which achieves SL through interactions among multiple agents. Specifically, we introduce collective collaboration and reciprocal altruism modules, organizing collaborative behaviors, promoting information sharing, and facilitating learning and knowledge interaction among individuals. We demonstrate the effectiveness of multi-agent collaboration in an extensive empirical study. Our code will be publicly available at https://github.com/yxjdarren/SL.'}",https://openreview.net{'value': '/pdf/c18349561f2ddadc7d250dd2887df5a94893b0bd.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=aGBpiEcB8z,{'value': 'BayOTIDE: Bayesian Online Multivariate Time Series Imputation with Functional Decomposition'},Shikai Fang; Qingsong Wen; Yingtao Luo; Shandian Zhe; Liang Sun,~Shikai_Fang2; ~Qingsong_Wen2; ~Yingtao_Luo1; ~Shandian_Zhe1; ~Liang_Sun2,,"{'value': 'In real-world scenarios such as traffic and energy management, we frequently encounter large volumes of time-series data characterized by missing values, noise, and irregular sampling patterns. While numerous imputation methods have been proposed, the majority tend to operate within a local horizon, which involves dividing long sequences into batches of fixed-length segments for model training. This local horizon often leads to the overlooking of global trends and periodic patterns. More importantly, most methods assume the observations are sampled at regular timestamps, and fail to handle complex irregular sampled time series in various applications. Additionally, most existing methods are learned in an offline manner. Thus, it is not suitable for applications with rapidly arriving streaming data. To address these challenges, we propose BayOTIDE: Bayesian Online Multivariate Time series Imputation with functional decomposition. Our method conceptualizes multivariate time series as the weighted combination of groups of low-rank temporal factors with different patterns. We employ a suite of Gaussian Processes (GPs),each with a unique kernel, as functional priors to model these factors. For computational efficiency, we further convert the GPs into a state-space prior by constructing an equivalent stochastic differential equation (SDE), and developing a scalable algorithm for online inference. The proposed method can not only handle imputation over arbitrary timestamps, but also offer uncertainty quantification and interpretability for the downstream application. We evaluate our method on both synthetic and real-world datasets. We release the code at https://github.com/xuangu-fang/BayOTIDE.'}",https://openreview.net{'value': '/pdf/fff338a46f4377e8e3d1ed109038b5a690594ad0.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=a8ZpjLJuKk,{'value': 'Critical windows: non-asymptotic theory for feature emergence in diffusion models'},Marvin Li; Sitan Chen,~Marvin_Li1; ~Sitan_Chen1,,"{'value': 'We develop theory to understand an intriguing property of diffusion models for image generation that we term *critical windows*. Empirically, it has been observed that there are narrow time intervals in sampling during which particular features of the final image emerge, e.g. the image class or background color (Ho et al., 2020b; Meng et al., 2022; Choi et al., 2022; Raya & Ambrogioni, 2023; Georgiev et al., 2023; Sclocchi et al., 2024; Biroli et al., 2024). While this is advantageous for interpretability as it implies one can localize properties of the generation to a small segment of the trajectory, it seems at odds with the continuous nature of the diffusion. We propose a formal framework for studying these windows and show that for data coming from a mixture of strongly log-concave densities, these windows can be provably bounded in terms of certain measures of inter- and intra-group separation. We also instantiate these bounds for concrete examples like well-conditioned Gaussian mixtures. Finally, we use our bounds to give a rigorous interpretation of diffusion models as hierarchical samplers that progressively “decide” output features over a discrete sequence of times. We validate our bounds with experiments on synthetic data and show that critical windows may serve as a useful tool for diagnosing fairness and privacy violations in real-world diffusion models.'}",https://openreview.net{'value': '/pdf/21496bfb75c69de812198854f2e050b3b1c889cb.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=a3XFF0PGLU,{'value': 'Reward Shaping for Reinforcement Learning with An Assistant Reward Agent'},Haozhe Ma; Kuankuan Sima; Thanh Vinh Vo; Di Fu; Tze-Yun Leong,~Haozhe_Ma1; ~Kuankuan_Sima1; ~Thanh_Vinh_Vo2; ~Di_Fu2; ~Tze-Yun_Leong2,,"{'value': 'Reward shaping is a promising approach to tackle the sparse-reward challenge of reinforcement learning by reconstructing more informative and dense rewards. This paper introduces a novel dual-agent reward shaping framework, composed of two synergistic agents: a policy agent to learn the optimal behavior and a reward agent to generate auxiliary reward signals. The proposed method operates as a self-learning approach, without reliance on expert knowledge or hand-crafted functions. By restructuring the rewards to capture future-oriented information, our framework effectively enhances the sample efficiency and convergence stability. Furthermore, the auxiliary reward signals facilitate the exploration of the environment in the early stage and the exploitation of the policy agent in the late stage, achieving a self-adaptive balance. We evaluate our framework on continuous control tasks with sparse and delayed rewards, demonstrating its robustness and superiority over existing methods.'}",https://openreview.net{'value': '/pdf/8633504e1d901816d2ffd43f9cd959a3f7e3b358.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=a1GvTbadqA,{'value': '$\\mathtt{VITS}$ : Variational Inference Thompson Sampling for contextual bandits'},Pierre Clavier; Tom Huix; Alain Oliviero Durmus,~Pierre_Clavier1; ~Tom_Huix1; ~Alain_Oliviero_Durmus1,,"{'value': 'In this paper, we introduce and analyze a variant of the Thompson sampling (TS) algorithm for contextual bandits. At each round, traditional TS requires samples from the current posterior distribution, which is usually intractable. To circumvent this issue, approximate inference techniques can be used and provide samples with distribution close to the posteriors. However, current approximate techniques yield to either poor estimation (Laplace approximation) or can be computationally expensive (MCMC methods, Ensemble sampling...). In this paper, we propose a new algorithm, Varational Inference TS $\\mathtt{VITS}$, based on Gaussian Variational Inference. This scheme provides powerful posterior approximations which are easy to sample from, and is computationally efficient, making it an ideal choice for TS. In addition, we show that $\\mathtt{VITS}$ achieves a sub-linear regret bound of the same order in the dimension and number of round as traditional TS for linear contextual bandit. Finally, we demonstrate experimentally the effectiveness of $\\mathtt{VITS}$ on both synthetic and real world datasets'}",https://openreview.net{'value': '/pdf/ecc53d6c92bf531a602b149ec5d7b5d1a46ec390.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=ZzFTrzo0Cp,{'value': 'MC-GTA: Metric-Constrained Model-Based Clustering using Goodness-of-fit Tests with Autocorrelations'},Zhangyu Wang; Gengchen Mai; Krzysztof Janowicz; Ni Lao,~Zhangyu_Wang1; ~Gengchen_Mai1; ~Krzysztof_Janowicz1; ~Ni_Lao1,,"{'value': 'A wide range of (multivariate) temporal (1D) and spatial (2D) data analysis tasks, such as grouping vehicle sensor trajectories, can be formulated as clustering with given metric constraints. Existing metric-constrained clustering algorithms overlook the rich correlation between feature similarity and metric distance, i.e., metric autocorrelation. The model-based variations of these clustering algorithms (e.g. TICC and STICC) achieve SOTA performance, yet suffer from computational instability and complexity by using a metric-constrained Expectation-Maximization procedure. In order to address these two problems, we propose a novel clustering algorithm, MC-GTA (**M**odel-based **C**lustering via **G**oodness-of-fit **T**ests with **A**utocorrelations). Its objective is only composed of pairwise weighted sums of feature similarity terms (square Wasserstein-2 distance) and metric autocorrelation terms (a novel multivariate generalization of classic semivariogram). We show that MC-GTA is effectively minimizing the total hinge loss for intra-cluster observation pairs not passing goodness-of-fit tests, i.e., statistically not originating from the same distribution. Experiments on 1D/2D synthetic and real-world datasets demonstrate that MC-GTA successfully incorporates metric autocorrelation. It outperforms strong baselines by large margins (up to 14.3% in ARI and 32.1% in NMI) with faster and stabler optimization (>10x speedup).'}",https://openreview.net{'value': '/pdf/1684410475e745b969823a4671e051b6e57b8c18.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=ZxDqSBgFSM,{'value': 'Federated Self-Explaining GNNs with Anti-shortcut Augmentations'},Linan Yue; Qi Liu; Weibo Gao; Ye Liu; Kai Zhang; Yichao Du; Li Wang; Fangzhou Yao,~Linan_Yue1; ~Qi_Liu3; ~Weibo_Gao1; ~Ye_Liu10; ~Kai_Zhang12; ~Yichao_Du1; ~Li_Wang18; ~Fangzhou_Yao1,,"{'value': 'Graph Neural Networks (GNNs) have demonstrated remarkable performance in graph classification tasks. However, ensuring the explainability of their predictions remains a challenge. To address this, graph rationalization methods have been introduced to generate concise subsets of the original graph, known as rationales, which serve to explain the predictions made by GNNs. Existing rationalizations often rely on shortcuts in data for prediction and rationale composition. In response, de-shortcut rationalization methods have been proposed, which commonly leverage counterfactual augmentation to enhance data diversity for mitigating the shortcut problem. Nevertheless, these methods have predominantly focused on centralized datasets and have not been extensively explored in the Federated Learning (FL) scenarios. To this end, in this paper, we propose a Federated Graph Rationalization (FedGR) with anti-shortcut augmentations to achieve self-explaining GNNs, which involves two data augmenters. These augmenters are employed to produce client-specific shortcut conflicted samples at each client, which contributes to mitigating the shortcut problem under the FL scenarios. Experiments on real-world benchmarks and synthetic datasets validate the effectiveness of FedGR under the FL scenarios.'}",https://openreview.net{'value': '/pdf/04585205e977b2e131373b686eda50f707f2586b.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=ZXsNkm3bxu,{'value': 'CaPS: Collaborative and Private Synthetic Data Generation from Distributed Sources'},Sikha Pentyala; Mayana Pereira; Martine De Cock,~Sikha_Pentyala1; ~Mayana_Pereira1; ~Martine_De_Cock1,,"{'value': 'Data is the lifeblood of the modern world, forming a fundamental part of AI, decision-making, and research advances. With increase in interest in data, governments have taken important steps towards a regulated data world, drastically impacting data sharing and data usability and resulting in massive amounts of data confined within the walls of organizations. While synthetic data generation (SDG) is an appealing solution to break down these walls and enable data sharing, the main drawback of existing solutions is the assumption of a trusted aggregator for generative model training. Given that many data holders may not want to, or be legally allowed to, entrust a central entity with their raw data, we propose a framework for collaborative and private generation of synthetic tabular data from distributed data holders. Our solution is general, applicable to any marginal-based SDG, and provides input privacy by replacing the trusted aggregator with secure multi-party computation (MPC) protocols and output privacy via differential privacy (DP). We demonstrate the applicability and scalability of our approach for the state-of-the-art select-measure-generate SDG algorithms MWEM+PGM and AIM.'}",https://openreview.net{'value': '/pdf/f7f6ef10aa187e278ab97e4996921eb8da1bb12b.pdf'},{'title_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=ZUXvpIrz5l,{'value': 'Safe Exploration in Dose Finding Clinical Trials with Heterogeneous Participants'},Isabel Chien; Wessel P Bruinsma; Javier Gonzalez; Richard E. Turner,~Isabel_Chien2; ~Wessel_P_Bruinsma1; ~Javier_Gonzalez2; ~Richard_E_Turner1,,"{'value': ""In drug development, early phase dose-finding clinical trials are carried out to identify an optimal dose to administer to patients in larger confirmatory clinical trials. Standard trial procedures do not optimize for participant benefit and do not consider participant heterogeneity, despite consequences to participants' health and downstream impacts to under-represented population subgroups. Many novel drugs also do not obey parametric modelling assumptions made in common dose-finding procedures. We present Safe Allocation for Exploration of Treatments SAFE-T, a procedure for adaptive dose-finding that adheres to safety constraints, improves utility for heterogeneous participants, and works well with small sample sizes. SAFE-T flexibly learns non-parametric multi-output Gaussian process models for dose toxicity and efficacy, using Bayesian optimization, and provides accurate final dose recommendations. We provide theoretical guarantees for the satisfaction of safety constraints. Using a comprehensive set of realistic synthetic scenarios, we demonstrate empirically that SAFE-T generally outperforms comparable methods and maintains performance across variations in sample size and subgroup distribution. Finally, we extend SAFE-T to a new adaptive setting, demonstrating its potential to improve traditional clinical trial procedures.""}",https://openreview.net{'value': '/pdf/275d4b1770912caa0adb1da80b10436314063dfc.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=ZQcqXCuoxD,{'value': 'Cooperative Graph Neural Networks'},Ben Finkelshtein; Xingyue Huang; Michael M. Bronstein; Ismail Ilkan Ceylan,~Ben_Finkelshtein1; ~Xingyue_Huang1; ~Michael_M._Bronstein1; ~Ismail_Ilkan_Ceylan2,,"{'value': 'Graph neural networks are popular architectures for graph machine learning, based on iterative computation of node representations of an input graph through a series of invariant transformations. A large class of graph neural networks follow a standard message-passing paradigm: at every layer, each node state is updated based on an aggregate of messages from its neighborhood. In this work, we propose a novel framework for training graph neural networks, where every node is viewed as a player that can choose to either `listen`, `broadcast`, `listen and broadcast`, or to `isolate`. The standard message propagation scheme can then be viewed as a special case of this framework where every node `listens and broadcasts` to all neighbors. Our approach offers a more flexible and dynamic message-passing paradigm, where each node can determine its own strategy based on their state, effectively exploring the graph topology while learning. We provide a theoretical analysis of the new message-passing scheme which is further supported by an extensive empirical analysis on a synthetic and real-world datasets.'}",https://openreview.net{'value': '/pdf/49b93186f87ed513d4869c1218f9706a6ba7e234.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=Yn8xnK90mS,{'value': 'Unveiling the Cycloid Trajectory of EM Iterations in Mixed Linear Regression'},Zhankun Luo; Abolfazl Hashemi,~Zhankun_Luo1; ~Abolfazl_Hashemi1,,"{'value': 'We study the trajectory of iterations and the convergence rates of the Expectation-Maximization (EM) algorithm for two-component Mixed Linear Regression (2MLR). The fundamental goal of MLR is to learn the regression models from unlabeled observations. The EM algorithm finds extensive applications in solving the mixture of linear regressions. Recent results have established the super-linear convergence of EM for 2MLR in the noiseless and high SNR settings under some assumptions and its global convergence rate with random initialization has been affirmed. However, the exponent of convergence has not been theoretically estimated and the geometric properties of the trajectory of EM iterations are not well-understood. In this paper, first, using Bessel functions we provide explicit closed-form expressions for the EM updates under all SNR regimes. Then, in the noiseless setting, we completely characterize the behavior of EM iterations by deriving a recurrence relation at the population level and notably show that all the iterations lie on a certain cycloid. Based on this new trajectory-based analysis, we exhibit the theoretical estimate for the exponent of super-linear convergence and further improve the statistical error bound at the finite-sample level. Our analysis provides a new framework for studying the behavior of EM for Mixed Linear Regression.'}",https://openreview.net{'value': '/pdf/721259b8a264d7a0bb5eaad7efe11aa37fa88d9a.pdf'},{'title_filter': 'Trajectory'},ICML.cc,2024,Conference
https://openreview.net/forum?id=YRWdiaupCr,{'value': 'Two-Stage Shadow Inclusion Estimation: An IV Approach for Causal Inference under Latent Confounding and Collider Bias'},Baohong Li; Anpeng Wu; Ruoxuan Xiong; Kun Kuang,~Baohong_Li1; ~Anpeng_Wu1; ~Ruoxuan_Xiong1; ~Kun_Kuang1,,"{'value': 'Latent confounding bias and collider bias are two key challenges of causal inference in observational studies. Latent confounding bias occurs when failing to control the unmeasured covariates that are common causes of treatments and outcomes, which can be addressed by using the Instrumental Variable (IV) approach. Collider bias comes from non-random sample selection caused by both treatments and outcomes, which can be addressed by using a different type of instruments, i.e., shadow variables. However, in most scenarios, these two biases simultaneously exist in observational data, and the previous methods focusing on either one are inadequate. To the best of our knowledge, no approach has been developed for causal inference when both biases exist. In this paper, we propose a novel IV approach, Two-Stage Shadow Inclusion (2SSI), which can simultaneously address latent confounding bias and collider bias by utilizing the residual of the treatment as a shadow variable. Extensive experimental results on benchmark synthetic datasets and a real-world dataset show that 2SSI achieves noticeable performance improvement when both biases exist compared to existing methods.'}",https://openreview.net{'value': '/pdf/8fa7dd5028f08d3fe0e772beefc4e362eac6d0b3.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=YPbcUBcTAk,{'value': 'Conformal Prediction with Learned Features'},Shayan Kiyani; George J. Pappas; Hamed Hassani,~Shayan_Kiyani2; ~George_J._Pappas1; ~Hamed_Hassani2,,"{'value': 'In this paper, we focus on the problem of conformal prediction with conditional guarantees. Prior work has shown that it is impossible to construct nontrivial prediction sets with full conditional coverage guarantees. A wealth of research has considered relaxations of full conditional guarantees, relying on some *predefined* uncertainty structures. Departing from this line of thinking, we propose Partition Learning Conformal Prediction (PLCP), a framework to improve conditional validity of prediction sets through *learning* uncertainty-guided features from the calibration data. We implement PLCP efficiently with alternating gradient descent, utilizing off-the-shelf machine learning models. We further analyze PLCP theoretically and provide conditional guarantees for infinite and finite sample sizes. Finally, our experimental results over four real-world and synthetic datasets show the superior performance of PLCP compared to state-of-the-art methods in terms of coverage and length in both classification and regression scenarios.'}",https://openreview.net{'value': '/pdf/d3cff0c1e7ab1ab396e6fd8190d89a3890481e1c.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=YNvGFaOG1p,{'value': 'Non-Asymptotic Analysis for Single-Loop (Natural) Actor-Critic with Compatible Function Approximation'},Yudan Wang; Yue Wang; Yi Zhou; Shaofeng Zou,~Yudan_Wang1; ~Yue_Wang16; ~Yi_Zhou2; ~Shaofeng_Zou1,,"{'value': 'Actor-critic (AC) is a powerful method for learning an optimal policy in reinforcement learning, where the critic uses algorithms, e.g., temporal difference (TD) learning with function approximation, to evaluate the current policy and the actor updates the policy along an approximate gradient direction using information from the critic. This paper provides the *tightest* non-asymptotic convergence bounds for both the AC and natural AC (NAC) algorithms. Specifically, existing studies show that AC converges to an $\\epsilon+\\varepsilon_{\\text{critic}}$ neighborhood of stationary points with the best known sample complexity of $\\mathcal{O}(\\epsilon^{-2})$ (up to a log factor), and NAC converges to an $\\epsilon+\\varepsilon_{\\text{critic}}+\\sqrt{\\varepsilon_{\\text{actor}}}$ neighborhood of the global optimum with the best known sample complexity of $\\mathcal{O}(\\epsilon^{-3})$, where $\\varepsilon_{\\text{critic}}$ is the approximation error of the critic and $\\varepsilon_{\\text{actor}}$ is the approximation error induced by the insufficient expressive power of the parameterized policy class. This paper analyzes the convergence of both AC and NAC algorithms with compatible function approximation. Our analysis eliminates the term $\\varepsilon_{\\text{critic}}$ from the error bounds while still achieving the best known sample complexities. Moreover, we focus on the challenging single-loop setting with a single Markovian sample trajectory. Our major technical novelty lies in analyzing the stochastic bias due to policy-dependent and time-varying compatible function approximation in the critic, and handling the non-ergodicity of the MDP due to the single Markovian sample trajectory. Numerical results are also provided in the appendix.'}",https://openreview.net{'value': '/pdf/3cade0558381a4ae54d9fa37aec2120ae1a8e00f.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2024,Conference
https://openreview.net/forum?id=Y8KsHT1kTV,{'value': 'Emergence of In-Context Reinforcement Learning from Noise Distillation'},Ilya Zisman; Vladislav Kurenkov; Alexander Nikulin; Viacheslav Sinii; Sergey Kolesnikov,~Ilya_Zisman1; ~Vladislav_Kurenkov1; ~Alexander_Nikulin1; ~Viacheslav_Sinii1; ~Sergey_Kolesnikov1,,"{'value': 'Recently, extensive studies in Reinforcement Learning have been carried out on the ability of transformers to adapt in-context to various environments and tasks. Current in-context RL methods are limited by their strict requirements for data, which needs to be generated by RL agents or labeled with actions from an optimal policy. In order to address this prevalent problem, we propose AD$^\\varepsilon$, a new data acquisition approach that enables in-context Reinforcement Learning from noise-induced curriculum. We show that it is viable to construct a synthetic noise injection curriculum which helps to obtain learning histories. Moreover, we experimentally demonstrate that it is possible to alleviate the need for generation using optimal policies, with in-context RL still able to outperform the best suboptimal policy in a learning dataset by a 2x margin.'}",https://openreview.net{'value': '/pdf/c03ad04deeee5eefac6d2d5b6e0a992c4484e031.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=Y4VgJfbjfl,{'value': 'CuTS: Customizable Tabular Synthetic Data Generation'},Mark Vero; Mislav Balunovic; Martin Vechev,~Mark_Vero1; ~Mislav_Balunovic1; ~Martin_Vechev1,,"{'value': 'Privacy, data quality, and data sharing concerns pose a key limitation for tabular data applications. While generating synthetic data resembling the original distribution addresses some of these issues, most applications would benefit from additional customization on the generated data. However, existing synthetic data approaches are limited to particular constraints, e.g., differential privacy (DP) or fairness. In this work, we introduce CuTS, the first customizable synthetic tabular data generation framework. Customization in CuTS is achieved via declarative statistical and logical expressions, supporting a wide range of requirements (e.g., DP or fairness, among others). To ensure high synthetic data quality in the presence of custom specifications, CuTS is pre-trained on the original dataset and fine-tuned on a differentiable loss automatically derived from the provided specifications using novel relaxations. We evaluate CuTS over four datasets and on numerous custom specifications, outperforming state-of-the-art specialized approaches on several tasks while being more general. In particular, at the same fairness level, we achieve 2.3% higher downstream accuracy than the state-of-the-art in fair synthetic data generation on the Adult dataset.'}",https://openreview.net{'value': '/pdf/a4689dbaeaf23b9715b4f0ff8e96743ccb4537b7.pdf'},{'title_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=XyhgssAo5b,{'value': 'Robust Learning-Augmented Dictionaries'},Ali Zeynali; Shahin Kamali; Mohammad Hajiesmaili,~Ali_Zeynali1; ~Shahin_Kamali1; ~Mohammad_Hajiesmaili1,,"{'value': 'We present the first learning-augmented data structure for implementing dictionaries with optimal consistency and robustness. Our data structure, named RobustSL, is a Skip list augmented by predictions of access frequencies of elements in a data sequence. With proper predictions, RobustSL has optimal consistency (achieves static optimality). At the same time, it maintains a logarithmic running time for each operation, ensuring optimal robustness, even if predictions are generated adversarially. Therefore, RobustSL has all the advantages of the recent learning-augmented data structures of Lin, Luo, and Woodruff (ICML 2022) and Cao et al. (arXiv 2023), while providing robustness guarantees that are absent in the previous work. Numerical experiments show that RobustSL outperforms alternative data structures using both synthetic and real datasets.'}",https://openreview.net{'value': '/pdf/7cb4fda84732e4fb5688cd4dbb33397b67076927.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=XUeoOBid3x,{'value': 'Magicoder: Empowering Code Generation with OSS-Instruct'},Yuxiang Wei; Zhe Wang; Jiawei Liu; Yifeng Ding; LINGMING ZHANG,~Yuxiang_Wei2; ~Zhe_Wang41; ~Jiawei_Liu11; ~Yifeng_Ding2; ~LINGMING_ZHANG2,,"{'value': 'We introduce Magicoder, a series of fully open-source (code, weights, and data) Large Language Models (LLMs) for code that significantly closes the gap with top code models while having no more than 7B parameters. Magicoder models are trained on 75K synthetic instruction data using **OSS-Instruct**, a novel approach to enlightening LLMs with open-source code snippets to generate diverse instruction data for code. Our main motivation is to mitigate the inherent bias of the synthetic data generated by LLMs through the wealth of open-source references for the production of more realistic and controllable data. The orthogonality of OSS-Instruct and other data generation methods like Evol-Instruct further enables us to build an enhanced MagicoderS. Both Magicoder and MagicoderS substantially outperform state-of-the-art code models with similar or even larger sizes on a wide range of coding benchmarks. Notably, MagicoderS-CL-7B based on CodeLlama even surpasses the prominent ChatGPT on HumanEval+ (66.5 vs. 65.9 in pass@1 ). Overall, OSS-Instruct opens a new direction for crafting diverse synthetic instruction data for code using abundant open-source references.'}",https://openreview.net{'value': '/pdf/cc86ab4aa69d60836d518d78fd4ac7ccc06fc003.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=XQz7ytgETQ,{'value': 'Network Tight Community Detection'},Jiayi Deng; Xiaodong Yang; Jun Yu; Jun Liu; Zhaiming Shen; Danyang Huang; Huimin Cheng,~Jiayi_Deng1; ~Xiaodong_Yang7; ~Jun_Yu4; ~Jun_Liu3; ~Zhaiming_Shen1; dyhuang89@126.com; ~Huimin_Cheng1,,"{'value': ""Conventional community detection methods often categorize all nodes into clusters. However, the presumed community structure of interest may only be valid for a subset of nodes (named as `tight nodes'), while the rest of the network may consist of noninformative ``scattered nodes''. For example, a protein-protein network often contains proteins that do not belong to specific biological functional modules but are involved in more general processes, or act as bridges between different functional modules. Forcing each of these proteins into a single cluster introduces unwanted biases and obscures the underlying biological implication. To address this issue, we propose a tight community detection (TCD) method to identify tight communities excluding scattered nodes. The algorithm enjoys a strong theoretical guarantee of tight node identification accuracy and is scalable for large networks. The superiority of the proposed method is demonstrated by various synthetic and real experiments.""}",https://openreview.net{'value': '/pdf/92e4301dd5ac0532d06078ce3721f0c2423740d4.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=XKxuTZRCXq,"{'value': 'Bounding the Excess Risk for Linear Models Trained on Marginal-Preserving, Differentially-Private, Synthetic Data'}",Yvonne Zhou; Mingyu Liang; Ivan Brugere; Danial Dervovic; Antigoni Polychroniadou; Min Wu; Dana Dachman-Soled,~Yvonne_Zhou1; ~Mingyu_Liang1; ~Ivan_Brugere1; ~Danial_Dervovic1; ~Antigoni_Polychroniadou1; ~Min_Wu1; ~Dana_Dachman-Soled1,,"{'value': 'The growing use of machine learning (ML) has raised concerns that an ML model may reveal private information about an individual who has contributed to the training dataset. To prevent leakage of sensitive data, we consider using differentially- private (DP), synthetic training data instead of real training data to train an ML model. A key desirable property of synthetic data is its ability to preserve the low-order marginals of the original distribution. Our main contribution comprises novel upper and lower bounds on the excess empirical risk of linear models trained on such synthetic data, for continuous and Lipschitz loss functions. We perform extensive experimentation alongside our theoretical results.'}",https://openreview.net{'value': '/pdf/bacb4584a367000291562e017accef1df3ee4c5f.pdf'},{'title_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=XBNhJQU84y,{'value': 'Enhancing Implicit Shape Generators Using Topological Regularizations'},Liyan Chen; Yan Zheng; Yang Li; Lohit Anirudh Jagarapu; Haoxiang Li; Hao Kang; Gang Hua; Qixing Huang,~Liyan_Chen1; ~Yan_Zheng4; ~Yang_Li4; ~Lohit_Anirudh_Jagarapu1; ~Haoxiang_Li1; ~Hao_Kang1; ~Gang_Hua3; ~Qixing_Huang1,,"{'value': 'A fundamental problem in learning 3D shapes generative models is that when the generative model is simply fitted to the training data, the resulting synthetic 3D models can present various artifacts. Many of these artifacts are topological in nature, e.g., broken legs, unrealistic thin structures, and small holes. In this paper, we introduce a principled approach that utilizes topological regularization losses on an implicit shape generator to rectify topological artifacts. The objectives are two-fold. The first is to align the persistent diagram (PD) distribution of the training shapes with that of synthetic shapes. The second ensures that the PDs are smooth among adjacent synthetic shapes. We show how to achieve these two objectives using two simple but effective formulations. Specifically, distribution alignment is achieved to learn a generative model of PDs and align this generator with PDs of synthetic shapes. We show how to handle discrete and continuous variabilities of PDs by using a shape-regularization term when performing PD alignment. Moreover, we enforce the smoothness of the PDs using a smoothness loss on the PD generator, which further improves the behavior of PD distribution alignment. Experimental results on ShapeNet show that our approach leads to much better generalization behavior than state-of-the-art implicit shape generators.'}",https://openreview.net{'value': '/pdf/35bdbfb06a7ff91e5034e703acd2400e0a9cc105.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=WwLtwPHmSM,{'value': 'Best Arm Identification for Stochastic Rising Bandits'},Marco Mussi; Alessandro Montenegro; Francesco Trovò; Marcello Restelli; Alberto Maria Metelli,~Marco_Mussi1; ~Alessandro_Montenegro1; ~Francesco_Trovò1; ~Marcello_Restelli1; ~Alberto_Maria_Metelli2,,"{'value': 'Stochastic Rising Bandits (SRBs) model sequential decision-making problems in which the expected reward of the available options increases every time they are selected. This setting captures a wide range of scenarios in which the available options are learning entities whose performance improves (in expectation) over time (e.g., online best model selection). While previous works addressed the regret minimization problem, this paper focuses on the fixed-budget Best Arm Identification (BAI) problem for SRBs. In this scenario, given a fixed budget of rounds, we are asked to provide a recommendation about the best option at the end of the identification process. We propose two algorithms to tackle the above-mentioned setting, namely R-UCBE, which resorts to a UCB-like approach, and R-SR, which employs a successive reject procedure. Then, we prove that, with a sufficiently large budget, they provide guarantees on the probability of properly identifying the optimal option at the end of the learning process and on the simple regret. Furthermore, we derive a lower bound on the error probability, matched by our R-SR (up to constants), and illustrate how the need for a sufficiently large budget is unavoidable in the SRB setting. Finally, we numerically validate the proposed algorithms in both synthetic and realistic environments.'}",https://openreview.net{'value': '/pdf/78c186f726d3e0a499f1ee69147a903ca569480b.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=WJ5fJhwvCl,{'value': 'Breaking the Barrier: Enhanced Utility and Robustness in Smoothed DRL Agents'},Chung-En Sun; Sicun Gao; Tsui-Wei Weng,~Chung-En_Sun1; ~Sicun_Gao1; ~Tsui-Wei_Weng1,,"{'value': 'Robustness remains a paramount concern in deep reinforcement learning (DRL), with randomized smoothing emerging as a key technique for enhancing this attribute. However, a notable gap exists in the performance of current smoothed DRL agents, often characterized by significantly low clean rewards and weak robustness. In response to this challenge, our study introduces innovative algorithms aimed at training effective smoothed robust DRL agents. We propose S-DQN and S-PPO, novel approaches that demonstrate remarkable improvements in clean rewards, empirical robustness, and robustness guarantee across standard RL benchmarks. Notably, our S-DQN and S-PPO agents not only significantly outperform existing smoothed agents by an average factor of $2.16\\times$ under the strongest attack, but also surpass previous robustly-trained agents by an average factor of $2.13\\times$. This represents a significant leap forward in the field. Furthermore, we introduce Smoothed Attack, which is $1.89\\times$ more effective in decreasing the rewards of smoothed agents than existing adversarial attacks. Our code is available at: [https://github.com/Trustworthy-ML-Lab/Robust_HighUtil_Smoothed_DRL](https://github.com/Trustworthy-ML-Lab/Robust_HighUtil_Smoothed_DRL)'}",https://openreview.net{'value': '/pdf/24bbc069ca941cbebd3a301de4014f7292cffafe.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=WIaZFk02fI,{'value': 'An Empirical Study of Realized GNN Expressiveness'},Yanbo Wang; Muhan Zhang,~Yanbo_Wang2; ~Muhan_Zhang1,,"{'value': 'Research on the theoretical expressiveness of Graph Neural Networks (GNNs) has developed rapidly, and many methods have been proposed to enhance the expressiveness. However, most methods do not have a uniform expressiveness measure except for a few that strictly follow the $k$-dimensional Weisfeiler-Lehman ($k$-WL) test hierarchy, leading to difficulties in quantitatively comparing their expressiveness. Previous research has attempted to use datasets for measurement, but facing problems with difficulty (any model surpassing 1-WL has nearly 100% accuracy), granularity (models tend to be either 100% correct or near random guess), and scale (only several essentially different graphs involved). To address these limitations, we study the realized expressive power that a practical model instance can achieve using a novel expressiveness dataset, BREC, which poses greater difficulty (with up to 4-WL-indistinguishable graphs), finer granularity (enabling comparison of models between 1-WL and 3-WL), a larger scale (consisting of 800 1-WL-indistinguishable graphs that are non-isomorphic to each other). We synthetically test 23 models with higher-than-1-WL expressiveness on BREC. Our experiment gives the first thorough measurement of the realized expressiveness of those state-of-the-art beyond-1-WL GNN models and reveals the gap between theoretical and realized expressiveness. Dataset and evaluation codes are released at: https://github.com/GraphPKU/BREC.'}",https://openreview.net{'value': '/pdf/236bacd610237e46e4508c497c59169d676e4e70.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=WFyolnFZOR,{'value': 'Language Models as Science Tutors'},Alexis Chevalier; Jiayi Geng; Alexander Wettig; Howard Chen; Sebastian Mizera; Toni Annala; Max Aragon; Arturo Rodriguez Fanlo; Simon Frieder; Simon Machado; Akshara Prabhakar; Ellie Thieu; Jiachen T. Wang; Zirui Wang; Xindi Wu; Mengzhou Xia; Wenhan Xia; Jiatong Yu; Junjie Zhu; Zhiyong Ren; Sanjeev Arora; Danqi Chen,~Alexis_Chevalier1; ~Jiayi_Geng1; ~Alexander_Wettig1; ~Howard_Chen1; ~Sebastian_Mizera1; ~Toni_Annala1; ~Max_Aragon1; ~Arturo_Rodriguez_Fanlo1; ~Simon_Frieder1; ~Simon_Machado1; ~Akshara_Prabhakar1; elliethieu.amherst@gmail.com; ~Jiachen_T._Wang1; ~Zirui_Wang5; ~Xindi_Wu1; ~Mengzhou_Xia1; ~Wenhan_Xia1; ~Jiatong_Yu1; ~Junjie_Zhu4; ~Zhiyong_Ren1; ~Sanjeev_Arora1; ~Danqi_Chen1,,"{'value': 'NLP has recently made exciting progress toward training language models (LMs) with strong scientific problem-solving skills. However, model development has not focused on real-life use-cases of LMs for science, including applications in education that require processing long scientific documents. To address this, we introduce TutorEval and TutorChat. TutorEval is a diverse question-answering benchmark consisting of questions about long chapters from STEM textbooks, written by experts. TutorEval helps measure real-life usability of LMs as scientific assistants, and it is the first benchmark combining long contexts, free-form generation, and multi-disciplinary scientific knowledge. Moreover, we show that fine-tuning base models with existing dialogue datasets leads to poor performance on TutorEval. Therefore, we create TutorChat, a dataset of 80,000 long synthetic dialogues about textbooks. We use TutorChat to fine-tune Llemma models with 7B and 34B parameters. These LM tutors specialized in math have a 32K-token context window, and they excel at TutorEval while performing strongly on GSM8K and MATH. Our datasets build on open-source materials, and we release our models, data, and evaluations publicly.'}",https://openreview.net{'value': '/pdf/21a2889654fe629571a9cdb02343900124196c1e.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=VuoB86HiCL,{'value': 'Automating the Selection of Proxy Variables of Unmeasured Confounders'},Feng Xie; Zhengming Chen; Shanshan Luo; Wang Miao; Ruichu Cai; Zhi Geng,~Feng_Xie1; ~Zhengming_Chen2; ~Shanshan_Luo2; ~Wang_Miao1; ~Ruichu_Cai1; ~Zhi_Geng1,,"{'value': 'Recently, interest has grown in the use of proxy variables of unobserved confounding for inferring the causal effect in the presence of unmeasured confounders from observational data. One difficulty inhibiting the practical use is finding valid proxy variables of unobserved confounding to a target causal effect of interest. These proxy variables are typically justified by background knowledge. In this paper, we investigate the estimation of causal effects among multiple treatments and a single outcome, all of which are affected by unmeasured confounders, within a linear causal model, without prior knowledge of the validity of proxy variables. To be more specific, we first extend the existing proxy variable estimator, originally addressing a single unmeasured confounder, to accommodate scenarios where multiple unmeasured confounders exist between the treatments and the outcome. Subsequently, we present two different sets of precise identifiability conditions for selecting valid proxy variables of unmeasured confounders, based on the second-order statistics and higher-order statistics of the data, respectively. Moreover, we propose two data-driven methods for the selection of proxy variables and for the unbiased estimation of causal effects. Theoretical analysis demonstrates the correctness of our proposed algorithms. Experimental results on both synthetic and real-world data show the effectiveness of the proposed approach.'}",https://openreview.net{'value': '/pdf/51aad5f1f0c80e82b56c379701e7ff85bd2b57ea.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=VsvfSMI5bs,{'value': 'BAGEL: Bootstrapping Agents by Guiding Exploration with Language'},Shikhar Murty; Christopher D Manning; Peter Shaw; Mandar Joshi; Kenton Lee,~Shikhar_Murty1; ~Christopher_D_Manning1; ~Peter_Shaw1; ~Mandar_Joshi1; ~Kenton_Lee1,,"{'value': 'Following natural language instructions by executing actions in digital environments (e.g. web-browsers and REST APIs) is a challenging task for language model (LM) agents. Unfortunately, LM agents often fail to generalize to new environments without human demonstrations. This work presents BAGEL, a method for bootstrapping LM agents without human supervision. BAGEL converts a seed set of randomly explored trajectories to synthetic demonstrations via round-trips between two noisy LM components: an LM labeler which converts a trajectory into a synthetic instruction, and a zero-shot LM agent which maps the synthetic instruction into a refined trajectory. By performing these round-trips iteratively, BAGEL quickly converts the initial distribution of trajectories towards those that are well-described by natural language. We adapt the base LM agent at test time with in-context learning by retrieving relevant BAGEL demonstrations based on the instruction, and find improvements of over 2-13% absolute on ToolQA and MiniWob++, with up to 13x reduction in execution failures.'}",https://openreview.net{'value': '/pdf/2783f896dc4c688f8410e6cdbe577dc298d5ffbd.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=ViZcgDQjyG,{'value': 'Position: Will we run out of data? Limits of LLM scaling based on human-generated data'},Pablo Villalobos; Anson Ho; Jaime Sevilla; Tamay Besiroglu; Lennart Heim; Marius Hobbhahn,~Pablo_Villalobos1; ~Anson_Ho1; jaime@epochai.org; tamay@epochai.org; ~Lennart_Heim1; ~Marius_Hobbhahn1,,"{'value': 'We investigate the potential constraints on LLM scaling posed by the availability of public human-generated text data. We forecast the growing demand for training data based on current trends and estimate the total stock of public human text data. Our findings indicate that if current LLM development trends continue, models will be trained on datasets roughly equal in size to the available stock of public human text data between 2026 and 2032, or slightly earlier if models are overtrained. We explore how progress in language modeling can continue when human-generated text datasets cannot be scaled any further. We argue that synthetic data generation, transfer learning from data-rich domains, and data efficiency improvements might support further progress.'}",https://openreview.net{'value': '/pdf/bfb3ffa8e9cee8f96d1ad2600d8617a958730bdb.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=VW7Jk8KhNC,{'value': 'Non-parametric Online Change Point Detection on Riemannian Manifolds'},Xiuheng Wang; Ricardo Augusto Borsoi; Cédric Richard,~Xiuheng_Wang1; ~Ricardo_Augusto_Borsoi1; ~Cédric_Richard1,,"{'value': 'Non-parametric detection of change points in streaming time series data that belong to Euclidean spaces has been extensively studied in the literature. Nevertheless, when the data belongs to a Riemannian manifold, existing approaches are no longer applicable as they fail to account for the structure and geometry of the manifold. In this paper, we introduce a non-parametric algorithm for online change point detection in manifold-valued data streams. This algorithm monitors the generalized Karcher mean of the data, computed using stochastic Riemannian optimization. We provide theoretical bounds on the detection and false alarm rate performances of the algorithm, using a new result on the non-asymptotic convergence of the stochastic Riemannian gradient descent. We apply our algorithm to two different Riemannian manifolds. Experimental results with both synthetic and real data illustrate the performance of the proposed method.'}",https://openreview.net{'value': '/pdf/f1060360d55a339d7729c38d361ade302c865b60.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=V4qV08Vk6S,{'value': 'An Embodied Generalist Agent in 3D World'},Jiangyong Huang; Silong Yong; Xiaojian Ma; Xiongkun Linghu; Puhao Li; Yan Wang; Qing Li; Song-Chun Zhu; Baoxiong Jia; Siyuan Huang,~Jiangyong_Huang1; ~Silong_Yong1; ~Xiaojian_Ma1; ~Xiongkun_Linghu1; ~Puhao_Li1; ~Yan_Wang24; ~Qing_Li1; ~Song-Chun_Zhu1; ~Baoxiong_Jia1; ~Siyuan_Huang2,,"{'value': ""Leveraging massive knowledge from large language models (LLMs), recent machine learning models show notable successes in general-purpose task solving in diverse domains such as computer vision and robotics. However, several significant challenges remain: (i) most of these models rely on 2D images yet exhibit a limited capacity for 3D input; (ii) these models rarely explore the tasks inherently defined in 3D world, e.g., 3D grounding, embodied reasoning and acting. We argue these limitations significantly hinder current models from performing real-world tasks and approaching general intelligence. To this end, we introduce LEO, an embodied multi-modal generalist agent that excels in perceiving, grounding, reasoning, planning, and acting in the 3D world. LEO is trained with a unified task interface, model architecture, and objective in two stages: (i) 3D vision-language (VL) alignment and (ii) 3D vision-language-action (VLA) instruction tuning. We collect large-scale datasets comprising diverse object-level and scene-level tasks, which require considerable understanding of and interaction with the 3D world. Moreover, we meticulously design an LLM-assisted pipeline to produce high-quality 3D VL data. Through extensive experiments, we demonstrate LEO's remarkable proficiency across a wide spectrum of tasks, including 3D captioning, question answering, embodied reasoning, navigation and manipulation. Our ablative studies and scaling analyses further provide valuable insights for developing future embodied generalist agents. Code and data are available on [project page](https://embodied-generalist.github.io/).""}",https://openreview.net{'value': '/pdf/c05b9e4c5fdd24c009b6825f60b1eb29633750b1.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=V3OpGwo68Z,{'value': 'Adapt and Diffuse: Sample-adaptive Reconstruction via Latent Diffusion Models'},Zalan Fabian; Berk Tinaz; Mahdi Soltanolkotabi,~Zalan_Fabian1; ~Berk_Tinaz1; ~Mahdi_Soltanolkotabi1,,"{'value': 'Inverse problems arise in a multitude of applications, where the goal is to recover a clean signal from noisy and possibly (non)linear observations. The difficulty of a reconstruction problem depends on multiple factors, such as the ground truth signal structure, the severity of the degradation and the complex interactions between the above. This results in natural sample-by-sample variation in the difficulty of a reconstruction problem. Our key observation is that most existing inverse problem solvers lack the ability to adapt their compute power to the difficulty of the reconstruction task, resulting in subpar performance and wasteful resource allocation. We propose a novel method, *severity encoding*, to estimate the degradation severity of corrupted signals in the latent space of an autoencoder. We show that the estimated severity has strong correlation with the true corruption level and can provide useful hints on the difficulty of reconstruction problems on a sample-by-sample basis. Furthermore, we propose a reconstruction method based on latent diffusion models that leverages the predicted degradation severities to fine-tune the reverse diffusion sampling trajectory and thus achieve sample-adaptive inference times. Our framework, Flash-Diffusion, acts as a wrapper that can be combined with any latent diffusion-based baseline solver, imbuing it with sample-adaptivity and acceleration. We perform experiments on both linear and nonlinear inverse problems and demonstrate that our technique greatly improves the performance of the baseline solver and achieves up to $10\\times$ acceleration in mean sampling speed.'}",https://openreview.net{'value': '/pdf/c0010f659cac8e5485a5020c696bf0520bbb0ead.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2024,Conference
https://openreview.net/forum?id=UdXDUDxq11,{'value': 'Zero-Sum Positional Differential Games as a Framework for Robust Reinforcement Learning: Deep Q-Learning Approach'},Anton Plaksin; Vitaly Kalev,~Anton_Plaksin1; ~Vitaly_Kalev1,,"{'value': ""Robust Reinforcement Learning (RRL) is a promising Reinforcement Learning (RL) paradigm aimed at training robust to uncertainty or disturbances models, making them more efficient for real-world applications. Following this paradigm, uncertainty or disturbances are interpreted as actions of a second adversarial agent, and thus, the problem is reduced to seeking the agents' policies robust to any opponent's actions. This paper is the first to propose considering the RRL problems within the positional differential game theory, which helps us to obtain theoretically justified intuition to develop a centralized Q-learning approach. Namely, we prove that under Isaacs's condition (sufficiently general for real-world dynamical systems), the same Q-function can be utilized as an approximate solution of both minimax and maximin Bellman equations. Based on these results, we present the Isaacs Deep Q-Network algorithms and demonstrate their superiority compared to other baseline RRL and Multi-Agent RL algorithms in various environments.""}",https://openreview.net{'value': '/pdf/0ef899174d6f71f0272d31cba9ef4a9de1c6624d.pdf'},{'abstract_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=TfWKkSAziC,{'value': 'LPGD: A General Framework for Backpropagation through Embedded Optimization Layers'},Anselm Paulus; Georg Martius; Vít Musil,~Anselm_Paulus1; ~Georg_Martius1; ~Vít_Musil1,,"{'value': 'Embedding parameterized optimization problems as layers into machine learning architectures serves as a powerful inductive bias. Training such architectures with stochastic gradient descent requires care, as degenerate derivatives of the embedded optimization problem often render the gradients uninformative. We propose Lagrangian Proximal Gradient Descent (LPGD), a flexible framework for training architectures with embedded optimization layers that seamlessly integrates into automatic differentiation libraries. LPGD efficiently computes meaningful replacements of the degenerate optimization layer derivatives by re-running the forward solver oracle on a perturbed input. LPGD captures various previously proposed methods as special cases, while fostering deep links to traditional optimization methods. We theoretically analyze our method and demonstrate on historical and synthetic data that LPGD converges faster than gradient descent even in a differentiable setup.'}",https://openreview.net{'value': '/pdf/f9e3c8fd04f6e05c559a85b2eb573cdac18fd70f.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=TejqrQBvll,"{'value': 'Generalization Bounds for Causal Regression: Insights, Guarantees and Sensitivity Analysis'}",Daniel Csillag; Claudio Jose Struchiner; Guilherme Tegoni Goedert,~Daniel_Csillag1; ~Claudio_Jose_Struchiner1; ~Guilherme_Tegoni_Goedert1,,"{'value': 'Many algorithms have been recently proposed for causal machine learning. Yet, there is little to no theory on their quality, especially considering finite samples. In this work, we propose a theory based on generalization bounds that provides such guarantees. By introducing a novel change-of-measure inequality, we are able to tightly bound the model loss in terms of the deviation of the treatment propensities over the population, which we show can be empirically limited. Our theory is fully rigorous and holds even in the face of hidden confounding and violations of positivity. We demonstrate our bounds on semi-synthetic and real data, showcasing their remarkable tightness and practical utility.'}",https://openreview.net{'value': '/pdf/a4b44f1642f23224e648561d90128eaa765a51a8.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=TTZXl9WYFF,{'value': 'Multi-Agent Reinforcement Learning with Hierarchical Coordination for Emergency Responder Stationing'},Amutheezan Sivagnanam; Ava Pettet; Hunter Lee; Ayan Mukhopadhyay; Abhishek Dubey; Aron Laszka,~Amutheezan_Sivagnanam1; ~Ava_Pettet1; ~Hunter_Lee1; ~Ayan_Mukhopadhyay1; ~Abhishek_Dubey1; ~Aron_Laszka1,,"{'value': 'An emergency responder management (ERM) system dispatches responders, such as ambulances, when it receives requests for medical aid. ERM systems can also proactively reposition responders between predesignated waiting locations to cover any gaps that arise due to the prior dispatch of responders or significant changes in the distribution of anticipated requests. Optimal repositioning is computationally challenging due to the exponential number of ways to allocate responders between locations and the uncertainty in future requests. The state-of-the-art approach in proactive repositioning is a hierarchical approach based on spatial decomposition and online Monte Carlo tree search, which may require minutes of computation for each decision in a domain where seconds can save lives. We address the issue of long decision times by introducing a novel reinforcement learning (RL) approach, based on the same hierarchical decomposition, but replacing online search with learning. To address the computational challenges posed by large, variable-dimensional, and discrete state and action spaces, we propose: (1) actor-critic based agents that incorporate transformers to handle variable-dimensional states and actions, (2) projections to fixed-dimensional observations to handle complex states, and (3) combinatorial techniques to map continuous actions to discrete allocations. We evaluate our approach using real-world data from two U.S. cities, Nashville, TN and Seattle, WA. Our experiments show that compared to the state of the art, our approach reduces computation time per decision by three orders of magnitude, while also slightly reducing average ambulance response time by 5 seconds.'}",https://openreview.net{'value': '/pdf/20b523099603aaa5ed4fea07c3edbbf36e727d08.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=TTYVG17wfc,{'value': 'OSN: Infinite Representations of Dynamic 3D Scenes from Monocular Videos'},Ziyang Song; Jinxi Li; Bo Yang,~Ziyang_Song1; ~Jinxi_Li2; ~Bo_Yang7,,"{'value': 'It has long been challenging to recover the underlying dynamic 3D scene representations from a monocular RGB video. Existing works formulate this problem into finding a single most plausible solution by adding various constraints such as depth priors and strong geometry constraints, ignoring the fact that there could be infinitely many 3D scene representations corresponding to a single dynamic video. In this paper, we aim to learn all plausible 3D scene configurations that match the input video, instead of just inferring a specific one. To achieve this ambitious goal, we introduce a new framework, called OSN. The key to our approach is a simple yet innovative object scale network together with a joint optimization module to learn an accurate scale range for every dynamic 3D object. This allows us to sample as many faithful 3D scene configurations as possible. Extensive experiments show that our method surpasses all baselines and achieves superior accuracy in dynamic novel view synthesis on multiple synthetic and real-world datasets. Most notably, our method demonstrates a clear advantage in learning fine-grained 3D scene geometry.'}",https://openreview.net{'value': '/pdf/60688ce9ab1a3878dfdaa0805fb6534cd31fcf5d.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=TJCUrzhbiH,{'value': 'diff History for Neural Language Agents'},Ulyana Piterbarg; Lerrel Pinto; Rob Fergus,~Ulyana_Piterbarg1; ~Lerrel_Pinto1; ~Rob_Fergus1,,"{'value': 'Neural Language Models (LMs) offer an exciting solution for general-purpose embodied control. However, a key technical issue arises when using an LM-based controller: environment observations must be converted to text, which coupled with history, results in long and verbose textual prompts. As a result, prior work in LM agents is limited to restricted domains with small observation size as well as minimal needs for interaction history or instruction finetuning. In this paper, we introduce diff history, a simple and highly effective solution to these issues. By applying the Unix diff command on consecutive text observations in the interaction histories used to prompt LM policies, we can both abstract away redundant information and focus the content of textual inputs on the salient changes in the environment. On NetHack, an unsolved video game that requires long-horizon reasoning for decision-making, LMs tuned with diff history match state-of-the-art performance for neural agents while needing 1800X fewer training examples compared to prior work. Even on the simpler BabyAI-Text environment with concise text observations, we find that although diff history increases the length of prompts, the representation it provides offers a 25% improvement in the efficiency of low-sample instruction finetuning. Further, we show that diff history scales favorably across different finetuning dataset sizes. We open-source our code and data to https://diffhistory.github.io.'}",https://openreview.net{'value': '/pdf/3272d736eb88d087a8817bf1d85827ec5b8b78af.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=Sz9mAYuqlE,{'value': 'Optimally Improving Cooperative Learning in a Social Setting'},Shahrzad Haddadan; Cheng Xin; Jie Gao,~Shahrzad_Haddadan1; ~Cheng_Xin2; ~Jie_Gao6,,"{'value': 'We consider a cooperative learning scenario where a collection of networked agents with individually owned classifiers dynamically update their predictions, for the same classification task, through communication or observations of each other’s predictions. Clearly if highly influential vertices use erroneous classifiers, there will be a negative effect on the accuracy of all the agents in the network. We ask the following question: how can we optimally fix the prediction of a few classifiers so as maximize the overall accuracy in the entire network. To this end we consider an aggregate and an egalitarian objective function. We show a polynomial time algorithm for optimizing the aggregate objective function, and show that optimizing the egalitarian objective function is NP-hard. Furthermore, we develop approximation algorithms for the egalitarian improvement. The performance of all of our algorithms are guaranteed by mathematical analysis and backed by experiments on synthetic and real data.'}",https://openreview.net{'value': '/pdf/8de2e5e7219a47e92934c5d310e4d0d5f6233dc9.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=SvBLKoBL4q,{'value': 'MLI Formula: A Nearly Scale-Invariant Solution with Noise Perturbation'},Bowen Tao; Xin-Chun Li; De-Chuan Zhan,~Bowen_Tao1; ~Xin-Chun_Li1; ~De-Chuan_Zhan1,,"{'value': 'Monotonic Linear Interpolation (MLI) refers to the peculiar phenomenon that the error between the initial and converged model monotonically decreases along the linear interpolation, i.e., $(1-\\alpha)\\boldsymbol{\\theta}_0 + \\alpha \\boldsymbol{\\theta}_F$. Previous works focus on paired initial and converged points, relating MLI to the smoothness of the optimization trajectory. In this paper, we find a shocking fact that the error curves still exhibit a monotonic decrease when $\\boldsymbol{\\theta}_0$ is replaced with noise or even zero values, implying that the decreasing curve may be primarily related to the property of the converged model rather than the optimization trajectory. We further explore the relationship between $\\alpha\\boldsymbol{\\theta}_F$ and $\\boldsymbol{\\theta}_F$ and propose scale invariance properties in various cases, including Generalized Scale Invariance (GSI), Rectified Scale Invariance (RSI), and Normalized Scale Invariance (NSI). From an inverse perspective, the MLI formula is essentially an equation that adds varying levels of noise (i.e., $(1-\\alpha)\\boldsymbol{\\epsilon}$) to a nearly scale-invariant network (i.e., $\\alpha \\boldsymbol{\\theta}_F$), resulting in a monotonically increasing error as the noise level rises. MLI is a special case where $\\boldsymbol{\\epsilon}$ is equal to $\\boldsymbol{\\theta}_0$.'}",https://openreview.net{'value': '/pdf/eae82fce6857c58c2d42d90a65d32adcf35c3ce7.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2024,Conference
https://openreview.net/forum?id=Stn8hXkpe6,"{'value': 'ReMax: A Simple, Effective, and Efficient Reinforcement Learning Method for Aligning Large Language Models'}",Ziniu Li; Tian Xu; Yushun Zhang; Zhihang Lin; Yang Yu; Ruoyu Sun; Zhi-Quan Luo,~Ziniu_Li1; ~Tian_Xu2; ~Yushun_Zhang1; ~Zhihang_Lin2; ~Yang_Yu5; ~Ruoyu_Sun1; ~Zhi-Quan_Luo1,,"{'value': 'Reinforcement Learning from Human Feedback (RLHF) is key to aligning Large Language Models (LLMs), typically paired with the Proximal Policy Optimization (PPO) algorithm. While PPO is a powerful method designed for general reinforcement learning tasks, it is overly sophisticated for LLMs, leading to laborious hyper-parameter tuning and significant computation burdens. To make RLHF efficient, we present ReMax, which leverages 3 properties of RLHF: fast simulation, deterministic transitions, and trajectory-level rewards. These properties are not exploited in PPO, making it less suitable for RLHF. Building on the renowned REINFORCE algorithm, ReMax does not require training an additional value model as in PPO and is further enhanced with a new variance reduction technique. ReMax offers several benefits over PPO: it is simpler to implement, eliminates more than 4 hyper-parameters in PPO, reduces GPU memory usage, and shortens training time. ReMax can save about 46% GPU memory than PPO when training a 7B model and enables training on A800-80GB GPUs without the memory-saving offloading technique needed by PPO. Applying ReMax to a Mistral-7B model resulted in a 94.78% win rate on the AlpacaEval leaderboard and a 7.739 score on MT-bench, setting a new SOTA for open-source 7B models. These results show the effectiveness of ReMax while addressing the limitations of PPO in LLMs.'}",https://openreview.net{'value': '/pdf/4a747e13ce84916704cdbf6cb312e8e97e17a4a6.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2024,Conference
https://openreview.net/forum?id=SoqxSnEUi1,{'value': 'Mastering Zero-Shot Interactions in Cooperative and Competitive Simultaneous Games'},Yannik Mahlau; Frederik Schubert; Bodo Rosenhahn,~Yannik_Mahlau1; ~Frederik_Schubert1; ~Bodo_Rosenhahn1,,"{'value': 'The combination of self-play and planning has achieved great successes in sequential games, for instance in Chess and Go. However, adapting algorithms such as AlphaZero to simultaneous games poses a new challenge. In these games, missing information about concurrent actions of other agents is a limiting factor as they may select different Nash equilibria or do not play optimally at all. Thus, it is vital to model the behavior of the other agents when interacting with them in simultaneous games. To this end, we propose Albatross: AlphaZero for Learning Bounded-rational Agents and Temperature-based Response Optimization using Simulated Self-play. Albatross learns to play the novel equilibrium concept of a Smooth Best Response Logit Equilibrium (SBRLE), which enables cooperation and competition with agents of any playing strength. We perform an extensive evaluation of Albatross on a set of cooperative and competitive simultaneous perfect-information games. In contrast to AlphaZero, Albatross is able to exploit weak agents in the competitive game of Battlesnake. Additionally, it yields an improvement of 37.6% compared to previous state of the art in the cooperative Overcooked benchmark.'}",https://openreview.net{'value': '/pdf/f8e23e9f4afd6d32b45370e761559201d5b7cbdb.pdf'},{'abstract_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=Sjv5RcqfuH,{'value': 'GATE: How to Keep Out Intrusive Neighbors'},Nimrah Mustafa; Rebekka Burkholz,~Nimrah_Mustafa1; ~Rebekka_Burkholz1,,"{'value': ""Graph Attention Networks (GATs) are designed to provide flexible neighborhood aggregation that assigns weights to neighbors according to their importance. In practice, however, GATs are often unable to switch off task-irrelevant neighborhood aggregation, as we show experimentally and analytically. To address this challenge, we propose GATE, a GAT extension that holds three major advantages: i) It alleviates over-smoothing by addressing its root cause of unnecessary neighborhood aggregation. ii) Similarly to perceptrons, it benefits from higher depth as it can still utilize additional layers for (non-)linear feature transformations in case of (nearly) switched-off neighborhood aggregation. iii) By down-weighting connections to unrelated neighbors, it often outperforms GATs on real-world heterophilic datasets. To further validate our claims, we construct a synthetic test bed to analyze a model's ability to utilize the appropriate amount of neighborhood aggregation, which could be of independent interest.""}",https://openreview.net{'value': '/pdf/e54cba5abe90455f67d24b21903db6ebec208ed9.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=SQIDlJd3hN,{'value': 'RoboGen: Towards Unleashing Infinite Data for Automated Robot Learning via Generative Simulation'},Yufei Wang; Zhou Xian; Feng Chen; Tsun-Hsuan Wang; Yian Wang; Katerina Fragkiadaki; Zackory Erickson; David Held; Chuang Gan,~Yufei_Wang4; ~Zhou_Xian1; ~Feng_Chen16; ~Tsun-Hsuan_Wang2; ~Yian_Wang1; ~Katerina_Fragkiadaki1; ~Zackory_Erickson1; ~David_Held1; ~Chuang_Gan1,,"{'value': 'We present RoboGen, a generative robotic agent that automatically learns diverse robotic skills at scale via generative simulation. RoboGen leverages the latest advancements in foundation and generative models. Instead of directly adapting these models to produce policies or low-level actions, we advocate for a generative scheme, which uses these models to automatically generate diversified tasks, scenes, and training supervisions, thereby scaling up robotic skill learning with minimal human supervision. Our approach equips a robotic agent with a self-guided propose-generate-learn cycle: the agent first proposes interesting tasks and skills to develop, and then generates simulation environments by populating pertinent assets with proper spatial configurations. Afterwards, the agent decomposes the proposed task into sub-tasks, selects the optimal learning approach (reinforcement learning, motion planning, or trajectory optimization), generates required training supervision, and then learns policies to acquire the proposed skill. Our fully generative pipeline can be queried repeatedly, producing an endless stream of skill demonstrations associated with diverse tasks and environments.'}",https://openreview.net{'value': '/pdf/1475e7232cd7c484bed60587c83c2040626987e5.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2024,Conference
https://openreview.net/forum?id=SLqdDWwibH,{'value': 'Few-Shot Unsupervised Implicit Neural Shape Representation Learning with Spatial Adversaries'},Amine Ouasfi; Adnane Boukhayma,~Amine_Ouasfi1; ~Adnane_Boukhayma2,,"{'value': 'Implicit Neural Representations have gained prominence as a powerful framework for capturing complex data modalities, encompassing a wide range from 3D shapes to images and audio. Within the realm of 3D shape representation, Neural Signed Distance Functions (SDF) have demonstrated remarkable potential in faithfully encoding intricate shape geometry. However, learning SDFs from sparse 3D point clouds in the absence of ground truth supervision remains a very challenging task. While recent methods rely on smoothness priors to regularize the learning, our method introduces a regularization term that leverages adversarial samples around the shape to improve the learned SDFs. Through extensive experiments and evaluations, we illustrate the efficacy of our proposed method, highlighting its capacity to improve SDF learning with respect to baselines and the state-of-the-art using synthetic and real data.'}",https://openreview.net{'value': '/pdf/905ba1020c506ee804e75a6900c96496de99d5c7.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=SAbL40d8A4,{'value': 'Winner-takes-all learners are geometry-aware conditional density estimators'},Victor Letzelter; David Perera; Cédric Rommel; Mathieu Fontaine; Slim Essid; Gaël Richard; Patrick Perez,~Victor_Letzelter1; david.perera@telecom-paris.fr; ~Cédric_Rommel1; ~Mathieu_Fontaine1; ~Slim_Essid1; ~Gaël_Richard1; ~Patrick_Perez1,,"{'value': 'Winner-takes-all training is a simple learning paradigm, which handles ambiguous tasks by predicting a set of plausible hypotheses. Recently, a connection was established between Winner-takes-all training and centroidal Voronoi tessellations, showing that, once trained, hypotheses should quantize optimally the shape of the conditional distribution to predict. However, the best use of these hypotheses for uncertainty quantification is still an open question. In this work, we show how to leverage the appealing geometric properties of the Winner-takes-all learners for conditional density estimation, without modifying its original training scheme. We theoretically establish the advantages of our novel estimator both in terms of quantization and density estimation, and we demonstrate its competitiveness on synthetic and real-world datasets, including audio data.'}",https://openreview.net{'value': '/pdf/921d1ad69af9654ee6a45bbf099e10add389f4c1.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=RbnojVv4HK,{'value': 'Ameliorate Spurious Correlations in Dataset Condensation'},Justin Cui; Ruochen Wang; Yuanhao Xiong; Cho-Jui Hsieh,~Justin_Cui1; ~Ruochen_Wang2; ~Yuanhao_Xiong1; ~Cho-Jui_Hsieh1,,"{'value': 'Dataset Condensation has emerged as a technique for compressing large datasets into smaller synthetic counterparts, facilitating downstream training tasks. In this paper, we study the impact of bias inside the original dataset on the performance of dataset condensation. With a comprehensive empirical evaluation on canonical datasets with color, corruption and background biases, we found that color and background biases in the original dataset will be amplified through the condensation process, resulting in a notable decline in the performance of models trained on the condensed dataset, while corruption bias is suppressed through the condensation process. To reduce bias amplification in dataset condensation, we introduce a simple yet highly effective approach based on a sample reweighting scheme utilizing kernel density estimation. Empirical results on multiple real-world and synthetic datasets demonstrate the effectiveness of the proposed method. Notably, on CMNIST with 5% bias-conflict ratio and IPC 50, our method achieves 91.5% test accuracy compared to 23.8% from vanilla DM, boosting the performance by 67.7%, whereas applying state-of-the-art debiasing method on the same dataset only achieves 53.7% accuracy. Our findings highlight the importance of addressing biases in dataset condensation and provide a promising avenue to address bias amplification in the process.'}",https://openreview.net{'value': '/pdf/ccbc9f68e601090a82cfcfbc5df2a136e9b8ab71.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=Qc5umSsUi8,{'value': 'Scalable Safe Policy Improvement for Factored Multi-Agent MDPs'},Federico Bianchi; Edoardo Zorzi; Alberto Castellini; Thiago D. Simão; Matthijs T. J. Spaan; Alessandro Farinelli,~Federico_Bianchi2; ~Edoardo_Zorzi1; ~Alberto_Castellini1; ~Thiago_D._Simão1; ~Matthijs_T._J._Spaan1; ~Alessandro_Farinelli1,,"{'value': 'In this work, we focus on safe policy improvement in multi-agent domains where current state-of-the-art methods cannot be effectively applied because of large state and action spaces. We consider recent results using Monte Carlo Tree Search for Safe Policy Improvement with Baseline Bootstrapping and propose a novel algorithm that scales this approach to multi-agent domains, exploiting the factorization of the transition model and value function. Given a centralized behavior policy and a dataset of trajectories, our algorithm generates an improved policy by selecting joint actions using a novel extension of Max-Plus (or Variable Elimination) that constrains local actions to guarantee safety criteria. An empirical evaluation on multi-agent SysAdmin and multi-UAV Delivery shows that the approach scales to very large domains where state-of-the-art methods cannot work.'}",https://openreview.net{'value': '/pdf/29655be18ba6a7710bcff110a811df3d786b6840.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=QMy2RLnxGN,{'value': 'DoraemonGPT: Toward Understanding Dynamic Scenes with Large Language Models (Exemplified as A Video Agent)'},Zongxin Yang; Guikun Chen; Xiaodi Li; Wenguan Wang; Yi Yang,~Zongxin_Yang1; ~Guikun_Chen1; ~Xiaodi_Li2; ~Wenguan_Wang4; ~Yi_Yang4,,"{'value': ""Recent LLM-driven visual agents mainly focus on solving image-based tasks, which limits their ability to understand dynamic scenes, making it far from real-life applications like guiding students in laboratory experiments and identifying their mistakes. Hence, this paper explores DoraemonGPT, a comprehensive and conceptually elegant system driven by LLMs to understand dynamic scenes. Considering the video modality better reflects the ever-changing nature of real-world scenarios, we exemplify DoraemonGPT as a video agent. Given a video with a question/task, DoraemonGPT begins by converting the input video into a symbolic memory that stores task-related attributes. This structured representation allows for spatial-temporal querying and reasoning by well-designed sub-task tools, resulting in concise intermediate results. Recognizing that LLMs have limited internal knowledge when it comes to specialized domains (e.g., analyzing the scientific principles underlying experiments), we incorporate plug-and-play tools to assess external knowledge and address tasks across different domains. Moreover, a novel LLM-driven planner based on Monte Carlo Tree Search is introduced to explore the large planning space for scheduling various tools. The planner iteratively finds feasible solutions by backpropagating the result's reward, and multiple solutions can be summarized into an improved final answer. We extensively evaluate DoraemonGPT's effectiveness on three benchmarks and several in-the-wild scenarios. Project page: https://z-x-yang.github.io/doraemon-gpt.""}",https://openreview.net{'value': '/pdf/c7d192d5108239568733dfb6fab72c04ea1e1d1b.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=PKdege0U6Z,{'value': 'Graph Mixup on Approximate Gromov–Wasserstein Geodesics'},Zhichen Zeng; Ruizhong Qiu; Zhe Xu; Zhining Liu; Yuchen Yan; Tianxin Wei; Lei Ying; Jingrui He; Hanghang Tong,~Zhichen_Zeng1; ~Ruizhong_Qiu1; ~Zhe_Xu5; ~Zhining_Liu1; ~Yuchen_Yan1; ~Tianxin_Wei1; ~Lei_Ying1; ~Jingrui_He1; ~Hanghang_Tong3,,"{'value': 'Mixup, which generates synthetic training samples on the data manifold, has been shown to be highly effective in augmenting Euclidean data. However, finding a proper data manifold for graph data is non-trivial, as graphs are non-Euclidean data in disparate spaces. Though efforts have been made, most of the existing graph mixup methods neglect the intrinsic geodesic guarantee, thereby generating inconsistent sample-label pairs. To address this issue, we propose GeoMix to mixup graphs on the Gromov-Wasserstein (GW) geodesics. A joint space over input graphs is first defined based on the GW distance, and graphs are then transformed into the GW space through equivalence-preserving transformations. We further show that the linear interpolation of the transformed graph pairs defines a geodesic connecting the original pairs on the GW manifold, hence ensuring the consistency between generated samples and labels. An accelerated mixup algorithm on the approximate low-dimensional GW manifold is further proposed. Extensive experiments show that the proposed GeoMix promotes the generalization and robustness of GNN models.'}",https://openreview.net{'value': '/pdf/46110df2326f57ce21d93d48d3578fa61c144a89.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=PDUQRBPkks,{'value': 'Distributed High-Dimensional Quantile Regression: Estimation Efficiency and Support Recovery'},Caixing Wang; Ziliang Shen,~Caixing_Wang1; ~Ziliang_Shen1,,"{'value': 'In this paper, we focus on distributed estimation and support recovery for high-dimensional linear quantile regression. Quantile regression is a popular alternative tool to the least squares regression for robustness against outliers and data heterogeneity. However, the non-smoothness of the check loss function poses big challenges to both computation and theory in the distributed setting. To tackle these problems, we transform the original quantile regression into the least-squares optimization. By applying a double-smoothing approach, we extend a previous Newton-type distributed approach without the restrictive independent assumption between the error term and covariates. An efficient algorithm is developed, which enjoys high computation and communication efficiency. Theoretically, the proposed distributed estimator achieves a near-oracle convergence rate and high support recovery accuracy after a constant number of iterations. Extensive experiments on synthetic examples and a real data application further demonstrate the effectiveness of the proposed method.'}",https://openreview.net{'value': '/pdf/4c72f31482a1d5e88930c0c90cd836e74c8a4c73.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=PApqOVbHYF,{'value': 'Bootstrapping Fisher Market Equilibrium and First-Price Pacing Equilibrium'},Luofeng Liao; Christian Kroer,~Luofeng_Liao1; ~Christian_Kroer1,,"{'value': 'Linear Fisher market (LFM) is an equilibrium model for fair and efficient resource allocation, and first-price pacing equilibrium (FPPE) is a model for budget-management in first-price auctions. One thing they have in common is that both have a corresponding Eisenberg-Gale convex program characterization. In this paper, we introduce and devise several statistically valid bootstrap inference procedures for LFM and FPPE. The most challenging part is to bootstrap general FPPE, which reduces to bootstrapping constrained M-estimators, a largely unexplored problem. We are able to devise a bootstrap procedure for FPPE with structures by using the powerful tool of epi-convergence theory. Experiments with synthetic and semi-real data verify our theory.'}",https://openreview.net{'value': '/pdf/0e390eb27fabf7d5087b95d19df302af2a2b17a2.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=PAbkWU0KDG,{'value': 'Limited Preference Aided Imitation Learning from Imperfect Demonstrations'},Xingchen Cao; Fan-Ming Luo; Junyin Ye; Tian Xu; Zhilong Zhang; Yang Yu,~Xingchen_Cao1; ~Fan-Ming_Luo1; ~Junyin_Ye1; ~Tian_Xu2; ~Zhilong_Zhang2; ~Yang_Yu5,,"{'value': 'Imitation learning mimics high-quality policies from expert data for sequential decision-making tasks. However, its efficacy is hindered in scenarios where optimal demonstrations are unavailable, and only imperfect demonstrations are present. To address this issue, introducing additional limited human preferences is a suitable approach as it can be obtained in a human-friendly manner, offering a promising way to learn the policy that exceeds the performance of imperfect demonstrations. In this paper, we propose a novel imitation learning (IL) algorithm, **P**reference **A**ided **I**mitation **L**earning from imperfect demonstrations (PAIL). Specifically, PAIL learns a preference reward by querying experts for limited preferences from imperfect demonstrations. This serves two purposes during training: 1) Reweighting imperfect demonstrations with the preference reward for higher quality. 2) Selecting explored trajectories with high cumulative preference rewards to augment imperfect demonstrations. The dataset with continuously improving quality empowers the performance of PAIL to transcend the initial demonstrations. Comprehensive empirical results across a synthetic task and two locomotion benchmarks show that PAIL surpasses baselines by **73.2%** and breaks through the performance bottleneck of imperfect demonstrations.'}",https://openreview.net{'value': '/pdf/45ba26a7afa6aa3d14bf961181d876b89f9f4b8c.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=Olix9pk6nV,{'value': 'A Unified Linear Programming Framework for Offline Reward Learning from Human Demonstrations and Feedback'},Kihyun Kim; Jiawei Zhang; Asuman E. Ozdaglar; Pablo Parrilo,~Kihyun_Kim1; ~Jiawei_Zhang6; ~Asuman_E._Ozdaglar1; ~Pablo_Parrilo1,,"{'value': 'Inverse Reinforcement Learning (IRL) and Reinforcement Learning from Human Feedback (RLHF) are pivotal methodologies in reward learning, which involve inferring and shaping the underlying reward function of sequential decision-making problems based on observed human demonstrations and feedback. Most prior work in reward learning has relied on prior knowledge or assumptions about decision or preference models, potentially leading to robustness issues. In response, this paper introduces a novel linear programming (LP) framework tailored for offline reward learning. Utilizing pre-collected trajectories without online exploration, this framework estimates a feasible reward set from the primal-dual optimality conditions of a suitably designed LP, and offers an optimality guarantee with provable sample efficiency. Our LP framework also enables aligning the reward functions with human feedback, such as pairwise trajectory comparison data, while maintaining computational tractability and sample efficiency. We demonstrate that our framework potentially achieves better performance compared to the conventional maximum likelihood estimation (MLE) approach through analytical examples and numerical experiments.'}",https://openreview.net{'value': '/pdf/e6d5cb22657fcf4ee6af3b83715fa0bfe41a6078.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2024,Conference
https://openreview.net/forum?id=OTmcsyEO5G,{'value': 'A Human-Inspired Reading Agent with Gist Memory of Very Long Contexts'},Kuang-Huei Lee; Xinyun Chen; Hiroki Furuta; John Canny; Ian Fischer,~Kuang-Huei_Lee1; ~Xinyun_Chen1; ~Hiroki_Furuta1; ~John_Canny1; ~Ian_Fischer1,,"{'value': 'Current Large Language Models (LLMs) are not only limited to some maximum context length, but also are not able to robustly consume long inputs. To address these limitations, we propose ReadAgent, an LLM agent system that increases effective context length up to 20x in our experiments. Inspired by how humans interactively read long documents, we implement ReadAgent as a simple prompting system that uses the advanced language capabilities of LLMs to (1) decide what content to store together in a memory episode, (2) compress those memory episodes into short episodic memories called *gist memories*, and (3) take actions to look up passages in the original text if ReadAgent needs to remind itself of relevant details to complete a task. We evaluate ReadAgent against baselines using retrieval methods, using the original long contexts, and using the gist memories. These evaluations are performed on three long-document reading comprehension tasks: QuALITY, NarrativeQA, and QMSum. ReadAgent outperforms the baselines on all three tasks while extending the effective context window by 3.5-20x.'}",https://openreview.net{'value': '/pdf/9814839ef5d206960fc07b5cb39f1724cfcd4a59.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=OQ7TlOphGX,{'value': 'Enhancing Trajectory Prediction through Self-Supervised Waypoint Distortion Prediction'},Pranav singh chib; Pravendra Singh,~Pranav_singh_chib1; ~Pravendra_Singh1,,"{'value': 'Trajectory prediction is an important task that involves modeling the indeterminate nature of agents to forecast future trajectories given the observed trajectory sequences. The task of predicting trajectories poses significant challenges, as agents not only move individually through time but also interact spatially. The learning of complex spatio-temporal representations stands as a fundamental challenge in trajectory prediction. To this end, we propose a novel approach called SSWDP (Self-Supervised Waypoint Distortion Prediction). We propose a simple yet highly effective self-supervised task of predicting distortion present in the observed trajectories to improve the representation learning of the model. Our approach can complement existing trajectory prediction methods. The experimental results highlight a significant improvement with relative percentage differences of 22.7%/38.9%, 33.8%/36.4%, and 16.60%/23.20% in ADE/FDE for the NBA, TrajNet++, and ETH-UCY datasets, respectively, compared to the baseline methods. Our approach also demonstrates a significant improvement over baseline methods with relative percentage differences of 76.8%/82.5% and 61.0%/36.1% in ADE/FDE for TrajNet++ and NBA datasets in distorted environments, respectively.'}",https://openreview.net{'value': '/pdf/6f5199a867ae97c4ee3f4303b1afe90f767d9d65.pdf'},{'title_filter': 'Trajectory'},ICML.cc,2024,Conference
https://openreview.net/forum?id=OF7e0w1uon,{'value': 'Q-Star Meets Scalable Posterior Sampling: Bridging Theory and Practice via HyperAgent'},Yingru Li; Jiawei Xu; Lei Han; Zhi-Quan Luo,~Yingru_Li1; ~Jiawei_Xu1; ~Lei_Han1; ~Zhi-Quan_Luo1,,"{'value': 'We propose HyperAgent, a reinforcement learning (RL) algorithm based on the hypermodel framework for exploration in RL. HyperAgent allows for the efficient incremental approximation of posteriors associated with an optimal action-value function ($Q^\\star$) without the need for conjugacy and follows the greedy policies w.r.t. these approximate posterior samples. We demonstrate that HyperAgent offers robust performance in large-scale deep RL benchmarks. It can solve Deep Sea hard exploration problems with episodes that optimally scale with problem size and exhibits significant efficiency gains in the Atari suite. Implementing HyperAgent requires minimal code addition to well-established deep RL frameworks like DQN. We theoretically prove that, under tabular assumptions, HyperAgent achieves logarithmic per-step computational complexity while attaining sublinear regret, matching the best known randomized tabular RL algorithm.'}",https://openreview.net{'value': '/pdf/21d1bbc8276fc96c77ad2ea600b16c1dfcd198ab.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=O8rrXl71D5,{'value': 'What needs to go right for an induction head? A mechanistic study of in-context learning circuits and their formation'},Aaditya K Singh; Ted Moskovitz; Felix Hill; Stephanie C.Y. Chan; Andrew M Saxe,~Aaditya_K_Singh1; ~Ted_Moskovitz1; ~Felix_Hill1; ~Stephanie_C.Y._Chan1; ~Andrew_M_Saxe1,,"{'value': 'In-context learning is a powerful emergent ability in transformer models. Prior work in mechanistic interpretability has identified a circuit element that may be critical for in-context learning – the induction head (IH), which performs a match-and-copy operation. During training of large transformers on natural language data, IHs emerge around the same time as a notable phase change in the loss. Despite the robust evidence for IHs and this interesting coincidence with the phase change, relatively little is known about the diversity and emergence dynamics of IHs. Why is there more than one IH, and how are they dependent on each other? Why do IHs appear all of a sudden, and what are the subcircuits that enable them to emerge? We answer these questions by studying IH emergence dynamics in a controlled setting by training on synthetic data. In doing so, we develop and share a novel optogenetics-inspired causal framework for modifying activations throughout training. Using this framework, we delineate the diverse and additive nature of IHs. By ""clamping"" subsets of activations throughout training, we then identify three underlying subcircuits that interact to drive IH formation, yielding the phase change. Furthermore, these subcircuits shed light on data-dependent properties of formation, such as phase change timing, already showing the promise of this more in-depth understanding of subcircuits that need to ""go right"" for an induction head.'}",https://openreview.net{'value': '/pdf/c15a621012a73fd6668c7e826df5e3a1f4ca7e2b.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=NbYAmsFJrc,{'value': 'Resisting Stochastic Risks in Diffusion Planners with the Trajectory Aggregation Tree'},Lang Feng; Pengjie Gu; Bo An; Gang Pan,~Lang_Feng1; ~Pengjie_Gu1; ~Bo_An2; ~Gang_Pan1,,"{'value': ""Diffusion planners have shown promise in handling long-horizon and sparse-reward tasks due to the non-autoregressive plan generation. However, their inherent stochastic risk of generating infeasible trajectories presents significant challenges to their reliability and stability. We introduce a novel approach, the Trajectory Aggregation Tree (TAT), to address this issue in diffusion planners. Compared to prior methods that rely solely on raw trajectory predictions, TAT aggregates information from both historical and current trajectories, forming a dynamic tree-like structure. Each trajectory is conceptualized as a branch and individual states as nodes. As the structure evolves with the integration of new trajectories, unreliable states are marginalized, and the most impactful nodes are prioritized for decision-making. TAT can be deployed without modifying the original training and sampling pipelines of diffusion planners, making it a training-free, ready-to-deploy solution. We provide both theoretical analysis and empirical evidence to support TAT's effectiveness. Our results highlight its remarkable ability to resist the risk from unreliable trajectories, guarantee the performance boosting of diffusion planners in 100% of tasks, and exhibit an appreciable tolerance margin for sample quality, thereby enabling planning with a more than $3\\times$ acceleration.""}",https://openreview.net{'value': '/pdf/6accfd93076547ce75e78b36ede20946331573ca.pdf'},{'title_filter': 'Trajectory'},ICML.cc,2024,Conference
https://openreview.net/forum?id=MurkwIl0h3,{'value': 'Balancing Feature Similarity and Label Variability for Optimal Size-Aware One-shot Subset Selection'},Abhinab Acharya; Dayou Yu; Qi Yu; Xumin Liu,~Abhinab_Acharya1; ~Dayou_Yu1; ~Qi_Yu1; ~Xumin_Liu1,,"{'value': 'Subset or core-set selection offers a data-efficient way for training deep learning models. One-shot subset selection poses additional challenges as subset selection is only performed once and full set data become unavailable after the selection. However, most existing methods tend to choose either diverse or difficult data samples, which fail to faithfully represent the joint data distribution that is comprised of both feature and label information. The selection is also performed independently from the subset size, which plays an essential role in choosing what types of samples. To address this critical gap, we propose to conduct Feature similarity and Label variability Balanced One-shot Subset Selection (BOSS), aiming to construct an optimal size-aware subset for data-efficient deep learning. We show that a novel balanced core-set loss bound theoretically justifies the need to simultaneously consider both diversity and difficulty to form an optimal subset. It also reveals how the subset size influences the bound. We further connect the inaccessible bound to a practical surrogate target which is tailored to subset sizes and varying levels of overall difficulty. We design a novel Beta-scoring importance function to delicately control the optimal balance of diversity and difficulty. Comprehensive experiments conducted on both synthetic and real data justify the important theoretical properties and demonstrate the superior performance of BOSS as compared with the competitive baselines.'}",https://openreview.net{'value': '/pdf/9a2022a17f16906eb862f26acfcd8649d21f71b0.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=MmZJ3kJXjX,{'value': 'What Would Gauss Say About Representations? Probing Pretrained Image Models using Synthetic Gaussian Benchmarks'},Ching-Yun Ko; Pin-Yu Chen; Payel Das; Jeet Mohapatra; Luca Daniel,~Ching-Yun_Ko1; ~Pin-Yu_Chen1; ~Payel_Das1; ~Jeet_Mohapatra1; ~Luca_Daniel1,,"{'value': 'Recent years have witnessed a paradigm shift in deep learning from task-centric model design to task-agnostic representation learning and task-specific fine-tuning. Pretrained model representations are commonly evaluated extensively across various real-world tasks and used as a foundation for different downstream tasks. This paper proposes a solution for assessing the quality of representations in a task-agnostic way. To circumvent the need for real-world data in evaluation, we explore the use of synthetic binary classification tasks with Gaussian mixtures to probe pretrained models and compare the robustness-accuracy performance on pretrained representations with an idealized reference. Our approach offers a holistic evaluation, revealing intrinsic model capabilities and reducing the dependency on real-life data for model evaluation. Evaluated with various pretrained image models, the experimental results confirm that our task-agnostic evaluation correlates with actual linear probing performance on downstream tasks and can also guide parameter choice in robust linear probing to achieve a better robustness-accuracy trade-off.'}",https://openreview.net{'value': '/pdf/be048a398a3c516485a2d34f23ba54b8334281b2.pdf'},{'title_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=MWTicAxmRP,{'value': 'Optimistic Multi-Agent Policy Gradient'},Wenshuai Zhao; Yi Zhao; Zhiyuan Li; Juho Kannala; Joni Pajarinen,~Wenshuai_Zhao1; ~Yi_Zhao6; ~Zhiyuan_Li9; ~Juho_Kannala5; ~Joni_Pajarinen2,,"{'value': '*Relative overgeneralization* (RO) occurs in cooperative multi-agent learning tasks when agents converge towards a suboptimal joint policy due to overfitting to suboptimal behaviors of other agents. No methods have been proposed for addressing RO in multi-agent policy gradient (MAPG) methods although these methods produce state-of-the-art results. To address this gap, we propose a general, yet simple, framework to enable optimistic updates in MAPG methods that alleviate the RO problem. Our approach involves clipping the advantage to eliminate negative values, thereby facilitating optimistic updates in MAPG. The optimism prevents individual agents from quickly converging to a local optimum. Additionally, we provide a formal analysis to show that the proposed method retains optimality at a fixed point. In extensive evaluations on a diverse set of tasks including the *Multi-agent MuJoCo* and *Overcooked* benchmarks, our method outperforms strong baselines on 13 out of 19 tested tasks and matches the performance on the rest.'}",https://openreview.net{'value': '/pdf/c02389af5493a9a921df511ad2e73451f52e65af.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=MGkeWJxQVl,"{'value': 'Reason for Future, Act for Now: A Principled Architecture for Autonomous LLM Agents'}",Zhihan Liu; Hao Hu; Shenao Zhang; Hongyi Guo; Shuqi Ke; Boyi Liu; Zhaoran Wang,~Zhihan_Liu1; ~Hao_Hu3; ~Shenao_Zhang1; ~Hongyi_Guo1; ~Shuqi_Ke1; ~Boyi_Liu1; ~Zhaoran_Wang1,,"{'value': 'Large language models (LLMs) demonstrate impressive reasoning abilities, but translating reasoning into actions in the real world remains challenging. In particular, it is unclear how to complete a given task provably within a minimum number of interactions with the external environment, e.g., through an internal mechanism of reasoning. To this end, we propose the first framework with provable regret guarantees to orchestrate reasoning and acting, which we call *reason for future, act for now* (**RAFA**). Specifically, we design a prompt template for reasoning that learns from the memory buffer and plans a future trajectory over a long horizon (*reason for future*). At each step, the LLM agent takes the initial action of the planned trajectory (*act for now*), stores the collected feedback in the memory buffer, and reinvokes the reasoning routine to replan the future trajectory from the new state. The key idea is to cast reasoning in LLMs as learning and planning in Bayesian adaptive Markov decision processes (MDPs). Correspondingly, we prompt LLMs with the memory buffer to estimate the unknown environment (learning) and generate an optimal trajectory for multiple future steps that maximize a value function (planning). The learning and planning subroutines are performed in an in-context manner to emulate the actor-critic update for MDPs. Our theoretical analysis establishes a $\\sqrt{T}$ regret, while our experimental validation demonstrates superior empirical performance.'}",https://openreview.net{'value': '/pdf/a70da518194158ed07a24ece4c37dfa9764b01df.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=M4Htd52HMH,{'value': 'Embodied CoT Distillation From LLM To Off-the-shelf Agents'},Wonje Choi; Woo Kyung Kim; Minjong Yoo; Honguk Woo,~Wonje_Choi2; ~Woo_Kyung_Kim1; ~Minjong_Yoo2; ~Honguk_Woo1,,"{'value': 'We address the challenge of utilizing large language models (LLMs) for complex embodied tasks, in the environment where decision-making systems operate timely on capacity-limited, off-the-shelf devices. We present DeDer, a framework for decomposing and distilling the embodied reasoning capabilities from LLMs to efficient, small language model (sLM)-based policies. In DeDer, the decision-making process of LLM-based strategies is restructured into a hierarchy with a reasoning-policy and planning-policy. The reasoning-policy is distilled from the data that is generated through the embodied in-context learning and self-verification of an LLM, so it can produce effective rationales. The planning-policy, guided by the rationales, can render optimized plans efficiently. In turn, DeDer allows for adopting sLMs for both policies, deployed on off-the-shelf devices. Furthermore, to enhance the quality of intermediate rationales, specific to embodied tasks, we devise the embodied knowledge graph, and to generate multiple rationales timely through a single inference, we also use the contrastively prompted attention model. Our experiments with the ALFRED benchmark demonstrate that DeDer surpasses leading language planning and distillation approaches, indicating the applicability and efficiency of sLM-based embodied policies derived through DeDer.'}",https://openreview.net{'value': '/pdf/4d395cf5c651f46c1b5123f8a7fceaf0400fd638.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=M3qRRkOuTN,{'value': 'Sequential Asynchronous Action Coordination in Multi-Agent Systems: A Stackelberg Decision Transformer Approach'},Bin Zhang; Hangyu Mao; Lijuan Li; Zhiwei Xu; Dapeng Li; Rui Zhao; Guoliang Fan,~Bin_Zhang12; ~Hangyu_Mao2; ~Lijuan_Li2; ~Zhiwei_Xu3; ~Dapeng_Li2; ~Rui_Zhao6; ~Guoliang_Fan3,,"{'value': 'Asynchronous action coordination presents a pervasive challenge in Multi-Agent Systems (MAS), which can be represented as a Stackelberg game (SG). However, the scalability of existing Multi-Agent Reinforcement Learning (MARL) methods based on SG is severely restricted by network architectures or environmental settings. To address this issue, we propose the Stackelberg Decision Transformer (STEER). It efficiently manages decision-making processes by incorporating the hierarchical decision structure of SG, the modeling capability of autoregressive sequence models, and the exploratory learning methodology of MARL. Our approach exhibits broad applicability across diverse task types and environmental configurations in MAS. Experimental results demonstrate both the convergence of our method towards Stackelberg equilibrium strategies and its superiority over strong baselines in complex scenarios.'}",https://openreview.net{'value': '/pdf/c4d831619d41dd1669b79571cecb2c5b1bae290a.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=LuhWZ2oJ5L,{'value': 'S$\\Omega$I: Score-based O-INFORMATION Estimation'},Mustapha BOUNOUA; Giulio Franzese; Pietro Michiardi,~Mustapha_BOUNOUA1; ~Giulio_Franzese1; ~Pietro_Michiardi1,,"{'value': 'The analysis of scientific data and complex multivariate systems requires information quantities that capture relationships among multiple random variables. Recently, new information-theoretic measures have been developed to overcome the shortcomings of classical ones, such as mutual information, that are restricted to considering pairwise interactions. Among them, the concept of information synergy and redundancy is crucial for understanding the high-order dependencies between variables. One of the most prominent and versatile measures based on this concept is *O-information*, which provides a clear and scalable way to quantify the synergy-redundancy balance in multivariate systems. However, its practical application is limited to simplified cases. In this work, we introduce **S$\\Omega$I**, which allows to compute *O-information* without restrictive assumptions about the system while leveraging a unique model. Our experiments validate our approach on synthetic data, and demonstrate the effectiveness of **S$\\Omega$I** in the context of a real-world use case.'}",https://openreview.net{'value': '/pdf/1df7a627ea96a1e02a800762afaeaf6edb6db5ad.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=Ln3moCobjO,{'value': 'Relaxing the Accurate Imputation Assumption in Doubly Robust Learning for Debiased Collaborative Filtering'},Haoxuan Li; Chunyuan Zheng; Shuyi Wang; Kunhan Wu; Eric Wang; Peng Wu; Zhi Geng; Xu Chen; Xiao-Hua Zhou,~Haoxuan_Li6; ~Chunyuan_Zheng1; ~Shuyi_Wang3; ~Kunhan_Wu1; ~Eric_Wang3; ~Peng_Wu5; ~Zhi_Geng1; ~Xu_Chen13; ~Xiao-Hua_Zhou1,,"{'value': 'Recommender system aims to recommend items or information that may interest users based on their behaviors and preferences. However, there may be sampling selection bias in the data collection process, i.e., the collected data is not a representative of the target population. Many debiasing methods are developed based on pseudo-labelings. Nevertheless, the validity of these methods relies heavily on accurate pseudo-labelings (i.e., the imputed labels), which is difficult to satisfy in practice. In this paper, we theoretically propose several novel doubly robust estimators that are unbiased when either (a) the pseudo-labelings deviate from the true labels with an arbitrary user-specific inductive bias, item-specific inductive bias, or a combination of both, or (b) the learned propensities are accurate. We further propose a propensity reconstruction learning approach that adaptively updates the constraint weights using an attention mechanism and effectively controls the variance. Extensive experiments show that our approach outperforms the state-of-the-art on one semi-synthetic and three real-world datasets.'}",https://openreview.net{'value': '/pdf/09b15b7ff4236944230f4e2953820829ee23189e.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=LfJgeBNCFI,{'value': 'DS-Agent: Automated Data Science by Empowering Large Language Models with Case-Based Reasoning'},Siyuan Guo; Cheng Deng; Ying Wen; Hechang Chen; Yi Chang; Jun Wang,~Siyuan_Guo2; ~Cheng_Deng4; ~Ying_Wen1; ~Hechang_Chen2; ~Yi_Chang4; ~Jun_Wang2,,"{'value': 'In this work, we investigate the potential of large language models (LLMs) based agents to automate data science tasks, with the goal of comprehending task requirements, then building and training the best-fit machine learning models. Despite their widespread success, existing LLM agents are hindered by generating unreasonable experiment plans within this scenario. To this end, we present DS-Agent, a novel automatic framework that harnesses LLM agent and case-based reasoning (CBR). In the development stage, DS-Agent follows the CBR framework to structure an automatic iteration pipeline, which can flexibly capitalize on the expert knowledge from Kaggle, and facilitate consistent performance improvement through the feedback mechanism. Moreover, DS-Agent implements a low-resource deployment stage with a simplified CBR paradigm to adapt past successful solutions from the development stage for direct code generation, significantly reducing the demand on foundational capabilities of LLMs. Empirically, DS-Agent with GPT-4 achieves 100% success rate in the development stage, while attaining 36% improvement on average one pass rate across alternative LLMs in the deployment stage. In both stages, DS-Agent achieves the best rank in performance, costing \r\n$1.60 and \\\\$0.13 per run with GPT-4, respectively. Our data and code are open-sourced at https://github.com/guosyjlu/DS-Agent.'}",https://openreview.net{'value': '/pdf/ca6f6e07e47b268198c00cca4b58903bd015c219.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=LWD7upg1ob,{'value': 'Differentially Private Synthetic Data via Foundation Model APIs 2: Text'},Chulin Xie; Zinan Lin; Arturs Backurs; Sivakanth Gopi; Da Yu; Huseyin A Inan; Harsha Nori; Haotian Jiang; Huishuai Zhang; Yin Tat Lee; Bo Li; Sergey Yekhanin,~Chulin_Xie1; ~Zinan_Lin1; ~Arturs_Backurs1; ~Sivakanth_Gopi1; ~Da_Yu1; ~Huseyin_A_Inan1; ~Harsha_Nori1; ~Haotian_Jiang2; ~Huishuai_Zhang3; ~Yin_Tat_Lee1; ~Bo_Li19; ~Sergey_Yekhanin1,,"{'value': 'Text data has become extremely valuable due to the emergence of machine learning algorithms that learn from it. A lot of high-quality text data generated in the real world is private and therefore cannot be shared or used freely due to privacy concerns. Generating synthetic replicas of private text data with a formal privacy guarantee, i.e., differential privacy (DP), offers a promising and scalable solution. However, existing methods necessitate DP finetuning of large language models (LLMs) on private data to generate DP synthetic data. This approach is not viable for proprietary LLMs (e.g., GPT-3.5) and also demands considerable computational resources for open-source LLMs. Lin et al. (2024) recently introduced the Private Evolution (PE) algorithm to generate DP synthetic images with only API access to diffusion models. In this work, we propose an augmented PE algorithm, named Aug-PE, that applies to the complex setting of text. We use API access to an LLM and generate DP synthetic text without any model training. We conduct comprehensive experiments on three benchmark datasets. Our results demonstrate that Aug-PE produces DP synthetic text that yields competitive utility with the SOTA DP finetuning baselines. This underscores the feasibility of relying solely on API access of LLMs to produce high-quality DP synthetic texts, thereby facilitating more accessible routes to privacy-preserving LLM applications.'}",https://openreview.net{'value': '/pdf/bee2f67bd302cf331efb7ba37b5a4b56573dccba.pdf'},{'title_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=LIQYhV45D4,{'value': 'Federated Representation Learning in the Under-Parameterized Regime'},Renpu Liu; Cong Shen; Jing Yang,~Renpu_Liu1; ~Cong_Shen1; ~Jing_Yang3,,"{'value': 'Federated representation learning (FRL) is a popular personalized federated learning (FL) framework where clients work together to train a common representation while retaining their personalized heads. Existing studies, however, largely focus on the over-parameterized regime. In this paper, we make the initial efforts to investigate FRL in the under-parameterized regime, where the FL model is insufficient to express the variations in all ground-truth models. We propose a novel FRL algorithm FLUTE, and theoretically characterize its sample complexity and convergence rate for linear models in the under-parameterized regime. To the best of our knowledge, this is the first FRL algorithm with provable performance guarantees in this regime. FLUTE features a data-independent random initialization and a carefully designed objective function that aids the distillation of subspace spanned by the global optimal representation from the misaligned local representations. On the technical side, we bridge low-rank matrix approximation techniques with the FL analysis, which may be of broad interest. We also extend FLUTE beyond linear representations. Experimental results demonstrate that FLUTE outperforms state-of-the-art FRL solutions in both synthetic and real-world tasks.'}",https://openreview.net{'value': '/pdf/caba776712b8ff35c8dbdd3699e990c179b644a4.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=LH6R06NxdB,"{'value': 'GLoRe: When, Where, and How to Improve LLM Reasoning via Global and Local Refinements'}",Alexander Havrilla; Sharath Chandra Raparthy; Christoforos Nalmpantis; Jane Dwivedi-Yu; Maksym Zhuravinskyi; Eric Hambro; Roberta Raileanu,~Alexander_Havrilla2; ~Sharath_Chandra_Raparthy3; ~Christoforos_Nalmpantis1; ~Jane_Dwivedi-Yu1; ~Maksym_Zhuravinskyi1; ~Eric_Hambro1; ~Roberta_Raileanu2,,"{'value': 'State-of-the-art language models can exhibit reasoning refinement capabilities on math, science or coding tasks. However, recent work demonstrates that even the best models struggle to identify *when and where to refine* without access to external feedback. In this paper, we propose Stepwise ORMs (**SORMs**) which are trained, only on synthetic data, to approximate the expected future reward of the optimal policy or $V^{\\star}$ as a form of Process-based reward modeling. Our experiments show that SORMs can more accurately detect incorrect reasoning steps compared to ORMs, thus enabling them to give precise step-level feedback to refinement models. We then train *global* refinement models, which take only the question and a draft solution as input and predict a corrected solution, and *local* refinement models which also take as input a critique indicating the location of the first reasoning error. We generate training data for both models synthetically by reusing data used to train the SORM. We find combining global and local refinements, using the ORM as a reranker, significantly outperforms either one individually, as well as a best of three sample baseline. With this strategy we can improve the accuracy of a LLaMA-2 13B model (already fine-tuned with RL) on GSM8K from 53% to 65% when greedily sampled.'}",https://openreview.net{'value': '/pdf/f61e100de3b3e1830998bd24202b473363d1f401.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=L1eJ3NKPCd,"{'value': 'Compositional Capabilities of Autoregressive Transformers: A Study on Synthetic, Interpretable Tasks'}",Rahul Ramesh; Ekdeep Singh Lubana; Mikail Khona; Robert P. Dick; Hidenori Tanaka,~Rahul_Ramesh2; ~Ekdeep_Singh_Lubana1; ~Mikail_Khona2; ~Robert_P._Dick1; ~Hidenori_Tanaka1,,"{'value': 'Transformers trained on huge text corpora exhibit a remarkable set of capabilities, e.g., performing simple logical operations. Given the inherent compositional nature of language, one can expect the model to learn to compose these capabilities, potentially yielding a combinatorial explosion of what operations it can perform on an input. Motivated by the above, we aim to assess in this paper “how capable can a transformer become?”. Specifically, we train autoregressive Transformer models on a data-generating process that involves compositions of a set of well-defined monolithic capabilities. Through a series of extensive and systematic experiments on this data-generating process, we show that: (1) autoregressive Transformers can learn compositional structures from small amounts of training data and generalize to exponentially or even combinatorially many functions; (2) composing functions by generating intermediate outputs is more effective at generalizing to unseen compositions, compared to generating no intermediate outputs; (3) biases in the order of the compositions in the training data, results in Transformers that fail to compose some combinations of functions; and (4) the attention layers seem to select the capability to apply while the feed-forward layers execute the capability.'}",https://openreview.net{'value': '/pdf/a40567d9d0a74f7a0ca97fddd58201e8d307dc80.pdf'},{'title_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=Kt4fwiuKqf,{'value': 'Path-Guided Particle-based Sampling'},Mingzhou Fan; Ruida Zhou; Chao Tian; Xiaoning Qian,~Mingzhou_Fan1; ~Ruida_Zhou1; ~Chao_Tian2; ~Xiaoning_Qian2,,"{'value': 'Particle-based Bayesian inference methods by sampling from a partition-free target (posterior) distribution, e.g., Stein variational gradient descent (SVGD), have attracted significant attention. We propose a path-guided particle-based sampling (PGPS) method based on a novel Log-weighted Shrinkage (LwS) density path linking an initial distribution to the target distribution. We propose to utilize a Neural network to learn a vector field motivated by the Fokker-Planck equation of the designed density path. Particles, initiated from the initial distribution, evolve according to the ordinary differential equation defined by the vector field. The distribution of these particles is guided along a density path from the initial distribution to the target distribution. The proposed LwS density path allows for an efficient search of modes of the target distribution while canonical methods fail. We theoretically analyze the Wasserstein distance of the distribution of the PGPS-generated samples and the target distribution due to approximation and discretization errors. Practically, the proposed PGPS-LwS method demonstrates higher Bayesian inference accuracy and better calibration ability in experiments conducted on both synthetic and real-world Bayesian learning tasks, compared to baselines, such as SVGD and Langevin dynamics, etc.'}",https://openreview.net{'value': '/pdf/a26ecd74e667051c187689d97b11f57c1bb93b66.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=KpUdNe9lsr,{'value': 'HGAP: Boosting Permutation Invariant and Permutation Equivariant in Multi-Agent Reinforcement Learning via Graph Attention Network'},Bor-Jiun Lin; Chun-Yi Lee,~Bor-Jiun_Lin1; ~Chun-Yi_Lee1,,"{'value': 'Graph representation has gained widespread application across various machine learning domains, attributed to its ability to discern correlations among input nodes. In the realm of Multi- agent Reinforcement Learning (MARL), agents are tasked with observing other entities within their environment to determine their behavior. Conventional MARL methodologies often suffer from training difficulties if Permutation Invariant (PI) and Permutation Equivariant (PE) properties are not considered during training. The adoption of graph representation offers a solution to these challenges by conceptualizing observed entities as a graph. In this context, we introduce the Hyper Graphical Attention Policy (HGAP) Network, which employs a graph attention mechanism to fulfill the PI and PE properties, while also understanding inter-entity interactions for decision-making. HGAP is assessed across various MARL benchmarks to confirm its effectiveness and efficiency. In addition, a series of ablation studies are provided to demonstrate its adaptability, transferability, and the capability to alleviate the complexities introduced by the POMDP constraint.'}",https://openreview.net{'value': '/pdf/3cb4ff61d9befbcc722f35d47cb08edcfb2b75e6.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=KYrAZSbEv6,{'value': 'Inferring Dynamic Networks from Marginals with Iterative Proportional Fitting'},Serina Chang; Frederic Koehler; Zhaonan Qu; Jure Leskovec; Johan Ugander,~Serina_Chang1; ~Frederic_Koehler1; ~Zhaonan_Qu1; ~Jure_Leskovec1; ~Johan_Ugander1,,"{'value': 'A common network inference problem, arising from real-world data constraints, is how to infer a dynamic network from its time-aggregated adjacency matrix and time-varying marginals (i.e., row and column sums). Prior approaches to this problem have repurposed the classic iterative proportional fitting (IPF) procedure, also known as Sinkhorn’s algorithm, with promising empirical results. However, the statistical foundation for using IPF has not been well understood: under what settings does IPF provide principled estimation of a dynamic network from its marginals, and how well does it estimate the network? In this work, we establish such a setting, by identifying a generative network model whose maximum likelihood estimates are recovered by IPF. Our model both reveals implicit assumptions on the use of IPF in such settings and enables new analyses, such as structure-dependent error bounds on IPF’s parameter estimates. When IPF fails to converge on sparse network data, we introduce a principled algorithm that guarantees IPF converges under minimal changes to the network structure. Finally, we conduct experiments with synthetic and real-world data, which demonstrate the practical value of our theoretical and algorithmic contributions.'}",https://openreview.net{'value': '/pdf/dfa567d37afcaa8e9c7f812f163c1db8a9943d07.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=KVvku47shW,{'value': 'A Tale of Tails: Model Collapse as a Change of Scaling Laws'},Elvis Dohmatob; Yunzhen Feng; Pu Yang; Francois Charton; Julia Kempe,~Elvis_Dohmatob1; ~Yunzhen_Feng1; ~Pu_Yang3; ~Francois_Charton1; ~Julia_Kempe1,,"{'value': 'As AI model size grows, neural *scaling laws* have become a crucial tool to predict the improvements of large models when increasing capacity and the size of original (human or natural) training data. Yet, the widespread use of popular models means that the ecosystem of online data and text will co-evolve to progressively contain increased amounts of synthesized data. In this paper we ask: *How will the scaling laws change in the inevitable regime where synthetic data makes its way into the training corpus?* Will future models, still improve, or be doomed to degenerate up to total *(model) collapse*? We develop a theoretical framework of model collapse through the lens of scaling laws. We discover a wide range of decay phenomena, analyzing loss of scaling, shifted scaling with number of generations, the \'\'un-learning"" of skills, and grokking when mixing human and synthesized data. Our theory is validated by large-scale experiments with a transformer on an arithmetic task and text generation using the large language model Llama2.'}",https://openreview.net{'value': '/pdf/c028ead5595978096e7ba1f2c41cc3bb709058f9.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=KVa4i4RR1O,{'value': 'convSeq: Fast and Scalable Method for Detecting Patterns in Spike Data'},Roman Koshkin; Tomoki Fukai,~Roman_Koshkin1; ~Tomoki_Fukai1,,"{'value': 'Spontaneous neural activity, crucial in memory, learning, and spatial navigation, often manifests itself as repetitive spatiotemporal patterns. Despite their importance, analyzing these patterns in large neural recordings remains challenging due to a lack of efficient and scalable detection methods. Addressing this gap, we introduce *convSeq*, an unsupervised method that employs backpropagation for optimizing spatiotemporal filters that effectively identify these neural patterns. Our method’s performance is validated on various synthetic data and real neural recordings, revealing spike sequences with unprecedented scalability and efficiency. Significantly surpassing existing methods in speed, *convSeq* sets a new standard for analyzing spontaneous neural activity, potentially advancing our understanding of information processing in neural circuits.'}",https://openreview.net{'value': '/pdf/8456d85118b920a46d1d02e5e1c7da296fbcab8b.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=KHymcy2xxF,{'value': 'Leverage Class-Specific Accuracy to Guide Data Generation for Improving Image Classification'},Jay Gala; Pengtao Xie,~Jay_Gala1; ~Pengtao_Xie3,,"{'value': 'In many image classification applications, the number of labeled training images is limited, which leads to model overfitting. To mitigate the lack of training data, deep generative models have been leveraged to generate synthetic training data. However, existing methods generate data for individual classes based on how much training data they have without considering their actual data needs. To address this limitation, we propose needs-aware image generation, which automatically identifies the different data needs of individual classes based on their classification performance and divides a limited data generation budget into these classes according to their needs. We propose a multi-level optimization based framework which performs four learning stages in an end-to-end manner. Experiments on both imbalanced and balanced classification datasets demonstrate the effectiveness of our proposed method.'}",https://openreview.net{'value': '/pdf/1a2ae5c2f474fbc03986a2fcce89479076b1bad8.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=K5h6VAsJaV,{'value': 'Improving Gradient-Guided Nested Sampling for Posterior Inference'},Pablo Lemos; Nikolay Malkin; Will Handley; Yoshua Bengio; Yashar Hezaveh; Laurence Perreault-Levasseur,~Pablo_Lemos1; ~Nikolay_Malkin1; ~Will_Handley1; ~Yoshua_Bengio1; ~Yashar_Hezaveh1; ~Laurence_Perreault-Levasseur1,,"{'value': 'We present a performant, general-purpose gradient-guided nested sampling (GGNS) algorithm, combining the state of the art in differentiable programming, Hamiltonian slice sampling, clustering, mode separation, dynamic nested sampling, and parallelization. This unique combination allows GGNS to scale well with dimensionality and perform competitively on a variety of synthetic and real-world problems. We also show the potential of combining nested sampling with generative flow networks to obtain large amounts of high-quality samples from the posterior distribution. This combination leads to faster mode discovery and more accurate estimates of the partition function.'}",https://openreview.net{'value': '/pdf/82e7166fd207ed1a7236aa88bfdd229d7a1f8377.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=JpzIGzru5F,{'value': 'A Fixed-Point Approach for Causal Generative Modeling'},Meyer Scetbon; Joel Jennings; Agrin Hilmkil; Cheng Zhang; Chao Ma,~Meyer_Scetbon1; ~Joel_Jennings1; ~Agrin_Hilmkil1; ~Cheng_Zhang1; ~Chao_Ma2,,"{'value': 'We propose a novel formalism for describing Structural Causal Models (SCMs) as fixed-point problems on causally ordered variables, eliminating the need for Directed Acyclic Graphs (DAGs), and establish the weakest known conditions for their unique recovery given the topological ordering (TO). Based on this, we design a two-stage causal generative model that first infers in a zero-shot manner a valid TO from observations, and then learns the generative SCM on the ordered variables. To infer TOs, we propose to amortize the learning of TOs on synthetically generated datasets by sequentially predicting the leaves of graphs seen during training. To learn SCMs, we design a transformer-based architecture that exploits a new attention mechanism enabling the modeling of causal structures, and show that this parameterization is consistent with our formalism. Finally, we conduct an extensive evaluation of each method individually, and show that when combined, our model outperforms various baselines on generated out-of-distribution problems.'}",https://openreview.net{'value': '/pdf/0e61c2eca4c8bc1465c4629348149b0ede693b02.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=JVhUR8q27o,{'value': 'Towards AutoAI: Optimizing a Machine Learning System with Black-box and Differentiable Components'},Zhiliang Chen; Chuan-Sheng Foo; Bryan Kian Hsiang Low,~Zhiliang_Chen1; ~Chuan-Sheng_Foo1; ~Bryan_Kian_Hsiang_Low1,,"{'value': ""*Machine learning* (ML) models in the real world typically do not exist in isolation. They are usually part of a complex system (e.g., healthcare systems, self-driving cars) containing multiple ML and *black-box* components. The problem of optimizing such systems, which we refer to as *automated AI* (AutoAI), requires us to *jointly* train all ML components together and presents a significant challenge because the number of system parameters is extremely high and the system has no analytical form. To circumvent this, we introduce a novel algorithm called A-BAD-BO which uses each ML component's local loss as an auxiliary indicator for system performance. A-BAD-BO uses *Bayesian optimization* (BO) to optimize the local loss configuration of a system in a smaller dimensional space and exploits the differentiable structure of ML components to recover optimal system parameters from the optimized configuration. We show A-BAD-BO converges to optimal system parameters by showing that it is *asymptotically no regret*. We use A-BAD-BO to optimize several synthetic and real-world complex systems, including a prompt engineering pipeline for *large language models* containing millions of system parameters. Our results demonstrate that A-BAD-BO yields better system optimality than gradient-driven baselines and is more sample-efficient than pure BO algorithms.""}",https://openreview.net{'value': '/pdf/02e9356d41b0c047326ed912cc069bf9b62349f1.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=JAfIDm7NED,{'value': 'Mimicking Better by Matching the Approximate Action Distribution'},Joao Candido Ramos; Lionel Blondé; Naoya Takeishi; Alexandros Kalousis,~Joao_Candido_Ramos1; ~Lionel_Blondé1; ~Naoya_Takeishi1; ~Alexandros_Kalousis1,,"{'value': 'In this paper, we introduce MAAD, a novel, sample-efficient on-policy algorithm for Imitation Learning from Observations. MAAD utilizes a surrogate reward signal, which can be derived from various sources such as adversarial games, trajectory matching objectives, or optimal transport criteria. To compensate for the non-availability of expert actions, we rely on an inverse dynamics model that infers plausible actions distribution given the expert’s state-state transitions; we regularize the imitator’s policy by aligning it to the inferred action distribution. MAAD leads to significantly improved sample efficiency and stability. We demonstrate its effectiveness in a number of MuJoCo environments, both int the OpenAI Gym and the DeepMind Control Suite. We show that it requires considerable fewer interactions to achieve expert performance, outperforming current state-of-the-art on-policy methods. Remarkably, MAAD often stands out as the sole method capable of attaining expert performance levels, underscoring its simplicity and efficacy.'}",https://openreview.net{'value': '/pdf/8dc85fc83aefd4d47e38990dd64400a69568add4.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2024,Conference
https://openreview.net/forum?id=J9YKDvqr65,{'value': 'Improving Sharpness-Aware Minimization by Lookahead'},Runsheng Yu; Youzhi Zhang; James Kwok,~Runsheng_Yu2; ~Youzhi_Zhang2; ~James_Kwok1,,"{'value': 'Sharpness-Aware Minimization (SAM), which performs gradient descent on adversarially perturbed weights, can improve generalization by identifying flatter minima. However, recent studies have shown that SAM may suffer from convergence instability and oscillate around saddle points, resulting in slow convergence and inferior performance. To address this problem, we propose the use of a lookahead mechanism to gather more information about the landscape by looking further ahead, and thus find a better trajectory to converge. By examining the nature of SAM, we simplify the extrapolation procedure, resulting in a more efficient algorithm. Theoretical results show that the proposed method converges to a stationary point and is less prone to saddle points. Experiments on standard benchmark datasets also verify that the proposed method outperforms the SOTAs, and converge more effectively to flat minima.'}",https://openreview.net{'value': '/pdf/9ed46cec23365c14004ce80ef09bd0ba9b2ef486.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2024,Conference
https://openreview.net/forum?id=J5Yg7HMy39,{'value': 'Learning Mixtures of Gaussian Processes through Random Projection'},Emmanuel Akeweje; Mimi Zhang,~Emmanuel_Akeweje1; ~Mimi_Zhang2,,"{'value': 'We propose an ensemble clustering framework to uncover latent cluster labels in functional data generated from a Gaussian process mixture. Our method exploits the fact that the projection coefficients of the functional data onto any given projection function follow a univariate Gaussian mixture model (GMM). By conducting multiple one-dimensional projections and learning a univariate GMM for each, we create an ensemble of GMMs. Each GMM serves as a base clustering, and applying ensemble clustering yields a consensus clustering. Our approach significantly reduces computational complexity compared to state-of-the-art methods, and we provide theoretical guarantees on the identifiability and learnability of Gaussian process mixtures. Extensive experiments on synthetic and real datasets confirm the superiority of our method over existing techniques.'}",https://openreview.net{'value': '/pdf/bf4232f791c83d9a2c6dcab8706381d40d4f831f.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=If6Q9OYfoJ,{'value': 'Listwise Reward Estimation for Offline Preference-based Reinforcement Learning'},Heewoong Choi; Sangwon Jung; Hongjoon Ahn; Taesup Moon,~Heewoong_Choi1; ~Sangwon_Jung1; ~Hongjoon_Ahn2; ~Taesup_Moon1,,"{'value': 'In Reinforcement Learning (RL), designing precise reward functions remains to be a challenge, particularly when aligning with human intent. Preference-based RL (PbRL) was introduced to address this problem by learning reward models from human feedback. However, existing PbRL methods have limitations as they often overlook the *second-order* preference that indicates the relative strength of preference. In this paper, we propose Listwise Reward Estimation (LiRE), a novel approach for offline PbRL that leverages second-order preference information by constructing a Ranked List of Trajectories (RLT), which can be efficiently built by using the same ternary feedback type as traditional methods. To validate the effectiveness of LiRE, we propose a new offline PbRL dataset that objectively reflects the effect of the estimated rewards. Our extensive experiments on the dataset demonstrate the superiority of LiRE, *i.e.,* outperforming state-of-the-art baselines even with modest feedback budgets and enjoying robustness with respect to the number of feedbacks and feedback noise. Our code is available at https://github.com/chwoong/LiRE'}",https://openreview.net{'value': '/pdf/39d1d44fab8f9e6054778c477270ed3b00d238e5.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2024,Conference
https://openreview.net/forum?id=INb8xV1xmf,{'value': 'Superpoint Gaussian Splatting for Real-Time High-Fidelity Dynamic Scene Reconstruction'},Diwen Wan; Ruijie Lu; Gang Zeng,~Diwen_Wan1; ~Ruijie_Lu1; ~Gang_Zeng1,,"{'value': 'Rendering novel view images in dynamic scenes is a crucial yet challenging task. Current methods mainly utilize NeRF-based methods to represent the static scene and an additional time-variant MLP to model scene deformations, resulting in relatively low rendering quality as well as slow inference speed. To tackle these challenges, we propose a novel framework named Superpoint Gaussian Splatting (SP-GS). Specifically, our framework first employs explicit 3D Gaussians to reconstruct the scene and then clusters Gaussians with similar properties (e.g., rotation, translation, and location) into superpoints. Empowered by these superpoints, our method manages to extend 3D Gaussian splatting to dynamic scenes with only a slight increase in computational expense. Apart from achieving state-of-the-art visual quality and real-time rendering under high resolutions, the superpoint representation provides a stronger manipulation capability. Extensive experiments demonstrate the practicality and effectiveness of our approach on both synthetic and real-world datasets. Please see our project page at https://dnvtmf.github.io/SP_GS.github.io.'}",https://openreview.net{'value': '/pdf/47bab0f40727681ca5adec9bafa96d20fb427e94.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=HsseRq2FAx,{'value': 'Dr. Strategy: Model-Based Generalist Agents with Strategic Dreaming'},Hany Hamed; Subin Kim; Dongyeong Kim; Jaesik Yoon; Sungjin Ahn,~Hany_Hamed1; ~Subin_Kim4; ~Dongyeong_Kim1; ~Jaesik_Yoon1; ~Sungjin_Ahn1,,"{'value': ""Model-based reinforcement learning (MBRL) has been a primary approach to ameliorating the sample efficiency issue as well as to make a generalist agent. However, there has not been much effort toward enhancing the strategy of dreaming itself. Therefore, it is a question *whether and how an agent can ``*dream better*''* in a more structured and strategic way. In this paper, inspired by the observation from cognitive science suggesting that humans use a spatial divide-and-conquer strategy in planning, we propose a new MBRL agent, called **Dr. Strategy**, which is equipped with a novel **Dr**eaming **Strategy**. The proposed agent realizes a version of divide-and-conquer-like strategy in dreaming. This is achieved by learning a set of latent landmarks and then utilizing these to learn a landmark-conditioned highway policy. With the highway policy, the agent can first learn in the dream to move to a landmark, and from there it tackles the exploration and achievement task in a more focused way. In experiments, we show that the proposed model outperforms prior pixel-based MBRL methods in various visually complex and partially observable navigation tasks.""}",https://openreview.net{'value': '/pdf/2df0ba6c3287a3539533864714ad27ac435f730c.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=HssOwuZiaB,{'value': 'Eureka-Moments in Transformers: Multi-Step Tasks Reveal Softmax Induced Optimization Problems'},David T Hoffmann; Simon Schrodi; Jelena Bratulić; Nadine Behrmann; Volker Fischer; Thomas Brox,~David_T_Hoffmann1; ~Simon_Schrodi1; ~Jelena_Bratulić1; ~Nadine_Behrmann1; ~Volker_Fischer1; ~Thomas_Brox1,,"{'value': 'In this work, we study rapid improvements of the training loss in transformers when being confronted with multi-step decision tasks. We found that transformers struggle to learn the intermediate task and both training and validation loss saturate for hundreds of epochs. When transformers finally learn the intermediate task, they do this rapidly and unexpectedly. We call these abrupt improvements Eureka-moments, since the transformer appears to suddenly learn a previously incomprehensible concept. We designed synthetic tasks to study the problem in detail, but the leaps in performance can be observed also for language modeling and in-context learning (ICL). We suspect that these abrupt transitions are caused by the multi-step nature of these tasks. Indeed, we find connections and show that ways to improve on the synthetic multi-step tasks can be used to improve the training of language modeling and ICL. Using the synthetic data we trace the problem back to the Softmax function in the self-attention block of transformers and show ways to alleviate the problem. These fixes reduce the required number of training steps, lead to higher likelihood to learn the intermediate task, to higher final accuracy and training becomes more robust to hyper-parameters.'}",https://openreview.net{'value': '/pdf/255af945027cc215c984fd05a24a0a620451528b.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=HrzQZXzrN2,{'value': 'Predictive Performance Comparison of Decision Policies Under Confounding'},Luke Guerdan; Amanda Lee Coston; Ken Holstein; Steven Wu,~Luke_Guerdan1; ~Amanda_Lee_Coston1; ~Ken_Holstein1; ~Steven_Wu1,,"{'value': 'Predictive models are often introduced to decision-making tasks under the rationale that they improve performance over an existing decision-making policy. However, it is challenging to compare predictive performance against an existing decision-making policy that is generally under-specified and dependent on unobservable factors. These sources of uncertainty are often addressed in practice by making strong assumptions about the data-generating mechanism. In this work, we propose a method to compare the predictive performance of decision policies under a variety of modern identification approaches from the causal inference and off-policy evaluation literatures (e.g., instrumental variable, marginal sensitivity model, proximal variable). Key to our method is the insight that there are regions of uncertainty that we can safely ignore in the policy comparison. We develop a practical approach for finite-sample estimation of regret intervals under no assumptions on the parametric form of the status quo policy. We verify our framework theoretically and via synthetic data experiments. We conclude with a real-world application using our framework to support a pre-deployment evaluation of a proposed modification to a healthcare enrollment policy.'}",https://openreview.net{'value': '/pdf/8600a2e5e665779b5b43982873cd7c9f2488afbe.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=HbdeEGVfEN,{'value': 'Deep Regression Representation Learning with Topology'},Shihao Zhang; Kenji Kawaguchi; Angela Yao,~Shihao_Zhang1; ~Kenji_Kawaguchi1; ~Angela_Yao1,,"{'value': 'Most works studying representation learning focus only on classification and neglect regression. Yet, the learning objectives and, therefore, the representation topologies of the two tasks are fundamentally different: classification targets class separation, leading to disconnected representations, whereas regression requires ordinality with respect to the target, leading to continuous representations. We thus wonder how the effectiveness of a regression representation is influenced by its topology, with evaluation based on the Information Bottleneck (IB) principle. The IB principle is an important framework that provides principles for learning effective representations. We establish two connections between it and the topology of regression representations. The first connection reveals that a lower intrinsic dimension of the feature space implies a reduced complexity of the representation $Z$. This complexity can be quantified as the conditional entropy of $Z$ on the target $Y$, and serves as an upper bound on the generalization error. The second connection suggests a feature space that is topologically similar to the target space will better align with the IB principle. Based on these two connections, we introduce PH-Reg, a regularizer specific to regression that matches the intrinsic dimension and topology of the feature space with the target space. Experiments on synthetic and real-world regression tasks demonstrate the benefits of PH-Reg. Code: https://github.com/needylove/PH-Reg.'}",https://openreview.net{'value': '/pdf/e834b0f5c058898fc3f36fa67af7bc43bec6cf65.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=HTMFUKAm8B,{'value': 'A Field Guide for Pacing Budget and ROS Constraints'},Santiago R. Balseiro; Kshipra Bhawalkar; Zhe Feng; Haihao Lu; Vahab Mirrokni; Balasubramanian Sivan; Di Wang,~Santiago_R._Balseiro1; ~Kshipra_Bhawalkar1; ~Zhe_Feng3; ~Haihao_Lu2; ~Vahab_Mirrokni2; ~Balasubramanian_Sivan1; ~Di_Wang4,,"{'value': ""Budget pacing is a popular service that has been offered by major internet advertising platforms since their inception. In the past few years, autobidding products that provide real-time bidding as a service to advertisers have seen a prominent rise in adoption. A popular autobidding stategy is value maximization subject to return-on-spend (ROS) constraints. For historical or business reasons, the systems that govern these two services, namely budget pacing and ROS pacing, are not necessarily always a single unified and coordinated entity that optimizes a global objective subject to both constraints. The purpose of this work is to theoretically and empirically compare algorithms with different degrees of coordination between these two pacing systems. In particular, we compare (a) a fully-decoupled sequential algorithm; (b) a minimally-coupled min-pacing algorithm; (c) a fully-coupled dual-based algorithm. Our main contribution is to theoretically analyze the min-pacing algorithm and show that it attains similar guarantees to the fully-coupled canonical dual-based algorithm. On the other hand, we show that the sequential algorithm, even though appealing by virtue of being fully decoupled, could badly violate the constraints. We validate our theoretical findings empirically by showing that the min-pacing algorithm performs almost as well as the canonical dual-based algorithm on a semi-synthetic dataset that was generated from a large online advertising platform's auction data.""}",https://openreview.net{'value': '/pdf/f6a633d69edbe4728c85f6462e86ce0585220f77.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=HQtTg1try7,{'value': 'Adversarial Robustness Limits via Scaling-Law and Human-Alignment Studies'},Brian R. Bartoldson; James Diffenderfer; Konstantinos Parasyris; Bhavya Kailkhura,~Brian_R._Bartoldson1; ~James_Diffenderfer1; ~Konstantinos_Parasyris2; ~Bhavya_Kailkhura1,,"{'value': ""This paper revisits the simple, long-studied, yet still unsolved problem of making image classifiers robust to imperceptible perturbations. Taking CIFAR10 as an example, SOTA clean accuracy is about $100$%, but SOTA robustness to $\\ell_{\\infty}$-norm bounded perturbations barely exceeds $70$%. To understand this gap, we analyze how model size, dataset size, and synthetic data quality affect robustness by developing the first scaling laws for adversarial training. Our scaling laws reveal inefficiencies in prior art and provide actionable feedback to advance the field. For instance, we discovered that SOTA methods diverge notably from compute-optimal setups, using excess compute for their level of robustness. Leveraging a compute-efficient setup, we surpass the prior SOTA with $20$% ($70$%) fewer training (inference) FLOPs. We trained various compute-efficient models, with our best achieving $74$% AutoAttack accuracy ($+3$% gain). However, our scaling laws also predict robustness slowly grows then plateaus at $90$%: dwarfing our new SOTA by scaling is impractical, and perfect robustness is impossible. To better understand this predicted limit, we carry out a small-scale human evaluation on the AutoAttack data that fools our top-performing model. Concerningly, we estimate that human performance also plateaus near $90$%, which we show to be attributable to $\\ell_{\\infty}$-constrained attacks' generation of invalid images not consistent with their original labels. Having characterized limiting roadblocks, we outline promising paths for future research.""}",https://openreview.net{'value': '/pdf/2bb15515c17df8cd8b771bbb3167aa1737d2c34f.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=HDrXBr26UI,{'value': 'Neuro-Symbolic Temporal Point Processes'},Yang Yang; Chao Yang; Boyang Li; Yinghao Fu; Shuang Li,~Yang_Yang56; ~Chao_Yang9; ~Boyang_Li4; ~Yinghao_Fu1; ~Shuang_Li3,,"{'value': 'Our goal is to $\\textit{efficiently}$ discover a compact set of temporal logic rules to explain irregular events of interest. We introduce a neural-symbolic rule induction framework within the temporal point process model. The negative log-likelihood is the loss that guides the learning, where the explanatory logic rules and their weights are learned end-to-end in a $\\textit{differentiable}$ way. Specifically, predicates and logic rules are represented as $\\textit{vector embeddings}$, where the predicate embeddings are fixed and the rule embeddings are trained via gradient descent to obtain the most appropriate compositional representations of the predicate embeddings. To make the rule learning process more efficient and flexible, we adopt a $\\textit{sequential covering algorithm}$, which progressively adds rules to the model and removes the event sequences that have been explained until all event sequences have been covered. All the found rules will be fed back to the models for a final rule embedding and weight refinement. Our approach showcases notable efficiency and accuracy across synthetic and real datasets, surpassing state-of-the-art baselines by a wide margin in terms of efficiency.'}",https://openreview.net{'value': '/pdf/a034d801cc76f664bc002bee239c5f56ef7a89d8.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=H86WzfH5N1,{'value': 'On the Trajectory Regularity of ODE-based Diffusion Sampling'},Defang Chen; Zhenyu Zhou; Can Wang; Chunhua Shen; Siwei Lyu,~Defang_Chen1; ~Zhenyu_Zhou6; ~Can_Wang5; ~Chunhua_Shen2; ~Siwei_Lyu1,,"{'value': 'Diffusion-based generative models use stochastic differential equations (SDEs) and their equivalent ordinary differential equations (ODEs) to establish a smooth connection between a complex data distribution and a tractable prior distribution. In this paper, we identify several intriguing trajectory properties in the ODE-based sampling process of diffusion models. We characterize an implicit denoising trajectory and discuss its vital role in forming the coupled sampling trajectory with a strong shape regularity, regardless of the generated content. We also describe a dynamic programming-based scheme to make the time schedule in sampling better fit the underlying trajectory structure. This simple strategy requires minimal modification to any given ODE-based numerical solvers and incurs negligible computational cost, while delivering superior performance in image generation, especially in $5\\sim 10$ function evaluations.'}",https://openreview.net{'value': '/pdf/f4de47001284bc7d0394f73e965f7e7a8666d6cb.pdf'},{'title_filter': 'Trajectory'},ICML.cc,2024,Conference
https://openreview.net/forum?id=H3bATm4mKn,{'value': 'Out of the Ordinary: Spectrally Adapting Regression for Covariate Shift'},Benjamin Eyre; Elliot Creager; David Madras; Vardan Papyan; Richard Zemel,~Benjamin_Eyre1; ~Elliot_Creager1; ~David_Madras1; ~Vardan_Papyan1; ~Richard_Zemel1,,"{'value': 'Designing deep neural network classifiers that perform robustly on distributions differing from the available training data is an active area of machine learning research. However, out-of-distribution generalization for regression---the analogous problem for modeling continuous targets---remains relatively unexplored. To tackle this problem, we return to first principles and analyze how the closed-form solution for Ordinary Least Squares (OLS) regression is sensitive to covariate shift. We characterize the out-of-distribution risk of the OLS model in terms of the eigenspectrum decomposition of the source and target data. We then use this insight to propose a method called Spectral Adapted Regressor (SpAR) for adapting the weights of the last layer of a pre-trained neural regression model to perform better on input data originating from a different distribution. We demonstrate how this lightweight spectral adaptation procedure can improve out-of-distribution performance for synthetic and real-world datasets.'}",https://openreview.net{'value': '/pdf/4a05637872a7560d88ea1d256be6499140eea24f.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=GktjBAGgo4,{'value': 'Reducing Balancing Error for Causal Inference via Optimal Transport'},Yuguang Yan; Hao Zhou; Zeqin Yang; Weilin Chen; Ruichu Cai; Zhifeng Hao,~Yuguang_Yan1; ~Hao_Zhou23; ~Zeqin_Yang1; ~Weilin_Chen1; ~Ruichu_Cai1; ~Zhifeng_Hao5,,"{'value': 'Most studies on causal inference tackle the issue of confounding bias by reducing the distribution shift between the control and treated groups. However, it remains an open question to adopt an appropriate metric for distribution shift in practice. In this paper, we define a generic balancing error on reweighted samples to characterize the confounding bias, and study the connection between the balancing error and the Wasserstein discrepancy derived from the theory of optimal transport. We not only regard the Wasserstein discrepancy as the metric of distribution shift, but also explore the association between the balancing error and the underlying cost function involved in the Wasserstein discrepancy. Motivated by this, we propose to reduce the balancing error under the framework of optimal transport with learnable marginal distributions and the cost function, which is implemented by jointly learning weights and representations associated with factual outcomes. The experiments on both synthetic and real-world datasets demonstrate the effectiveness of our proposed method.'}",https://openreview.net{'value': '/pdf/4f6962d6d84dd5545b20293abffedb22e2312010.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=GJzqRKOdRi,{'value': 'From Inverse Optimization to Feasibility to ERM'},Saurabh kumar Mishra; Anant Raj; Sharan Vaswani,~Saurabh_kumar_Mishra1; ~Anant_Raj2; ~Sharan_Vaswani1,,"{'value': 'Inverse optimization involves inferring unknown parameters of an optimization problem from known solutions and is widely used in fields such as transportation, power systems, and healthcare. We study the *contextual inverse optimization setting* that utilizes additional contextual information to better predict the unknown problem parameters. We focus on contextual inverse linear programming (CILP) addressing the challenges posed by the non-differentiable nature of LPs. For a linear prediction model, we reduce CILP to a convex feasibility problem allowing the use of standard algorithms such as alternating projections. The resulting algorithm for CILP is equipped with theoretical convergence guarantees without additional assumptions such as degeneracy or interpolation. Next, we reduce CILP to empirical risk minimization (ERM) on a smooth, convex loss that satisfies the Polyak-Lojasiewicz condition. This reduction enables the use of scalable first-order optimization methods to solve large non-convex problems while maintaining theoretical guarantees in the convex setting. Subsequently, we use the reduction to ERM to quantify the generalization performance of the proposed algorithm on previously unseen instances. Finally, we experimentally validate our approach on synthetic and real-world problems and demonstrate improved performance compared to existing methods.'}",https://openreview.net{'value': '/pdf/30a4041178df6c926142f31c99bc843ece238c47.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=GDp7Gyd9nf,{'value': 'Mechanistic Design and Scaling of Hybrid Architectures'},Michael Poli; Armin W Thomas; Eric Nguyen; Pragaash Ponnusamy; Björn Deiseroth; Kristian Kersting; Taiji Suzuki; Brian Hie; Stefano Ermon; Christopher Re; Ce Zhang; Stefano Massaroli,~Michael_Poli1; ~Armin_W_Thomas1; ~Eric_Nguyen1; ~Pragaash_Ponnusamy1; ~Björn_Deiseroth1; ~Kristian_Kersting1; ~Taiji_Suzuki1; brianhie@stanford.edu; ~Stefano_Ermon1; ~Christopher_Re1; ~Ce_Zhang1; ~Stefano_Massaroli1,,"{'value': 'The development of deep learning architectures is a resource-demanding process, due to a vast design space, long prototyping times, and high compute costs associated with at-scale model training and evaluation. We set out to simplify this process by grounding it in an end-to-end mechanistic architecture design (MAD) pipeline, encompassing small-scale capability unit tests predictive of scaling laws. Through a suite of synthetic token manipulation tasks such as compression and recall, designed to probe capabilities, we identify and test new hybrid architectures constructed from a variety of computational primitives. We experimentally validate the resulting architectures via an extensive compute-optimal and a new state-optimal scaling law analysis, training over 500 language models between 70M to 7B parameters. Surprisingly, we find MAD synthetics to correlate with compute-optimal perplexity, enabling accurate evaluation of new architectures via isolated proxy tasks. The new architectures found via MAD, based on simple ideas such as hybridization and sparsity, outperform state-of-the-art Transformer, convolutional, and recurrent architectures (Transformer++, Hyena, Mamba) in scaling, both at compute-optimal budgets and in overtrained regimes. Overall, these results provide evidence that performance on curated synthetic tasks can be predictive of scaling laws, and that an optimal architecture should leverage specialized layers via a hybrid topology.'}",https://openreview.net{'value': '/pdf/1f23a20e6e98232c95c75607749544c9df15185c.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=G0z4bCNmkG,{'value': 'ByMI: Byzantine Machine Identification with False Discovery Rate Control'},Chengde Qian; Mengyuan Wang; Haojie Ren; Changliang Zou,~Chengde_Qian1; ~Mengyuan_Wang2; ~Haojie_Ren1; ~Changliang_Zou2,,"{'value': 'Various robust estimation methods or algorithms have been proposed to hedge against Byzantine failures in distributed learning. However, there is a lack of systematic approaches to provide theoretical guarantees of significance in detecting those Byzantine machines. In this paper, we develop a general detection procedure, ByMI, via error rate control to address this issue, which is applicable to many robust learning problems. The key idea is to apply the sample-splitting strategy on each worker machine to construct a score statistic integrated with a general robust estimation and then to utilize the symmetry property of those scores to derive a data-driven threshold. The proposed method is dimension insensitive and p-value free with the help of the symmetry property and can achieve false discovery rate control under mild conditions. Numerical experiments on both synthetic and real data validate the theoretical results and demonstrate the effectiveness of our proposed method on Byzantine machine identification.'}",https://openreview.net{'value': '/pdf/d8122c8888faadab02d07a0060f14c09fd9ab98c.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=Fzp1DRzCIN,{'value': 'Implicit meta-learning may lead language models to trust more reliable sources'},Dmitrii Krasheninnikov; Egor Krasheninnikov; Bruno Kacper Mlodozeniec; Tegan Maharaj; David Krueger,~Dmitrii_Krasheninnikov1; ~Egor_Krasheninnikov1; ~Bruno_Kacper_Mlodozeniec2; ~Tegan_Maharaj1; ~David_Krueger1,,"{'value': 'We demonstrate that large language models (LLMs) may learn indicators of document usefulness and modulate their updates accordingly. We introduce random strings (""tags"") as indicators of usefulness in a synthetic fine-tuning dataset. Fine-tuning on this dataset leads to **implicit meta-learning (IML)**: in further fine-tuning, the model updates to make more use of text that is tagged as useful. We perform a thorough empirical investigation of this phenomenon, finding (among other things) that (i) it occurs in both pretrained LLMs and those trained from scratch, as well as on a vision task, and (ii) larger models and smaller batch sizes tend to give more IML. We also use probing to examine how IML changes the way models store knowledge in their parameters. Finally, we reflect on what our results might imply about the capabilities, risks, and controllability of future AI systems.'}",https://openreview.net{'value': '/pdf/f9ff7df1c721b133862e6327f51393e368a6dd80.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=FQQ4476dT2,{'value': 'FightLadder: A Benchmark for Competitive Multi-Agent Reinforcement Learning'},Wenzhe Li; Zihan Ding; Seth Karten; Chi Jin,~Wenzhe_Li2; ~Zihan_Ding1; ~Seth_Karten1; ~Chi_Jin1,,"{'value': 'Recent advances in reinforcement learning (RL) heavily rely on a variety of well-designed benchmarks, which provide environmental platforms and consistent criteria to evaluate existing and novel algorithms. Specifically, in multi-agent RL (MARL), a plethora of benchmarks based on cooperative games have spurred the development of algorithms that improve the scalability of cooperative multi-agent systems. However, for the competitive setting, a lightweight and open-sourced benchmark with challenging gaming dynamics and visual inputs has not yet been established. In this work, we present FightLadder, a real-time fighting game platform, to empower competitive MARL research. Along with the platform, we provide implementations of state-of-the-art MARL algorithms for competitive games, as well as a set of evaluation metrics to characterize the performance and exploitability of agents. We demonstrate the feasibility of this platform by training a general agent that consistently defeats 12 built-in characters in single-player mode, and expose the difficulty of training a non-exploitable agent without human knowledge and demonstrations in two-player mode. FightLadder provides meticulously designed environments to address critical challenges in competitive MARL research, aiming to catalyze a new era of discovery and advancement in the field. Videos and code at https://sites.google.com/view/fightladder/home.'}",https://openreview.net{'value': '/pdf/108e490ca041bf79b4022833a8e3a87f90615bf2.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=FCmWhJQ14I,{'value': 'Evaluation of Trajectory Distribution Predictions with Energy Score'},Novin Shahroudi; Mihkel Lepson; Meelis Kull,~Novin_Shahroudi1; ~Mihkel_Lepson1; ~Meelis_Kull1,,"{'value': 'Predicting the future trajectory of surrounding objects is inherently uncertain and vital in the safe and reliable planning of autonomous systems such as in self-driving cars. Although trajectory prediction models have become increasingly sophisticated in dealing with the complexities of spatiotemporal data, the evaluation methods used to assess these models have not kept pace. ""Minimum of N"" is a common family of metrics used to assess the rich outputs of such models. We critically examine the Minimum of N within the proper scoring rules framework to show that it is not strictly proper and demonstrate how that could lead to a misleading assessment of multimodal trajectory predictions. As an alternative, we propose using Energy Score-based evaluation measures, leveraging their proven propriety for a more reliable evaluation of trajectory distribution predictions.'}",https://openreview.net{'value': '/pdf/ebcc0b1955e28327a9562073b6524f7ea3ad163b.pdf'},{'title_filter': 'Trajectory'},ICML.cc,2024,Conference
https://openreview.net/forum?id=F3RdeyiR5H,{'value': 'Trust Regions for Explanations via Black-Box Probabilistic Certification'},Amit Dhurandhar; Swagatam Haldar; Dennis Wei; Karthikeyan Natesan Ramamurthy,~Amit_Dhurandhar1; ~Swagatam_Haldar1; ~Dennis_Wei1; ~Karthikeyan_Natesan_Ramamurthy1,,"{'value': 'Given the black box nature of machine learning models, a plethora of explainability methods have been developed to decipher the factors behind individual decisions. In this paper, we introduce a novel problem of black box (probabilistic) explanation certification. We ask the question: Given a black box model with only query access, an explanation for an example and a quality metric (viz. fidelity, stability), can we find the largest hypercube (i.e., $\\ell_{\\infty}$ ball) centered at the example such that when the explanation is applied to all examples within the hypercube, (with high probability) a quality criterion is met (viz. fidelity greater than some value)? Being able to efficiently find such a *trust region* has multiple benefits: i) insight into model behavior in a *region*, with a *guarantee*; ii) ascertained *stability* of the explanation; iii) *explanation reuse*, which can save time, energy and money by not having to find explanations for every example; and iv) a possible *meta-metric* to compare explanation methods. Our contributions include formalizing this problem, proposing solutions, providing theoretical guarantees for these solutions that are computable, and experimentally showing their efficacy on synthetic and real data.'}",https://openreview.net{'value': '/pdf/b2a7209434a5c1b5230d83ce82d0e6dc0f53196f.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=F3936hVwQa,{'value': 'Conformal Validity Guarantees Exist for Any Data Distribution (and How to Find Them)'},Drew Prinster; Samuel Don Stanton; Anqi Liu; Suchi Saria,~Drew_Prinster1; ~Samuel_Don_Stanton1; ~Anqi_Liu2; ~Suchi_Saria1,,"{'value': ""As artificial intelligence (AI) / machine learning (ML) gain widespread adoption, practitioners are increasingly seeking means to quantify and control the risk these systems incur. This challenge is especially salient when such systems have autonomy to collect their own data, such as in black-box optimization and active learning, where their actions induce sequential feedback-loop shifts in the data distribution. Conformal prediction is a promising approach to uncertainty and risk quantification, but prior variants' validity guarantees have assumed some form of ``quasi-exchangeability'' on the data distribution, thereby excluding many types of sequential shifts. In this paper we prove that conformal prediction can theoretically be extended to *any* joint data distribution, not just exchangeable or quasi-exchangeable ones. Although the most general case is exceedingly impractical to compute, for concrete practical applications we outline a procedure for deriving specific conformal algorithms for any data distribution, and we use this procedure to derive tractable algorithms for a series of AI/ML-agent-induced covariate shifts. We evaluate the proposed algorithms empirically on synthetic black-box optimization and active learning tasks.""}",https://openreview.net{'value': '/pdf/8d122e5aa12fe2d49a1b2ec5eb72eb76b9e95b0e.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=EQXZqBXeW9,{'value': 'Federated Neuro-Symbolic Learning'},Pengwei Xing; Songtao Lu; Han Yu,~Pengwei_Xing2; ~Songtao_Lu1; ~Han_Yu1,,"{'value': 'Neuro-symbolic learning (NSL) models complex symbolic rule patterns into latent variable distributions by neural networks, which reduces rule search space and generates unseen rules to improve downstream task performance. Centralized NSL learning involves directly acquiring data from downstream tasks, which is not feasible for federated learning (FL). To address this limitation, we shift the focus from such a one-to-one interactive neuro-symbolic paradigm to one-to-many Federated Neuro-Symbolic Learning framework (FedNSL) with latent variables as the FL communication medium. Built on the basis of our novel reformulation of the NSL theory, FedNSL is capable of identifying and addressing rule distribution heterogeneity through a simple and effective Kullback-Leibler (KL) divergence constraint on rule distribution applicable under the FL setting. It further theoretically adjusts variational expectation maximization (V-EM) to reduce the rule search space across domains. This is the first incorporation of distribution-coupled bilevel optimization into FL. Extensive experiments based on both synthetic and real-world data demonstrate significant advantages of FedNSL compared to five state-of-the-art methods. It outperforms the best baseline by 17% and 29% in terms of unbalanced average training accuracy and unseen average testing accuracy, respectively.'}",https://openreview.net{'value': '/pdf/43f80c62e4202abd707a4a4b9276af4f6f18e823.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=DzLna0cFL1,"{'value': 'Position: Towards Unified Alignment Between Agents, Humans, and Environment'}",Zonghan Yang; An Liu; Zijun Liu; Kaiming Liu; Fangzhou Xiong; Yile Wang; Zeyuan Yang; Qingyuan Hu; Xinrui Chen; Zhenhe Zhang; Fuwen Luo; Zhicheng Guo; Peng Li; Yang Liu,~Zonghan_Yang1; ~An_Liu4; ~Zijun_Liu2; ~Kaiming_Liu1; ~Fangzhou_Xiong1; ~Yile_Wang1; ~Zeyuan_Yang3; huqy23@mails.tsinghua.edu.cn; cxr21@mails.tsinghua.edu.cn; zhenhe-z21@mails.tsinghua.edu.cn; ~Fuwen_Luo1; ~Zhicheng_Guo2; ~Peng_Li2; ~Yang_Liu19,,"{'value': 'The rapid progress of foundation models has led to the prosperity of autonomous agents, which leverage the universal capabilities of foundation models to conduct reasoning, decision-making, and environmental interaction. However, the efficacy of agents remains limited when operating in intricate, realistic environments. In this work, we introduce the principles of **U**nified **A**lignment for **A**gents (**UA**$^2$), which advocate for the simultaneous alignment of agents with human intentions, environmental dynamics, and self-constraints such as the limitation of monetary budgets. From the perspective of **UA**$^2$, we review the current agent research and highlight the neglected factors in existing agent benchmarks and method candidates. We also conduct proof-of-concept studies by introducing realistic features to WebShop, including user profiles demonstrating intentions, personalized reranking reflecting complex environmental dynamics, and runtime cost statistics as self-constraints. We then follow the principles of **UA**$^2$ to propose an initial design of our agent and benchmark its performance with several candidate baselines in the retrofitted WebShop. The extensive experimental results further prove the importance of the principles of **UA**$^2$. Our research sheds light on the next steps of autonomous agent research with improved general problem-solving abilities.'}",https://openreview.net{'value': '/pdf/7048a365946aa64a64fdd4a7b9bdeb70b5f9ceb6.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=DyvhD8J3Wl,{'value': 'Benign Overfitting in Adversarial Training of Neural Networks'},Yunjuan Wang; Kaibo Zhang; Raman Arora,~Yunjuan_Wang1; ~Kaibo_Zhang3; ~Raman_Arora1,,"{'value': 'Benign overfitting is the phenomenon wherein none of the predictors in the hypothesis class can achieve perfect accuracy (i.e., non-realizable or noisy setting), but a model that interpolates the training data still achieves good generalization. A series of recent works aim to understand this phenomenon for regression and classification tasks using linear predictors as well as two-layer neural networks. In this paper, we study such a benign overfitting phenomenon in an adversarial setting. We show that under a distributional assumption, interpolating neural networks found using adversarial training generalize well despite inference-time attacks. Specifically, we provide convergence and generalization guarantees for adversarial training of two-layer networks (with smooth as well as non-smooth activation functions) showing that under moderate $\\ell_2$ norm perturbation budget, the trained model has near-zero robust training loss and near-optimal robust generalization error. We support our theoretical findings with an empirical study on synthetic and real-world data.'}",https://openreview.net{'value': '/pdf/392a979794efca8e48de23f56366fedb8174d5fc.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=DwTgy1hXXo,{'value': 'Dynamic Evaluation of Large Language Models by Meta Probing Agents'},Kaijie Zhu; Jindong Wang; Qinlin Zhao; Ruochen Xu; Xing Xie,~Kaijie_Zhu1; ~Jindong_Wang1; ~Qinlin_Zhao1; ~Ruochen_Xu2; ~Xing_Xie3,,"{'value': ""Evaluation of large language models (LLMs) has raised great concerns in the community due to the issue of data contamination. Existing work designed evaluation protocols using well-defined algorithms for specific tasks, which cannot be easily extended to diverse scenarios. Moreover, current evaluation benchmarks can only provide the overall benchmark results and cannot support a fine-grained and multifaceted analysis of LLMs' abilities. In this paper, we propose meta probing agents (MPA), a general dynamic evaluation protocol inspired by psychometrics to evaluate LLMs. MPA designs the probing and judging agents to automatically transform an original evaluation problem into a new one following psychometric theory on three basic cognitive abilities: language understanding, problem solving, and domain knowledge. These basic abilities are also dynamically configurable, allowing multifaceted analysis. We conducted extensive evaluations using MPA and found that most LLMs achieve poorer performance, indicating room for improvement. Our multifaceted analysis demonstrated the strong correlation between the basic abilities and an implicit Mattew effect on model size, i.e., larger models possess stronger correlations of the abilities. MPA can also be used as a data augmentation approach to enhance LLMs. Code is available at: https://github.com/microsoft/promptbench.""}",https://openreview.net{'value': '/pdf/6be8863976b902562dd8463aab34c8f5b9043bd6.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=DYd4vyyhUu,{'value': 'Optimal Kernel Choice for Score Function-based Causal Discovery'},Wenjie Wang; Biwei Huang; Feng Liu; Xinge You; Tongliang Liu; Kun Zhang; Mingming Gong,~Wenjie_Wang3; ~Biwei_Huang1; ~Feng_Liu2; ~Xinge_You1; ~Tongliang_Liu1; ~Kun_Zhang1; ~Mingming_Gong1,,"{'value': 'Score-based methods have demonstrated their effectiveness in discovering causal relationships by scoring different causal structures based on their goodness of fit to the data. Recently, Huang et al. proposed a generalized score function that can handle general data distributions and causal relationships by modeling the relations in reproducing kernel Hilbert space (RKHS). The selection of an appropriate kernel within this score function is crucial for accurately characterizing causal relationships and ensuring precise causal discovery. However, the current method involves manual heuristic selection of kernel parameters, making the process tedious and less likely to ensure optimality. In this paper, we propose a kernel selection method within the generalized score function that automatically selects the optimal kernel that best fits the data. Specifically, we model the generative process of the variables involved in each step of the causal graph search procedure as a mixture of independent noise variables. Based on this model, we derive an automatic kernel selection method by maximizing the marginal likelihood of the variables involved in each search step. We conduct experiments on both synthetic data and real-world benchmarks, and the results demonstrate that our proposed method outperforms heuristic kernel selection methods.'}",https://openreview.net{'value': '/pdf/7e2f6e43a57d1d8b68ebcf8547bbed8148f2fb37.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=DYN66IJCI9,{'value': 'Graph Distillation with Eigenbasis Matching'},Yang Liu; Deyu Bo; Chuan Shi,~Yang_Liu105; ~Deyu_Bo1; ~Chuan_Shi1,,"{'value': 'The increasing amount of graph data places requirements on the efficient training of graph neural networks (GNNs). The emerging graph distillation (GD) tackles this challenge by distilling a small synthetic graph to replace the real large graph, ensuring GNNs trained on real and synthetic graphs exhibit comparable performance. However, existing methods rely on GNN-related information as supervision, including gradients, representations, and trajectories, which have two limitations. First, GNNs can affect the spectrum (*i.e*., eigenvalues) of the real graph, causing *spectrum bias* in the synthetic graph. Second, the variety of GNN architectures leads to the creation of different synthetic graphs, requiring *traversal* to obtain optimal performance. To tackle these issues, we propose Graph Distillation with Eigenbasis Matching (GDEM), which aligns the eigenbasis and node features of real and synthetic graphs. Meanwhile, it directly replicates the spectrum of the real graph and thus prevents the influence of GNNs. Moreover, we design a discrimination constraint to balance the effectiveness and generalization of GDEM. Theoretically, the synthetic graphs distilled by GDEM are restricted spectral approximations of the real graphs. Extensive experiments demonstrate that GDEM outperforms state-of-the-art GD methods with powerful cross-architecture generalization ability and significant distillation efficiency. Our code is available at https://github.com/liuyang-tian/GDEM.'}",https://openreview.net{'value': '/pdf/317826b87750d6350c6761ef82758f92a2942fad.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=DYMj03Gbri,{'value': 'Agent Smith: A Single Image Can Jailbreak One Million Multimodal LLM Agents Exponentially Fast'},Xiangming Gu; Xiaosen Zheng; Tianyu Pang; Chao Du; Qian Liu; Ye Wang; Jing Jiang; Min Lin,~Xiangming_Gu1; ~Xiaosen_Zheng1; ~Tianyu_Pang1; ~Chao_Du1; ~Qian_Liu2; ~Ye_Wang3; ~Jing_Jiang1; ~Min_Lin1,,"{'value': 'A multimodal large language model (MLLM) agent can receive instructions, capture images, retrieve histories from memory, and decide which tools to use. Nonetheless, red-teaming efforts have revealed that adversarial images/prompts can jailbreak an MLLM and cause unaligned behaviors. In this work, we report an even more severe safety issue in multi-agent environments, referred to as infectious jailbreak. It entails the adversary simply jailbreaking a single agent, and without any further intervention from the adversary, (almost) all agents will become infected exponentially fast and exhibit harmful behaviors. To validate the feasibility of infectious jailbreak, we simulate multi-agent environments containing up to one million LLaVA-1.5 agents, and employ randomized pair-wise chat as a proof-of-concept instantiation for multi-agent interaction. Our results show that feeding an (infectious) adversarial image into the memory of any randomly chosen agent is sufficient to achieve infectious jailbreak. Finally, we derive a simple principle for determining whether a defense mechanism can provably restrain the spread of infectious jailbreak, but how to design a practical defense that meets this principle remains an open question to investigate.'}",https://openreview.net{'value': '/pdf/5e3d2c9612d18846d22f7e5dc0568925afb9f6ca.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=DRGgT7SyC7,{'value': 'Sparsest Models Elude Pruning: An Exposé of Pruning’s Current Capabilities'},Stephen Zhang; Vardan Papyan,~Stephen_Zhang4; ~Vardan_Papyan1,,"{'value': ""Pruning has emerged as a promising approach for compressing large-scale models, yet its effectiveness in recovering the sparsest of models has not yet been explored. We conducted an extensive series of 485,838 experiments, applying a range of state-of-the-art pruning algorithms to a synthetic dataset we created, named the Cubist Spiral. Our findings reveal a significant gap in performance compared to ideal sparse networks, which we identified through a novel combinatorial search algorithm. We attribute this performance gap to current pruning algorithms' poor behaviour under overparameterization, their tendency to induce disconnected paths throughout the network, and their propensity to get stuck at suboptimal solutions, even when given the optimal width and initialization. This gap is concerning, given the simplicity of the network architectures and datasets used in our study. We hope that our research encourages further investigation into new pruning techniques that strive for true network sparsity.""}",https://openreview.net{'value': '/pdf/5ebc86edc2e46cb0e084fafd9e92b6964719de43.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=Cw6Xl0g8a5,{'value': 'Probabilistic Conceptual Explainers: Trustworthy Conceptual Explanations for Vision Foundation Models'},Hengyi Wang; Shiwei Tan; Hao Wang,~Hengyi_Wang1; ~Shiwei_Tan1; ~Hao_Wang3,,"{'value': ""Vision transformers (ViTs) have emerged as a significant area of focus, particularly for their capacity to be jointly trained with large language models and to serve as robust vision foundation models. Yet, the development of trustworthy explanation methods for ViTs has lagged, particularly in the context of post-hoc interpretations of ViT predictions. Existing sub-image selection approaches, such as feature-attribution and conceptual models, fall short in this regard. This paper proposes five desiderata for explaining ViTs -- faithfulness, stability, sparsity, multi-level structure, and parsimony -- and demonstrates the inadequacy of current methods in meeting these criteria comprehensively. We introduce a variational Bayesian explanation framework, dubbed ProbAbilistic Concept Explainers (PACE), which models the distributions of patch embeddings to provide trustworthy post-hoc conceptual explanations. Our qualitative analysis reveals the distributions of patch-level concepts, elucidating the effectiveness of ViTs by modeling the joint distribution of patch embeddings and ViT's predictions. Moreover, these patch-level explanations bridge the gap between image-level and dataset-level explanations, thus completing the multi-level structure of PACE. Through extensive experiments on both synthetic and real-world datasets, we demonstrate that PACE surpasses state-of-the-art methods in terms of the defined desiderata.""}",https://openreview.net{'value': '/pdf/13c56028b7b7c9f62b980d737d41d5e97711f64f.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=CrUmgUaAQp,{'value': 'Should we be going MAD? A Look at Multi-Agent Debate Strategies for LLMs'},Andries Petrus Smit; Nathan Grinsztajn; Paul Duckworth; Thomas D Barrett; Arnu Pretorius,~Andries_Petrus_Smit1; ~Nathan_Grinsztajn1; ~Paul_Duckworth1; ~Thomas_D_Barrett1; ~Arnu_Pretorius1,,"{'value': 'Recent advancements in large language models (LLMs) underscore their potential for responding to inquiries in various domains. However, ensuring that generative agents provide accurate and reliable answers remains an ongoing challenge. In this context, multi-agent debate (MAD) has emerged as a promising strategy for enhancing the truthfulness of LLMs. We benchmark a range of debating and prompting strategies to explore the trade-offs between cost, time, and accuracy. Importantly, we find that multi-agent debating systems, in their current form, do not reliably outperform other proposed prompting strategies, such as self-consistency and ensembling using multiple reasoning paths. However, when performing hyperparameter tuning, several MAD systems, such as Multi-Persona, perform better. This suggests that MAD protocols might not be inherently worse than other approaches, but that they are more sensitive to different hyperparameter settings and difficult to optimize. We build on these results to offer insights into improving debating strategies, such as adjusting agent agreement levels, which can significantly enhance performance and even surpass all other non-debate protocols we evaluated. We provide an open-source repository to the community with several state-of-the-art protocols together with evaluation scripts to benchmark across popular research datasets.'}",https://openreview.net{'value': '/pdf/0fd2b81090b6d115f084feaf2cfe9313e49db29f.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=CiZN2OATRp,{'value': 'Statistical Inference Under Constrained Selection Bias'},Santiago Cortes-Gomez; Mateo Dulce Rubio; Carlos Miguel Patiño; Bryan Wilder,~Santiago_Cortes-Gomez1; ~Mateo_Dulce_Rubio1; ~Carlos_Miguel_Patiño1; ~Bryan_Wilder2,,"{'value': 'Large-scale datasets are increasingly being used to inform decision making. While this effort aims to ground policy in real-world evidence, challenges have arisen as selection bias and other forms of distribution shifts often plague observational data. Previous attempts to provide robust inference have given guarantees depending on a user-specified amount of possible distribution shift (e.g., the maximum KL divergence between the observed and target distributions). However, decision makers will often have additional knowledge about the target distribution which constrains the kind of possible shifts. To leverage such information, we propose a framework that enables statistical inference in the presence of selection bias which obeys user-specified constraints in the form of functions whose expectation is known under the target distribution. The output is high-probability bounds on the value of an estimand for the target distribution. Hence, our method leverages domain knowledge in order to partially identify a wide class of estimands. We analyze the computational and statistical properties of methods to estimate these bounds and show that our method can produce informative bounds on a variety of simulated and semisynthetic tasks, as well as in a real-world use case.'}",https://openreview.net{'value': '/pdf/40f57ae98c4eed622109f78f822811508a89a5fb.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=CgO2cuWWLV,{'value': 'Provable Interactive Learning with Hindsight Instruction Feedback'},Dipendra Misra; Aldo Pacchiano; Robert E. Schapire,~Dipendra_Misra1; ~Aldo_Pacchiano1; ~Robert_E._Schapire1,,"{'value': ""We study interactive learning in a setting where the agent has to generate a response (e.g., an action or trajectory) given a context and an instruction. In contrast, to typical approaches that train the system using reward or expert supervision on response, we study _learning with hindsight labeling_ where a teacher provides an instruction that is most suitable for the agent's generated response. This hindsight labeling of instruction is often easier to provide than providing expert supervision of the optimal response which may require expert knowledge or can be impractical to elicit. We initiate the theoretical analysis of _interactive learning with hindsight labeling_. We first provide a lower bound showing that in general, the regret of any algorithm must scale with the size of the agent's response space. Next, we study a specialized setting where the underlying instruction-response distribution can be decomposed as a low-rank matrix. We introduce an algorithm called LORIL for this setting and show that it is a no-regret algorithm with the regret scaling with $\\sqrt{T}$ and depends on the _intrinsic rank_ but does not depend on the agent's response space. We provide experiments showing the performance of LORIL in practice for 2 domains.""}",https://openreview.net{'value': '/pdf/0735abb7bf7cccff31f9eead95cfd02c4450334b.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2024,Conference
https://openreview.net/forum?id=BRfqYrikdo,{'value': 'WorkArena: How Capable are Web Agents at Solving Common Knowledge Work Tasks?'},Alexandre Drouin; Maxime Gasse; Massimo Caccia; Issam H. Laradji; Manuel Del Verme; Tom Marty; David Vazquez; Nicolas Chapados; Alexandre Lacoste,~Alexandre_Drouin2; ~Maxime_Gasse2; ~Massimo_Caccia1; ~Issam_H._Laradji1; ~Manuel_Del_Verme1; ~Tom_Marty1; ~David_Vazquez1; ~Nicolas_Chapados1; ~Alexandre_Lacoste1,,"{'value': ""We study the use of large language model-based agents for interacting with software via web browsers. Unlike prior work, we focus on measuring the agents' ability to perform tasks that span the typical daily work of knowledge workers utilizing enterprise software systems. To this end, we propose WorkArena, a remote-hosted benchmark of 33 tasks based on the widely-used ServiceNow platform. We also introduce BrowserGym, an environment for the design and evaluation of such agents, offering a rich set of actions as well as multimodal observations. Our empirical evaluation reveals that while current agents show promise on WorkArena, there remains a considerable gap towards achieving full task automation. Notably, our analysis uncovers a significant performance disparity between open and closed-source LLMs, highlighting a critical area for future exploration and development in the field.""}",https://openreview.net{'value': '/pdf/0c811411201e47d4cf23053011bc7b2fcb7f36d4.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=BPQHXwVNvl,{'value': 'Online Speculative Decoding'},Xiaoxuan Liu; Lanxiang Hu; Peter Bailis; Alvin Cheung; Zhijie Deng; Ion Stoica; Hao Zhang,~Xiaoxuan_Liu2; ~Lanxiang_Hu1; ~Peter_Bailis2; ~Alvin_Cheung2; ~Zhijie_Deng1; ~Ion_Stoica1; ~Hao_Zhang2,,"{'value': ""Speculative decoding is a pivotal technique to accelerate the inference of large language models (LLMs) by employing a smaller draft model to predict the target model's outputs. However, its efficacy can be limited due to the low predictive accuracy of the draft model, particularly when faced with diverse text inputs and a significant capability gap between the draft and target models. We introduce online speculative decoding to address this challenge. The main idea is to continuously update the (multiple) draft model(s) on observed user query data. Adapting to query distribution mitigates the shifts between the training distribution of the draft model and the query distribution, enabling the draft model to more accurately predict the target model's outputs. We develop a prototype of online speculative decoding based on knowledge distillation and evaluate it using both synthetic and real query data. The results show a substantial increase in the token acceptance rate by 0.1 to 0.65, bringing 1.42x to 2.17x latency reduction. Our code is available at https://github.com/LiuXiaoxuanPKU/OSD.""}",https://openreview.net{'value': '/pdf/a16e9f7afdd698f8df25df799c107004e4f29707.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=BNAvYSCrLD,{'value': 'In-Context Learning Agents Are Asymmetric Belief Updaters'},Johannes A. Schubert; Akshay Kumar Jagadish; Marcel Binz; Eric Schulz,~Johannes_A._Schubert1; ~Akshay_Kumar_Jagadish1; ~Marcel_Binz1; ~Eric_Schulz1,,"{'value': 'We study the in-context learning dynamics of large language models (LLMs) using three instrumental learning tasks adapted from cognitive psychology. We find that LLMs update their beliefs in an asymmetric manner and learn more from better-than-expected outcomes than from worse-than-expected ones. Furthermore, we show that this effect reverses when learning about counterfactual feedback and disappears when no agency is implied. We corroborate these findings by investigating idealized in-context learning agents derived through meta-reinforcement learning, where we observe similar patterns. Taken together, our results contribute to our understanding of how in-context learning works by highlighting that the framing of a problem significantly influences how learning occurs, a phenomenon also observed in human cognition.'}",https://openreview.net{'value': '/pdf/7e0ee1d5685d79e1226f09684e2d571594b49c22.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=BCEtumPYDt,{'value': 'Uncertainty for Active Learning on Graphs'},Dominik Fuchsgruber; Tom Wollschläger; Bertrand Charpentier; Antonio Oroz; Stephan Günnemann,~Dominik_Fuchsgruber1; ~Tom_Wollschläger1; ~Bertrand_Charpentier2; ~Antonio_Oroz1; ~Stephan_Günnemann1,,"{'value': 'Uncertainty Sampling is an Active Learning strategy that aims to improve the data efficiency of machine learning models by iteratively acquiring labels of data points with the highest uncertainty. While it has proven effective for independent data its applicability to graphs remains under-explored. We propose the first extensive study of Uncertainty Sampling for node classification: **(1)** We benchmark Uncertainty Sampling beyond predictive uncertainty and highlight a significant performance gap to other Active Learning strategies. **(2)** We develop ground-truth Bayesian uncertainty estimates in terms of the data generating process and prove their effectiveness in guiding Uncertainty Sampling toward optimal queries. We confirm our results on synthetic data and design an approximate approach that consistently outperforms other uncertainty estimators on real datasets. **(3)** Based on this analysis, we relate pitfalls in modeling uncertainty to existing methods. Our analysis enables and informs the development of principled uncertainty estimation on graphs.'}",https://openreview.net{'value': '/pdf/a0959fb86ec0469b6380322f18a880cf7bf7f312.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=B1W712hMBi,{'value': 'NExT: Teaching Large Language Models to Reason about Code Execution'},Ansong Ni; Miltiadis Allamanis; Arman Cohan; Yinlin Deng; Kensen Shi; Charles Sutton; Pengcheng Yin,~Ansong_Ni1; ~Miltiadis_Allamanis1; ~Arman_Cohan1; ~Yinlin_Deng1; ~Kensen_Shi1; ~Charles_Sutton1; ~Pengcheng_Yin1,,"{'value': 'A fundamental skill among human developers is the ability to understand and reason about program execution. As an example, a programmer can mentally simulate code execution in natural language to debug and repair code (aka. rubber duck debugging). However, large language models (LLMs) of code are typically trained on the surface textual form of programs, thus may lack a semantic understanding of how programs execute at run-time. To address this issue, we propose NExT, a method to teach LLMs to inspect the execution traces of programs (variable states of executed lines) and reason about their run-time behavior through chain-of-thought (CoT) rationales. Specifically, NExT uses self-training to bootstrap a synthetic training set of execution-aware rationales that lead to correct task solutions (e.g., fixed programs) without laborious manual annotation. Experiments on program repair tasks based on MBPP and HumanEval demonstrate that NExT improves the fix rate of a PaLM 2 model, by 26.1% and 10.3% absolute, respectively, with significantly improved rationale quality as verified by automated metrics and human raters. Our model can also generalize to scenarios where program traces are absent at test-time.'}",https://openreview.net{'value': '/pdf/a415d96356e8fc8bcc1dfd9b9d0cedbd3b815dbf.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=AVEc9LvSlO,"{'value': ""Experts Don't Cheat: Learning What You Don't Know By Predicting Pairs""}",Daniel D. Johnson; Daniel Tarlow; David Duvenaud; Chris J. Maddison,~Daniel_D._Johnson1; ~Daniel_Tarlow1; ~David_Duvenaud2; ~Chris_J._Maddison1,,"{'value': 'Identifying how much a model $\\hat{p}\\_{Y|X}^{\\theta}$ knows about the stochastic real-world process $p\\_{Y|X}$ it was trained on is important to ensure it avoids producing incorrect or ""hallucinated"" answers or taking unsafe actions. But this is difficult for generative models because probabilistic predictions do not distinguish between per-response noise (aleatoric uncertainty) and lack of knowledge about the process (epistemic uncertainty), and existing epistemic uncertainty quantification techniques tend to be overconfident when the model underfits. We propose a general strategy for teaching a model to both approximate $p\\_{Y|X}$ and also estimate the remaining gaps between $\\hat{p}_{Y|X}^{\\theta}$ and $p\\_{Y|X}$: train it to predict *pairs* of independent responses drawn from the true conditional distribution, allow it to ""cheat"" by observing one response while predicting the other, then measure how much it cheats. Remarkably, we prove that being good at cheating (i.e. cheating whenever it improves your prediction) is equivalent to being *second-order calibrated*, a principled extension of ordinary calibration that allows us to construct provably-correct frequentist confidence intervals for $p\\_{Y|X}$ and detect incorrect responses with high probability. We demonstrate empirically that our approach accurately estimates how much models don\'t know across ambiguous image classification, (synthetic) language modeling, and partially-observable navigation tasks, outperforming existing techniques.'}",https://openreview.net{'value': '/pdf/9cf59fde42aece4313abd28a189ffa842e439598.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=AG45XqwPKU,{'value': 'Learning Exceptional Subgroups by End-to-End Maximizing KL-Divergence'},Sascha Xu; Nils Philipp Walter; Janis Kalofolias; Jilles Vreeken,~Sascha_Xu1; ~Nils_Philipp_Walter1; ~Janis_Kalofolias1; ~Jilles_Vreeken2,,"{'value': 'Finding and describing sub-populations that are exceptional in terms of a target property has important applications in many scientific disciplines, from identifying disadvantaged demographic groups in census data to finding conductive molecules within gold nanoparticles. Current approaches to finding such subgroups require pre-discretized predictive variables, do not permit non-trivial target distributions, do not scale to large datasets, and struggle to find diverse results. To address these limitations, we propose SYFLOW, an end-to-end optimizable approach in which we leverage normalizing flows to model arbitrary target distributions and introduce a novel neural layer that results in easily interpretable subgroup descriptions. We demonstrate on synthetic data, real-world data, and via a case study, that SYFLOW reliably finds highly exceptional subgroups accompanied by insightful descriptions.'}",https://openreview.net{'value': '/pdf/d1dca98d0c3e90f8af6232d60f15e1618d745c93.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=A9hJvQHEEP,{'value': 'Quantum Theory and Application of Contextual Optimal Transport'},Nicola Mariella; Albert Akhriev; Francesco Tacchino; Christa Zoufal; Juan Carlos Gonzalez-Espitia; Benedek Harsanyi; Eugene Koskin; Ivano Tavernelli; Stefan Woerner; Marianna Rapsomaniki; Sergiy Zhuk; Jannis Born,~Nicola_Mariella1; albert_akhriev@ie.ibm.com; fta@zurich.ibm.com; ~Christa_Zoufal1; juan.carlos.gonzalez.espitia@ibm.com; benedek.harsanyi@ibm.com; eugin.koskin@gmail.com; ita@zurich.ibm.com; ~Stefan_Woerner1; ~Marianna_Rapsomaniki1; ~Sergiy_Zhuk1; ~Jannis_Born1,,"{'value': ""Optimal Transport (OT) has fueled machine learning (ML) across many domains. When paired data measurements $(\\boldsymbol{\\mu}, \\boldsymbol{\\nu})$ are coupled to covariates, a challenging conditional distribution learning setting arises. Existing approaches for learning a *global* transport map parameterized through a potentially unseen context utilize Neural OT and largely rely on Brenier's theorem. Here, we propose a first-of-its-kind quantum computing formulation for amortized optimization of contextualized transportation plans. We exploit a direct link between doubly stochastic matrices and unitary operators thus unravelling a natural connection between OT and quantum computation. We verify our method (QontOT) on synthetic and real data by predicting variations in cell type distributions conditioned on drug dosage. Importantly we conduct a 24-qubit hardware experiment on a task challenging for classical computers and report a performance that cannot be matched with our classical neural OT approach. In sum, this is a first step toward learning to predict contextualized transportation plans through quantum computing.""}",https://openreview.net{'value': '/pdf/c3d9690be4d962086c8000e56ca80effe2b240d3.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=9xUpLGAOy9,{'value': 'Chain-of-Thought Predictive Control'},Zhiwei Jia; Vineet Thumuluri; Fangchen Liu; Linghao Chen; Zhiao Huang; Hao Su,~Zhiwei_Jia1; ~Vineet_Thumuluri1; ~Fangchen_Liu2; ~Linghao_Chen2; ~Zhiao_Huang1; ~Hao_Su1,,"{'value': 'We study generalizable policy learning from demonstrations for complex low-level control (e.g., contact-rich object manipulations). We propose a novel hierarchical imitation learning method that utilizes sub-optimal demos. Firstly, we propose an observation space-agnostic approach that efficiently discovers the multi-step subskill decomposition of the demos in an unsupervised manner. By grouping temporarily close and functionally similar actions into subskill-level demo segments, the observations at the segment boundaries constitute a chain of planning steps for the task, which we refer to as the chain-of-thought (CoT). Next, we propose a Transformer-based design that effectively learns to predict the CoT as the subskill-level guidance. We couple action and subskill predictions via learnable prompt tokens and a hybrid masking strategy, which enable dynamically updated guidance at test time and improve feature representation of the trajectory for generalizable policy learning. Our method, Chain-of-Thought Predictive Control (CoTPC), consistently surpasses existing strong baselines on various challenging low-level manipulation tasks with sub-optimal demos. See project page at https://sites.google.com/view/cotpc.'}",https://openreview.net{'value': '/pdf/36291353613f34f7dfaae8532cf48373ce9cd197.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2024,Conference
https://openreview.net/forum?id=9cG1oRnqNd,{'value': 'Curated LLM: Synergy of LLMs and Data Curation for tabular augmentation in low-data regimes'},Nabeel Seedat; Nicolas Huynh; Boris van Breugel; Mihaela van der Schaar,~Nabeel_Seedat1; ~Nicolas_Huynh1; ~Boris_van_Breugel2; ~Mihaela_van_der_Schaar2,,"{'value': 'Machine Learning (ML) in low-data settings remains an underappreciated yet crucial problem. Hence, data augmentation methods to increase the sample size of datasets needed for ML are key to unlocking the transformative potential of ML in data-deprived regions and domains. Unfortunately, the limited training set constrains traditional tabular synthetic data generators in their ability to generate a large and diverse augmented dataset needed for ML tasks. To address this challenge, we introduce $\\texttt{CLLM}$, which leverages the prior knowledge of Large Language Models (LLMs) for data augmentation in the low-data regime. However, not all the data generated by LLMs will improve downstream utility, as for any generative model. Consequently, we introduce a principled curation mechanism, leveraging learning dynamics, coupled with confidence and uncertainty metrics, to obtain a high-quality dataset. Empirically, on multiple real-world datasets, we demonstrate the superior performance of $\\texttt{CLLM}$ in the low-data regime compared to conventional generators. Additionally, we provide insights into the LLM generation and curation mechanism, shedding light on the features that enable them to output high-quality augmented datasets.'}",https://openreview.net{'value': '/pdf/22f7cdf74f49877c6c6c1aa16514c013b223c300.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=9QRcp2ubDt,{'value': 'Centralized Selection with Preferences in the Presence of Biases'},L. Elisa Celis; Amit Kumar; Nisheeth K. Vishnoi; Andrew Xu,~L._Elisa_Celis2; ~Amit_Kumar7; ~Nisheeth_K._Vishnoi2; andrew.xu@yale.edu,,"{'value': ""This paper considers the scenario in which there are multiple institutions, each with a limited capacity for candidates, and candidates, each with preferences over the institutions. A central entity evaluates the utility of each candidate to the institutions, and the goal is to select candidates for each institution in a way that maximizes utility while also considering the candidates' preferences. The paper focuses on the setting in which candidates are divided into multiple groups and the observed utilities of candidates in some groups are biased--systematically lower than their true utilities. The first result is that, in these biased settings, prior algorithms can lead to selections with sub-optimal true utility and significant discrepancies in the fraction of candidates from each group that get their preferred choices. Subsequently, an algorithm is presented along with proof that it produces selections that achieve near-optimal group fairness with respect to preferences while also nearly maximizing the true utility under distributional assumptions. Further, extensive empirical validation of these results in real-world and synthetic settings, in which the distributional assumptions may not hold, are presented.""}",https://openreview.net{'value': '/pdf/a277d91287831c2afa5e8509714b8e1be5d25e4c.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=9HdQr68Zyl,{'value': 'Open-Domain Text Evaluation via Contrastive Distribution Methods'},Sidi Lu; Hongyi Liu; Asli Celikyilmaz; Tianlu Wang; Nanyun Peng,~Sidi_Lu1; ~Hongyi_Liu4; ~Asli_Celikyilmaz1; ~Tianlu_Wang1; ~Nanyun_Peng1,,"{'value': ""Recent advancements in open-domain text generation, driven by the power of large pre-trained language models (LLMs), have demonstrated remarkable performance. However, assessing these models' generation quality remains a challenge. In this paper, we introduce a novel method for evaluating open-domain text generation called Contrastive Distribution Methods (CDM). Leveraging the connection between increasing model parameters and enhanced LLM performance, CDM creates a mapping from the _contrast_ of two probabilistic distributions -- one known to be superior to the other -- to quality measures. We investigate CDM for open-domain text generation evaluation under two paradigms: 1) _Generative_ CDM, which harnesses the contrast of two language models' distributions to generate synthetic examples for training discriminator-based metrics; 2) _Discriminative_ CDM, which directly uses distribution disparities between two language models for evaluation. Our experiments on coherence evaluation for multi-turn dialogue and commonsense evaluation for controllable generation demonstrate CDM's superior correlate with human judgment than existing automatic evaluation metrics, highlighting the strong performance and generalizability of our approach.""}",https://openreview.net{'value': '/pdf/612ce3f0d748296f9c4ecd89d41d6a19378bdfaf.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=8uzBOVmh8H,{'value': 'CLLMs: Consistency Large Language Models'},Siqi Kou; Lanxiang Hu; Zhezhi He; Zhijie Deng; Hao Zhang,~Siqi_Kou1; ~Lanxiang_Hu1; ~Zhezhi_He1; ~Zhijie_Deng1; ~Hao_Zhang2,,"{'value': 'Jacobi decoding shows promise for more efficient LLM inference as it breaks the sequential nature of the LLM decoding process and transforms it into more parallelizable computation. However, in practice, it achieves little speedup compared to traditional autoregressive (AR) decoding, primarily because Jacobi decoding seldom accurately predicts more than one token in a single fixed-point iteration step. To address this, we develop a new approach aimed at realizing fast convergence from any state to the fixed point in a Jacobi trajectory. This is accomplished by refining the target LLM to consistently predict the fixed point given any state as input. Extensive experiments demonstrate the effectiveness of our method, showing 2.4$\\times$ to 3.4$\\times$ improvements in generation speed while preserving generation quality across both domain-specific and open-domain benchmarks.'}",https://openreview.net{'value': '/pdf/1021dbc76059c1f6463349283933064bffd8bf96.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2024,Conference
https://openreview.net/forum?id=8mKXMnhnFW,{'value': 'Sharpness-Aware Data Generation for Zero-shot Quantization'},Hoang Anh Dung; Cuong Pham; Trung Le; Jianfei Cai; Thanh-Toan Do,~Hoang_Anh_Dung1; ~Cuong_Pham3; ~Trung_Le2; ~Jianfei_Cai1; ~Thanh-Toan_Do4,,"{'value': 'Zero-shot quantization aims to learn a quantized model from a pre-trained full-precision model with no access to original real training data. The common idea in zero-shot quantization approaches is to generate synthetic data for quantizing the full-precision model. While it is well-known that deep neural networks with low sharpness have better generalization ability, none of the previous zero-shot quantization works considers the sharpness of the quantized model as a criterion for generating training data. This paper introduces a novel methodology that takes into account quantized model sharpness in synthetic data generation to enhance generalization. Specifically, we first demonstrate that sharpness minimization can be attained by maximizing gradient matching between the reconstruction loss gradients computed on synthetic and real validation data, under certain assumptions. We then circumvent the problem of the gradient matching without real validation set by approximating it with the gradient matching between each generated sample and its neighbors. Experimental evaluations on CIFAR-100 and ImageNet datasets demonstrate the superiority of the proposed method over the state-of-the-art techniques in low-bit quantization settings.'}",https://openreview.net{'value': '/pdf/cbd8e58793e2c219a4cdd21b53b12e60ad30d68b.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=8m4V6Fx6ma,{'value': 'Optimal Exact Recovery in Semi-Supervised Learning: A Study of Spectral Methods and Graph Convolutional Networks'},Haixiao Wang; Zhichao Wang,~Haixiao_Wang1; ~Zhichao_Wang3,,"{'value': 'We delve into the challenge of semi-supervised node classification on the Contextual Stochastic Block Model (CSBM) dataset. Here, nodes from the two-cluster Stochastic Block Model (SBM) are coupled with feature vectors, which are derived from a Gaussian Mixture Model (GMM) that corresponds to their respective node labels. With only a subset of the CSBM node labels accessible for training, our primary objective becomes the accurate classification of the remaining nodes. Venturing into the transductive learning landscape, we, for the first time, pinpoint the information-theoretical threshold for the exact recovery of all test nodes in CSBM. Concurrently, we design an optimal spectral estimator inspired by Principal Component Analysis (PCA) with the training labels and essential data from both the adjacency matrix and feature vectors. We also evaluate the efficacy of graph ridge regression and Graph Convolutional Networks (GCN) on this synthetic dataset. Our findings underscore that graph ridge regression and GCN possess the ability to achieve the information threshold of exact recovery in a manner akin to the optimal estimator when using the optimal weighted self-loops. This highlights the potential role of feature learning in augmenting the proficiency of GCN, especially in the realm of semi-supervised learning.'}",https://openreview.net{'value': '/pdf/d5ca09c6a313daea686586d818939878e11595b2.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=8VEGkphQaK,{'value': 'Towards an Understanding of Stepwise Inference in Transformers: A Synthetic Graph Navigation Model'},Mikail Khona; Maya Okawa; Jan Hula; Rahul Ramesh; Kento Nishi; Robert P. Dick; Ekdeep Singh Lubana; Hidenori Tanaka,~Mikail_Khona2; ~Maya_Okawa1; ~Jan_Hula1; ~Rahul_Ramesh2; ~Kento_Nishi1; ~Robert_P._Dick1; ~Ekdeep_Singh_Lubana1; ~Hidenori_Tanaka1,,"{'value': 'Stepwise inference protocols, such as scratchpads and chain-of-thought, help language models solve complex problems by decomposing them into a sequence of simpler subproblems. To unravel the underlying mechanisms of stepwise inference we propose to study autoregressive Transformer models on a synthetic task that embodies the multi-step nature of problems where stepwise inference is generally most useful. Specifically, we define a graph navigation problem wherein a model is tasked with traversing a path from a start to a goal node on the graph. We find we can empirically reproduce and analyze several phenomena observed at scale: (i) the stepwise inference reasoning gap, the cause of which we find in the structure of the training data; (ii) a diversity-accuracy trade-off in model generations as sampling temperature varies; (iii) a simplicity bias in the model’s output; and (iv) compositional generalization and a primacy bias with in-context exemplars. Overall, our work introduces a grounded, synthetic framework for studying stepwise inference and offers mechanistic hypotheses that can lay the foundation for a deeper understanding of this phenomenon.'}",https://openreview.net{'value': '/pdf/42cc2e3998e69cc10e4d7fdb1bcbcfb2fa8cbdfd.pdf'},{'title_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=8PTx4CpNoT,{'value': 'Emergent Representations of Program Semantics in Language Models Trained on Programs'},Charles Jin; Martin Rinard,~Charles_Jin1; ~Martin_Rinard1,,"{'value': 'We present evidence that language models (LMs) of code can learn to represent the formal semantics of programs, despite being trained only to perform next-token prediction. Specifically, we train a Transformer model on a synthetic corpus of programs written in a domain-specific language for navigating 2D grid world environments. Each program in the corpus is preceded by a (partial) specification in the form of several input-output grid world states. Despite providing no further inductive biases, we find that a probing classifier is able to extract increasingly accurate representations of the *unobserved, intermediate* grid world states from the LM hidden states over the course of training, suggesting the LM acquires an emergent ability to *interpret* programs in the formal sense. We also develop a novel interventional baseline that enables us to disambiguate what is represented by the LM as opposed to learned by the probe. We anticipate that this technique may be generally applicable to a broad range of *semantic* probing experiments. In summary, this paper does not propose any new techniques for training LMs of code, but develops an experimental framework for and provides insights into the acquisition and representation of formal semantics in statistical models of code.'}",https://openreview.net{'value': '/pdf/73c9961e93ee6386b96ebffc894ee9079c5e13c8.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=7gEcbhMqKU,{'value': 'Faster Sampling via Stochastic Gradient Proximal Sampler'},Xunpeng Huang; Difan Zou; Hanze Dong; Yian Ma; Tong Zhang,~Xunpeng_Huang2; ~Difan_Zou1; ~Hanze_Dong1; ~Yian_Ma1; ~Tong_Zhang2,,"{'value': 'Stochastic gradients have been widely integrated into Langevin-based methods to improve their scalability and efficiency in solving large-scale sampling problems. However, the proximal sampler, which exhibits much faster convergence than Langevin-based algorithms in the deterministic setting (Lee et al., 2021), has yet to be explored in its stochastic variants. In this paper, we study the Stochastic Proximal Samplers (SPS) for sampling from non-log-concave distributions. We first establish a general framework for implementing stochastic proximal samplers and establish the convergence theory accordingly. We show that the convergence to the target distribution can be guaranteed as long as the second moment of the algorithm trajectory is bounded and restricted Gaussian oracles can be well approximated. We then provide two implementable variants based on Stochastic gradient Langevin dynamics (SGLD) and Metropolis-adjusted Langevin algorithm (MALA), giving rise to SPS-SGLD and SPS-MALA. We further show that SPS-SGLD and SPS-MALA can achieve $\\epsilon$-sampling error in total variation (TV) distance within $\\tilde{\\mathcal{O}}(d\\epsilon^{-2})$ and $\\tilde{\\mathcal{O}}(d^{1/2}\\epsilon^{-2})$ gradient complexities, which outperform the best-known result by at least an $\\tilde{\\mathcal{O}}(d^{1/3})$ factor. This enhancement in performance is corroborated by our empirical studies on synthetic data with various dimensions, demonstrating the efficiency of our proposed algorithm.'}",https://openreview.net{'value': '/pdf/f79171a7219615f15a0e89b6ef88c4ef330d6bdf.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=7ckuC9C2FZ,{'value': 'NeuralIndicator: Implicit Surface Reconstruction from Neural Indicator Priors'},Shi-Sheng Huang; Guo Chen; CHEN LI HENG; Hua Huang,~Shi-Sheng_Huang2; ~Guo_Chen6; ~CHEN_LI_HENG1; ~Hua_Huang1,,"{'value': 'The neural implicit surface reconstruction from unorganized points is still challenging, especially when the point clouds are incomplete and/or noisy with complex topology structure. Unlike previous approaches performing neural implicit surface learning relying on local shape priors, this paper proposes to utilize global shape priors to regularize the neural implicit function learning for more reliable surface reconstruction. To this end, we first introduce a differentiable module to generate a smooth indicator function, which globally encodes both the indicative prior and local SDFs of the entire input point cloud. Benefit from this, we propose a new framework, called NeuralIndicator, to jointly learn both the smooth indicator function and neural implicit function simultaneously, using the global shape prior encoded by smooth indicator function to effectively regularize the neural implicit function learning, towards reliable and high-fidelity surface reconstruction from unorganized points without any normal information. Extensive evaluations on synthetic and real-scan datasets show that our approach consistently outperforms previous approaches, especially when point clouds are incomplete and/or noisy with complex topology structure.'}",https://openreview.net{'value': '/pdf/b2723850d3769dbc0e7cd8fc2a4f6454a6f5283c.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=7RSIGQRT1F,{'value': 'A Geometric Decomposition of Finite Games: Convergence vs. Recurrence under Exponential Weights'},Davide Legacci; Panayotis Mertikopoulos; Bary Pradelski,davide.legacci@univ-grenoble-alpes.fr; ~Panayotis_Mertikopoulos1; ~Bary_Pradelski1,,"{'value': ""In view of the complexity of the dynamics of learning in games, we seek to decompose a game into simpler components where the dynamics' long-run behavior is well understood. A natural starting point for this is Helmholtz's theorem, which decomposes a vector field into a potential and an incompressible component. However, the geometry of game dynamics - and, in particular, the dynamics of exponential / multiplicative weights (EW) schemes - is not compatible with the Euclidean underpinnings of Helmholtz's theorem. This leads us to consider a specific Riemannian framework based on the so-called *Shahshahani metric*, and introduce the class of *incompressible games*, for which we establish the following results: First, in addition to being volume-preserving, the continuous-time EW dynamics in incompressible games admit a constant of motion and are *Poincaré recurrent* - i.e., almost every trajectory of play comes arbitrarily close to its starting point infinitely often. Second, we establish a deep connection with a well-known decomposition of games into a potential and harmonic component (where the players' objectives are aligned and anti-aligned respectively): a game is incompressible if and only if it is harmonic, implying in turn that the EW dynamics lead to Poincaré recurrence in harmonic games.""}",https://openreview.net{'value': '/pdf/702a846f0fb2f5eb95529060a73d3176764d92de.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2024,Conference
https://openreview.net/forum?id=72oT4mPLUb,{'value': 'From Self-Attention to Markov Models: Unveiling the Dynamics of Generative Transformers'},Muhammed Emrullah Ildiz; Yixiao Huang; Yingcong Li; Ankit Singh Rawat; Samet Oymak,~Muhammed_Emrullah_Ildiz1; ~Yixiao_Huang3; ~Yingcong_Li1; ~Ankit_Singh_Rawat1; ~Samet_Oymak2,,"{'value': 'Modern language models rely on the transformer architecture and attention mechanism to perform language understanding and text generation. In this work, we study learning a 1-layer self-attention model from a set of prompts and the associated outputs sampled from the model. We first establish a formal link between the self-attention mechanism and Markov models under suitable conditions: Inputting a prompt to the self-attention model samples the output token according to a *context-conditioned Markov chain* (CCMC). *CCMC* is obtained by weighing the transition matrix of a standard Markov chain according to the sufficient statistics of the prompt/context. Building on this formalism, we develop identifiability/coverage conditions for the data distribution that guarantee consistent estimation of the latent model under a teacher-student setting and establish sample complexity guarantees under IID data. Finally, we study the problem of learning from a single output trajectory generated in response to an initial prompt. We characterize a *winner-takes-all* phenomenon where the generative process of self-attention evolves to sampling from a small set of *winner tokens* that dominate the context window. This provides a mathematical explanation to the tendency of modern LLMs to generate repetitive text.'}",https://openreview.net{'value': '/pdf/c5420e5129bcbe1ac3a75e9281092cc45efd0a90.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2024,Conference
https://openreview.net/forum?id=6wVlH96oMX,{'value': 'Leveraging Self-Consistency for Data-Efficient Amortized Bayesian Inference'},Marvin Schmitt; Desi R. Ivanova; Daniel Habermann; Ullrich Koethe; Paul-Christian Bürkner; Stefan T. Radev,~Marvin_Schmitt1; ~Desi_R._Ivanova1; ~Daniel_Habermann1; ~Ullrich_Koethe1; ~Paul-Christian_Bürkner1; ~Stefan_T._Radev1,,"{'value': ""We propose a method to improve the efficiency and accuracy of amortized Bayesian inference by leveraging universal symmetries in the joint probabilistic model of parameters and data. In a nutshell, we invert Bayes' theorem and estimate the marginal likelihood based on approximate representations of the joint model. Upon perfect approximation, the marginal likelihood is constant across all parameter values by definition. However, errors in approximate inference lead to undesirable variance in the marginal likelihood estimates across different parameter values. We penalize violations of this symmetry with a self-consistency loss which significantly improves the quality of approximate inference in low data regimes and can be used to augment the training of popular neural density estimators. We apply our method to a number of synthetic problems and realistic scientific models, discovering notable advantages in the context of both neural posterior and likelihood approximation.""}",https://openreview.net{'value': '/pdf/b8746aa40e326b981a332ce8985a13530fd4dcdb.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=6n99bIxb3r,"{'value': 'Tackling Prevalent Conditions in Unsupervised Combinatorial Optimization: Cardinality, Minimum, Covering, and More'}",Fanchen Bu; Hyeonsoo Jo; Soo Yong Lee; Sungsoo Ahn; Kijung Shin,~Fanchen_Bu1; ~Hyeonsoo_Jo1; ~Soo_Yong_Lee1; ~Sungsoo_Ahn1; ~Kijung_Shin2,,"{'value': 'Combinatorial optimization (CO) is naturally discrete, making machine-learning techniques based on differentiable optimization inapplicable. Karalias & Loukas (2020) adapted the probabilistic method by Erdős & Spencer (1974), to incorporate CO into differentiable optimization. Their work ignited the research on unsupervised learning for CO, composed of two main components: probabilistic objectives and derandomization. However, each component confronts unique challenges. First, deriving objectives under complex conditions and constraints is nontrivial. Second, the derandomization process is underexplored, and the existing derandomization methods are either random sampling or naive rounding. In this work, we aim to tackle complex conditions in unsupervised CO. First, we concretize the targets for probabilistic objective construction and derandomization with theoretical justification. Then, for various complex conditions commonly involved in different CO problems, we derive nontrivial objectives and derandomization to meet the targets. Finally, we apply the derivations to various CO problems. Via extensive experiments on synthetic and real-world graphs, we validate the correctness of our derivations and show our empirical superiority w.r.t. both optimization quality and speed.'}",https://openreview.net{'value': '/pdf/b732bf69231edf5c3713322de2dff28ce4ba795b.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=6Zl9rv6PDx,{'value': 'Causal Action Influence Aware Counterfactual Data Augmentation'},Núria Armengol Urpí; Marco Bagatella; Marin Vlastelica; Georg Martius,~Núria_Armengol_Urpí1; ~Marco_Bagatella1; ~Marin_Vlastelica1; ~Georg_Martius1,,"{'value': 'Offline data are both valuable and practical resources for teaching robots complex behaviors. Ideally, learning agents should not be constrained by the scarcity of available demonstrations, but rather generalize beyond the training distribution. However, the complexity of real-world scenarios typically requires huge amounts of data to prevent neural network policies from picking up on spurious correlations and learning non-causal relationships. We propose CAIAC, a data augmentation method that can create feasible synthetic transitions from a fixed dataset without having access to online environment interactions. By utilizing principled methods for quantifying causal influence, we are able to perform counterfactual reasoning by swapping $\\textit{action}$-unaffected parts of the state-space between independent trajectories in the dataset. We empirically show that this leads to a substantial increase in robustness of offline learning algorithms against distributional shift.'}",https://openreview.net{'value': '/pdf/957b6ba3a663e0817dcfd30eff78129efb7cc953.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=6CV1N7hhpA,{'value': 'Stationarity without mean reversion in improper Gaussian processes'},Luca Ambrogioni,~Luca_Ambrogioni1,,"{'value': 'The behavior of a GP regression depends on the choice of covariance function. Stationary covariance functions are preferred in machine learning applications. However, (non-periodic) stationary covariance functions are always mean reverting and can therefore exhibit pathological behavior when applied to data that does not relax to a fixed global mean value. In this paper we show that it is possible to use improper GP priors with infinite variance to define processes that are stationary but not mean reverting. To this aim, we use of non-positive kernels that can only be defined in this limit regime. The resulting posterior distributions can be computed analytically and it involves a simple correction of the usual formulas. The main contribution of the paper is the introduction of a large family of smooth non-reverting covariance functions that closely resemble the kernels commonly used in the GP literature (e.g. squared exponential and Matérn class). By analyzing both synthetic and real data, we demonstrate that these non-positive kernels solve some known pathologies of mean reverting GP regression while retaining most of the favorable properties of ordinary smooth stationary kernels.'}",https://openreview.net{'value': '/pdf/720dfb9e4f9e2bc9e209b985277b9ee6f9b50e32.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=60F0fVbknK,{'value': 'Learning Causal Relations from Subsampled Time Series with Two Time-Slices'},Anpeng Wu; Haoxuan Li; Kun Kuang; Zhang Keli; Fei Wu,~Anpeng_Wu1; ~Haoxuan_Li6; ~Kun_Kuang1; ~Zhang_Keli1; ~Fei_Wu1,,"{'value': 'This paper studies the causal relations from subsampled time series, in which measurements are sparse and sampled at a coarser timescale than the causal timescale of the underlying system. In such data, because there are numerous missing time-slices (i.e., cross-sections at each time point) between two consecutive measurements, conventional causal discovery methods designed for standard time series data would produce significant errors. To learn causal relations from subsampled time series, a typical solution is to conduct different interventions and then make a comparison. However, full interventions are often expensive, unethical, or even infeasible, particularly in fields such as health and social science. In this paper, we first explore how readily available two-time-slices data can replace intervention data to improve causal ordering, and propose a novel Descendant Hierarchical Topology algorithm with Conditional Independence Test (DHT-CIT) to learn causal relations from subsampled time series using only two time-slices. Specifically, we develop a conditional independence criterion that can be applied iteratively to test each node from time series and identify all of its descendant nodes. Empirical results on both synthetic and real-world datasets demonstrate the superiority of our DHT-CIT algorithm.'}",https://openreview.net{'value': '/pdf/64c6826ef93be3cb63a4fb5ffeaf19147db488ab.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=5lI9wm4dws,{'value': 'Doubly Robust Causal Effect Estimation under Networked Interference via Targeted Learning'},Weilin Chen; Ruichu Cai; Zeqin Yang; Jie Qiao; Yuguang Yan; Zijian Li; Zhifeng Hao,~Weilin_Chen1; ~Ruichu_Cai1; ~Zeqin_Yang1; ~Jie_Qiao1; ~Yuguang_Yan1; ~Zijian_Li1; ~Zhifeng_Hao5,,"{'value': 'Causal effect estimation under networked interference is an important but challenging problem. Available parametric methods are limited in their model space, while previous semiparametric methods, e.g., leveraging neural networks to fit only one single nuisance function, may still encounter misspecification problems under networked interference without appropriate assumptions on the data generation process. To mitigate bias stemming from misspecification, we propose a novel doubly robust causal effect estimator under networked interference, by adapting the targeted learning technique to the training of neural networks. Specifically, we generalize the targeted learning technique into the networked interference setting and establish the condition under which an estimator achieves double robustness. Based on the condition, we devise an end-to-end causal effect estimator by transforming the identified theoretical condition into a targeted loss. Moreover, we provide a theoretical analysis of our designed estimator, revealing a faster convergence rate compared to a single nuisance model. Extensive experimental results on two real-world networks with semisynthetic data demonstrate the effectiveness of our proposed estimators.'}",https://openreview.net{'value': '/pdf/fae46b2cf3e635e7d98f920bdce60cc0a2230b6a.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=5kVgd2MwMY,{'value': 'A Minimaximalist Approach to Reinforcement Learning from Human Feedback'},Gokul Swamy; Christoph Dann; Rahul Kidambi; Steven Wu; Alekh Agarwal,~Gokul_Swamy1; ~Christoph_Dann1; ~Rahul_Kidambi1; ~Steven_Wu1; ~Alekh_Agarwal2,,"{'value': 'We present *Self-Play Preference Optimization* (SPO), an algorithm for reinforcement learning from human feedback. Our approach is *minimalist* in that it does not require training a reward model nor unstable adversarial training and is therefore rather simple to implement. Our approach is *maximalist* in that it provably handles non-Markovian, intransitive, and stochastic preferences while being robust to the compounding errors that plague offline approaches to sequential prediction. To achieve the preceding qualities, we build upon the concept of a *Minimax Winner* (MW), a notion of preference aggregation from the social choice theory literature that frames learning from preferences as a zero-sum game between two policies. By leveraging the symmetry of this game, we prove that rather than using the traditional technique of dueling two policies to compute the MW, we can simply have a *single* agent play against itself while maintaining strong convergence guarantees. Practically, this corresponds to sampling multiple trajectories from a policy, asking a *preference* or teacher model to compare them, and then using the proportion of wins as the reward for a particular trajectory. We demonstrate that on a suite of continuous control tasks, we are able to learn significantly more efficiently than reward-model based approaches while maintaining robustness to the intransitive and stochastic preferences that frequently occur in practice when aggregating human judgments.'}",https://openreview.net{'value': '/pdf/1fcd68ca02bba8193b3a2491f69fa2b4e150802d.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2024,Conference
https://openreview.net/forum?id=5PQhu8flSO,{'value': 'Detecting and Identifying Selection Structure in Sequential Data'},Yujia Zheng; Zeyu Tang; Yiwen Qiu; Bernhard Schölkopf; Kun Zhang,~Yujia_Zheng1; ~Zeyu_Tang1; ~Yiwen_Qiu1; ~Bernhard_Schölkopf1; ~Kun_Zhang1,,"{'value': 'We argue that the selective inclusion of data points based on latent objectives is common in practical situations, such as music sequences. Since this selection process often distorts statistical analysis, previous work primarily views it as a bias to be corrected and proposes various methods to mitigate its effect. However, while controlling this bias is crucial, selection also offers an opportunity to provide a deeper insight into the hidden generation process, as it is a fundamental mechanism underlying what we observe. In particular, overlooking selection in sequential data can lead to an incomplete or overcomplicated inductive bias in modeling, such as assuming a universal autoregressive structure for all dependencies. Therefore, rather than merely viewing it as a bias, we explore the causal structure of selection in sequential data to delve deeper into the complete causal process. Specifically, we show that selection structure is identifiable without any parametric assumptions or interventional experiments. Moreover, even in cases where selection variables coexist with latent confounders, we still establish the nonparametric identifiability under appropriate structural conditions. Meanwhile, we also propose a provably correct algorithm to detect and identify selection structures as well as other types of dependencies. The framework has been validated empirically on both synthetic data and real-world music.'}",https://openreview.net{'value': '/pdf/468668453d8930bbfdfac9b7d35908440c8a1c45.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=4zOZ0yKhm6,{'value': 'Probabilistic Modeling of Interpersonal Coordination Processes'},Paulo Soares; Adarsh Pyarelal; Meghavarshini Krishnaswamy; Emily Butler; Kobus Barnard,~Paulo_Soares1; ~Adarsh_Pyarelal1; ~Meghavarshini_Krishnaswamy1; ~Emily_Butler3; ~Kobus_Barnard1,,"{'value': 'We develop a novel probabilistic model for interpersonal coordination as a latent phenomenon explaining statistical temporal influence between multiple components in a system. For example, the state of one person can influence that of another at a later time, as indicated by their observed behaviors. We characterize coordination as the degree to which the distributions for such states at one time point are merged for the next salient time point. We evaluate our model in the context of three-person teams executing a virtual search and rescue (SAR) mission. We first use synthetic data to confirm that our technical definition of coordination is consistent with expectations and that we can recover generated coordination despite noise. We then show that captured coordination can be predictive of team performance on real data. Here we use speech vocalics and semantics to infer coordination for 36 teams carrying out two successive SAR missions. In two different datasets, we find that coordination is generally predictive of team score for the second mission, but not for the first, where teams are largely learning to play the game. In addition, we found that including a semantic modality improves prediction in some scenarios. This shows that our intuitive technical definition can capture useful explanatory aspects of team behavior.'}",https://openreview.net{'value': '/pdf/11be8b41e366147b99f0dda35946343722dcb642.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=4zN9tvZfns,{'value': 'Privacy-Preserving Data Release Leveraging Optimal Transport and Particle Gradient Descent'},Konstantin Donhauser; Javier Abad; Neha Hulkund; Fanny Yang,~Konstantin_Donhauser1; ~Javier_Abad1; ~Neha_Hulkund1; ~Fanny_Yang1,,"{'value': 'We present a novel approach for differentially private data synthesis of protected tabular datasets, a relevant task in highly sensitive domains such as healthcare and government. Current state-of-the-art methods predominantly use marginal-based approaches, where a dataset is generated from private estimates of the marginals. In this paper, we introduce PrivPGD, a new generation method for marginal-based private data synthesis, leveraging tools from optimal transport and particle gradient descent. Our algorithm outperforms existing methods on a large range of datasets while being highly scalable and offering the flexibility to incorporate additional domain-specific constraints.'}",https://openreview.net{'value': '/pdf/753fc77a1c8f41eb28821bde352d5b5f443d5a3a.pdf'},{'abstract_filter': 'Data Synthesis'},ICML.cc,2024,Conference
https://openreview.net/forum?id=4ye2I5OelI,{'value': 'Model-Based RL for Mean-Field Games is not Statistically Harder than Single-Agent RL'},Jiawei Huang; Niao He; Andreas Krause,~Jiawei_Huang3; ~Niao_He3; ~Andreas_Krause1,,"{'value': 'We study the sample complexity of reinforcement learning (RL) in Mean-Field Games (MFGs) with model-based function approximation that requires strategic exploration to find a Nash Equilibrium policy. We introduce the Partial Model-Based Eluder Dimension (P-MBED), a more effective notion to characterize the model class complexity. Notably, P-MBED measures the complexity of the single-agent model class converted from the given mean-field model class, and potentially, can be exponentially lower than the MBED proposed by Huang et al. (2024). We contribute a model elimination algorithm featuring a novel exploration strategy and establish sample complexity results polynomial w.r.t. P-MBED. Crucially, our results reveal that, under the basic realizability and Lipschitz continuity assumptions, *learning Nash Equilibrium in MFGs is no more statistically challenging than solving a logarithmic number of single-agent RL problems*. We further extend our results to Multi-Type MFGs, generalizing from conventional MFGs and involving multiple types of agents. This extension implies statistical tractability of a broader class of Markov Games through the efficacy of mean-field approximation. Finally, inspired by our theoretical algorithm, we present a heuristic approach with improved computational efficiency and empirically demonstrate its effectiveness.'}",https://openreview.net{'value': '/pdf/250ff9f2493ea21f02261c485e2a1a00c2d6dde2.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=4uTJfGYA2t,{'value': 'An Efficient Self-Learning Framework For Interactive Spoken Dialog Systems'},Hitesh Tulsiani; David Chan; Shalini Ghosh; Garima Lalwani; Prabhat Pandey; Ankish Bansal; Sri Garimella; Ariya Rastrow; Björn Hoffmeister,hittul@amazon.com; ~David_Chan3; ~Shalini_Ghosh3; glalwani@amazon.com; panprabh@amazon.com; bankish@amazon.com; srigar@amazon.com; ~Ariya_Rastrow2; bjornh@amazon.com,,"{'value': 'Dialog systems, such as voice assistants, are expected to engage with users in complex, evolving conversations. Unfortunately, traditional automatic speech recognition (ASR) systems deployed in such applications are usually trained to recognize each turn independently and lack the ability to adapt to the conversational context or incorporate user feedback. In this work, we introduce a general framework for ASR in dialog systems that can go beyond learning from single-turn utterances and learn over time how to adapt to both explicit supervision and implicit user feedback present in multi-turn conversations. We accomplish that by leveraging advances in student-teacher learning and context-aware dialog processing, and designing contrastive self-supervision approaches with Ohm, a new online hard-negative mining approach. We show that leveraging our new framework compared to traditional training leads to relative WER reductions of close to 10% in real-world dialog systems, and up to 26% on public synthetic data.'}",https://openreview.net{'value': '/pdf/a65306c3311ccd3f62cc73c71fb9914bf19f87cc.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=4jqOV6NlUz,{'value': 'Automated Evaluation of Retrieval-Augmented Language Models with Task-Specific Exam Generation'},Gauthier Guinet; Behrooz Omidvar-Tehrani; Anoop Deoras; Laurent Callot,~Gauthier_Guinet1; omidvart@amazon.com; ~Anoop_Deoras1; ~Laurent_Callot1,,"{'value': ""We propose a new method to measure the task-specific accuracy of Retrieval-Augmented Large Language Models (RAG). Evaluation is performed by scoring the RAG on an automatically-generated synthetic exam composed of multiple choice questions based on the corpus of documents associated with the task. Our method is an automated, cost-efficient, interpretable, and robust strategy to select the optimal components for a RAG system. We leverage Item Response Theory (IRT) to estimate the quality of an exam and its informativeness on task-specific accuracy. IRT also provides a natural way to iteratively improve the exam by eliminating the exam questions that are not sufficiently informative about a model's ability. We demonstrate our approach on four new open-ended Question-Answering tasks based on Arxiv abstracts, StackExchange questions, AWS DevOps troubleshooting guides, and SEC filings. In addition, our experiments reveal more general insights into factors impacting RAG performance like size, retrieval mechanism, prompting and fine-tuning. Most notably, our findings show that choosing the right retrieval algorithms often leads to bigger performance gains than simply using a larger language model.""}",https://openreview.net{'value': '/pdf/69297602a41ed4ed72853cd87bb3928aa9bc5a19.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=3Z9CRr5srL,{'value': 'In-Context Language Learning: Architectures and Algorithms'},Ekin Akyürek; Bailin Wang; Yoon Kim; Jacob Andreas,~Ekin_Akyürek1; ~Bailin_Wang3; ~Yoon_Kim1; ~Jacob_Andreas1,,"{'value': 'Some neural language models (LMs) exhibit a remarkable capacity for in-context learning (ICL): they can fit predictors to datasets provided as input. While the mechanisms underlying ICL are well-studied in the context of synthetic problems like in-context linear regression, there is still some divergence between these model problems and the “real” ICL exhibited by LMs trained on large text corpora. In this paper, we study ICL through the lens of a new family of model problems we term in context language learning (ICLL). In ICLL, LMs are presented with a set of strings from a formal language, and must generate additional strings from the same language. We focus on in- context learning of regular languages generated by random finite automata. We evaluate a diverse set of neural sequence models on regular ICLL tasks. We first show that Transformers significantly outperform neural sequence models with recurrent or convolutional representations on ICLL tasks. Next, we provide evidence that they do so by computing in-context n-gram statistics using specialized attention heads. Finally, we show that hard-wiring these heads into neural models improves performance not just on synthetic ICLL, but natural language modeling, reducing the perplexity of 340M-parameter Transformers by up to 1.14 points (6.7%) on the SlimPajama dataset. Our results highlight the usefulness of in-context formal language learning as a tool for understanding ICL in models of natural text.'}",https://openreview.net{'value': '/pdf/53601bf2e9fd639152a9e3a4954cfe607e47a559.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=3WCvnkHnxV,{'value': 'PrE-Text: Training Language Models on Private Federated Data in the Age of LLMs'},Charlie Hou; Akshat Shrivastava; Hongyuan Zhan; Rylan Conway; Trang Le; Adithya Sagar; Giulia Fanti; Daniel Lazar,~Charlie_Hou1; ~Akshat_Shrivastava1; ~Hongyuan_Zhan2; ~Rylan_Conway1; ~Trang_Le1; adithyasagar@meta.com; ~Giulia_Fanti1; ~Daniel_Lazar1,,"{'value': ""On-device training is currently the most common approach for training machine learning (ML) models on private, distributed user data. Despite this, on-device training has several drawbacks: (1) most user devices are too small to train large models on-device, (2) on-device training is communication- and computation-intensive, and (3) on-device training can be difficult to debug and deploy. To address these problems, we propose Private Evolution-Text (PrE-Text), a method for generating differentially private (DP) synthetic textual data. First, we show that across multiple datasets, training small models (models that fit on user devices) with PrE-Text synthetic data outperforms small models trained on-device under practical privacy regimes ($\\epsilon=1.29$, $\\epsilon=7.58$). We achieve these results while using 9$\\times$ fewer rounds, 6$\\times$ less client computation per round, and 100$\\times$ less communication per round. Second, finetuning large models on PrE-Text's DP synthetic data improves large language model (LLM) performance on private data across the same range of privacy budgets. Altogether, these results suggest that training on DP synthetic data can be a better option than training a model on-device on private distributed data. Code is available at https://github.com/houcharlie/PrE-Text.""}",https://openreview.net{'value': '/pdf/f008240cc2c168eb5e23534f6c9a07aa412dc41d.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=3Tzdpjc59k,{'value': 'Borda Regret Minimization for Generalized Linear Dueling Bandits'},Yue Wu; Tao Jin; Qiwei Di; Hao Lou; Farzad Farnoud; Quanquan Gu,~Yue_Wu12; ~Tao_Jin3; ~Qiwei_Di1; ~Hao_Lou1; ~Farzad_Farnoud1; ~Quanquan_Gu1,,"{'value': 'Dueling bandits are widely used to model preferential feedback prevalent in many applications such as recommendation systems and ranking. In this paper, we study the Borda regret minimization problem for dueling bandits, which aims to identify the item with the highest Borda score while minimizing the cumulative regret. We propose a rich class of generalized linear dueling bandit models, which cover many existing models. We first prove a regret lower bound of order $\\Omega(d^{2/3} T^{2/3})$ for the Borda regret minimization problem, where $d$ is the dimension of contextual vectors and $T$ is the time horizon. To attain this lower bound, we propose an explore-then-commit type algorithm for the stochastic setting, which has a nearly matching regret upper bound $\\tilde{O}(d^{2/3} T^{2/3})$. We also propose an EXP3-type algorithm for the adversarial linear setting, where the underlying model parameter can change in each round. Our algorithm achieves an $\\tilde{O}(d^{2/3} T^{2/3})$ regret, which is also optimal. Empirical evaluations on both synthetic data and a simulated real-world environment are conducted to corroborate our theoretical analysis.'}",https://openreview.net{'value': '/pdf/72ae1fa107043e51a3e3a307051279f9f117bfdf.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=3Pq6uI1MTE,{'value': 'Differentiable Combinatorial Scheduling at Scale'},Mingju Liu; Yingjie Li; Jiaqi Yin; Zhiru Zhang; CUNXI YU,~Mingju_Liu1; ~Yingjie_Li1; jyin629@umd.edu; ~Zhiru_Zhang2; ~CUNXI_YU1,,"{'value': 'This paper addresses the complex issue of resource-constrained scheduling, an NP-hard problem that spans critical areas including chip design and high-performance computing. Traditional scheduling methods often stumble over scalability and applicability challenges. We propose a novel approach using a differentiable combinatorial scheduling framework, utilizing Gumbel-Softmax differentiable sampling technique. This new technical allows for a fully differentiable formulation of linear programming (LP) based scheduling, extending its application to a broader range of LP formulations. To encode inequality constraints for scheduling tasks, we introduce *constrained Gumbel Trick*, which adeptly encodes arbitrary inequality constraints. Consequently, our method facilitates an efficient and scalable scheduling via gradient descent without the need for training data. Comparative evaluations on both synthetic and real-world benchmarks highlight our capability to significantly improve the optimization efficiency of scheduling, surpassing state-of-the-art solutions offered by commercial and open-source solvers such as CPLEX, Gurobi, and CP-SAT in the majority of the designs.'}",https://openreview.net{'value': '/pdf/d00d3d75e919070e4e43e44dd45448f1fa99ce4a.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=3MIuPRJYwf,{'value': 'Expand-and-Cluster: Parameter Recovery of Neural Networks'},Flavio Martinelli; Berfin Simsek; Wulfram Gerstner; Johanni Brea,~Flavio_Martinelli1; ~Berfin_Simsek1; ~Wulfram_Gerstner1; ~Johanni_Brea1,,"{'value': ""Can we identify the weights of a neural network by probing its input-output mapping? At first glance, this problem seems to have many solutions because of permutation, overparameterisation and activation function symmetries. Yet, we show that the incoming weight vector of each neuron is identifiable up to sign or scaling, depending on the activation function. Our novel method 'Expand-and-Cluster’ can identify layer sizes and weights of a target network for all commonly used activation functions. Expand-and-Cluster consists of two phases: (i) to relax the non-convex optimisation problem, we train multiple overparameterised student networks to best imitate the target function; (ii) to reverse engineer the target network's weights, we employ an ad-hoc clustering procedure that reveals the learnt weight vectors shared between students -- these correspond to the target weight vectors. We demonstrate successful weights and size recovery of trained shallow and deep networks with less than 10% overhead in the layer size and describe an 'ease-of-identifiability' axis by analysing 150 synthetic problems of variable difficulty.""}",https://openreview.net{'value': '/pdf/6688fa747b5bf119ad557b509e4857d1db41c4cf.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=3KMMPxrAk5,{'value': 'Local Causal Structure Learning in the Presence of Latent Variables'},Feng Xie; Zheng Li; Peng Wu; Yan Zeng; Chunchen LIU; Zhi Geng,~Feng_Xie1; ~Zheng_Li27; ~Peng_Wu5; ~Yan_Zeng2; ~Chunchen_LIU2; ~Zhi_Geng1,,"{'value': 'Discovering causal relationships from observational data, particularly in the presence of latent variables, poses a challenging problem. While current local structure learning methods have proven effective and efficient when the focus lies solely on the local relationships of a target variable, they operate under the assumption of causal sufficiency. This assumption implies that all the common causes of the measured variables are observed, leaving no room for latent variables. Such a premise can be easily violated in various real-world applications, resulting in inaccurate structures that may adversely impact downstream tasks. In light of this, our paper delves into the primary investigation of locally identifying potential parents and children of a target from observational data that may include latent variables. Specifically, we harness the causal information from m-separation and V-structures to derive theoretical consistency results, effectively bridging the gap between global and local structure learning. Together with the newly developed stop rules, we present a principled method for determining whether a variable is a direct cause or effect of a target. Further, we theoretically demonstrate the correctness of our approach under the standard causal Markov and faithfulness conditions, with infinite samples. Experimental results on both synthetic and real-world data validate the effectiveness and efficiency of our approach.'}",https://openreview.net{'value': '/pdf/dbd19398374a80d9527ccf96f7c0dcefe8f7afd4.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=3B6vmW2L80,{'value': 'Single-Trajectory Distributionally Robust Reinforcement Learning'},Zhipeng Liang; Xiaoteng Ma; Jose Blanchet; Jun Yang; Jiheng Zhang; Zhengyuan Zhou,~Zhipeng_Liang1; ~Xiaoteng_Ma1; ~Jose_Blanchet1; ~Jun_Yang6; ~Jiheng_Zhang1; ~Zhengyuan_Zhou2,,"{'value': ""To mitigate the limitation that the classical reinforcement learning (RL) framework heavily relies on identical training and test environments, Distributionally Robust RL (DRRL) has been proposed to enhance performance across a range of environments, possibly including unknown test environments. As a price for robustness gain, DRRL involves optimizing over a set of distributions, which is inherently more challenging than optimizing over a fixed distribution in the non-robust case. Existing DRRL algorithms are either model-based or fail to learn from a single sample trajectory. In this paper, we design a first fully model-free DRRL algorithm, called distributionally robust Q-learning with single trajectory (DRQ). We delicately design a multi-timescale framework to fully utilize each incrementally arriving sample and directly learn the optimal distributionally robust policy without modeling the environment, thus the algorithm can be trained along a single trajectory in a model-free fashion. Despite the algorithm's complexity, we provide asymptotic convergence guarantees by generalizing classical stochastic approximation tools.Comprehensive experimental results demonstrate the superior robustness and sample complexity of our proposed algorithm, compared to non-robust methods and other robust RL algorithms.""}",https://openreview.net{'value': '/pdf/f2a8c3ca71df8ce832e6178e58f509c80b0fbb4c.pdf'},{'title_filter': 'Trajectory'},ICML.cc,2024,Conference
https://openreview.net/forum?id=3AuoStfUIH,{'value': 'Offline Multi-Objective Optimization'},Ke Xue; Rongxi Tan; Xiaobin Huang; Chao Qian,~Ke_Xue1; ~Rongxi_Tan1; ~Xiaobin_Huang2; ~Chao_Qian1,,"{'value': 'Offline optimization aims to maximize a black-box objective function with a static dataset and has wide applications. In addition to the objective function being black-box and expensive to evaluate, numerous complex real-world problems entail optimizing multiple conflicting objectives, i.e., multi-objective optimization (MOO). Nevertheless, offline MOO has not progressed as much as offline single-objective optimization (SOO), mainly due to the lack of benchmarks like Design-Bench for SOO. To bridge this gap, we propose a first benchmark for offline MOO, covering a range of problems from synthetic to real-world tasks. This benchmark provides tasks, datasets, and open-source examples, which can serve as a foundation for method comparisons and advancements in offline MOO. Furthermore, we analyze how the current related methods can be adapted to offline MOO from four fundamental perspectives, including data, model architecture, learning algorithm, and search algorithm. Empirical results show improvements over the best value of the training set, demonstrating the effectiveness of offline MOO methods. As no particular method stands out significantly, there is still an open challenge in further enhancing the effectiveness of offline MOO. We finally discuss future challenges for offline MOO, with the hope of shedding some light on this emerging field. Our code is available at https://github.com/lamda-bbo/offline-moo.'}",https://openreview.net{'value': '/pdf/4ce26dbf2920683db2dd5cbc7936aebd54dcca24.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=321GwKMtxO,{'value': 'REMEDI: Corrective Transformations for Improved Neural Entropy Estimation'},Viktor Nilsson; Anirban Samaddar; Sandeep Madireddy; Pierre Nyquist,~Viktor_Nilsson1; ~Anirban_Samaddar1; ~Sandeep_Madireddy1; ~Pierre_Nyquist1,,"{'value': 'Information theoretic quantities play a central role in machine learning. The recent surge in the complexity of data and models has increased the demand for accurate estimation of these quantities. However, as the dimension grows the estimation presents significant challenges, with existing methods struggling already in relatively low dimensions. To address this issue, in this work, we introduce REMEDI for efficient and accurate estimation of differential entropy, a fundamental information theoretic quantity. The approach combines the minimization of the cross-entropy for simple, adaptive base models and the estimation of their deviation, in terms of the relative entropy, from the data density. Our approach demonstrates improvement across a broad spectrum of estimation tasks, encompassing entropy estimation on both synthetic and natural data. Further, we extend important theoretical consistency results to a more generalized setting required by our approach. We illustrate how the framework can be naturally extended to information theoretic supervised learning models, with a specific focus on the Information Bottleneck approach. It is demonstrated that the method delivers better accuracy compared to the existing methods in Information Bottleneck. In addition, we explore a natural connection between REMEDI and generative modeling using rejection sampling and Langevin dynamics.'}",https://openreview.net{'value': '/pdf/798d5815517bdd495b1fa263245cb7f72ae4dc87.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=2xbkWiEuR1,{'value': 'Offline Training of Language Model Agents with Functions as Learnable Weights'},Shaokun Zhang; Jieyu Zhang; Jiale Liu; Linxin Song; Chi Wang; Ranjay Krishna; Qingyun Wu,~Shaokun_Zhang2; ~Jieyu_Zhang1; ~Jiale_Liu2; ~Linxin_Song1; ~Chi_Wang3; ~Ranjay_Krishna1; ~Qingyun_Wu2,,"{'value': ""Researchers and practitioners have recently reframed powerful Large Language Models (LLMs) as *agents*, enabling them to automate complex tasks largely via the use of specialized functions. To facilitate the development of LLM agents, we present a novel paradigm of training LLM agents without modifying the LLM weights, which is particularly useful when the LLMs are difficult or inaccessible for modifications. Inspired by how humans continuously forge tools to adapt to real-world tasks, rather than change our biological structure to fit a static set of tools, we propose to progressively forge agent's functions to better solve the downstream tasks instead of modifying the LLM weights. By treating the functions as learnable `agent parameters' and leveraging the fundamental idea of model training in artificial intelligence, we develop AgentOptimizer that employs the LLM to update agents' functions and devise an *agent training* algorithm with two strategies, roll-back, and early-stop, to streamline the training process. With extensive experiments, we showcase that the agent training paradigm could significantly improve the performance of representative LLM agents in various downstream tasks. We also study the behavior of the agent training regarding aspects like the learning curve and domain transferability.""}",https://openreview.net{'value': '/pdf/7fc4174c8876ce9cd87db0e2a33d814d09583fb1.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=2K87GFLYWz,{'value': 'Breaking through the learning plateaus of in-context learning in Transformer'},Jingwen Fu; Tao Yang; Yuwang Wang; Yan Lu; Nanning Zheng,~Jingwen_Fu1; ~Tao_Yang9; ~Yuwang_Wang3; ~Yan_Lu7; ~Nanning_Zheng1,,"{'value': ""In-context learning, i.e., learning from context examples, is an impressive ability of Transformer. Training Transformers to possess this in-context learning skill is computationally intensive due to the occurrence of *learning plateaus*, which are periods within the training process where there is minimal or no enhancement in the model's in-context learning capability. To study the mechanism behind the learning plateaus, we conceptually separate a component within the model's internal representation that is exclusively affected by the model's weights. We call this the “weights component”, and the remainder is identified as the “context component”. By conducting meticulous and controlled experiments on synthetic tasks, we note that the persistence of learning plateaus correlates with compromised functionality of the weights component. Recognizing the impaired performance of the weights component as a fundamental behavior that drives learning plateaus, we have developed three strategies to expedite the learning of Transformers. The effectiveness of these strategies is further confirmed in natural language processing tasks. In conclusion, our research demonstrates the feasibility of cultivating a powerful in-context learning ability within AI systems in an eco-friendly manner.""}",https://openreview.net{'value': '/pdf/4eadeb1dda051935267e78b000bb58a4628eba8e.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=2FKzbEE24s,{'value': 'A Differentiable Partially Observable Generalized Linear Model with Forward-Backward Message Passing'},Chengrui Li; Weihan Li; Yule Wang; Anqi Wu,~Chengrui_Li1; ~Weihan_Li1; ~Yule_Wang1; ~Anqi_Wu3,,"{'value': 'The partially observable generalized linear model (POGLM) is a powerful tool for understanding neural connectivities under the assumption of existing hidden neurons. With spike trains only recorded from visible neurons, existing works use variational inference to learn POGLM meanwhile presenting the difficulty of learning this latent variable model. There are two main issues: (1) the sampled Poisson hidden spike count hinders the use of the pathwise gradient estimator in VI; and (2) the existing design of the variational model is neither expressive nor time-efficient, which further affects the performance. For (1), we propose a new differentiable POGLM, which enables the pathwise gradient estimator, better than the score function gradient estimator used in existing works. For (2), we propose the forward-backward message-passing sampling scheme for the variational model. Comprehensive experiments show that our differentiable POGLMs with our forward-backward message passing produce a better performance on one synthetic and two real-world datasets. Furthermore, our new method yields more interpretable parameters, underscoring its significance in neuroscience.'}",https://openreview.net{'value': '/pdf/b416d3289f94c901e00b6c6ad0ee9934bda3e649.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=1sesUtOIH5,{'value': 'DecisionNCE: Embodied Multimodal Representations via Implicit Preference Learning'},Jianxiong Li; Jinliang Zheng; Yinan Zheng; Liyuan Mao; Xiao Hu; Sijie Cheng; Haoyi Niu; Jihao Liu; Yu Liu; Jingjing Liu; Ya-Qin Zhang; Xianyuan Zhan,~Jianxiong_Li1; ~Jinliang_Zheng1; ~Yinan_Zheng1; ~Liyuan_Mao2; ~Xiao_Hu7; ~Sijie_Cheng1; ~Haoyi_Niu1; ~Jihao_Liu4; ~Yu_Liu2; ~Jingjing_Liu2; ~Ya-Qin_Zhang1; ~Xianyuan_Zhan1,,"{'value': 'Multimodal pretraining is an effective strategy for the trinity of goals of representation learning in autonomous robots: $1)$ extracting both local and global task progressions; $2)$ enforcing temporal consistency of visual representation; $3)$ capturing trajectory-level language grounding. Most existing methods approach these via separate objectives, which often reach sub-optimal solutions. In this paper, we propose a universal unified objective that can simultaneously extract meaningful task progression information from image sequences and seamlessly align them with language instructions. We discover that via implicit preferences, where a visual trajectory inherently aligns better with its corresponding language instruction than mismatched pairs, the popular Bradley-Terry model can transform into representation learning through proper reward reparameterizations. The resulted framework, DecisionNCE, mirrors an InfoNCE-style objective but is distinctively tailored for decision-making tasks, providing an embodied representation learning framework that elegantly extracts both local and global task progression features, with temporal consistency enforced through implicit time contrastive learning, while ensuring trajectory-level instruction grounding via multimodal joint encoding. Evaluation on both simulated and real robots demonstrates that DecisionNCE effectively facilitates diverse downstream policy learning tasks, offering a versatile solution for unified representation and reward learning. Project Page: https://2toinf.github.io/DecisionNCE/'}",https://openreview.net{'value': '/pdf/74e25fbbf5a730ba3ad2107241d4b9a5c249565b.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2024,Conference
https://openreview.net/forum?id=1JgCpZS17T,{'value': 'Inferring Change Points in High-Dimensional Linear Regression via Approximate Message Passing'},Gabriel Arpino; Xiaoqi Liu; Ramji Venkataramanan,~Gabriel_Arpino1; ~Xiaoqi_Liu1; rv285@cam.ac.uk,,"{'value': 'We consider the problem of localizing change points in high-dimensional linear regression. We propose an Approximate Message Passing (AMP) algorithm for estimating both the signals and the change point locations. Assuming Gaussian covariates, we give an exact asymptotic characterization of its estimation performance in the limit where the number of samples grows proportionally to the signal dimension. Our algorithm can be tailored to exploit any prior information on the signal, noise, and change points. It also enables uncertainty quantification in the form of an efficiently computable approximate posterior distribution, whose asymptotic form we characterize exactly. We validate our theory via numerical experiments, and demonstrate the favorable performance of our estimators on both synthetic data and images.'}",https://openreview.net{'value': '/pdf/075b5f0ccd74f7df5b463bcca18cc498c98a9baf.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=1Fs1LvjYQW,{'value': 'MLAgentBench: Evaluating Language Agents on Machine Learning Experimentation'},Qian Huang; Jian Vora; Percy Liang; Jure Leskovec,~Qian_Huang2; ~Jian_Vora1; ~Percy_Liang1; ~Jure_Leskovec1,,"{'value': 'A central aspect of machine learning research is experimentation, the process of designing and running experiments, analyzing the results, and iterating towards some positive outcome (e.g., improving accuracy). Could agents driven by powerful language models perform machine learning experimentation effectively? To answer this question, we introduce MLAgentBench, a suite of 13 tasks ranging from improving model performance on CIFAR-10 to recent research problems like BabyLM. For each task, an agent can perform actions like reading/writing files, executing code, and inspecting outputs. We then construct an agent that can perform ML experimentation based on ReAct framework. We benchmark agents based on Claude v1.0, Claude v2.1, Claude v3 Opus, GPT-4, GPT-4-turbo, Gemini-Pro, and Mixtral and find that a Claude v3 Opus agent is the best in terms of success rate. It can build compelling ML models over many tasks in MLAgentBench with 37.5% average success rate. Our agents also display highly interpretable plans and actions. However, the success rates vary considerably; they span from 100% on well-established older datasets to as low as 0% on recent Kaggle challenges created potentially after the underlying LM was trained. Finally, we identify several key challenges for LM-based agents such as long-term planning and reducing hallucination.'}",https://openreview.net{'value': '/pdf/876ec336c520a85523ba8ea9e85d6950a1f86bd6.pdf'},{'title_filter': 'Agent'},ICML.cc,2024,Conference
https://openreview.net/forum?id=126SR50BEL,{'value': 'A Dual-module Framework for Counterfactual Estimation over Time'},Xin Wang; Shengfei Lyu; Lishan Yang; Yibing Zhan; Huanhuan Chen,~Xin_Wang46; ~Shengfei_Lyu1; ~Lishan_Yang2; ~Yibing_Zhan2; ~Huanhuan_Chen1,,"{'value': 'Efficiently and effectively estimating counterfactuals over time is crucial for optimizing treatment strategies. We present the Adversarial Counterfactual Temporal Inference Network (ACTIN), a novel framework with dual modules to enhance counterfactual estimation. The balancing module employs a distribution-based adversarial method to learn balanced representations, extending beyond the limitations of current classification-based methods to mitigate confounding bias across various treatment types. The integrating module adopts a novel Temporal Integration Predicting (TIP) strategy, which has a wider receptive field of treatments and balanced representations from the beginning to the current time for a more profound level of analysis. TIP goes beyond the established Direct Predicting (DP) strategy, which only relies on current treatments and representations, by empowering the integrating module to effectively capture long-range dependencies and temporal treatment interactions. ACTIN exceeds the confines of specific base models, and when implemented with simple base models, consistently delivers state-of-the-art performance and efficiency across both synthetic and real-world datasets.'}",https://openreview.net{'value': '/pdf/761ddf1af196b5da140cfb367fcd90adeeee0dc4.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=0vozy8vstt,{'value': 'Efficient Contextual Bandits with Uninformed Feedback Graphs'},Mengxiao Zhang; Yuheng Zhang; Haipeng Luo; Paul Mineiro,~Mengxiao_Zhang2; ~Yuheng_Zhang1; ~Haipeng_Luo1; ~Paul_Mineiro1,,"{'value': 'Bandits with feedback graphs are powerful online learning models that interpolate between the full information and classic bandit problems, capturing many real-life applications. A recent work by [Zhang et al., 2023] studies the contextual version of this problem and proposes an efficient and optimal algorithm via a reduction to online regression. However, their algorithm crucially relies on seeing the feedback graph before making each decision, while in many applications, the feedback graph is *uninformed*, meaning that it is either only revealed after the learner makes her decision or even never fully revealed at all. This work develops the first contextual algorithms for such uninformed settings, via an efficient reduction to online regression over both the losses and the graphs. Importantly, we show that it is critical to learn the graphs using *log loss* instead of squared loss to obtain favorable regret guarantees. We also demonstrate the empirical effectiveness of our algorithm on a bidding application using both synthetic and real-world data.'}",https://openreview.net{'value': '/pdf/2d76d467d7739a3ab2a46ca021e086d8b9c4b1a0.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=0tuwdgBiSN,{'value': 'Complexity Matters: Feature Learning in the Presence of Spurious Correlations'},GuanWen Qiu; Da Kuang; Surbhi Goel,~GuanWen_Qiu1; ~Da_Kuang2; ~Surbhi_Goel1,,"{'value': 'Existing research often posits spurious features as **easier** to learn than core features in neural network optimization, but the impact of their relative simplicity remains under-explored. Moreover, studies mainly focus on end performance rather than the learning dynamics of feature learning. In this paper, we propose a theoretical framework and an associated synthetic dataset grounded in boolean function analysis. This setup allows for fine-grained control over the relative complexity (compared to core features) and correlation strength (with respect to the label) of spurious features to study the dynamics of feature learning under spurious correlations. Our findings uncover several interesting phenomena: (1) stronger spurious correlations or simpler spurious features slow down the learning rate of the core features, (2) two distinct subnetworks are formed to learn core and spurious features separately, (3) learning phases of spurious and core features are not always separable, (4) spurious features are not forgotten even after core features are fully learned. We demonstrate that our findings justify the success of retraining the last layer to remove spurious correlation and also identifies limitations of popular debiasing algorithms that exploit early learning of spurious features. We support our empirical findings with theoretical analyses for the case of learning XOR features with a one-hidden-layer ReLU network.'}",https://openreview.net{'value': '/pdf/33572bf323f2ef10fba47303016428622fe8c34f.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=0JV5WpLQgv,{'value': 'PointMC: Multi-instance Point Cloud Registration based on Maximal Cliques'},Yue Wu; Xidao hu; Yongzhe Yuan; Xiaolong Fan; Maoguo Gong; Hao Li; Mingyang Zhang; Qiguang Miao; Wenping Ma,~Yue_Wu14; ~Xidao_hu1; ~Yongzhe_Yuan2; ~Xiaolong_Fan1; ~Maoguo_Gong2; ~Hao_Li12; ~Mingyang_Zhang4; ~Qiguang_Miao1; ~Wenping_Ma3,,"{'value': 'Multi-instance point cloud registration is the problem of estimating multiple rigid transformations between two point clouds. Existing solutions rely on global spatial consistency of ambiguity and the time-consuming clustering of highdimensional correspondence features, making it difficult to handle registration scenarios where multiple instances overlap. To address these problems, we propose a maximal clique based multiinstance point cloud registration framework called PointMC. The key idea is to search for maximal cliques on the correspondence compatibility graph to estimate multiple transformations, and cluster these transformations into clusters corresponding to different instances to efficiently and accurately estimate all poses. PointMC leverages a correspondence embedding module that relies on local spatial consistency to effectively eliminate outliers, and the extracted discriminative features empower the network to circumvent missed pose detection in scenarios involving multiple overlapping instances. We conduct comprehensive experiments on both synthetic and real-world datasets, and the results show that the proposed PointMC yields remarkable performance improvements.'}",https://openreview.net{'value': '/pdf/ae33d580a1c8963f077a80fc9642b019fef388e8.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=0FWPKHMCSc,{'value': 'Large Scale Dataset Distillation with Domain Shift'},Noel Loo; Alaa Maalouf; Ramin Hasani; Mathias Lechner; Alexander Amini; Daniela Rus,~Noel_Loo1; ~Alaa_Maalouf1; ~Ramin_Hasani1; ~Mathias_Lechner1; ~Alexander_Amini1; ~Daniela_Rus1,,"{'value': 'Dataset Distillation seeks to summarize a large dataset by generating a reduced set of synthetic samples. While there has been much success at distilling small datasets such as CIFAR-10 on smaller neural architectures, Dataset Distillation methods fail to scale to larger high-resolution datasets and architectures. In this work, we introduce **D**ataset **D**istillation with **D**omain **S**hift (**D3S**), a scalable distillation algorithm, made by reframing the dataset distillation problem as a *domain shift* one. In doing so, we derive a universal bound on the distillation loss, and provide a method for efficiently approximately optimizing it. We achieve state-of-the-art results on Tiny-ImageNet, ImageNet-1k, and ImageNet-21K over a variety of recently proposed baselines, including high cross-architecture generalization. Additionally, our ablation studies provide lessons on the importance of validation-time hyperparameters on distillation performance, motivating the need for standardization.'}",https://openreview.net{'value': '/pdf/e7630517117be90e03f8d1aef9224f4167509892.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
https://openreview.net/forum?id=07fSWltF6M,{'value': 'ProtoGate: Prototype-based Neural Networks with Global-to-local Feature Selection for Tabular Biomedical Data'},Xiangjian Jiang; Andrei Margeloiu; Nikola Simidjievski; Mateja Jamnik,~Xiangjian_Jiang1; ~Andrei_Margeloiu1; ~Nikola_Simidjievski1; ~Mateja_Jamnik1,,"{'value': 'Tabular biomedical data poses challenges in machine learning because it is often high-dimensional and typically low-sample-size (HDLSS). Previous research has attempted to address these challenges via local feature selection, but existing approaches often fail to achieve optimal performance due to their limitation in identifying globally important features and their susceptibility to the co-adaptation problem. In this paper, we propose ProtoGate, a prototype-based neural model for feature selection on HDLSS data. ProtoGate first selects instance-wise features via adaptively balancing global and local feature selection. Furthermore, ProtoGate employs a non-parametric prototype-based prediction mechanism to tackle the co-adaptation problem, ensuring the feature selection results and predictions are consistent with underlying data clusters. We conduct comprehensive experiments to evaluate the performance and interpretability of ProtoGate on synthetic and real-world datasets. The results show that ProtoGate generally outperforms state-of-the-art methods in prediction accuracy by a clear margin while providing high-fidelity feature selection and explainable predictions. Code is available at https://github.com/SilenceX12138/ProtoGate.'}",https://openreview.net{'value': '/pdf/6feb266d77010f527b2800d0c5f828266b3e7eea.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2024,Conference
