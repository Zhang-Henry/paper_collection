forum,title,authors,authorids,keywords,abstract,pdf,match,venue,year,type
https://openreview.net/forum?id=zy15E0X3Dq,{'value': 'Pretraining Generative Flow Networks with Inexpensive Rewards for Molecular Graph Generation'},Mohit Pandey; Gopeshh Subbaraj; Artem Cherkasov; Martin Ester; Emmanuel Bengio,~Mohit_Pandey2; ~Gopeshh_Subbaraj1; ~Artem_Cherkasov1; ~Martin_Ester1; ~Emmanuel_Bengio1,"{'value': ['Generative Flow Networks', 'Foundation model', 'Drug Discovery']}","{'value': 'Generative Flow Networks (GFlowNets) have recently emerged as a suitable framework for generating diverse and high-quality molecular structures by learning from rewards treated as unnormalized distributions. Previous works in this framework often restrict exploration by using predefined molecular fragments as building blocks, limiting the chemical space that can be accessed. In this work, we introduce Atomic GFlowNets (A-GFNs), a foundational generative model leveraging individual atoms as building blocks to explore drug-like chemical space more comprehensively. We propose an unsupervised pre-training approach using drug-like molecule datasets, which teaches A-GFNs about inexpensive yet informative molecular descriptors such as drug-likeliness, topological polar surface area, and synthetic accessibility scores. These properties serve as proxy rewards, guiding A-GFNs towards regions of chemical space that exhibit desirable pharmacological properties. We further implement a goal-conditioned finetuning process, which adapts A-GFNs to optimize for specific target properties. In this work, we pretrain A-GFN on a subset of ZINC dataset, and by employing robust evaluation metrics we show the effectiveness of our approach when compared to other relevant baseline methods for a wide range of drug design tasks.  The code is accessible at https://github.com/diamondspark/AGFN.'}",https://openreview.net{'value': '/pdf/ef5781a4cfc7d0805624c139fbedc64fcffdc3de.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=zkGfPYAM5D,{'value': 'Point-Level Topological Representation Learning on Point Clouds'},Vincent Peter Grande; Michael T Schaub,~Vincent_Peter_Grande1; ~Michael_T_Schaub1,"{'value': ['Topological Data Analysis', 'Differential Geometry', 'Representation Learning', 'Hodge Laplacian', 'Simplicial Complex', 'Persistent Homology', 'Point Clouds']}","{'value': 'Topological Data Analysis (TDA) allows us to extract powerful topological and higher-order information on the global shape of a data set or point cloud.\nTools like Persistent Homology give a single complex description of the global structure of the point cloud.\nHowever, common machine learning applications like classification require point-level information and features.\nIn this paper, we bridge this gap and propose a novel method to extract node-level topological features from complex point clouds using discrete variants of concepts from algebraic topology and differential geometry.\nWe verify the effectiveness of these topological point features (TOPF) on both synthetic and real-world data and study their robustness under noise and heterogeneous sampling.'}",https://openreview.net{'value': '/pdf/dbffcb34a6f3c3d436e591119a7fb342af366683.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=zQS9YryNHs,{'value': 'MIRROR: Make Your Object-Level Multi-View Generation More Consistent with Training-Free Rectification'},Tianchi Xing; Bonan Li; Congying Han; Xinmin Qiu; Zicheng Zhang; Tiande Guo,~Tianchi_Xing1; ~Bonan_Li2; ~Congying_Han1; ~Xinmin_Qiu1; ~Zicheng_Zhang3; ~Tiande_Guo1,"{'value': ['3D Generation', 'Diffusion Model', 'Training-Free']}","{'value': 'Multi-view Diffusion has greatly advanced the development of 3D content creation by generating multiple images from distinct views, achieving remarkable photorealistic results. However, existing works are still vulnerable to inconsistent 3D geometric structures (commonly known as Janus Problem) and severe artifacts. In this paper, we introduce MIRROR, a versatile plug-and-play method that rectifies such inconsistencies in a training-free manner, enabling the acquisition of high-fidelity, realistic structures without compromising diversity. Our key idea focuses on tracing the motion trajectory of physical points across adjacent viewpoints, enabling rectifications based on neighboring observations of the same region. Technically, MIRROR comprises two core modules: Trajectory Tracking Module (TTM) for pixel-wise trajectory tracking that labels identical points across views, and Feature Rectification Module (FRM) for explicitly adjustment of each pixel embedding on noisy synthesized images by minimizing the distance to corresponding block features in neighboring views, thereby achieving consistent outputs. Extensive evaluations demonstrate that MIRROR can seamlessly integrate with a diverse range of off-the-shelf object-level multi-view diffusion models, significantly enhancing both the consistency and the fidelity in an efficient way.'}",https://openreview.net{'value': '/pdf/28b7e5d416ed63d26b6179c2722dedec8f1d6134.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=zFB0ujQ1R5,{'value': 'Generalists vs. Specialists: Evaluating LLMs on Highly-Constrained Biophysical Sequence Optimization Tasks'},Angelica Chen; Samuel Don Stanton; Frances Ding; Robert G Alberstein; Andrew Martin Watkins; Richard Bonneau; Vladimir Gligorijevic; Kyunghyun Cho; Nathan C. Frey,~Angelica_Chen1; ~Samuel_Don_Stanton1; ~Frances_Ding1; ~Robert_G_Alberstein1; ~Andrew_Martin_Watkins1; ~Richard_Bonneau2; ~Vladimir_Gligorijevic2; ~Kyunghyun_Cho1; ~Nathan_C._Frey1,"{'value': ['biophysical optimization', 'large language models', 'discrete sequence optimization']}","{'value': 'Although large language models (LLMs) have shown promise in biomolecule optimization problems, they incur heavy computational costs and struggle to satisfy precise constraints. On the other hand, specialized solvers like LaMBO-2 offer efficiency and fine-grained control but require more domain expertise. \nComparing these approaches is challenging due to expensive laboratory validation and inadequate synthetic benchmarks. \nWe address this by introducing Ehrlich functions, a synthetic test suite that captures the geometric structure of biophysical sequence optimization problems. \nWith prompting alone, off-the-shelf LLMs struggle to optimize Ehrlich functions. \nIn response, we propose LLOME (Language Model Optimization with Margin Expectation), a bilevel optimization routine for online black-box optimization.\nWhen combined with a novel preference learning loss, we find LLOME can not only learn to solve some Ehrlich functions, but \ncan even perform as well as or better than LaMBO-2 on moderately difficult Ehrlich variants. \nHowever, LLMs also exhibit some likelihood-reward miscalibration and struggle without explicit rewards. \nOur results indicate LLMs can occasionally provide significant benefits, but specialized solvers are still competitive and incur less overhead.'}",https://openreview.net{'value': '/pdf/28cd04462a9939847df9774eea2e70286c250f5a.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=zDZkyvZqFR,{'value': 'Beyond One-Hot Labels: Semantic Mixing for Model Calibration'},Haoyang Luo; Linwei Tao; Minjing Dong; Chang Xu,~Haoyang_Luo1; ~Linwei_Tao2; ~Minjing_Dong1; ~Chang_Xu4,"{'value': ['model calibration', 'semantic mixing', 'diffusion models']}","{'value': 'Model calibration seeks to ensure that models produce confidence scores that accurately reflect the true likelihood of their predictions being correct. However, existing calibration approaches are fundamentally tied to datasets of one-hot labels implicitly assuming full certainty in all the annotations. Such datasets are effective for classification but provides insufficient knowledge of uncertainty for model calibration, necessitating the curation of datasets with numerically rich ground-truth confidence values. However, due to the scarcity of uncertain visual examples, such samples are not easily available as real datasets. In this paper, we introduce calibration-aware data augmentation to create synthetic datasets of diverse samples and their ground-truth uncertainty. Specifically, we present **Calibration-aware Semantic Mixing (CSM)**, a novel framework that generates training samples with mixed class characteristics and annotates them with distinct confidence scores via diffusion models. Based on this framework, we propose calibrated reannotation to tackle the misalignment between the annotated confidence score and the mixing ratio during the diffusion reverse process. Besides, we explore the loss functions that better fit the new data representation paradigm. Experimental results demonstrate that CSM achieves superior calibration compared to the state-of-the-art calibration approaches. Our code is [available here](https://github.com/E-Galois/CSM).'}",https://openreview.net{'value': '/pdf/3d97f8f6e3832107b9dffcf0440de9b7fead655f.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=z7lApwS4nV,{'value': 'CtrlSynth: Controllable Image Text Synthesis for Data-Efficient Multimodal Learning'},Qingqing Cao; Mahyar Najibi; Sachin Mehta,~Qingqing_Cao1; ~Mahyar_Najibi1; ~Sachin_Mehta1,"{'value': ['clip', 'synthetic data', 'multimodal learning', 'longtail']}","{'value': 'Pretraining robust vision or multimodal foundation models (e.g., CLIP) relies on large-scale datasets that may be noisy, potentially misaligned, and have long-tail distributions. Previous works have shown promising results in augmenting datasets by generating synthetic samples. However, they only support domain-specific ad hoc use cases (e.g., either image or text only, but not both), and are limited in data diversity due to a lack of fine-grained control over the synthesis process. In this paper, we design a controllable image-text synthesis pipeline, CtrlSynth, for data-efficient and robust multimodal learning. The key idea is to decompose the visual semantics of an image into basic elements, apply user-specified control policies (e.g., remove, add, or replace operations), and recompose them to synthesize images or texts. The decompose and recompose feature in CtrlSynth allows users to control data synthesis in a fine-grained manner by defining customized control policies to manipulate the basic elements. CtrlSynth leverages the capabilities of pretrained foundation models such as large language models or diffusion models to reason and recompose basic elements such that synthetic samples are natural and composed in diverse ways. CtrlSynth is a closed-loop, training-free, and modular framework, making it easy to support different pretrained models. With extensive experiments on 31 datasets spanning different vision and vision-language tasks, we show that CtrlSynth substantially improves zero-shot classification, image-text retrieval, and compositional reasoning performance of CLIP models.'}",https://openreview.net{'value': '/pdf/e5a6df3d73064f47aac53b2a8124aec2d2692b8c.pdf'},{'abstract_filter': 'Data Synthesis'},ICML.cc,2025,Conference
https://openreview.net/forum?id=ysRvf0tjVP,{'value': 'TANGO: Clustering with Typicality-Aware Nonlocal Mode-Seeking and Graph-Cut Optimization'},Haowen Ma; Zhiguo Long; Hua Meng,~Haowen_Ma2; ~Zhiguo_Long2; ~Hua_Meng2,"{'value': ['clustering', 'density-based clustering', 'mode-seeking', 'spectral clustering']}","{'value': 'Density-based mode-seeking methods generate a density-ascending dependency from low-density points towards higher-density neighbors.\nCurrent mode-seeking methods identify modes by breaking some dependency connections, but relying heavily on local data characteristics, requiring case-by-case threshold settings or human intervention to be effective for different datasets. To address this issue, we introduce a novel concept called typicality, by exploring the locally defined dependency from a global perspective, to quantify how confident a point would be a mode. We devise an algorithm that effectively and efficiently identifies modes with the help of the global-view typicality. To implement and validate our idea, we design a clustering method called TANGO, which not only leverages typicality to detect modes, but also utilizes graph-cut with an improved path-based similarity to aggregate data into the final clusters. Moreover, this paper also provides some theoretical analysis on the proposed algorithm. Experimental results on several synthetic and extensive real-world datasets demonstrate the effectiveness and superiority of TANGO. The code is available at https://github.com/SWJTU-ML/TANGO_code.'}",https://openreview.net{'value': '/pdf/9ce6b1d83de623f5158e14e061c46c4af2124164.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=yeICCRy3lE,{'value': 'AdaPTS: Adapting Univariate Foundation Models to Probabilistic Multivariate Time Series Forecasting'},Abdelhakim Benechehab; Vasilii Feofanov; Giuseppe Paolo; Albert Thomas; Maurizio Filippone; Balázs Kégl,~Abdelhakim_Benechehab1; ~Vasilii_Feofanov1; ~Giuseppe_Paolo1; ~Albert_Thomas1; ~Maurizio_Filippone1; ~Balázs_Kégl2,"{'value': ['Multivariate time series forecasting', 'Foundation models', 'Probabilistic inference']}","{'value': 'Pre-trained foundation models (FMs) have shown exceptional performance in univariate time series forecasting tasks. However, several practical challenges persist, including managing intricate dependencies among features and quantifying uncertainty in predictions. This study aims to tackle these critical limitations by introducing **adapters**—feature-space transformations that facilitate the effective use of pre-trained univariate time series FMs for multivariate tasks. Adapters operate by projecting multivariate inputs into a suitable latent space and applying the FM independently to each dimension. Inspired by the literature on representation learning and partially stochastic Bayesian neural networks, we present a range of adapters and optimization/inference strategies. Experiments conducted on both synthetic and real-world datasets confirm the efficacy of adapters, demonstrating substantial enhancements in forecasting accuracy and uncertainty quantification compared to baseline methods. Our framework, **AdaPTS**, positions adapters as a modular, scalable, and effective solution for leveraging time series FMs in multivariate contexts, thereby promoting their wider adoption in real-world applications. We release the code at https://github.com/abenechehab/AdaPTS.'}",https://openreview.net{'value': '/pdf/334b6de0481e713fff8b63780c5469e23450a356.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=ybODpT8ydV,{'value': 'PatchPilot: A Cost-Efficient Software Engineering Agent with Early Attempts on Formal Verification'},Hongwei Li; Yuheng Tang; Shiqi Wang; Wenbo Guo,~Hongwei_Li6; ~Yuheng_Tang1; ~Shiqi_Wang2; ~Wenbo_Guo1,"{'value': ['large language model', 'automatic program repair', 'autonomous software improvement', 'autonomous software engineering']}","{'value': 'Recent research builds various patching agents that combine large language models (LLMs) with non-ML tools and achieve promising results on the state-of-the-art (SOTA) software patching benchmark, SWE-bench. \nBased on how to determine the patching workflows, existing patching agents can be categorized as agent-based planning methods, which rely on LLMs for planning, and rule-based planning methods, which follow a pre-defined workflow.\nAt a high level, agent-based planning methods achieve high patching performance but with a high cost and limited stability. \nRule-based planning methods, on the other hand, are more stable and efficient but have key workflow limitations that compromise their patching performance.\nIn this paper, we propose PatchPilot, an agentic patcher that strikes a balance between patching efficacy, stability, and cost-efficiency. \nPatchPilot proposes a novel rule-based planning workflow with five components: reproduction, localization, generation, validation, and refinement (where refinement is unique to PatchPilot).\nWe introduce novel and customized designs to each component to optimize their effectiveness and efficiency. \nThrough extensive experiments on the SWE-bench benchmarks, PatchPilot shows a superior performance than existing open-source methods while maintaining low cost (less than 1\\$ per instance) and ensuring higher stability.\nWe also conduct a detailed ablation study to validate the key designs in each component.\nOur code is available at https://github.com/ucsb-mlsec/PatchPilot.'}",https://openreview.net{'value': '/pdf/c2c4afde4d7db510dc642f39b9559ea1bb6b4f07.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=ybA4EcMmUZ,{'value': 'Plan-and-Act: Improving Planning of Agents for Long-Horizon Tasks'},Lutfi Eren Erdogan; Nicholas Lee; Sehoon Kim; Suhong Moon; Hiroki Furuta; Gopala Anumanchipalli; Kurt Keutzer; Amir Gholami,~Lutfi_Eren_Erdogan1; ~Nicholas_Lee1; ~Sehoon_Kim1; ~Suhong_Moon1; ~Hiroki_Furuta1; ~Gopala_Anumanchipalli1; ~Kurt_Keutzer1; ~Amir_Gholami2,"{'value': ['LLM', 'Agents', 'Web Agents', 'Planning']}","{'value': 'Large language models (LLMs) have shown remarkable advancements in enabling language agents to tackle simple tasks. However, applying them for complex, multi-step, long-horizon tasks remains a challenge. Recent work have found success by separating high-level planning from low-level execution, which enables the model to effectively balance high-level planning objectives and low-level execution details. However, generating accurate plans remains difficult since LLMs are not inherently trained for this task. To address this, we propose Plan-and-Act, a novel framework that incorporates explicit planning into LLM-based agents and introduces a scalable method to enhance plan generation through a novel synthetic data generation method. Plan-and-Act consists of a Planner model which generates structured, high-level plans to achieve user goals, and an Executor model that translates these plans into environment-specific actions. To train the Planner effectively, we introduce a synthetic data generation method that annotates ground-truth trajectories with feasible plans, augmented with diverse and extensive examples to enhance generalization. We evaluate Plan-and-Act using web navigation as a representative long-horizon planning environment, demonstrating a state-of-the-art 57.58% success rate on the WebArena-Lite benchmark as well as a text-only state-of-the-art 81.36% success rate on WebVoyager.'}",https://openreview.net{'value': '/pdf/3c36989fe5865e915c75d8ddc26baa89b226452e.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=ySWrJer7mW,"{'value': 'Think Twice, Act Once: A Co-Evolution Framework of LLM and RL for Large-Scale Decision Making'}",Xu Wan; Wenyue Xu; Chao Yang; Mingyang Sun,~Xu_Wan1; ~Wenyue_Xu2; ~Chao_Yang7; ~Mingyang_Sun6,"{'value': ['Power Grid Control', 'Large Language Models-enhanced Reinforcement Learning']}","{'value': ""Recent advancements in Large Language Models (LLMs) and Reinforcement Learning (RL) have shown significant promise in decision-making tasks. Nevertheless, for large-scale industrial decision problems, both approaches face distinct challenges: LLMs lack real-time long-sequence decision-making capabilities, while RL struggles with sample efficiency in vast action spaces. To bridge this gap, we propose **A**gents **C**o-**E**volution (ACE), a synergistic framework between LLMs and RL agent for large-scale decision-making scenarios. ACE introduces a dual-role trajectory refinement mechanism where LLMs act as both Policy Actor and Value Critic during RL's training: the Actor refines suboptimal actions via multi-step reasoning and environment validation, while the Critic performs temporal credit assignment through trajectory-level reward shaping. Concurrently, RL agent enhance LLMs' task-specific decision-making via prioritized experience replay.\n\nThrough extensive experiments across multiple power grid operation challenges with action spaces exceeding 60K discrete actions, ACE demonstrates superior performance over existing RL methods and LLM-based methods.""}",https://openreview.net{'value': '/pdf/8e907c3e429cfb20725cd801703a2f02c6c4ad8e.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=yNpYb376zf,{'value': 'Fleet of Agents: Coordinated Problem Solving with Large Language Models'},Lars Henning Klein; Nearchos Potamitis; Roland Aydin; Robert West; Caglar Gulcehre; Akhil Arora,~Lars_Henning_Klein1; ~Nearchos_Potamitis1; ~Roland_Aydin1; ~Robert_West1; ~Caglar_Gulcehre1; ~Akhil_Arora1,"{'value': ['large language models', 'genetic particle filtering', 'heuristic search', 'general problem solving', 'decision making', 'explore vs exploit', 'efficiency', 'cost-quality trade-off']}","{'value': ""While numerous frameworks have been developed to enhance the reasoning abilities of large language models (LLMs), there is a scarcity of methods that effectively balance the trade-off between cost and quality. \nIn this paper, we introduce Fleet of Agents (FoA), a novel and intuitive yet principled framework utilizing LLMs as agents to navigate through dynamic tree searches, employing a genetic-type particle filtering approach. \nFoA spawns a multitude of agents, each exploring the search space autonomously, followed by a selection phase where resampling based on a heuristic value function optimizes the balance between exploration and exploitation. \nThis mechanism enables dynamic branching, adapting the exploration strategy based on discovered solutions. \nWe conduct extensive experiments on four benchmark tasks, \\``Game of 24\\'', \\``Mini-Crosswords\\'', \\``WebShop\\'' and \\``SciBench\\'', utilizing four different LLMs, GPT-3.5, GPT-4, LLaMA3.2-11B, and LLaMA3.2-90B. \nOn average across all tasks and LLMs, FoA obtains an absolute quality improvement of $\\simeq 5\\%$ while requiring only $\\simeq 35\\%$ of the cost of previous SOTA methods. Notably, our analyses reveal that (1) FoA achieves the best cost-quality trade-off among all benchmarked methods, and (2) FoA+ LLaMA3.2-11B surpasses the Llama3.2-90B model. FoA is publicly available at [https://github.com/au-clan/FoA](https://github.com/au-clan/FoA).""}",https://openreview.net{'value': '/pdf/b304f876ddf9e646e819e721bcb2f0c10d33c6b3.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=yIfCq03hsM,{'value': 'Convex Markov Games: A New Frontier for Multi-Agent Reinforcement Learning'},Ian Gemp; Andreas Alexander Haupt; Luke Marris; Siqi Liu; Georgios Piliouras,~Ian_Gemp1; ~Andreas_Alexander_Haupt1; ~Luke_Marris2; ~Siqi_Liu1; ~Georgios_Piliouras1,"{'value': ['Markov Decision Process', 'Nash Equilibrium', 'Markov Game', 'N-player General-Sum', 'Convex Optimization', 'Occupancy Measure']}","{'value': ""Behavioral diversity, expert imitation, fairness, safety goals and others give rise to preferences in sequential decision making domains that do not decompose additively across time. We introduce the class of convex Markov games that allow general convex preferences over occupancy measures. Despite infinite time horizon and strictly higher generality than Markov games, pure strategy Nash equilibria exist. Furthermore, equilibria can be approximated empirically by performing gradient descent on an upper bound of exploitability. Our experiments reveal novel solutions to classic repeated normal-form games, find fair solutions in a repeated asymmetric coordination game, and prioritize safe long-term behavior in a robot warehouse environment. In the prisoner's dilemma, our algorithm leverages transient imitation to find a policy profile that deviates from observed human play only slightly, yet achieves higher per-player utility while also being three orders of magnitude less exploitable.""}",https://openreview.net{'value': '/pdf/2a9c7e4459dea6f70375861204f815eea1cb287e.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=yI24Wy5YaN,{'value': 'Principal-Agent Bandit Games with Self-Interested and Exploratory Learning Agents'},Junyan Liu; Lillian J. Ratliff,~Junyan_Liu1; ~Lillian_J._Ratliff1,"{'value': ['Bandits', 'Principal-agent problem', 'Incentive design', 'Regret minimization']}","{'value': ""We study the repeated principal-agent bandit game, where the principal indirectly explores an unknown environment by incentivizing an agent to play arms. \nUnlike prior work that assumes a greedy agent with full knowledge of reward means, we consider a self-interested learning agent who iteratively updates reward estimates and may explore arbitrarily with some probability.\nAs a warm-up, we first consider a self-interested learning agent without exploration.\nWe propose algorithms for both i.i.d. and linear reward settings with bandit feedback in a finite horizon $T$, achieving regret bounds of $\\widetilde{O}(\\sqrt{T})$ and $\\widetilde{O}(T^{\\frac{2}{3}})$, respectively. \nSpecifically, these algorithms rely on a novel elimination framework coupled with new search algorithms which accommodate the uncertainty from the agent's learning behavior. We then extend the framework to handle an exploratory learning agent and develop an algorithm to achieve a $\\widetilde{O}(T^{\\frac{2}{3}})$ regret bound in i.i.d. reward setup by enhancing the robustness of our elimination framework to the potential agent exploration. Finally, when our agent model reduces to that in (Dogan et al., 2023a), we propose an algorithm based on our robust framework, which achieves a $\\widetilde{O}(\\sqrt{T})$ regret bound, significantly improving upon their $\\widetilde{O}(T^{\\frac{11}{12}})$ bound.""}",https://openreview.net{'value': '/pdf/66c13e56c3b71fed68b634dfbce043c8696e90c7.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=y9JV6VANYp,{'value': 'Contrastive Visual Data Augmentation'},Yu Zhou; Bingxuan Li; Tang Mohan; Xiaomeng Jin; Te-Lin Wu; Kuan-Hao Huang; Heng Ji; Kai-Wei Chang; Nanyun Peng,~Yu_Zhou20; ~Bingxuan_Li2; ~Tang_Mohan1; ~Xiaomeng_Jin3; ~Te-Lin_Wu1; ~Kuan-Hao_Huang1; ~Heng_Ji3; ~Kai-Wei_Chang1; ~Nanyun_Peng1,"{'value': ['Data Augmentation', 'Text-to-Image Generation', 'Feature Extraction']}","{'value': 'Large multimodal models (LMMs) often struggle to recognize novel concepts, as they rely on pre-trained knowledge and have limited ability to capture subtle visual details. Domain-specific knowledge gaps in training also make them prone to confusing visually similar, commonly misrepresented, or low-resource concepts. To help LMMs better align nuanced visual features with language, improving their ability to recognize and reason about novel or rare concepts, we propose a Contrastive visual Data Augmentation (CoDA) strategy. CoDA extracts key contrastive textual and visual features of target concepts against the known concepts they are misrecognized as, and then uses multimodal generative models to produce targeted synthetic data. Automatic filtering of extracted features and augmented images is implemented to guarantee their quality, as verified by human annotators. We show the effectiveness and efficiency of CoDA on low-resource concept and diverse scene recognition datasets including INaturalist and SUN. We additionally collect NovelSpecies, a benchmark dataset consisting of newly discovered animal species that are guaranteed to be unseen by LMMs. LLaVA-1.6 1-shot updating results on these three datasets show CoDA significantly improves SOTA visual data augmentation strategies by 12.3% (NovelSpecies), 5.1% (SUN), and 6.0% (iNat) absolute gains in accuracy.'}",https://openreview.net{'value': '/pdf/d5317102f9271010c6667ea15b240084a541789a.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=y62fhuA69I,{'value': 'video-SALMONN-o1: Reasoning-enhanced Audio-visual Large Language Model'},Guangzhi Sun; Yudong Yang; Jimin Zhuang; Changli Tang; Yixuan Li; Wei Li; Zejun MA; Chao Zhang,~Guangzhi_Sun1; ~Yudong_Yang1; ~Jimin_Zhuang1; ~Changli_Tang1; ~Yixuan_Li13; ~Wei_Li78; ~Zejun_MA1; ~Chao_Zhang20,"{'value': ['audio-visual', 'chain-of-thought reasoning', 'large language models', 'process reward model', 'direct preference optimization']}","{'value': 'While recent advancements in reasoning optimization have significantly enhanced the capabilities of large language models (LLMs), existing efforts to improve reasoning have been limited to solving mathematical problems and focusing on visual graphical inputs, neglecting broader applications in general video understanding. This paper proposes video-SALMONN-o1, the first open-source reasoning-enhanced audio-visual LLM designed for general video understanding tasks. To enhance its reasoning abilities, we develop a reasoning-intensive dataset featuring challenging audio-visual questions with step-by-step solutions. We also propose process direct preference optimization (pDPO), which leverages contrastive step selection to achieve efficient step-level reward modelling tailored for multimodal inputs. Additionally, we introduce RivaBench, the first reasoning-intensive video understanding benchmark, featuring over 4,000 high-quality, expert-curated question-answer pairs across scenarios such as standup comedy, academic presentations, and synthetic video detection. video-SALMONN-o1 achieves 3-8% accuracy improvements over the LLaVA-OneVision baseline across different video reasoning benchmarks. Besides, pDPO achieves 6-8% improvements compared to the supervised fine-tuning model on RivaBench. Enhanced reasoning enables video-SALMONN-o1 zero-shot synthetic video detection capabilities.'}",https://openreview.net{'value': '/pdf/783ef0e044846408164817db1a87c437c5e527e1.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=y3d4Bs2r7r,{'value': 'Addressing Misspecification in Simulation-based Inference through Data-driven Calibration'},Antoine Wehenkel; Juan L. Gamella; Ozan Sener; Jens Behrmann; Guillermo Sapiro; Joern-Henrik Jacobsen; marco cuturi,~Antoine_Wehenkel1; ~Juan_L._Gamella1; ~Ozan_Sener1; ~Jens_Behrmann1; ~Guillermo_Sapiro1; ~Joern-Henrik_Jacobsen1; ~marco_cuturi2,"{'value': ['Simulation-based Inference', 'Misspecification', 'Optimal Transport', 'Bayesian Inference', 'Neural Posterior Estimation', 'Robust Inference']}","{'value': ""Driven by steady progress in deep generative modeling, simulation-based inference (SBI) has emerged as the workhorse for inferring the parameters of stochastic simulators. However, recent work has demonstrated that model misspecification can harm SBI's reliability, preventing its adoption in important applications where only misspecified simulators are available.\nThis work introduces robust posterior estimation (RoPE), a framework that overcomes model misspecification with a small real-world calibration set of ground truth parameter measurements.\nWe formalize the misspecification gap as the solution of an optimal transport (OT) problem between learned representations of real-world and simulated observations, allowing RoPE to learn a model of the misspecification without placing additional assumptions on its nature. RoPE shows how the calibration set and OT together offer a controllable balance between calibrated uncertainty and informative inference even under severely misspecified simulators. Results on four synthetic tasks and two real-world problems with ground-truth labels demonstrate that RoPE outperforms baselines and consistently returns informative and calibrated credible intervals.""}",https://openreview.net{'value': '/pdf/bd4cf426b53f3b3b34d5141735d339432360a9e1.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=xtxCM4XZ82,{'value': 'FlexiClip: Locality-Preserving Free-Form Character Animation'},Anant Khandelwal,~Anant_Khandelwal1,{'value': ['Text-to-Video generation']},"{'value': 'Animating clipart images with seamless motion while maintaining visual fidelity and temporal coherence presents significant challenges. Existing methods, such as AniClipart, effectively model spatial deformations but often fail to ensure smooth temporal transitions, resulting in artifacts like abrupt motions and geometric distortions. Similarly, text-to-video (T2V) and image-to-video (I2V) models struggle to handle clipart due to the mismatch in statistical properties between natural video and clipart styles. This paper introduces FlexiClip, a novel approach designed to overcome these limitations by addressing the intertwined challenges of temporal consistency and geometric integrity. FlexiClip extends traditional Bézier curve-based trajectory modeling with key innovations: temporal Jacobians to correct motion dynamics incrementally, continuous-time modeling via probability flow ODEs (pfODEs) to mitigate temporal noise, and a flow matching loss inspired by GFlowNet principles to optimize smooth motion transitions. These enhancements ensure coherent animations across complex scenarios involving rapid movements and non-rigid deformations. Extensive experiments validate the effectiveness of FlexiClip in generating animations that are not only smooth and natural but also structurally consistent across diverse clipart types, including humans and animals. By integrating spatial and temporal modeling with pre-trained video diffusion models, FlexiClip sets a new standard for high-quality clipart animation, offering robust performance across a wide range of visual content. Project Page: https://creative-gen.github.io/flexiclip.github.io/'}",https://openreview.net{'value': '/pdf/0d392ccf879852f539617733eae90936bc21902c.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=xkV3uCQtJm,{'value': 'Nonparametric Modern Hopfield Models'},Jerry Yao-Chieh Hu; Bo-Yu Chen; Dennis Wu; Feng Ruan; Han Liu,~Jerry_Yao-Chieh_Hu1; ~Bo-Yu_Chen1; ~Dennis_Wu1; ~Feng_Ruan1; ~Han_Liu4,"{'value': ['dense associative memory', 'modern Hopfield model', 'Hopfield network', 'efficient transformer', 'efficient attention', 'transformer', 'attention', 'foundation model', 'large language model']}","{'value': 'We present a nonparametric interpretation for deep learning compatible modern Hopfield models and utilize this new perspective to debut efficient variants. \nOur key contribution stems from interpreting the memory storage and retrieval processes in modern Hopfield models as a nonparametric regression problem subject to a set of query-memory pairs.\nInterestingly,\nour framework not only recovers the known results from the original dense modern Hopfield model but also fills the void in the literature regarding efficient modern Hopfield models, by introducing *sparse-structured* modern Hopfield models with sub-quadratic complexity.\nWe establish that this sparse model inherits the appealing theoretical properties of its dense analogue --- connection with transformer attention,  fixed point convergence and exponential memory capacity.\nAdditionally, we showcase the versatility of our framework by constructing a family of modern Hopfield models as extensions, including linear, random masked, top-$K$ and positive random feature modern Hopfield models.\nEmpirically, we validate our framework in both synthetic and realistic settings for memory retrieval and learning tasks.'}",https://openreview.net{'value': '/pdf/07c0afe8bcf8cea9fef9dc04a8643d1fc47c2d1a.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=xWu5qpDK6U,{'value': 'Audio Flamingo 2: An Audio-Language Model with Long-Audio Understanding and Expert Reasoning Abilities'},Sreyan Ghosh; Zhifeng Kong; Sonal Kumar; S Sakshi; Jaehyeon Kim; Wei Ping; Rafael Valle; Dinesh Manocha; Bryan Catanzaro,~Sreyan_Ghosh1; ~Zhifeng_Kong1; ~Sonal_Kumar1; ~S_Sakshi1; ~Jaehyeon_Kim1; ~Wei_Ping1; ~Rafael_Valle1; ~Dinesh_Manocha3; ~Bryan_Catanzaro1,"{'value': ['audio', 'sound', 'large audio-language model']}","{'value': 'Understanding and reasoning over non-speech sounds and music are crucial for both humans and AI agents to interact effectively with their environments. In this paper, we introduce Audio Flamingo 2 (AF2), an Audio-Language Model (ALM) with advanced audio understanding and reasoning capabilities. AF2 leverages (i) a custom CLAP model, (ii) synthetic Audio QA data for fine-grained audio reasoning, and (iii) a multi-stage curriculum learning strategy. AF2 achieves state-of-the-art performance with only a 3B parameter small language model, surpassing large open-source and proprietary models across over 20 benchmarks. Next, for the first time, we extend audio understanding to long audio segments (30 secs to 5 mins) and propose LongAudio, a large and novel dataset for training ALMs on long audio captioning and question-answering tasks. Fine-tuning AF2 on LongAudio leads to exceptional performance on our proposed LongAudioBench, an expert-annotated benchmark for evaluating ALMs on long audio understanding capabilities. We conduct extensive ablation studies to confirm the efficacy of our approach.'}",https://openreview.net{'value': '/pdf/303ac4970502bea74c0e0c44636ac53234a485d9.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=xF5PuTLPbn,{'value': 'PaperBench: Evaluating AI’s Ability to Replicate AI Research'},Giulio Starace; Oliver Jaffe; Dane Sherburn; James Aung; Jun Shern Chan; Leon Maksin; Rachel Dias; Evan Mays; Benjamin Kinsella; Wyatt Thompson; Johannes Heidecke; Amelia Glaese; Tejal Patwardhan,~Giulio_Starace1; ~Oliver_Jaffe2; ~Dane_Sherburn1; ~James_Aung1; ~Jun_Shern_Chan1; ~Leon_Maksin1; ~Rachel_Dias1; ~Evan_Mays1; ~Benjamin_Kinsella1; ~Wyatt_Thompson1; ~Johannes_Heidecke1; ~Amelia_Glaese1; ~Tejal_Patwardhan1,"{'value': ['benchmark', 'evals', 'evaluations', 'dataset', 'tasks', 'engineering', 'agents', 'scaffold', 'coding', 'mle', 'research', 'r&d']}","{'value': ""We introduce PaperBench, a benchmark evaluating the ability of AI agents to replicate state-of-the-art AI research. Agents must replicate 20 ICML 2024 Spotlight and Oral papers from scratch, including understanding paper contributions, developing a codebase, and successfully executing experiments. For objective evaluation, we develop rubrics that hierarchically decompose each replication task into smaller sub-tasks with clear grading criteria. In total, PaperBench contains 8,316 individually gradable tasks. Rubrics are co-developed with the author(s) of each ICML paper for accuracy and realism. To enable scalable evaluation, we also develop an LLM-based judge to automatically grade replication attempts against rubrics, and assess our judge's performance by creating a separate benchmark for judges. We evaluate several frontier models on PaperBench, finding that the best-performing tested agent, Claude 3.5 Sonnet (New) with open-source scaffolding, achieves an average replication score of 21.0%. Finally, we recruit top ML PhDs to attempt a subset of PaperBench, finding that models do not yet outperform the human baseline. We open-source our code (https://github.com/openai/preparedness) to facilitate future research in understanding the AI engineering capabilities of AI agents.""}",https://openreview.net{'value': '/pdf/ea535a4499f13139a80db861234e438736baa2b9.pdf'},{'abstract_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=x9LGowGzZu,{'value': 'GoIRL: Graph-Oriented Inverse Reinforcement Learning for Multimodal Trajectory Prediction'},Muleilan Pei; Shaoshuai Shi; Lu Zhang; Peiliang Li; Shaojie Shen,~Muleilan_Pei1; ~Shaoshuai_Shi1; ~Lu_Zhang12; ~Peiliang_Li2; ~Shaojie_Shen1,"{'value': ['Autonomous Driving', 'Trajectory Prediction', 'Inverse Reinforcement Learning']}","{'value': 'Trajectory prediction for surrounding agents is a challenging task in autonomous driving due to its inherent uncertainty and underlying multimodality. Unlike prevailing data-driven methods that primarily rely on supervised learning, in this paper, we introduce a novel **G**raph-**o**riented **I**nverse **R**einforcement **L**earning (GoIRL) framework, which is an IRL-based predictor equipped with vectorized context representations. We develop a feature adaptor to effectively aggregate lane-graph features into grid space, enabling seamless integration with the maximum entropy IRL paradigm to infer the reward distribution and obtain the policy that can be sampled to induce multiple plausible plans. Furthermore, conditioned on the sampled plans, we implement a hierarchical parameterized trajectory generator with a refinement module to enhance prediction accuracy and a probability fusion strategy to boost prediction confidence. Extensive experimental results showcase our approach not only achieves state-of-the-art performance on the large-scale Argoverse & nuScenes motion forecasting benchmarks but also exhibits superior generalization abilities compared to existing supervised models.'}",https://openreview.net{'value': '/pdf/b26e8134c9b1143b89f3289af70f0f21e7fa71e4.pdf'},{'title_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=x5RQnF7Vw9,{'value': 'Do Bayesian Neural Networks Actually Behave Like Bayesian Models?'},Gábor Pituk; Vik Shirvaikar; Tom Rainforth,~Gábor_Pituk1; ~Vik_Shirvaikar1; ~Tom_Rainforth1,"{'value': ['Bayesian Neural Networks', 'BNNs', 'Bayesian Deep Learning']}","{'value': 'We empirically investigate how well popular approximate inference algorithms for Bayesian Neural Networks (BNNs) respect the theoretical properties of Bayesian belief updating. We find strong evidence on synthetic regression and real-world image classification tasks that common BNN algorithms such as variational inference, Laplace approximation, SWAG, and SGLD fail to update in a consistent manner, forget about old data under sequential updates, and violate the predictive coherence properties that would be expected of Bayesian methods. These observed behaviors imply that care should be taken when treating BNNs as true Bayesian models, particularly when using them beyond static prediction settings, such as for active, continual, or transfer learning.'}",https://openreview.net{'value': '/pdf/cef8d54394647848e88b848050a0c36e544128eb.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=x4yTgv2WkJ,{'value': 'Orient Anything: Learning Robust Object Orientation Estimation from Rendering 3D Models'},Zehan Wang; Ziang Zhang; Tianyu Pang; Chao Du; Hengshuang Zhao; Zhou Zhao,~Zehan_Wang2; ~Ziang_Zhang1; ~Tianyu_Pang1; ~Chao_Du1; ~Hengshuang_Zhao2; ~Zhou_Zhao3,"{'value': ['Object pose', 'Orientation']}","{'value': 'Orientation is a fundamental attribute of objects, essential for understanding their spatial pose and arrangement. However, practical solutions for estimating the orientation of open-world objects in monocular images remain underexplored. In this work, we introduce Orient Anything, the first foundation model for zero-shot object orientation estimation. A key challenge in this task is the scarcity of orientation annotations for open-world objects. To address this, we propose leveraging the vast resources of 3D models. By developing a pipeline to annotate the front face of 3D objects and render them from random viewpoints, we curate 2 million images with precise orientation annotations across a wide variety of object categories. To fully leverage the dataset, we design a robust training objective that models the 3D orientation as probability distributions over three angles and predicts the object orientation by fitting these distributions. Besides, we propose several strategies to further enhance the synthetic-to-real transfer. Our model achieves state-of-the-art orientation estimation accuracy on both rendered and real images, demonstrating impressive zero-shot capabilities across various scenarios. Furthermore, it shows great potential in enhancing high-level applications, such as understanding complex spatial concepts in images and adjusting 3D object pose.'}",https://openreview.net{'value': '/pdf/d6ffeb413e07dd7aa805fbb7c1cbcff5946053e5.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=wxU2LuTE74,"{'value': 'Sparse Autoencoders, Again?'}",Yin Lu; Xuening Zhu; Tong He; David Wipf,~Yin_Lu2; ~Xuening_Zhu2; ~Tong_He5; ~David_Wipf1,"{'value': ['autoencoders', 'sparse representations', 'variational autoencoders', 'low-dimensional manifolds']}","{'value': 'Is there really much more to say about sparse autoencoders (SAEs)?  Autoencoders in general, and SAEs in particular, represent deep architectures that are capable of modeling low-dimensional latent structure in data. Such structure could reflect, among other things, correlation patterns in large language model activations, or complex natural image manifolds. And yet despite the wide-ranging applicability, there have been relatively few changes to SAEs beyond the original recipe from decades ago, namely, standard deep encoder/decoder layers trained with a classical/deterministic sparse regularizer applied within the latent space. One possible exception is the variational autoencoder (VAE), which adopts a stochastic encoder module capable of producing sparse representations when applied to manifold data. In this work we formalize underappreciated weaknesses with both canonical SAEs, as well as analogous VAEs applied to similar tasks, and propose a hybrid alternative model that circumvents these prior limitations.  In terms of theoretical support, we prove that global minima of our proposed model recover certain forms of structured data spread across a union of manifolds.  Meanwhile, empirical evaluations on synthetic and real-world datasets substantiate the efficacy of our approach in accurately estimating underlying manifold dimensions and producing sparser latent representations without compromising reconstruction error.  In general, we are able to exceed the performance of equivalent-capacity SAEs and VAEs, as well as recent diffusion models where applicable, within domains such as images and language model activation patterns.'}",https://openreview.net{'value': '/pdf/95710f4bd102651fef48c23d6a18b604f6efc775.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=wjZcCbTvrU,{'value': 'Learning Mixtures of Experts with EM: A Mirror Descent Perspective'},Quentin Fruytier; Aryan Mokhtari; Sujay Sanghavi,~Quentin_Fruytier1; ~Aryan_Mokhtari3; ~Sujay_Sanghavi2,"{'value': ['Expectation Maximization (EM)', 'Mixtures of Experts (MoE)', 'Mirror Descent']}","{'value': 'Classical Mixtures of Experts (MoE) are Machine Learning models that involve partitioning the input space, with a separate ""expert"" model trained on each partition. Recently, MoE-based model architectures have become popular as a means to reduce training and inference costs. There, the partitioning function and the experts are both learnt jointly via gradient descent-type methods on the log-likelihood. In this paper we study theoretical guarantees of the Expectation Maximization (EM) algorithm for the training of MoE models. We first rigorously analyze EM for MoE where the conditional distribution of the target and latent variable conditioned on the feature variable belongs to an exponential family of distributions and show its equivalence to projected Mirror Descent with unit step size and a Kullback-Leibler Divergence regularizer. This perspective allows us to derive new convergence results and identify conditions for local linear convergence; In the special case of mixture of 2 linear or logistic experts, we additionally provide guarantees for linear convergence based on the signal-to-noise ratio. Experiments on synthetic and (small-scale) real-world data supports that EM outperforms the gradient descent algorithm both in terms of convergence rate and the achieved accuracy.'}",https://openreview.net{'value': '/pdf/9e356444c702d66eedd97483dcd4a92b5da23fb7.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=wITGhlMPXz,{'value': 'Relating Misfit to Gain in Weak-to-Strong Generalization Beyond the Squared Loss'},Abhijeet Mulgund; Chirag Pabbaraju,~Abhijeet_Mulgund1; ~Chirag_Pabbaraju1,"{'value': ['Weak-to-Strong Generalization', 'Bregman Divergence', 'Information Geometry', 'Alignment', 'Large-Language Models']}","{'value': 'The paradigm of weak-to-strong generalization constitutes the training of a strong AI model on data labeled by a weak AI model, with the goal that the strong model nevertheless outperforms its weak supervisor on the target task of interest. For the setting of real-valued regression with the squared loss, recent work quantitatively characterizes the gain in performance of the strong model over the weak model in terms of the misfit between the strong and weak model. We generalize such a characterization to learning tasks whose loss functions correspond to arbitrary Bregman divergences when the strong class is convex. This extends the misfit-based characterization of performance gain in weak-to-strong generalization to classification tasks, as the cross-entropy loss can be expressed in terms of a Bregman divergence. In most practical scenarios, however, the strong model class may not be convex. We therefore weaken this assumption and study weak-to-strong generalization for convex combinations of $k$ strong models in the strong class, in the concrete setting of classification. This allows us to obtain a similar misfit-based characterization of performance gain, up to an additional error term that vanishes as $k$ gets large. Our theoretical findings are supported by thorough experiments on synthetic as well as real-world datasets.'}",https://openreview.net{'value': '/pdf/f6694500b6e25d4dd2c197c166e9b8f8f6671db6.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=w0QxS5arnp,{'value': 'Adaptive Sensitivity Analysis for Robust Augmentation against Natural Corruptions in Image Segmentation'},Laura Yu Zheng; Wenjie Wei; Tony Wu; Jacob Clements; Shreelekha Revankar; Andre Harrison; Yu Shen; Ming Lin,~Laura_Yu_Zheng1; ~Wenjie_Wei2; ~Tony_Wu1; ~Jacob_Clements1; ~Shreelekha_Revankar1; ~Andre_Harrison1; ~Yu_Shen1; ~Ming_Lin2,"{'value': ['image segmentation', 'augmentation', 'robustness', 'heuristic', 'natural corruptions', 'adverse weather']}","{'value': 'Achieving robustness in image segmentation models is challenging due to the fine-grained nature of pixel-level classification. These models, which are crucial for many real-time perception applications, particularly struggle when faced with natural corruptions in the wild for autonomous systems. While sensitivity analysis can help us understand how input variables influence model outputs, its application to natural and uncontrollable corruptions in training data is computationally expensive. In this work, we present an adaptive, sensitivity-guided augmentation method to enhance robustness against natural corruptions. Our sensitivity analysis on average runs 10 times faster and requires about 200 times less storage than previous sensitivity analysis, enabling practical, on-the-fly estimation during training for a model-free augmentation policy. With minimal fine-tuning, our sensitivity-guided augmentation method achieves improved robustness on both real-world and synthetic datasets compared to state-of-the-art data augmentation techniques in image segmentation.'}",https://openreview.net{'value': '/pdf/3c8aa1340fae04410723558a97f646ec99277732.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=vZhdXRnfPU,{'value': 'Active Learning of Deep Neural Networks via Gradient-Free Cutting Planes'},Erica Zhang; Fangzhao Zhang; Mert Pilanci,~Erica_Zhang1; ~Fangzhao_Zhang1; ~Mert_Pilanci3,"{'value': ['convex optimization', 'cutting plane method', 'active learning']}","{'value': 'Active learning methods aim to improve sample complexity in machine learning. In this work, we investigate an active learning scheme via a novel gradient-free cutting-plane training method for ReLU networks of arbitrary depth and develop a convergence theory. \nWe demonstrate, for the first time, that cutting-plane algorithms, traditionally used in linear models, can be extended to deep neural networks despite their nonconvexity and nonlinear decision boundaries. Moreover, this training method induces the first deep active learning scheme known to achieve convergence guarantees, revealing a geometric contraction rate of the feasible set. We exemplify the effectiveness of our proposed active learning method against popular deep active learning baselines via both synthetic data experiments and sentimental classification task on real datasets.'}",https://openreview.net{'value': '/pdf/045cd95c9c011a761d27c51ce676bf489a8dfe57.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=vUDWRMB3tX,{'value': 'Reidentify: Context-Aware Identity Generation for Contextual Multi-Agent Reinforcement Learning'},Zhiwei Xu; Kun Hu; Xin Xin; Weiliang Meng; Yiwei Shi; Hangyu Mao; Bin Zhang; Dapeng Li; Jiangjin Yin,~Zhiwei_Xu3; ~Kun_Hu7; ~Xin_Xin2; ~Weiliang_Meng1; ~Yiwei_Shi1; ~Hangyu_Mao2; ~Bin_Zhang12; ~Dapeng_Li2; ~Jiangjin_Yin1,"{'value': ['Multi-Agent System', 'Reinforcement Learning']}","{'value': 'Generalizing multi-agent reinforcement learning (MARL) to accommodate variations in problem configurations remains a critical challenge in real-world applications, where even subtle differences in task setups can cause pre-trained policies to fail. To address this, we propose Context-Aware Identity Generation (CAID), a novel framework to enhance MARL performance under the Contextual MARL (CMARL) setting. CAID dynamically generates unique agent identities through the agent identity decoder built on a causal Transformer architecture. These identities provide contextualized representations that align corresponding agents across similar problem variants, facilitating policy reuse and improving sample efficiency. Furthermore, the action regulator in CAID incorporates these agent identities into the action-value space, enabling seamless adaptation to varying contexts. Extensive experiments on CMARL benchmarks demonstrate that CAID significantly outperforms existing approaches by enhancing both sample efficiency and generalization across diverse context variants.'}",https://openreview.net{'value': '/pdf/eee5c253e8b2421db7f1821b4ffd74fe67842b0e.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=vOxaD3hhPt,{'value': 'MetaAgent: Automatically Constructing Multi-Agent Systems Based on Finite State Machines'},Yaolun Zhang; Xiaogeng Liu; Chaowei Xiao,~Yaolun_Zhang1; ~Xiaogeng_Liu1; ~Chaowei_Xiao2,"{'value': ['LLM Agent', 'Multi-Agent System']}","{'value': ""Large Language Models (LLMs) have demonstrated the ability to solve a wide range of practical tasks within multi-agent systems. However, existing human-designed multi-agent frameworks are typically limited to a small set of pre-defined scenarios, while current automated design methods suffer from several limitations, such as the lack of tool integration, dependence on external training data, and rigid communication structures. In this paper, we propose \\textbf{MetaAgent}, a  \\textbf{finite state machine} based framework that can automatically generate a multi-agent system. Given a task description, MetaAgent will design a multi-agent system and polish it through an optimization algorithm. When the multi-agent system is deployed, the finite state machine will control the agent's actions and the state transitions. To evaluate our framework, we conduct experiments on both text-based tasks and practical tasks. The results indicate that the generated multi-agent system surpasses other auto-designed methods and can achieve a comparable performance with the human-designed multi-agent system, which is optimized for those specific tasks.""}",https://openreview.net{'value': '/pdf/34ab3426aaf31798b2df911672d4e1e4643a631d.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=vOCPctm3nb,{'value': 'CLARIFY: Contrastive Preference Reinforcement Learning for Untangling Ambiguous Queries'},Ni Mu; Hao Hu; Xiao Hu; Yiqin Yang; Bo XU; Qing-Shan Jia,~Ni_Mu1; ~Hao_Hu3; ~Xiao_Hu7; ~Yiqin_Yang1; ~Bo_XU10; ~Qing-Shan_Jia1,"{'value': ['Preference-based RL', 'contrastive learning']}","{'value': 'Preference-based reinforcement learning (PbRL) bypasses explicit reward engineering by inferring reward functions from human preference comparisons, enabling better alignment with human intentions. However, humans often struggle to label a clear preference between similar segments, reducing label efficiency and limiting PbRL’s real-world applicability. To address this, we propose an offline PbRL method: Contrastive LeArning for ResolvIng Ambiguous Feedback (CLARIFY), which learns a trajectory embedding space that incorporates preference information, ensuring clearly distinguished segments are spaced apart, thus facilitating the selection of more unambiguous queries. Extensive experiments demonstrate that CLARIFY outperforms baselines in both non-ideal teachers and real human feedback settings. Our approach not only selects more distinguished queries but also learns meaningful trajectory embeddings.'}",https://openreview.net{'value': '/pdf/3e6bbb1ab5233d4a52bd5e629e7d178765c9813e.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=vF5F7cL76i,{'value': 'unMORE: Unsupervised Multi-Object Segmentation via Center-Boundary Reasoning'},Yafei YANG; Zihui Zhang; Bo Yang,~Yafei_YANG1; ~Zihui_Zhang2; ~Bo_Yang7,"{'value': ['unsupervised object segmentation', 'object-centric representation']}","{'value': 'We study the challenging problem of unsupervised multi-object segmentation on single images. Existing methods, which rely on image reconstruction objectives to learn objectness or leverage pretrained image features to group similar pixels, often succeed only in segmenting simple synthetic objects or discovering a limited number of real-world objects. In this paper, we introduce unMORE, a novel two-stage pipeline designed to identify many complex objects in real-world images. The key to our approach involves explicitly learning three levels of carefully defined object-centric representations in the first stage. Subsequently, our multi-object reasoning module utilizes these learned object priors to discover multiple objects in the second stage. Notably, this reasoning module is entirely network-free and does not require human labels. Extensive experiments demonstrate that unMORE significantly outperforms all existing unsupervised methods across 6 real-world benchmark datasets, including the challenging COCO dataset, achieving state-of-the-art object segmentation results. Remarkably, our method excels in crowded images where all baselines collapse. Our code and data are available at https://github.com/vLAR-group/unMORE.'}",https://openreview.net{'value': '/pdf/7a36ff55a2c54d9942950bf306465d78cd674751.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=v77ZMzbsBA,{'value': 'Outlier Gradient Analysis: Efficiently Identifying Detrimental Training Samples for Deep Learning Models'},Anshuman Chhabra; Bo Li; Jian Chen; Prasant Mohapatra; Hongfu Liu,~Anshuman_Chhabra1; ~Bo_Li29; ~Jian_Chen11; ~Prasant_Mohapatra1; ~Hongfu_Liu2,"{'value': ['Data-centric learning', 'Detrimental sample detection']}","{'value': 'A core data-centric learning challenge is the identification of training samples that are detrimental to model performance. Influence functions serve as a prominent tool for this task and offer a robust framework for assessing training data influence on model predictions. Despite their widespread use, their high computational cost associated with calculating the inverse of the Hessian matrix pose constraints, particularly when analyzing large-sized deep models. In this paper, we establish a bridge between identifying detrimental training samples via influence functions and outlier gradient detection. This transformation not only presents a straightforward and Hessian-free formulation but also provides insights into the role of the gradient in sample impact. Through systematic empirical evaluations, we first validate the hypothesis of our proposed outlier gradient analysis approach on synthetic datasets. We then demonstrate its effectiveness in detecting mislabeled samples in vision models and selecting data samples for improving performance of natural language processing transformer models. We also extend its use to influential sample identification for fine-tuning Large Language Models.'}",https://openreview.net{'value': '/pdf/e5607078ffbbf2cbb10c98ed1e80edc460db9e60.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=uvU29AfoNT,{'value': 'Few-Shot Learner Generalizes Across AI-Generated Image Detection'},Shiyu Wu; Jing Liu; Jing Li; Yequan Wang,~Shiyu_Wu2; ~Jing_Liu1; ~Jing_Li19; ~Yequan_Wang1,"{'value': ['Deepfake Detection', 'Synthetic Image Detection', 'Few-Shot Learning']}","{'value': 'Current fake image detectors trained on large synthetic image datasets perform satisfactorily on limited studied generative models. However, these detectors suffer a notable performance decline over unseen models. Besides, collecting adequate training data from online generative models is often expensive or infeasible. To overcome these issues, we propose Few-Shot Detector (FSD), a novel AI-generated image detector which learns a specialized metric space for effectively distinguishing unseen fake images using very few samples. Experiments show that FSD achieves state-of-the-art performance by $+11.6\\%$ average accuracy on the GenImage dataset with only $10$ additional samples. More importantly, our method is better capable of capturing the intra-category commonality in unseen images without further training. Our code is available at https://github.com/teheperinko541/Few-Shot-AIGI-Detector.'}",https://openreview.net{'value': '/pdf/25aa2f4e307292d640fa1187b63fd738315c5b37.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=up21Rwj5Fo,{'value': 'Fully Dynamic Euclidean Bi-Chromatic Matching in Sublinear Update Time'},Gramoz Goranci; Peter Kiss; Neel Patel; Martin P. Seybold; Eva Szilagyi; Da Wei Zheng,~Gramoz_Goranci1; ~Peter_Kiss1; ~Neel_Patel1; ~Martin_P._Seybold1; ~Eva_Szilagyi1; ~Da_Wei_Zheng1,"{'value': ['Euclidean bi-chromatic matching', 'dynamic algorithm', '1-Wasserstein distance']}","{'value': 'We consider the Euclidean bi-chromatic matching problem in the dynamic setting, where the goal is to efficiently process point insertions and deletions while maintaining a high-quality solution. Computing the minimum cost bi-chromatic matching is one of the core problems in geometric optimization that has found many applications, most notably in estimating Wasserstein distance between two distributions. In this work, we present the first fully dynamic algorithm for Euclidean bi-chromatic matching with sublinear update time. For any fixed $\\varepsilon > 0$, our algorithm achieves $O(1/\\varepsilon)$-approximation and handles updates in $O(n^{\\varepsilon})$ time.  Our experiments show that our algorithm enables effective monitoring of the distributional drift in the Wasserstein distance on real and synthetic data sets, while outperforming the runtime of baseline approximations by orders of magnitudes.'}",https://openreview.net{'value': '/pdf/f1e7311469320777ba1a757d3e19b8944bb27042.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=ue1ptN4kSS,{'value': 'High-Dimensional Tensor Regression With Oracle Properties'},Wenbin Wang; Yu Shi; Ziping Zhao,~Wenbin_Wang7; ~Yu_Shi17; ~Ziping_Zhao1,"{'value': ['tensor regression', 'non-convex optimization', 'oracle properties', 'high-dimensional statistics', 'sparse', 'low rank']}","{'value': 'The emergence of multi-dimensional data presents significant challenges for traditional regression models based on matrices or vectors, particularly in capturing multi-directional correlations. In response, tensor regression has been proposed as a powerful framework for modeling linear relationships among multi-dimensional variables. In this paper, we introduce a high-dimensional tensor-response tensor regression model under low-dimensional structural assumptions, such as sparsity and low-rankness. Assuming the underlying tensor lies within an unknown low-dimensional subspace, we consider a least squares estimation framework with non-convex penalties. Theoretically, we derive general risk bounds for the resulting estimators and demonstrate that they achieve the oracle statistical rates under mild technical conditions. To compute the proposed estimators efficiently, we introduce an accelerated proximal gradient algorithm demonstrating rapid convergence in practice. Extensive experiments on synthetic and real-world datasets validate the effectiveness of the proposed regression model and showcase the practical utility of the theoretical findings.'}",https://openreview.net{'value': '/pdf/fe9fa415a39f9b9ee8dd99653d21ed614a569c14.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=uWAGlqVkAv,{'value': 'Balancing Interference and Correlation in Spatial Experimental Designs: A Causal Graph Cut Approach'},Jin Zhu; Jingyi Li; Hongyi Zhou; Yinan Lin; Zhenhua Lin; Chengchun Shi,~Jin_Zhu1; ~Jingyi_Li3; ~Hongyi_Zhou5; ~Yinan_Lin2; ~Zhenhua_Lin2; ~Chengchun_Shi1,"{'value': ['policy evaluation', 'AB testing', 'Graph cut', 'Spatial interference', 'Spatial correlation']}","{'value': 'This paper focuses on the design of spatial experiments to optimize the amount of information derived from the experimental data and enhance the accuracy of the resulting causal effect estimator. We propose a surrogate function for the mean squared error (MSE) of the estimator, which facilitates the use of classical graph cut algorithms to learn the optimal design. Our proposal offers three key advances: (1) it accommodates moderate to large spatial interference effects; (2) it adapts to different spatial covariance functions; (3) it is computationally efficient.  Theoretical results and numerical experiments based on synthetic environments and a dispatch simulator that models a city-scale ridesharing market, further validate the effectiveness of our design. A python implementation of our method is available at https://github.com/Mamba413/CausalGraphCut.'}",https://openreview.net{'value': '/pdf/d1f357180848c654cf552a995238a33c9de6d99b.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=uRD6wkqulN,{'value': 'BRIDGE: Bootstrapping Text to Control Time-Series Generation via Multi-Agent Iterative Optimization and Diffusion Modeling'},Hao Li; Yu-Hao Huang; Chang Xu; Viktor Schlegel; Renhe Jiang; Riza Batista-Navarro; Goran Nenadic; Jiang Bian,~Hao_Li25; ~Yu-Hao_Huang2; ~Chang_Xu10; ~Viktor_Schlegel1; ~Renhe_Jiang1; ~Riza_Batista-Navarro1; ~Goran_Nenadic1; ~Jiang_Bian1,"{'value': ['Multi-agents Systems', 'Time Series Generation', 'Large Language Models']}","{'value': ""Time-series Generation (TSG) is a prominent research area with broad applications in simulations, data augmentation, and counterfactual analysis. While existing methods have shown promise in unconditional single-domain TSG, real-world applications demand for cross-domain approaches capable of controlled generation tailored to domain-specific constraints and instance-level requirements. \nIn this paper, we argue that text can provide semantic insights, domain information and instance-specific temporal patterns, to guide and improve TSG.  We introduce ``Text-Controlled TSG'', a task focused on generating realistic time series by incorporating textual descriptions.\nTo address data scarcity in this setting, we propose a novel LLM-based Multi-Agent framework that synthesizes diverse, realistic text-to-TS datasets. Furthermore, we introduce Bridge, a hybrid text-controlled TSG framework that integrates semantic prototypes with text description for supporting domain-level guidance. This approach achieves state-of-the-art generation fidelity on 11 of 12 datasets, and improves controllability by up to 12% on MSE and 6% MAE compared to no text input generation, highlighting its potential for generating tailored time-series data.""}",https://openreview.net{'value': '/pdf/c9eebe9ec79971c3504b2a13413d34dfc66ede75.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=uCkwqAG0uS,{'value': 'Proposer-Agent-Evaluator (PAE): Autonomous Skill Discovery For Foundation Model Internet Agents'},Yifei Zhou; Qianlan Yang; Kaixiang Lin; Min Bai; Xiong Zhou; Yu-Xiong Wang; Sergey Levine; Li Erran Li,~Yifei_Zhou1; ~Qianlan_Yang1; ~Kaixiang_Lin1; ~Min_Bai1; ~Xiong_Zhou2; ~Yu-Xiong_Wang1; ~Sergey_Levine1; ~Li_Erran_Li1,"{'value': ['Web agents', 'LLM Agents', 'Autonomous skill discovery']}","{'value': 'A generalist foundation model agent needs to have a large and diverse skill repertoire, such as finding directions between two travel locations and buying specific items from the Internet. If each skill needs to be specified manually through a fixed set of human-annotated instructions, the agent’s skill repertoire will necessarily be limited due to the scalability of human-annotated instructions. In this work, we address this challenge by proposing Proposer-Agent-Evaluator (PAE), an effective learning system that enables foundation model agents to autonomously discover and practice skills in the wild. After a context-aware task proposer generates instructions based on website information, the agent policy attempts those tasks in the real world with resulting trajectories evaluated by an autonomous VLM-based success evaluator. The success evaluation serves as the reward signal for the agent to refine its policies through RL. We validate PAE on challenging vision-based web navigation, using both real-world and selfhosted websites from WebVoyager and WebArena. Our results show that PAE significantly improves the zero-shot generalization capability of VLM Internet agents (around 50% relative improvement)\nto both unseen tasks and websites.'}",https://openreview.net{'value': '/pdf/32f364e06158d8b2667c0b635c22d6ab44ebb33a.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=u6xeKVHS6K,{'value': 'GMAIL: Generative Modality Alignment for generated Image Learning'},Shentong Mo; Sukmin Yun,~Shentong_Mo1; ~Sukmin_Yun1,"{'value': ['diffusion models', 'generated visual learning', 'vision-language models']}","{'value': 'Generative models have made it possible to synthesize highly realistic images, potentially providing an abundant data source for training machine learning models. Despite the advantages of these synthesizable data sources, the indiscriminate use of generated images as real images for training can even cause mode collapse due to modality discrepancies between real and synthetic domains. In this paper, we propose a novel framework for discriminative use of generated images, coined \\textit{GMAIL}, that explicitly treats generated images as a separate modality from real images. Instead of indiscriminately replacing real images with generated ones in the pixel space, our approach bridges the two distinct modalities in the same latent space through a multi-modal learning approach. To be specific, we first fine-tune a model exclusively on generated images using a cross-modality alignment loss and then employ this aligned model to further train various vision-language models with generated images. By aligning the two modalities, our approach effectively leverages the benefits of recent advances in generative models, thereby boosting the effectiveness of generated image learning across a range of vision-language tasks. Our framework can be easily incorporated with various vision-language models, and we demonstrate its efficacy throughout extensive experiments. For example, our framework significantly improves performance on image captioning, zero-shot image retrieval, zero-shot image classification, and long caption retrieval tasks. It also shows positive generated data scaling trends and notable enhancements in the captioning performance of the large multimodal model, LLaVA.'}",https://openreview.net{'value': '/pdf/4b124c2c322081b6dfbeee5899ea83ec54d2a452.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=u6k5y3FDW1,{'value': 'Optimal Information Retention for Time-Series Explanations'},Jinghang Yue; Jing Wang; Lu Zhang; Shuo Zhang; Da Li; Zhaoyang Ma; Youfang Lin,~Jinghang_Yue1; ~Jing_Wang21; ~Lu_Zhang34; ~Shuo_Zhang37; ~Da_Li15; ~Zhaoyang_Ma1; ~Youfang_Lin1,"{'value': ['Explanations', 'Time Series', 'Optimal Information Retention']}","{'value': 'Explaining deep models for time-series data is crucial for identifying key patterns in sensitive domains, such as healthcare and finance. However, due to the lack of unified optimization criterion, existing explanation methods often suffer from redundancy and incompleteness, where irrelevant patterns are included or key patterns are missed in explanations. To address this challenge, we propose the Optimal Information Retention Principle, where conditional mutual information defines minimizing redundancy and maximizing completeness as optimization objectives. We then derive the corresponding objective function theoretically. As a practical framework, we introduce an explanation framework ORTE, learning a binary mask to eliminate redundant information while mining temporal patterns of explanations. We decouple the discrete mapping process to ensure the stability of gradient propagation, while employing contrastive learning to achieve precise filtering of explanatory patterns through the mask, thereby realizing a trade-off between low redundancy and high completeness. Extensive quantitative and qualitative experiments on synthetic and real-world datasets demonstrate that the proposed principle significantly improves the accuracy and completeness of explanations compared to baseline methods. The code is available at https://github.com/moon2yue/ORTE_public.'}",https://openreview.net{'value': '/pdf/59847dad1062a635e4ee5bf6a33507ad06c1f2d1.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=tqL8gJsuS5,{'value': 'Efficient Source-free Unlearning via Energy-Guided Data Synthesis and Discrimination-Aware Multitask Optimization'},Xiuyuan Wang; Chaochao Chen; Weiming Liu; Xinting Liao; Fan Wang; Xiaolin Zheng,~Xiuyuan_Wang1; ~Chaochao_Chen3; ~Weiming_Liu2; ~Xinting_Liao1; ~Fan_Wang14; ~Xiaolin_Zheng1,"{'value': ['source-free unlearning', 'machine unlearning', 'unlearn']}","{'value': 'With growing privacy concerns and the enforcement of data protection regulations, machine unlearning has emerged as a promising approach for removing the influence of forget data while maintaining model performance on retain data. However, most existing unlearning methods require access to the original training data, which is often impractical due to privacy policies, storage constraints, and other limitations. This gives rise to the challenging task of source-free unlearning, where unlearning must be accomplished without accessing the original training data. Few existing source-free unlearning methods rely on knowledge distillation and model retraining, which impose substantial computational costs. In this work, we propose the Data Synthesis-based Discrimination-Aware (DSDA) unlearning framework, which enables efficient source-free unlearning in two stages: (1) Accelerated Energy-Guided Data Synthesis (AEGDS), which employs Langevin dynamics to model the training data distribution while integrating Runge–Kutta methods and momentum to enhance efficiency. (2) Discrimination-Aware Multitask Optimization (DAMO), which refines the feature distribution of retain data and mitigates the gradient conflicts among multiple unlearning objectives. Extensive experiments on three benchmark datasets demonstrate that DSDA outperforms existing unlearning methods, validating its effectiveness and efficiency in source-free unlearning.'}",https://openreview.net{'value': '/pdf/ff476a868a14b3d5baeec884faa4698690953c55.pdf'},{'title_filter': 'Data Synthesis'},ICML.cc,2025,Conference
https://openreview.net/forum?id=tpbtodnI1p,{'value': 'World Model Implanting for Test-time Adaptation of Embodied Agents'},Minjong Yoo; Jinwoo Jang; Sihyung Yoon; Honguk Woo,~Minjong_Yoo2; ~Jinwoo_Jang1; ~Sihyung_Yoon1; ~Honguk_Woo1,"{'value': ['Embodied AI', 'Model implanting', 'World models', 'Large language model']}","{'value': ""In embodied AI, a persistent challenge is enabling agents to robustly adapt to novel domains without requiring extensive data collection or retraining. To address this, we present a world model implanting framework (WorMI) that combines the reasoning capabilities of large language models (LLMs) with independently learned, domain-specific world models through test-time composition. By allowing seamless implantation and removal of the world models, the embodied agent's policy achieves and maintains cross-domain adaptability. In the WorMI framework, we employ a prototype-based world model retrieval approach, utilizing efficient trajectory-based abstract representation matching, to incorporate relevant models into test-time composition. We also develop a world-wise compound attention method that not only integrates the knowledge from the retrieved world models but also aligns their intermediate representations with the reasoning model's representation within the agent's policy. This framework design effectively fuses domain-specific knowledge from multiple world models, ensuring robust adaptation to unseen domains. We evaluate our WorMI on the VirtualHome and ALFWorld benchmarks, demonstrating superior zero-shot and few-shot performance compared to several LLM-based approaches across a range of unseen domains. These results highlight the framework’s potential for scalable, real-world deployment in embodied agent scenarios where adaptability and data efficiency are essential.""}",https://openreview.net{'value': '/pdf/728f58c6b742bb833f6bf0eae19ab79ce56b60bb.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=tVDZlyVMIZ,{'value': 'Distributionally Robust Active Learning for Gaussian Process Regression'},Shion Takeno; Yoshito Okura; Yu Inatsu; Aoyama Tatsuya; Tomonari Tanaka; Akahane Satoshi; Hiroyuki Hanada; Noriaki Hashimoto; Taro Murayama; Hanju Lee; Shinya Kojima; Ichiro Takeuchi,~Shion_Takeno1; ~Yoshito_Okura1; ~Yu_Inatsu1; ~Aoyama_Tatsuya1; ~Tomonari_Tanaka1; ~Akahane_Satoshi1; ~Hiroyuki_Hanada2; ~Noriaki_Hashimoto1; ~Taro_Murayama1; ~Hanju_Lee1; ~Shinya_Kojima1; ~Ichiro_Takeuchi1,"{'value': ['Gaussian process', 'Active learning', 'distributionally robust', 'experimental design']}","{'value': 'Gaussian process regression (GPR) or kernel ridge regression is a widely used and powerful tool for nonlinear prediction. Therefore, active learning (AL) for GPR, which actively collects data labels to achieve an accurate prediction with fewer data labels, is an important problem. However, existing AL methods do not theoretically guarantee prediction accuracy for target distribution. Furthermore, as discussed in the distributionally robust learning literature, specifying the target distribution is often difficult. Thus, this paper proposes two AL methods that effectively reduce the worst-case expected error for GPR, which is the worst-case expectation in target distribution candidates. We show an upper bound of the worst-case expected squared error, which suggests that the error will be arbitrarily small by a finite number of data labels under mild conditions. Finally, we demonstrate the effectiveness of the proposed methods through synthetic and real-world datasets.'}",https://openreview.net{'value': '/pdf/61c3a6526e4568f263120cba7f42c1bd45f03543.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=sxL3irchez,{'value': 'Long-Short Alignment for Effective Long-Context Modeling in LLMs'},Tianqi Du; Haotian Huang; Yifei Wang; Yisen Wang,~Tianqi_Du1; ~Haotian_Huang1; ~Yifei_Wang1; ~Yisen_Wang1,"{'value': ['Large language model', 'length generalization', 'long-short alignment']}","{'value': 'Large language models (LLMs) have exhibited impressive performance and surprising emergent properties. However, their effectiveness remains limited by the fixed context window of the transformer architecture, posing challenges for long-context modeling. Among these challenges, length generalization — the ability to generalize to sequences longer than those seen during training — is a classical and fundamental problem. In this work, we propose a fresh perspective on length generalization, shifting the focus from the conventional emphasis on input features such as positional encodings or data structures to the output distribution of the model. Specifically, through case studies on synthetic tasks, we highlight the critical role of **long-short alignment** — the consistency of output distributions across sequences of varying lengths. Extending this insight to natural language tasks, we propose a metric called Long-Short Misalignment to quantify this phenomenon, uncovering a strong correlation between the metric and length generalization performance. Building on these findings, we develop a regularization term that promotes long-short alignment during training. Extensive experiments validate the effectiveness of our approach, offering new insights for achieving more effective long-context modeling in LLMs. Code is available at https://github.com/PKU-ML/LongShortAlignment.'}",https://openreview.net{'value': '/pdf/0c545c111c72e2444c9ed6aa0a5eaee35866d047.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=stgw28KnaX,{'value': 'Dynamic Similarity Graph Construction with Kernel Density Estimation'},Steinar Laenen; Peter Macgregor; He Sun,~Steinar_Laenen1; ~Peter_Macgregor1; ~He_Sun5,"{'value': ['similarity graphs', 'kernel density estimation', 'spectral clustering']}","{'value': 'In the kernel density estimation (KDE) problem, we are given a set  $X$ of data points in $\\mathbb{R}^d$, a kernel function $k: \\mathbb{R}^d \\times \\mathbb{R}^d \\rightarrow \\mathbb{R}$, and a query point $\\mathbf{q} \\in \\mathbb{R}^d$, and the objective is to quickly output an estimate of $\\sum_{\\mathbf{x} \\in X} k(\\mathbf{q}, \\mathbf{x})$.\nIn this paper, we consider $\\textsf{KDE}$ in the dynamic setting, and introduce a data structure that efficiently maintains the _estimates_ for a set of query points as data points are added to $X$ over time.\nBased on this, we design a dynamic data structure that maintains a sparse approximation of the fully connected similarity graph on \n$X$, and develop a fast dynamic spectral clustering algorithm.\nWe further evaluate the effectiveness of our algorithms on both synthetic and real-world datasets.'}",https://openreview.net{'value': '/pdf/cf10042ec3e4f7fff631f1ddd832ffd520ce03f0.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=skAjaAEuA2,{'value': 'Plausible Token Amplification for Improving Accuracy of Differentially Private In-Context Learning Based on Implicit Bayesian Inference'},Yusuke Yamasaki; Kenta Niwa; Daiki Chijiwa; Takumi Fukami; Takayuki Miura,~Yusuke_Yamasaki1; ~Kenta_Niwa1; ~Daiki_Chijiwa1; ~Takumi_Fukami1; ~Takayuki_Miura1,"{'value': ['in-context learning', 'differential privacy', 'large language models']}","{'value': ""We propose Plausible Token Amplification (PTA) to improve the accuracy of Differentially Private In-Context Learning (DP-ICL) using DP synthetic demonstrations. While Tang et al. empirically improved the accuracy of DP-ICL by limiting vocabulary space during DP synthetic demonstration generation, its theoretical basis remains unexplored. By interpreting ICL as implicit Bayesian inference on a concept underlying demonstrations, we not only provide theoretical evidence supporting Tang et al.'s empirical method but also introduce PTA, a refined method for modifying next-token probability distribution. Through the modification, PTA highlights tokens that distinctly represent the ground-truth concept underlying the original demonstrations. As a result, generated DP synthetic demonstrations guide the Large Language Model to successfully infer the ground-truth concept, which improves the accuracy of DP-ICL. Experimental evaluations on both synthetic and real-world text-classification datasets validated the effectiveness of PTA.""}",https://openreview.net{'value': '/pdf/75f72c2c073dc85fb26f52cc52da9c084e0e8b5a.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=si1iynl5y7,{'value': 'Gamma Distribution PCA-Enhanced Feature Learning for Angle-Robust SAR Target Recognition'},Chong Zhang; Peng Zhang; Mengke Li,~Chong_Zhang15; ~Peng_Zhang67; ~Mengke_Li3,{'value': ['Synthetic aperture radar; Automatic target recognition']},"{'value': ""Scattering characteristics of synthetic aperture radar (SAR) targets are typically related to observed azimuth and depression angles. \nHowever, in practice, it is difficult to obtain adequate training samples at all observation angles, which probably leads to poor robustness of deep networks. In this paper, we first propose a Gamma-Distribution Principal Component Analysis ($\\Gamma$PCA) model that fully accounts for the statistical characteristics of SAR data. The $\\Gamma$PCA derives consistent convolution kernels to effectively capture the angle-invariant features of the same target at various attitude angles, thus alleviating deep models' sensitivity to angle changes in SAR target recognition task. We validate $\\Gamma$PCA model based on two commonly used backbones, ResNet and ViT, and conduct multiple robustness experiments on the MSTAR benchmark dataset. The experimental results demonstrate that $\\Gamma$PCA effectively enables the model to withstand substantial distributional discrepancy caused by angle changes. Additionally, $\\Gamma$PCA convolution kernel is designed to require no parameter updates, introducing no extra computational burden to the network. The source code is available at \\href{https://github.com/ChGrey/GammaPCA}{https://github.com/ChGrey/GammaPCA}.""}",https://openreview.net{'value': '/pdf/859676fdb3905d9731290e6dd8d2704f2c6142e3.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=saqVVehEOM,{'value': 'Conformal Prediction with Cellwise Outliers: A Detect-then-Impute Approach'},Qian Peng; Yajie Bao; Haojie Ren; Zhaojun Wang; Changliang Zou,~Qian_Peng3; ~Yajie_Bao2; ~Haojie_Ren1; ~Zhaojun_Wang1; ~Changliang_Zou2,"{'value': ['Conformal prediction', 'Cellwise outliers', 'Detection-imputation method', 'Nonexchangeability']}","{'value': 'Conformal prediction is a powerful tool for constructing prediction intervals for black-box models, providing a finite sample coverage guarantee for exchangeable data. However, this exchangeability is compromised when some entries of the test feature are contaminated, such as in the case of cellwise outliers. To address this issue, this paper introduces a novel framework called *detect-then-impute conformal prediction*. This framework first employs an outlier detection procedure on the test feature and then utilizes an imputation method to fill in those cells identified as outliers. To quantify the uncertainty in the processed test feature, we adaptively apply the detection and imputation procedures to the calibration set, thereby constructing exchangeable features for the conformal prediction interval of the test label. We develop two practical algorithms, $\\texttt{PDI-CP}$ and $\\texttt{JDI-CP}$, and provide a distribution-free coverage analysis under some commonly used detection and imputation procedures. Notably, $\\texttt{JDI-CP}$ achieves a finite sample $1-2\\alpha$ coverage guarantee. Numerical experiments on both synthetic and real datasets demonstrate that our proposed algorithms exhibit robust coverage properties and comparable efficiency to the oracle baseline.'}",https://openreview.net{'value': '/pdf/241adae286e288c2d5d695f7ffe8261742ebc0d6.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=sDGafRLNQa,{'value': 'Multi-Objective Causal Bayesian Optimization'},Shriya Bhatija; Paul-David Zuercher; Jakob Thumm; Thomas Bohné,~Shriya_Bhatija1; ~Paul-David_Zuercher1; ~Jakob_Thumm1; ~Thomas_Bohné1,"{'value': ['Causality', 'Multi-Objective Bayesian Optimisation']}","{'value': 'In decision-making problems, the outcome of an intervention often depends on the causal relationships between system components and is highly costly to evaluate. In such settings, causal Bayesian optimization (CBO) exploits the causal relationships between the system variables and sequentially performs interventions to approach the optimum with minimal data. Extending CBO to the multi-outcome setting, we propose *multi-objective Causal Bayesian optimization* (MO-CBO), a paradigm for identifying Pareto-optimal interventions within a known multi-target causal graph. Our methodology first reduces the search space by discarding sub-optimal interventions based on the structure of the given causal graph. We further show that any MO-CBO problem can be decomposed into several traditional multi-objective optimization tasks. Our proposed MO-CBO algorithm is designed to identify Pareto-optimal interventions by iteratively exploring these underlying tasks, guided by relative hypervolume improvement. Experiments on synthetic and real-world causal graphs demonstrate the superiority of our approach over non-causal multi-objective Bayesian optimization in settings where causal information is available.'}",https://openreview.net{'value': '/pdf/add732701f1f6e4a3653d260db44c3268ecd650d.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=s7HUJamWqX,{'value': 'Agent Reviewers: Domain-specific Multimodal Agents with Shared Memory for Paper Review'},Kai Lu; Shixiong Xu; Jinqiu Li; Kun Ding; Gaofeng Meng,~Kai_Lu11; ~Shixiong_Xu3; ~Jinqiu_Li1; ~Kun_Ding2; ~Gaofeng_Meng1,{'value': ['Peer Review Automation; Multimodal Review System; Multi-agent System; Shared Memory Pool;']},"{'value': ""Feedback from peer review is essential to improve the quality of scientific articles. However, at present, many manuscripts do not receive sufficient external feedback for refinement before or during submission. Therefore, a system capable of providing detailed and professional feedback is crucial for enhancing research efficiency. In this paper, we have compiled the largest dataset of paper reviews to date by collecting historical open-access papers and their corresponding review comments and standardizing them using LLM. We then developed a multi-agent system that mimics real human review processes, based on LLMs. This system, named Agent Reviewers, includes the innovative introduction of multimodal reviewers to provide feedback on the visual elements of papers. Additionally, a shared memory pool that stores historical papers' metadata is preserved, which supplies reviewer agents with background knowledge from different fields. Our system is evaluated using ICLR 2024 papers and achieves superior performance compared to existing AI-based review systems. Comprehensive ablation studies further demonstrate the effectiveness of each module and agent in this system.""}",https://openreview.net{'value': '/pdf/2294c4a695dd37359e55a4596e6f2ab9b5ac44b2.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=s015m2jUGg,{'value': 'Efficient Diffusion Models for Symmetric Manifolds'},Oren Mangoubi; Neil He; Nisheeth K. Vishnoi,~Oren_Mangoubi1; ~Neil_He1; ~Nisheeth_K._Vishnoi2,"{'value': ['Diffusion Models', 'Symmetric Manifolds', 'Random Matrix Theory', 'Score-Based Generative Models', 'Efficient Sampling']}","{'value': 'We introduce a framework for designing efficient diffusion models for $d$-dimensional symmetric-space Riemannian manifolds, including the torus, sphere,  special orthogonal group and unitary group. Existing manifold diffusion models often depend on heat kernels, which lack closed-form expressions and require either $d$ gradient evaluations or exponential-in-$d$ arithmetic operations per training step. We introduce a new diffusion model for symmetric manifolds with a spatially-varying covariance, allowing us to leverage a projection of Euclidean Brownian motion to bypass heat kernel computations. Our training algorithm minimizes a novel efficient objective derived via Ito\'s Lemma, allowing each step to run in $O(1)$ gradient evaluations and nearly-linear-in-$d$ ($O(d^{1.19})$) *arithmetic* operations, reducing the gap between diffusions on symmetric manifolds and Euclidean space. Manifold symmetries ensure the diffusion satisfies an ""average-case"" Lipschitz condition, enabling accurate and efficient sample generation. Empirically, our model outperforms prior methods in training speed and improves sample quality on synthetic datasets on the torus, special orthogonal group, and unitary group.'}",https://openreview.net{'value': '/pdf/45118cfac0be65a5348c9ccbb4a64d7dfaa81ebb.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=rkwXYSDKso,{'value': 'Can Compressed LLMs Truly Act? An Empirical Evaluation of Agentic Capabilities in LLM Compression'},Peijie Dong; Zhenheng Tang; Xiang Liu; Lujun Li; Xiaowen Chu; Bo Li,~Peijie_Dong1; ~Zhenheng_Tang2; ~Xiang_Liu10; ~Lujun_Li1; ~Xiaowen_Chu2; ~Bo_Li33,"{'value': ['Agent', 'LLM', 'Quantization', 'Pruning']}","{'value': ""Post-training compression reduces the computational and memory costs of large language models (LLMs), enabling resource-efficient deployment. However, existing compression benchmarks focus narrowly on language modeling (e.g., perplexity) and natural language understanding tasks (e.g., GLUE accuracy), ignoring the agentic capabilities—workflow, tool use/function call, long-context understanding and real-world application. We introduce the Agent Compression Benchmark (ACBench), the first comprehensive benchmark for evaluating how compression impacts LLMs' agentic abilities. ACBench spans (1) 12 tasks across 4 capabilities (e.g., WorfBench for workflow generation, Needle-in-Haystack for long-context retrieval), (2) 4-bit quantization (GPTQ, AWQ) and 50% pruning (Wanda, SparseGPT), and (3) 15 models, including small (Gemma-2B), standard (Qwen2.5-7B), and distilled reasoning LLMs (DeepSeek-R1-Distill). Our experiments reveal compression tradeoffs: 4-bit quantization preserves workflow generation and tool use (1%--3% drop) but degrades real-world application accuracy by 10%--15%. We introduce ERank, Top-k Ranking Correlation and Energy to systematize analysis. ACBench provides actionable insights for optimizing LLM compression in agentic scenarios, bridging the gap between algorithmic efficiency and real-world applicability.""}",https://openreview.net{'value': '/pdf/b3a4b8fbc846757b6e3fd02e54880bec9d6a7720.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=riYSkLG0vt,{'value': 'One Diffusion Step to Real-World Super-Resolution via Flow Trajectory Distillation'},Jianze Li; Jiezhang Cao; Yong Guo; Wenbo Li; Yulun Zhang,~Jianze_Li2; ~Jiezhang_Cao2; ~Yong_Guo1; ~Wenbo_Li6; ~Yulun_Zhang1,"{'value': ['One step Diffusion', 'FLUX.1-dev', 'flow matching models', 'Image Super Resolution']}","{'value': 'Diffusion models (DMs) have significantly advanced the development of real-world image super-resolution (Real-ISR), but the computational cost of multi-step diffusion models limits their application. One-step diffusion models generate high-quality images in a one sampling step, greatly reducing computational overhead and inference latency. However, most existing one-step diffusion methods are constrained by the performance of the teacher model, where poor teacher performance results in image artifacts. To address this limitation, we propose FluxSR, a novel one-step diffusion Real-ISR technique based on flow matching models. We use the state-of-the-art diffusion model FLUX.1-dev as both the teacher model and the base model. First, we introduce Flow Trajectory Distillation (FTD) to distill a multi-step flow matching model into a one-step Real-ISR. Second, to improve image realism and address high-frequency artifact issues in generated images, we propose TV-LPIPS as a perceptual loss and introduce Attention Diversification Loss (ADL) as a regularization term to reduce token similarity in transformer, thereby eliminating high-frequency artifacts. Comprehensive experiments demonstrate that our method outperforms existing one-step diffusion-based Real-ISR methods. The code and model will be released at \\url{https://github.com/JianzeLi-114/FluxSR}.'}",https://openreview.net{'value': '/pdf/ec754c97f376a167ccfc4b019fb7a787bdab442a.pdf'},{'title_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=reuPtSzCU9,{'value': 'Generalizing from SIMPLE to HARD Visual Reasoning: Can We Mitigate Modality Imbalance in VLMs?'},Simon Park; Abhishek Panigrahi; Yun Cheng; Dingli Yu; Anirudh Goyal; Sanjeev Arora,~Simon_Park1; ~Abhishek_Panigrahi1; ~Yun_Cheng2; ~Dingli_Yu1; ~Anirudh_Goyal1; ~Sanjeev_Arora1,"{'value': ['vision language models', 'modality imbalance', 'SIMPLE-to-HARD generalization', 'gradient alignment']}","{'value': 'Vision Language Models (VLMs) are impressive at visual question answering and image captioning. But they underperform on multi-step visual reasoning---even compared to LLMs on the same tasks presented in text form---giving rise to perceptions of *modality imbalance* or *brittleness*. Towards a systematic study of such issues, we introduce a synthetic framework for assessing the ability of VLMs to perform algorithmic visual reasoning, comprising three tasks: Table Readout, Grid Navigation, and Visual Analogy. Each has two levels of difficulty, SIMPLE and HARD, and even the SIMPLE versions are difficult for frontier VLMs. We propose strategies for training on the SIMPLE version of tasks that improve performance on the corresponding HARD task, i.e., simple-to-hard (S2H) generalization. This controlled setup, where each task also has an equivalent text-only version, allows a quantification of the modality imbalance and how it is impacted by training strategy. We show that 1) explicit image-to-text conversion is important in promoting S2H generalization on images, by transferring reasoning from text; 2) conversion can be internalized at test time. We also report results of mechanistic study of this phenomenon. We identify measures of gradient alignment that can identify training strategies that promote better S2H generalization. Ablations highlight the importance of chain-of-thought.'}",https://openreview.net{'value': '/pdf/fc6b12c874629726ab5c59c3ba7724e782e11ad7.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=rdeDanrYEj,{'value': 'MoRAgent: Parameter Efficient Agent Tuning with Mixture-of-Roles'},Jing Han; Binwei Yan; Tianyu Guo; Zheyuan Bai; Mengyu Zheng; Hanting Chen; Ying Nie,~Jing_Han6; ~Binwei_Yan1; ~Tianyu_Guo1; ~Zheyuan_Bai2; ~Mengyu_Zheng1; ~Hanting_Chen1; ~Ying_Nie1,"{'value': ['LLMs', 'Agent', 'Mixture-of-Roles']}","{'value': ""Despite recent advancements of fine-tuning large language models (LLMs) to facilitate agent tasks, parameter-efficient fine-tuning (PEFT) methodologies for agent remain largely unexplored. In this paper, we introduce three key strategies for PEFT in agent tasks: 1) Inspired by the increasingly dominant \\textit{Reason+Action} paradigm, we first decompose the capabilities necessary for the agent tasks into three distinct roles: reasoner, executor, and summarizer. The reasoner is responsible for comprehending the user's query and determining the next role based on the execution trajectory. The executor is tasked with identifying the appropriate functions and parameters to invoke. The summarizer conveys the distilled information from conversations back to the user. 2) We then propose the Mixture-of-Roles (MoR) framework, which comprises three specialized Low-Rank Adaptation (LoRA) groups, each designated to fulfill a distinct role. By focusing on their respective specialized capabilities and engaging in collaborative interactions, these LoRAs collectively accomplish the agent task. 3) To effectively fine-tune the framework, we develop a multi-role data generation pipeline based on publicly available datasets, incorporating role-specific content completion and reliability verification.\nWe conduct extensive experiments and thorough ablation studies on various LLMs and agent benchmarks, demonstrating the effectiveness of the proposed method. This project is publicly available at https://mor-agent.github.io""}",https://openreview.net{'value': '/pdf/dd65c44d51e23d2ebe9deebc16a94ae249098e5a.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=rYiSEOEE0p,{'value': 'Towards the Efficient Inference by Incorporating Automated Computational Phenotypes under Covariate Shift'},chao ying; Jun Jin; Yi Guo; Xiudi Li; Muxuan Liang; Jiwei Zhao,~chao_ying1; ~Jun_Jin2; ~Yi_Guo15; ~Xiudi_Li1; ~Muxuan_Liang1; ~Jiwei_Zhao1,"{'value': ['semi-supervised learning', 'covariate shift', 'automated computational phenotype', 'efficiency gain']}","{'value': 'Collecting gold-standard phenotype data via manual extraction is typically labor-intensive and slow, whereas automated computational phenotypes (ACPs) offer a systematic and much faster alternative.\nHowever, simply replacing the gold-standard with ACPs, without acknowledging their differences, could lead to biased results and misleading conclusions.\nMotivated by the complexity of incorporating ACPs while maintaining the validity of downstream analyses, in this paper, we consider a semi-supervised learning setting that consists of both labeled data (with gold-standard) and unlabeled data (without gold-standard), under the covariate shift framework.\nWe develop doubly robust and semiparametrically efficient estimators that leverage ACPs for general target parameters in the unlabeled and combined populations. In addition,\nwe carefully analyze the efficiency gains achieved by incorporating ACPs, comparing scenarios with and without their inclusion.\nNotably, we identify that ACPs for the unlabeled data, instead of for the labeled data, drive the enhanced efficiency gains. To validate our theoretical findings, we conduct comprehensive synthetic experiments and apply our method to multiple real-world datasets, confirming the practical advantages of our approach.'}",https://openreview.net{'value': '/pdf/e5b93c947dbe890e0621c60fe21d4bd7643632b4.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=qr4a4uS82y,{'value': 'Policy Design for Two-sided Platforms with Participation Dynamics'},Haruka Kiyohara; Fan Yao; Sarah Dean,~Haruka_Kiyohara1; ~Fan_Yao2; ~Sarah_Dean2,"{'value': ['two-sided platforms', 'provider-fairness', 'bandits', 'population dynamics']}","{'value': 'In two-sided platforms (e.g., video streaming or e-commerce), viewers and providers engage in interactive dynamics: viewers benefit from increases in provider populations, while providers benefit from increases in viewer population. Despite the importance of such “population effects” on long-term platform health, recommendation policies do not generally take the participation dynamics into account. This paper thus studies the dynamics and recommender policy design on two-sided platforms under the population effects for the first time. Our control- and game-theoretic findings warn against the use of the standard “myopic-greedy” policy and shed light on the importance of provider-side considerations (i.e., effectively distributing exposure among provider groups) to improve social welfare via population growth. We also present a simple algorithm to optimize long-term social welfare by taking the population effects into account, and demonstrate its effectiveness in synthetic and real-data experiments. Our experiment code is available at https://github.com/sdean-group/dynamics-two-sided-market.'}",https://openreview.net{'value': '/pdf/db5f83955e1565c8fabc80d5d76e45e0db90b2e1.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=qpi7NiaCYj,{'value': 'Direct Motion Models for Assessing Generated Videos'},Kelsey R Allen; Carl Doersch; Guangyao Zhou; Mohammed Suhail; Danny Driess; Ignacio Rocco; Yulia Rubanova; Thomas Kipf; Mehdi S. M. Sajjadi; Kevin Patrick Murphy; Joao Carreira; Sjoerd van Steenkiste,~Kelsey_R_Allen1; ~Carl_Doersch1; ~Guangyao_Zhou1; ~Mohammed_Suhail1; ~Danny_Driess1; ~Ignacio_Rocco1; ~Yulia_Rubanova2; ~Thomas_Kipf2; ~Mehdi_S._M._Sajjadi1; ~Kevin_Patrick_Murphy1; ~Joao_Carreira1; ~Sjoerd_van_Steenkiste1,"{'value': ['metrics', 'videos', 'motion', 'point tracking']}","{'value': 'A current limitation of video generative video models is that they generate plausible looking frames, but poor motion --- an issue that is not well captured by FVD and other popular methods for evaluating generated videos. Here we go beyond FVD by developing a metric which better measures plausible object interactions and motion. Our novel approach is based on auto-encoding point tracks and yields motion features that can be used to not only compare distributions of videos (as few as one generated and one ground truth, or as many as two datasets), but also for evaluating motion of single videos. We show that using point tracks instead of pixel reconstruction or action recognition features results in a metric which is markedly more sensitive to temporal distortions in synthetic data, and can predict human evaluations of temporal consistency and realism in generated videos obtained from open-source models better than a wide range of alternatives. We also show that by using a point track representation, we can spatiotemporally localize generative video inconsistencies, providing extra interpretability of generated video errors relative to prior work. An overview of the results and link to the code can be found on the project page: trajan-paper.github.io.'}",https://openreview.net{'value': '/pdf/f4efdf1ce6c21aaaf71273492b5b6f14bb549943.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=qnE2m3pIAb,{'value': 'Automated Benchmark Generation for Repository-Level Coding Tasks'},Konstantinos Vergopoulos; Mark Niklas Mueller; Martin Vechev,~Konstantinos_Vergopoulos2; ~Mark_Niklas_Mueller2; ~Martin_Vechev1,"{'value': ['Code Agents', 'Benchmark Generation', 'Coding Benchmark', 'Large Language Models']}","{'value': ""Code Agent development is an extremely active research area, where a reliable performance metric is critical for tracking progress and guiding new developments. This demand is underscored by the meteoric rise in popularity of SWE-Bench -- a benchmark that challenges code agents to generate patches addressing GitHub issues given the full repository as context. The correctness of generated patches is then evaluated by executing a human-written test suite extracted from the repository after the issue's resolution.\n\nHowever, constructing benchmarks like SWE-Bench requires substantial manual effort to set up historically accurate execution environments for testing. Crucially, this severely limits the number of considered repositories, e.g., just 12 for SWE-Bench. Considering so few repositories, selected for their popularity runs the risk of leading to a distributional mismatch, i.e., the measured performance may not be representative of real-world scenarios running the riks of misguiding development efforts. \n\nIn this work, we address this challenge and introduce SetUpAgent, a fully automated system capable of historically accurate dependency setup, test execution, and result parsing. Using SetUpAgent, we generate two new datasets: (i) SWEE-Bench an extended version of SWE-Bench encompassing hundreds of repositories, and (ii) SWA-Bench a benchmark focusing on applications rather than libraries. Comparing these datasets to SWE-Bench with respect to their characteristics and code agent performance, we find significant distributional differences, including lower issue description quality and detail level, higher fix complexity, and most importantly up to 60% lower agent success rates.""}",https://openreview.net{'value': '/pdf/53dd5935c42f65f596554c48761621c07da72c09.pdf'},{'abstract_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=qdKzBrYhiu,{'value': 'Telling Peer Direct Effects from Indirect Effects in Observational Network Data'},Xiaojing Du; Jiuyong Li; Debo Cheng; Lin Liu; Wentao Gao; XIONGREN CHEN; Ziqi Xu,~Xiaojing_Du1; ~Jiuyong_Li1; ~Debo_Cheng1; ~Lin_Liu4; ~Wentao_Gao1; ~XIONGREN_CHEN1; ~Ziqi_Xu1,"{'value': ['Estimate Causal Effects', 'Peer Effects', 'Causal Mediation Analysis', 'Graph Neural Networks']}","{'value': ""Estimating causal effects is crucial for decision-makers in many applications, but it is particularly challenging with observational network data due to peer interactions. Some algorithms have been proposed to estimate causal effects involving network data, particularly peer effects, but they often fail to tell apart diverse peer effects. To address this issue, we propose a general setting which considers both peer direct effects and peer indirect effects, and the effect of an individual's own treatment, and provide the identification conditions of these causal effects. To differentiate these effects, we leverage causal mediation analysis and tailor it specifically for network data. Furthermore, given the inherent challenges of accurately estimating effects in networked environments, we propose to incorporate attention mechanisms to capture the varying influences of different neighbors and to explore high-order neighbor effects using multi-layer graph neural networks (GNNs). Additionally, we employ the Hilbert-Schmidt Independence Criterion (HSIC) to further enhance the model’s robustness and accuracy. Extensive experiments on two semi-synthetic datasets derived from real-world networks and on a dataset from a recommendation system confirm the effectiveness of our approach. Our findings have the potential to improve intervention strategies in networked systems, particularly in social networks and public health.""}",https://openreview.net{'value': '/pdf/dbaea094662cc8e5c73dc0171df02fbfdd151f8f.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=qZMLrURRr9,{'value': 'R*: Efficient Reward Design via Reward Structure Evolution and Parameter Alignment Optimization with Large Language Models'},Pengyi Li; Jianye HAO; Hongyao Tang; Yifu Yuan; Jinbin Qiao; Zibin Dong; YAN ZHENG,~Pengyi_Li1; ~Jianye_HAO1; ~Hongyao_Tang1; ~Yifu_Yuan1; ~Jinbin_Qiao1; ~Zibin_Dong1; ~YAN_ZHENG1,"{'value': ['Reward Design', 'Reinforcement Learning']}","{'value': 'Reward functions are crucial for policy learning. Large Language Models (LLMs), with strong coding capabilities and valuable domain knowledge, provide an automated solution for high-quality reward design. \nHowever, \ncode-based reward functions require precise guiding logic and parameter configurations within a vast design space, leading to low optimization efficiency.\nTo address the challenges,\nwe propose an efficient automated reward design framework, called R*,\nwhich decomposes reward design into two parts: reward structure evolution and parameter alignment optimization. To design high-quality reward structures, R* maintains a reward function population and modularizes the functional components. LLMs are employed as the mutation operator, and module-level crossover is proposed to facilitate efficient exploration and exploitation.\nTo design more efficient reward parameters, R* first leverages LLMs to generate multiple critic functions for trajectory comparison and annotation. Based on these critics, a voting mechanism is employed to collect the trajectory segments with high-confidence labels.\nThese labeled segments are then used to refine the reward function parameters through preference learning.\nExperiments on diverse robotic control tasks demonstrate that R* outperforms strong baselines in both reward design efficiency and quality, surpassing human-designed reward functions.'}",https://openreview.net{'value': '/pdf/f4dcdc12830796dc486af237f226b1ebeaaac6b6.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=qQBzVFwtPN,{'value': 'Adaptive Sample Sharing for Multi Agent Linear Bandits'},Hamza Cherkaoui; Merwan Barlier; Igor Colin,~Hamza_Cherkaoui1; ~Merwan_Barlier1; ~Igor_Colin1,"{'value': ['linear bandit', 'collaboration', 'sample sharing']}","{'value': ""The multi-agent linear bandit setting is a well-known setting for which designing efficient collaboration between agents remains challenging. This paper studies the impact of data sharing among agents on regret minimization. Unlike most existing approaches, our contribution does not rely on any assumptions on the bandit parameters structure. Our main result formalizes the trade-off between the bias and uncertainty of the bandit parameter estimation for efficient collaboration. This result is the cornerstone of the Bandit Adaptive Sample Sharing (BASS) algorithm, whose efficiency over the current state-of-the-art is validated through both theoretical analysis and empirical evaluations on both synthetic and real-world datasets. Furthermore, we demonstrate that, when agents' parameters display a cluster structure, our algorithm accurately recovers them.""}",https://openreview.net{'value': '/pdf/222a7e502b088afc791e67771b37515b14aeea45.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=qOgKMqv9T7,{'value': 'TIMING: Temporality-Aware Integrated Gradients for Time Series Explanation'},Hyeongwon Jang; Changhun Kim; Eunho Yang,~Hyeongwon_Jang1; ~Changhun_Kim1; ~Eunho_Yang1,"{'value': ['Time Series', 'XAI', 'Explainability']}","{'value': 'Recent explainable artificial intelligence (XAI) methods for time series primarily estimate point-wise attribution magnitudes, while overlooking the directional impact on predictions, leading to suboptimal identification of significant points. Our analysis shows that conventional Integrated Gradients (IG) effectively capture critical points with both positive and negative impacts on predictions. However, current evaluation metrics fail to assess this capability, as they inadvertently cancel out opposing feature contributions. To address this limitation, we propose novel evaluation metrics—Cumulative Prediction Difference (CPD) and Cumulative Prediction Preservation\n(CPP)—to systematically assess whether attribution methods accurately identify significant positive and negative points in time series XAI. Under these metrics, conventional IG outperforms recent counterparts. However, directly applying IG to time series data may lead to suboptimal outcomes, as generated paths ignore temporal relationships and introduce out-of-distribution samples. To overcome these challenges, we introduce TIMING, which enhances IG by incorporating temporal awareness while maintaining its theoretical properties. Extensive experiments on synthetic and real-world time series benchmarks demonstrate that TIMING outperforms existing time\nseries XAI baselines. Our code is available at https://github.com/drumpt/TIMING.'}",https://openreview.net{'value': '/pdf/0954dcf01dc5530aa1bb6655b8819ca54c401844.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=qA3xHJzF6B,{'value': 'A Causal World Model Underlying Next Token Prediction: Exploring GPT in a Controlled Environment'},Raanan Yehezkel Rohekar; Yaniv Gurwicz; Sungduk Yu; Estelle Aflalo; Vasudev Lal,~Raanan_Yehezkel_Rohekar1; ~Yaniv_Gurwicz1; ~Sungduk_Yu1; ~Estelle_Aflalo1; ~Vasudev_Lal1,"{'value': ['structural causal model', 'causal reasoning', 'GPT', 'mechanistic interpretability', 'explainable AI', 'causal discovery']}","{'value': 'Are generative pre-trained transformer (GPT) models, trained only to predict the next token, implicitly learning a world model from which sequences are generated one token at a time? We address this question by deriving a causal interpretation of the attention mechanism in GPT and presenting a causal world model that arises from this interpretation. Furthermore, we propose that GPT models, at inference time, can be utilized for zero-shot causal structure learning for input sequences, and introduce a corresponding confidence score. Empirical tests were conducted in controlled environments using the setups of the Othello and Chess strategy games. A GPT, pre-trained on real-world games played with the intention of winning, was tested on out-of-distribution synthetic data consisting of sequences of random legal moves. We find that the GPT model is likely to generate legal next moves for out-of-distribution sequences for which a causal structure is encoded in the attention mechanism with high confidence. In cases where it generates illegal moves, it also fails to capture a causal structure.'}",https://openreview.net{'value': '/pdf/8bd958b5c0a6cc61570d2576722ee286642876be.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=q9lITFNKds,{'value': 'Zero-shot Meta-learning for Tabular Prediction Tasks with Adversarially Pre-trained Transformer'},Yulun Wu; Doron L Bergman,~Yulun_Wu1; ~Doron_L_Bergman1,"{'value': ['zero-shot', 'meta-learning', 'adversarial training', 'tabular deep learning', 'bayesian inference', 'in-context learning']}","{'value': ""We present an Adversarially Pre-trained Transformer (APT) that is able to perform zero-shot meta-learning on tabular prediction tasks without using any real-world dataset to pre-train the model, extending on the recent development of Prior-Data Fitted Networks (PFNs) and TabPFN. Specifically, APT is pre-trained with adversarial synthetic data agents, who continue to shift their underlying data generating distribution and deliberately challenge the model with different synthetic datasets. In addition, we propose a mixture block model architecture that is able to handle classification tasks with arbitrary number of classes, addressing the class size limitation -- a crucial weakness of prior tabular zero-shot learning algorithms. In experiments, we show that our framework matches state-of-the-art performance on small tabular classification tasks without filtering on dataset characteristics such as number of classes and number of missing values, while maintaining an average runtime under one second. On common benchmark dataset suites in both classification and regression, we show that adversarial pre-training was able to enhance TabPFN's performance. In our analysis, we demonstrate that the adversarial synthetic data agents were able to generate a more diverse collection of data compared to the ordinary random generator in TabPFN. In addition, we demonstrate that our mixture block neural design has improved generalizability and greatly accelerated pre-training.""}",https://openreview.net{'value': '/pdf/e6815ef58ca8e275792dfe72fd41f16b70870889.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=q7PAIE0z5p,{'value': 'Discrepancies are Virtue: Weak-to-Strong Generalization through Lens of Intrinsic Dimension'},Yijun Dong; Yicheng Li; Yunai Li; Jason D. Lee; Qi Lei,~Yijun_Dong1; ~Yicheng_Li6; ~Yunai_Li1; ~Jason_D._Lee1; ~Qi_Lei1,"{'value': ['Weak-to-Strong generalization', 'Intrinsic dimension', 'Finetuning']}","{'value': 'Weak-to-strong (W2S) generalization is a type of finetuning (FT) where a strong (large) student model is trained on pseudo-labels generated by a weak teacher. Surprisingly, W2S FT often outperforms the weak teacher. We seek to understand this phenomenon through the observation that FT often occurs in intrinsically low-dimensional spaces. Leveraging the low intrinsic dimensionality of FT, we analyze W2S in the ridgeless regression setting from a variance reduction perspective. For a strong student-weak teacher pair with sufficiently expressive low-dimensional feature subspaces $\\mathcal{V}_s, \\mathcal{V}_w$, we provide an exact characterization of the variance that dominates the generalization error of W2S. This unveils a virtue of discrepancy between the strong and weak models in W2S: the variance of the weak teacher is inherited by the strong student in $\\mathcal{V}_s \\cap \\mathcal{V}_w$, while reduced by a factor of $\\mathrm{dim}(\\mathcal{V}_s)/N$ in the subspace of discrepancy $\\mathcal{V}_w \\setminus \\mathcal{V}_s$ with $N$ pseudo-labels for W2S. Our analysis further casts light on the sample complexities and the scaling of performance gap recovery in W2S. The analysis is supported by experiments on synthetic regression problems, as well as real vision and NLP tasks.'}",https://openreview.net{'value': '/pdf/e242b3492a18076d0afacb3ae6a8f0b29b4aba38.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=q6aopfT2d5,{'value': 'Finite-Time Convergence Rates in Stochastic Stackelberg Games with Smooth Algorithmic Agents'},Eric Frankel; Kshitij Kulkarni; Dmitriy Drusvyatskiy; Sewoong Oh; Lillian J. Ratliff,~Eric_Frankel1; ~Kshitij_Kulkarni2; ~Dmitriy_Drusvyatskiy1; ~Sewoong_Oh3; ~Lillian_J._Ratliff1,"{'value': ['Stackelberg game', 'stochastic optimization', 'learning and games', 'stochastic tracking']}","{'value': ""Decision-makers often adaptively influence downstream competitive agents' behavior to minimize their cost, yet in doing so face critical challenges:  $(i)$ decision-makers might not *a priori* know the agents' objectives; $(ii)$ agents might *learn* their responses, introducing stochasticity and non-stationarity into the decision-making process; and $(iii)$ there may be additional non-strategic environmental stochasticity. \nCharacterizing convergence of this complex system is contingent on how the decision-maker controls for the tradeoff between the induced drift and additional noise from the learning agent behavior and environmental stochasticity. To understand how the learning agents' behavior is influenced by the decision-maker’s actions, we first consider a decision-maker that deploys an arbitrary sequence of actions which induces a sequence of games and corresponding equilibria.   We characterize how the drift and noise in the agents' stochastic algorithms decouples from their optimization error. Leveraging this decoupling and accompanying finite-time efficiency estimates, we design decision-maker algorithms that control the induced drift relative to the agent noise. This enables efficient finite-time tracking of game theoretic equilibrium concepts that adhere to the incentives of the players' collective learning processes.""}",https://openreview.net{'value': '/pdf/458b8e35502fc2a8fff2787df9e3bbb63cf299e2.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=q2pjlx1OeX,{'value': 'Of Mice and Machines: A Comparison of Learning Between Real World Mice and RL Agents'},Shuo Han; German Espinosa; Junda Huang; Daniel Dombeck; Malcolm A. MacIver; Bradly C. Stadie,~Shuo_Han8; ~German_Espinosa1; ~Junda_Huang4; ~Daniel_Dombeck1; ~Malcolm_A._MacIver1; ~Bradly_C._Stadie1,"{'value': ['Reinforcement learning', 'Biological agents', 'Comparative study', 'Variance-penalized temporal difference learning', 'Experience replay', 'Behavioral alignment']}","{'value': ""Recent advances in reinforcement learning (RL) have demonstrated impressive capabilities in complex decision-making tasks. This progress raises a natural question: how do these artificial systems compare to biological agents, which have been shaped by millions of years of evolution? To help answer this question, we undertake a comparative study of biological mice and RL agents in a predator-avoidance maze environment. Through this analysis, we identify a striking disparity: RL agents consistently demonstrate a lack of self-preservation instinct, readily risking ``death'' for marginal efficiency gains. These risk-taking strategies are in contrast to biological agents, which exhibit sophisticated risk-assessment and avoidance behaviors. Towards bridging this gap between the biological and artificial, we propose two novel mechanisms that encourage more naturalistic risk-avoidance behaviors in RL agents. Our approach leads to the emergence of naturalistic behaviors, including strategic environment assessment, cautious path planning, and predator avoidance patterns that closely mirror those observed in biological systems.""}",https://openreview.net{'value': '/pdf/7f3b778ac8cb1b888eefa0d6ad00e2f14d3e70b4.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=perpuTFEF7,{'value': 'Leveraging Skills from Unlabeled Prior Data for Efficient Online Exploration'},Max Wilcoxson; Qiyang Li; Kevin Frans; Sergey Levine,~Max_Wilcoxson1; ~Qiyang_Li1; ~Kevin_Frans1; ~Sergey_Levine1,"{'value': ['Offline-to-online RL', 'Unsupervised Pre-training', 'Exploration']}","{'value': 'Unsupervised pretraining has been transformative in many supervised domains. However, applying such ideas to reinforcement learning (RL) presents a unique challenge in that fine-tuning does not involve mimicking task-specific data, but rather exploring and locating the solution through iterative self-improvement. In this work, we study how unlabeled offline trajectory data can be leveraged to learn efficient exploration strategies. While prior data can be used to pretrain a set of low-level skills, or as additional off-policy data for online RL, it has been unclear how to combine these ideas effectively for online exploration. Our method SUPE (Skills from Unlabeled Prior data for Exploration) demonstrates that a careful combination of these ideas compounds their benefits. Our method first extracts low-level skills using a variational autoencoder (VAE), and then pseudo-labels unlabeled trajectories with optimistic rewards and high-level action labels, transforming prior data into high-level, task-relevant examples that encourage novelty-seeking behavior. Finally, SUPE uses these transformed examples as additional off-policy data for online RL to learn a high-level policy that composes pretrained low-level skills to explore efficiently. In our experiments, SUPE consistently outperforms prior strategies across a suite of 42 long-horizon, sparse-reward tasks.'}",https://openreview.net{'value': '/pdf/97cae7ac478683371e1f3940db21e7cfa16652ad.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=pekYL20W3n,{'value': 'When Data-Free Knowledge Distillation Meets Non-Transferable Teacher: Escaping Out-of-Distribution Trap is All You Need'},Ziming Hong; Runnan Chen; Zengmao Wang; Bo Han; Bo Du; Tongliang Liu,~Ziming_Hong1; ~Runnan_Chen1; ~Zengmao_Wang1; ~Bo_Han1; ~Bo_Du3; ~Tongliang_Liu1,"{'value': ['Data-free Knowledge Distillation', 'Non-Transferable Learning']}","{'value': ""Data-free knowledge distillation (DFKD) transfers knowledge from a teacher to a student without access the real in-distribution (ID) data. Its common solution is to use a generator to synthesize fake data and use them as a substitute for real ID data. However, existing works typically assume teachers are trustworthy, leaving the robustness and security of DFKD from untrusted teachers largely unexplored. In this work, we conduct the first investigation into distilling non-transferable learning (NTL) teachers using DFKD, where the transferability from an ID domain to an out-of-distribution (OOD) domain is prohibited. We find that NTL teachers fool DFKD through divert the generator's attention from the useful ID knowledge to the misleading OOD knowledge. This hinders ID knowledge transfer but prioritizes OOD knowledge transfer. To mitigate this issue, we propose Adversarial Trap Escaping (ATEsc) to benefit DFKD by identifying and filtering out OOD-like synthetic samples. Specifically, inspired by the evidence that NTL teachers show stronger adversarial robustness on OOD samples than ID samples, we split synthetic samples into two groups according to their robustness. The fragile group is treated as ID-like data and used for normal knowledge distillation, while the robust group is seen as OOD-like data and utilized for forgetting OOD knowledge. Extensive experiments demonstrate the effectiveness of ATEsc for improving DFKD against NTL teachers.""}",https://openreview.net{'value': '/pdf/ff3cfb3c57a6c14c83e3b2722dbf8291054aac9c.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=pdNtji3ktF,{'value': 'Divide and Conquer: Grounding LLMs as Efficient Decision-Making Agents via Offline Hierarchical Reinforcement Learning'},Zican Hu; Wei Liu; Xiaoye Qu; Xiangyu Yue; Chunlin Chen; Zhi Wang; Yu Cheng,~Zican_Hu1; ~Wei_Liu25; ~Xiaoye_Qu1; ~Xiangyu_Yue1; ~Chunlin_Chen1; ~Zhi_Wang7; ~Yu_Cheng1,"{'value': ['Language agents', 'Hierarchical reinforcement learning', 'Offline reinforcement learning']}","{'value': 'While showing sophisticated reasoning abilities, large language models (LLMs) still struggle with long-horizon decision-making tasks due to deficient exploration and long-term credit assignment, especially in sparse-reward scenarios. Inspired by the divide-and-conquer principle, we propose an innovative framework **GLIDER** (**G**rounding **L**anguage Models as Eff**I**cient **D**ecision-Making Agents via Offline Hi**E**rarchical **R**einforcement Learning) that introduces a parameter-efficient and generally applicable hierarchy to LLM policies. We develop a scheme where the low-level controller is supervised with abstract, step-by-step plans that are learned and instructed by the high-level policy. This design decomposes complicated problems into a series of coherent chain-of-thought reasoning sub-tasks, providing flexible temporal abstraction to significantly enhance exploration and learning for long-horizon tasks. Furthermore, GLIDER facilitates fast online adaptation to non-stationary environments owing to the strong transferability of its task-agnostic low-level skills. Experiments on ScienceWorld and ALFWorld benchmarks show that GLIDER achieves consistent performance gains, along with enhanced generalization capabilities.'}",https://openreview.net{'value': '/pdf/32625ed6ccde1fe152f5b6854372f3ad6934b566.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=pUCYJ9JJuZ,{'value': 'Behavior-Regularized Diffusion Policy Optimization for Offline Reinforcement Learning'},Chen-Xiao Gao; Chenyang Wu; Mingjun Cao; Chenjun Xiao; Yang Yu; Zongzhang Zhang,~Chen-Xiao_Gao1; ~Chenyang_Wu1; ~Mingjun_Cao1; ~Chenjun_Xiao1; ~Yang_Yu5; ~Zongzhang_Zhang1,"{'value': ['Behavior-regularized Reinforcement Learning', 'Diffusion Policy', 'Offline Reinforcement Learning']}","{'value': 'Behavior regularization, which constrains the policy to stay close to some behavior policy, is widely used in offline reinforcement learning (RL) to manage the risk of hazardous exploitation of unseen actions. Nevertheless, existing literature on behavior-regularized RL primarily focuses on explicit policy parameterizations, such as Gaussian policies. Consequently, it remains unclear how to extend this framework to more advanced policy parameterizations, such as diffusion models. In this paper, we introduce BDPO, a principled behavior-regularized RL framework tailored for diffusion-based policies, thereby combining the expressive power of diffusion policies and the robustness provided by regularization. The key ingredient of our method is to calculate the Kullback-Leibler (KL) regularization analytically as the accumulated discrepancies in reverse-time transition kernels along the diffusion trajectory. By integrating the regularization, we develop an efficient two-time-scale actor-critic RL algorithm that produces the optimal policy while respecting the behavior constraint. Comprehensive evaluations conducted on synthetic 2D tasks and continuous control tasks from the D4RL benchmark validate its effectiveness and superior performance.'}",https://openreview.net{'value': '/pdf/e25038885cd2d26e6b3307d4d9e3b812fcfca2de.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=pRmxQHgjb1,{'value': 'UDora: A Unified Red Teaming Framework against LLM Agents by Dynamically Hijacking Their Own Reasoning'},Jiawei Zhang; Shuang Yang; Bo Li,~Jiawei_Zhang9; ~Shuang_Yang5; ~Bo_Li19,{'value': ['adversarial attack; llm agent; jailbreak; reasoning and acting']},"{'value': ""Large Language Model (LLM) agents equipped with external tools have become increasingly powerful for complex tasks such as web shopping, automated email replies, and financial trading. However, these advancements amplify the risks of adversarial attacks, especially when agents can access sensitive external functionalities. Nevertheless, manipulating LLM agents into performing targeted malicious actions or invoking specific tools remains challenging, as these agents extensively reason or plan before executing final actions. In this work, we present UDora, a unified red teaming framework designed for LLM agents that dynamically hijacks the agent's reasoning processes to compel malicious behavior. Specifically, UDora first generates the model’s reasoning trace for the given task, then automatically identifies optimal points within this trace to insert targeted perturbations. The resulting perturbed reasoning is then used as a surrogate response for optimization. By iteratively applying this process, the LLM agent will then be induced to undertake designated malicious actions or to invoke specific malicious tools. Our approach demonstrates superior effectiveness compared to existing methods across three LLM agent datasets. The code is available at https://github.com/AI-secure/UDora.""}",https://openreview.net{'value': '/pdf/1489f884ee66981b358bb3e08dcb5c1b74ebbf4f.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=pOAEfqa26i,{'value': 'Learning Time-Varying Multi-Region Brain Communications  via Scalable Markovian Gaussian Processes'},Weihan Li; Yule Wang; Chengrui Li; Anqi Wu,~Weihan_Li1; ~Yule_Wang1; ~Chengrui_Li1; ~Anqi_Wu3,{'value': ['Multiple Brain Region Communications; Markovian Gaussian Processes; State Space Model']},"{'value': 'Understanding and constructing brain communications that capture dynamic communications across multiple regions is fundamental to modern system neuroscience, yet current methods struggle to find time-varying region-level communications or scale to large neural datasets with long recording durations. We present a novel framework using Markovian Gaussian Processes to learn brain communications with time-varying temporal delays from multi-region neural recordings, named Adaptive Delay Model (ADM). Our method combines Gaussian Processes with State Space Models and employs parallel scan inference algorithms, enabling efficient scaling to large datasets while identifying concurrent  communication patterns that evolve over time. This time-varying approach captures how brain region interactions shift dynamically during cognitive processes. Validated on synthetic and multi-region neural recordings datasets, our approach discovers both the directionality and temporal dynamics of neural communication. This work advances our understanding of distributed neural computation and provides a scalable tool for analyzing dynamic brain networks.'}",https://openreview.net{'value': '/pdf/e3dbc98cfa1add1c1bf0dc2f1d23526c85ede717.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=pNyodFNPhv,{'value': 'Preconditioned Riemannian Gradient Descent Algorithm for Low-Multilinear-Rank Tensor Completion'},Yuanwei Zhang; Fengmiao Bian; Xiaoqun Zhang; Jian-Feng Cai,~Yuanwei_Zhang2; ~Fengmiao_Bian1; ~Xiaoqun_Zhang1; ~Jian-Feng_Cai4,"{'value': ['Tensor completion', 'Multilinear rank', 'Riemannian gradient descent', 'Preconditioning']}","{'value': 'Tensors play a crucial role in numerous scientific and engineering fields. This paper addresses the low-multilinear-rank tensor completion problem, a fundamental task in tensor-related applications. By exploiting the manifold structure inherent to the fixed-multilinear-rank tensor set, we introduce a simple yet highly effective preconditioned Riemannian metric and propose the Preconditioned Riemannian Gradient Descent (PRGD) algorithm. Compared to the standard Riemannian Gradient Descent (RGD), PRGD achieves faster convergence while maintaining the same order of per-iteration computational complexity. Theoretically, we provide the recovery guarantee for PRGD under near-optimal sampling complexity. Numerical results highlight the efficiency of PRGD, outperforming state-of-the-art methods on both synthetic data and real-world video inpainting tasks.'}",https://openreview.net{'value': '/pdf/6f0f66054aeebd5c2f21beb7e9fa06b2a482f28d.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=pL87Z7YTJS,{'value': 'Robust Reward Alignment via Hypothesis Space Batch Cutting'},Zhixian Xie; Haode Zhang; Yizhe Feng; Wanxin Jin,~Zhixian_Xie1; ~Haode_Zhang2; ~Yizhe_Feng1; ~Wanxin_Jin1,"{'value': ['Learning from Human Feedback', 'Inverse Reinforcement Learning', 'Preference Based Reinforcement Learning', 'Robust Learning']}","{'value': 'Reward design in reinforcement learning and optimal control is challenging. Preference-based alignment addresses this by enabling agents to learn rewards from ranked trajectory pairs provided by humans. However, existing methods often struggle from poor robustness to unknown false human preferences. In this work, we propose a robust and efficient reward alignment method based on a novel and geometrically interpretable perspective: hypothesis space batched cutting. Our method iteratively refines the reward hypothesis space through “cuts” based on batches of human preferences. Within each batch, human preferences, queried based on disagreement, are grouped using a voting function to determine the appropriate cut, ensuring a bounded human query complexity. To handle unknown erroneous preferences, we introduce a conservative cutting method within each batch, preventing erroneous human preferences from making overly aggressive cuts to the hypothesis space. This guarantees provable robustness against false preferences, while eliminating the need to explicitly identify them. We evaluate our method in a model predictive control setting across diverse tasks. The results demonstrate that our framework achieves comparable or superior performance to state-of-the-art methods in error-free settings while significantly outperforming existing methods when handling a high percentage of erroneous human preferences.'}",https://openreview.net{'value': '/pdf/12f3d4e988f01dd441d0a7a0a74b6fb79ccf3611.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=pKaNgFzJBy,{'value': 'On the Guidance of Flow Matching'},Ruiqi Feng; Chenglei Yu; Wenhao Deng; Peiyan Hu; Tailin Wu,~Ruiqi_Feng1; ~Chenglei_Yu1; ~Wenhao_Deng2; ~Peiyan_Hu1; ~Tailin_Wu1,"{'value': ['flow matching', 'guided generation', 'generative modeling']}","{'value': 'Flow matching has shown state-of-the-art performance in various generative tasks, ranging from image generation to decision-making, where generation under energy guidance (abbreviated as guidance in the following) is pivotal. However, the guidance of flow matching is more general than and thus substantially different from that of its predecessor, diffusion models. Therefore, the challenge in guidance for general flow matching remains largely underexplored. In this paper, we propose the first framework of general guidance for flow matching. From this framework, we derive a family of guidance techniques that can be applied to general flow matching. These include a new training-free asymptotically exact guidance, novel training losses for training-based guidance, and two classes of approximate guidance that cover classical gradient guidance methods as special cases. We theoretically investigate these different methods to give a practical guideline for choosing suitable methods in different scenarios. Experiments on synthetic datasets, image inverse problems, and offline reinforcement learning demonstrate the effectiveness of our proposed guidance methods and verify the correctness of our flow matching guidance framework. Code to reproduce the experiments can be found at https://github.com/AI4Science-WestlakeU/flow_guidance.'}",https://openreview.net{'value': '/pdf/e2dd444c9ee42a88cf224f105664c30f330cc158.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=p6PElhIM4E,{'value': 'Stealix: Model Stealing via Prompt Evolution'},Zhixiong Zhuang; Hui-Po Wang; Maria-Irina Nicolae; Mario Fritz,~Zhixiong_Zhuang1; ~Hui-Po_Wang1; ~Maria-Irina_Nicolae1; ~Mario_Fritz1,"{'value': ['model stealing', 'security', 'genetic algorithm', 'prompt optimization']}","{'value': 'Model stealing poses a significant security risk in machine learning by enabling attackers to replicate a black-box model without access to its training data, thus jeopardizing intellectual property and exposing sensitive information.\nRecent methods that use pre-trained diffusion models for data synthesis improve efficiency and performance but rely heavily on manually crafted prompts, limiting automation and scalability, especially for attackers with little expertise.\nTo assess the risks posed by open-source pre-trained models, we propose a more realistic threat model that eliminates the need for prompt design skills or knowledge of class names.\nIn this context, we introduce Stealix, the first approach to perform model stealing without predefined prompts. Stealix uses two open-source pre-trained models to infer the victim model’s data distribution, and iteratively refines prompts through a genetic algorithm, progressively improving the precision and diversity of synthetic images.\nOur experimental results demonstrate that Stealix significantly outperforms other methods, even those with access to class names or fine-grained prompts, while operating under the same query budget. These findings highlight the scalability of our approach and suggest that the risks posed by pre-trained generative models in model stealing may be greater than previously recognized.'}",https://openreview.net{'value': '/pdf/da502819a396b67b73b7acf9c3285685ef2d4b00.pdf'},{'abstract_filter': 'Data Synthesis'},ICML.cc,2025,Conference
https://openreview.net/forum?id=p2smPMRQae,{'value': 'A Tale of Two Structures: Do LLMs Capture the Fractal Complexity of Language?'},Ibrahim Alabdulmohsin; Andreas Peter Steiner,~Ibrahim_Alabdulmohsin1; ~Andreas_Peter_Steiner1,"{'value': ['large language models', 'fractals', 'Hurst exponent', 'Holder exponent', 'self-similarity', 'detection', 'decoding', 'instruction-tuning', 'prompting']}","{'value': ""Language exhibits a fractal structure in its information-theoretic complexity (i.e. bits per token), with self-similarity across scales and long-range dependence (LRD). In this work, we investigate whether large language models (LLMs) can replicate such fractal characteristics and identify conditions-such as temperature setting and prompting method-under which they may fail. Moreover, we find that the fractal parameters observed in natural language are contained within a narrow range, whereas those of LLMs' output vary widely, suggesting that fractal parameters might prove helpful in detecting a non-trivial portion of LLM-generated texts. Notably, these findings, and many others reported in this work, are robust to the choice of the architecture; e.g. Gemini 1.0 Pro, Mistral-7B and Gemma-2B. We also release a dataset comprising over 240,000 articles generated by various LLMs (both pretrained and instruction-tuned) with different decoding temperatures and prompting methods, along with their corresponding human-generated texts. We hope that this work highlights the complex interplay between fractal properties, prompting, and statistical mimicry in LLMs, offering insights for generating, evaluating and detecting synthetic texts.""}",https://openreview.net{'value': '/pdf/24a915dffd25e65de01b432425e1c303a95b159f.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=p1UBWkOvZm,{'value': 'AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML'},Patara Trirat; Wonyong Jeong; Sung Ju Hwang,~Patara_Trirat3; ~Wonyong_Jeong1; ~Sung_Ju_Hwang1,"{'value': ['Automated Machine Learning', 'Multi-Agent Framework', 'Large Language Models']}","{'value': ""Automated machine learning (AutoML) accelerates AI development by automating tasks in the development pipeline, such as optimal model search and hyperparameter tuning. Existing AutoML systems often require technical expertise to set up complex tools, which is in general time-consuming and requires a large amount of human effort. Therefore, recent works have started exploiting large language models (LLM) to lessen such burden and increase the usability of AutoML frameworks via a natural language interface, allowing non-expert users to build their data-driven solutions. These methods, however, are usually designed only for a particular process in the AI development pipeline and do not efficiently use the inherent capacity of the LLMs. This paper proposes *AutoML-Agent*, a novel multi-agent framework tailored for full-pipeline AutoML, i.e., from data retrieval to model deployment. *AutoML-Agent* takes user's task descriptions, facilitates collaboration between specialized LLM agents, and delivers deployment-ready models. Unlike existing work, instead of devising a single plan, we introduce a retrieval-augmented planning strategy to enhance exploration to search for more optimal plans. We also decompose each plan into sub-tasks (e.g., data preprocessing and neural network design) each of which is solved by a specialized agent we build via prompting executing in parallel, making the search process more efficient. Moreover, we propose a multi-stage verification to verify executed results and guide the code generation LLM in implementing successful solutions. Extensive experiments on seven downstream tasks using fourteen datasets show that *AutoML-Agent* achieves a higher success rate in automating the full AutoML process, yielding systems with good performance throughout the diverse domains.""}",https://openreview.net{'value': '/pdf/e11df054e7e2b676ce0272b6b5318b01b7327210.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=oRdfFS7xO5,{'value': 'Contrastive Private Data Synthesis via Weighted Multi-PLM Fusion'},Tianyuan Zou; Yang Liu; Peng Li; Yufei Xiong; Jianqing Zhang; Jingjing Liu; Xiaozhou Ye; Ye Ouyang; Ya-Qin Zhang,~Tianyuan_Zou1; ~Yang_Liu59; ~Peng_Li2; ~Yufei_Xiong1; ~Jianqing_Zhang1; ~Jingjing_Liu2; ~Xiaozhou_Ye1; ~Ye_Ouyang1; ~Ya-Qin_Zhang1,"{'value': ['Differentially Private Synthetic Dataset', 'Collaboration between Private Data and Private Model', 'Fusion of Pre-trained Language Model']}","{'value': 'Substantial quantity and high quality are the golden rules of making a good training dataset with sample privacy protection equally important. Generating synthetic samples that resemble high-quality private data while ensuring Differential Privacy (DP), a formal privacy guarantee, promises scalability and practicality. However, existing methods relying on pre-trained models for data synthesis often struggle in data-deficient scenarios, suffering from limited sample size, inevitable generation noise and existing pre-trained model bias. To address these challenges, we propose a novel contr**A**stive private data **S**ynthesis via **W**eighted multiple **P**re-trained generative models framework, named as **WASP**. WASP utilizes limited private samples for more accurate private data distribution estimation via a Top-*Q* voting mechanism, and leverages low-quality synthetic samples for contrastive generation via collaboration among dynamically weighted multiple pre-trained models. Extensive experiments on 6 well-developed datasets with 6 open-source and 3 closed-source PLMs demonstrate the superiority of WASP in improving model performance over diverse downstream tasks. Code is available at https://github.com/LindaLydia/WASP.'}",https://openreview.net{'value': '/pdf/366c522d13e2e39c6026e3d04cc70912ec1af2aa.pdf'},{'title_filter': 'Data Synthesis'},ICML.cc,2025,Conference
https://openreview.net/forum?id=oOAICE3sY7,{'value': 'Minimax Optimal Regret Bound for Reinforcement Learning with Trajectory Feedback'},Zihan Zhang; Yuxin Chen; Jason D. Lee; Simon Shaolei Du; Ruosong Wang,~Zihan_Zhang1; ~Yuxin_Chen5; ~Jason_D._Lee1; ~Simon_Shaolei_Du1; ~Ruosong_Wang1,"{'value': ['reinforcement learning', 'online learning', 'trajectory feedback']}","{'value': 'In this work, we study reinforcement learning (RL) with trajectory feedback. \nCompared to the standard RL setting, in RL with trajectory feedback, the agent only observes the accumulative reward along the trajectory, and therefore, this model is particularly suitable for scenarios where querying the reward in each single step incurs prohibitive cost. \nFor a finite-horizon Markov Decision Process (MDP) with $S$ states, $A$ actions and a horizon length of $H$, we develop an algorithm that enjoys an asymptotically nearly optimal regret of $\\tilde{O}\\left(\\sqrt{SAH^3K}\\right)$ in $K$ episodes.\nTo achieve this result, our new technical ingredients include\n(i) constructing a tighter confidence region for the reward function by incorporating the RL with trajectory feedback setting with techniques in linear bandits and \n (ii) constructing a reference transition model to better guide the exploration process.'}",https://openreview.net{'value': '/pdf/26f159c3b9ac64adcead51e48b00716fb3a05f70.pdf'},{'title_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=oMkmNTBb0l,{'value': 'Learning Safe Strategies for Value Maximizing Buyers in Uniform Price Auctions'},Negin Golrezaei; Sourav Sahoo,~Negin_Golrezaei1; ~Sourav_Sahoo1,"{'value': ['multi-unit auctions', 'value maximizers', 'bidding strategies', 'online learning']}","{'value': 'We study the bidding problem in repeated uniform price multi-unit auctions from the perspective of a single *value-maximizing* buyer who aims to maximize their cumulative value over $T$ rounds while adhering to return-on-investment (RoI) constraints in each round. Buyers adopt $m$-*uniform bidding* format, where they submit $m$ bid-quantity pairs $(b_i, q_i)$ to demand $q_i$ units at bid $b_i$. We introduce *safe* bidding strategies as those that satisfy RoI constraints in every auction, regardless of competing bids. We show that these strategies depend only on the bidder’s valuation curve, and the bidder can focus on a finite subset of this class without loss of generality. While the number of strategies in this subset is exponential in $m$, we develop a polynomial-time algorithm to learn the optimal safe strategy that achieves sublinear regret in the online setting, where regret is measured against a clairvoyant benchmark that knows the competing bids *a priori* and selects a fixed hindsight optimal safe strategy. We then evaluate the performance of safe strategies against a clairvoyant that selects the optimal strategy from a richer class of strategies in the online setting. In this scenario, we compute the *richness ratio*, $\\alpha\\in(0, 1]$ for the class of strategies chosen by the clairvoyant and show that our algorithm, designed to learn safe strategies, achieves $\\alpha$-approximate sublinear regret against these stronger benchmarks. Experiments on semi-synthetic data from real-world auctions show that safe strategies substantially outperform the derived theoretical bounds, making them quite appealing in practice.'}",https://openreview.net{'value': '/pdf/38a10436d433bf9561a8da2861988a15e7c40ec7.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=nxCWKWok8N,{'value': 'Leveraging Sparsity for Sample-Efficient Preference Learning: A Theoretical Perspective'},Yunzhen Yao; Lie He; Michael Gastpar,~Yunzhen_Yao1; ~Lie_He1; ~Michael_Gastpar1,"{'value': ['preference learning', 'RLHF', 'sparsity', 'statistical estimation', 'reward modeling', 'sample efficiency']}","{'value': 'This paper considers the sample-efficiency of preference learning, which models and predicts human choices based on comparative judgments. The minimax optimal estimation error rate $\\Theta(d/n)$ in classical estimation theory requires that the number of samples $n$ scales linearly with the dimensionality of the feature space $d$. However, the high dimensionality of the feature space and the high cost of collecting human-annotated data challenge the efficiency of traditional estimation methods. To remedy this, we leverage sparsity in the preference model and establish sharp error rates. We show that under the sparse random utility model, where the parameter of the reward function is $k$-sparse, the minimax optimal rate can be reduced to $\\Theta(k/n \\log(d/k))$. Furthermore, we analyze the $\\ell_{1}$-regularized estimator and show that it achieves near-optimal rate under mild assumptions on the Gram matrix. \nExperiments on synthetic data and LLM alignment data validate our theoretical findings, showing that sparsity-aware methods significantly reduce sample complexity and improve prediction accuracy.'}",https://openreview.net{'value': '/pdf/f02795d06c4d938cbb57c969ad896c826b29b8d1.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=mgJkeqc685,{'value': 'HYGMA: Hypergraph Coordination Networks with Dynamic Grouping for Multi-Agent Reinforcement Learning'},Chiqiang Liu; Dazi Li,~Chiqiang_Liu1; ~Dazi_Li1,"{'value': ['Multi-Agent Reinforcement Learning', 'Hypergraph Convolution', 'Dynamic Grouping', 'Multi-Agent Cooperation']}","{'value': ""Cooperative multi-agent reinforcement learning faces significant challenges in effectively organizing agent relationships and facilitating information exchange, particularly when agents need to adapt their coordination patterns dynamically. This paper presents a novel framework that integrates dynamic spectral clustering with hypergraph neural networks to enable adaptive group formation and efficient information processing in multi-agent systems. The proposed framework dynamically constructs and updates hypergraph structures through spectral clustering on agents' state histories, enabling higher-order relationships to emerge naturally from agent interactions. The hypergraph structure is enhanced with attention mechanisms for selective information processing, providing an expressive and efficient way to model complex agent relationships. This architecture can be implemented in both value-based and policy-based paradigms through a unified objective combining task performance with structural regularization. Extensive experiments on challenging cooperative tasks demonstrate that our method significantly outperforms state-of-the-art approaches in both sample efficiency and final performance. The code is available at: https://github.com/mysteryelder/HYGMA.""}",https://openreview.net{'value': '/pdf/33b171228d99ae0600b13ea7f6202a034fcfdf84.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=mUDnPzopZF,{'value': 'Proto Successor Measure: Representing the Behavior Space of an RL Agent'},Siddhant Agarwal; Harshit Sikchi; Peter Stone; Amy Zhang,~Siddhant_Agarwal1; ~Harshit_Sikchi1; ~Peter_Stone1; ~Amy_Zhang1,"{'value': ['Unsupervised Reinforcement Learning', 'Zero Shot Reinforcement Learning', 'Representation Learning']}","{'value': 'Having explored an environment, intelligent agents should be able to transfer their knowledge to most downstream tasks within that environment without additional interactions. Referred to as ""zero-shot learning"", this ability remains elusive for general-purpose reinforcement learning algorithms.  While recent works have attempted to produce zero-shot RL agents, they make assumptions about the nature of the tasks or the structure of the MDP. We present *Proto Successor Measure*: the basis set for all possible behaviors of a Reinforcement Learning Agent in a dynamical system. We prove that any possible behavior (represented using visitation distributions) can be represented using an affine combination of these policy-independent basis functions. Given a reward function at test time, we simply need to find the right set of linear weights to combine these bases corresponding to the optimal policy. We derive a practical algorithm to learn these basis functions using reward-free interaction data from the environment and show that our approach can produce the near-optimal policy at test time for any given reward function without additional environmental interactions. Project page: agarwalsiddhant10.github.io/projects/psm.html.'}",https://openreview.net{'value': '/pdf/918d583c68939f735716c48fb5d826d047f01593.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=mQeZEsdODh,{'value': 'Continual Reinforcement Learning by Planning with Online World Models'},Zichen Liu; Guoji Fu; Chao Du; Wee Sun Lee; Min Lin,~Zichen_Liu1; ~Guoji_Fu1; ~Chao_Du1; ~Wee_Sun_Lee1; ~Min_Lin1,"{'value': ['model-based rl', 'continual rl', 'online learning', 'incremental learning', 'catastrophic forgetting']}","{'value': 'Continual reinforcement learning (CRL) refers to a naturalistic setting where an agent needs to endlessly evolve, by trial and error, to solve multiple tasks that are presented sequentially. One of the largest obstacles to CRL is that the agent may forget how to solve previous tasks when learning a new task, known as catastrophic forgetting. In this paper, we propose to address this challenge by planning with online world models. Specifically, we learn a Follow-The-Leader shallow model online to capture the world dynamics, in which we plan using model predictive control to solve a set of tasks specified by any reward functions. The online world model is immune to forgetting by construction with a proven regret bound of $\\mathcal{O}(\\sqrt{K^2D\\log(T)})$ under mild assumptions. The planner searches actions solely based on the latest online model, thus forming a FTL Online Agent (OA) that updates incrementally. To assess OA, we further design Continual Bench, a dedicated environment for CRL, and compare with several strong baselines under the same model-planning algorithmic framework. The empirical results show that OA learns continuously to solve new tasks while not forgetting old skills, outperforming agents built on deep world models with various continual learning techniques.'}",https://openreview.net{'value': '/pdf/38e5ddd74a27dbb7d17b242cb39aa8363095eeae.pdf'},{'abstract_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=mHySkOp46b,{'value': 'Synthetic Text Generation for Training Large Language Models via Gradient Matching'},Dang Nguyen; Zeman Li; Mohammadhossein Bateni; Vahab Mirrokni; Meisam Razaviyayn; Baharan Mirzasoleiman,~Dang_Nguyen2; ~Zeman_Li1; ~Mohammadhossein_Bateni1; ~Vahab_Mirrokni2; ~Meisam_Razaviyayn1; ~Baharan_Mirzasoleiman1,"{'value': ['Synthetic data', 'Large language models', 'Gradient matching', 'ADMM']}","{'value': 'Synthetic data has the potential to improve the performance, training efficiency, and privacy of real training examples. Nevertheless, existing approaches for synthetic text generation are mostly heuristics and cannot generate human-readable text without compromising the privacy of real data, or provide performance guarantees for training Large Language Models (LLMs). In this work, we propose the first theoretically rigorous approach for generating synthetic human-readable text that provides convergence, performance, and privacy guarantees for fine-tuning LLMs on a target task. To do so, we leverage Alternating Direction Method of Multipliers (ADMM) that iteratively optimizes the embeddings of synthetic examples to match the noisy gradient of the target training or validation data, and maps them to a sequence of text tokens with low perplexity. In doing so, the generated synthetic text guarantees convergence of the model to a close neighborhood of the solution obtained by fine-tuning on real data and preserves their privacy. Experiments on various classification tasks confirm the effectiveness of our proposed approach. Our code is available at [https://github.com/BigML-CS-UCLA/GRADMM](https://github.com/BigML-CS-UCLA/GRADMM).'}",https://openreview.net{'value': '/pdf/e774bb85702971b864f878cde4d69532367d4325.pdf'},{'title_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=mEEiiUXQ7O,{'value': 'BOOD: Boundary-based Out-Of-Distribution Data Generation'},Qilin Liao; Shuo Yang; Bo Zhao; Ping Luo; Hengshuang Zhao,~Qilin_Liao1; ~Shuo_Yang5; ~Bo_Zhao4; ~Ping_Luo2; ~Hengshuang_Zhao2,"{'value': ['OOD detection', 'Diffusion models', 'Training data generation']}","{'value': 'Harnessing the power of diffusion models to synthesize auxiliary training data based on latent space features has proven effective in enhancing out-of-distribution (OOD) detection performance. However, extracting effective features outside the in-distribution (ID) boundary in latent space remains challenging due to the difficulty of identifying decision boundaries between classes. This paper proposes a novel framework called Boundary-based Out-Of-Distribution data generation (BOOD), which synthesizes high-quality OOD features and generates human-compatible outlier images using diffusion models. BOOD first learns a text-conditioned latent feature space from the ID dataset, selects ID features closest to the decision boundary, and perturbs them to cross the decision boundary to form OOD features. These synthetic OOD features are then decoded into images in pixel space by a diffusion model. Compared to previous works, BOOD provides a more training efficient strategy for synthesizing informative OOD features, facilitating clearer distinctions between ID and OOD data. Extensive experimental results on common benchmarks demonstrate that BOOD surpasses the state-of-the-art method significantly, achieving a 29.64\\% decrease in average FPR95 (40.31\\% vs. 10.67\\%) and a 7.27\\% improvement in average AUROC (90.15\\% vs. 97.42\\%) on the Cifar-100 dataset.'}",https://openreview.net{'value': '/pdf/c4a461855a37640eba8403d942dd2bf56b46e9d1.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=lyUJH51URt,{'value': 'Grokking in the Wild: Data Augmentation for Real-World Multi-Hop Reasoning with Transformers'},Roman Abramov; Felix Steinbauer; Gjergji Kasneci,~Roman_Abramov1; ~Felix_Steinbauer1; ~Gjergji_Kasneci2,"{'value': ['multi-hop reasoning', 'transformers', 'grokking', 'knowledge graphs', 'data synthesis', 'generalization circuits', 'factual reasoning', 'NLP', 'synthetic data augmentation.']}","{'value': 'Transformers have achieved great success in numerous NLP tasks but continue to exhibit notable gaps in multi-step factual reasoning, especially when real-world knowledge is sparse. Recent advances in grokking have demonstrated that neural networks can transition from memorizing to perfectly generalizing once they detect underlying logical patterns -- yet these studies have primarily used small, synthetic tasks. In this paper, for the first time, we extend grokking to real-world factual data and address the challenge of dataset sparsity by augmenting existing knowledge graphs with carefully designed synthetic data to raise the ratio $\\phi_r$ of inferred facts to atomic facts above the threshold required for grokking. Surprisingly, we find that even factually incorrect synthetic data can strengthen emergent reasoning circuits rather than degrade accuracy, as it forces the model to rely on relational structure rather than memorization. When evaluated on multi-hop reasoning benchmarks, our approach achieves up to 95--100\\% accuracy on 2WikiMultiHopQA -- substantially improving over strong baselines and matching or exceeding current state-of-the-art results. We further provide an in-depth analysis of how increasing $\\phi_r$ drives the formation of generalizing circuits inside Transformers. Our findings suggest that grokking-based data augmentation can unlock implicit multi-hop reasoning capabilities, opening the door to more robust and interpretable factual reasoning in large-scale language models.'}",https://openreview.net{'value': '/pdf/8a566e78b5dca6a5c80305e69b1d8f24b38a75b2.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=lvvMwGUam6,{'value': 'Code-Generated Graph Representations Using Multiple LLM Agents for Material Properties Prediction'},Jiao Huang; Qianli Xing; Jinglong Ji; Bo Yang,~Jiao_Huang1; ~Qianli_Xing2; ~Jinglong_Ji1; ~Bo_Yang6,"{'value': ['Material structure representation', 'Material property prediction', 'Multi-agent systems', 'Large language models']}","{'value': 'Graph neural networks have recently demonstrated remarkable performance in predicting material properties. \nCrystalline material data is manually encoded into graph representations.\nExisting methods incorporate different attributes into constructing representations to satisfy the constraints arising from symmetries of material structure.\nHowever, existing methods for obtaining graph representations are specific to certain constraints, which are ineffective when facing new constraints.\nIn this work, we propose a code generation framework with multiple large language model agents to obtain representations named Rep-CodeGen with three iterative stages simulating an evolutionary algorithm. \nTo the best of our knowledge, Rep-CodeGen is the first framework for automatically generating code to obtain representations that can be used when facing new constraints. \nFurthermore, a type of representation from generated codes by our framework satisfies six constraints, with codes satisfying three constraints as bases. \nExtensive experiments on two real-world material datasets show that a property prediction method based on such a graph representation achieves state-of-the-art performance in material property prediction tasks.'}",https://openreview.net{'value': '/pdf/b7e2e632db4757c4b9bee53022999a9c68437be4.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=lvkVhZ776k,{'value': 'CAN: Leveraging Clients As Navigators for Generative Replay in Federated Continual Learning'},Xuankun Rong; Jianshu Zhang; Kun He; Mang Ye,~Xuankun_Rong1; ~Jianshu_Zhang3; ~Kun_He5; ~Mang_Ye1,"{'value': ['Federated Learning', 'Continual Learning']}","{'value': 'Generative replay (GR) has been extensively validated in continual learning as a mechanism to synthesize data and replay past knowledge to mitigate forgetting. \nBy leveraging synthetic rather than real data for the replay, GR has been adopted in some federated continual learning (FCL) approaches to ensure the privacy of client-side data. \nWhile existing GR-based FCL approaches have introduced improvements, none of their enhancements specifically take into account the unique characteristics of federated learning settings. \nBeyond privacy constraints, what other fundamental aspects of federated learning should be explored in the context of FCL?\nIn this work, we explore the potential benefits that come from emphasizing the role of clients throughout the process.\nWe begin by highlighting two key observations: (a) Client Expertise Superiority, where clients, rather than the server, act as domain experts, and (b) Client Forgetting Variance, where heterogeneous data distributions across clients lead to varying levels of forgetting.\nBuilding on these insights, we propose CAN (Clients As Navigators), highlighting the pivotal role of clients in both data synthesis and data replay. \nExtensive evaluations demonstrate that this client-centric approach achieves state-of-the-art performance. Notably, it requires a smaller buffer size, reducing storage overhead and enhancing computational efficiency.'}",https://openreview.net{'value': '/pdf/379e5ca8fcb380378d702d933e77256013b5dea1.pdf'},{'abstract_filter': 'Data Synthesis'},ICML.cc,2025,Conference
https://openreview.net/forum?id=li59703WbA,{'value': 'LBI-FL: Low-Bit Integerized Federated Learning with Temporally Dynamic Bit-Width Allocation'},Li Ding; Hao Zhang; Wenrui Dai; Chenglin Li; Weijia Lu; ZHIFEI YANG; xiaodong Zhang; Xiaofeng Ma; Junni Zou; Hongkai Xiong,~Li_Ding5; ~Hao_Zhang36; ~Wenrui_Dai1; ~Chenglin_Li2; ~Weijia_Lu1; ~ZHIFEI_YANG2; ~xiaodong_Zhang6; ~Xiaofeng_Ma1; ~Junni_Zou1; ~Hongkai_Xiong1,"{'value': ['Federated learning', 'low-bit integerized training', 'network quantization']}","{'value': 'Federated learning (FL) is greatly challenged by the communication bottleneck and computation limitation on clients. Existing methods based on quantization for FL cannot simultaneously reduce the uplink and downlink communication cost and mitigate the computation burden on clients. To address this problem, in this paper, we propose the first low-bit integerized federated learning (LBI-FL) framework that quantizes the weights, activations, and gradients to lower than INT8 precision to evidently reduce the communication and computational costs. Specifically, we achieve dynamical temporal bit-width allocation for weights, activations, and gradients along the training trajectory via reinforcement learning. An agent is trained to determine bit-width allocation by comprehensively considering the states like current bit-width, training stage, and quantization loss as the state. The agent efficiently trained on small-scale datasets can be well generalized to train varying network architectures on non-independent and identically distributed datasets. Furthermore, we demonstrated in theory that federated learning with gradient quantization achieves an equivalent convergence rate to FedAvg. The proposed LBI-FL can  reduce the communication costs by 8 times compared to full-precision FL. Extensive experiments show that the proposed LBI-FL achieves a reduction of more than 50\\% BitOPs per client on average for FL with less than 2\\% accuracy loss compared to low-bit training with INT8 precision.'}",https://openreview.net{'value': '/pdf/7c182d880830fad0cca0c62ff84d1b6d7dccbd46.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=lbrqeIipJr,{'value': 'Disentangling and Integrating Relational and Sensory Information in Transformer Architectures'},Awni Altabaa; John Lafferty,~Awni_Altabaa1; ~John_Lafferty2,"{'value': ['relational', 'reasoning', 'attention', 'transformers', 'inductive biases', 'sensory', 'relational', 'architecture', 'attention']}","{'value': 'Relational reasoning is a central component of generally intelligent systems, enabling robust and data-efficient inductive generalization. Recent empirical evidence shows that many existing neural architectures, including Transformers, struggle with tasks requiring relational reasoning. In this work, we distinguish between two types of information: *sensory* information about the properties of individual objects, and *relational* information about the relationships between objects. While neural attention provides a powerful mechanism for controlling the flow of sensory information between objects, the Transformer lacks an explicit computational mechanism for routing and processing relational information. To address this limitation, we propose an architectural extension of the Transformer framework that we call the *Dual Attention Transformer (DAT)*, featuring two distinct attention mechanisms: sensory attention for directing the flow of sensory information, and a novel relational attention mechanism for directing the flow of relational information. We empirically evaluate *DAT* on a diverse set of tasks ranging from synthetic relational benchmarks to complex real-world tasks such as language modeling and visual processing. Our results demonstrate that integrating explicit relational computational mechanisms into the Transformer architecture leads to significant performance gains in terms of data efficiency and parameter efficiency.'}",https://openreview.net{'value': '/pdf/282a569dcdc38003b1ad12fb4893f68ecbba8719.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=lZ4HiOwpBO,{'value': 'SING: Spatial Context in Large Language Model for Next-Gen Wearables'},Ayushi Mishra; Yang Bai; Priyadarshan Narayanasamy; Nakul Garg; Nirupam Roy,~Ayushi_Mishra1; ~Yang_Bai14; ~Priyadarshan_Narayanasamy1; ~Nakul_Garg1; ~Nirupam_Roy1,"{'value': ['Spatial Speech ASR', 'Direction of Arrival', 'Large Language Models']}","{'value': 'Integrating spatial context into large language models (LLMs) has the potential to revolutionize human-computer interaction, particularly in wearable devices. In this work, we present a novel system architecture that incorporates spatial speech understanding into LLMs, enabling contextually aware and adaptive applications for wearable technologies. Our approach leverages microstructure-based spatial sensing to extract precise Direction of Arrival (DoA) information using a monaural microphone. To address the lack of existing dataset for microstructure-assisted speech recordings, we synthetically create a dataset by using the LibriSpeech dataset. This spatial information is fused with linguistic embeddings from OpenAI’s Whisper model, allowing each modality to learn complementary contextual representations. The fused embeddings are aligned with the input space of LLaMA-3.2 3B model and fine-tuned with lightweight adaptation technique LoRA to optimize for on-device processing. SING supports spatially-aware automatic speech recognition (ASR), achieving a mean error of 25.72°—a substantial improvement compared to the 88.52° median error in existing work—with a word error rate (WER) of 5.3. SING also supports soundscaping, for example, inference how many people were talking and their directions, with up to 5 people and a median DoA error of 16°. Our system demonstrates superior performance in spatial speech understanding while addressing the challenges of power efficiency, privacy, and hardware constraints, paving the way for advanced applications in augmented reality, accessibility, and immersive experiences.'}",https://openreview.net{'value': '/pdf/36529d717129e316c07348f36f1b20815df60f80.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=lLnAua5poB,{'value': 'Differential Privacy Guarantees of Markov Chain Monte Carlo Algorithms'},Andrea Bertazzi; Tim Johnston; Gareth O. Roberts; Alain Oliviero Durmus,~Andrea_Bertazzi1; ~Tim_Johnston1; ~Gareth_O._Roberts1; ~Alain_Oliviero_Durmus1,"{'value': ['Differential Privacy', 'Markov Chain Monte Carlo Methods', ""Girsanov's theorem""]}","{'value': ""This paper aims to provide differential privacy (DP) guarantees for Markov chain Monte Carlo (MCMC) algorithms. In a first part, we establish DP guarantees on samples output by MCMC algorithms as well as Monte Carlo estimators associated with these methods under assumptions on the convergence properties of the underlying Markov chain. In particular, our results highlight the critical condition of ensuring the target distribution is differentially private itself. In a second part, we specialise our analysis to the unadjusted Langevin algorithm and stochastic gradient Langevin dynamics and establish guarantees on their (Rényi) DP. To this end, we develop a novel methodology based on Girsanov's theorem combined with a perturbation trick to obtain bounds for an unbounded domain and in a non-convex setting. We establish: (i) uniform in $n$ privacy guarantees when the state of the chain after $n$ iterations is released, (ii) bounds on the privacy of the entire chain trajectory. These findings provide concrete guidelines for privacy-preserving MCMC.""}",https://openreview.net{'value': '/pdf/be1d221a5b16f4e422a03bb72e5d6c87da51c9a2.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=lEV0x6aDKc,{'value': 'Inverse Optimization via Learning Feasible Regions'},Ke Ren; Peyman Mohajerin Esfahani; Angelos Georghiou,~Ke_Ren3; ~Peyman_Mohajerin_Esfahani2; ~Angelos_Georghiou1,"{'value': ['Inverse Optimization', 'Non-convex Optimization', 'Data-driven Optimization']}","{'value': 'We study inverse optimization (IO), where the goal is to use a parametric optimization program as the hypothesis class to infer relationships between input-decision pairs. Most of the literature focuses on learning only the objective function, as learning the constraint function (i.e., feasible regions) leads to nonconvex training programs. Motivated by this, we focus on learning feasible regions for known linear objectives, and introduce two training losses along with a hypothesis class to parameterize the  constraint function. Our hypothesis class surpasses the previous objective-only method by naturally capturing discontinuous behaviors in input-decision pairs. We introduce a customized block coordinate descent algorithm with a smoothing technique to solve the training problems, while for further restricted hypothesis classes, we reformulate the training optimization as a tractable convex program or mixed integer linear program. Synthetic experiments and two power system applications including comparisons with state-of-the-art approaches showcase and validate the proposed approach.'}",https://openreview.net{'value': '/pdf/84d32ef174e4b8d34f45fecd8361301c1579ef91.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=l1sx5KiM7Z,{'value': 'Curvature Enhanced Data Augmentation for Regression'},Ilya Kaufman; Omri Azencot,~Ilya_Kaufman1; ~Omri_Azencot1,"{'value': ['Manifold learning', 'Data augmentation', 'Regression']}","{'value': 'Deep learning models with a large number of parameters, often referred to as over-parameterized models, have achieved exceptional performance across various tasks. Despite concerns about overfitting, these models frequently generalize well to unseen data, thanks to effective regularization techniques, with data augmentation being among the most widely used. While data augmentation has shown great success in classification tasks using label-preserving transformations, its application in regression problems has received less attention. Recently, a novel manifold learning approach for generating synthetic data was proposed, utilizing a first-order approximation of the data manifold. Building on this foundation, we present a theoretical framework and practical tools for approximating and sampling general data manifolds. Furthermore, we introduce the Curvature-Enhanced Manifold Sampling (CEMS) method for regression tasks. CEMS leverages a second-order representation of the data manifold to enable efficient sampling and reconstruction of new data points. Extensive evaluations across multiple datasets and comparisons with state-of-the-art methods demonstrate that CEMS delivers superior performance in both in-distribution and out-of-distribution scenarios, while introducing only minimal computational overhead. Code is available at https://github.com/azencot-group/CEMS.'}",https://openreview.net{'value': '/pdf/ebedcf08aa61fa70f9fe9203dcfe4d8c6cafdf25.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=l19DmXbwPK,{'value': 'VersaPRM: Multi-Domain Process Reward Model via Synthetic Reasoning Data'},Thomas Zeng; Shuibai Zhang; Shutong Wu; Christian Classen; Daewon Chae; Ethan Ewer; Minjae Lee; Heeju Kim; Wonjun Kang; Jackson Kunde; Ying Fan; Jungtaek Kim; Hyung Il Koo; Kannan Ramchandran; Dimitris Papailiopoulos; Kangwook Lee,~Thomas_Zeng1; ~Shuibai_Zhang1; ~Shutong_Wu1; ~Christian_Classen1; ~Daewon_Chae2; ~Ethan_Ewer1; ~Minjae_Lee2; ~Heeju_Kim1; ~Wonjun_Kang1; ~Jackson_Kunde1; ~Ying_Fan2; ~Jungtaek_Kim1; ~Hyung_Il_Koo1; ~Kannan_Ramchandran1; ~Dimitris_Papailiopoulos1; ~Kangwook_Lee1,{'value': ['Proccess Reward Model']},"{'value': ""Process Reward Models (PRMs) have proven effective at enhancing mathematical reasoning for Large Language Models (LLMs) by leveraging increased inference-time computation. However, they are predominantly trained on mathematical data and their generalizability to non-mathematical domains has not been rigorously studied. In response, this work first shows that current PRMs have poor performance in other domains. To address this limitation, we introduce ***VersaPRM***, a multi-domain PRM trained on synthetic reasoning data generated using our novel data generation and annotation method. VersaPRM achieves consistent performance gains across diverse domains. For instance, in the MMLU-Pro category of Law, VersaPRM via weighted majority voting, achieves a 7.9% performance gain over the majority voting baseline–surpassing Qwen2.5-Math-PRM's gain of 1.3%. We further contribute to the community by open-sourcing all data, code and models for VersaPRM.""}",https://openreview.net{'value': '/pdf/68aca347ffb40ac50f9eb713e88dfb26aa3bcf41.pdf'},{'title_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=kwHvs1UdTM,{'value': 'On the Role of Label Noise in the Feature Learning Process'},Andi Han; Wei Huang; Zhanpeng Zhou; Gang Niu; Wuyang Chen; Junchi Yan; Akiko Takeda; Taiji Suzuki,~Andi_Han1; ~Wei_Huang6; ~Zhanpeng_Zhou1; ~Gang_Niu1; ~Wuyang_Chen1; ~Junchi_Yan2; ~Akiko_Takeda2; ~Taiji_Suzuki1,"{'value': ['Label noise', 'Feature Learning', 'Training Dynamics']}","{'value': 'Deep learning with noisy labels presents significant challenges. In this work, we theoretically characterize the role of label noise from a feature learning perspective. Specifically, we consider a signal-noise data distribution, where each sample comprises a label-dependent signal and label-independent noise, and rigorously analyze the training dynamics of a two-layer convolutional neural network under this data setup, along with the presence of label noise. Our analysis identifies two key stages. In Stage I, the model perfectly fits all the clean samples (i.e., samples without label noise) while ignoring the noisy ones (i.e., samples with noisy labels). During this stage, the model learns the signal from the clean samples, which generalizes well on unseen data. In Stage II, as the training loss converges, the gradient in the direction of noise surpasses that of the signal, leading to overfitting on noisy samples. Eventually, the model memorizes the noise present in the noisy samples and degrades its generalization ability. Furthermore, our analysis provides a theoretical basis for two widely used techniques for tackling label noise: early stopping and sample selection. Experiments on both synthetic and real-world setups validate our theory.'}",https://openreview.net{'value': '/pdf/2b69df5fb20add3f0e18e81f0398f0875a639115.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=kmg7hweySi,{'value': 'Feature learning from non-Gaussian inputs: the case of Independent Component Analysis in high dimensions'},Fabiola Ricci; Lorenzo Bardone; Sebastian Goldt,~Fabiola_Ricci1; ~Lorenzo_Bardone1; ~Sebastian_Goldt1,"{'value': ['independent component analysis', 'stochastic gradient descent', 'FastICA']}","{'value': 'Deep neural networks learn structured features from complex, non-Gaussian inputs, but the mechanisms behind this process remain poorly understood. \n  Our work is motivated by the observation that the first-layer filters learnt by deep convolutional neural networks from natural images resemble those learnt by independent component analysis (ICA), a simple unsupervised method that seeks the most non-Gaussian projections of its inputs. \n  This similarity suggests that ICA provides a simple, yet principled model for studying feature learning. \n  Here, we leverage this connection to investigate the interplay between data structure and optimisation in feature learning for the most popular ICA algorithm, FastICA, and stochastic gradient descent (SGD), which is used to train deep networks. \n  We rigorously establish that FastICA requires at least $n\\gtrsim d^4$ samples to recover a single non-Gaussian direction from $d$-dimensional inputs on a simple synthetic data model. We show that vanilla online SGD outperforms FastICA, and prove that the optimal sample complexity $n\\gtrsim d^2$ can be reached by smoothing the loss, albeit in a data-dependent way. We finally demonstrate the existence of a search phase for FastICA on ImageNet, and discuss how the strong non-Gaussianity of said images compensates for the poor sample complexity of FastICA.'}",https://openreview.net{'value': '/pdf/66cf5a9afa3d10087c872bc0fce1db8f4bc1ffa0.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=klw8Ko4ENe,{'value': 'SPRI: Aligning Large Language Models with Context-Situated Principles'},Hongli Zhan; Muneeza Azmat; Raya Horesh; Junyi Jessy Li; Mikhail Yurochkin,~Hongli_Zhan1; ~Muneeza_Azmat1; ~Raya_Horesh1; ~Junyi_Jessy_Li2; ~Mikhail_Yurochkin1,"{'value': ['Large Language Models', 'Alignment', 'Scalable Context-Situated Oversight']}","{'value': 'Aligning Large Language Models to integrate and reflect human values, especially for tasks that demand intricate human oversight, is arduous since it is resource-intensive and time-consuming to depend on human expertise for context-specific guidance. Prior work has utilized predefined sets of rules or principles to steer the behavior of models (Bai et al., 2022; Sun et al., 2023). However, these principles tend to be generic, making it challenging to adapt them to each individual input query or context. In this work, we present Situated-PRInciples (SPRI), a framework requiring minimal or no human effort that is designed to automatically generate guiding principles in real-time for each input query and utilize them to align each response. We evaluate SPRI on three tasks, and show that 1) SPRI can derive principles in a complex domain-specific task that leads to on-par performance as expert-crafted ones; 2) SPRI-generated principles lead to instance-specific rubrics that outperform prior LLM-as-a-judge frameworks; 3) using SPRI to generate synthetic SFT data leads to substantial improvement on truthfulness.'}",https://openreview.net{'value': '/pdf/caa52c0d68434b9ec30b12f952429d144f6a9b23.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=kVtyv7bpnw,{'value': 'How Do Transformers Learn Variable Binding in Symbolic Programs?'},Yiwei Wu; Atticus Geiger; Raphaël Millière,~Yiwei_Wu1; ~Atticus_Geiger1; ~Raphaël_Millière3,"{'value': ['variable binding', 'mechanistic interpretability', 'causal interventions', 'transformers', 'language models']}","{'value': 'Variable binding---the ability to associate variables with values---is fundamental to symbolic computation and cognition. Although classical architectures typically implement variable binding via addressable memory, it is not well understood how modern neural networks lacking built-in binding operations may acquire this capacity. We investigate this by training a Transformer to dereference queried variables in symbolic programs where variables are assigned either numerical constants or other variables. Each program requires following chains of variable assignments up to four steps deep to find the queried value, and also contains irrelevant chains of assignments acting as distractors. Our analysis reveals a developmental trajectory with three distinct phases during training: (1) random prediction of numerical constants, (2) a shallow heuristic prioritizing early variable assignments, and (3) the emergence of a systematic mechanism for dereferencing assignment chains.\nUsing causal interventions, we find that the model learns to exploit the residual stream as an addressable memory space, with specialized attention heads routing information across token positions. \nThis mechanism allows the model to dynamically track variable bindings across layers, resulting in accurate dereferencing. \nOur results show how Transformer models can learn to implement systematic variable binding without explicit architectural support, bridging connectionist and symbolic approaches.'}",https://openreview.net{'value': '/pdf/339617fb255028230cbb82e847f721aea60edc33.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=kRKsUOJdp5,{'value': 'Regression for the Mean: Auto-Evaluation and Inference with Few Labels through Post-hoc Regression'},Benjamin Eyre; David Madras,~Benjamin_Eyre1; ~David_Madras1,"{'value': ['auto-evaluation', 'prediction-powered-inference', 'regression', 'variance-reduction']}","{'value': 'The availability of machine learning systems that can effectively perform arbitrary tasks has led to synthetic labels from these systems being used in applications of statistical inference, such as data analysis or model evaluation. The Prediction Powered Inference (PPI) framework provides a way of leveraging both a large pool of pseudo-labelled data and a small sample with real, high-quality labels to produce a low-variance, unbiased estimate of the quantity being evaluated for. Most work on PPI considers a relatively sizable set of labelled samples, which can be resource intensive to obtain.  However, we find that when labelled data is scarce, the PPI++ method can perform even worse than classical inference. We analyze this phenomenon by relating PPI++ to ordinary least squares regression, which also experiences high variance with small sample sizes, and use this regression framework to better understand the efficacy of PPI. Motivated by this, we present two new PPI-based techniques that leverage robust regressors to produce even lower variance estimators in the few-label regime'}",https://openreview.net{'value': '/pdf/92c1139175e775087c4338b8fa18ba5697ada35a.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=kONwjsPKcI,{'value': 'Falsification of Unconfoundedness by Testing Independence of Causal Mechanisms'},Rickard Karlsson; JH Krijthe,~Rickard_Karlsson1; ~JH_Krijthe1,"{'value': ['causal inference', 'observational data', 'falsification', 'unmeasured confounding', 'independent causal mechanisms']}","{'value': 'A major challenge in estimating treatment effects in observational studies is the reliance on untestable conditions such as the assumption of no unmeasured confounding. In this work, we propose an algorithm that can falsify the assumption of no unmeasured confounding in a setting with observational data from multiple heterogeneous sources, which we refer to as environments. Our proposed falsification strategy leverages a key observation that unmeasured confounding can cause observed causal mechanisms to appear dependent. Building on this observation, we develop a novel two-stage procedure that detects these dependencies with high statistical power while controlling false positives. The algorithm does not require access to randomized data and, in contrast to other falsification approaches, functions even under transportability violations when the environment has a direct effect on the outcome of interest. To showcase the practical relevance of our approach, we show that our method is able to efficiently detect confounding on both simulated and semi-synthetic data.'}",https://openreview.net{'value': '/pdf/3f72c1cc817b8954c88144c49141d76dcb35b695.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=kHEVCfES4Q,{'value': 'A Closer Look at Transformers for Time Series Forecasting: Understanding Why They Work and Where They Struggle'},Yu Chen; Nathalia Céspedes; Payam Barnaghi,~Yu_Chen10; ~Nathalia_Céspedes1; ~Payam_Barnaghi1,"{'value': ['Time series forecasting', 'transformers', 'point-wise', 'patch-wise', 'variate-wise', 'tokenization', 'model evaluation']}","{'value': 'Time-series forecasting is crucial across various domains, including finance, healthcare, and energy. Transformer models, originally developed for natural language processing, have demonstrated significant potential in addressing challenges associated with time-series data. These models utilize different tokenization strategies, point-wise, patch-wise, and variate-wise, to represent time-series data, each resulting in different scope of attention maps. Despite the emergence of sophisticated architectures, simpler transformers  consistently outperform their more complex counterparts in widely used benchmarks. This study examines why point-wise transformers are generally less effective, why intra- and inter-variate attention mechanisms yield similar outcomes, and which architectural components drive the success of simpler models. By analyzing mutual information and evaluating models on synthetic datasets, we demonstrate that intra-variate dependencies are the primary contributors to prediction performance on benchmarks, while inter-variate dependencies have a minor impact. Additionally, techniques such as Z-score normalization and skip connections are also crucial. However, these results are largely influenced by the self-dependent and stationary nature of benchmark datasets. By validating our findings on real-world healthcare data, we provide insights for designing more effective transformers for practical applications.'}",https://openreview.net{'value': '/pdf/418f7dc77d63dc46ec9492cb9c20bbdd4be7e86b.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=k6p8UKRdH7,{'value': 'Nemotron-CORTEXA: Enhancing LLM Agents for Software Engineering Tasks via Improved Localization and Solution Diversity'},Atefeh Sohrabizadeh; Jialin Song; Mingjie Liu; Rajarshi Roy; Chankyu Lee; Jonathan Raiman; Bryan Catanzaro,~Atefeh_Sohrabizadeh1; ~Jialin_Song1; ~Mingjie_Liu2; ~Rajarshi_Roy1; ~Chankyu_Lee1; ~Jonathan_Raiman1; ~Bryan_Catanzaro1,"{'value': ['Coding assistant', 'code embedding model', 'localization agent', 'SWE-bench', 'prompt design', 'contextual information', 'multi-LLM', 'multi-prompt']}","{'value': ""Large Language Models (LLMs) have demonstrated significant potential in code generation by following natural language instructions.  Unfortunately, crucial real-world software engineering tasks, such as debugging or repository-level feature implementation, involve processing extensive contexts beyond current LLM context sizes and performing complex reasoning that is brittle using standard autoregressive decoding. Enhancing LLMs' performance in these scenarios requires careful consideration of the contextual information provided to the model, optimizing how the model leverages that, and identifying tools that enable more effective navigation of the development environment.\nTo address these challenges, we introduce Nemotron-CORTEXA, an agentic system built on a predefined scaffold that enhances LLMs' ability to navigate and reason efficiently in complex software engineering contexts. Specifically, we develop a novel code embedding model that retrieves the most relevant files with greater precision, along with a localization agent that refines the granularity of the retrieval process. Additionally, we demonstrate that providing diverse contextual information and utilizing different prompt formats enable the model to identify and resolve issues more efficiently. We evaluate Nemotron-CORTEXA using SWE-bench, a benchmark derived from real-world GitHub issues. Compared to the widely used Agentless framework, Nemotron-CORTEXA achieves a higher issue resolution rate at a lower cost, highlighting its practical impact in addressing real-world software engineering challenges.""}",https://openreview.net{'value': '/pdf/4d5cffc360ef13fae77f7d00e3c2be8616712102.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=jvP1wbD0xh,{'value': 'Better to Teach than to Give: Domain Generalized Semantic Segmentation via Agent Queries with Diffusion Model Guidance'},Fan Li; Xuan Wang; Min Qi; Zhaoxiang Zhang; Yuelei Xu,~Fan_Li15; ~Xuan_Wang10; ~Min_Qi1; ~Zhaoxiang_Zhang7; ~Yuelei_Xu2,"{'value': ['semantic segmentation', 'domain generalization', 'diffusion model']}","{'value': ""Domain Generalized Semantic Segmentation (DGSS) trains a model on a labeled source domain to generalize to unseen target domains with consistent contextual distribution and varying visual appearance.\nMost existing methods rely on domain randomization or data generation but struggle to capture the underlying scene distribution, resulting in the loss of useful semantic information. \nInspired by the diffusion model's capability to generate diverse variations within a given scene context, we consider harnessing its rich prior knowledge of scene distribution to tackle the challenging DGSS task.\nIn this paper, we propose a novel agent \\textbf{Query}-driven learning framework based on \\textbf{Diff}usion model guidance for DGSS, named QueryDiff. \nOur recipe comprises three key ingredients: (1) generating agent queries from segmentation features to aggregate semantic information about instances within the scene; \n(2) learning the inherent semantic distribution of the scene through agent queries guided by diffusion features; \n(3) refining segmentation features using optimized agent queries for robust mask predictions.\nExtensive experiments across various settings demonstrate that our method significantly outperforms previous state-of-the-art methods. \nNotably, it enhances the model's ability to generalize effectively to extreme domains, such as cubist art styles. Code is available at https://github.com/FanLiHub/QueryDiff.""}",https://openreview.net{'value': '/pdf/1df9324bb9e8aa213d988c0fe3f78514b940f1ec.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=jkVH7nLzUR,{'value': 'Three-Dimensional Trajectory Prediction with 3DMoTraj Dataset'},Hao Zhou; Xu Yang; Mingyu Fan; Lu Qi; Xiangtai Li; Ming-Hsuan Yang; Fei Luo,~Hao_Zhou18; ~Xu_Yang1; ~Mingyu_Fan2; ~Lu_Qi1; ~Xiangtai_Li1; ~Ming-Hsuan_Yang1; ~Fei_Luo3,"{'value': ['3D trajectory prediction', '3D trajectory dataset', 'Decoupled trajectory prediction']}","{'value': 'With the growing interest in embodied and spatial intelligence, accurately predicting trajectories in 3D environments has become increasingly critical. However, no datasets have been explicitly designed to study 3D trajectory prediction. To this end, we contribute a 3D motion trajectory (3DMoTraj) dataset collected from unmanned underwater vehicles (UUVs) operating in oceanic environments. Mathematically, trajectory prediction becomes significantly more complex when transitioning from 2D to 3D. To tackle this challenge, we analyze the prediction complexity of 3D trajectories and propose a new method consisting of two key components: decoupled trajectory prediction and correlated trajectory refinement. The former decouples inter-axis correlations, thereby reducing prediction complexity and generating coarse predictions. The latter refines the coarse predictions by modeling their inter-axis correlations. Extensive experiments show that our method significantly improves 3D trajectory prediction accuracy and outperforms state-of-the-art methods. Both the 3DMoTraj dataset and the method are available at https://github.com/zhouhao94/3DMoTraj.'}",https://openreview.net{'value': '/pdf/f3a8e791e48e54d0dbc8c45d62b953e3d54ffe16.pdf'},{'title_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=jdBWtGZnYd,{'value': 'Provably Efficient Algorithm for Best Scoring Rule Identification in Online Principal-Agent Information Acquisition'},Zichen Wang; Chuanhao Li; Huazheng Wang,~Zichen_Wang8; ~Chuanhao_Li1; ~Huazheng_Wang1,"{'value': ['Online information acquisition', 'multi-armed bandits', 'principal-agent game']}","{'value': ""We investigate the problem of identifying the optimal scoring rule within the principal-agent framework for online information acquisition problem. We focus on the principal's perspective, seeking to determine the desired scoring rule through interactions with the agent. To address this challenge, we propose two algorithms: OIAFC and OIAFB, tailored for fixed confidence and fixed budget settings, respectively. Our theoretical analysis demonstrates that OIAFC can extract the desired $(\\epsilon, \\delta)$-scoring rule with a efficient instance-dependent sample complexity or an instance-independent sample complexity. Our analysis also shows that OIAFB matches the instance-independent performance bound of OIAFC, while both algorithms share the same complexity across fixed confidence and fixed budget settings.""}",https://openreview.net{'value': '/pdf/3d3aa11beb2604e2b19c1121176595c93144f013.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=jP59rz1bZk,{'value': 'ITBench: Evaluating AI Agents across Diverse Real-World IT Automation Tasks'},Saurabh Jha; Rohan R. Arora; Yuji Watanabe; Takumi Yanagawa; Yinfang Chen; Jackson Clark; Bhavya Bhavya; Mudit Verma; Harshit Kumar; Hirokuni Kitahara; Noah Zheutlin; Saki Takano; Divya Pathak; Felix George; Xinbo Wu; Bekir O Turkkan; Gerard Vanloo; Michael Nidd; Ting Dai; Oishik Chatterjee; Pranjal Gupta; Suranjana Samanta; Pooja Aggarwal; Rong Lee; Jae-wook Ahn; Debanjana Kar; Amit Paradkar; Yu Deng; Pratibha Moogi; Prateeti Mohapatra; Naoki Abe; Chandrasekhar Narayanaswami; Tianyin Xu; Lav R. Varshney; Ruchi Mahindru; Anca Sailer; Laura Shwartz; Daby Sow; Nicholas C. M. Fuller; Ruchir Puri,~Saurabh_Jha3; ~Rohan_R._Arora1; ~Yuji_Watanabe1; ~Takumi_Yanagawa1; ~Yinfang_Chen1; ~Jackson_Clark1; ~Bhavya_Bhavya2; ~Mudit_Verma3; ~Harshit_Kumar1; ~Hirokuni_Kitahara1; ~Noah_Zheutlin1; ~Saki_Takano1; ~Divya_Pathak1; ~Felix_George1; ~Xinbo_Wu1; ~Bekir_O_Turkkan1; ~Gerard_Vanloo1; ~Michael_Nidd1; ~Ting_Dai2; ~Oishik_Chatterjee1; ~Pranjal_Gupta2; ~Suranjana_Samanta1; ~Pooja_Aggarwal1; ~Rong_Lee1; ~Jae-wook_Ahn2; ~Debanjana_Kar1; ~Amit_Paradkar1; ~Yu_Deng4; ~Pratibha_Moogi1; ~Prateeti_Mohapatra1; ~Naoki_Abe1; ~Chandrasekhar_Narayanaswami1; ~Tianyin_Xu1; ~Lav_R._Varshney1; ~Ruchi_Mahindru1; ~Anca_Sailer1; ~Laura_Shwartz1; ~Daby_Sow1; ~Nicholas_C._M._Fuller1; ~Ruchir_Puri1,"{'value': ['Benchmark', 'GenAI', 'Agents', 'IT Automation']}","{'value': 'Realizing the vision of using AI agents to automate critical IT tasks depends on the ability to measure and understand effectiveness of proposed solutions. We introduce ITBench, a framework that offers a systematic methodology for benchmarking AI agents to address real-world IT automation tasks. Our initial release targets three key areas: Site Reliability Engineering (SRE), Compliance and Security Operations (CISO), and Financial Operations (FinOps). The design enables AI researchers to understand the challenges and opportunities of AI agents for IT automation with push-button workflows and interpretable metrics. IT-Bench includes an initial set of 102 real-world scenarios, which can be easily extended by community contributions. Our results show that agents powered by state-of-the-art models resolve only 11.4% of SRE scenarios, 25.2% of CISO scenarios, and 25.8% of FinOps scenarios (excluding anomaly detection). For FinOps-specific anomaly detection (AD) scenarios, AI agents achieve an F1 score of 0.35. We expect ITBench to be a key enabler of AI-driven IT automation that is correct, safe, and fast. IT-Bench, along with a leaderboard and sample agent implementations, is available at https://github.com/ibm/itbench.'}",https://openreview.net{'value': '/pdf/d2122a3a706c4c7cd0d382ee9b13da641bd1fe5a.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=jMNQaNbjQl,{'value': 'Leveraging Offline Data in Linear Latent Contextual Bandits'},Chinmaya Kausik; Kevin Tan; Ambuj Tewari,~Chinmaya_Kausik1; ~Kevin_Tan3; ~Ambuj_Tewari1,"{'value': ['bandits', 'latent bandits', 'hybrid RL', 'online learning with offline datasets', 'dimensionality reduction', 'linear bandits']}","{'value': 'Leveraging offline data is an attractive way to accelerate online sequential decision-making. However, it is crucial to account for latent states in users or environments in the offline data, and latent bandits form a compelling model for doing so. In this light, we design end-to-end latent bandit algorithms capable of handing uncountably many latent states. We focus on a linear latent contextual bandit &mdash; a linear bandit where each user has its own high-dimensional reward parameter in $\\mathbb{R}^{d_A}$, but reward parameters across users lie in a low-rank latent subspace of dimension $d_K \\ll d_A$. First, we provide an offline algorithm to learn this subspace with provable guarantees. We then present two online algorithms that utilize the output of this offline algorithm to accelerate online learning. The first enjoys $\\tilde O(\\min(d_A\\sqrt{T}, d_K\\sqrt{T}(1+\\sqrt{d_AT/d_KN})))$ regret guarantees, so that the effective dimension is lower when the size $N$ of the offline dataset is larger. We prove a matching lower bound on regret, showing that our algorithm is minimax optimal. The second is a practical algorithm that enjoys only a slightly weaker guarantee, but is computationally efficient. We also establish the efficacy of our methods using experiments on both synthetic data and real-life movie recommendation data from MovieLens. Finally, we theoretically establish the generality of the latent bandit model by proving a de Finetti theorem for stateless decision processes.'}",https://openreview.net{'value': '/pdf/5768a6bd1b4b1a4996c12dbf9f0355d6870bffe1.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=jMKaATBEKb,{'value': 'Behavior-agnostic Task Inference for Robust Offline In-context Reinforcement Learning'},Long Ma; Fangwei Zhong; Yizhou Wang,~Long_Ma5; ~Fangwei_Zhong3; ~Yizhou_Wang1,"{'value': ['In-context Reinforcement Learning', 'Distribution Shift', 'Meta-Reinforcement Learning', 'Task Inference', 'Offline Reinforcement Learning']}","{'value': 'The ability to adapt to new environments with noisy dynamics and unseen objectives is crucial for AI agents. In-context reinforcement learning (ICRL) has emerged as a paradigm to build adaptive policies, employing a **context** trajectory of the test-time interactions to infer the true task and the corresponding optimal policy efficiently without gradient updates. However, ICRL policies heavily rely on context trajectories, making them vulnerable to distribution shifts from training to testing and degrading performance, particularly in offline settings where the training data is static. In this paper, we highlight that most existing offline ICRL methods are trained for approximate Bayesian inference based on the training distribution, rendering them vulnerable to distribution shifts at test time and resulting in poor generalization. To address this, we introduce Behavior-agnostic Task Inference (BATI) for ICRL, a model-based maximum-likelihood solution to infer the task representation robustly. In contrast to previous methods that rely on a learned encoder as the approximate posterior, BATI focuses purely on dynamics, thus insulating itself against the behavior of the context collection policy. Experiments on MuJoCo environments demonstrate that BATI effectively interprets out-of-distribution contexts and outperforms other methods, even in the presence of significant environmental noise.'}",https://openreview.net{'value': '/pdf/abe4f2f70df294e019ec70e3010eb84670af9ced.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=jHLSnYNt1m,{'value': 'Counterfactual Effect Decomposition in Multi-Agent Sequential Decision Making'},Stelios Triantafyllou; Aleksa Sukovic; Yasaman Zolfimoselo; Goran Radanovic,~Stelios_Triantafyllou1; ~Aleksa_Sukovic1; ~Yasaman_Zolfimoselo2; ~Goran_Radanovic1,"{'value': ['counterfactual reasoning', 'causal explanation formula', 'multi-agent Markov decision processes', 'accountability']}","{'value': 'We address the challenge of explaining counterfactual outcomes in multi-agent Markov decision processes. In particular, we aim to explain the total counterfactual effect of an agent\'s action on the outcome of a realized scenario through its influence on the environment dynamics and the agents\' behavior. To achieve this, we introduce a novel causal explanation formula that decomposes the counterfactual effect by attributing to each agent and state variable a score reflecting their respective contributions to the effect. First, we show that the total counterfactual effect of an agent\'s action can be decomposed into two components: one measuring the effect that propagates through all subsequent agents\' actions and another related to the effect that propagates through the state transitions. Building on recent advancements in causal contribution analysis, we further decompose these two effects as follows. For the former, we consider agent-specific effects -- a causal concept that quantifies the counterfactual effect of an agent\'s action that propagates through a subset of agents. Based on this notion, we use Shapley value to attribute the effect to individual agents. For the latter, we consider the concept of structure-preserving interventions and attribute the effect to state variables based on their ""intrinsic\'\' contributions. Through extensive experimentation, we demonstrate the interpretability of our approach in a Gridworld environment with LLM-assisted agents and a sepsis management simulator.'}",https://openreview.net{'value': '/pdf/2f7d4d2bfa2d4174af3cfb3e5252d97c84dea050.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=j68NJfjMVH,{'value': 'Online Sparsification of  Bipartite-Like Clusters in Graphs'},Joyentanuj Das; Suranjan De; He Sun,~Joyentanuj_Das1; ~Suranjan_De2; ~He_Sun5,"{'value': ['bipartite-like components', 'sparsification', 'online algorithms']}","{'value': 'Graph clustering is an important algorithmic technique for analysing massive graphs, and has been widely applied in many research fields of data science. While the objective of most   graph clustering algorithms is to find a vertex set of low conductance, there has been a sequence of recent studies that highlight the importance of the inter-connection between clusters when analysing real-world datasets. Following this line of research, in this work we study bipartite-like clusters and present efficient and  online algorithms that  find such clusters in both undirected graphs and directed ones. We   conduct experimental studies on both synthetic and real-world datasets, and show that our algorithms significantly speedup the running time of existing clustering algorithms while preserving their effectiveness.'}",https://openreview.net{'value': '/pdf/37691b4e2a21f0f721fad9a9af90f4d29ca4581e.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=imcyVlzpXh,{'value': 'Multi-agent Architecture Search via Agentic Supernet'},Guibin Zhang; Luyang Niu; Junfeng Fang; Kun Wang; LEI BAI; Xiang Wang,~Guibin_Zhang1; ~Luyang_Niu1; ~Junfeng_Fang1; ~Kun_Wang15; ~LEI_BAI1; ~Xiang_Wang6,"{'value': ['LLM-agent', 'Agentic Workflows', 'Multi-agent System']}","{'value': 'Large Language Model (LLM)-empowered multi-agent systems extend the cognitive boundaries of individual agents through disciplined collaboration and interaction, while constructing these systems often requires labor-intensive manual designs. Despite the availability of methods to automate the design of agentic workflows, they typically seek to identify a static, complex, one-size-fits-all system, which, however, fails to dynamically allocate inference resources based on the difficulty and domain of each query. To address this challenge, we shift away from the pursuit of a monolithic agentic system, instead optimizing the \\textbf{agentic supernet}, a probabilistic and continuous distribution of agentic architectures. We introduce \\textbf{MaAS}, an automated framework that samples query-dependent agentic systems from the supernet, delivering high-quality solutions and tailored resource allocation (\\textit{e.g.}, LLM calls, tool calls, token cost). Comprehensive evaluation across six benchmarks demonstrates that MaAS \\textbf{(I)} requires only $6\\\\sim45\\\\%$ of the inference costs of existing handcrafted or automated multi-agent systems, \\textbf{(II)} surpasses them by $0.54\\\\%\\sim11.82\\\\%$, and \\textbf{(III)} enjoys superior cross-dataset and cross-LLM-backbone transferability.'}",https://openreview.net{'value': '/pdf/46a781e93da44fdacc085588e4eeb8edc5f20439.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=ihUi76a4u7,{'value': 'How to Synthesize Text Data without Model Collapse?'},Xuekai Zhu; Daixuan Cheng; Hengli Li; Kaiyan Zhang; Ermo Hua; Xingtai Lv; Ning Ding; Zhouhan Lin; Zilong Zheng; Bowen Zhou,~Xuekai_Zhu1; ~Daixuan_Cheng1; ~Hengli_Li1; ~Kaiyan_Zhang1; ~Ermo_Hua1; ~Xingtai_Lv1; ~Ning_Ding5; ~Zhouhan_Lin1; ~Zilong_Zheng1; ~Bowen_Zhou8,"{'value': ['synthetic data', 'model collapse']}","{'value': 'Model collapse in synthetic data indicates that iterative training on self-generated data leads to a gradual decline in performance. With the proliferation of AI models, synthetic data will fundamentally reshape the web data ecosystem. Future GPT-$\\{n\\}$ models will inevitably be trained on a blend of synthetic and human-produced data. In this paper, we focus on two questions: what is the impact of synthetic data on language model training, and how to synthesize data without model collapse? We first pre-train language models across different proportions of synthetic data, revealing a negative correlation between the proportion of synthetic data and model performance. We further conduct statistical analysis on synthetic data to uncover distributional shift phenomenon and over-concentration of n-gram features. Inspired by the above findings, we propose token editing on human-produced data to obtain semi-synthetic data. As a proof of concept, we theoretically demonstrate that token-level editing can prevent model collapse, as the test error is constrained by a finite upper bound. We conduct extensive experiments on pre-training from scratch, continual pre-training, and supervised fine-tuning. The results validate our theoretical proof that token-level editing improves data quality and enhances model performance.'}",https://openreview.net{'value': '/pdf/246df417175bd03d15d19c279b491d8dcb9a4ba3.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=ibX0A4agKU,{'value': 'Fraud-Proof Revenue Division on Subscription Platforms'},Abheek Ghosh; Tzeh Yuan Neoh; Nicholas Teh; Giannis Tyrovolas,~Abheek_Ghosh1; ~Tzeh_Yuan_Neoh2; ~Nicholas_Teh2; ~Giannis_Tyrovolas1,"{'value': ['fraud-proof', 'revenue division', 'subscription platforms', 'mechanism design']}","{'value': 'We study a model of subscription-based platforms where users pay a fixed fee for unlimited access to content, and creators receive a share of the revenue. Existing approaches to detecting fraud predominantly rely on machine learning methods, engaging in an ongoing arms race with bad actors. We explore revenue division mechanisms that inherently disincentivize manipulation. We formalize three types of manipulation-resistance axioms and examine which existing rules satisfy these. We show that a mechanism widely used by streaming platforms, not only fails to prevent fraud, but also makes detecting manipulation computationally intractable. We also introduce a novel rule, ScaledUserProp, that satisfies all three manipulation-resistance axioms. Finally, experiments with both real-world and synthetic streaming data support ScaledUserProp as a fairer alternative compared to existing rules.'}",https://openreview.net{'value': '/pdf/9a1a897850a89d59f5fd26d77835617add88775d.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=iTevNo8PzG,{'value': 'Automated Hypothesis Validation with Agentic Sequential Falsifications'},Kexin Huang; Ying Jin; Ryan Li; Michael Y. Li; Emmanuel Candes; Jure Leskovec,~Kexin_Huang1; ~Ying_Jin4; ~Ryan_Li3; ~Michael_Y._Li1; ~Emmanuel_Candes1; ~Jure_Leskovec1,"{'value': ['LLM agent', 'hypothesis testing', 'sequential decision making', 'safe testing', 'data-driven discovery', 'sequential error control']}","{'value': ""Hypotheses are central to information acquisition, decision-making, and discovery. However, many real-world hypotheses are abstract, high-level statements that are difficult to validate directly. This challenge is further intensified by the rise of hypothesis generation from Large Language Models (LLMs), which are prone to hallucination and produce hypotheses in volumes that make manual validation impractical. Here we propose POPPER, an agentic framework for rigorous automated validation of free-form hypotheses. Guided by Karl Popper's principle of falsification, POPPER validates a hypothesis using LLM agents that design and execute falsification experiments targeting its measurable implications. A novel sequential testing framework ensures strict Type-I error control while actively gathering evidence from diverse observations, whether drawn from existing data or newly conducted procedures. We demonstrate POPPER on six domains including biology, economics, and sociology. POPPER delivers robust error control, high power, and scalability. Furthermore, compared to human scientists, POPPER achieved comparable performance in validating complex biological hypotheses while reducing time by 10 folds, providing a scalable, rigorous solution for hypothesis validation. POPPER is freely available at https://github.com/snap-stanford/POPPER.""}",https://openreview.net{'value': '/pdf/af66e5b5c9b71d73c71be1bfae7dd31838c77ac2.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=iIPAdNq9cq,{'value': 'Extracting Rare Dependence Patterns via Adaptive Sample Reweighting'},Yiqing Li; Yewei Xia; Xiaofei Wang; Zhengming Chen; Liuhua Peng; Mingming Gong; Kun Zhang,~Yiqing_Li1; ~Yewei_Xia1; ~Xiaofei_Wang3; ~Zhengming_Chen2; ~Liuhua_Peng1; ~Mingming_Gong1; ~Kun_Zhang1,"{'value': ['Independence tests', 'Sample reweighting', 'Causal discovery']}","{'value': 'Discovering dependence patterns between variables from observational data is a fundamental issue in data analysis. However, existing testing methods often fail to detect subtle yet critical patterns that occur within small regions of the data distribution--patterns we term rare dependence. These rare dependencies obscure the true underlying dependence structure in variables, particularly in causal discovery tasks. \nTo address this issue, we propose a novel testing method that combines kernel-based (conditional) independence testing with adaptive sample importance reweighting. By learning and assigning higher importance weights to data points exhibiting significant dependence, our method amplifies the patterns and can detect them successfully. Theoretically, we analyze the asymptotic distributions of the statistics in this method and show the uniform bound of the learning scheme. Furthermore, we integrate our tests into the PC algorithm, a constraint-based approach for causal discovery, equipping it to uncover causal relationships even in the presence of rare dependence. Empirical evaluation of synthetic and real-world datasets comprehensively demonstrates the efficacy of our method.'}",https://openreview.net{'value': '/pdf/5c8f5dff7f1570d75eb4753d28feb0b46cbfdd07.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=i9npQatSev,{'value': 'What Has a Foundation Model Found? Using Inductive Bias to Probe for World Models'},Keyon Vafa; Peter G. Chang; Ashesh Rambachan; Sendhil Mullainathan,~Keyon_Vafa1; ~Peter_G._Chang1; ~Ashesh_Rambachan1; ~Sendhil_Mullainathan2,"{'value': ['world models', 'foundation models', 'inductive bias', 'large language models']}","{'value': ""Foundation models are premised on the idea that sequence prediction can uncover deeper domain understanding, much like how Kepler's predictions of planetary motion later led to the discovery of Newtonian mechanics. However, evaluating whether these models truly capture deeper structure remains a challenge. We develop a technique for evaluating foundation models that examines how they adapt to synthetic datasets generated from some postulated world model. Our technique measures whether the foundation model's inductive bias aligns with the world model, and so we refer to it as an inductive bias probe. Across multiple domains, we find that foundation models can excel at their training tasks yet fail to develop inductive biases towards the underlying world model when adapted to new tasks. We particularly find that foundation models trained on orbital trajectories consistently fail to apply Newtonian mechanics when adapted to new physics tasks. Further analysis reveals that these models behave as if they develop task-specific heuristics that fail to generalize.""}",https://openreview.net{'value': '/pdf/c7bd7b6abc8d19b02ba885f5a08c806b90851ef7.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=i17GUNGzVq,{'value': 'Counterfactual Voting Adjustment for Quality Assessment and Fairer Voting in Online Platforms with Helpfulness Evaluation'},Chang Liu; Yixin Wang; Moontae Lee,~Chang_Liu43; ~Yixin_Wang1; ~Moontae_Lee1,"{'value': ['helpfulness voting', 'question answers', 'position bias', 'herding bias', 'online evaluation', 'causal effect']}","{'value': 'Efficient access to high-quality information is vital for online platforms. To promote more useful information, users not only create new content but also evaluate existing content, often through helpfulness voting. Although aggregated votes help service providers rank their user content, these votes are often biased by disparate accessibility per position and the cascaded influence of prior votes. For a fairer assessment of information quality, we propose the Counterfactual Voting Adjustment (CVA), a causal framework that accounts for the context in which individual votes are cast. Through preliminary and semi-synthetic experiments, we show that CVA effectively models the position and herding biases, accurately recovering the predefined content quality. In a real experiment, we demonstrate that reranking content based on the learned quality by CVA exhibits stronger alignment with both user sentiment and quality evaluation assessed by GPT-4o, outperforming system rankings based on aggregated votes and model-based rerankings without causal inference. Beyond the individual quality inference, our embeddings offer comparative insights into the behavioral dynamics of expert user groups across 120 major StackExchange communities.'}",https://openreview.net{'value': '/pdf/3c859dcbe35f24bd062323394218f4e386b8e85e.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=i0m3hToUwf,{'value': 'Learning Joint Interventional Effects from Single-Variable Interventions in Additive Models'},Armin Kekić; Sergio Hernan Garrido Mejia; Bernhard Schölkopf,~Armin_Kekić1; ~Sergio_Hernan_Garrido_Mejia1; ~Bernhard_Schölkopf1,"{'value': ['Causality', 'Treatment Effect', 'Causal Representation Learning']}","{'value': 'Estimating causal effects of joint interventions on multiple variables is crucial in many domains, but obtaining data from such simultaneous interventions can be challenging. Our study explores how to learn joint interventional effects using only observational data and single-variable interventions. We present an identifiability result for this problem, showing that for a class of nonlinear additive outcome mechanisms, joint effects can be inferred without access to joint interventional data. We propose a practical estimator that decomposes the causal effect into confounded and unconfounded contributions for each intervention variable. Experiments on synthetic data demonstrate that our method achieves performance comparable to models trained directly on joint interventional data, outperforming a purely observational estimator.'}",https://openreview.net{'value': '/pdf/c3b47be1b8eeaaf5be58f6c7241350001c548ee4.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=hz9LN310jZ,{'value': 'The impact of uncertainty on regularized learning in games'},Pierre-Louis Cauvin; Davide Legacci; Panayotis Mertikopoulos,~Pierre-Louis_Cauvin1; ~Davide_Legacci1; ~Panayotis_Mertikopoulos1,"{'value': ['Follow the regularized leader', 'uncertainty', 'Nash equilibrium']}","{'value': 'In this paper, we investigate how randomness and uncertainty influence learning in games. Specifically, we examine a perturbed variant of the dynamics of “follow-the-regularized-leader” (FTRL), where the players’ payoff observations and strategy updates are continually impacted by random shocks. Our findings reveal that, in a fairly precise sense, “uncertainty favors extremes”: in any game, regardless of the noise level, every player’s trajectory of play reaches an arbitrarily small neighborhood of a pure strategy in finite time (which we estimate). Moreover, even if the player does not ultimately settle at this strategy, they return arbitrarily close to some\n(possibly different) pure strategy infinitely often. This prompts the question of which sets of pure strategies emerge as robust predictions of learning under uncertainty. We show that (a) the only possible limits of the FTRL dynamics under uncertainty are pure Nash equilibria; and (b) a span of pure strategies is stable and attracting if and only if it is closed under better replies. Finally, we turn to games where the deterministic dynamics are recurrent—such as zero-sum games with interior equilibria—and show that randomness disrupts this behavior, causing the stochastic dynamics to drift toward the boundary on average.'}",https://openreview.net{'value': '/pdf/d98b458d3c01713346302883cd518a15af70cadd.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=htP5YRXcS9,{'value': 'Craftium: Bridging Flexibility and Efficiency for Rich 3D Single- and Multi-Agent Environments'},Mikel Malagón; Josu Ceberio; Jose A. Lozano,~Mikel_Malagón1; ~Josu_Ceberio1; ~Jose_A._Lozano1,"{'value': ['environment', 'reinforcement learning', 'agent', 'embodied AI', 'open endedness']}","{'value': 'Advances in large models, reinforcement learning, and open-endedness have accelerated progress toward autonomous agents that can learn and interact in the real world. To achieve this, flexible tools are needed to create rich, yet computationally efficient, environments. While scalable 2D environments fail to address key real-world challenges like 3D navigation and spatial reasoning, more complex 3D environments are computationally expensive and lack features like customizability and multi-agent support. This paper introduces Craftium, a highly customizable and easy-to-use platform for building rich 3D single- and multi-agent environments. We showcase environments of different complexity and nature: from single- and multi-agent tasks to vast worlds with many creatures and biomes, and customizable procedural task generators. Benchmarking shows that Craftium significantly reduces the computational cost of alternatives of similar richness, achieving +2K steps per second more than Minecraft-based frameworks.'}",https://openreview.net{'value': '/pdf/a834b5fb79305e685bf19594caefd1d17a946dca.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=hrdLhNDAzp,{'value': 'MCU: An Evaluation Framework for Open-Ended Game Agents'},Xinyue Zheng; Haowei Lin; Kaichen He; Zihao Wang; QIANG FU; Haobo Fu; Zilong Zheng; Yitao Liang,~Xinyue_Zheng2; ~Haowei_Lin1; ~Kaichen_He1; ~Zihao_Wang23; ~QIANG_FU8; ~Haobo_Fu2; ~Zilong_Zheng1; ~Yitao_Liang1,"{'value': ['benchmark', 'automatic evaluation', 'agent']}","{'value': 'Developing AI agents capable of interacting with open-world environments to solve diverse tasks is a compelling challenge. However, evaluating such open-ended agents remains difficult, with current benchmarks facing scalability limitations. To address this, we introduce \\textit{Minecraft Universe} (MCU), a comprehensive evaluation framework set within the open-world video game Minecraft. MCU incorporates three key components: (1) an expanding collection of 3,452 composable atomic tasks that encompasses 11 major categories and 41 subcategories of challenges; (2) a task composition mechanism capable of generating infinite diverse tasks with varying difficulty; and (3) a general evaluation framework that achieves 91.5\\% alignment with human ratings for open-ended task assessment. Empirical results reveal that even state-of-the-art foundation agents struggle with the increasing diversity and complexity of tasks. These findings highlight the necessity of MCU as a robust benchmark to drive progress in AI agent development within open-ended environments. Our evaluation code and scripts are available at https://github.com/CraftJarvis/MCU.'}",https://openreview.net{'value': '/pdf/f293c1c135a7e3ab045d15897631d1f8efad035c.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=hEaiFYEx3a,"{'value': 'Data-Driven Selection of Instrumental Variables for Additive Nonlinear, Constant Effects Models'}",Xichen Guo; Feng Xie; Yan Zeng; Hao Zhang; Zhi Geng,~Xichen_Guo1; ~Feng_Xie1; ~Yan_Zeng2; ~Hao_Zhang61; ~Zhi_Geng1,{'value': ['Instrumental Variable; Testability; Causal Effect; Unmeasured Confounders; Causal Graphical Models']},"{'value': 'We consider the problem of selecting instrumental variables from observational data, a fundamental challenge in causal inference.  \nExisting methods mostly focus on additive linear, constant effects models, limiting their applicability in complex real-world scenarios.\nIn this paper, we tackle a more general and challenging setting: the additive non-linear, constant effects model. We first propose a novel testable condition, termed the Cross Auxiliary-based independent Test (CAT) condition, for selecting the valid IV set. We show that this condition is both necessary and sufficient for identifying valid instrumental variable sets within such a model under milder assumptions. Building on this condition, we develop a practical algorithm for selecting the set of valid instrumental variables. Extensive experiments on both synthetic and two real-world datasets demonstrate the effectiveness and robustness of our proposed approach, highlighting its potential for broader applications in causal analysis.'}",https://openreview.net{'value': '/pdf/604591c5f0e1afdb7da2148c522c657d1b4a466b.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=hE0uIz07cv,{'value': 'R.I.P.: Better Models by Survival of the Fittest Prompts'},Ping Yu; Weizhe Yuan; Olga Golovneva; Tianhao Wu; Sainbayar Sukhbaatar; Jason E Weston; Jing Xu,~Ping_Yu2; ~Weizhe_Yuan1; ~Olga_Golovneva1; ~Tianhao_Wu1; ~Sainbayar_Sukhbaatar1; ~Jason_E_Weston1; ~Jing_Xu5,"{'value': ['Data Filtering', 'Preference Optimization', 'Synthetic Data']}","{'value': 'Training data quality is one of the most important drivers of final model quality. In this work, we introduce a method for evaluating data integrity based on the assumption that low-quality input prompts result in high variance and low quality responses. This is achieved by measuring the rejected response quality and the reward gap between the chosen and rejected preference pair. Our method, Rejecting Instruction Preferences (RIP) can be used to filter prompts from existing training sets, or to make high quality synthetic datasets, yielding large performance gains across various benchmarks compared to unfiltered data. Using Llama 3.1-8B-Instruct, RIP improves AlpacaEval2 LC Win Rate by 9.4%, Arena-Hard by 8.7%, and WildBench by 9.9%. Using Llama 3.3-70B-Instruct, RIP improves Arena-Hard from 67.5 to 82.9, from 18th place to 6th overall in the leaderboard.'}",https://openreview.net{'value': '/pdf/330b70d3d63d038e13e986c5a868c1c6e368d6e7.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=h5TXCnnEyy,{'value': 'Towards Attributions of Input Variables in a Coalition'},Xinhao Zheng; Huiqi Deng; Quanshi Zhang,~Xinhao_Zheng2; ~Huiqi_Deng1; ~Quanshi_Zhang1,"{'value': ['Attribution methods', 'Shapley value']}","{'value': ""This paper focuses on the fundamental challenge of partitioning input variables in attribution methods for Explainable AI, particularly in Shapley value-based approaches. Previous methods always compute attributions given a predefined partition but lack theoretical guidance on how to form meaningful variable partitions. We identify that attribution conflicts arise when the attribution of a coalition differs from the sum of its individual variables' attributions. To address this, we analyze the numerical effects of AND-OR interactions in AI models and extend the Shapley value to a new attribution metric for variable coalitions. Our theoretical findings reveal that specific interactions cause attribution conflicts, and we propose three metrics to evaluate coalition faithfulness. Experiments on synthetic data, NLP, image classification, and the game of Go validate our approach, demonstrating consistency with human intuition and practical applicability.""}",https://openreview.net{'value': '/pdf/20046ae2dc16a7bfbfcb4aec5091bd080e85de42.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=gt1MmGaKdZ,{'value': 'MELON: Provable Defense Against Indirect Prompt Injection Attacks in AI Agents'},Kaijie Zhu; Xianjun Yang; Jindong Wang; Wenbo Guo; William Yang Wang,~Kaijie_Zhu1; ~Xianjun_Yang1; ~Jindong_Wang4; ~Wenbo_Guo1; ~William_Yang_Wang2,"{'value': ['Indirect prompt injection', 'Agent system for tool use', 'Large langugae models']}","{'value': 'Recent research has explored that LLM agents are vulnerable to indirect prompt injection (IPI) attacks, where malicious tasks embedded in tool-retrieved information can redirect the agent to take unauthorized actions. Existing defenses against IPI have significant limitations: either require essential model training resources, lack effectiveness against sophisticated attacks, or harm the normal utilities. We present MELON (Masked re-Execution and TooL comparisON), a novel IPI defense. Our approach builds on the observation that under a successful attack, the agent’s next action becomes less dependent on user tasks and more on malicious tasks. Following this, we design MELON to detect attacks by re-executing the agent’s trajectory with a masked user prompt modified through a masking function. We identify an attack if the actions generated in the original and masked executions are similar. We also include three key designs to reduce the potential false positives and false negatives. Extensive evaluation on the IPI benchmark AgentDojo demonstrates that MELON outperforms SOTA defenses in both attack prevention and utility preservation. Moreover, we show that combining MELON with a SOTA prompt augmentation defense (denoted as MELON-Aug) further improves its performance. We also conduct a detailed ablation study to validate our key designs. Code is available at https://github.com/kaijiezhu11/MELON.'}",https://openreview.net{'value': '/pdf/455cec253a3c4390498bbee22b03a4e4f1b58864.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=gqZO3eSZRy,{'value': 'Galileo: Learning Global & Local Features of Many Remote Sensing Modalities'},Gabriel Tseng; Anthony Fuller; Marlena Reil; Henry Herzog; Patrick Beukema; Favyen Bastani; James R Green; Evan Shelhamer; Hannah Kerner; David Rolnick,~Gabriel_Tseng1; ~Anthony_Fuller1; ~Marlena_Reil1; ~Henry_Herzog1; ~Patrick_Beukema1; ~Favyen_Bastani1; ~James_R_Green1; ~Evan_Shelhamer2; ~Hannah_Kerner1; ~David_Rolnick1,"{'value': ['remote sensing', 'ai for good', 'land cover mapping', 'satellite data', 'agriculture']}","{'value': 'We introduce a highly multimodal transformer to represent many remote sensing modalities - multispectral optical, synthetic aperture radar, elevation, weather, pseudo-labels, and more - across space and time. These inputs are useful for diverse remote sensing tasks, such as crop mapping and flood detection. However, learning shared representations of remote sensing data is challenging, given the diversity of relevant data modalities, and because objects of interest vary massively in scale, from small boats (1-2 pixels and fast) to glaciers (thousands of pixels and slow). We present a novel self-supervised learning algorithm that extracts multi-scale features across a flexible set of input modalities through masked modeling. Our dual global and local contrastive losses differ in their targets (deep representations vs. shallow input projections) and masking strategies (structured vs. not). Our Galileo is a single generalist model that outperforms SoTA specialist models for satellite images and pixel time series across eleven benchmarks and multiple tasks.'}",https://openreview.net{'value': '/pdf/a499de7fec7be671215836a344682b595c3f03f7.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=glvtfXlzCS,{'value': 'Permutation-Free High-Order Interaction Tests'},Zhaolu Liu; Robert Peach; Mauricio Barahona,~Zhaolu_Liu1; ~Robert_Peach1; ~Mauricio_Barahona1,{'value': ['high-order interaction; kernel method; permutation-free']},"{'value': 'Kernel-based hypothesis tests offer a flexible, non-parametric tool to detect high-order interactions in multivariate data, beyond pairwise relationships. Yet the scalability of such tests is limited by the computationally demanding permutation schemes used to generate null approximations. Here we introduce a family of permutation-free high-order tests for joint independence and partial factorisations of $d$ variables. Our tests eliminate the need for permutation-based approximations by leveraging V-statistics and a novel cross-centring technique to yield test statistics with a standard normal limiting distribution under the null. We present implementations of the tests and showcase their efficacy and scalability through synthetic datasets. We also show applications inspired by causal discovery and feature selection, which highlight both the importance of high-order interactions in data and the need for efficient computational methods.'}",https://openreview.net{'value': '/pdf/c6997a5b1f8f56f75ac54718b54adaf2874fc6e6.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=ggyHPOXLGH,{'value': 'Variational Counterfactual Intervention Planning to Achieve Target Outcomes'},Xin Wang; Shengfei Lyu; Chi Luo; Xiren Zhou; Huanhuan Chen,~Xin_Wang46; ~Shengfei_Lyu1; ~Chi_Luo1; ~Xiren_Zhou2; ~Huanhuan_Chen1,"{'value': ['causal inference', 'counterfactual reasoning', 'counterfactual target achievement']}","{'value': 'A key challenge in personalized healthcare is identifying optimal intervention sequences to guide temporal systems toward target outcomes, a novel problem we formalize as counterfactual target achievement. In addressing this problem, directly adopting counterfactual estimation methods face compounding errors due to the unobservability of counterfactuals. To overcome this, we propose Variational Counterfactual Intervention Planning (VCIP), which reformulates the problem by modeling the conditional likelihood of achieving target outcomes, implemented through variational inference. By leveraging the g-formula to bridge the gap between interventional and observational log-likelihoods, VCIP enables reliable training from observational data. Experiments on both synthetic and real-world datasets show that VCIP significantly outperforms existing methods in target achievement accuracy.'}",https://openreview.net{'value': '/pdf/daefc16ca45223b44aa54d98c2fa39ec9030120f.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=ggERt5kcpa,{'value': 'Matrix Completion with Incomplete Side Information via Orthogonal Complement Projection'},Gengshuo Chang; Wei Zhang; Lehan Zhang,~Gengshuo_Chang1; ~Wei_Zhang71; ~Lehan_Zhang1,"{'value': ['matrix completion', 'side information', 'PAC learning theory', 'orthogonal complement projection']}","{'value': 'Matrix completion aims to recover missing entries in a data matrix using a subset of observed entries. Previous studies show that side information can greatly improve completion accuracy, but most assume perfect side information, which is rarely available in practice.   In this paper, we propose an orthogonal complement matrix completion (OCMC) model to address the challenge of matrix completion with incomplete side information. The model leverages the orthogonal complement projection derived from the available side information,   generalizing the traditional perfect side information matrix completion to the scenarios with incomplete side information.  Moreover, using probably approximately correct (PAC) learning theory, we show that the sample complexity of OCMC model decreases quadratically with the completeness level. To efficiently solve the OCMC model, a linearized Lagrangian algorithm is developed with convergence guarantees. Experimental results show that the proposed OCMC model outperforms state-of-the-art methods on both synthetic data and real-world applications.'}",https://openreview.net{'value': '/pdf/bb7ddd85697825ff365fc7d43cbecebda643e328.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=gdsZ3uMPsY,{'value': 'Adaptive Self-improvement LLM Agentic System for ML Library Development'},Genghan Zhang; Weixin Liang; Olivia Hsu; Kunle Olukotun,~Genghan_Zhang1; ~Weixin_Liang1; ~Olivia_Hsu1; ~Kunle_Olukotun1,"{'value': ['LLM agents', 'Self-improvement learning', 'Machine learning library']}","{'value': 'ML libraries, often written in architecture-specific programming languages (ASPLs) that target domain-specific architectures, are key to efficient ML systems. However, writing these high-performance ML libraries is challenging because it requires expert knowledge of both ML algorithms and the ASPL. Large language models (LLMs), on the other hand, have shown general coding capabilities. However, challenges remain when using LLMs for generating ML libraries using ASPLs because 1) this task is complicated even for human experts and 2) there are limited code examples due to the esoteric and evolving nature of ASPLs. We present an adaptive self-improvement agentic system that enables LLMs to perform such complex reasoning under limited data by iteratively improving their capability through self-generated experience. In order to evaluate the effectiveness of our system, we construct a benchmark of a typical ML library and generate ASPL code with both open and closed-source LLMs on this benchmark. Our results show improvements of up to $3.9\\times$ over a baseline single LLM.'}",https://openreview.net{'value': '/pdf/d013faeb37aa2c25302c9e10b9716c3324e908df.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=g5CijB2ERy,{'value': 'Cavia: Camera-controllable Multi-view Video Diffusion with View-Integrated Attention'},Dejia Xu; Yifan Jiang; Chen Huang; Liangchen Song; Thorsten Gernoth; Liangliang Cao; Zhangyang Wang; Hao Tang,~Dejia_Xu1; ~Yifan_Jiang2; ~Chen_Huang1; ~Liangchen_Song1; ~Thorsten_Gernoth1; ~Liangliang_Cao1; ~Zhangyang_Wang1; ~Hao_Tang16,"{'value': ['Video Generation', 'Camera Control', '3D Consistency']}","{'value': 'In recent years there have been remarkable breakthroughs in image-to-video generation. However, the 3D consistency and camera controllability of generated frames have remained unsolved. Recent studies have attempted to incorporate camera control into the generation process, but their results are often limited to simple trajectories or lack the ability to generate consistent videos from multiple distinct camera paths for the same scene. To address these limitations, we introduce Cavia, a novel framework for camera-controllable, multi-view video generation, capable of converting an input image into multiple spatiotemporally consistent videos. Our framework extends the spatial and temporal attention modules into view-integrated attention modules, improving both viewpoint and temporal consistency. This flexible design allows for joint training with diverse curated data sources, including scene-level static videos, object-level synthetic multi-view dynamic videos, and real-world monocular dynamic videos. To the best of our knowledge, Cavia is the first framework that enables users to generate multiple videos of the same scene with precise control over camera motion, while simultaneously preserving object motion. Extensive experiments demonstrate that Cavia surpasses state-of-the-art methods in terms of geometric consistency and perceptual quality.'}",https://openreview.net{'value': '/pdf/e9c60b4f52d33f36d1e729b6437c1a2e25bdc3a8.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=fzmtDDOcJ3,{'value': 'WildChat-50M: A Deep Dive Into the Role of Synthetic Data in Post-Training'},Benjamin Feuer; Chinmay Hegde,~Benjamin_Feuer1; ~Chinmay_Hegde1,"{'value': ['deep learning', 'machine learning', 'foundation models', 'llms', 'large language models', 'datasets', 'sft', 'post-training']}","{'value': 'Language model (LLM) post-training can refine behaviors and unlock new skills, but the open science supporting these post-training techniques is still in its infancy. One limiting factor has been the difficulty of conducting large-scale comparative analyses of synthetic data generating models and LLM judges. To close this gap, we introduce WildChat-50M, the largest public chat dataset to date. We extend the existing WildChat dataset to include responses not only from GPT, but from over 50 different open-weight models, ranging in size from 0.5B to 104B parameters. We conduct an extensive comparative analysis and demonstrate the potential of this dataset by creating Re-Wild, our own public SFT mix, which outperforms the recent Tulu-3 SFT mixture from Allen AI with only 40% as many samples.'}",https://openreview.net{'value': '/pdf/ee565e916a5eeca22f6131fbbc13764b1fdd6fba.pdf'},{'title_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=fyLsLTi1rE,{'value': 'Differentiable Structure Learning with Ancestral Constraints'},Taiyu Ban; Changxin Rong; Xiangyu Wang; Lyuzhou Chen; Xin Wang; Derui Lyu; Qinrui Zhu; Huanhuan Chen,~Taiyu_Ban1; ~Changxin_Rong1; ~Xiangyu_Wang7; ~Lyuzhou_Chen1; ~Xin_Wang46; ~Derui_Lyu1; ~Qinrui_Zhu1; ~Huanhuan_Chen1,"{'value': ['Causal discovery', 'Continuous DAG structure learning', 'Constrained optimization problem']}","{'value': 'Differentiable structure learning of causal directed acyclic graphs (DAGs) is an emerging field in causal discovery, leveraging powerful neural learners. However, the incorporation of ancestral constraints, essential for representing abstract prior causal knowledge, remains an open research challenge. This paper addresses this gap by introducing a generalized framework for integrating ancestral constraints. Specifically, we identify two key issues: the non-equivalence of relaxed characterizations for representing path existence and order violations among paths during optimization. In response, we propose a binary-masked characterization method and an order-guided optimization strategy, tailored to address these challenges. We provide theoretical justification for the correctness of our approach, complemented by experimental evaluations on both synthetic and real-world datasets.'}",https://openreview.net{'value': '/pdf/750191dcde544d50142bcb04dd529cf52e05807d.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=fxmJHFscQz,{'value': 'Learning Gaussian  DAG Models without Condition Number Bounds'},Constantinos Costis Daskalakis; ANTHIMOS VARDIS KANDIROS; Rui Yao,~Constantinos_Costis_Daskalakis1; ~ANTHIMOS_VARDIS_KANDIROS1; ~Rui_Yao2,"{'value': ['Bayesian network', 'graphical model', 'Gaussian DAG models', 'condition number']}","{'value': 'We study the problem of learning the topology of a directed Gaussian Graphical Model under the equal-variance assumption, where the graph has $n$ nodes and maximum in-degree $d$. Prior work has established that $O(d \\log n)$ samples are sufficient for this task. However, an important factor that is often overlooked in these analyses is the dependence on the condition number of the covariance matrix of the model. Indeed, all algorithms from prior work require a number of samples that grows polynomially with this condition number. In many cases this is unsatisfactory, since the condition number could grow polynomially with $n$, rendering these prior approaches impractical in high-dimensional settings. In this work, we provide an algorithm that recovers the underlying graph and prove that the number of samples required is independent of the condition number. Furthermore, we establish lower bounds that nearly match the upper bound up to a $d$-factor, thus providing an almost tight characterization of the true sample complexity of the problem. Moreover, under a further assumption that all the variances of the variables are bounded, we design a polynomial-time algorithm that recovers the underlying graph, at the cost of an additional polynomial dependence of the sample complexity on $d$. \nWe complement our theoretical findings with simulations on synthetic datasets that confirm our predictions.'}",https://openreview.net{'value': '/pdf/297f0327d089ee2d5d60ce14be7e8cdb2bd0b94f.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=fsf7LhbYdf,"{'value': 'From Low Rank Gradient Subspace Stabilization to Low-Rank Weights: Observations, Theories, and Applications'}",AJAY KUMAR JAISWAL; Yifan Wang; Lu Yin; Shiwei Liu; Runjin Chen; Jiawei Zhao; Ananth Grama; Yuandong Tian; Zhangyang Wang,~AJAY_KUMAR_JAISWAL1; ~Yifan_Wang14; ~Lu_Yin1; ~Shiwei_Liu2; ~Runjin_Chen1; ~Jiawei_Zhao2; ~Ananth_Grama1; ~Yuandong_Tian1; ~Zhangyang_Wang1,"{'value': ['Large language models', 'Gradient subspace', 'Memory-efficient training', 'Optimization', 'Low Rank Compression']}","{'value': 'Large Language Models (LLMs) matrices can often be expressed in low-rank format with potential to relax memory and compute resource requirements. Unlike previous works which pivot around developing novel matrix decomposition algorithms, in this work we focus to study the emerging non-uniform low-rank properties across weight matrices in LLMs through the lens of stabilizing gradient subspace. \\textit{Firstly,} we provide a theoretical framework to understand the stabilization of gradient subspaces through Hessian analysis. \\textit{Secondly,} we empirically establish a consequential relationship between the gradient dynamics and low-rank expressiveness of weight matrices. Our findings reveal that different LLM components exhibit varying levels of converged low-rank structure, necessitating a non-uniform rank reduction across them to minimize performance drop due to compression. In view of that, we present \\textit{Weight Low-Rank Projection} \\textbf{(WeLore)} that unifies weight compression and memory-efficient fine-tuning as ONE, in a data-agnostic and one-shot way. Going beyond only as a compression technique, WeLore categorizes weight matrices into Low-rank Components (LRCs) and Non-Low-rank Components (N-LRCs) based on their ability to express themselves as low-rank. Our gradient dynamics perspective illustrate that \\textit{LRCs tend to have better finetuning capabilities} and their standalone finetuning can closely mimic (sometimes outperform) the training loss trajectory and performance of full-finetuning with notable memory and compute footprint reduction. All codes and checkpoints will be released.'}",https://openreview.net{'value': '/pdf/84a40a724e43529a28845f461579277a2bc9378c.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=fgjN8B6xVX,{'value': 'High-Fidelity Simultaneous Speech-To-Speech Translation'},Tom Labiausse; Laurent Mazaré; Edouard Grave; Alexandre Défossez; Neil Zeghidour,~Tom_Labiausse1; ~Laurent_Mazaré1; ~Edouard_Grave1; ~Alexandre_Défossez1; ~Neil_Zeghidour1,"{'value': ['audio language models', 'speech translation', 'multimodal language models', 'speech-to-speech']}","{'value': 'We introduce Hibiki, a decoder-only model for simultaneous speech translation. Hibiki leverages a multistream language model to synchronously process source and target speech, and jointly produces text and audio tokens to perform speech-to-text and speech-to-speech translation. We furthermore address the fundamental challenge of simultaneous interpretation, which unlike its consecutive counterpart --where one waits for the end of the source utterance to start translating-- adapts its flow to accumulate just enough context to produce a correct translation in real-time, chunk by chunk. To do so, we introduce a weakly-supervised method that leverages the perplexity of an off-the-shelf text translation system to identify optimal delays on a per-word basis and create aligned synthetic data. After supervised training, Hibiki performs adaptive, simultaneous speech translation with vanilla temperature sampling. On a French-English simultaneous speech translation task, Hibiki demonstrates state-of-the-art performance in translation quality, speaker fidelity and naturalness. Moreover, the simplicity of its inference process makes it compatible with batched translation and even real-time on-device deployment. We provide examples on *huggingface.co/spaces/kyutai/hibiki-samples* as well as models and inference code at *github.com/kyutai-labs/hibiki*.'}",https://openreview.net{'value': '/pdf/4334c986d717ca8480ee013672ab57ec07587a7e.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=fbRbrtSvKm,{'value': 'Linear Contextual Bandits With Interference'},Yang Xu; Wenbin Lu; Rui Song,~Yang_Xu13; ~Wenbin_Lu1; ~Rui_Song2,"{'value': ['Contextual Bandits', 'Interference', 'Causality', 'Multi-agent', 'Asymptotics', 'Sublinear regret']}","{'value': ""Interference, a key concept in causal inference, extends the reward modeling process by accounting for the impact of one unit's actions on the rewards of others. In contextual bandit (CB) settings where multiple units are present in the same round, interference can significantly affect the estimation of expected rewards for different arms, thereby influencing the decision-making process. Although some prior work has explored multi-agent and adversarial bandits in interference-aware settings, how to model interference in CB remains significantly underexplored. In this paper, we introduce a systematic framework to address interference in Linear CB (LinCB), bridging the gap between causal inference and online decision-making. We propose a series of algorithms that explicitly quantify the interference effect in the reward modeling process and provide comprehensive theoretical guarantees, including sublinear regret bounds, finite sample upper bounds, and asymptotic properties. The effectiveness of our approach is demonstrated through simulations and a synthetic data generated based on MovieLens data.""}",https://openreview.net{'value': '/pdf/1178ca6dead411cd5e48a0298ed283815900ec56.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=fXCfT7ErvL,{'value': 'Towards a Formal Theory of Representational Compositionality'},Eric Elmoznino; Thomas Jiralerspong; Yoshua Bengio; Guillaume Lajoie,~Eric_Elmoznino1; ~Thomas_Jiralerspong1; ~Yoshua_Bengio1; ~Guillaume_Lajoie1,"{'value': ['compositionality', 'complexity', 'deep learning', 'representation', 'generalization']}","{'value': 'Compositionality is believed to be fundamental to intelligence. In humans, it underlies the structure of thought and language. In AI, it enables a powerful form of out-of-distribution generalization, in which a model systematically adapts to novel combinations of known concepts. However, while we have strong intuitions about what compositionality is, we lack satisfying formal definitions for it. Here, we propose such a definition called representational compositionality that is conceptually simple, quantitative, and grounded in algorithmic information theory. Intuitively, representational compositionality states that a compositional representation is both expressive and describable as a simple function of parts. We validate our definition on both real and synthetic data, and show how it unifies disparate intuitions from across the literature in both AI and cognitive science. We hope that our definition can inspire the design of novel, theoretically-driven models that better capture the mechanisms of compositional thought. We make our code available at https://github.com/EricElmoznino/complexity_compositionality.'}",https://openreview.net{'value': '/pdf/f15317b2ae4d0458ea51a47b404973458acfc4e6.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=fFBnsYRsPg,{'value': 'Breaking the Curse of Multiagency in Robust Multi-Agent Reinforcement Learning'},Laixi Shi; Jingchu Gai; Eric Mazumdar; Yuejie Chi; Adam Wierman,~Laixi_Shi1; ~Jingchu_Gai1; ~Eric_Mazumdar1; ~Yuejie_Chi1; ~Adam_Wierman1,"{'value': ['multi-agent reinforcement learning', 'robust Markov games', 'game theory', 'distribution shift', 'behavioral economics']}","{'value': ""Standard multi-agent reinforcement learning (MARL) algorithms are vulnerable to sim-to-real gaps. To address this, distributionally robust Markov games (RMGs) have been proposed to enhance robustness in MARL by optimizing the worst-case performance when game dynamics shift within a prescribed uncertainty set. RMGs remains under-explored, from reasonable problem formulation to the development of sample-efficient algorithms. Two notorious and open challenges are the formulation of the uncertainty set and whether the corresponding RMGs can overcome the curse of multiagency,  where the sample complexity scales exponentially with the number of agents. In this work, we propose a natural class of RMGs inspired by behavioral economics, where each agent's uncertainty set is shaped by both the environment and the integrated behavior of other agents. We first establish the well-posedness of this class of RMGs by proving the existence of game-theoretic solutions such as robust Nash equilibria and coarse correlated equilibria (CCE). Assuming access to a generative model, we then introduce a sample-efficient algorithm for learning the CCE whose sample complexity scales polynomially with all relevant parameters. To the best of our knowledge, this is the first algorithm to break the curse of multiagency for RMGs, regardless of the uncertainty set formulation.""}",https://openreview.net{'value': '/pdf/e10e87d34520973e4d07c7118115bf6d9925e3d1.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=f6lio2CZIM,{'value': 'QLASS: Boosting Language Agent Inference via Q-Guided Stepwise Search'},Zongyu Lin; Yao Tang; Xingcheng Yao; Da Yin; Ziniu Hu; Yizhou Sun; Kai-Wei Chang,~Zongyu_Lin1; ~Yao_Tang2; ~Xingcheng_Yao1; ~Da_Yin2; ~Ziniu_Hu1; ~Yizhou_Sun1; ~Kai-Wei_Chang1,"{'value': ['Agent', 'process reward model']}","{'value': 'Language agents have become a promising solution to complex interactive tasks. One of the key ingredients to the success of language agents is the reward model on the trajectory of the agentic workflow, which provides valuable guidance during training or inference. However, due to the lack of annotations of intermediate interactions, most existing works use an outcome reward model to optimize policies across entire trajectories. This may lead to sub-optimal policies and hinder the overall performance. To address this, we propose QLASS (Q-guided Language Agent Stepwise Search), to automatically generate annotations by estimating Q-values in a stepwise manner for open language agents. By introducing a reasoning tree and performing process reward modeling, QLASS provides effective intermediate guidance for each step. With the stepwise guidance, we propose a Q-guided generation strategy to enable language agents to better adapt to long-term value, resulting in significant performance improvement during model inference on complex interactive agent tasks. Notably, even with almost half the annotated data, QLASS retains strong performance, demonstrating its efficiency in handling limited supervision. We also empirically demonstrate that QLASS can lead to more effective decision making through qualitative analysis.'}",https://openreview.net{'value': '/pdf/35249bd8bba5562812b709db9282171592808a51.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=f3mQ0xYA1I,{'value': 'The Canary’s Echo: Auditing Privacy Risks of LLM-Generated Synthetic Text'},Matthieu Meeus; Lukas Wutschitz; Santiago Zanella-Beguelin; Shruti Tople; Reza Shokri,~Matthieu_Meeus1; ~Lukas_Wutschitz1; ~Santiago_Zanella-Beguelin1; ~Shruti_Tople2; ~Reza_Shokri1,"{'value': ['privacy', 'language models', 'synthetic data']}","{'value': 'How much information about training samples can be leaked through synthetic data generated by Large Language Models (LLMs)? Overlooking the subtleties of information flow in synthetic data generation pipelines can lead to a false sense of privacy. In this paper, we assume an adversary has access to some synthetic data generated by a LLM. We design membership inference attacks (MIAs) that target the training data used to fine-tune the LLM that is then used to synthesize data. The significant performance of our MIA shows that synthetic data leak information about the training data. Further, we find that canaries crafted for model-based MIAs are sub-optimal for privacy auditing when only synthetic data is released. Such out-of-distribution canaries have limited influence on the model’s output when prompted to generate useful, in-distribution synthetic data, which drastically reduces their effectiveness. To tackle this problem, we leverage the mechanics of auto-regressive models to design canaries with an in-distribution prefix and a high-perplexity suffix that leave detectable traces in synthetic data. This enhances the power of data-based MIAs and provides a better assessment of the privacy risks of releasing synthetic data generated by LLMs.'}",https://openreview.net{'value': '/pdf/c08bdf548d715b575a8fcfbee3432a17a7119cdf.pdf'},{'title_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=f3iBgm2Zi0,{'value': 'Proactive Agents for Multi-Turn Text-to-Image Generation Under Uncertainty'},Meera Hahn; Wenjun Zeng; Nithish Kannen; Rich Galt; Kartikeya Badola; Been Kim; Zi Wang,~Meera_Hahn1; ~Wenjun_Zeng4; ~Nithish_Kannen1; ~Rich_Galt1; ~Kartikeya_Badola1; ~Been_Kim1; ~Zi_Wang1,"{'value': ['Prompt Underspecification', 'Interpretability', 'Explainable AI', 'Dialog', 'Human-AI-Interaction', 'Agents']}","{'value': ""User prompts for generative AI models are often underspecified, leading to a misalignment between the user intent and models' understanding. As a result, users commonly have to painstakingly refine their prompts. We study this alignment problem in text-to-image (T2I) generation and propose a prototype for proactive T2I agents equipped with an interface to (1) actively ask clarification questions when uncertain, and (2) present their uncertainty about user intent as an understandable and editable belief graph. We build simple prototypes for such agents and propose a new scalable and automated evaluation approach using two agents, one with a ground truth intent (an image) while the other tries to ask as few questions as possible to align with the ground truth. We experiment over three image-text datasets: ImageInWords (Garg et al., 2024), COCO (Lin et al., 2014) and DesignBench, a benchmark we curated with strong artistic and design elements. Experiments over the three datasets demonstrate the proposed T2I agents' ability to ask informative questions and elicit crucial information to achieve successful alignment with at least 2 times higher VQAScore (Lin et al., 2024) than the standard T2I generation. Moreover, we conducted human studies and observed that at least 90% of human subjects found these agents and their belief graphs helpful for their T2I workflow, highlighting the effectiveness of our approach. Code and DesignBench can be found at https://github.com/google-deepmind/proactive_t2i_agents.""}",https://openreview.net{'value': '/pdf/05d38d5c7907dd6fded9ded03cef69648242c3a1.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=f21sRSRb1E,{'value': 'Global curvature for second-order optimization of neural networks'},Alberto Bernacchia,~Alberto_Bernacchia1,"{'value': ['Curvature', 'Second-order optimization', 'Symmetric neural networks']}","{'value': 'Second-order optimization methods, which leverage the local curvature of the loss function, have the potential to dramatically accelerate the training of machine learning models. \nHowever, these methods are often hindered by the computational burden of constructing and inverting large curvature matrices with $\\mathcal{O}(p^2)$ elements, where $p$ is the number of parameters. \nIn this work, we present a theory that predicts the \\emph{exact} structure of the global curvature by leveraging the intrinsic symmetries of neural networks, such as invariance under parameter permutations. \nFor Multi-Layer Perceptrons (MLPs), our approach reveals that the global curvature can be expressed in terms of $\\mathcal{O}(d^2 + L^2)$ independent factors, where $d$ is the number of input/output dimensions and $L$ is the number of layers, significantly reducing the computational burden compared to the $\\mathcal{O}(p^2)$ elements of the full matrix. \nThese factors can be estimated efficiently, enabling precise curvature computations.\nTo evaluate the practical implications of our framework, we apply second-order optimization to synthetic data, achieving markedly faster convergence compared to traditional optimization methods.\nOur findings pave the way for a better understanding of the loss landscape of neural networks, and for designing more efficient training methodologies in deep learning.\nCode: \\href{https://github.com/mtkresearch/symo_notebooks}{github.com/mtkresearch/symo\\_notebooks}'}",https://openreview.net{'value': '/pdf/8d496427965a11eb7f24c2fc71e70bf54cc60d92.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=ehcWKZ2nEn,"{'value': 'GTR: A General, Multi-View, and Dynamic Framework for Trajectory Representation Learning'}",Xiangheng Wang; Ziquan Fang; Chenglong Huang; Danlei Hu; Lu Chen; Yunjun Gao,~Xiangheng_Wang1; ~Ziquan_Fang1; ~Chenglong_Huang3; ~Danlei_Hu1; ~Lu_Chen5; ~Yunjun_Gao1,"{'value': ['Trajectory representation learning', 'mobility learning', 'spatio-temporal learning']}","{'value': 'Trajectory representation learning aims to transform raw trajectory data into compact and low-dimensional vectors that are suitable for downstream analysis. However, most existing methods adopt either a free-space view or a road-network view during the learning process, which limits their ability to capture the complex, multi-view spatiotemporal features inherent in trajectory data. Moreover, these approaches rely on task-specific model training, restricting their generalizability and effectiveness for diverse analysis tasks. To this end, we propose GTR, a general, multi-view, and dynamic Trajectory Representation framework built on a pre-train and fine-tune architecture. Specifically, GTR introduces a multi-view encoder that captures the intrinsic multi-view spatiotemporal features. Based on the pre-train and fine-tune architecture, we provide the spatio-temporal fusion pre-training with a spatio-temporal mixture of experts to dynamically combine spatial and temporal features, enabling seamless adaptation to diverse trajectory analysis tasks. Furthermore, we propose an online frozen-hot updating strategy to efficiently update the representation model, accommodating the dynamic nature of trajectory data. Extensive experiments on two real-world datasets demonstrate that GTR consistently outperforms 15 state-of-the-art methods across 6 mainstream trajectory analysis tasks. All source code and data are available at https://github.com/ZJU-DAILY/GTR.'}",https://openreview.net{'value': '/pdf/cae16f9a69f957790f303e75bc95c372b0ec8b9c.pdf'},{'title_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=egqOSr5gGw,{'value': 'Instance-Optimal Pure Exploration for Linear Bandits on Continuous Arms'},Sho Takemori; Yuhei Umeda; Aditya Gopalan,~Sho_Takemori1; ~Yuhei_Umeda1; ~Aditya_Gopalan1,"{'value': ['pure exploration', 'linear bandits', 'continous arm set']}","{'value': ""This paper studies a pure exploration problem with linear bandit feedback on continuous arm sets, aiming to identify an $\\epsilon$-optimal arm with high probability. Previous approaches for continuous arm sets have employed instance-independent methods due to technical challenges such as the infinite dimensionality of the space of probability measures and the non-smoothness of the objective function. This paper proposes a novel, tractable algorithm that addresses these challenges by leveraging a reparametrization of the sampling distribution and projected subgradient descent. However, this approach introduces new challenges related to the projection and reconstruction of the distribution from the reparametrization. We address these by focusing on the connection to the approximate Carath\\'eodory  problem. Compared to the original optimization problem on the infinite-dimensional space, our method is tractable, requiring only the solution of quadratic and fractional quadratic problems on the arm set. We establish an instance-dependent optimality for our method, and empirical results on synthetic data demonstrate its superiority over existing instance-independent baselines.""}",https://openreview.net{'value': '/pdf/f7baacdf495544a33a6dd5d332eb61e7600c0214.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=ef1UHxznNy,{'value': 'Active Learning with Selective Time-Step Acquisition for PDEs'},Yegon Kim; Hyunsu Kim; Gyeonghoon Ko; Juho Lee,~Yegon_Kim1; ~Hyunsu_Kim2; ~Gyeonghoon_Ko1; ~Juho_Lee2,"{'value': ['Active learning', 'Partial Differential Equation (PDE)']}","{'value': ""Accurately solving partial differential equations (PDEs) is critical to understanding complex scientific and engineering phenomena, yet traditional numerical solvers are computationally expensive. Surrogate models offer a more efficient alternative, but their development is hindered by the cost of generating sufficient training data from numerical solvers. In this paper, we present a novel framework for active learning (AL) in PDE surrogate modeling that reduces this cost. Unlike the existing AL methods for PDEs that always acquire entire PDE trajectories, our approach strategically generates only the most important time steps with the numerical solver, while employing the surrogate model to approximate the remaining steps. This dramatically reduces the cost incurred by each trajectory and thus allows the active learning algorithm to try out a more diverse set of trajectories given the same budget. To accommodate this novel framework, we develop an acquisition function that estimates the utility of a set of time steps by approximating its resulting variance reduction. We demonstrate the effectiveness of our method on several benchmark PDEs, including the Burgers' equation, Korteweg–De Vries equation, Kuramoto–Sivashinsky equation, the incompressible Navier-Stokes equation, and the compressible Navier-Stokes equation.\nExperiments show that our approach improves performance by large margins over the best existing method. Our method not only reduces average error but also the 99\\%, 95\\%, and 50\\% quantiles of error, which is rare for an AL algorithm. All in all, our approach offers a data-efficient solution to surrogate modeling for PDEs.""}",https://openreview.net{'value': '/pdf/23e02e1f37560a7542ffd1ef946fd57b881db1d6.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=eYBA77XorT,{'value': 'CAD-Editor: A Locate-then-Infill Framework with Automated Training Data Synthesis for Text-Based CAD Editing'},Yu Yuan; Shizhao Sun; Qi Liu; Jiang Bian,~Yu_Yuan5; ~Shizhao_Sun2; ~Qi_Liu3; ~Jiang_Bian1,"{'value': ['Computer Aided Design', 'Generative Models', 'Text-based Editing', 'Large Language Models']}","{'value': 'Computer Aided Design (CAD) is indispensable across various industries. \n\\emph{Text-based CAD editing}, which automates the modification of CAD models based on textual instructions, holds great potential but remains underexplored.\nExisting methods primarily focus on design variation generation or text-based CAD generation, either lacking support for text-based control or neglecting existing CAD models as constraints.\nWe introduce \\emph{CAD-Editor}, the first framework for text-based CAD editing. \nTo address the challenge of demanding triplet data with accurate correspondence for training, we propose an automated data synthesis pipeline. \nThis pipeline utilizes design variation models to generate pairs of original and edited CAD models and employs Large Vision-Language Models (LVLMs) to summarize their differences into editing instructions.\nTo tackle the composite nature of text-based CAD editing, we propose a locate-then-infill framework that decomposes the task into two focused sub-tasks: locating regions requiring modification and infilling these regions with appropriate edits. \nLarge Language Models (LLMs) serve as the backbone for both sub-tasks, leveraging their capabilities in natural language understanding and CAD knowledge.\nExperiments show that CAD-Editor achieves superior performance both quantitatively and qualitatively.'}",https://openreview.net{'value': '/pdf/598264748d6bb13c0e06d2d69cf54345e2aa9aaf.pdf'},{'title_filter': 'Data Synthesis'},ICML.cc,2025,Conference
https://openreview.net/forum?id=eUMGCipgtE,{'value': 'Aligning LLMs by Predicting Preferences from User Writing Samples'},Stéphane Aroca-Ouellette; Natalie Mackraz; Barry-John Theobald; Katherine Metcalf,~Stéphane_Aroca-Ouellette1; ~Natalie_Mackraz1; ~Barry-John_Theobald1; ~Katherine_Metcalf1,"{'value': ['NLP', 'LLM', 'preference learning', 'user demonstrations', 'benchmark']}","{'value': ""Accommodating human preferences is essential for creating aligned LLM agents that deliver personalized and effective interactions. Recent work has shown the potential for LLMs acting as writing agents to infer a description of user preferences. Agent alignment then comes from conditioning on the inferred preference description. However, existing methods often produce generic preference descriptions that fail to capture the unique and individualized nature of human preferences. This paper introduces PROSE, a method designed to enhance the precision of preference descriptions inferred from user writing samples. PROSE incorporates two key elements: (1) iterative refinement of inferred preferences, and (2) verification of inferred preferences across multiple user writing samples. We evaluate PROSE with several LLMs (i.e., Qwen2.5 7B and 72B Instruct, GPT-mini, and GPT-4o) on a summarization and an email writing task. We find that PROSE more accurately infers nuanced human preferences, improving the quality of the writing agent's generations over CIPHER (a state-of-the-art method for inferring preferences) by 33\\%. Lastly, we demonstrate that ICL and PROSE are complementary methods, and combining them provides up to a 9\\% improvement over ICL alone. Code: https://github.com/apple/ml-predict""}",https://openreview.net{'value': '/pdf/d6c98d214568eddf2a75033d95d4dda21396f9c3.pdf'},{'abstract_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=eIm0PQVu55,{'value': 'QMamba: On First Exploration of Vision Mamba for Image Quality Assessment'},Fengbin Guan; Xin Li; Zihao Yu; Yiting Lu; Zhibo Chen,~Fengbin_Guan1; ~Xin_Li28; ~Zihao_Yu3; ~Yiting_Lu1; ~Zhibo_Chen1,"{'value': ['Image Quality Assessment', 'State Space Model', 'Prompt Tuning']}","{'value': 'In this work, we take the first exploration of the recently popular foundation model, *i.e.,* State Space Model/Mamba, in image quality assessment (IQA), aiming at observing and excavating the perception potential in vision Mamba.  A series of works on Mamba has shown its significant potential in various fields, *e.g.,* segmentation and classification. However, the perception capability of Mamba remains under-explored. Consequently, we propose QMamba by revisiting and adapting the Mamba model for three crucial IQA tasks, *i.e.,* task-specific, universal, and transferable IQA, which reveals its clear advantages over existing foundational models, *e.g.,* Swin Transformer, ViT, and CNNs, in terms of perception and computational cost.  To improve the transferability of QMamba, we propose the StylePrompt tuning paradigm, where lightweight mean and variance prompts are injected to assist task-adaptive transfer learning of pre-trained QMamba for different downstream IQA tasks. Compared with existing prompt tuning strategies, our StylePrompt enables better perceptual transfer with lower computational cost.  Extensive experiments on multiple synthetic, authentic IQA datasets, and cross IQA datasets demonstrate the effectiveness of our proposed QMamba.'}",https://openreview.net{'value': '/pdf/1b16c173e2701ee2e4bf821b92723c53232a9fcd.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=drBVowFvqf,{'value': 'Temporal Distance-aware Transition Augmentation for Offline Model-based Reinforcement Learning'},Dongsu Lee; Minhae Kwon,~Dongsu_Lee1; ~Minhae_Kwon1,"{'value': ['State Representation', 'Latent World Model', 'Data Augmentation']}","{'value': 'The goal of offline reinforcement learning (RL) is to extract the best possible policy from the previously collected dataset considering the *out-of-distribution* (OOD) sample issue. Offline model-based RL (MBRL) is a captivating solution capable of alleviating such issues through a \\textit{state-action transition augmentation} with a learned dynamic model. Unfortunately, offline MBRL methods have been observed to fail in sparse rewarded and long-horizon environments for a long time. In this work, we propose a novel MBRL method, dubbed Temporal Distance-Aware Transition Augmentation (TempDATA), that generates additional transitions in a geometrically structured representation space, instead of state space. For comprehending long-horizon behaviors efficiently, our main idea is to learn state abstraction, which captures a *temporal distance* from both *trajectory and transition levels* of state space. Our experiments empirically confirm that TempDATA outperforms previous offline MBRL methods and achieves matching or surpassing the performance of diffusion-based trajectory augmentation and goal-conditioned RL on the D4RL AntMaze, FrankaKitchen, CALVIN, and pixel-based FrankaKitchen.'}",https://openreview.net{'value': '/pdf/2ed7998c128e22bff57a785baeaf3069de0425ac.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=dewZTXKwli,{'value': 'Bayesian Basis Function Approximation for Scalable Gaussian Process Priors in Deep Generative Models'},Mehmet Yiğit Balık; Maksim Sinelnikov; Priscilla Ong; Harri Lähdesmäki,~Mehmet_Yiğit_Balık1; ~Maksim_Sinelnikov2; ~Priscilla_Ong1; ~Harri_Lähdesmäki1,"{'value': ['Gaussian Process', 'High-dimensional time-series', 'Variational Autoencoder', 'Conditional Generation', 'Reproducing Kernel Hilbert Space']}","{'value': 'High-dimensional time-series datasets are common in domains such as healthcare and economics. Variational autoencoder (VAE) models, where latent variables are modeled with a Gaussian process (GP) prior, have become a prominent model class to analyze such correlated datasets. However, their applications are challenged by the inherent cubic time complexity that requires specific GP approximation techniques, as well as the general challenge of modeling both shared and individual-specific correlations across time. Though inducing points enhance GP prior VAE scalability, optimizing them remains challenging, especially since discrete covariates resist gradient‑based methods. In this work, we propose a scalable basis function approximation technique for GP prior VAEs that mitigates these challenges and results in linear time complexity, with a global parametrization that eliminates the need for amortized variational inference and the associated amortization gap, making it well-suited for conditional generation tasks where accuracy and efficiency are crucial. Empirical evaluations on synthetic and real-world benchmark datasets demonstrate that our approach not only improves scalability and interpretability but also drastically enhances predictive performance.'}",https://openreview.net{'value': '/pdf/1be1547d67526bd0562ffbf8afd08e1b0ed214ee.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=dNnA8ahuTY,{'value': 'Understanding Synthetic Context Extension via Retrieval Heads'},Xinyu Zhao; Fangcong Yin; Greg Durrett,~Xinyu_Zhao6; ~Fangcong_Yin1; ~Greg_Durrett1,"{'value': ['Large Language Models', 'Synthetic Data', 'Long Context', 'Retrieval Heads']}","{'value': 'Long-context LLMs are increasingly in demand for applications such as retrieval-augmented generation. To defray the cost of pretraining LLMs over long contexts, recent work takes an approach of synthetic context extension: fine-tuning LLMs with synthetically-generated long-context data. However, it remains unclear how and why this synthetic context extension imparts abilities for downstream long-context tasks. In this paper, we investigate fine-tuning on synthetic data for three long-context tasks that require retrieval and reasoning. We vary the realism of ""needle\'\' concepts to be retrieved and diversity of the surrounding ""haystack\'\' context, from using LLMs to construct synthetic documents to using templated relations and creating symbolic datasets. Although models trained on synthetic data underperform models trained on the real data, the impacts of both training settings can be understood via a shared feature of the attention computation, retrieval heads (Wu et al., 2024). The retrieval heads learned from synthetic data have high overlap with retrieval heads learned on real data. Furthermore, there is a strong correlation between the recall of heads learned and the downstream performance of a model, allowing us to interpret and predict the performance of models trained in different settings. Our results shed light on how to interpret synthetic data fine-tuning performance and how to approach creating better data for learning real-world LLM capabilities over long contexts.'}",https://openreview.net{'value': '/pdf/31806cc3f30bea634e6c848cf413e04469233041.pdf'},{'title_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=d8GDXPcoW8,{'value': 'BAnG: Bidirectional Anchored Generation for Conditional RNA Design'},Roman Klypa; Alberto Bietti; Sergei Grudinin,~Roman_Klypa1; ~Alberto_Bietti1; ~Sergei_Grudinin1,"{'value': ['generative modeling', 'sequential data', 'autoregressive generation', 'RNA design', 'biological sequences', 'deep learning models']}","{'value': 'Designing RNA molecules that interact with specific proteins is a critical challenge in experimental and computational biology. Existing computational approaches require a substantial amount of experimentally determined RNA sequences for each specific protein or a detailed knowledge of RNA structure, restricting their utility in practice. To address this limitation, we develop RNA-BAnG, a deep learning-based model designed to generate RNA sequences for protein interactions without these requirements. Central to our approach is a novel generative method, Bidirectional Anchored Generation (BAnG), which leverages the observation that protein-binding RNA sequences often contain functional binding motifs embedded within broader sequence contexts. We first validate our method on generic synthetic tasks involving similar localized motifs to those appearing in RNAs, demonstrating its benefits over existing generative approaches. We then evaluate our model on biological sequences, showing its effectiveness for conditional RNA sequence design given a binding protein.'}",https://openreview.net{'value': '/pdf/abc56c706871cdd391ad12baf0ef61c367a401d8.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=d2aGLPSpFz,{'value': 'Sanity Checking Causal Representation Learning on a Simple Real-World System'},Juan L. Gamella; Simon Bing; Jakob Runge,~Juan_L._Gamella1; ~Simon_Bing1; ~Jakob_Runge2,"{'value': ['causal representation learning', 'benchmarks', 'causality']}","{'value': 'We evaluate methods for causal representation learning (CRL) on a simple, real-world system where these methods are expected to work. The system consists of a controlled optical experiment specifically built for this purpose, which satisfies the core assumptions of CRL and where the underlying causal factors---the inputs to the experiment---are known, providing a ground truth. We select methods representative of different approaches to CRL and find that they all fail to recover the underlying causal factors. To understand the failure modes of the evaluated algorithms, we perform an ablation on the data by substituting the real data-generating process with a simpler synthetic equivalent. The results reveal a reproducibility problem, as most methods already fail on this synthetic ablation despite its simple data-generating process. Additionally, we observe that common assumptions on the mixing function are crucial for the performance of some of the methods but do not hold in the real data. Our efforts highlight the contrast between the theoretical promise of the state of the art and the challenges in its application. We hope the benchmark serves as a simple, real-world sanity check to further develop and validate methodology, bridging the gap towards CRL methods that work in practice. We make all code and datasets publicly available at <anonymized>.'}",https://openreview.net{'value': '/pdf/f49eb15381f8ea150aedc07d26d294f4b7c91ada.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=cumipBkkAR,{'value': 'InfoCons: Identifying Interpretable Critical Concepts in Point Clouds via Information Theory'},Feifei Li; Mi Zhang; Zhaoxiang Wang; Min Yang,~Feifei_Li7; ~Mi_Zhang2; ~Zhaoxiang_Wang1; ~Min_Yang12,"{'value': ['Information Theory', 'Interpretability', 'Point Cloud']}","{'value': 'Interpretability of point cloud (PC) models becomes imperative given their deployment in safety-critical scenarios such as autonomous vehicles. \nWe focus on attributing PC model outputs to interpretable critical concepts, defined as meaningful subsets of the input point cloud.\nTo enable human-understandable diagnostics of model failures, an ideal critical subset should be *faithful* (preserving points that causally influence predictions) and *conceptually coherent* (forming semantically meaningful structures that align with human perception).\nWe propose InfoCons, an explanation framework that applies information-theoretic principles to decompose the point cloud into 3D concepts, enabling the examination of their causal effect on model predictions with learnable priors.\nWe evaluate InfoCons on synthetic datasets for classification, comparing it qualitatively and quantitatively with four baselines. \nWe further demonstrate its scalability and flexibility on two real-world datasets and in two applications that utilize critical scores of PC.'}",https://openreview.net{'value': '/pdf/ec82b7b22c69e659fb3ecde54df091266ce462d0.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=crcxt5uy8x,{'value': 'Reinforcement Learning with Random Time Horizons'},Enric Ribera Borrell; Lorenz Richter; Christof Schuette,~Enric_Ribera_Borrell1; ~Lorenz_Richter1; ~Christof_Schuette1,"{'value': ['reinforcement learning', 'policy gradient theorem', 'random stopping times', 'optimal control']}","{'value': 'We extend the standard reinforcement learning framework to random time horizons. While the classical setting typically assumes finite and deterministic or infinite runtimes of trajectories, we argue that multiple real-world applications naturally exhibit random (potentially trajectory-dependent) stopping times. Since those stopping times typically depend on the policy, their randomness has an effect on policy gradient formulas, which we (mostly for the first time) derive rigorously in this work both for stochastic and deterministic policies. We present two complementary perspectives, trajectory or state-space based, and establish connections to optimal control theory. Our numerical experiments demonstrate that using the proposed formulas can significantly improve optimization convergence compared to traditional approaches.'}",https://openreview.net{'value': '/pdf/02b5219f82801d4077c5d4978cf84cf625dd1bc2.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=crCPLUtIuU,{'value': 'Chip Placement with Diffusion Models'},Vint Lee; Minh Nguyen; Leena Elzeiny; Chun Deng; Pieter Abbeel; John Wawrzynek,~Vint_Lee1; ~Minh_Nguyen10; ~Leena_Elzeiny1; ~Chun_Deng1; ~Pieter_Abbeel2; ~John_Wawrzynek1,"{'value': ['macro placement', 'diffusion', 'machine learning', 'chip design', 'synthetic data']}","{'value': 'Macro placement is a vital step in digital circuit design that defines the physical location of large collections of components, known as macros, on a 2D chip. Because key performance metrics of the chip are determined by the placement, optimizing it is crucial. Existing learning-based methods typically fall short because of their reliance on reinforcement learning (RL), which is slow and struggles to generalize, requiring online training on each new circuit. Instead, we train a diffusion model capable of placing new circuits zero-shot, using guided sampling in lieu of RL to optimize placement quality. To enable such models to train at scale, we designed a capable yet efficient architecture for the denoising model, and propose a novel algorithm to generate large synthetic datasets for pre-training. To allow zero-shot transfer to real circuits, we empirically study the design decisions of our dataset generation algorithm, and identify several key factors enabling generalization. When trained on our synthetic data, our models generate high-quality placements on unseen, realistic circuits, achieving competitive performance on placement benchmarks compared to state-of-the-art methods.'}",https://openreview.net{'value': '/pdf/902b5c576389f6c02d0a1fff514188c5dfc92e77.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=clLERWKNja,{'value': 'Bootstrapping Self-Improvement of Language Model Programs for Zero-Shot Schema Matching'},Nabeel Seedat; Mihaela van der Schaar,~Nabeel_Seedat1; ~Mihaela_van_der_Schaar2,"{'value': ['schema matching', 'healthcare', 'Large Language Models', 'data-centric AI']}","{'value': ""Schema matching -- the task of finding matches between attributes across disparate data sources with different tables and hierarchies -- is critical for creating interoperable machine learning (ML)-ready data. Addressing this fundamental data-centric problem has wide implications, especially in domains like healthcare, finance and e-commerce --- but also has the potential to benefit ML models more generally, by increasing the data available for ML model training. However, schema matching is a challenging ML task due to structural/hierarchical and semantic heterogeneity between different schemas. Previous ML approaches to automate schema matching have either required significant labeled data for model training, which is often unrealistic or suffer from poor zero-shot performance. To this end, we propose Matchmaker -  a compositional language model program for schema matching, comprised of candidate generation, refinement and confidence scoring. Matchmaker also self-improves in a zero-shot manner without the need for labeled demonstrations via a novel optimization approach, which constructs synthetic in-context demonstrations to guide the language model's reasoning process.  Empirically, we demonstrate on real-world medical schema matching benchmarks that Matchmaker outperforms previous ML-based approaches, highlighting its potential to accelerate data integration and interoperability of ML-ready data.""}",https://openreview.net{'value': '/pdf/59aa70134452a0f7107f0ca5a0706ffef45ae00b.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=ck7dvZFbRW,{'value': 'EVOLvE: Evaluating and Optimizing LLMs For In-Context Exploration'},Allen Nie; Yi Su; Bo Chang; Jonathan Lee; Ed H. Chi; Quoc V Le; Minmin Chen,~Allen_Nie1; ~Yi_Su2; ~Bo_Chang1; ~Jonathan_Lee4; ~Ed_H._Chi1; ~Quoc_V_Le1; ~Minmin_Chen1,"{'value': ['Exploration', 'In-Context Reinforcement Learning', 'Bandit']}","{'value': ""Despite their success in many domains, large language models (LLMs) remain under-studied in scenarios requiring optimal decision-making under uncertainty. This is crucial as many real-world applications, ranging from personalized recommendations to healthcare interventions, demand that LLMs not only predict but also actively learn to make optimal decisions through exploration. In this work, we measure LLMs' (in)ability to make optimal decisions in bandits, a state-less reinforcement learning setting relevant to many applications. We develop a comprehensive suite of environments, including both context-free and contextual bandits with varying task difficulties, to benchmark LLMs' performance. Motivated by the existence of optimal exploration algorithms, we propose efficient ways to integrate this algorithmic knowledge into LLMs: by providing explicit algorithm-guided support during inference; and through algorithm distillation via in-context demonstrations and fine-tuning, using synthetic data generated from these algorithms. Impressively, these techniques allow us to achieve superior exploration performance with smaller models, surpassing larger models on various tasks. We conducted an extensive ablation study to shed light on various factors, such as task difficulty and data representation, that influence the efficiency of LLM exploration. Additionally, we conduct a rigorous analysis of the LLM's exploration efficiency using the concept of regret, linking its ability to explore to the model size and underlying algorithm.""}",https://openreview.net{'value': '/pdf/a06474848ecd686ead21f6344b24c6f9d264cf69.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=cW9Ttnm1aC,{'value': 'Nonparametric Identification of Latent Concepts'},Yujia Zheng; Shaoan Xie; Kun Zhang,~Yujia_Zheng1; ~Shaoan_Xie4; ~Kun_Zhang1,"{'value': ['Concept Learning', 'Compositional Learning', 'Nonparametric Identification']}","{'value': 'We are born with the ability to learn concepts by comparing diverse observations. This helps us to understand the new world in a compositional manner and facilitates extrapolation, as objects naturally consist of multiple concepts. In this work, we argue that the cognitive mechanism of comparison, fundamental to human learning, is also vital for machines to recover true concepts underlying the data. This offers correctness guarantees for the field of concept learning, which, despite its impressive empirical successes, still lacks general theoretical support. Specifically, we aim to develop a theoretical framework for the identifiability of concepts with multiple classes of observations. We show that with sufficient diversity across classes, hidden concepts can be identified without assuming specific concept types, functional relations, or parametric generative models. Interestingly, even when conditions are not globally satisfied, we can still provide alternative guarantees for as many concepts as possible based on local comparisons, thereby extending the applicability of our theory to more flexible scenarios. Moreover, the hidden structure between classes and concepts can also be identified nonparametrically. We validate our theoretical results in both synthetic and real-world settings.'}",https://openreview.net{'value': '/pdf/0f90d014bdbd4050efb58164f2a8b888e22abcf4.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=cUNfm13VUR,{'value': 'Comparing Few to Rank Many: Active Human Preference Learning Using Randomized Frank-Wolfe Method'},Kiran Koshy Thekumparampil; Gaurush Hiranandani; Kousha Kalantari; Shoham Sabach; Branislav Kveton,~Kiran_Koshy_Thekumparampil1; ~Gaurush_Hiranandani1; ~Kousha_Kalantari1; ~Shoham_Sabach1; ~Branislav_Kveton1,"{'value': ['active learning', 'human preference learning', 'comparison feedback', 'optimal design', 'Frank-Wolfe method']}","{'value': 'We study learning human preferences from limited comparison feedback, a core machine learning problem that is at the center of reinforcement learning from human feedback (RLHF). We formulate the problem as learning a Plackett-Luce (PL) model from a limited number of $K$-subset comparisons over a universe of $N$ items, where typically $K \\ll N$. Our objective is to select the $K$-subsets such that all items can be ranked with minimal mistakes within the budget. We solve the problem using the D-optimal design, which minimizes the worst-case ranking loss under the estimated PL model. All known algorithms for this problem are computationally infeasible in our setting because we consider exponentially many subsets in $K$. To address this challenge, we propose a randomized Frank-Wolfe algorithm with memoization and sparse updates that has a low $O(N^2 + K^2)$ per-iteration complexity. We analyze it and demonstrate its empirical superiority on synthetic and open-source NLP datasets.'}",https://openreview.net{'value': '/pdf/bf05f501edc1ca9f2979bef5d6c125f616479259.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=bwidSkOyWF,{'value': 'AdvAgent: Controllable Blackbox Red-teaming on Web Agents'},Chejian Xu; Mintong Kang; Jiawei Zhang; Zeyi Liao; Lingbo Mo; Mengqi Yuan; Huan Sun; Bo Li,~Chejian_Xu1; ~Mintong_Kang1; ~Jiawei_Zhang9; ~Zeyi_Liao1; ~Lingbo_Mo1; ~Mengqi_Yuan3; ~Huan_Sun1; ~Bo_Li19,"{'value': ['Web Agents', 'Large Language Models', 'Prompt Injection Attack']}","{'value': 'Foundation model-based agents are increasingly used to automate complex tasks, enhancing efficiency and productivity. However, their access to sensitive resources and autonomous decision-making also introduce significant security risks, where successful attacks could lead to severe consequences. To systematically uncover these vulnerabilities, we propose AdvAgent, a black-box red-teaming framework for attacking web agents. Unlike existing approaches, AdvAgent employs a reinforcement learning-based pipeline to train an adversarial prompter model that optimizes adversarial prompts using feedback from the black-box agent. With careful attack design, these prompts effectively exploit agent weaknesses while maintaining stealthiness and controllability. Extensive evaluations demonstrate that AdvAgent achieves high success rates against state-of-the-art GPT-4-based web agents across diverse web tasks. Furthermore, we find that existing prompt-based defenses provide only limited protection, leaving agents vulnerable to our framework. These findings highlight critical vulnerabilities in current web agents and emphasize the urgent need for stronger defense mechanisms. We release code at https://ai-secure.github.io/AdvAgent/.'}",https://openreview.net{'value': '/pdf/f64244bb0a5279175399b26d6faada0bba34367c.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=buwLCdOHxO,{'value': 'Collapse or Thrive: Perils and Promises of Synthetic Data in a Self-Generating World'},Joshua Kazdan; Rylan Schaeffer; Apratim Dey; Matthias Gerstgrasser; Rafael Rafailov; David L. Donoho; Sanmi Koyejo,~Joshua_Kazdan1; ~Rylan_Schaeffer2; ~Apratim_Dey1; ~Matthias_Gerstgrasser1; ~Rafael_Rafailov1; ~David_L._Donoho1; ~Sanmi_Koyejo1,"{'value': ['model collapse', 'synthetic data', 'model-data feedback loops', 'data-model feedback loops', 'generative models', 'generative modeling', 'kernel density estimation', 'supervised finetuning']}","{'value': 'What happens when generative machine learning models are pretrained on web-scale datasets containing data generated by earlier models? Some prior work warns of “model collapse” as the web is overwhelmed by synthetic data; other work suggests the problem can be contained (i.e. collapse can be avoided) by managing how available data are used in pretraining. In this paper, we report experiments on three ways of using data (training-workflows), across three generative model task-settings (multivariate Gaussian estimation, kernel density estimation, and language-model fine-tuning) to further confirm the possibility of containment: (a) we confirm that the training-workflow of {\\it replacing} all real data by successive generations of purely synthetic data indeed suffers model collapse in all task-settings studied; (b) we consider the training-workflow of {\\it accumulating} synthetic data alongside real data and training on all data combined and confirming that, although the proportion of real data eventually becomes zero, models remain stable and their test losses do not diverge under this training-workflow; (c) we consider a training-workflow where real and synthetic data accumulate together but successive generations of pretraining are constrained to use fixed-size data subsets each generation. In this workflow, we observe slow and gradual rather than explosive degradation of test loss performance across generations. Our insights are particularly important when forecasting whether future frontier generative models will collapse or thrive, and our results open avenues for empirically and mathematically studying the context-dependent value of synthetic data.'}",https://openreview.net{'value': '/pdf/5b1eaa468699fbe6f6fe4fef45ab36a911f106cc.pdf'},{'title_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=bnhFueOeav,{'value': 'Robust Multi-Agent Reinforcement Learning with Stochastic Adversary'},Ziyuan Zhou; Guanjun Liu; Mengchu Zhou; Weiran Guo,~Ziyuan_Zhou1; ~Guanjun_Liu2; ~Mengchu_Zhou1; ~Weiran_Guo1,"{'value': ['Multi-Agent Reinforcement Learning', 'Adversarial Training', 'Stochastic Adversary', 'Entropy Maximization']}","{'value': ""The performance of models trained by Multi-Agent Reinforcement Learning (MARL) is sensitive to perturbations in observations, lowering their trustworthiness in complex environments. Adversarial training is a valuable approach to enhance their performance robustness. However, existing methods often overfit to adversarial perturbations of observations and fail to incorporate prior information about the policy adopted by their protagonist agent, i.e., the primary one being trained. To address this important issue, this paper introduces Adversarial Training with Stochastic Adversary (ATSA), where the proposed adversary is trained online alongside the protagonist agent. The former consists of Stochastic Director (SDor) and SDor-guided generaTor (STor). SDor performs policy perturbations by minimizing the expected team reward of protagonists and maximizing the entropy of its policy, while STor generates adversarial perturbations of observations by following SDor's guidance. We prove that SDor's soft policy converges to a global optimum according to factorized maximum-entropy MARL and leads to the optimal adversary. This paper also introduces an SDor-STor loss function to quantify the difference between a) perturbations in the agent's policy and b) those advised by SDor. We evaluate our ATSA on StarCraft II tasks and autonomous driving scenarios, demonstrating that a) it is robust against diverse perturbations of observations while maintaining outstanding performance in perturbation-free environments, and b) it outperforms the state-of-the-art methods.""}",https://openreview.net{'value': '/pdf/5da5a3fdc53d5712b7c8cde2342e02bfbc55cf8a.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=bkiM54QftZ,{'value': 'On the Resilience of LLM-Based Multi-Agent Collaboration with Faulty Agents'},Jen-tse Huang; Jiaxu Zhou; Tailin Jin; Xuhui Zhou; Zixi Chen; Wenxuan Wang; Youliang Yuan; Michael Lyu; Maarten Sap,~Jen-tse_Huang1; ~Jiaxu_Zhou1; ~Tailin_Jin1; ~Xuhui_Zhou1; ~Zixi_Chen5; ~Wenxuan_Wang2; ~Youliang_Yuan1; ~Michael_Lyu1; ~Maarten_Sap1,"{'value': ['Multi-Agent Collaboration', 'Large Language Models', 'Resilience']}","{'value': 'Large language model-based multi-agent systems have shown great abilities across various tasks due to the collaboration of expert agents, each focusing on a specific domain. However, the impact of clumsy or even malicious agents—those who frequently make errors in their tasks—on the overall performance of the system remains underexplored. This paper investigates: (1) What is the resilience of various system structures (e.g., A$\\rightarrow$B$\\rightarrow$C, A$\\leftrightarrow$B$\\leftrightarrow$C) under faulty agents, on different downstream tasks? (2) How can we increase system resilience to defend against these agents? To simulate faulty agents, we propose two approaches—AutoTransform and AutoInject—which introduce mistakes into the agents\' responses. Experiments on four downstream tasks using six systems show that the ""hierarchical"" structure, i.e., A$\\rightarrow$(B$\\leftrightarrow$C), exhibits superior resilience with the lowest performance drop of 5.5%, compared to 10.5% and 23.7% of other two structures. To further improve resilience, we introduce (1) Challenger, that introduces a mechanism for each agent to challenge others\' outputs, and (2) Inspector, an additional agent to review and correct messages, recovering up to 96.4% errors made by faulty agents. Our code and data are available at https://github.com/CUHK-ARISE/MAS-Resilience.'}",https://openreview.net{'value': '/pdf/9e2edbde1577fb0c18c09cfef297de459fecb239.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=bUGdGaNFhi,{'value': 'TimePoint: Accelerated Time Series Alignment via Self-Supervised Keypoint and Descriptor Learning'},Ron Shapira Weber; Shahar benishay; Andrey Lavrinenko; Shahaf E. Finder; Oren Freifeld,~Ron_Shapira_Weber2; ~Shahar_benishay1; ~Andrey_Lavrinenko1; ~Shahaf_E._Finder1; ~Oren_Freifeld1,"{'value': ['Time series', 'alignment', 'dtw', 'dynamic time warping']}","{'value': 'Fast and scalable alignment of time series is a fundamental challenge in many domains. The standard solution, Dynamic Time Warping (DTW), struggles with poor scalability and sensitivity to noise. We introduce TimePoint, a self-supervised method that dramatically accelerates DTW-based alignment while typically improving alignment accuracy by learning keypoints and descriptors from synthetic data. Inspired by 2D keypoint detection but carefully adapted to the unique challenges of 1D signals, TimePoint leverages efficient 1D diffeomorphisms, which effectively model nonlinear time warping,  to generate realistic training data. This adaptation, along with fully convolutional and wavelet convolutional architectures, enables the extraction of informative keypoints and descriptors. Applying DTW to these sparse representations yields major speedups and typically higher alignment accuracy than standard DTW applied to the full signals. Despite being trained solely on synthetic data, TimePoint generalizes well to real-world time series. Extensive experiments demonstrate that TimePoint consistently achieves faster and more accurate alignments than standard DTW, making it a scalable solution for time-series analysis. Our code is available at https://github.com/\nBGU-CS-VIL/TimePoint.'}",https://openreview.net{'value': '/pdf/7bbf2eafca1142aa562090e29a3895f75a0c04ae.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=bPJVWvyII5,{'value': 'In-Context Deep Learning via Transformer Models'},Weimin Wu; Maojiang Su; Jerry Yao-Chieh Hu; Zhao Song; Han Liu,~Weimin_Wu4; ~Maojiang_Su1; ~Jerry_Yao-Chieh_Hu1; ~Zhao_Song3; ~Han_Liu4,"{'value': ['foundation model', 'transformer', 'in-context learning']}","{'value': ""We investigate the transformer's capability for in-context learning (ICL) to simulate the training process of deep models. \nOur key contribution is providing a positive example of using a transformer to train a deep neural network by gradient descent in an implicit fashion via ICL. \nSpecifically, we provide an explicit construction of a $(2N+4)L$-layer transformer capable of simulating $L$ gradient descent steps of an $N$-layer ReLU network through ICL.\nWe also give the theoretical guarantees for the approximation within any given error and the convergence of the ICL gradient descent.\nAdditionally, we extend our analysis to the more practical setting using Softmax-based transformers. \nWe validate our findings on synthetic datasets for 3-layer, 4-layer, and 6-layer neural networks.\nThe results show that ICL performance matches that of direct training.""}",https://openreview.net{'value': '/pdf/0b0847c92f0dfc896d9b48398bfceae94fbdbf47.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=bHCio4Pg7e,{'value': 'Generalizing Causal Effects from Randomized Controlled Trials to Target Populations across Diverse Environments'},Baohong Li; Yingrong Wang; Anpeng Wu; Ming Ma; Ruoxuan Xiong; Kun Kuang,~Baohong_Li1; ~Yingrong_Wang1; ~Anpeng_Wu1; ~Ming_Ma5; ~Ruoxuan_Xiong1; ~Kun_Kuang1,"{'value': ['Causal Inference', 'Randomized Controlled Trial', 'Generalization', 'Treatment Effect Estimation', 'Data Fusion', 'Missing Covariates', 'Selection Bias']}","{'value': 'Generalizing causal effects from Randomized Controlled Trials (RCTs) to target populations across diverse environments is of significant practical importance, as RCTs are often costly and logistically complex to conduct. A key challenge is environmental shift, defined as changes in the distribution and availability of covariates between source and target environments. A common approach addressing this challenge is to identify a separating set--covariates that govern both treatment effect heterogeneity and environmental differences--and combine RCT samples with target populations matched on this set. However, this approach assumes that the separating set is fully observed and shared across datasets, an assumption often violated in practice. We propose a novel Two-Stage Doubly Robust (2SDR) method that relaxes this assumption by allowing the separating set to be observed in only one of the two datasets. 2SDR leverages shadow variables to impute missing components of the separating set and generalize treatment effects across environments in a two-stage procedure. We show the identification of causal effects in target environments under 2SDR and demonstrate its effectiveness through extensive experiments on both synthetic and real-world datasets.'}",https://openreview.net{'value': '/pdf/68677426eb752e4f47acb0a537711b72b0409a31.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=bDBnd9T2Cz,{'value': 'Automated Red Teaming with GOAT: the Generative Offensive Agent Tester'},Maya Pavlova; Erik Brinkman; Krithika Iyer; Vítor Albiero; Joanna Bitton; Hailey Nguyen; Cristian Canton Ferrer; Ivan Evtimov; Aaron Grattafiori,~Maya_Pavlova1; ~Erik_Brinkman1; ~Krithika_Iyer2; ~Vítor_Albiero1; ~Joanna_Bitton1; ~Hailey_Nguyen1; ~Cristian_Canton_Ferrer1; ~Ivan_Evtimov2; ~Aaron_Grattafiori1,"{'value': ['red teaming', 'adversarial machine learning', 'adversarial examples', 'attacks on language models']}","{'value': 'Red teaming aims to assess how large language models (LLMs) can produce content that violates norms, policies, and rules set forth during their safety training. However, most existing automated methods in literature are not representative of the way common users exploit the multi-turn conversational nature of AI models. While manual testing addresses this gap, it is an inefficient and often expensive process. To address these limitations, we introduce the Generative Offensive Agent Tester (GOAT), an automated agentic red teaming system that simulates plain language adversarial conversations while leveraging multiple adversarial prompting techniques to identify vuLnerabilities in LLMs. We instantiate GOAT with 7 red teaming attacks by prompting a general purpose model in a way that encourages reasoning through the choices of methods available, the current target model’s response, and the next steps. Our approach is designed to be extensible and efficient, allowing human testers to focus on exploring new areas of risk while automation covers the scaled adversarial stress-testing of known risk territory. We present the design and evaluation of GOAT, demonstrating its effectiveness in identifying vulnerabilities in state-of-the-art LLMs, with an ASR@10 of 96% against smaller models such as Llama 3.1 8B, and 91% against Llama 3.1 70B and 94% for GPT-4o when evaluated against larger models on the JailbreakBench dataset.'}",https://openreview.net{'value': '/pdf/a62df688f1dab76fcadd91d8dc2ba4a269fe9045.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=b90EKQbL7B,{'value': 'Learning Survival Distributions with the Asymmetric Laplace Distribution'},Deming Sheng; Ricardo Henao,~Deming_Sheng1; ~Ricardo_Henao1,{'value': ['Deep Learning; Survival Analysis; Asymmetric Laplace Distribution; Censored Data']},"{'value': 'Probabilistic survival analysis models seek to estimate the distribution of the future occurrence (time) of an event given a set of covariates.\nIn recent years, these models have preferred nonparametric specifications that avoid directly estimating survival distributions via discretization.\nSpecifically, they estimate the probability of an individual event at fixed times or the time of an event at fixed probabilities (quantiles), using supervised learning.\nBorrowing ideas from the quantile regression literature, we propose a parametric survival analysis method based on the Asymmetric Laplace Distribution (ALD).\nThis distribution allows for closed-form calculation of popular event summaries such as mean, median, mode, variation, and quantiles.\nThe model is optimized by maximum likelihood to learn, at the individual level, the parameters (location, scale, and asymmetry) of the ALD distribution.\nExtensive results on synthetic and real-world data demonstrate that the proposed method outperforms parametric and nonparametric approaches in terms of accuracy, discrimination and calibration.'}",https://openreview.net{'value': '/pdf/7bdba89677255b0c2ee4efd0b39cba61892a8e75.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=agtwOsnLUB,{'value': 'ROME is Forged in Adversity: Robust Distilled Datasets via Information Bottleneck'},Zheng Zhou; Wenquan Feng; Qiaosheng Zhang; Shuchang Lyu; Qi Zhao; Guangliang Cheng,~Zheng_Zhou1; ~Wenquan_Feng1; ~Qiaosheng_Zhang2; ~Shuchang_Lyu1; ~Qi_Zhao14; ~Guangliang_Cheng2,"{'value': ['Dataset distillation', 'adversarial robustness', 'information bottleneck', 'synthetic subsets', 'adversarial attacks']}","{'value': 'Dataset Distillation (DD) compresses large datasets into smaller, synthetic subsets, enabling models trained on them to achieve performance comparable to those trained on the full data. However, these models remain vulnerable to adversarial attacks, limiting their use in safety-critical applications. While adversarial robustness has been extensively studied in related fields, research on improving DD robustness is still limited. To address this, we propose ROME, a novel method that enhances the adversarial RObustness of DD by leveraging the InforMation BottlenEck (IB) principle. ROME includes two components: a performance-aligned term to preserve accuracy and a robustness-aligned term to improve robustness by aligning feature distributions between synthetic and perturbed images. Furthermore, we introduce the Improved Robustness Ratio (I-RR), a refined metric to better evaluate DD robustness. Extensive experiments on CIFAR-10 and CIFAR-100 demonstrate that ROME outperforms existing DD methods in adversarial robustness, achieving maximum I-RR improvements of nearly 40% under white-box attacks and nearly 35% under black-box attacks. Our code is available at https://github.com/zhouzhengqd/ROME.'}",https://openreview.net{'value': '/pdf/a10fc74b4c0d328d858e2481778fbcc0759c9050.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=afpc1MFMYU,{'value': 'Non-stationary Diffusion For Probabilistic Time Series Forecasting'},Weiwei Ye; Zhuopeng Xu; Ning Gui,~Weiwei_Ye2; ~Zhuopeng_Xu1; ~Ning_Gui1,"{'value': ['Probabilistic Time Series Forecasting', 'Denoising Diffusion Process Model', 'Non-stationary Forecasting']}","{'value': 'Due to the dynamics of underlying physics and external influences, the uncertainty of time series often varies over time. However, existing Denoising Diffusion Probabilistic Models (DDPMs) often fail to capture this non-stationary nature, constrained by their constant variance assumption from the additive noise model (ANM). In this paper, we innovatively utilize the Location-Scale Noise Model (LSNM) to relax the fixed uncertainty assumption of ANM. A diffusion-based probabilistic forecasting framework, termed Non-stationary Diffusion (NsDiff), is designed based on LSNM that is capable of modeling the changing pattern of uncertainty. Specifically, NsDiff combines a denoising diffusion-based conditional generative model with a pre-trained conditional mean and variance estimator, enabling adaptive endpoint distribution modeling. Furthermore, we propose an uncertainty-aware noise schedule, which dynamically adjusts the noise levels to accurately reflect the data uncertainty at each step and integrates the time-varying variances into the diffusion process. Extensive experiments conducted on nine real-world and synthetic datasets demonstrate the superior performance of NsDiff compared to existing approaches. Code is available at https://github.com/wwy155/NsDiff.'}",https://openreview.net{'value': '/pdf/ec01309fd59995a6e375ca52742c33f9a06c930a.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=aFNq67ilos,{'value': 'Training Dynamics of In-Context Learning in Linear Attention'},Yedi Zhang; Aaditya K Singh; Peter E. Latham; Andrew M Saxe,~Yedi_Zhang3; ~Aaditya_K_Singh1; ~Peter_E._Latham1; ~Andrew_M_Saxe1,"{'value': ['learning dynamics', 'in-context learning', 'linear attention']}","{'value': 'While attention-based models have demonstrated the remarkable ability of in-context learning (ICL), the theoretical understanding of how these models acquired this ability through gradient descent training is still preliminary. Towards answering this question, we study the gradient descent dynamics of multi-head linear self-attention trained for in-context linear regression. We examine two parametrizations of linear self-attention: one with the key and query weights merged as a single matrix (common in theoretical studies), and one with separate key and query matrices (closer to practical settings). For the merged parametrization, we show that the training dynamics has two fixed points and the loss trajectory exhibits a single, abrupt drop. We derive an analytical time-course solution for a certain class of datasets and initialization. For the separate parametrization, we show that the training dynamics has exponentially many fixed points and the loss exhibits saddle-to-saddle dynamics, which we reduce to scalar ordinary differential equations. During training, the model implements principal component regression in context with the number of principal components increasing over training time. Overall, we provide a theoretical description of how ICL abilities evolve during gradient descent training of linear attention, revealing abrupt acquisition or progressive improvements depending on how the key and query are parametrized.'}",https://openreview.net{'value': '/pdf/fcd60484d07593c57da494cdda1fcdd4a99bd8c4.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=aDVzd958YY,{'value': 'Efficient Motion Prompt Learning for Robust Visual Tracking'},Jie Zhao; Xin Chen; Yongsheng Yuan; Michael Felsberg; Dong Wang; Huchuan Lu,~Jie_Zhao3; ~Xin_Chen21; ~Yongsheng_Yuan1; ~Michael_Felsberg2; ~Dong_Wang5; ~Huchuan_Lu1,"{'value': ['visual object tracking', 'temporal encoding', 'prompt learning']}","{'value': 'Due to the challenges of processing temporal information, most trackers depend solely on visual discriminability and overlook the unique temporal coherence of video data. In this paper, we propose a lightweight and plug-and-play motion prompt tracking method. It can be easily integrated into existing vision-based trackers to build a joint tracking framework leveraging both motion and vision cues, thereby achieving robust tracking through efficient prompt learning. A motion encoder with three different positional encodings is proposed to encode the long-term motion trajectory into the visual embedding space, while a fusion decoder and an adaptive weight mechanism are designed to dynamically fuse visual and motion features. We integrate our motion module into three different trackers with five models in total. Experiments on seven challenging tracking benchmarks demonstrate that the proposed motion module significantly improves the robustness of vision-based trackers, with minimal training costs and negligible speed sacrifice. Code is available at https://github.com/zj5559/Motion-Prompt-Tracking.'}",https://openreview.net{'value': '/pdf/78420a2fc9b052d68f0adcf7888bc4c98606c4bb.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=a5Kgv47d2e,{'value': 'Unlocking Post-hoc Dataset Inference with Synthetic Data'},Bihe Zhao; Pratyush Maini; Franziska Boenisch; Adam Dziedzic,~Bihe_Zhao1; ~Pratyush_Maini1; ~Franziska_Boenisch2; ~Adam_Dziedzic1,"{'value': ['large language models', 'dataset inference', 'synthetic data']}","{'value': 'The remarkable capabilities of Large Language Models (LLMs) can be mainly attributed to their massive training datasets, which are often scraped from the internet without respecting data owners’ intellectual property rights. Dataset Inference (DI) offers a potential remedy by identifying whether a suspect dataset was used in training, thereby enabling data owners to verify unauthorized use. However, existing DI methods require a private set—known to be absent from training—that closely matches the compromised dataset’s distribution. Such in-distribution, held-out data is rarely available in practice, severely limiting the applicability of DI. In this work, we address this challenge by synthetically generating the required held-out set. Our approach tackles two key obstacles: (1) creating high-quality, diverse synthetic data that accurately reflects the original distribution, which we achieve via a data generator trained on a carefully designed suffix-based completion task, and (2) bridging likelihood gaps between real and synthetic data, which is realized through post-hoc calibration. Extensive experiments on diverse text datasets show that using our generated data as a held-out set enables DI to detect the original training sets with high confidence, while maintaining a low false positive rate. This result empowers copyright owners to make legitimate claims on data usage and demonstrates our method’s reliability for real-world litigations. Our code is available at https://github.com/sprintml/PostHocDatasetInference.'}",https://openreview.net{'value': '/pdf/e7817a2c2ee07b0622334cc28802b58b5665c6a8.pdf'},{'title_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=a3swNuXTxI,{'value': 'The Limits of Predicting Agents from Behaviour'},Alexis Bellot; Jonathan Richens; Tom Everitt,~Alexis_Bellot1; ~Jonathan_Richens1; ~Tom_Everitt1,"{'value': ['Safety', 'Alignment', 'Causality', 'Partial Identification.']}","{'value': ""As the complexity of AI systems and their interactions with the world increases, generating explanations for their behaviour is important for safely deploying AI. For agents, the most natural abstractions for predicting behaviour attribute beliefs, intentions and goals to the system. If an agent behaves as if it has a certain goal or belief, then we can make reasonable predictions about how it will behave in novel situations, including those where comprehensive safety evaluations are untenable. How well can we infer an agent’s beliefs from their behaviour, and how reliably can these inferred beliefs predict the agent’s behaviour in novel situations? We provide a precise answer to this question under the assumption that the agent’s behaviour is guided by a world model. Our contribution is the derivation of novel bounds on the agent's behaviour in new (unseen) deployment environments, which represent a theoretical limit for predicting intentional agents from behavioural data alone. We discuss the implications of these results for several research areas including fairness and safety.""}",https://openreview.net{'value': '/pdf/de5ffa4df1fbf1280df1e04a8fc02956d4ad13db.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=ZuaU2bYzlc,{'value': 'Private Federated Learning using Preference-Optimized Synthetic Data'},Charlie Hou; Mei-Yu Wang; Yige Zhu; Daniel Lazar; Giulia Fanti,~Charlie_Hou1; ~Mei-Yu_Wang1; ~Yige_Zhu2; ~Daniel_Lazar1; ~Giulia_Fanti1,"{'value': ['Differential privacy', 'large language models', 'synthetic data', 'federated learning', 'preference optimization', 'reinforcement learning']}","{'value': 'In practical settings, differentially private federated learning (DP-FL) is the dominant method for training models from private, on-device client data. Recent work has suggested that DP-FL may be enhanced or outperformed by methods that use DP synthetic data  (Wu et al., 2024; Hou et al., 2024). The primary algorithms for generating DP synthetic data for FL applications require careful prompt engineering based on public information and/or iterative private client feedback. Our key insight is that the private client feedback collected by prior DP synthetic data methods (Hou et al., 2024; Xie et al., 2024)  can be viewed as an RL reward. Our algorithm, Policy Optimization for Private Data (POPri) harnesses client feedback using policy optimization algorithms such as Direct Preference Optimization (DPO) to fine-tune LLMs to generate high-quality DP synthetic data. To evaluate POPri, we release LargeFedBench, a new federated text benchmark for uncontaminated LLM evaluations on federated client data. POPri closes the gap in performance between the fully-private and non-private settings by up to 58%, compared to 28% for prior synthetic data methods, and 3% for state-of-the-art DP federated learning methods. The code and data are available at https://github.com/meiyuw/POPri.'}",https://openreview.net{'value': '/pdf/b96e11fa2d46e60733e7627944e980d0739469ce.pdf'},{'title_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=Zt05jXhqXx,{'value': 'Stealing That Free Lunch: Exposing the Limits of Dyna-Style Reinforcement Learning'},Brett Barkley; David Fridovich-Keil,~Brett_Barkley1; ~David_Fridovich-Keil1,"{'value': ['model-based reinforcement learning', 'online reinforcement learning', 'deep reinforcement learning']}","{'value': 'Dyna-style off-policy model-based reinforcement learning (DMBRL) algorithms are a family of techniques for generating synthetic state transition data and thereby enhancing the sample efficiency of off-policy RL algorithms. This paper identifies and investigates a surprising performance gap observed when applying DMBRL algorithms across different benchmark environments with proprioceptive observations. We show that, while DMBRL algorithms perform well in control tasks in OpenAI Gym, their performance can drop significantly in DeepMind Control Suite (DMC), even though these settings offer similar tasks and identical physics backends. Modern techniques designed to address several key issues that arise in these settings do not provide a consistent improvement across all environments, and overall our results show that adding synthetic rollouts to the training process --- the backbone of Dyna-style algorithms --- significantly degrades performance across most DMC environments. Our findings contribute to a deeper understanding of several fundamental challenges in model-based RL and show that, like many optimization fields, there is no free lunch when evaluating performance across diverse benchmarks in RL.'}",https://openreview.net{'value': '/pdf/1be5bc1a79b8e47121923eb1ac889c79951a5061.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=ZcvGJH4ps7,{'value': 'Finite-Time Global Optimality Convergence in Deep Neural Actor-Critic Methods for Decentralized Multi-Agent Reinforcement Learning'},Zhiyao Zhang; Myeung Suk Oh; FNU Hairi; Ziyue Luo; Alvaro Velasquez; Jia Liu,~Zhiyao_Zhang2; ~Myeung_Suk_Oh1; ~FNU_Hairi1; ~Ziyue_Luo1; ~Alvaro_Velasquez1; ~Jia_Liu1,"{'value': ['Fully decentralized multi-agent reinforcement learning', 'Deep neural network', 'Finite-time global convergence.']}","{'value': 'Actor-critic methods for decentralized multi-agent reinforcement learning (MARL) facilitate collaborative optimal decision making without centralized coordination, thus enabling a wide range of applications in practice. To date, however, most theoretical convergence studies for existing actor-critic decentralized MARL methods are limited to the guarantee of a stationary solution under the linear function approximation. This leaves a significant gap between the highly successful use of deep neural actor-critic for decentralized MARL in practice and the current theoretical understanding. To bridge this gap, in this paper, we make the first attempt to develop a deep neural actor-critic method for decentralized MARL, where both the actor and critic components are inherently non-linear. We show that our proposed method enjoys a global optimality guarantee with a finite-time convergence rate of $\\mathcal{O}(1/T)$, where $T$ is the total iteration times. This marks the first global convergence result for deep neural actor-critic methods in the MARL literature. We also conduct extensive numerical experiments, which verify our theoretical results.'}",https://openreview.net{'value': '/pdf/7fb32bc0201766928bb60aabb99c2295170e0454.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=ZPQU4uGMBA,{'value': 'Do Vision-Language Models Really Understand Visual Language?'},Yifan Hou; Buse Giledereli; Yilei Tu; Mrinmaya Sachan,~Yifan_Hou1; ~Buse_Giledereli1; ~Yilei_Tu1; ~Mrinmaya_Sachan3,"{'value': ['vision-language model', 'visual language', 'evaluation', 'interpretation', 'diagram']}","{'value': 'Visual language is a system of communication that conveys information through symbols, shapes, and spatial arrangements. Diagrams are a typical example of a visual language depicting complex concepts and their relationships in the form of an image. The symbolic nature of diagrams presents significant challenges for building models capable of understanding them. Yet, recent studies seem to suggest that Large Vision-Language Models (LVLMs) can even tackle complex reasoning tasks involving diagrams. In this paper, we investigate this phenomenon by developing a comprehensive test suite to evaluate the diagram comprehension capability of LVLMs. Our test suite uses a variety of questions focused on concept entities and their relationships over a set of synthetic as well as real diagrams across several domains to evaluate the recognition and reasoning abilities of models. Our evaluation of six LVLMs shows that while these models can accurately identify and reason about entities, their ability to understand relationships is notably limited. Further testing reveals that the decent performance on diagram understanding largely stems from leveraging their background knowledge as shortcuts to identify and reason about the relational information. Thus, we conclude that LVLMs have a limited capability for genuine diagram understanding, and their impressive performance in diagram reasoning is an illusion emanating from other confounding factors, such as the background knowledge in the models.'}",https://openreview.net{'value': '/pdf/9f7513b064db0f13bf4c85402bacbfc8e5deda85.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=ZLyb8DwXXE,{'value': 'Multi-Marginal Stochastic Flow Matching for High-Dimensional Snapshot Data at Irregular Time Points'},Justin Lee; Behnaz Moradijamei; Heman Shakeri,~Justin_Lee4; ~Behnaz_Moradijamei1; ~Heman_Shakeri1,"{'value': ['Stochastic Flow Matching', 'Multi-Marginal Optimal Transport', 'Irregular Time Points', 'Snapshot Data', 'Simulation-Free Methods', 'Score Matching', 'Generative Models', 'Single-Cell Data']}","{'value': ""Modeling the evolution of high-dimensional systems from limited snapshot observations at irregular time points poses a significant challenge in quantitative biology and related fields. Traditional approaches often rely on dimensionality reduction techniques, which can oversimplify the dynamics and fail to capture critical transient behaviors in non-equilibrium systems. We present Multi-Marginal Stochastic Flow Matching (MMSFM), a novel extension of simulation-free score and flow matching methods to the multi-marginal setting, enabling the alignment of high-dimensional data measured at non-equidistant time points without reducing dimensionality. The use of measure-valued splines enhances robustness to irregular snapshot timing, and score matching prevents overfitting in high-dimensional spaces. \nWe validate our framework on several synthetic and benchmark datasets, including gene expression data collected at uneven time points and an image progression task, demonstrating the method's versatility.""}",https://openreview.net{'value': '/pdf/0f7040c2d855948fc4f06b222ed0f6273d889a7c.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=ZEPWk1Q6ww,{'value': 'Backdoor Attacks in Token Selection of Attention Mechanism'},Yunjuan Wang; Raman Arora,~Yunjuan_Wang1; ~Raman_Arora1,"{'value': ['Backdoor attacks', 'attention mechanism', 'token selection', 'transformer models', 'gradient descent dynamics', 'theoretical analysis', 'adversarial machine learning', 'label poisoning']}","{'value': 'Despite the remarkable success of large foundation models across a range of tasks, they remain susceptible to security threats such as backdoor attacks. By injecting poisoned data containing specific triggers during training, adversaries can manipulate model predictions in a targeted manner. While prior work has focused on empirically designing and evaluating such attacks, a rigorous theoretical understanding of when and why they succeed is lacking. In this work, we analyze backdoor attacks that exploit the token selection process within attention mechanisms--a core component of transformer-based architectures. We show that single-head self-attention transformers trained via gradient descent can interpolate poisoned training data. Moreover, we prove that when the backdoor triggers are sufficiently strong but not overly dominant, attackers can successfully manipulate model predictions. Our analysis characterizes how adversaries manipulate token selection to alter outputs and identifies the theoretical conditions under which these attacks succeed. We validate our findings through experiments on synthetic datasets.'}",https://openreview.net{'value': '/pdf/27d35fa7176f4fe2cf1c67175a40703bfdc71d1f.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=Z9BaaWDE0r,{'value': 'ETTA: Elucidating the Design Space of Text-to-Audio Models'},Sang-gil Lee; Zhifeng Kong; Arushi Goel; Sungwon Kim; Rafael Valle; Bryan Catanzaro,~Sang-gil_Lee1; ~Zhifeng_Kong1; ~Arushi_Goel2; ~Sungwon_Kim2; ~Rafael_Valle1; ~Bryan_Catanzaro1,"{'value': ['audio generation', 'text-to-audio', 'synthetic data', 'diffusion', 'flow matching']}","{'value': ""Recent years have seen significant progress in Text-To-Audio (TTA) synthesis, enabling users to enrich their creative workflows with synthetic audio generated from natural language prompts. Despite this progress, the effects of data, model architecture, training objective functions, and sampling strategies on target benchmarks are not well understood. With the purpose of providing a holistic understanding of the design space of TTA models, we set up a large-scale empirical experiment focused on diffusion and flow matching models. Our contributions include: 1) AF-Synthetic, a large dataset of high quality synthetic captions obtained from an audio understanding model; 2) a systematic comparison of different architectural, training, and inference design choices for TTA models; 3) an analysis of sampling methods and their Pareto curves with respect to generation quality and inference speed. We leverage the knowledge obtained from this extensive analysis to propose our best model dubbed Elucidated Text-To-Audio (ETTA). When evaluated on AudioCaps and MusicCaps, ETTA provides improvements over the baselines trained on publicly available data, while being competitive with models trained on proprietary data. Finally, we show ETTA's improved ability to generate creative audio following complex and imaginative captions -- a task that is more challenging than current benchmarks.""}",https://openreview.net{'value': '/pdf/28a5bd98f262624ee40b6b18e5189476e0676c66.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=Z0jnz149L1,{'value': 'Isolated Causal Effects of Natural Language'},Victoria Lin; Louis-Philippe Morency; Eli Ben-Michael,~Victoria_Lin2; ~Louis-Philippe_Morency1; ~Eli_Ben-Michael1,"{'value': ['causal inference', 'natural language processing', 'omitted variable bias']}","{'value': ""As language technologies become widespread, it is important to understand how changes in language affect reader perceptions and behaviors. These relationships may be formalized as the *isolated causal effect* of some *focal* language-encoded intervention (e.g., factual inaccuracies) on an external outcome (e.g., readers' beliefs). In this paper, we introduce a formal estimation framework for isolated causal effects of language. We show that a core challenge of estimating isolated effects is the need to approximate all *non-focal* language outside of the intervention. Drawing on the principle of *omitted variable bias*, we provide measures for evaluating the quality of both non-focal language approximations and isolated effect estimates themselves. We find that poor approximation of non-focal language can lead to bias in the corresponding isolated effect estimates due to omission of relevant variables, and we show how to assess the sensitivity of effect estimates to such bias along the two key axes of *fidelity* and *overlap*. In experiments on semi-synthetic and real-world data, we validate the ability of our framework to correctly recover isolated effects and demonstrate the utility of our proposed measures.""}",https://openreview.net{'value': '/pdf/c305c1549e61c8300b2575fd07316f54318c8efd.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=Z0ffRRtOim,{'value': 'Variational Control for Guidance in Diffusion Models'},Kushagra Pandey; Farrin Marouf Sofian; Felix Draxler; Theofanis Karaletsos; Stephan Mandt,~Kushagra_Pandey1; ~Farrin_Marouf_Sofian1; ~Felix_Draxler1; ~Theofanis_Karaletsos1; ~Stephan_Mandt1,"{'value': ['Diffusion Models', 'Inverse Problems']}","{'value': 'Diffusion models exhibit excellent sample quality, but existing guidance methods often require additional model training or are limited to specific tasks. We revisit guidance in diffusion models from the perspective of variational inference and control, introducing \\emph{Diffusion Trajectory Matching (DTM)} that enables guiding pretrained diffusion trajectories to satisfy a terminal cost. DTM unifies a broad class of guidance methods and enables novel instantiations. We introduce a new method within this framework that achieves state-of-the-art results on several linear, non-linear, and blind inverse problems without requiring additional model training or specificity to pixel or latent space diffusion models. Our code will be available at https://github.com/czi-ai/oc-guidance.'}",https://openreview.net{'value': '/pdf/63283cdbfaa026c8b8cd44b8b4383ee5829652d2.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=YUtJsxQjv3,{'value': 'EcoMapper: Generative Modeling for Climate-Aware Satellite Imagery'},Muhammed Goktepe; Amir hossein Shamseddin; Erencan Uysal; Javier Muinelo Monteagudo; Lukas Drees; Aysim Toker; Senthold Asseng; Malte von Bloh,~Muhammed_Goktepe1; ~Amir_hossein_Shamseddin1; ~Erencan_Uysal1; ~Javier_Muinelo_Monteagudo1; ~Lukas_Drees2; ~Aysim_Toker1; ~Senthold_Asseng1; ~Malte_von_Bloh1,"{'value': ['remote sensing', 'generative modeling', 'stable diffusion', 'climate', 'satellite imagery', 'computer vision']}","{'value': 'Satellite imagery is essential for Earth observation, enabling applications like crop yield prediction, environmental monitoring, and climate\nchange assessment. However, integrating satellite imagery with climate data remains a challenge, limiting its utility for forecasting and scenario analysis. We introduce a novel dataset of 2.9 million Sentinel-2 images spanning 15 land cover types with corresponding climate records, forming the foundation for two satellite image generation approaches using fine-tuned Stable Diffusion 3 models. The first is a text-to-image generation model that uses textual prompts with climate and land cover details to produce realistic synthetic imagery for specific regions. The second leverages ControlNet for multi-conditional image generation, preserving spatial structures while mapping climate data or generating time-series to simulate landscape evolution. By combining synthetic image generation with climate and land cover data, our work advances generative modeling in remote sensing, offering realistic inputs for environmental forecasting and new possibilities for climate adaptation and geospatial analysis.'}",https://openreview.net{'value': '/pdf/e6870f8d32b3506d84767401b7936a61762de32e.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=YJ1My9ttEN,{'value': 'Adaptive Flow Matching for Resolving Small-Scale Physics'},Stathi Fotiadis; Noah D Brenowitz; Tomas Geffner; Yair Cohen; Michael Pritchard; Arash Vahdat; Morteza Mardani,~Stathi_Fotiadis1; ~Noah_D_Brenowitz1; ~Tomas_Geffner1; ~Yair_Cohen1; ~Michael_Pritchard1; ~Arash_Vahdat3; ~Morteza_Mardani1,"{'value': ['flow matching', 'diffusion models', 'weather downscaling', 'distribution misalignment']}","{'value': 'Conditional diffusion and flow models are effective for super-resolving small-scale details in natural images. However, in physical sciences such as weather, three major challenges arise: (i) spatially misaligned input-output distributions (PDEs at different resolutions lead to divergent trajectories), (ii) misaligned and distinct input-output channels (channel synthesis), (iii) several channels with diverse stochasticity scales (multiscale). To address these, we propose to first encode inputs into a latent base distribution that is closer to the target, then apply Flow Matching to generate small-scale physics. The encoder captures deterministic components, while Flow Matching adds stochastic details. To handle uncertainty in the deterministic part, we inject noise via an adaptive noise scaling mechanism, dynamically adjusted by maximum-likelihood estimates of the encoder’s predictions. Experiments on real-world weather data (including super-resolution from 25 km to 2 km scales in Taiwan) and in synthetic Kolmogorov flow datasets show that our proposed Adaptive Flow Matching (AFM) framework outperforms existing methods and produces better-calibrated ensembles.'}",https://openreview.net{'value': '/pdf/f33ad7b5945caf9cd5c0665944a4c15012279323.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=YC6ItZfdVk,{'value': 'Improving Compositional Generation with Diffusion Models Using Lift Scores'},Chenning Yu; Sicun Gao,~Chenning_Yu1; ~Sicun_Gao1,"{'value': ['Diffusion Models', 'Training-free', 'Rejection Sampling']}","{'value': 'We introduce a novel resampling criterion using lift scores, for improving compositional generation in diffusion models. By leveraging the lift scores, we evaluate whether generated samples align with each single condition and then compose the results to determine whether the composed prompt is satisfied. Our key insight is that lift scores can be efficiently approximated using only the original diffusion model, requiring no additional training or external modules. We develop an optimized variant that achieves relatively lower computational overhead during inference while maintaining effectiveness. Through extensive experiments, we demonstrate that lift scores significantly improved the condition alignment for compositional generation across 2D synthetic data, CLEVR position tasks, and text-to-image synthesis. Our code is available at github.com/rainorangelemon/complift.'}",https://openreview.net{'value': '/pdf/e614442d9c1a58b62387c3b2e1d2985ab5b17ec2.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=Y34a82DptF,{'value': 'Learning Mean Field Control on Sparse Graphs'},Christian Fabian; Kai Cui; Heinz Koeppl,~Christian_Fabian1; ~Kai_Cui3; ~Heinz_Koeppl1,"{'value': ['Mean Field Control', 'Large Graphs', 'Sparse Networks', 'Multi-Agent Reinforcement Learning']}","{'value': 'Large agent networks are abundant in applications and nature and pose difficult challenges in the field of multi-agent reinforcement learning (MARL) due to their computational and theoretical complexity. While graphon mean field games and their extensions provide efficient learning algorithms for dense and moderately sparse agent networks, the case of realistic sparser graphs remains largely unsolved. Thus, we propose a novel mean field control model inspired by local weak convergence to include sparse graphs such as power law networks with coefficients above two. Besides a theoretical analysis, we design scalable learning algorithms which apply to the challenging class of graph sequences with finite first moment. We compare our model and algorithms for various examples on synthetic and real world networks with mean field algorithms based on Lp graphons and graphexes. As it turns out, our approach outperforms existing methods in many examples and on various networks due to the special design aiming at an important, but so far hard to solve class of MARL problems.'}",https://openreview.net{'value': '/pdf/d02eb86e15e25abfef60e949a6eb33c10cbd8fd6.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=Xsyrolw1Q1,{'value': 'Bayesian Neural Scaling Law Extrapolation with Prior-Data Fitted Networks'},Dongwoo Lee; Dong Bok Lee; Steven Adriaensen; Juho Lee; Sung Ju Hwang; Frank Hutter; Seon Joo Kim; Hae Beom Lee,~Dongwoo_Lee3; ~Dong_Bok_Lee1; ~Steven_Adriaensen1; ~Juho_Lee2; ~Sung_Ju_Hwang1; ~Frank_Hutter1; ~Seon_Joo_Kim2; ~Hae_Beom_Lee1,"{'value': ['Neural Scaling Laws', 'Bayesian Inference', 'Prior-data Fitted Networks']}","{'value': 'Scaling has been a major driver of recent advancements in deep learning. Numerous empirical studies have found that scaling laws often follow the power-law and proposed several variants of power-law functions to predict the scaling behavior at larger scales. However, existing methods mostly rely on point estimation and do not quantify uncertainty, which is crucial for real-world applications involving decision-making problems such as determining the expected performance improvements achievable by investing additional computational resources. In this work, we explore a Bayesian framework based on Prior-data Fitted Networks (PFNs) for neural scaling law extrapolation. Specifically, we design a prior distribution that enables the sampling of infinitely many synthetic functions resembling real-world neural scaling laws, allowing our PFN to meta-learn the extrapolation. We validate the effectiveness of our approach on real-world neural scaling laws, comparing it against both the existing point estimation methods and Bayesian approaches. Our method demonstrates superior performance, particularly in data-limited scenarios such as Bayesian active learning, underscoring its potential for reliable, uncertainty-aware extrapolation in practical applications.'}",https://openreview.net{'value': '/pdf/3c532113de1d80ca00c92d2ecb3a9959c6d81063.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=Xd3J3QJg0b,{'value': 'Speeding up Policy Simulation in Supply Chain RL'},Vivek Farias; Joren Gijsbrechts; Aryan I. Khojandi; Tianyi Peng; Andrew Zheng,~Vivek_Farias1; ~Joren_Gijsbrechts1; ~Aryan_I._Khojandi1; ~Tianyi_Peng1; ~Andrew_Zheng1,"{'value': ['Parallel Computing', 'Markov Decision Process', 'Policy Evaluation', 'Supply Chain', 'Operations Research']}","{'value': 'Simulating a single trajectory of a dynamical system under some state-dependent policy is a core bottleneck in policy optimization (PO) algorithms. The many inherently serial policy evaluations that must be performed in a single simulation constitute the bulk of this bottleneck. In applying PO to supply chain optimization (SCO) problems, simulating a single sample path corresponding to one month of a supply chain can take several hours. We present an iterative algorithm to accelerate policy simulation, dubbed Picard Iteration. This scheme carefully assigns policy evaluation tasks to independent processes. Within an iteration, any given process evaluates the policy only on its assigned tasks while assuming a certain ‘cached’ evaluation for other tasks; the cache is updated at the end of the iteration. Implemented on GPUs, this scheme admits batched evaluation of the policy across a single trajectory. We prove that the structure afforded by many SCO problems allows convergence in a small number of iterations independent of the horizon. We demonstrate practical speedups of 400x on large-scale SCO problems even with a single GPU, and also demonstrate practical efficacy in other RL environments.'}",https://openreview.net{'value': '/pdf/b5c706309e5673c99ba4afccbde1aa7296508552.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=XUkJGDfuXu,"{'value': 'EARL-BO: Reinforcement Learning for Multi-Step Lookahead, High-Dimensional Bayesian Optimization'}",Mujin Cheon; Jay H Lee; Dong-Yeun Koh; Calvin Tsay,~Mujin_Cheon1; ~Jay_H_Lee1; ~Dong-Yeun_Koh1; ~Calvin_Tsay1,"{'value': ['Bayesian Optimization', 'Reinforcement Learning', 'High-dimensional Optimization', 'Nonmyopic Bayesian Optimization']}","{'value': 'To avoid myopic behavior, multi-step lookahead Bayesian optimization (BO) algorithms consider the sequential nature of BO and have demonstrated promising results in recent years. However, owing to the curse of dimensionality, most of these methods make significant approximations or suffer scalability issues. This paper presents a novel reinforcement learning (RL)-based framework for multi-step lookahead BO in high-dimensional black-box optimization problems. The proposed method enhances the scalability and decision-making quality of multi-step lookahead BO by efficiently solving the sequential dynamic program of the BO process in a near-optimal manner using RL. We first introduce an Attention-DeepSets encoder to represent the state of knowledge to the RL agent and subsequently propose a multi-task, fine-tuning procedure based on end-to-end (encoder-RL) on-policy learning. We evaluate the proposed method, EARL-BO (Encoder Augmented RL for BO), on synthetic benchmark functions and hyperparameter tuning problems, finding significantly improved performance compared to existing multi-step lookahead and high-dimensional BO methods.'}",https://openreview.net{'value': '/pdf/aaf1b54c4fbda4fc66f36f9278dcc1be4a2d3784.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=XKuTFM93mG,{'value': 'K$^2$IE: Kernel Method-based Kernel Intensity Estimators for Inhomogeneous Poisson Processes'},Hideaki Kim; Tomoharu Iwata; Akinori Fujino,~Hideaki_Kim1; ~Tomoharu_Iwata1; ~Akinori_Fujino1,"{'value': ['point processes', 'kernel methods', 'kernel intensity estimators', 'representer theorem', 'least squares loss']}","{'value': 'Kernel method-based intensity estimators, formulated within reproducing kernel Hilbert spaces (RKHSs), and classical kernel intensity estimators (KIEs) have been among the most easy-to-implement and feasible methods for estimating the intensity functions of inhomogeneous Poisson processes. While both approaches share the term ""kernel"", they are founded on distinct theoretical principles, each with its own strengths and limitations. In this paper, we propose a novel regularized kernel method for Poisson processes based on the least squares loss and show that the resulting intensity estimator involves a specialized variant of the representer theorem: it has the dual coefficient of unity and coincides with classical KIEs. This result provides new theoretical insights into the connection between classical KIEs and kernel method-based intensity estimators, while enabling us to develop an efficient KIE by leveraging advanced techniques from RKHS theory. We refer to the proposed model as the *kernel method-based kernel intensity estimator* (K$^2$IE). Through experiments on synthetic datasets, we show that K$^2$IE achieves comparable predictive performance while significantly surpassing the state-of-the-art kernel method-based estimator in computational efficiency.'}",https://openreview.net{'value': '/pdf/4215ef1ca58f512d390fab7119ed385321d4258c.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=XGZeCEzeRT,{'value': 'A Non-Asymptotic Convergent Analysis for Scored-Based Graph Generative Model via a System of Stochastic Differential Equations'},Junwei Su; Chuan Wu,~Junwei_Su1; ~Chuan_Wu1,"{'value': ['graph generation', 'score-based generative model', 'convergence analysis']}","{'value': 'This paper investigates the convergence behavior of score-based graph generative models (SGGMs). Unlike common score-based generative models (SGMs) that are governed by a single stochastic differential equation (SDE), SGGMs utilize a system of dependent SDEs, where the graph structure and node features are modeled separately, while accounting for their inherent dependencies. This distinction makes existing convergence analyses from SGMs inapplicable for SGGMs. In this work, we present the first convergence analysis for SGGMs, focusing on the convergence bound (the risk of generative error) across three key graph generation paradigms: (1) feature generation with a fixed graph structure, (2) graph structure generation with fixed node features, and (3) joint generation of both graph structure and node features. Our analysis reveals several unique factors specific to SGGMs (e.g., the topological properties of the graph structure) which significantly affect the convergence bound. Additionally, we offer theoretical insights into the selection of hyperparameters (e.g., sampling steps and diffusion length) and advocate for techniques like normalization to improve convergence. To validate our theoretical findings, we conduct a controlled empirical study using a synthetic graph model. The results in this paper contribute to a deeper theoretical understanding of SGGMs and offer practical guidance for designing more efficient and effective SGGMs.'}",https://openreview.net{'value': '/pdf/dde5da10f1880e82b54a4d7afc5b983416d530e9.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=XAckVo0iNj,{'value': 'Shielded Diffusion: Generating Novel and Diverse Images using Sparse Repellency'},Michael Kirchhof; James Thornton; Louis Béthune; Pierre Ablin; Eugene Ndiaye; marco cuturi,~Michael_Kirchhof1; ~James_Thornton1; ~Louis_Béthune1; ~Pierre_Ablin2; ~Eugene_Ndiaye1; ~marco_cuturi2,"{'value': ['Diffusion Model', 'Guidance', 'Repellency', 'Diversity']}","{'value': 'The adoption of text-to-image diffusion models raises concerns over reliability, drawing scrutiny under the lens of various metrics like calibration, fairness, or compute efficiency. We focus in this work on two issues that arise when deploying these models: a lack of diversity when prompting images, and a tendency to recreate images from the training set. To solve both problems, we propose a method that coaxes the sampled trajectories of pretrained diffusion models to land on images that fall outside of a reference set. We achieve this by adding repellency terms to the diffusion SDE throughout the generation trajectory, which are triggered whenever the path is expected to land too closely to an image in the shielded reference set. Our method is sparse in the sense that these repellency terms are zero and inactive most of the time, and even more so towards the end of the generation trajectory. Our method, named SPELL for sparse repellency, can be used either with a static reference set that contains protected images, or dynamically, by updating the set at each timestep with the expected images concurrently generated within a batch, and with the images of previously generated batches. We show that adding SPELL to popular diffusion models improves their diversity while impacting their FID only marginally, and performs comparatively better than other recent training-free diversity methods. We also demonstrate how SPELL can ensure a shielded generation away from a very large set of protected images by considering all 1.2M images from ImageNet as the protected set.'}",https://openreview.net{'value': '/pdf/d1f2b86fa8285a1e5ae0f426c390ee527999e532.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=WR0ahlhOoy,{'value': 'Improving Zero-Shot Adversarial Robustness in Vision-Language Models by Closed-form Alignment of Adversarial Path Simplices'},Junhao Dong; Piotr Koniusz; Yifei Zhang; Hao Zhu; Weiming Liu; Xinghua Qu; Yew-Soon Ong,~Junhao_Dong1; ~Piotr_Koniusz1; ~Yifei_Zhang6; ~Hao_Zhu2; ~Weiming_Liu2; ~Xinghua_Qu1; ~Yew-Soon_Ong1,"{'value': ['Vision-Language Models', 'Adversarial Examples', 'Zero-Shot Classification']}","{'value': 'Vision-Language Models (VLMs) such as CLIP excel at zero-shot classification due to large-scale pre-training but are vulnerable to adversarial examples. Adversarial fine-tuning robustifies zero-shot models by aligning prediction scores of individual adversaries with their clean counterparts, which typically overlooks intermediate adversarial samples along the adversarial trajectory crossing the decision boundary. Such intermediate adversaries and their vicinity produce informative representations capturing the decision boundary in detail. They can be improved by sampling adversarial candidates from simplices formed by joining two consecutive vertices on the adversarial trajectory and their clean counterpart. However, sampling simplices for adversaries is very costly. To train robust VLM, we overcome these limitations by Taylor expansion and formulating an upper-bound of alignment loss that depends on the Jacobian/Hessian obtained at clean samples. As regions between clean and intermediate adversarial samples capture a larger decision landscape, we robustify VLM by plausible adversaries from simplices by our closed-form formulation equivalent to infinite uniform sampling of the simplex. We obtain state-of-the-art robustness across 15 datasets and diverse vision-language tasks.'}",https://openreview.net{'value': '/pdf/b1200ff08644a1c497b0f81618aa10f88ec508f7.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=WPeAraSKAK,{'value': 'Discovering Latent Causal Graphs from Spatiotemporal Data'},Kun Wang; Sumanth Varambally; Duncan Watson-Parris; Yian Ma; Rose Yu,~Kun_Wang1; ~Sumanth_Varambally1; ~Duncan_Watson-Parris1; ~Yian_Ma1; ~Rose_Yu1,"{'value': ['Representation Learning', 'Causal Discovery', 'Spatiotemporal Inference', 'Variational Inference', 'Time Series Analysis']}","{'value': 'Many important phenomena in scientific fields like climate, neuroscience, and epidemiology are naturally represented as spatiotemporal gridded data with complex interactions.  Inferring causal relationships from these data is a challenging problem compounded by the high dimensionality of such data and the correlations between spatially proximate points. We present SPACY (SPAtiotemporal Causal discoverY), a novel framework based on variational inference, designed to model latent time series and their causal relationships from spatiotemporal data. SPACY alleviates the high-dimensional challenge by discovering causal structures in the latent space. To aggregate spatially proximate, correlated grid points, we use spatial factors, parametrized by spatial kernel functions, to map observational time series to latent representations. Theoretically, we generalize the problem to a continuous spatial domain and establish identifiability when the observations arise from a nonlinear, invertible function of the product of latent series and spatial factors. Using this approach, we avoid assumptions that are often unverifiable, including those about instantaneous effects or sufficient variability. Empirically, SPACY outperforms state-of-the-art baselines on synthetic data, even in challenging settings where existing methods struggle, while remaining scalable for large grids. SPACY also identifies key known phenomena from real-world climate data. An implementation of SPACY is available at \\url{https://github.com/Rose-STL-Lab/SPACY/}'}",https://openreview.net{'value': '/pdf/6f566beba990322ba8f1b6f277efc99ffc0e1e04.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=W9s817KqYf,{'value': 'Windows Agent Arena: Evaluating Multi-Modal OS Agents at Scale'},Rogerio Bonatti; Dan Zhao; Francesco Bonacci; Dillon Dupont; Sara Abdali; Yinheng Li; Yadong Lu; Justin Wagle; Kazuhito Koishida; Arthur Bucker; Lawrence Keunho Jang; Zheng Hui,~Rogerio_Bonatti1; ~Dan_Zhao3; ~Francesco_Bonacci1; ~Dillon_Dupont1; ~Sara_Abdali1; ~Yinheng_Li2; ~Yadong_Lu1; ~Justin_Wagle1; ~Kazuhito_Koishida1; ~Arthur_Bucker1; ~Lawrence_Keunho_Jang1; ~Zheng_Hui2,"{'value': ['agents', 'benchmark', 'computer agents', 'AI agents', 'multimodal agents', 'large language models']}","{'value': 'Large language models (LLMs) show potential as computer agents, enhancing productivity and software accessibility in multi-modal tasks. \nHowever, measuring agent performance in sufficiently realistic and complex environments becomes increasingly challenging as: \n(i) most benchmarks are limited to specific modalities/domains (e.g., text-only, web navigation, Q&A) and \n(ii) full benchmark evaluations are slow (on order of magnitude of multiple hours/days) given the multi-step sequential nature of tasks.\nTo address these challenges, we introduce Windows Agent Arena: a general environment focusing exclusively on the Windows operating system (OS) where agents can operate freely within a real OS to use the same applications and tools available to human users when performing tasks.\nWe create 150+ diverse tasks across representative domains that require agentic abilities in planning, screen understanding, and tool usage.\nOur benchmark is scalable and can be seamlessly parallelized for a full benchmark evaluation in as little as $20$ minutes.\nOur work not only speeds up the development and evaluation cycle of multi-modal agents, but also highlights and analyzes existing shortfalls in the agentic  abilities of several multimodal LLMs as agents within the Windows computing environment---with the best achieving only a 19.5\\% success rate compared to a human success rate of 74.5\\%.'}",https://openreview.net{'value': '/pdf/649fdc07b1256b087a6db62c7d4274d3b265c9d2.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=W6RPXUUFic,{'value': 'Communicating Activations Between Language Model Agents'},Vignav Ramesh; Kenneth Li,~Vignav_Ramesh1; ~Kenneth_Li1,"{'value': ['large language models', 'multiagent communication', 'embedding representation', 'multiagent debate']}","{'value': 'Communication between multiple language model (LM) agents has been shown to scale up the reasoning ability of LMs. While natural language has been the dominant medium for inter-LM communication, it is not obvious this should be the standard: not only does natural language communication incur high inference costs that scale quickly with the number of both agents and messages, but also the decoding process abstracts away too much rich information that could be otherwise accessed from the internal activations. In this work, we propose a simple technique whereby LMs communicate via *activations*; concretely, we pause an LM $B$\'s computation at an intermediate layer, combine its current activation with another LM $A$\'s intermediate activation via some function $f$, then pass $f$\'s output into the next layer of $B$ and continue the forward pass till decoding is complete. This approach scales up LMs on new tasks with *zero* additional parameters and data, and saves a *substantial amount of compute* over natural language communication. We test our method with various functional forms $f$ on two experimental setups—multi-player coordination games and reasoning benchmarks—and find that it achieves up to $27$% improvement over natural language communication across datasets with $<$$1/4$ the compute, illustrating the superiority and robustness of activations as an alternative ""language"" for communication between LMs.'}",https://openreview.net{'value': '/pdf/230f2250cdf450e5de4b3133a40fb2ef3bc8ebd7.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=Vw4f8M67jE,{'value': 'Gravity-Bench-v1: A Benchmark on Gravitational Physics Discovery for Agents'},Nolan Koblischke; Hyunseok Jang; Kristen Menou; Mohamad Ali-Dib,~Nolan_Koblischke1; ~Hyunseok_Jang1; ~Kristen_Menou1; ~Mohamad_Ali-Dib1,"{'value': ['Scientific Discovery', 'Benchmarking', 'Evaluations', 'Physics', 'Agents', 'Planning', 'Large Language Models']}","{'value': 'Modern science emerged from reasoning over repeatedly-observed planetary motions. We present Gravity-Bench-v1, an environment-based benchmark that challenges AI agents on tasks that parallel this historical development. Gravity-Bench-v1 evaluates agents on the discovery of physics concealed within a dynamic environment, using rigorous gravitational dynamics simulations. Gravity-Bench includes out-of-distribution cases, i.e. with physics that deviates from the real world, to evaluate true scientific generalization capabilities. Agents must plan to collect data within an experimental budget and must perform a dynamic form of data analysis and reasoning to solve tasks efficiently. Our benchmark admits an open-ended space of solutions. Reference solutions for each task are provided to calibrate AI performance against human expertise. Technically at an upper-undergraduate level, our benchmark proves challenging to baseline AI agents. Gravity-Bench-v1 and planned extensions should help map out AI progress towards scientific discovery capabilities.'}",https://openreview.net{'value': '/pdf/38e0e698321ef1012408b4d8e50ab1bd0274b784.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=VY74pP1w93,{'value': 'Attributes Shape the Embedding Space of Face Recognition Models'},Pierrick Leroy; Antonio Mastropietro; Marco Nurisso; Francesco Vaccarino,~Pierrick_Leroy1; ~Antonio_Mastropietro1; ~Marco_Nurisso1; ~Francesco_Vaccarino1,"{'value': ['Face Recognition', 'Representation Learning', 'Interpretability', 'Embeddings', 'Contrastive Loss']}","{'value': 'Face Recognition (FR) tasks have made significant progress with the advent of Deep Neural Networks, particularly through margin-based triplet losses that embed facial images into high-dimensional feature spaces. \nDuring training, these contrastive losses focus exclusively on identity information as labels. \nHowever, we observe a multiscale geometric structure emerging in the embedding space, influenced by interpretable facial (e.g., hair color) and image attributes (e.g., contrast).\nWe propose a geometric approach to describe the dependence or invariance of FR models to these attributes and introduce a physics-inspired alignment metric. \nWe evaluate the proposed metric on controlled, simplified models and widely used FR models fine-tuned with synthetic data for targeted attribute augmentation. \nOur findings reveal that the models exhibit varying degrees of invariance across different attributes, providing insight into their strengths and weaknesses and enabling deeper interpretability.\nCode available here: https://github.com/mantonios107/attrs-fr-embs.'}",https://openreview.net{'value': '/pdf/6f7e0a731204ae9a76bb4694d3a43fc64648ac47.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=VPHFKbhJIJ,{'value': 'Symmetry-Driven Discovery of Dynamical Variables in Molecular Simulations'},Jeet Mohapatra; Nima Dehmamy; Csaba Both; Subhro Das; Tommi Jaakkola,~Jeet_Mohapatra1; ~Nima_Dehmamy1; ~Csaba_Both1; ~Subhro_Das1; ~Tommi_Jaakkola1,"{'value': ['AI4Science', 'Molecular Dynamics', 'Second Order Methods', 'Symmetry Discovery']}","{'value': 'We introduce a novel approach for discovering effective degrees of freedom (DOF) in molecular dynamics simulations by mapping the DOF to approximate symmetries of the energy landscape. Unlike most existing methods, we do not require trajectory data but instead rely on knowledge of the forcefield (energy function) around the initial state. We present a scalable symmetry loss function compatible with existing force-field frameworks and a Hessian-based method efficient for smaller systems. Our approach enables systematic exploration of conformational space by connecting structural dynamics to energy landscape symmetries. We apply our method to two systems, Alanine dipeptide and Chignolin, recovering their known important conformations. Our approach can prove useful for efficient exploration in molecular simulations with potential applications in protein folding and drug discovery.'}",https://openreview.net{'value': '/pdf/a994ae17137117c14037377b5b0ef318acf23b68.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=VD4rLMrHXZ,{'value': 'Multidimensional Adaptive Coefficient for Inference Trajectory Optimization in Flow and Diffusion'},Dohoon Lee; Jaehyun Park; Hyunwoo J. Kim; Kyogu Lee,~Dohoon_Lee2; ~Jaehyun_Park5; ~Hyunwoo_J._Kim3; ~Kyogu_Lee1,"{'value': ['Multidimensional Adaptive Coefficient', 'Inference Trajectory Optimization', 'Flow', 'Diffusion', 'Adversarial Optimization']}","{'value': 'Flow and diffusion models have demonstrated strong performance and training stability across various tasks but lack two critical properties of simulation-based methods: freedom of dimensionality and adaptability to different inference trajectories. To address this limitation, we propose the Multidimensional Adaptive Coefficient (MAC), a plug-in module for flow and diffusion models that extends conventional unidimensional coefficients to multidimensional ones and enables inference trajectory-wise adaptation. MAC is trained via simulation-based feedback through adversarial refinement. Empirical results across diverse frameworks and datasets demonstrate that MAC enhances generative quality with high training efficiency. Consequently, our work offers a new perspective on inference trajectory optimality, encouraging future research to move beyond vector field design and to leverage training-efficient, simulation-based optimization.'}",https://openreview.net{'value': '/pdf/43ed4a1987d7e6641880382945f473e2f20515e6.pdf'},{'title_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=VBTHduhm4K,{'value': 'Permutation-based Rank Test in the Presence of Discretization and Application in Causal Discovery with Mixed Data'},Xinshuai Dong; Ignavier Ng; Boyang Sun; Haoyue Dai; Guang-Yuan Hao; Shunxing Fan; Peter Spirtes; Yumou Qiu; Kun Zhang,~Xinshuai_Dong1; ~Ignavier_Ng1; ~Boyang_Sun1; ~Haoyue_Dai1; ~Guang-Yuan_Hao1; ~Shunxing_Fan1; ~Peter_Spirtes1; ~Yumou_Qiu2; ~Kun_Zhang1,"{'value': ['Rank Test', 'Discretization', 'Causal Discovery']}","{'value': 'Recent advances have shown that statistical tests for the rank of cross-covariance matrices play an important role in causal discovery. These rank tests include partial correlation tests as special cases and provide further graphical information about latent variables. Existing rank tests typically assume that all the continuous variables can be perfectly measured, and yet, in practice many variables can only be measured after discretization. For example, in psychometric studies, the continuous level of certain personality dimensions of a person can only be measured after being discretized into order-preserving options such as disagree, neutral, and agree. Motivated by this, we propose Mixed data Permutation-based Rank Test (MPRT), which properly controls the statistical errors even when some or all variables are discretized. Theoretically, we establish the exchangeability and estimate the asymptotic null distribution by permutations; as a consequence, MPRT can effectively control the Type I error in the presence of discretization while previous methods cannot. Empirically, our method is validated by extensive experiments on synthetic data and real-world data to demonstrate its effectiveness as well as applicability in causal discovery (code will be available at https://github.com/dongxinshuai/scm-identify).'}",https://openreview.net{'value': '/pdf/011c7851cfb8ccbe5fcddd736cf2c5ee5094f74f.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=V7JPraxi5j,{'value': 'UP-VLA:  A Unified Understanding and Prediction Model for Embodied Agent'},Jianke Zhang; Yanjiang Guo; Yucheng Hu; Xiaoyu Chen; Xiang Zhu; Jianyu Chen,~Jianke_Zhang1; ~Yanjiang_Guo1; ~Yucheng_Hu1; ~Xiaoyu_Chen4; ~Xiang_Zhu2; ~Jianyu_Chen1,"{'value': ['VLA', 'VLM', 'Embodied Agent']}","{'value': 'Recent advancements in Vision-Language-Action (VLA) models have leveraged pre-trained Vision-Language Models (VLMs) to improve the generalization capabilities.\nVLMs, typically pre-trained on vision-language understanding tasks, provide rich semantic knowledge and reasoning abilities. \nHowever, prior research has shown that VLMs often focus on\nhigh-level semantic content and neglect low-level features, \nlimiting their ability to capture detailed spatial information and understand physical dynamics.\nThese aspects, which are crucial for embodied control tasks, remain underexplored in existing pre-training paradigms.\nIn this paper, we investigate the training paradigm for VLAs, and \nintroduce \\textbf{UP-VLA}, a \\textbf{U}nified VLA model training with both multi-modal \\textbf{U}nderstanding and future \\textbf{P}rediction objectives, enhancing both high-level semantic comprehension and low-level spatial understanding. Experimental results show that UP-VLA achieves a 33\\% improvement on the Calvin ABC-D benchmark compared to the previous state-of-the-art method. Additionally, UP-VLA demonstrates improved success rates in real-world manipulation tasks, particularly those requiring precise spatial information.'}",https://openreview.net{'value': '/pdf/a31d9729845e48950a82af3a4935b4f181940e6e.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=UtlFqRDJKl,"{'value': 'TabSDS: a Lightweight, Fully Non-Parametric, and Model Free Approach for Generating Synthetic Tabular Data'}",Elias Chaibub Neto,~Elias_Chaibub_Neto1,"{'value': ['Tabular synthetic data', 'non-parametric', 'model-free', 'lightweight']}","{'value': 'The development of deep generative models for tabular data is currently a very active research area in machine learning. These models, however, tend to be computationally heavy and require careful tuning of multiple model parameters. In this paper, we propose TabSDS - a lightweight, non-parametric, and model free alternative to tabular deep generative models which leverages rank and data shuffling transformations for generating synthetic data which closely approximates the joint probability distribution of the real data. We evaluate TabSDS against multiple baselines implemented in the Synthcity Python library across several datasets. TabSDS showed very competitive performance against all baselines (including TabDDPM - a strong baseline model for tabular data generation). Importantly, the execution time of TabSDS is orders of magnitude faster than the deep generative baselines, and also considerably faster than other computationally efficient baselines such as adversarial random forests.'}",https://openreview.net{'value': '/pdf/0df94cfebb6fff1f894e2e961781b346e4b409b2.pdf'},{'title_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=Us8v5tDOFd,{'value': 'Point Cloud Dataset Distillation'},Deyu Bo; Xinchao Wang,~Deyu_Bo1; ~Xinchao_Wang1,"{'value': ['Dataset Distillation', 'Point Cloud']}","{'value': 'This study introduces dataset distillation (DD) tailored for 3D data, particularly point clouds. DD aims to substitute large-scale real datasets with a small set of synthetic samples while preserving model performance. Existing methods mainly focus on structured data such as images. However, adapting DD for unstructured point clouds poses challenges due to their diverse orientations and resolutions in 3D space. To address these challenges, we theoretically demonstrate the importance of matching rotation-invariant features between real and synthetic data for 3D distillation. We further propose a plug-and-play point cloud rotator to align the point cloud to a canonical orientation, facilitating the learning of rotation-invariant features by all point cloud models. Furthermore, instead of optimizing fixed-size synthetic data directly, we devise a point-wise generator to produce point clouds at various resolutions based on the sampled noise amount. Compared to conventional DD methods, the proposed approach, termed DD3D, enables efficient training on low-resolution point clouds while generating high-resolution data for evaluation, thereby significantly reducing memory requirements and enhancing model scalability. Extensive experiments validate the effectiveness of DD3D in shape classification and part segmentation tasks across diverse scenarios, such as cross-architecture and cross-resolution settings.'}",https://openreview.net{'value': '/pdf/821ef5ed7e16786a2d1c0f8880d907f7df47e018.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=Ukjl86EsIk,{'value': 'Decision Theoretic Foundations for Conformal Prediction: Optimal Uncertainty Quantification for Risk-Averse Agents'},Shayan Kiyani; George J. Pappas; Aaron Roth; Hamed Hassani,~Shayan_Kiyani2; ~George_J._Pappas1; ~Aaron_Roth1; ~Hamed_Hassani2,"{'value': ['Decision making', 'Uncertainty Quantification', 'Prediction sets', 'Conformal prediction', 'Calibration', 'Risk Averse', 'Risk Aware', 'Risk sensitive', 'distribution free']}","{'value': ""A fundamental question in data-driven decision making is how to quantify the uncertainty of predictions to inform risk-sensitive downstream actions, as often required in domains such as medicine. We develop a decision-theoretic foundation linking prediction sets to risk-averse decision-making, addressing three questions: (1) What is the correct notion of uncertainty quantification for risk-averse decision makers? We prove that prediction sets are optimal for decision makers who wish to optimize their value at risk. (2) What is the optimal policy that a risk averse decision maker should use to map prediction sets to actions? We show that a simple max-min decision policy is optimal for risk-averse decision makers. Finally, (3) How can we derive prediction sets that are optimal for such decision makers? We provide an exact characterization in the population regime and a distribution free finite-sample construction. These insights leads to *Risk-Averse Calibration (RAC)*, a principled algorithm that is both *practical*—exploiting black-box predictions to enhance downstream utility—and *safe*—adhering to user-defined risk thresholds. We experimentally demonstrate RAC's advantages in medical diagnosis and recommendation systems, showing that it substantially improves the trade-off between safety and utility, delivering higher utility than existing methods while avoiding critical errors.""}",https://openreview.net{'value': '/pdf/0fe770c2b744b8b1bf4d1d93431f6677c823c95e.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=UeB3Hdrhda,{'value': 'Training a Generally Curious Agent'},Fahim Tajwar; Yiding Jiang; Abitha Thankaraj; Sumaita Sadia Rahman; J Zico Kolter; Jeff Schneider; Russ Salakhutdinov,~Fahim_Tajwar1; ~Yiding_Jiang2; ~Abitha_Thankaraj1; ~Sumaita_Sadia_Rahman1; ~J_Zico_Kolter1; ~Jeff_Schneider1; ~Russ_Salakhutdinov1,"{'value': ['LLM Agent', 'Synethic Data', 'Multiturn finetuning']}","{'value': ""Efficient exploration is essential for intelligent systems interacting with their environment, but existing language models often fall short in scenarios that require strategic information gathering. In this paper, we present **Paprika**, a fine-tuning approach that enables language models to develop general decision-making capabilities that are not confined to particular environments. By training on synthetic interaction data from different tasks that require diverse strategies, Paprika teaches models to explore and adapt their behavior on a new task based on environment feedback in-context without more gradient updates. Experimental results show that models fine-tuned with Paprika can effectively transfer their learned decision-making capabilities to entirely unseen tasks without additional training. Unlike traditional training, our approach's primary bottleneck lies in sampling useful interaction data instead of model updates. To improve sample efficiency, we propose a curriculum learning strategy that prioritizes sampling trajectories from tasks with high learning potential. These results suggest a promising path towards AI systems that can autonomously solve novel sequential decision-making problems that require interactions with the external world.""}",https://openreview.net{'value': '/pdf/343ed2b173782ae353b1802ea0a0774532296a3a.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=Uc0dTE2Wox,{'value': 'Rethinking Benign Overfitting in Two-Layer Neural Networks'},Ruichen Xu; Kexin Chen,~Ruichen_Xu1; ~Kexin_Chen4,"{'value': ['Benign overfitting', 'long-tailed data', 'two-layer neural networks']}","{'value': 'Recent theoretical studies (Kou et al., 2023; Cao et al., 2022) revealed a sharp phase transition from benign to harmful overfitting when the\nnoise-to-feature ratio exceeds a threshold—a situation common in long-tailed data distributions where atypical data is prevalent. However, such harmful overfitting rarely happens in overparameterized neural networks. Further experimental results suggested that memorization is necessary for achieving near-optimal generalization error in long-tailed data distributions (Feldman & Zhang, 2020). We argue that this discrepancy between theoretical predictions and empirical observations arises because previous feature-noise data models overlook the heterogeneous nature of noise across different data classes. In this paper, we refine the feature-noise data model by incorporating class-dependent heterogeneous noise and re-examine the overfitting phenomenon in neural networks. Through a comprehensive analysis of the training dynamics, we establish test loss bounds for the refined model. Our findings reveal that neural networks can leverage ""data noise"" to learn implicit features that improve the classification accuracy for long-tailed data. Our analysis also provides a training-free metric for evaluating data influence on test performance. Experimental validation on both synthetic and real-world datasets supports our theoretical results.'}",https://openreview.net{'value': '/pdf/e247731b079ecaf0aa651c2e0e2d51d26f854d7f.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=UWWNxyIT1h,{'value': 'Self-Consuming Generative Models with Adversarially Curated Data'},Xiukun Wei; Xueru Zhang,~Xiukun_Wei1; ~Xueru_Zhang2,"{'value': ['generative model', 'self-consuming loop', 'human feedback', 'adversarial curation', 'attack algorithms']}","{'value': 'Recent advances in generative models have made it increasingly difficult to distinguish real data from model-generated synthetic data. Using synthetic data for successive training of future model generations creates “self-consuming loops,” which may lead to model collapse or training instability. Furthermore, synthetic data is often subject to human feedback and curated by users based on their preferences. Ferbach et al. (2024) recently showed that when data is curated according to user preferences, the self-consuming retraining loop drives the model to converge toward a distribution that optimizes those preferences. However, in practice, data curation is often noisy or adversarially manipulated. For example, competing platforms may recruit malicious users to adversarially curate data and disrupt rival models. In this paper, we study how generative models evolve under self-consuming retraining loops with noisy and adversarially curated data. We theoretically analyze the impact of such noisy data curation on generative models and identify conditions for the robustness and stability of the retraining process. Building on this analysis, we design attack algorithms for competitive adversarial scenarios, where a platform with a limited budget employs malicious users to misalign a rival’s model from actual user preferences. Experiments on both synthetic and real-world datasets demonstrate the effectiveness of the proposed algorithms.'}",https://openreview.net{'value': '/pdf/c49617f80222881b694df7c023117c57045cbb7d.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=UWTz4ai3FZ,{'value': 'LLM Enhancers for GNNs: An Analysis from the Perspective of Causal Mechanism Identification'},Hang Gao; Huang Wenxuan; Fengge Wu; Zhao Junsuo; Changwen Zheng; Huaping Liu,~Hang_Gao6; ~Huang_Wenxuan1; ~Fengge_Wu1; ~Zhao_Junsuo1; ~Changwen_Zheng1; ~Huaping_Liu3,{'value': ['Large language models; Graph Neural Netwroks; Causal']},"{'value': 'The use of large language models (LLMs) as feature enhancers to optimize node representations, which are then used as inputs for graph neural networks (GNNs), has shown significant potential in graph representation learning. However, the fundamental properties of this approach remain underexplored. To address this issue, we propose conducting a more in-depth analysis of this issue based on the interchange intervention method. First, we construct a synthetic graph dataset with controllable causal relationships, enabling precise manipulation of semantic relationships and causal modeling to provide data for analysis. Using this dataset, we conduct interchange interventions to examine the deeper properties of LLM enhancers and GNNs, uncovering their underlying logic and internal mechanisms. Building on the analytical results, we design a plug-and-play optimization module to improve the information transfer between LLM enhancers and GNNs. Experiments across multiple datasets and models validate the proposed module.'}",https://openreview.net{'value': '/pdf/5c64862070af4b6d4420126b50d6d8de73644ea6.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=UFlyLkvyAE,{'value': 'Graph Adaptive Autoregressive Moving Average Models'},Moshe Eliasof; Alessio Gravina; Andrea Ceni; Claudio Gallicchio; Davide Bacciu; Carola-Bibiane Schönlieb,~Moshe_Eliasof1; ~Alessio_Gravina1; ~Andrea_Ceni1; ~Claudio_Gallicchio1; ~Davide_Bacciu1; ~Carola-Bibiane_Schönlieb1,"{'value': ['Graph Neural Networks', 'Auto-regressive Moving Average']}","{'value': 'Graph State Space Models (SSMs) have recently been introduced to enhance Graph Neural Networks (GNNs) in modeling long-range interactions. Despite their success, existing methods either compromise on permutation equivariance or limit their focus to pairwise interactions rather than sequences. Building on the connection between Autoregressive Moving Average (ARMA)  and SSM, in this paper, we introduce GRAMA, a Graph Adaptive method based on a learnable ARMA framework that addresses these limitations. \nBy transforming from static to sequential graph data, GRAMA leverages the strengths of the ARMA framework, while preserving permutation equivariance. Moreover, GRAMA incorporates a selective attention mechanism for dynamic learning of ARMA coefficients, enabling efficient and flexible long-range information propagation. We also establish theoretical connections between GRAMA and Selective SSMs, providing insights into its ability to capture long-range dependencies. Experiments on 26 synthetic and real-world datasets demonstrate that GRAMA consistently outperforms backbone models and performs competitively with state-of-the-art methods.'}",https://openreview.net{'value': '/pdf/3732393d0dbdc3656d11ceed615f2bff475d02c9.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=ThMQfsBnje,{'value': 'SADA: Stability-guided Adaptive Diffusion Acceleration'},Ting Jiang; Yixiao Wang; Hancheng Ye; Zishan Shao; Jingwei Sun; Jingyang Zhang; Zekai Chen; Jianyi Zhang; Yiran Chen; Hai Li,~Ting_Jiang5; ~Yixiao_Wang7; ~Hancheng_Ye1; ~Zishan_Shao1; ~Jingwei_Sun2; ~Jingyang_Zhang2; ~Zekai_Chen4; ~Jianyi_Zhang1; ~Yiran_Chen1; ~Hai_Li1,"{'value': ['Diffusion Model', 'Efficient Algorithm', 'Training-Free Acceleration']}","{'value': 'Diffusion models have achieved remarkable success in generative tasks but suffer from high computational costs due to their iterative sampling process and quadratic‐attention costs. \nExisting training-free acceleration strategies that reduce per-step computation cost, while effectively reducing sampling time, demonstrate low faithfulness compared to the original baseline. \nWe hypothesize that this fidelity gap arises because (a) different prompts correspond to varying denoising trajectory, and (b) such methods do not consider the underlying ODE formulation and its numerical solution. \nIn this paper, we propose **Stability-guided Adaptive Diffusion Acceleration (SADA)**, a novel paradigm that unifies step-wise and token-wise sparsity decisions via a single stability criterion to accelerate sampling of ODE-based generative models (Diffusion and Flow-matching). \nFor (a), SADA adaptively allocates sparsity based on the sampling trajectory. \nFor (b), SADA introduces principled approximation schemes that leverage the precise gradient information from the numerical ODE solver.\nComprehensive evaluations on SD‐2, SDXL, and Flux using both EDM and DPM++ solvers reveal consistent $\\ge 1.8\\times$ speedups with minimal fidelity degradation (LPIPS $\\leq 0.10$ and FID $\\leq 4.5$) compared to unmodified baselines, significantly outperforming prior methods.\nMoreover, SADA adapts seamlessly to other pipelines and modalities: It accelerates ControlNet without any modifications and speeds up MusicLDM by \\(1.8\\times\\) with \\(\\sim 0.01\\) spectrogram LPIPS.\nOur code is available at: [https://github.com/Ting-Justin-Jiang/sada-icml](https://github.com/Ting-Justin-Jiang/sada-icml).'}",https://openreview.net{'value': '/pdf/c67bc6b44140b7535c28689099350611f60a9b8a.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=ThK6o74QLc,{'value': 'Adapting Precomputed Features for Efficient Graph Condensation'},Yuan Li; Jun Hu; Zemin Liu; Bryan Hooi; Jia Chen; Bingsheng He,~Yuan_Li12; ~Jun_Hu3; ~Zemin_Liu1; ~Bryan_Hooi1; ~Jia_Chen2; ~Bingsheng_He1,"{'value': ['graph neural networks', 'data condensation']}","{'value': ""Graph Neural Networks (GNNs) face significant computational challenges when handling large-scale graphs. To address this, Graph Condensation (GC) methods aim to compress large graphs into smaller, synthetic ones that are more manageable for GNN training. Recently, trajectory matching methods have shown state-of-the-art (SOTA) performance for GC, aligning the model's training behavior on a condensed graph with that on the original graph by guiding the trajectory of model parameters. However, these approaches require repetitive GNN retraining during condensation, making them computationally expensive. To address the efficiency issue, we completely bypass trajectory matching and propose a novel two-stage framework. The first stage, a precomputation stage, performs one-time message passing to extract structural and semantic information from the original graph. The second stage, a diversity-aware adaptation stage, performs class-wise alignment while maximizing the diversity of synthetic features. Remarkably, even with just the precomputation stage, which takes only seconds, our method either matches or surpasses 5 out of 9 baseline results. Extensive experiments show that our approach achieves comparable or better performance while being 96× to 2,455× faster than SOTA methods, making it more practical for large-scale GNN applications. Our code and data are available at https://github.com/Xtra-Computing/GCPA.""}",https://openreview.net{'value': '/pdf/47a950073bb46a20d3f647d7f3aed9a654b628ce.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=TXcifVbFpG,{'value': 'RepoAudit: An Autonomous LLM-Agent for Repository-Level Code Auditing'},Jinyao Guo; Chengpeng Wang; Xiangzhe Xu; Zian Su; Xiangyu Zhang,~Jinyao_Guo1; ~Chengpeng_Wang2; ~Xiangzhe_Xu1; ~Zian_Su1; ~Xiangyu_Zhang3,"{'value': ['agent', 'code reasoning', 'code auditing', 'bug detection']}","{'value': 'Code auditing is the process of reviewing code with the aim of identifying bugs. Large Language Models (LLMs) have demonstrated promising capabilities for this task without requiring compilation, while also supporting user-friendly customization. However, auditing a code repository with LLMs poses significant challenges: limited context windows and hallucinations can degrade the quality of bug reports, and analyzing large-scale repositories incurs substantial time and token costs, hindering efficiency and scalability.\n\nThis work introduces an LLM-based agent, RepoAudit, designed to perform autonomous repository-level code auditing. Equipped with agent memory, RepoAudit explores the codebase on demand by analyzing data-flow facts along feasible program paths within individual functions. It further incorporates a validator module to mitigate hallucinations by verifying data-flow facts and checking the satisfiability of path conditions associated with potential bugs, thereby reducing false positives. RepoAudit detects 40 true bugs across 15 real-world benchmark projects with a precision of 78.43%, requiring on average only 0.44 hours and $2.54 per project. Also, it detects 185 new bugs in high-profile projects, among which 174 have been confirmed or fixed. We have open-sourced RepoAudit at https://github.com/PurCL/RepoAudit.'}",https://openreview.net{'value': '/pdf/a1873b8175a0bde39dcadf38e1e9824f2d59e31b.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=TOn1rhgdeD,{'value': 'Privacy Amplification Through Synthetic Data: Insights from Linear Regression'},Clément Pierquin; Aurélien Bellet; Marc Tommasi; Matthieu Boussard,~Clément_Pierquin1; ~Aurélien_Bellet1; ~Marc_Tommasi1; ~Matthieu_Boussard1,"{'value': ['Differential Privacy', 'Synthetic Data']}","{'value': ""Synthetic data inherits the differential privacy guarantees of the model used to generate it. Additionally, synthetic data may benefit from privacy amplification when the generative model is kept hidden. While empirical studies suggest this phenomenon, a rigorous theoretical understanding is still lacking. In this paper, we investigate this question through the well-understood framework of linear regression. First, we establish negative results showing that if an adversary controls the seed of the generative model, a single synthetic data point can leak as much information as releasing the model itself. Conversely, we show that when synthetic data is generated from random inputs, releasing a limited number of synthetic data points amplifies privacy beyond the model's inherent guarantees. We believe our findings in linear regression can serve as a foundation for deriving more general bounds in the future.""}",https://openreview.net{'value': '/pdf/ed3b0d55b43ad6ea61b1ab6c5f6bc14f83ae12b5.pdf'},{'title_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=TFXxarWZzv,{'value': 'Tokenized Bandit for LLM Decoding and Alignment'},Suho Shin; Chenghao Yang; Haifeng Xu; MohammadTaghi Hajiaghayi,~Suho_Shin1; ~Chenghao_Yang1; ~Haifeng_Xu1; ~MohammadTaghi_Hajiaghayi1,"{'value': ['Contextual Bandit', 'Multi-armed Bandit', 'Large Language Model', 'LLM Alignment', 'Decoding-time Alignment', 'Decoding Algorithm']}","{'value': ""We introduce the tokenized linear bandit (TLB) and multi-armed bandit (TMAB), variants of linear and stochastic multi-armed bandit problems inspired by LLM decoding and alignment. In these problems, at each round $t \\in [T]$, a user submits a query (context), and the decision maker (DM) sequentially selects a token irrevocably from a token set. Once the sequence is complete, the DM observes a random utility from the user, whose expectation is presented by a sequence function mapping the chosen token sequence to a nonnegative real value that depends on the query.\n\nIn both problems, we first show that learning is impossible without any structure on the sequence function.\nWe introduce a natural assumption, diminishing distance with more commons (DDMC), and propose algorithms with regret $\\tilde{O}(L\\sqrt{T})$ and $\\tilde{O}(L\\sqrt{T^{2/3}})$ for TLB and TMAB, respectively.\nAs a side product, we obtain an (almost) optimality of the greedy decoding for LLM decoding algorithm under DDMC, which justifies the unresaonable effectiveness of greedy decoding in several tasks.\nThis also has an immediate application to decoding-time LLM alignment, when the misaligned utility can be represented as the frozen LLM's utility and a linearly realizable latent function.\nWe finally validate our algorithm's performance empirically as well as verify our assumptions using synthetic and real-world datasets.""}",https://openreview.net{'value': '/pdf/10a67bce5091f91b7314774b23dd77bf0d4874df.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=TCsdlqzZNL,{'value': 'Enhancing Cooperative Multi-Agent Reinforcement Learning with State Modelling and Adversarial Exploration'},Andreas Kontogiannis; Konstantinos Papathanasiou; Yi Shen; Giorgos Stamou; Michael M. Zavlanos; George Vouros,~Andreas_Kontogiannis1; ~Konstantinos_Papathanasiou1; ~Yi_Shen3; ~Giorgos_Stamou1; ~Michael_M._Zavlanos2; ~George_Vouros1,"{'value': ['Cooperative Multi-Agent Reinforcement Learning', 'State Modelling', 'Sparse Reward']}","{'value': ""Learning to cooperate in distributed partially observable environments with no communication abilities poses significant challenges for multi-agent deep reinforcement learning (MARL). This paper addresses key concerns in this domain, focusing on inferring state representations from individual agent observations and leveraging these representations to enhance agents' exploration and collaborative task execution policies. To this end, we propose a novel state modelling framework for cooperative MARL, where agents infer meaningful belief representations of the non-observable state, with respect to optimizing their own policies, while filtering redundant and less informative joint state information. Building upon this framework, we propose the MARL SMPE$^2$ algorithm. In SMPE$^2$, agents enhance their own policy's discriminative abilities under partial observability, explicitly by incorporating their beliefs into the policy network, and implicitly by adopting an adversarial type of exploration policies which encourages agents to discover novel, high-value states while improving the discriminative abilities of others. Experimentally, we show that SMPE$^2$ outperforms a plethora of state-of-the-art MARL algorithms in complex fully cooperative tasks from the MPE, LBF, and RWARE benchmarks.""}",https://openreview.net{'value': '/pdf/3ea46bea6f8a096cc159b06d7614626459d8a4f7.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=T5IZ32ImAB,{'value': 'Graph Diffusion for Robust Multi-Agent Coordination'},Xianghua Zeng; Hang Su; Zhengyi Wang; Zhiyuan LIN,~Xianghua_Zeng1; ~Hang_Su3; ~Zhengyi_Wang1; ~Zhiyuan_LIN5,"{'value': ['multi-agent coordination', 'offline reinforcement learning', 'diffusion models']}","{'value': 'Offline multi-agent reinforcement learning (MARL) struggles to estimate out-of-distribution states and actions due to the absence of real-time environmental feedback. While diffusion models show promise in addressing these challenges, their application primarily focuses on independently diffusing the historical trajectories of individual agents, neglecting crucial multi-agent coordination dynamics and reducing policy robustness in dynamic environments. In this paper, we propose MCGD, a novel Multi-agent Coordination framework based on Graph Diffusion models to improve the effectiveness and robustness of collaborative policies. Specifically, we begin by constructing a sparse coordination graph that includes continuous node attributes and discrete edge attributes to effectively identify the underlying dynamics of multi-agent interactions. Next, we derive transition probabilities between edge categories and present adaptive categorical diffusion to capture the structure diversity of multi-agent coordination. Leveraging this coordination structure, we define neighbor-dependent forward noise and develop anisotropic diffusion to enhance the action diversity of each agent. Extensive experiments across various multi-agent environments demonstrate that MCGD significantly outperforms existing state-of-the-art baselines in coordination performance and policy robustness in dynamic environments.'}",https://openreview.net{'value': '/pdf/79f3d75d3322bdd5bddcd896cfb54793f6e97e57.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=SyQPiZJVWY,{'value': 'LLM-SRBench: A New Benchmark for Scientific Equation Discovery with Large Language Models'},Parshin Shojaee; Ngoc-Hieu Nguyen; Kazem Meidani; Amir Barati Farimani; Khoa D Doan; Chandan K. Reddy,~Parshin_Shojaee1; ~Ngoc-Hieu_Nguyen1; ~Kazem_Meidani1; ~Amir_Barati_Farimani2; ~Khoa_D_Doan1; ~Chandan_K._Reddy1,"{'value': ['Benchmark', 'Scientific Discovery', 'Large Language Models', 'Symbolic Regression']}","{'value': 'Scientific equation discovery is a fundamental task in the history of scientific progress, enabling the derivation of laws governing natural phenomena. Recently, Large Language Models (LLMs) have gained interest for this task due to their potential to leverage embedded scientific knowledge for hypothesis generation. However, evaluating the true discovery capabilities of these methods remains challenging, as existing benchmarks often rely on common equations that are susceptible to memorization by LLMs, leading to inflated performance metrics that do not reflect actual discovery. In this paper, we introduce LLM-SRBench, a comprehensive benchmark with 239 challenging problems across four scientific domains specifically designed to evaluate LLM-based scientific equation discovery methods while preventing trivial memorization. Our benchmark comprises two main categories: LSR-Transform, which transforms common physical models into less common mathematical representations to test reasoning beyond memorization, and LSR-Synth, which introduces synthetic, discovery-driven problems requiring data-driven reasoning. Through extensive evaluation of several state-of-the-art methods on LLM-SRBench, using both open and closed LLMs, we find that the best-performing system so far achieves only 31.5% symbolic accuracy.\nThese findings highlight the challenges of scientific equation discovery, positioning LLM-SRBench as a valuable resource for future research.'}",https://openreview.net{'value': '/pdf/48d1424bf6e96316c2c8fc42ae1a34bf9489b153.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=Sp7jclUwkV,{'value': 'Simultaneous Multi-Robot Motion Planning with Projected Diffusion Models'},Jinhao Liang; Jacob K Christopher; Sven Koenig; Ferdinando Fioretto,~Jinhao_Liang1; ~Jacob_K_Christopher1; ~Sven_Koenig1; ~Ferdinando_Fioretto1,"{'value': ['Multi-Agent Path Planning', 'Diffusion Models']}","{'value': 'Recent advances in diffusion models hold significant potential in robotics, enabling the generation of diverse and smooth trajectories directly from raw representations of the environment. Despite this promise, applying diffusion models to motion planning remains challenging due to their difficulty in enforcing critical constraints, such as collision avoidance and kinematic feasibility. These limitations become even more pronounced in Multi-Robot Motion Planning (MRMP), where multiple robots must coordinate in shared spaces. To address these challenges, this work proposes **S**imultaneous **M**RMP **D**iffusion (SMD), a novel approach integrating constrained optimization into the diffusion sampling process to produce collision-free, kinematically feasible trajectories. Additionally, the paper introduces a comprehensive MRMP benchmark to evaluate trajectory planning algorithms across scenarios with varying robot densities, obstacle complexities, and motion constraints. Experimental results show SMD consistently outperforms classical and other learning-based motion planners, achieving higher success rates and efficiency in complex multi-robot environments. The code and implementation are available at https://github.com/RAISELab-atUVA/Diffusion-MRMP.'}",https://openreview.net{'value': '/pdf/d76930933d1acce5a0a7cec4fc6c587d2ee7f7aa.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=SnZ7SKykHh,{'value': 'PokéChamp: an Expert-level Minimax Language Agent'},Seth Karten; Andy Luu Nguyen; Chi Jin,~Seth_Karten1; ~Andy_Luu_Nguyen1; ~Chi_Jin1,"{'value': ['multi-agent systems', 'LLM Agents', 'competitive games', 'partially observable', 'test-time compute', 'pokemon']}","{'value': 'We introduce PokéChamp, a minimax agent powered by Large Language Models (LLMs) for Pokémon battles. Built on a general framework for two-player competitive games, PokéChamp leverages the generalist capabilities of LLMs to enhance minimax tree search. Specifically, LLMs replace three key modules: (1) player action sampling, (2) opponent modeling, and (3) value function estimation, enabling the agent to effectively utilize gameplay history and human knowledge to reduce the search space and address partial observability. Notably, our framework requires no additional LLM training. We evaluate PokéChamp in the popular Gen 9 OU format. When powered by GPT-4o, it achieves a win rate of 76\\% against the best existing LLM-based bot and 84\\% against the strongest rule-based bot, demonstrating its superior performance. Even with an open-source 8-billion-parameter Llama 3.1 model, PokéChamp consistently outperforms the previous best LLM-based bot, Pokéllmon powered by GPT-4o, with a 64\\% win rate. PokéChamp attains a projected Elo of 1300-1500 on the Pokémon Showdown online ladder, placing it among the top 30\\%-10\\% of human players. In addition, this work compiles the largest real-player Pokémon battle dataset, featuring over 3 million games, including more than 500k high-Elo matches. Based on this dataset, we establish a series of battle benchmarks and puzzles to evaluate specific battling skills. We further provide key updates to the local game engine. This work establishes Pokémon as a benchmark to integrate LLM technologies with game-theoretic algorithms addressing general multi-agent problems. Videos, code, and dataset are available online.'}",https://openreview.net{'value': '/pdf/c7f1cd4ef8e9ece7984843502e6e5e47d0748496.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=SgIg3cZjuN,{'value': 'Differential Privacy Under Class Imbalance: Methods and Empirical Insights'},Lucas Rosenblatt; Yuliia Lut; Ethan Turok; Marco Avella Medina; Rachel Cummings,~Lucas_Rosenblatt1; ~Yuliia_Lut1; ~Ethan_Turok1; ~Marco_Avella_Medina1; ~Rachel_Cummings1,"{'value': ['differential privacy', 'imbalanced learning', 'synthetic data', 'binary classification']}","{'value': 'Imbalanced learning occurs in classification settings where the distribution of class-labels is highly skewed in the training data, such as when predicting rare diseases or in fraud detection. This class imbalance presents a significant algorithmic challenge, which can be further exacerbated when privacy-preserving techniques such as differential privacy are applied to protect sensitive training data. Our work formalizes these challenges and provides a number of algorithmic solutions. We consider DP variants of pre-processing methods that privately augment the original dataset to reduce the class imbalance, alongside DP variants of in-processing techniques, which adjust the learning algorithm to account for the imbalance. For each method, we either adapt an existing imbalanced learning technique to the private setting or demonstrate its incompatibility with differential privacy. Finally, we empirically evaluate these privacy-preserving imbalanced learning methods under various data and distributional settings. We find that private synthetic data methods perform well as a data pre-processing step, while class-weighted ERMs are an alternative in higher-dimensional settings where private synthetic data suffers from the curse of dimensionality.'}",https://openreview.net{'value': '/pdf/765acb0d94c2615c9c8e7d3379e63bc0cfe29961.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=Sa9DluzlXJ,{'value': 'Finding Wasserstein Ball Center: Efficient Algorithm and The Applications in Fairness'},Yuntao Wang; Yuxuan Li; Qingyuan Yang; Hu Ding,~Yuntao_Wang4; ~Yuxuan_Li9; ~Qingyuan_Yang1; ~Hu_Ding1,"{'value': ['Wasserstein barycenter', 'fairness']}","{'value': 'Wasserstein Barycenter (WB) is a fundamental geometric optimization problem in machine learning, whose objective is to find a representative probability measure that minimizes the sum of Wasserstein distances to given distributions. WB has a number of applications in various areas.  However, \nWB may lead to unfair outcome towards underrepresented groups in some applications (e.g., a ""minority\'\' distribution may be far away from the obtained WB under Wasserstein distance). \nTo address this issue, we propose an alternative objective called  ""Wasserstein Ball Center (WBC)\'\'. Specifically, WBC is a distribution that encompasses all input distributions within the minimum Wasserstein distance, which can be formulated as a ``minmax\'\' optimization problem.\n We show that the WBC problem with fixed support is equivalent to solving a large-scale linear programming (LP) instance, which is quite different from the previously studied LP model for WB. By incorporating some novel observations on the induced normal equation, we propose an efficient algorithm that accelerates the interior point method by $O(\\min(N^2m, Nm^2, m^4))$ times (""$N$\'\' is the number of distributions and \n ""$m$\'\' is the support size).  Finally,  we conduct a set of experiments on  both synthetic and real-world datasets, demonstrating the computational efficiency  of our algorithm, and showing its ability to provide more fairness for input distributions.'}",https://openreview.net{'value': '/pdf/3cd1a56f7357d640e6f69df6609a05a1fca9e6df.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=SUX6Wzy9t1,{'value': 'Stochastic Poisson Surface Reconstruction with One Solve using Geometric Gaussian Processes'},Sidhanth Holalkere; David Bindel; Silvia Sellán; Alexander Terenin,~Sidhanth_Holalkere1; ~David_Bindel1; ~Silvia_Sellán1; ~Alexander_Terenin1,"{'value': ['stochastic poisson surface reconstruction', 'geometric gaussian processes', 'computer graphics']}","{'value': ""Poisson Surface Reconstruction is a widely-used algorithm for reconstructing a surface from an oriented point cloud. To facilitate applications where only partial surface information is available, or scanning is performed sequentially, a recent line of work proposes to incorporate uncertainty into the reconstructed surface via Gaussian process models. The resulting algorithms first perform Gaussian process interpolation, then solve a set of volumetric partial differential equations globally in space, resulting in a computationally expensive two-stage procedure. In this work, we apply recently-developed techniques from geometric Gaussian processes to combine interpolation and surface reconstruction into a single stage, requiring only one linear solve per sample. The resulting reconstructed surface samples can be queried locally in space, without the use of problem-dependent volumetric meshes or grids. These capabilities enable one to (a) perform probabilistic collision detection locally around the region of interest, (b) perform ray casting without evaluating points not on the ray's trajectory, and (c) perform next-view planning on a per-ray basis. They also do not requiring one to approximate kernel matrix inverses with diagonal matrices as part of intermediate computations, unlike prior methods. Results show that our approach provides a cleaner, more-principled, and more-flexible stochastic surface reconstruction pipeline.""}",https://openreview.net{'value': '/pdf/f509cf2e8ea833b50e50a2902ab536e1d337482c.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=SJkpCMeIxu,{'value': 'Breaking the Barrier of Hard Samples: A Data-Centric Approach to Synthetic Data for Medical Tasks'},MAYNARA DONATO DE SOUZA; Cleber Zanchettin,~MAYNARA_DONATO_DE_SOUZA1; ~Cleber_Zanchettin1,"{'value': ['Medical tasks', 'synthetic data', 'data-centric']}","{'value': ""Data scarcity and quality issues remain significant barriers to developing robust predictive models in medical research. Traditional reliance on real-world data often leads to biased models with poor generalizability across diverse patient populations. Synthetic data generation has emerged as a promising solution, yet challenges related to these sample's representativeness and effective utilization persist. This paper introduces Profile2Gen, a novel data-centric framework designed to guide the generation and refinement of synthetic data, focusing on addressing hard-to-learn samples in regression tasks. We conducted approximately 18,000 experiments to validate its effectiveness across six medical datasets, utilizing seven state-of-the-art generative models. Results demonstrate that refined synthetic samples can reduce predictive errors and enhance model reliability. Additionally, we generalize the DataIQ framework to support regression tasks, enabling its application in broader contexts. Statistical analyses confirm that our approach achieves equal or superior performance compared to models trained exclusively on real data.""}",https://openreview.net{'value': '/pdf/26d85c4924349ea4fc811f377cb41c26805a0907.pdf'},{'title_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=S9LkB0UBKb,{'value': 'The Role of Sparsity for Length Generalization in LLMs'},Noah Golowich; Samy Jelassi; David Brandfonbrener; Sham M. Kakade; Eran Malach,~Noah_Golowich1; ~Samy_Jelassi1; ~David_Brandfonbrener1; ~Sham_M._Kakade1; ~Eran_Malach3,"{'value': ['Length generalization', 'Transformers', 'Positional Encoding']}","{'value': ""Training large language models to predict beyond their training context lengths has drawn much attention in recent years, yet the principles driving such behavior of length generalization remain underexplored. We propose a new theoretical framework to study length generalization for the next-token prediction task, as performed by decoder-only transformers. Conceptually, we show that length generalization occurs as long as each predicted token depends on a small (fixed) number of previous tokens. We formalize such tasks via a notion we call k-sparse planted correlation distributions, and show that an idealized model of transformers which generalize attention heads successfully length-generalize on such tasks. As a bonus, our theoretical model allows us to provide justifications for techniques to modify positional embeddings which have been introduced to improve length generalization, such as position coupling.\n\nWe support our theoretical results with experiments on synthetic tasks and natural language, which confirm that a key factor driving length generalization is indeed a ``sparse'' dependency structure of each token on the previous ones. Further, inspired by our theory, we introduce Predictive Position Coupling, a generalization of position coupling which trains the transformer to predict the position IDs used in a positional coupling approach.  Predictive Position Coupling thereby allows us to broaden the array of tasks to which Position Coupling can successfully be applied to achieve length generalization.""}",https://openreview.net{'value': '/pdf/1afeb006dcd50f9e5c7d5bbb572b842013b30297.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=S8kbmk12Oo,{'value': 'AutoEval Done Right: Using Synthetic Data for Model Evaluation'},Pierre Boyeau; Anastasios Nikolas Angelopoulos; Tianle Li; Nir Yosef; Jitendra Malik; Michael I. Jordan,~Pierre_Boyeau1; ~Anastasios_Nikolas_Angelopoulos1; ~Tianle_Li2; ~Nir_Yosef1; ~Jitendra_Malik2; ~Michael_I._Jordan2,"{'value': ['Prediction-powered inference', 'model evaluation', 'large language models', 'annotation', 'synthetic data', 'statistical inference']}",{'value': 'The evaluation of machine learning models using human-labeled validation data can be expensive and time-consuming. AI-labeled synthetic data can be used to decrease the number of human annotations required for this purpose in a process called autoevaluation. We suggest efficient and statistically principled algorithms for this purpose that improve sample efficiency while remaining unbiased.'},https://openreview.net{'value': '/pdf/9084501c0d9f75dabfca3985b3265837bc68cee2.pdf'},{'title_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=Rzzy69QL6Q,{'value': 'Dual Feature Reduction for the Sparse-group Lasso and its Adaptive Variant'},Fabio Feser; Marina Evangelou,~Fabio_Feser1; ~Marina_Evangelou1,"{'value': ['penalized regression', 'screening rules', 'karush–kuhn–tucker', 'lasso', 'high-dimensional', 'sparse-group', 'feature reduction']}","{'value': 'The sparse-group lasso performs both variable and group selection, simultaneously using the strengths of the lasso and group lasso. It has found widespread use in genetics, a field that regularly involves the analysis of high-dimensional data, due to its sparse-group penalty, which allows it to utilize grouping information. However, the sparse-group lasso can be computationally expensive, due to the added shrinkage complexity, and its additional hyperparameter that needs tuning. This paper presents a novel feature reduction method, Dual Feature Reduction (DFR), that uses strong screening rules for the sparse-group lasso and the adaptive sparse-group lasso to reduce their input space before optimization, without affecting solution optimality. DFR applies two layers of screening through the application of dual norms and subdifferentials. Through synthetic and real data studies, it is shown that DFR drastically reduces the computational cost under many different scenarios.'}",https://openreview.net{'value': '/pdf/e76259aacff0d23cbff63654eb6a61e19bcfb578.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=RvYO10B5ss,{'value': 'MASS: Mathematical Data Selection via Skill Graphs for Pretraining Large Language Models'},Jiazheng Li; Lu Yu; Qing Cui; Zhiqiang Zhang; JUN ZHOU; Yanfang Ye; Chuxu Zhang,~Jiazheng_Li3; ~Lu_Yu1; ~Qing_Cui1; ~Zhiqiang_Zhang4; ~JUN_ZHOU6; ~Yanfang_Ye1; ~Chuxu_Zhang2,"{'value': ['Large language models', 'Data selection', 'Pre-training']}","{'value': 'High-quality data plays a critical role in the pretraining and fine-tuning of large language models (LLMs), even determining their performance ceiling to some degree. Consequently, numerous data selection methods have been proposed to identify subsets of data that can effectively and efficiently enhance model performance. However, most of these methods focus on general data selection and tend to overlook the specific nuances of domain-related data. In this paper, we introduce MASS, a Mathematical data Selection framework using the Skill graph for pretraining LLMs in the mathematical reasoning domain. By taking into account the unique characteristics of mathematics and reasoning, we construct a skill graph that captures the mathematical skills and their interrelations from a reference dataset. This skill graph guides us in assigning quality scores to the target dataset, enabling us to select the top-ranked subset which is further used to pretrain LLMs. Experimental results demonstrate the efficiency and effectiveness of MASS across different model sizes (1B and 7B) and pretraining datasets (web data and synthetic data). Specifically, in terms of efficiency, models trained on subsets selected by MASS can achieve similar performance to models trained on the original datasets, with a significant reduction in the number of trained tokens - ranging from 50\\% to 70\\% fewer tokens. In terms of effectiveness, when trained on the same amount of tokens, models trained on the data selected by MASS outperform those trained on the original datasets by 3.3\\% to 5.9\\%. These results underscore the potential of MASS to improve both the efficiency and effectiveness of pretraining LLMs.'}",https://openreview.net{'value': '/pdf/4c1ab5b1d836af5d92dbc82507465f1c67d29c96.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=Rk18ZikrFI,{'value': 'Variational Rectified Flow Matching'},Pengsheng Guo; Alex Schwing,~Pengsheng_Guo1; ~Alex_Schwing1,"{'value': ['Flow Matching', 'Diffusion Model', 'Generative Model']}","{'value': ""We study Variational Rectified Flow Matching, a framework that enhances classic rectified flow matching by modeling multi-modal velocity vector-fields. At inference time, classic rectified flow matching 'moves' samples from a source distribution to the target distribution by solving an ordinary differential equation via integration along a velocity vector-field. At training time, the velocity vector-field is learnt by linearly interpolating between coupled samples one drawn from the source and one drawn from the target distribution randomly. This leads to ''ground-truth'' velocity vector-fields that point in different directions at the same location, i.e., the velocity vector-fields are multi-modal/ambiguous. However, since training uses a standard mean-squared-error loss, the learnt velocity vector-field averages ''ground-truth'' directions and isn't multi-modal. In contrast,  variational rectified flow matching learns and samples from multi-modal flow directions. We show on synthetic data, MNIST, CIFAR-10, and ImageNet that variational rectified flow matching leads to compelling results.""}",https://openreview.net{'value': '/pdf/1f4f3677cac865106f7e6174b126c17d50f80dda.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=RfQNtVTY7Q,{'value': 'Efficient Network Automatic Relevance Determination'},Hongwei Zhang; Ziqi Ye; Xinyuan Wang; Xin Guo; Zenglin Xu; Yuan Cheng; Zixin Hu; Yuan Qi,~Hongwei_Zhang3; ~Ziqi_Ye1; ~Xinyuan_Wang6; ~Xin_Guo2; ~Zenglin_Xu2; ~Yuan_Cheng1; ~Zixin_Hu1; ~Yuan_Qi2,"{'value': ['Automatic Relevance Determination', 'Graphical Lasso']}","{'value': 'We propose Network Automatic Relevance Determination (NARD), an extension of ARD for linearly probabilistic models, to simultaneously model sparse relationships between inputs $X \\in \\mathbb R^{d \\times N}$ and outputs $Y \\in \\mathbb R^{m \\times N}$, while capturing the correlation structure among the $Y$. NARD employs a matrix normal prior which contains a sparsity-inducing parameter to identify and discard irrelevant features, thereby promoting sparsity in the model. Algorithmically, it iteratively updates both the precision matrix and the relationship between $Y$ and the refined inputs. To mitigate the computational inefficiencies of the $\\mathcal O(m^3 + d^3)$ cost per iteration, we introduce Sequential NARD, which evaluates features sequentially, and a Surrogate Function Method, leveraging an efficient approximation of the marginal likelihood and simplifying the calculation of determinant and inverse of an intermediate matrix. Combining the Sequential update with the Surrogate Function method further reduces computational costs. The computational complexity per iteration for these three methods is reduced to $\\mathcal O(m^3+p^3)$, $\\mathcal O(m^3 + d^2)$, $\\mathcal O(m^3+p^2)$ respectively, where $p \\ll d$ is the final number of features in the model. Our methods demonstrate significant improvements in computational efficiency with comparable performance on both synthetic and real-world datasets.'}",https://openreview.net{'value': '/pdf/5f4821ddb712eb0dfa518c0b10aa9c1106085c0c.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=RQwexjUCxm,{'value': 'From Debate to Equilibrium: Belief‑Driven Multi‑Agent LLM Reasoning via Bayesian Nash Equilibrium'},Xie Yi; Zhanke Zhou; Chentao Cao; Qiyu Niu; Tongliang Liu; Bo Han,~Xie_Yi1; ~Zhanke_Zhou1; ~Chentao_Cao1; ~Qiyu_Niu1; ~Tongliang_Liu1; ~Bo_Han1,"{'value': ['Large Language Models', 'Reasoning', 'Multiagent Reasoning']}","{'value': 'Multi-agent frameworks can substantially boost the reasoning power of large language models (LLMs), but they typically incur heavy computational costs and lack convergence guarantees. To overcome these challenges, we recast multi-LLM coordination as an incomplete-information game and seek a Bayesian Nash equilibrium (BNE), in which each agent optimally responds to its probabilistic beliefs about the strategies of others. We introduce Efficient Coordination via Nash Equilibrium (ECON), a hierarchical reinforcement-learning paradigm that marries distributed reasoning with centralized final output. Under ECON, each LLM independently selects responses that maximize its expected reward, conditioned on its beliefs about co-agents, without requiring costly inter-agent exchanges.\nWe mathematically prove that ECON attains a markedly tighter regret bound than non-equilibrium multi-agent schemes. Empirically, ECON outperforms existing multi-LLM approaches by 11.2% on average across six benchmarks spanning complex reasoning and planning tasks. Further experiments demonstrate ECON’s ability to flexibly incorporate additional models, confirming its scalability and paving the way toward larger, more powerful multi-LLM ensembles. The code is publicly available at: https://github.com/tmlr-group/ECON.'}",https://openreview.net{'value': '/pdf/a1eece15699456124c78cf6db973f89168b5b339.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=RO5OGOzs6M,{'value': 'PINNsAgent: Automated PDE Surrogation with Large Language Models'},Qingpo Wuwu; Chonghan Gao; Tianyu Chen; Yihang Huang; Yuekai Zhang; Jianing Wang; Jianxin Li; Haoyi Zhou; Shanghang Zhang,~Qingpo_Wuwu1; ~Chonghan_Gao1; ~Tianyu_Chen1; ~Yihang_Huang2; ~Yuekai_Zhang2; ~Jianing_Wang6; ~Jianxin_Li3; ~Haoyi_Zhou1; ~Shanghang_Zhang4,"{'value': ['pinns', 'llm-agent']}","{'value': 'Solving partial differential equations (PDEs) using neural methods has been a long-standing scientific and engineering research pursuit. Physics-Informed Neural Networks (PINNs) have emerged as a promising alternative to traditional numerical methods for solving PDEs. However, the gap between domain-specific knowledge and deep learning expertise often limits the practical application of PINNs. Previous works typically involve manually conducting extensive PINNs experiments and summarizing heuristic rules for hyperparameter tuning. In this work, we introduce PINNsAgent, a novel surrogation framework that leverages large language models (LLMs) to bridge the gap between domain-specific knowledge and deep learning. PINNsAgent integrates Physics-Guided Knowledge Replay (PGKR) for efficient knowledge transfer from solved PDEs to similar problems, and Memory Tree Reasoning for exploring the search space of optimal PINNs architectures. We evaluate PINNsAgent on 14 benchmark PDEs, demonstrating its effectiveness in automating the surrogation process and significantly improving the accuracy of PINNs-based solutions.'}",https://openreview.net{'value': '/pdf/0b5689674009f472e87504ca1bcbf73dc3e6f9e0.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=RBly0nOr2h,{'value': 'Categorical Schrödinger Bridge Matching'},Grigoriy Ksenofontov; Alexander Korotin,~Grigoriy_Ksenofontov1; ~Alexander_Korotin2,"{'value': ['Schrödinger Bridge', 'Entropic Optimal Transport', 'Optimal transport', 'Unpaired Learning', 'Discrete space']}","{'value': 'The Schrödinger Bridge (SB) is a powerful framework for solving generative modeling tasks such as unpaired domain translation. Most SB-related research focuses on continuous data space $\\mathbb{R}^{D}$ and leaves open theoretical and algorithmic questions about applying SB methods to discrete data, e.g, on finite spaces $\\mathbb{S}^{D}$. Notable examples of such sets $\\mathbb{S}$ are codebooks of vector-quantized (VQ) representations of modern autoencoders, tokens in texts, categories of atoms in molecules, etc. In this paper, we provide a theoretical and algorithmic foundation for solving SB in discrete spaces using the recently introduced Iterative Markovian Fitting (IMF) procedure. Specifically, we theoretically justify the convergence of discrete-time IMF (D-IMF) to SB in discrete spaces. This enables us to develop a practical computational algorithm for SB, which we call Categorical Schrödinger Bridge Matching (CSBM). We show the performance of CSBM via a series of experiments with synthetic data and VQ representations of images. The code of CSBM is available at [this repository](https://github.com/gregkseno/csbm).'}",https://openreview.net{'value': '/pdf/8c42f504a0e32830621f37ac3c665c645885a215.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=QxOgS8WwCr,{'value': 'Synthetic Face Datasets Generation via Latent Space Exploration from Brownian Identity Diffusion'},David Geissbühler; Hatef Otroshi Shahreza; Sébastien Marcel,~David_Geissbühler1; ~Hatef_Otroshi_Shahreza1; ~Sébastien_Marcel1,"{'value': ['Brownian Identity Diffusion', 'Face Recognition', 'Latent Space', 'Synthetic Dataset']}","{'value': 'Face recognition models are trained on large-scale datasets, which have privacy and ethical concerns. Lately, the use of synthetic data to complement or replace genuine data for the training of face recognition models has been proposed. While promising results have been obtained, it still remains unclear if generative models can yield diverse enough data for such tasks. In this work, we introduce a new method, inspired by the physical motion of soft particles subjected to stochastic Brownian forces, allowing us to sample identities distributions in a latent space under various constraints. We introduce three complementary algorithms, called Langevin, Dispersion, and DisCo, aimed at generating large synthetic face datasets. With this in hands, we generate several face datasets and benchmark them by training face recognition models, showing that data generated with our method exceeds the performance of previously GAN-based datasets and achieves competitive performance with state-of-the-art diffusion-based synthetic datasets. While diffusion models are shown to memorize training data, we prevent leakage in our new synthetic datasets, paving the way for more responsible synthetic datasets. Project page: https://www.idiap.ch/paper/synthetics-disco'}",https://openreview.net{'value': '/pdf/24d4f1164ab80d867cf4de87505afff619684d5e.pdf'},{'title_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=QuecSemZIy,{'value': 'KBQA-o1: Agentic Knowledge Base Question Answering with Monte Carlo Tree Search'},Haoran Luo; Haihong E; Yikai Guo; Qika Lin; Xiaobao Wu; Xinyu Mu; Wenhao Liu; Meina Song; Yifan Zhu; Anh Tuan Luu,~Haoran_Luo1; ~Haihong_E1; ~Yikai_Guo2; ~Qika_Lin1; ~Xiaobao_Wu1; ~Xinyu_Mu4; ~Wenhao_Liu4; ~Meina_Song1; ~Yifan_Zhu1; ~Anh_Tuan_Luu2,"{'value': ['Knowledge Base Question Answering', 'Large Language Model', 'LLM Agents', 'Monte Carlo Tree Search']}","{'value': ""Knowledge Base Question Answering (KBQA) aims to answer natural language questions with a large-scale structured knowledge base (KB). Despite advancements with large language models (LLMs), KBQA still faces challenges in weak KB awareness, imbalance between effectiveness and efficiency, and high reliance on annotated data. To address these challenges, we propose KBQA-o1, a novel agentic KBQA method with Monte Carlo Tree Search (MCTS). It introduces a ReAct-based agent process for stepwise logical form generation with KB environment exploration. Moreover, it employs MCTS, a heuristic search method driven by policy and reward models, to balance agentic exploration's performance and search space. With heuristic exploration, KBQA-o1 generates high-quality annotations for further improvement by incremental fine-tuning. Experimental results show that KBQA-o1 outperforms previous low-resource KBQA methods with limited annotated data, boosting Llama-3.1-8B model's GrailQA F1 performance to 78.5% compared to 48.5% of the previous sota method with GPT-3.5-turbo. Our code is publicly available.""}",https://openreview.net{'value': '/pdf/5e0f37d1f2efb61233f410b7041693458ed3f062.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=QlEx8f3S61,{'value': 'Federated Causal Structure Learning with Non-identical Variable Sets'},Yunxia Wang; Fuyuan CAO; Kui Yu; Jiye Liang,~Yunxia_Wang1; ~Fuyuan_CAO2; ~Kui_Yu2; ~Jiye_Liang1,"{'value': ['Federated causal structure learning', 'privacy-preserving', 'non-identical variable sets', 'spurious dependencies']}","{'value': 'Federated causal structure learning aims to infer causal relationships from data stored on individual clients, with privacy concerns. Most existing methods assume identical variable sets across clients and present federated strategies for aggregating local updates. However, in practice, clients often observe overlapping but non-identical variable sets, and non-overlapping variables may introduce spurious dependencies. Moreover, existing strategies typically reflect only the overall quality of local graphs, ignoring the varying importance of relationships within each graph. In this paper, we study federated causal structure learning with non-identical variable sets, aiming to design an effective strategy for aggregating “correct” and “good” (non-)causal relationships across distributed datasets. Specifically, we first develop theories for detecting spurious dependencies, examining whether the learned relationships are “correct” or not. Furthermore, we define stable relationships as those that are both “correct” and “good” across multiple graphs, and finally design a two-level priority selection strategy for aggregating local updates, obtaining a global causal graph over the integrated variables. Experimental results on synthetic, benchmark and real-world data demonstrate the effectiveness of our method.'}",https://openreview.net{'value': '/pdf/647d09a8d4c04285f3837baa4d219c7a7b4cbd93.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=QfKrcgyase,{'value': 'Propagate and Inject: Revisiting Propagation-Based Feature Imputation for Graphs with Partially Observed Features'},Daeho Um; Sunoh Kim; Jiwoong Park; Jongin Lim; Seong Jin Ahn; Seulki Park,~Daeho_Um1; ~Sunoh_Kim1; ~Jiwoong_Park1; ~Jongin_Lim1; ~Seong_Jin_Ahn1; ~Seulki_Park1,"{'value': ['graph neural networks', 'graphs', 'missing features']}","{'value': 'In this paper, we address learning tasks on graphs with missing features, enhancing the applicability of graph neural networks to real-world graph-structured data. We identify a critical limitation of existing imputation methods based on feature propagation: they produce channels with nearly identical values within each channel, and these low-variance channels contribute very little to performance in graph learning tasks. To overcome this issue, we introduce synthetic features that target the root cause of low-variance channel production, thereby increasing variance in these channels. By preventing propagation-based imputation methods from generating meaningless feature values shared across all nodes, our synthetic feature propagation scheme mitigates significant performance degradation, even under extreme missing rates. Extensive experiments demonstrate the effectiveness of our approach across various graph learning tasks with missing features, ranging from low to extremely high missing rates. Additionally, we provide both empirical evidence and theoretical proof to validate the low-variance problem. The source code is available at https://github.com/daehoum1/fisf.'}",https://openreview.net{'value': '/pdf/448520c0cda7a63b0dd5e96f33ac4f560de0f3ce.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=QW6f72tutX,{'value': 'Generative Human Trajectory Recovery via Embedding-Space Conditional Diffusion'},Kaijun Liu; Sijie Ruan; Liang Zhang; Cheng Long; Shuliang Wang; liang yu,~Kaijun_Liu3; ~Sijie_Ruan1; ~Liang_Zhang31; ~Cheng_Long1; ~Shuliang_Wang1; ~liang_yu1,"{'value': ['Trajectory recovery', 'Diffusion model', 'Self-supervised learning', 'Human mobility']}","{'value': 'Recovering human trajectories from incomplete or missing data is crucial for many mobility-based urban applications, e.g., urban planning, transportation, and location-based services. Existing methods mainly rely on recurrent neural networks or attention mechanisms. Though promising, they encounter limitations in capturing complex spatial-temporal dependencies in low-sampling trajectories. Recently, diffusion models show potential in content generation. However, most of proposed methods are used to generate contents in continuous numerical representations, which cannot be directly adapted to the human location trajectory recovery. In this paper, we introduce a conditional diffusion-based trajectory recovery method, namely, DiffMove. It first transforms locations in trajectories into the embedding space, in which the embedding denoising is performed, and then missing locations are recovered by an embedding decoder. DiffMove not only improves accuracy by introducing high-quality generative methods in the trajectory recovery, but also carefully models the transition, periodicity, and temporal patterns in human mobility. Extensive experiments based on two representative real-world mobility datasets are conducted, and the results show significant improvements (an average of 11% in recall) over the best baselines.'}",https://openreview.net{'value': '/pdf/302411c43b1aee85c921c195201fb97d81ffb33f.pdf'},{'title_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=QRms4lx0Fp,{'value': 'Evolving Minds: Logic-Informed Inference from Temporal Action Patterns'},Chao Yang; Shuting Cui; Yang Yang; Shuang Li,~Chao_Yang9; ~Shuting_Cui1; ~Yang_Yang56; ~Shuang_Li3,"{'value': ['Logic-Informed Temporal Point Process', 'Amortized Variational EM', 'Human-AI Collaboration']}","{'value': 'Understanding human mental states—such as intentions and desires—is crucial for natural AI-human collaboration. However, this is challenging because human actions occur irregularly over time, and the underlying mental states that drive these actions are unobserved. To tackle this, we propose a novel framework that combines a logic-informed temporal point process (TPP) with amortized variational Expectation-Maximization (EM). Our key innovation is integrating logic rules as priors to guide the TPP’s intensity function, allowing the model to capture the interplay between actions and mental events while reducing dependence on large datasets. To handle the intractability of mental state inference, we introduce a discrete-time renewal process to approximate the posterior. By jointly optimizing model parameters, logic rules, and inference networks, our approach infers entire mental event sequences and adaptively predicts future actions. Experiments on both synthetic and real-world datasets show that our method outperforms existing approaches in accurately inferring mental states and predicting actions, demonstrating its effectiveness in modeling human cognitive processes.'}",https://openreview.net{'value': '/pdf/18a491d3aa320a25dd15e237c748382955c88169.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=QRNpmG8XGd,{'value': 'Solving Linear-Gaussian Bayesian Inverse Problems with Decoupled Diffusion Sequential Monte Carlo'},Filip Ekström Kelvinius; Zheng Zhao; Fredrik Lindsten,~Filip_Ekström_Kelvinius1; ~Zheng_Zhao1; ~Fredrik_Lindsten1,"{'value': ['diffusion models', 'sequential monte carlo', 'posterior sampling']}","{'value': 'A recent line of research has exploited pre-trained generative diffusion models as priors for solving Bayesian inverse problems. We contribute to this research direction by designing a sequential Monte Carlo method for linear-Gaussian inverse problems which builds on ``decoupled diffusion"", where the generative process is designed such that larger updates to the sample are possible. The method is asymptotically exact and we demonstrate the effectiveness of our Decoupled Diffusion Sequential Monte Carlo (DDSMC) algorithm on both synthetic as well as protein and image data. Further, we demonstrate how the approach can be extended to discrete data.'}",https://openreview.net{'value': '/pdf/9a3ce331513a7ef32271aea9a904c509a50b3598.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=Q9DAI0AYv1,{'value': 'NExtLong: Toward Effective Long-Context Training without Long Documents'},Chaochen Gao; Xing W; Zijia Lin; Debing Zhang; Songlin Hu,~Chaochen_Gao1; ~Xing_W1; ~Zijia_Lin1; ~Debing_Zhang1; ~Songlin_Hu2,"{'value': ['Long-Context Model', 'Synthetic Data']}","{'value': ""Large language models (LLMs) with extended context windows have made significant strides yet remain a challenge due to the scarcity of long documents. Existing methods tend to synthesize long-context data but lack a clear mechanism to reinforce the long-range dependency modeling. To address this limitation, we propose NExtLong, a novel framework for synthesizing long-context data through Negative document Extension. NExtLong decomposes a document into multiple meta-chunks and extends the context by interleaving hard negative distractors retrieved from pretraining corpora. This approach compels the model to discriminate long-range dependent context from distracting content, enhancing its ability to model long-range dependencies. Extensive experiments demonstrate that NExtLong achieves significant performance improvements on the HELMET and RULER benchmarks compared to existing long-context synthesis approaches and leading models, which are trained on non-synthetic long documents. These findings highlight NExtLong's ability to reduce reliance on non-synthetic long documents, making it an effective framework for developing advanced long-context LLMs.""}",https://openreview.net{'value': '/pdf/8e6251659c42fbd3d850ef130218a665b3beb701.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=Py2KmXaRmi,{'value': 'Trajectory World Models for Heterogeneous Environments'},Shaofeng Yin; Jialong Wu; Siqiao Huang; Xingjian Su; Xu He; Jianye HAO; Mingsheng Long,~Shaofeng_Yin2; ~Jialong_Wu1; ~Siqiao_Huang1; ~Xingjian_Su1; ~Xu_He2; ~Jianye_HAO1; ~Mingsheng_Long5,"{'value': ['world models', 'pre-training', 'heterogeneous environments']}","{'value': 'Heterogeneity in sensors and actuators across environments poses a significant challenge to building large-scale pre-trained world models on top of this low-dimensional sensor information. In this work, we explore pre-training world models for heterogeneous environments by addressing key transfer barriers in both data diversity and model flexibility. We introduce UniTraj, a unified dataset comprising over one million trajectories from 80 environments, designed to scale data while preserving critical diversity. Additionally, we propose TrajWorld, a novel architecture capable of flexibly handling varying sensor and actuator information and capturing environment dynamics in-context. Pre-training TrajWorld on UniTraj yields substantial gains in transition prediction, achieves a new state-of-the-art for off-policy evaluation, and also delivers superior online performance of model predictive control. To the best of our knowledge, this work, for the first time, demonstrates the transfer benefits of world models across heterogeneous and complex control environments. Code and data are available at https://github.com/thuml/TrajWorld.'}",https://openreview.net{'value': '/pdf/a4a120a98c7328387e4f63a586ede81414c630b0.pdf'},{'title_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=PqJFVbJAMR,{'value': 'One-Shot Heterogeneous Federated Learning with Local Model-Guided Diffusion Models'},Mingzhao Yang; Shangchao Su; Bin Li; Xiangyang Xue,~Mingzhao_Yang1; ~Shangchao_Su2; ~Bin_Li4; ~Xiangyang_Xue2,"{'value': ['Federated Learning', 'Diffusion Model']}","{'value': 'In recent years, One-shot Federated Learning (OSFL) methods based on Diffusion Models (DMs) have garnered increasing attention due to their remarkable performance. However, most of these methods require the deployment of foundation models on client devices, which significantly raises the computational requirements and reduces their adaptability to heterogeneous client models. In this paper, we propose FedLMG, a heterogeneous one-shot Federated learning method with Local Model-Guided diffusion models. In our method, clients do not need access to any foundation models but only train and upload their local models, which is consistent with traditional FL methods. On the clients, we employ classification loss and batch normalization loss to capture the broad category features and detailed contextual features of the client distributions. On the server, based on the uploaded client models, we utilize backpropagation to guide the server’s DM in generating synthetic datasets that comply with the client distributions, which are then used to train the aggregated model. By using the local models as a medium to transfer client knowledge, our method significantly reduces the computational requirements on client devices and effectively adapts to scenarios with heterogeneous clients. Extensive quantitation and visualization experiments on three large-scale real-world datasets, along with theoretical analysis, demonstrate that the synthetic datasets generated by FedLMG exhibit comparable quality and diversity to the client datasets, which leads to an aggregated model that outperforms all compared methods and even the performance ceiling, further elucidating the significant potential of utilizing DMs in FL.'}",https://openreview.net{'value': '/pdf/a37a60789cc3f2f85490af0cb8a61015319b288f.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=PlihOwfx4r,{'value': 'Aguvis: Unified Pure Vision Agents for Autonomous GUI Interaction'},Yiheng Xu; Zekun Wang; Junli Wang; Dunjie Lu; Tianbao Xie; Amrita Saha; Doyen Sahoo; Tao Yu; Caiming Xiong,~Yiheng_Xu1; ~Zekun_Wang1; ~Junli_Wang3; ~Dunjie_Lu1; ~Tianbao_Xie1; ~Amrita_Saha2; ~Doyen_Sahoo1; ~Tao_Yu5; ~Caiming_Xiong1,"{'value': ['GUI Agent', 'Visual Language Model', 'Large Language Model', 'Grounding', 'Reasoning', 'Planning', 'Computer Use Agent', 'Vision Language Action Model']}","{'value': 'Automating GUI tasks remains challenging due to reliance on textual representations, platform-specific action spaces, and limited reasoning capabilities. We introduce Aguvis, a unified vision-based framework for autonomous GUI agents that directly operates on screen images, standardizes cross-platform interactions and incorporates structured reasoning via inner monologue. To enable this, we construct Aguvis data collection, a large-scale dataset with multimodal grounding and reasoning annotations, and develop a two-stage training pipeline that separates GUI grounding from planning and reasoning. Experiments show that Aguvis achieves state-of-the-art performance across offline and real-world online benchmarks, marking the first fully autonomous vision-based GUI agent that operates without closed-source models. We open-source all datasets, models, and training recipes at https://aguvis-project.github.io to advance future research.'}",https://openreview.net{'value': '/pdf/9ca0242185005d8f3c4a467f4dd37b9e29bae832.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=PfyyEeVzQW,{'value': 'De-coupled NeuroGF for Shortest Path Distance Approximations on Large Terrain Graphs'},Samantha Chen; Pankaj K Agarwal; Yusu Wang,~Samantha_Chen1; ~Pankaj_K_Agarwal1; ~Yusu_Wang1,"{'value': ['geospatial analysis', 'graph neural networks', 'terrains', 'shortest paths']}","{'value': 'The ability to acquire high-resolution, large-scale geospatial data at an unprecedented using LiDAR and other related technologies has intensified the need for scalable algorithms for terrain analysis, including *shortest-path-distance* (SPD) queries on large-scale terrain digital elevation models (DEMs). \nIn this paper, we present a *neural data structure* for efficiently answering SPD queries approximately on a large terrain DEM, which is based on the recently proposed neural geodesic field (NeuroGF) framework (Zhang et al., 2023)---the state-of-the-art neural data structure for estimating geodesic distance.\nIn particular, we  propose a decoupled-NeuroGF data structure  combined with an efficient two-stage mixed-training strategy, which significantly reduces computational bottlenecks and enables efficient training on terrain DEMs at a scale not feasible before. We demonstrate the efficacy \nof our approach by performing detailed experiments on both synthetic and real data sets.\nFor instance, we can train a small model with around 70000 parameters on a terrain DEM with 16 million nodes in a matter of hours that can answer SPD queries with 1\\% relative error in at most 10ms per query.'}",https://openreview.net{'value': '/pdf/6ea7a41b4c926f7214824aa456e1bf0323e441be.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=PUzNwYmb3l,{'value': 'Efficient First-Order Optimization on the Pareto Set for Multi-Objective Learning under Preference Guidance'},Lisha Chen; Quan Xiao; Ellen Hidemi Fukuda; Xinyi Chen; Kun Yuan; Tianyi Chen,~Lisha_Chen1; ~Quan_Xiao1; ~Ellen_Hidemi_Fukuda1; ~Xinyi_Chen9; ~Kun_Yuan4; ~Tianyi_Chen5,"{'value': ['multi-objective optimization', 'optimization on the Pareto set', 'semivectorial bilevel optimization']}","{'value': 'Multi-objective learning under user-specified preference is common in real-world problems such as multi-lingual speech recognition under fairness. In this work, we frame such a problem as a semivectorial bilevel optimization problem, whose goal is to optimize a pre-defined preference function, subject to the constraint that the model parameters are weakly Pareto optimal. To solve this problem, we convert the multi-objective constraints to a single-objective constraint through a merit function with an easy-to-evaluate gradient, and then, we use a penalty-based reformulation of the bilevel optimization problem. We theoretically establish the properties of the merit function, and the relations of solutions for the penalty reformulation and the constrained formulation. Then we propose algorithms to solve the reformulated single-level problem, and establish its convergence guarantees. We test the method on various synthetic and real-world problems. The results demonstrate the effectiveness of the proposed method in finding preference-guided optimal solutions to the multi-objective problem.'}",https://openreview.net{'value': '/pdf/9f54c27d8c3b4cdac41e4d3385a41f3a9afd5821.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=PNRznmmWP7,{'value': 'Learning to Plan & Reason for Evaluation with Thinking-LLM-as-a-Judge'},Swarnadeep Saha; Xian Li; Marjan Ghazvininejad; Jason E Weston; Tianlu Wang,~Swarnadeep_Saha2; ~Xian_Li1; ~Marjan_Ghazvininejad1; ~Jason_E_Weston1; ~Tianlu_Wang1,"{'value': ['LLM-as-a-Judge', 'Planning', 'Reasoning', 'Evaluation']}","{'value': 'LLM-as-a-Judge models generate chain-of-thought (CoT) sequences intended to capture the step-by-step reasoning process that underlies the final evaluation of a response. However, due to the lack of human-annotated CoTs for evaluation, the required components and structure of effective reasoning traces remain understudied. Consequently, previous approaches often (1) constrain reasoning traces to hand-designed components, such as a list of criteria, reference answers, or verification questions and (2) structure them such that planning is intertwined with the reasoning for evaluation. In this work, we propose EvalPlanner, a preference optimization algorithm for Thinking-LLM-as-a-Judge that first generates an unconstrained evaluation plan, followed by its execution, and then the final judgment. In a self-training loop, EvalPlanner iteratively optimizes over synthetically constructed evaluation plans and executions, leading to better final verdicts. Our method achieves a new state-of-the-art performance for generative reward models on RewardBench and PPE, despite being trained on fewer amount of, and synthetically generated, preference pairs. Additional experiments on other benchmarks like RM-Bench, JudgeBench, and FollowBenchEval further highlight the utility of both planning and reasoning for building robust LLM-as-a-Judge reasoning models.'}",https://openreview.net{'value': '/pdf/be5f03fbff70940be98e18a637b593f091a0e693.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=P9DQ2IExgS,{'value': 'Synthesizing Software Engineering Data in a Test-Driven Manner'},Lei Zhang; Jiaxi Yang; Min Yang; Jian Yang; Mouxiang Chen; Jiajun Zhang; Zeyu Cui; Binyuan Hui; Junyang Lin,~Lei_Zhang32; ~Jiaxi_Yang1; ~Min_Yang4; ~Jian_Yang10; ~Mouxiang_Chen1; ~Jiajun_Zhang4; ~Zeyu_Cui1; ~Binyuan_Hui1; ~Junyang_Lin1,"{'value': ['Large language Model', 'Software Engineering', 'Test-Driven Development', 'Code Agent']}","{'value': 'We introduce **SWE-Flow**, a novel data synthesis framework grounded in Test-Driven Development (TDD).\nUnlike existing software engineering data that rely on human-submitted issues, **SWE-Flow** automatically infers incremental development steps directly from unit tests, which inherently encapsulate high-level requirements.\nThe core of **SWE-Flow** is the construction of a Runtime Dependency Graph (RDG), which precisely captures function interactions, enabling the generation of a structured, step-by-step *development schedule*.\nAt each step, **SWE-Flow** produces a partial codebase, the corresponding unit tests, and the necessary code modifications, resulting in fully verifiable TDD tasks.\nWith this approach, we generated 16,061 training instances and 2,020 test instances from real-world GitHub projects, creating the **SWE-Flow-Eval** benchmark.\nOur experiments show that fine-tuning open model on this dataset significantly improves performance in TDD-based coding.\nTo facilitate further research, we release all code, datasets, models, and Docker images at [Github](https://github.com/Hambaobao/SWE-Flow).'}",https://openreview.net{'value': '/pdf/2d182121aca3afc796101876991322370e53a173.pdf'},{'abstract_filter': 'Data Synthesis'},ICML.cc,2025,Conference
https://openreview.net/forum?id=P0zvNhHGG9,{'value': 'Diversified Flow Matching with Translation Identifiability'},Sagar Shrestha; Xiao Fu,~Sagar_Shrestha1; ~Xiao_Fu1,"{'value': ['unsupervised domain translation', 'flow matching', 'GAN', 'identifiability']}","{'value': ""Diversified distribution matching (DDM) finds a unified translation function mapping a diverse collection of conditional source distributions to their target counterparts. DDM was proposed to resolve content misalignment issues in unpaired domain translation, achieving translation identifiability. However, DDM has only been implemented using GANs due to its constraints on the translation function. GANs are often unstable to train and do not provide the transport trajectory information---yet such trajectories are useful in applications such as single-cell evolution analysis and robot route planning. This work introduces *diversified flow matching* (DFM), an ODE-based framework for DDM. Adapting flow matching (FM) to enforce a unified translation function as in DDM is challenging, as FM learns the translation function's velocity rather than the translation function itself. A custom bilevel optimization-based training loss, a nonlinear interpolant, and a structural reformulation are proposed to address these challenges, offering a tangible implementation. To our knowledge, DFM is the first ODE-based approach guaranteeing translation identifiability. Experiments on synthetic and real-world datasets validate the proposed method.""}",https://openreview.net{'value': '/pdf/59116253aa21d47f8737be645edf37fe0e8e6029.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=P0wSGDoip1,{'value': 'Gradient-based Explanations for Deep Learning Survival Models'},Sophie Hanna Langbein; Niklas Koenen; Marvin N. Wright,~Sophie_Hanna_Langbein1; ~Niklas_Koenen1; ~Marvin_N._Wright1,"{'value': ['Deep Learning', 'Survival Analysis', 'Explainable Artificial Intelligence', 'Interpretable Machine Learning', 'XAI', 'IML', 'Feature Attribution']}","{'value': 'Deep learning survival models often outperform classical methods in time-to-event predictions, particularly in personalized medicine, but their ""black box"" nature hinders broader adoption. We propose a framework for gradient-based explanation methods tailored to survival neural networks, extending their use beyond regression and classification. We analyze the implications of their theoretical assumptions for time-dependent explanations in the survival setting and propose effective visualizations incorporating the temporal dimension. Experiments on synthetic data show that gradient-based methods capture the magnitude and direction of local and global feature effects, including time dependencies. We introduce GradSHAP(t), a gradient-based counterpart to SurvSHAP(t), which outperforms SurvSHAP(t) and SurvLIME in a computational speed vs. accuracy trade-off. Finally, we apply these methods to medical data with multi-modal inputs, revealing relevant tabular features and visual patterns, as well as their temporal dynamics.'}",https://openreview.net{'value': '/pdf/a8966af1b000b130a4a0271671c5f5420d3e583a.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=OjXXqktkPz,{'value': 'Hypothesis Testing for Generalized Thurstone Models'},Anuran Makur; Japneet Singh,~Anuran_Makur1; ~Japneet_Singh1,"{'value': ['generalized Thurstone model', 'hypothesis testing', 'minimax risk', 'cycle decomposition.']}","{'value': 'In this work, we develop a hypothesis testing framework to determine whether pairwise comparison data is generated by an underlying *generalized Thurstone model* $\\mathcal{T}_F$ for a given choice function $F$. While prior work has predominantly focused on parameter estimation and uncertainty quantification for such models, we address the fundamental problem of minimax hypothesis testing for $\\mathcal{T}_F$ models. We formulate this testing problem by introducing a notion of separation distance between general pairwise comparison models and the class of $\\mathcal{T}_F$ models. We then derive upper and lower bounds on the critical threshold for testing that depend on the topology of the observation graph. For the special case of complete observation graphs, this threshold scales as $\\Theta((nk)^{-1/2})$, where $n$ is the number of agents and $k$ is the number of comparisons per pair. Furthermore, we propose a hypothesis test based on our separation distance, construct confidence intervals, establish time-uniform bounds on the probabilities of type I and II errors using reverse martingale techniques, and derive minimax lower bounds using information-theoretic methods. Finally, we validate our results through experiments on synthetic and real-world datasets.'}",https://openreview.net{'value': '/pdf/63162b00e3723897dfaf8f381a180a66e9c6402c.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=Of3wZhVv1R,{'value': 'EnIGMA: Interactive Tools Substantially Assist LM Agents in Finding Security Vulnerabilities'},Talor Abramovich; Meet Udeshi; Minghao Shao; Kilian Lieret; Haoran Xi; Kimberly Milner; Sofija Jancheska; John Yang; Carlos E Jimenez; Farshad Khorrami; Prashanth Krishnamurthy; Brendan Dolan-Gavitt; Muhammad Shafique; Karthik R Narasimhan; Ramesh Karri; Ofir Press,~Talor_Abramovich1; ~Meet_Udeshi1; ~Minghao_Shao3; ~Kilian_Lieret1; ~Haoran_Xi1; ~Kimberly_Milner1; ~Sofija_Jancheska1; ~John_Yang3; ~Carlos_E_Jimenez1; ~Farshad_Khorrami1; ~Prashanth_Krishnamurthy1; ~Brendan_Dolan-Gavitt1; ~Muhammad_Shafique1; ~Karthik_R_Narasimhan1; ~Ramesh_Karri1; ~Ofir_Press1,"{'value': ['Language Model Agents', 'Language Model', 'Agents', 'Security', 'Vulnerabilities', 'Capture The Flag']}","{'value': ""Although language model (LM) agents have demonstrated increased performance in multiple domains, including coding and web-browsing, their success in cybersecurity has been limited. We present *EnIGMA*, an LM agent for autonomously solving  Capture The Flag (CTF) challenges. We introduce new tools and interfaces to improve the agent's ability to find and exploit security vulnerabilities, focusing on interactive terminal programs.  These novel *Interactive Agent Tools* enable LM agents, for the first time,  to run interactive utilities, such as a debugger and a server connection tool, which are essential for solving these challenges.\nEmpirical analysis on 390 CTF challenges across four benchmarks demonstrate that these new tools and interfaces substantially improve our agent's performance, achieving state-of-the-art results on NYU CTF, Intercode-CTF, and CyBench. Finally, we analyze data leakage, developing new methods to quantify it and identifying a new phenomenon we term *soliloquizing*, where the model self-generates hallucinated observations without interacting with the environment.""}",https://openreview.net{'value': '/pdf/5ecd11e2019e356fc71618b5524a77c77d929916.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=OYbZWmNHwn,{'value': 'SAH-Drive: A Scenario-Aware Hybrid Planner for Closed-Loop Vehicle Trajectory Generation'},Yuqi Fan; Zhiyong Cui; Zhenning Li; Yilong Ren; Haiyang Yu,~Yuqi_Fan1; ~Zhiyong_Cui2; ~Zhenning_Li1; ~Yilong_Ren2; ~Haiyang_Yu10,"{'value': ['diffusion model', 'autonomous driving', 'hybrid planner', 'trajectory planning']}","{'value': 'Reliable planning is crucial for achieving autonomous driving. Rule-based planners are efficient but lack generalization, while learning-based planners excel in generalization yet have limitations in real-time performance and interpretability. In long-tail scenarios, these challenges make planning particularly difficult. To leverage the strengths of both rule-based and learning-based planners, we proposed the **Scenario-Aware Hybrid Planner** (SAH-Drive) for closed-loop vehicle trajectory planning. Inspired by human driving behavior, SAH-Drive combines a lightweight rule-based planner and a comprehensive learning-based planner, utilizing a dual-timescale decision neuron to determine the final trajectory. To enhance the computational efficiency and robustness of the hybrid planner, we also employed a diffusion proposal number regulator and a trajectory fusion module. The experimental results show that the proposed method significantly improves the generalization capability of the planning system, achieving state-of-the-art performance in interPlan, while maintaining computational efficiency without incurring substantial additional runtime.'}",https://openreview.net{'value': '/pdf/b9753655e43bdf7980dcc9f4cb71ce02f1c06bb4.pdf'},{'title_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=OUr945QeUb,"{'value': 'Collaborative Mean Estimation Among Heterogeneous Strategic Agents: Individual Rationality, Fairness, and Truthful Contribution'}",Alex Clinton; Yiding Chen; Jerry Zhu; Kirthevasan Kandasamy,~Alex_Clinton1; ~Yiding_Chen1; ~Jerry_Zhu1; ~Kirthevasan_Kandasamy1,"{'value': ['Mechanism design', 'collaborative learning', 'mean estimation']}","{'value': ""We study a collaborative learning problem where $m$ agents aim to estimate a vector $\\mu =(\\mu_1,\\ldots,\\mu_d)\\in \\mathbb{R}^d$ by sampling from associated univariate normal distributions $(\\mathcal{N}(\\mu_k, \\sigma^2))\\_{k\\in[d]}$. Agent $i$ incurs a cost $c_{i,k}$ to sample from $\\mathcal{N}(\\mu_k, \\sigma^2)$. Instead of working independently, agents can exchange data, collecting cheaper samples and sharing them in return for costly data, thereby reducing both costs and estimation error. We design a mechanism to facilitate such collaboration, while addressing two key challenges: ensuring *individually rational (IR) and fair outcomes* so all agents benefit, and *preventing strategic behavior* (e.g. non-collection, data fabrication) to avoid socially undesirable outcomes.\nWe design a mechanism and an associated Nash equilibrium (NE) which minimizes the social penalty-sum of agents' estimation errors and collection costs-while being IR for all agents. We achieve a $\\mathcal{O}(\\sqrt{m})$-approximation to the minimum social penalty in the worst case and an $\\mathcal{O}(1)$-approximation under favorable conditions. Additionally, we establish three hardness results: no nontrivial mechanism guarantees *(i)* a dominant strategy equilibrium where agents report truthfully, *(ii)* is IR for every strategy profile of other agents, *(iii)* or avoids a worst-case $\\Omega(\\sqrt{m})$ price of stability in any NE. Finally, by integrating concepts from axiomatic bargaining, we demonstrate that our mechanism supports fairer outcomes than one which minimizes social penalty.""}",https://openreview.net{'value': '/pdf/60e48590980fdee1ffe9a452e7325873ed519ad8.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=OKWlVPHeW1,"{'value': 'Boosting Virtual Agent Learning and Reasoning: A Step-Wise, Multi-Dimensional, and Generalist Reward Model with Benchmark'}",Bingchen Miao; Yang Wu; Minghe Gao; Qifan Yu; Wendong Bu; Wenqiao Zhang; Yunfei Li; Siliang Tang; Tat-Seng Chua; Juncheng Li,~Bingchen_Miao1; ~Yang_Wu16; ~Minghe_Gao1; ~Qifan_Yu1; ~Wendong_Bu1; ~Wenqiao_Zhang1; ~Yunfei_Li6; ~Siliang_Tang1; ~Tat-Seng_Chua2; ~Juncheng_Li3,{'value': ['Virtual Agent; Digital Agent; Reward Model']},"{'value': 'The development of Generalist Virtual Agents (GVAs) has shown significant promise in autonomous task execution. However, current training paradigms face critical limitations, including reliance on outcome supervision and labor-intensive human annotations. To address these challenges, we propose **Similar**, a **s**tep-w**i**se **m**ult**i**-dimensiona**l** gener**a**list **r**eward model, which offers fine-grained signals for agent training and can choose better actions for inference-time scaling. Specifically, we begin by systematically defining five dimensions for evaluating agent actions. Building on this framework, we design an MCTS-P algorithm to automatically collect and annotate step-wise, five-dimensional agent execution data. Using this data, we train **Similar** with our crafted Triple-M strategy. Furthermore, we introduce the first benchmark in the virtual agent domain for step-wise, multi-dimensional reward model training and evaluation, named ***SRM***. This benchmark consists of two components: ***SRMTrain***, which serves as the training set for **Similar**, and ***SRMEval***, a manually selected test set for evaluating the reward model. Experimental results demonstrate that **Similar**, through its step-wise, multi-dimensional assessment and synergistic gain, provides GVAs with effective intermediate signals during both training and inference-time scaling. The code is available at [https://github.com/antgroup/Similar](https://github.com/antgroup/Similar).'}",https://openreview.net{'value': '/pdf/8a469f657adcc38ba92235e00abd12557eccfeee.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=OKDN1Hg3im,{'value': 'Physics-informed Temporal Alignment for Auto-regressive PDE Foundation Models'},Congcong Zhu; Xiaoyan Xu; Jiayue Han; Jingrun Chen,~Congcong_Zhu1; ~Xiaoyan_Xu1; ~Jiayue_Han1; ~Jingrun_Chen2,"{'value': ['PDE foundation model', 'Physics-informed constrain', 'Inverse problem', 'Self-supervised learning']}","{'value': 'Auto-regressive partial differential equation (PDE) foundation models have shown great potential in handling time-dependent data. However, these models suffer from error accumulation caused by the shortcut problem deeply rooted in auto-regressive prediction. The challenge becomes particularly evident for out-of-distribution data, as the pretraining performance may approach random model initialization for downstream tasks with long-term dynamics. To deal with this problem, we propose physics-informed temporal alignment (PITA), a self-supervised learning framework inspired by inverse problem solving. Specifically, PITA aligns the physical dynamics discovered at different time steps on each given PDE trajectory by integrating physics-informed constraints into the self-supervision signal. The alignment is derived from observation data without relying on known physics priors, indicating strong generalization ability to out-of-distribution data. Extensive experiments show that PITA significantly enhances the accuracy and robustness of existing foundation models on diverse time-dependent PDE data. The code is available at \\url{https://github.com/SCAILab-USTC/PITA}.'}",https://openreview.net{'value': '/pdf/9560dd0a862f2f335d9cb5f7e473cf84b1d76a60.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=O2fUpyeRWs,{'value': 'Optimal Transport Barycenter via Nonconvex-Concave Minimax Optimization'},Kaheon Kim; Rentian Yao; Changbo Zhu; Xiaohui Chen,~Kaheon_Kim1; ~Rentian_Yao1; ~Changbo_Zhu2; ~Xiaohui_Chen3,{'value': ['Wasserstein barycenter; optimal transport; nonconvex-concave minimax optimization; convergence rate;']},"{'value': 'The optimal transport barycenter (a.k.a. Wasserstein barycenter) is a fundamental notion of averaging that extends from the Euclidean space to the Wasserstein space of probability distributions. Computation of the *unregularized* barycenter for discretized probability distributions on point clouds is a challenging task when the domain dimension $d > 1$. Most practical algorithms for approximating the barycenter problem are based on entropic regularization. In this paper, we introduce a nearly linear time $O(m \\log{m})$ and linear space complexity $O(m)$ primal-dual algorithm, the *Wasserstein-Descent $\\dot{\\mathbb{H}}^1$-Ascent* (WDHA) algorithm, for computing the *exact* barycenter when the input probability density functions are discretized on an $m$-point grid. The key success of the WDHA algorithm hinges on alternating between two different yet closely related Wasserstein and Sobolev optimization geometries for the primal barycenter and dual Kantorovich potential subproblems. Under reasonable assumptions, we establish the convergence rate and iteration complexity of WDHA to its stationary point when the step size is appropriately chosen. Superior computational efficacy, scalability, and accuracy over the existing Sinkhorn-type algorithms are demonstrated on high-resolution (e.g., $1024 \\times 1024$ images) 2D synthetic and real data.'}",https://openreview.net{'value': '/pdf/8bb5df1144f498a203da539287019dce5f1a9c8a.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=O14GjxDAt3,{'value': 'Accurate Identification of Communication Between Multiple Interacting Neural Populations'},Belle Liu; Jacob Sacks; Matthew D. Golub,~Belle_Liu1; ~Jacob_Sacks1; ~Matthew_D._Golub2,"{'value': ['Computational Neuroscience', 'Dynamical Systems', 'Interpretability', 'Brain-Wide Communication']}","{'value': 'Neural recording technologies now enable simultaneous recording of population activity across multiple brain regions, motivating the development of data-driven models of communication between recorded brain regions. Existing models can struggle to disentangle communication from the effects of unrecorded regions and local neural population dynamics. Here, we introduce Multi-Region Latent Factor Analysis via Dynamical Systems (MR-LFADS), a sequential variational autoencoder composed of  region-specific recurrent networks. MR-LFADS features structured information bottlenecks, data-constrained communication, and unsupervised inference of unobserved inputs--features that specifically support disentangling of inter-regional communication, inputs from unobserved regions, and local population dynamics. MR-LFADS outperforms existing approaches at identifying communication across dozens of simulations of task-trained multi-region networks. Applied to large-scale electrophysiology, MR-LFADS predicts brain-wide effects of circuit perturbations that were not seen during model fitting. These validations on synthetic and real neural data suggest that MR-LFADS could serve as a powerful tool for uncovering the principles of brain-wide information processing.'}",https://openreview.net{'value': '/pdf/1c963f3a390da8dd8c8e881f18faa4090522c3f1.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=O0oe7hPtbl,{'value': 'Gridded Transformer Neural Processes for Spatio-Temporal Data'},Matthew Ashman; Cristiana Diaconu; Eric Langezaal; Adrian Weller; Richard E. Turner,~Matthew_Ashman1; ~Cristiana_Diaconu1; ~Eric_Langezaal1; ~Adrian_Weller1; ~Richard_E_Turner1,"{'value': ['neural process', 'probabilistic machine learning', 'transformer', 'spatio-temporal data', 'spatio-temporal modelling', 'translation equivariance']}","{'value': 'Effective modelling of large-scale spatio-temporal datasets is essential for many domains, yet existing approaches often impose rigid constraints on the input data, such as requiring them to lie on fixed-resolution grids. With the rise of foundation models, the ability to process diverse, heterogeneous data structures is becoming increasingly important. Neural processes (NPs), particularly transformer neural processes (TNPs), offer a promising framework for such tasks, but struggle to scale to large spatio-temporal datasets due to the lack of an efficient attention mechanism. To address this, we introduce gridded pseudo-token TNPs which employ specialised encoders and decoders to handle unstructured data and utilise a processor comprising gridded pseudo-tokens with efficient attention mechanisms. Furthermore, we develop equivariant gridded TNPs for applications where exact or approximate translation equivariance is a useful inductive bias, improving accuracy and training efficiency. Our method consistently outperforms a range of strong baselines in various synthetic and real-world regression tasks involving large-scale data, while maintaining competitive computational efficiency. Experiments with weather data highlight the potential of gridded TNPs and serve as just one example of a domain where they can have a significant impact.'}",https://openreview.net{'value': '/pdf/b6c2975d397bbff81dd4fc4c122dbd43bce667af.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=NxxHkScf8z,{'value': 'When Model Knowledge meets Diffusion Model: Diffusion-assisted Data-free Image Synthesis with Alignment of Domain and Class'},Yujin Kim; Hyunsoo Kim; Hyunwoo J. Kim; Suhyun Kim,~Yujin_Kim1; ~Hyunsoo_Kim7; ~Hyunwoo_J._Kim3; ~Suhyun_Kim1,"{'value': ['Data-Free Image Synthesis', 'Diffusion', 'Data-Free Knowlege Distillation']}","{'value': 'Open-source pre-trained models hold great potential for diverse applications, but their utility declines when their training data is unavailable. Data-Free Image Synthesis (DFIS) aims to generate images that approximate the learned data distribution of a pre-trained model without accessing the original data. However, existing DFIS methods produce samples that deviate from the training data distribution due to the lack of prior knowledge about natural images. To overcome this limitation, we propose DDIS, the first Diffusion-assisted Data-free Image Synthesis method that leverages a text-to-image diffusion model as a powerful image prior, improving synthetic image quality. DDIS extracts knowledge about the learned distribution from the given model and uses it to guide the diffusion model, enabling the generation of images that accurately align with the training data distribution. To achieve this, we introduce Domain Alignment Guidance (DAG) that aligns the synthetic data domain with the training data domain during the diffusion sampling process. Furthermore, we optimize a single Class Alignment Token (CAT) embedding to effectively capture class-specific attributes in the training dataset. Experiments on PACS and ImageNet demonstrate that DDIS outperforms prior DFIS methods by generating samples that better reflect the training data distribution, achieving SOTA performance in data-free applications.'}",https://openreview.net{'value': '/pdf/6151c5feeade30f8fa5c685034cc44239411032e.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=NpIIbrg361,{'value': 'Refining Adaptive Zeroth-Order Optimization at Ease'},Yao Shu; Qixin Zhang; Kun He; Zhongxiang Dai,~Yao_Shu1; ~Qixin_Zhang1; ~Kun_He1; ~Zhongxiang_Dai1,"{'value': ['Adaptive Method', 'Zeroth-Order Optimization', 'Variance Reduction', 'Convergence']}","{'value': 'Recently, zeroth-order (ZO) optimization plays an essential role in scenarios where gradient information is inaccessible or unaffordable, such as black-box systems and resource-constrained environments. While existing adaptive methods such as ZO-AdaMM have shown promise, they are fundamentally limited by their underutilization of moment information during optimization, usually resulting in underperforming convergence. To overcome these limitations, this paper introduces *Refined Adaptive Zeroth-Order Optimization* (R-AdaZO). Specifically, we first show the untapped variance reduction effect of first moment estimate on ZO gradient estimation, which improves the accuracy and stability of ZO updates. We then refine the second moment estimate based on these variance-reduced gradient estimates to better capture the geometry of the optimization landscape, enabling a more effective scaling of ZO updates. We present rigorous theoretical analysis to show **_(a)_** *the first analysis* to the variance reduction of first moment estimate in ZO optimization, **_(b)_** *the improved second moment estimates* with a more accurate approximation of its variance-free ideal, **_(c)_** *the first variance-aware convergence framework* for adaptive ZO methods, which may be of independent interest, and **_(d)_** *the faster convergence* of R-AdaZO than existing baselines like ZO-AdaMM. Our extensive experiments, including synthetic problems, black-box adversarial attack, and memory-efficient fine-tuning of large language models (LLMs), further verify the superior convergence of R-AdaZO, indicating that R-AdaZO offers an improved solution for real-world ZO optimization challenges.'}",https://openreview.net{'value': '/pdf/dde18164b58363475e49b2731ba5f6914d29cf48.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=Nn9POI9Ekt,{'value': 'Agent-as-a-Judge: Evaluate Agents with Agents'},Mingchen Zhuge; Changsheng Zhao; Dylan R. Ashley; Wenyi Wang; Dmitrii Khizbullin; Yunyang Xiong; Zechun Liu; Ernie Chang; Raghuraman Krishnamoorthi; Yuandong Tian; Yangyang Shi; Vikas Chandra; Jürgen Schmidhuber,~Mingchen_Zhuge2; ~Changsheng_Zhao2; ~Dylan_R._Ashley1; ~Wenyi_Wang1; ~Dmitrii_Khizbullin2; ~Yunyang_Xiong2; ~Zechun_Liu1; ~Ernie_Chang4; ~Raghuraman_Krishnamoorthi1; ~Yuandong_Tian1; ~Yangyang_Shi1; ~Vikas_Chandra2; ~Jürgen_Schmidhuber1,"{'value': ['Code Generation', 'Agent-as-a-Judge', 'AI Developer', 'AI Judge', 'LLM']}","{'value': 'Contemporary evaluation techniques are inadequate for agentic systems. These approaches either focus exclusively on final outcomes---ignoring the step-by-step nature of the thinking done by agentic systems---or require excessive manual labour. To address this, we introduce the **Agent-as-a-Judge** framework, wherein agentic systems are used to evaluate agentic systems. This is a natural extension of the LLM-as-a-Judge framework, incorporating agentic features that enable intermediate feedback for the entire task-solving processes for more precise evaluations. We apply the Agent-as-a-Judge framework to the task of code generation. To overcome issues with existing benchmarks and provide a proof-of-concept testbed for Agent-as-a-Judge, we present **DevAI**, a new benchmark of 55 realistic AI code generation tasks. DevAI includes rich manual annotations, like a total of 365 hierarchical solution requirements, which make it particularly suitable for an agentic evaluator. We benchmark three of the top code-generating agentic systems using Agent-as-a-Judge and find that our framework dramatically outperforms LLM-as-a-Judge and is as reliable as our human evaluation baseline. Altogether, we believe that this work represents a concrete step towards enabling vastly more sophisticated agentic systems. To help that, our dataset and the full implementation of Agent-as-a-Judge will be publically available at https://github.com/metauto-ai/agent-as-a-judge'}",https://openreview.net{'value': '/pdf/f14b13d73341c2db8f0de5403926c1d746b00edd.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=NhkNX8jYld,{'value': 'LLM-Augmented Chemical Synthesis and Design Decision Programs'},Haorui Wang; Jeff Guo; Lingkai Kong; Rampi Ramprasad; Philippe Schwaller; Yuanqi Du; Chao Zhang,~Haorui_Wang1; ~Jeff_Guo1; ~Lingkai_Kong1; ~Rampi_Ramprasad1; ~Philippe_Schwaller1; ~Yuanqi_Du1; ~Chao_Zhang15,"{'value': ['Large Language models', 'Retrosynthesis planning', 'Molecule design']}","{'value': 'Retrosynthesis, the process of breaking down a target molecule into simpler precursors through a series of valid reactions, stands at the core of organic chemistry and drug development. Although recent machine learning (ML) research has advanced single-step retrosynthetic modeling and subsequent route searches, these solutions remain restricted by the extensive combinatorial space of possible pathways. Concurrently, large language models (LLMs) have exhibited remarkable chemical knowledge, hinting at their potential to tackle complex decision-making tasks in chemistry. In this work, we explore whether LLMs can successfully navigate the highly constrained, multi-step retrosynthesis planning problem. We introduce an efficient scheme for encoding reaction pathways and present a new route-level search strategy, moving beyond the conventional step-by-step reactant prediction. Through comprehensive evaluations, we show that our LLM-augmented approach excels at retrosynthesis planning and extends naturally to the broader challenge of synthesizable molecular design.'}",https://openreview.net{'value': '/pdf/376ef815b9a647137561c4ea61afaa3283f95a5f.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=NYi9B34E1e,{'value': 'Action-Constrained Imitation Learning'},Chia-Han Yeh; Tse-Sheng Nan; Risto Vuorio; Wei Hung; Hung Yen Wu; Shao-Hua Sun; Ping-Chun Hsieh,~Chia-Han_Yeh1; ~Tse-Sheng_Nan1; ~Risto_Vuorio1; ~Wei_Hung1; ~Hung_Yen_Wu1; ~Shao-Hua_Sun1; ~Ping-Chun_Hsieh1,{'value': ['Imitation Learning; Action Constraints']},"{'value': 'Policy learning under action constraints plays a central role in ensuring safe behaviors in various robot control and resource allocation applications.\nIn this paper, we study a new problem setting termed Action-Constrained Imitation Learning (ACIL), where an action-constrained imitator aims to learn from a demonstrative expert with larger action space.\nThe fundamental challenge of ACIL lies in the unavoidable mismatch of occupancy measure between the expert and the imitator caused by the action constraints. We tackle this mismatch through trajectory alignment and propose DTWIL, which replaces the original expert demonstrations with a surrogate dataset that follows similar state trajectories while adhering to the action constraints. Specifically, we recast trajectory alignment as a planning problem and solve it via Model Predictive Control, which aligns the surrogate trajectories with the expert trajectories based on the Dynamic Time Warping (DTW) distance. Through extensive experiments, we demonstrate that learning from the dataset generated by DTWIL significantly enhances performance across multiple robot control tasks and outperforms various benchmark imitation learning algorithms in terms of sample efficiency.'}",https://openreview.net{'value': '/pdf/ce9bfbf942639ee5e377c6a24021630146b33ea4.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=NTAhi2JEEE,{'value': 'Agent Workflow Memory'},Zora Zhiruo Wang; Jiayuan Mao; Daniel Fried; Graham Neubig,~Zora_Zhiruo_Wang1; ~Jiayuan_Mao1; ~Daniel_Fried1; ~Graham_Neubig1,"{'value': ['agent', 'memory', 'web navigation']}","{'value': 'Despite the potential of language model-based agents to solve real-world tasks such as web navigation, current methods still struggle with long-horizon tasks with complex action trajectories. In contrast, humans can flexibly solve complex tasks by learning reusable task workflows from past experiences and using them to guide future actions. To build agents that can similarly benefit from this process, we introduce Agent Workflow Memory (AWM), a method for inducing commonly reused routines, i.e., workflows, and selectively providing workflows to the agent to guide subsequent generations. AWM flexibly applies to both offline and online scenarios, where agents induce workflows from training examples beforehand or from test queries on the fly. We experiment on two major web navigation benchmarks — Mind2Web and WebArena — that collectively cover 1000+ tasks from 200+ domains across travel, shopping, and social media, among others. AWM substantially improves the baseline results by 24.6% and 51.1% relative success rate on Mind2Web and WebArena while reducing the number of steps taken to solve WebArena tasks successfully. Furthermore, online AWM robustly generalizes in cross-task, website, and domain evaluations, surpassing baselines from 8.9 to 14.0 absolute points as train-test task distribution gaps widen.'}",https://openreview.net{'value': '/pdf/c7ec3d6eaa775686f3b8750477e00bc7a65034e3.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=NMdWQXosFs,{'value': 'Guided Search Strategies in Non-Serializable Environments with Applications to Software Engineering Agents'},Karina Zainullina; Alexander Golubev; Maria Trofimova; Sergei Polezhaev; Ibragim Badertdinov; Daria Litvintseva; Simon Karasik; Filipp Fisin; Sergei Skvortsov; Maksim Nekrashevich; Anton Shevtsov; Boris Yangel,~Karina_Zainullina1; ~Alexander_Golubev2; ~Maria_Trofimova1; ~Sergei_Polezhaev1; ~Ibragim_Badertdinov1; ~Daria_Litvintseva1; ~Simon_Karasik1; ~Filipp_Fisin1; ~Sergei_Skvortsov1; ~Maksim_Nekrashevich1; ~Anton_Shevtsov1; ~Boris_Yangel2,"{'value': ['RL', 'Planning', 'Test-time search', 'Test-time computation', 'Agents', 'LLM', 'Software Engineering', 'SWE-bench', 'Process supervision', 'Outcome supervision']}","{'value': 'Large language models (LLMs) have recently achieved remarkable results in complex multi-step tasks, such as mathematical reasoning and agentic software engineering. However, they often struggle to maintain consistent performance across multiple solution attempts. One effective approach to narrow the gap between average-case and best-case performance is guided test-time search, which explores multiple solution paths to identify the most promising one. Unfortunately, effective search techniques (e.g. MCTS) are often unsuitable for *non-serializable* RL environments, such as Docker containers, where intermediate environment states cannot be easily saved and restored. We investigate two complementary search strategies applicable to such environments: 1-step lookahead and trajectory selection, both guided by a learned action-value function estimator. On the SWE-bench Verified benchmark, a key testbed for agentic software engineering, we find these methods to double the average success rate of a fine-tuned Qwen-72B model, achieving $40.8$\\%, the new state-of-the-art for open-weights models. Additionally, we show that these techniques are transferable to more advanced closed models, yielding similar improvements with GPT-4o.'}",https://openreview.net{'value': '/pdf/4de1c6717579fe7576145d583c293f19059efff9.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=NIe74CY9lk,{'value': 'MGD$^3$ : Mode-Guided Dataset Distillation using Diffusion Models'},Jeffrey A Chan Santiago; praveen tirupattur; Gaurav Kumar Nayak; Gaowen Liu; Mubarak Shah,~Jeffrey_A_Chan_Santiago1; ~praveen_tirupattur1; ~Gaurav_Kumar_Nayak2; ~Gaowen_Liu4; ~Mubarak_Shah3,"{'value': ['Dataset distillation', 'Dataset Condensation', 'Diffusion Models']}","{'value': 'Dataset distillation has emerged as an effective strategy, significantly reducing training costs and facilitating more efficient model deployment.\nRecent advances have leveraged generative models to distill datasets by capturing the underlying data distribution. Unfortunately, existing methods require model fine-tuning with distillation losses to encourage diversity and representativeness. However, these methods do not guarantee sample diversity, limiting their performance.\nWe propose a mode-guided diffusion model leveraging a pre-trained diffusion model without the need to fine-tune with distillation losses. Our approach addresses dataset diversity in three stages: Mode Discovery to identify distinct data modes, Mode Guidance to enhance intra-class diversity, and Stop Guidance to mitigate artifacts in synthetic samples that affect performance.\nWe evaluate our approach on ImageNette, ImageIDC, ImageNet-100, and ImageNet-1K, achieving accuracy improvements of 4.4%, 2.9%, 1.6%, and 1.6%, respectively, over state-of-the-art methods. Our method eliminates the need for fine-tuning diffusion models with distillation losses, significantly reducing computational costs.'}",https://openreview.net{'value': '/pdf/3026cd24c5231c89f8d06946f2cd75a046944383.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=NHTqYrp5YL,{'value': 'MissScore: High-Order Score Estimation in the Presence of Missing Data'},Wenqin Liu; Haoze Hou; Erdun Gao; Biwei Huang; Qiuhong Ke; Howard Bondell; Mingming Gong,~Wenqin_Liu1; ~Haoze_Hou1; ~Erdun_Gao1; ~Biwei_Huang1; ~Qiuhong_Ke6; ~Howard_Bondell2; ~Mingming_Gong1,{'value': ['Generative models; Score matching; Tabular data']},"{'value': 'Score-based generative models are essential in various machine learning applications, with strong capabilities in generation quality. In particular, high-order derivatives (scores) of data density offer deep insights into data distributions, building on the proven effectiveness of first-order scores for modeling and generating synthetic data, unlocking new possibilities for applications. However, learning them typically requires complete data, which is often unavailable in domains such as healthcare and finance due to data corruption, acquisition constraints, or incomplete records. To tackle this challenge, we introduce MissScore, a novel framework for estimating high-order scores in the presence of missing data. We derive objective functions for estimating high-order scores under different missing data mechanisms and propose a new algorithm specifically designed to handle missing data effectively. Our empirical results demonstrate that MissScore accurately and efficiently learns the high-order scores from incomplete data and generates high-quality samples, resulting in strong performance across a range of downstream tasks.'}",https://openreview.net{'value': '/pdf/dbfadef8d659fb5a58861194c5644b1b699f91c5.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=NCZOxhBTrz,{'value': 'Reasoning Limitations of Multimodal Large Language Models. A case study of Bongard Problems'},Mikołaj Małkiński; Szymon Pawlonka; Jacek Mańdziuk,~Mikołaj_Małkiński1; ~Szymon_Pawlonka1; ~Jacek_Mańdziuk1,"{'value': ['Multimodal Large Language Models', 'Abstract Visual Reasoning', 'Bongard Problems']}","{'value': 'Abstract visual reasoning (AVR) involves discovering shared concepts across images through analogy, akin to solving IQ test problems. Bongard Problems (BPs) remain a key challenge in AVR, requiring both visual reasoning and verbal description. We investigate whether multimodal large language models (MLLMs) can solve BPs by formulating a set of diverse MLLM-suited solution strategies and testing $4$ proprietary and $4$ open-access models on $3$ BP datasets featuring synthetic (classic BPs) and real-world (Bongard HOI and Bongard-OpenWorld) images. Despite some successes on real-world datasets, MLLMs struggle with synthetic BPs. To explore this gap, we introduce Bongard-RWR, a dataset representing synthetic BP concepts using real-world images. Our findings suggest that weak MLLM performance on classical BPs is not due to the domain specificity, but rather comes from their general AVR limitations. Code and dataset are available at: https://github.com/pavonism/bongard-rwr'}",https://openreview.net{'value': '/pdf/640a31fddca8e06ea1327b84901b5945c9a709d8.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=NBi8mjNebT,{'value': 'Identifying biological perturbation targets through causal differential networks'},Menghua Wu; Umesh Padia; Sean H. Murphy; Regina Barzilay; Tommi Jaakkola,~Menghua_Wu1; ~Umesh_Padia1; ~Sean_H._Murphy1; ~Regina_Barzilay1; ~Tommi_Jaakkola1,"{'value': ['perturbation', 'transcriptomics', 'causality']}","{'value': 'Identifying variables responsible for changes to a biological system enables applications in  drug target discovery and cell engineering. Given a pair of observational and interventional datasets, the goal is to isolate the subset of observed variables that were the targets of the intervention. Directly applying causal discovery algorithms is challenging: the data may contain thousands of variables with as few as tens of samples per intervention, and biological systems do not adhere to classical causality assumptions. We propose a causality-inspired approach to address this practical setting. First, we infer noisy causal graphs from the observational and interventional data. Then, we learn to map the differences between these graphs, along with additional statistical features, to sets of variables that were intervened upon. Both modules are jointly trained in a supervised framework, on simulated and real data that reflect the nature of biological interventions. This approach consistently outperforms baselines for perturbation modeling on seven single-cell transcriptomics datasets. We also demonstrate significant improvements over current causal discovery methods for predicting soft and hard intervention targets across a variety of synthetic data.'}",https://openreview.net{'value': '/pdf/1b33caab98ac969c00a7a70e4c34e8edd5b3159e.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=N82967FcVK,{'value': 'Distributional Diffusion Models with Scoring Rules'},Valentin De Bortoli; Alexandre Galashov; J Swaroop Guntupalli; Guangyao Zhou; Kevin Patrick Murphy; Arthur Gretton; Arnaud Doucet,~Valentin_De_Bortoli1; ~Alexandre_Galashov1; ~J_Swaroop_Guntupalli1; ~Guangyao_Zhou1; ~Kevin_Patrick_Murphy1; ~Arthur_Gretton1; ~Arnaud_Doucet2,"{'value': ['Diffusion models', 'energy distance', 'maximum mean discrepancy', 'scoring rules', 'accelerated sampling of diffusion models']}","{'value': 'Diffusion models generate high-quality synthetic data. They operate by defining a continuous-time forward process which gradually adds Gaussian noise to  data until fully corrupted. The corresponding reverse process progressively ``denoises"" a Gaussian sample into a sample from the data distribution. However, generating high-quality outputs requires many discretization steps to obtain a faithful approximation of the reverse process. This is expensive and has motivated the development of many acceleration methods. We propose to speed up sample generation by learning the posterior distribution of  clean data samples  given their noisy versions, instead of only the mean of this distribution. This allows us to sample from the probability transitions of the reverse process on a coarse time scale, significantly accelerating inference with minimal degradation of the quality of the output. This is  accomplished by replacing the standard regression loss used to estimate conditional means with a  scoring rule. We validate our method on  image and robot trajectory generation, where we  consistently outperform standard diffusion models at few discretization steps.'}",https://openreview.net{'value': '/pdf/7215d2d3de147b4ab2ade2c9f4e4af9e10961136.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=N2mOBiSqhc,{'value': 'Learning Strategic Language Agents in the Werewolf Game with Iterative Latent Space Policy Optimization'},Zelai Xu; Wanjun Gu; Chao Yu; Yi Wu; Yu Wang,~Zelai_Xu1; ~Wanjun_Gu1; ~Chao_Yu1; ~Yi_Wu1; ~Yu_Wang3,"{'value': ['LLM agents', 'strategic language games', 'game-theoretic methods', 'multi-agent']}","{'value': 'Large language model (LLM) agents have recently demonstrated impressive capabilities in various domains like open-ended conversation and multi-step decision-making. However, it remains challenging for these agents to solve strategic language games, such as Werewolf, which demand both strategic decision-making and free-form language interactions. Existing LLM agents often suffer from intrinsic bias in their action distributions and limited exploration of the unbounded text action space, resulting in suboptimal performance. To address these challenges, we propose Latent Space Policy Optimization (LSPO), an iterative framework that combines game-theoretic methods with LLM fine-tuning to build strategic language agents. LSPO leverages the observation that while the language space is combinatorially large, the underlying strategy space is relatively compact. We first map free-form utterances into a finite latent strategy space, yielding an abstracted extensive-form game. Then we apply game-theoretic methods like Counterfactual Regret Minimization (CFR) to optimize the policy in the latent space. Finally, we fine-tune the LLM via Direct Preference Optimization (DPO) to align with the learned policy. By iteratively alternating between these steps, our LSPO agents progressively enhance both strategic reasoning and language communication. Experiment on the Werewolf game shows that our agents iteratively expand the strategy space with improving performance and outperform existing Werewolf agents, underscoring their effectiveness in free-form language games with strategic interactions.'}",https://openreview.net{'value': '/pdf/800ecc872243b5ce81fff913f3b070f8a62a8762.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=MjVmVakGdx,{'value': 'Stochastic Encodings for Active Feature Acquisition'},Alexander Luke Ian Norcliffe; Changhee Lee; Fergus Imrie; Mihaela van der Schaar; Pietro Lio,~Alexander_Luke_Ian_Norcliffe2; ~Changhee_Lee1; ~Fergus_Imrie1; ~Mihaela_van_der_Schaar2; ~Pietro_Lio1,"{'value': ['Active Feature Acquisition', 'Dynamic Feature Selection']}","{'value': 'Active Feature Acquisition is an instance-wise, sequential decision making problem. The aim is to dynamically select which feature to measure based on current observations, independently for each test instance. Common approaches either use Reinforcement Learning, which experiences training difficulties, or greedily maximize the conditional mutual information of the label and unobserved features, which makes myopic acquisitions. To address these shortcomings, we introduce a latent variable model, trained in a supervised manner. Acquisitions are made by reasoning about the features across many possible unobserved realizations in a stochastic latent space. Extensive evaluation on a large range of synthetic and real datasets demonstrates that our approach reliably outperforms a diverse set of baselines.'}",https://openreview.net{'value': '/pdf/8ff35be52a66e6e65b6bad36b9d5880db7ec0f3c.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=MRD19y4Zjm,{'value': 'Risk-Sensitive Theory of Mind: Coordinating with Agents of Unknown Bias using Cumulative Prospect Theory'},Mason O. Smith; Wenlong Zhang,~Mason_O._Smith1; ~Wenlong_Zhang1,"{'value': ['Human-autonomy teaming', 'reinforcement learning', 'risk', 'cumulative prospect theory']}","{'value': 'Humans are often modeled as rational actors by interactive agents when they are in fact frequently observed to make biased decisions. This erroneous assumption may cause an agent’s model of the human to fail, especially when interaction occurs in bias-inducing settings that prompt risky decisions. To address this, this paper formulates a risk-sensitive multi-agent coordination problem and presents the novel Risk-Sensitive Theory of Mind (RS-ToM) framework that allows an autonomous agent to reason about and adapt to a partner of unknown risk-sensitivity. In simulated studies, we show that an agent with an RS-ToM is able to better coordinate with such a partner when compared to an agent that assumes their partner is rational. Thus, we observe significant improvements to team performance, coordination fluency, compliance with partner risk-preferences, and predictability. The presented results suggest that an RS-ToM will be able to model and plan with partners that exhibit these risk-sensitive biases in the real world.'}",https://openreview.net{'value': '/pdf/b60eb4dcfb1bb3b33c5165fac746c57c165ca3b4.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=MNSW6U5zUA,{'value': 'Impossible Videos'},Zechen Bai; Hai Ci; Mike Zheng Shou,~Zechen_Bai1; ~Hai_Ci1; ~Mike_Zheng_Shou1,"{'value': ['Videos', 'Benchmark', 'Evaluation', 'Impossible Videos', 'Counterfactual', 'Anti-reality']}","{'value': ""Synthetic videos nowadays is widely used to complement data scarcity and diversity of real-world videos.\nCurrent synthetic datasets primarily replicate real-world scenarios, leaving impossible, counterfactual and anti-reality video concepts underexplored. This work aims to answer two questions: 1) Can today's video generation models effectively follow prompts to create impossible video content? 2) Are today's video understanding models good enough for understanding impossible videos?\nTo this end, we introduce *IPV-Bench*, a novel benchmark designed to evaluate and foster progress in video understanding and generation. *IPV-Bench* is underpinned by a comprehensive taxonomy, encompassing 4 domains, 14 categories.\nIt features diverse scenes that defy physical, biological, geographical, or social laws. Based on the taxonomy, a prompt suite is constructed to evaluate video generation models, challenging their prompt following and creativity capabilities. In addition, a video benchmark is curated to assess Video-LLMs on their ability of understanding impossible videos, which particularly requires reasoning on temporal dynamics and world knowledge. Comprehensive evaluations reveal limitations and insights for future directions of video models, paving the way for next-generation video models.""}",https://openreview.net{'value': '/pdf/a12e14946fb7b2425a8c386ca26176c10d78cf30.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=MM6ZWF7gl9,{'value': 'Understanding the Statistical Accuracy-Communication Trade-off in Personalized Federated Learning with Minimax Guarantees'},Xin Yu; Zelin He; Ying Sun; Lingzhou Xue; Runze Li,~Xin_Yu12; ~Zelin_He2; ~Ying_Sun5; ~Lingzhou_Xue1; ~Runze_Li1,"{'value': ['Personalized Federated Learning', 'Statistical Complexity', 'Communication Complexity']}","{'value': 'Personalized federated learning (PFL) offers a flexible framework for aggregating information across distributed clients with heterogeneous data. This work considers a personalized federated learning setting that simultaneously learns global and local models. While purely local training has no communication cost, collaborative learning among the clients can leverage shared knowledge to improve statistical accuracy, presenting an accuracy-communication trade-off in personalized federated learning. However, the theoretical analysis of how personalization quantitatively influences sample and algorithmic efficiency and their inherent trade-off is largely unexplored. This paper makes a contribution towards filling this gap, by providing a quantitative characterization of the personalization degree on the tradeoff. The results further offer theoretical insights for choosing the personalization degree. As a side contribution, we establish the minimax optimality in terms of statistical accuracy for a widely studied PFL formulation. The theoretical result is validated on both synthetic and real-world datasets and its generalizability is verified in a non-convex setting.'}",https://openreview.net{'value': '/pdf/c31488a58ff253d2544168b2539340eb8812c429.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=MHaSq1LlTe,{'value': 'Signed Laplacians for Constrained Graph Clustering'},John Stewart Fabila Carrasco; He Sun,~John_Stewart_Fabila_Carrasco1; ~He_Sun5,"{'value': ['signed Laplacians', 'constrained clustering', 'Cheeger inequality']}","{'value': 'Given two weighted graphs $G = (V, E, w_G)$ and $H = (V, F, w_H)$ defined on the same vertex set, the constrained clustering problem seeks to find a subset $S \\subset V$ that minimises the cut ratio between $w_G(S, V \\setminus S)$ and $w_H(S, V \\setminus S)$. In this work, we establish a Cheeger-type inequality that relates the solution of the constrained clustering problem to the spectral properties of $ G$ and $H$. To reduce computational complexity, we utilise the signed Laplacian of $H$, streamlining calculations while maintaining accuracy. By solving a generalised eigenvalue problem, our proposed algorithm achieves notable performance improvements, particularly in challenging scenarios where traditional spectral clustering methods struggle. We demonstrate its practical effectiveness through experiments on both synthetic and real-world datasets.'}",https://openreview.net{'value': '/pdf/ca3d159cd99be59f097c2f3b58131c12051de8af.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=M7mVzCV6uU,{'value': 'Federated Generalised Variational Inference: A Robust Probabilistic Federated Learning Framework'},Terje Mildner; Oliver Hamelijnck; Paris Giampouras; Theodoros Damoulas,~Terje_Mildner1; ~Oliver_Hamelijnck1; ~Paris_Giampouras1; ~Theodoros_Damoulas1,"{'value': ['Federated Learning', 'Probabilistic Machine Learning', 'Model Misspecification', 'Robustness', 'Generalised Variational Inference']}","{'value': 'We introduce FedGVI, a probabilistic Federated Learning (FL) framework that is robust to both prior and likelihood misspecification. FedGVI addresses limitations in both frequentist and Bayesian FL by providing unbiased predictions under model misspecification, with calibrated uncertainty quantification. Our approach generalises previous FL approaches, specifically Partitioned Variational Inference (Ashman et al., 2022), by allowing robust and conjugate updates, decreasing computational complexity at the clients. We offer theoretical analysis in terms of fixed-point convergence, optimality of the cavity distribution, and provable robustness to likelihood misspecification. Further, we empirically demonstrate the effectiveness of FedGVI in terms of improved robustness and predictive performance on multiple synthetic and real world classification data sets.'}",https://openreview.net{'value': '/pdf/5b38226a734c962c4736d7ffe813309f8be546e9.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=LyUfPOvM6I,{'value': 'OrcaLoca: An LLM Agent Framework for Software Issue Localization'},Zhongming Yu; Hejia Zhang; Yujie Zhao; Hanxian Huang; Matrix Yao; Ke Ding; Jishen Zhao,~Zhongming_Yu3; ~Hejia_Zhang3; ~Yujie_Zhao2; ~Hanxian_Huang1; ~Matrix_Yao1; ~Ke_Ding2; ~Jishen_Zhao1,"{'value': ['LLM', 'LLM Agent', 'Software Engineering']}","{'value': 'Recent developments in Large Language Model (LLM) agents are revolutionizing Autonomous Software Engineering (ASE), enabling automated coding, problem fixes, and feature improvements. However, localization -- precisely identifying software problems by navigating to relevant code sections -- remains a significant challenge. Current approaches often yield suboptimal results due to a lack of effective integration between LLM agents and precise code search mechanisms. This paper introduces OrcaLoca, an LLM agent framework that improves accuracy for software issue localization by integrating priority-based scheduling for LLM-guided action, action decomposition with relevance scoring, and distance-aware context pruning. Experimental results demonstrate that OrcaLoca becomes the new open-source state-of-the-art (SOTA) in function match rate (65.33%) on SWE-bench Lite. It also improves the final resolved rate of an open-source framework by 6.33 percentage points through its patch generation integration.'}",https://openreview.net{'value': '/pdf/cbe1532f24173922a754556fa140bdc9b76be780.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=LbJQYNSH41,{'value': 'A Unified Framework for Entropy Search and Expected Improvement in Bayesian Optimization'},Nuojin Cheng; Leonard Papenmeier; Stephen Becker; Luigi Nardi,~Nuojin_Cheng1; ~Leonard_Papenmeier1; ~Stephen_Becker1; ~Luigi_Nardi1,"{'value': ['Bayesian optimization', 'Entropy search', 'Variational inference', 'Acquisition function']}","{'value': 'Bayesian optimization is a widely used method for optimizing expensive black-box functions, with Expected Improvement being one of the most commonly used acquisition functions. In contrast, information-theoretic acquisition functions aim to reduce uncertainty about the function’s optimum and are often considered fundamentally distinct from EI. In this work, we challenge this prevailing perspective by introducing a unified theoretical framework, Variational Entropy Search, which reveals that EI and information-theoretic acquisition functions are more closely related than previously recognized. We demonstrate that EI can be interpreted as a variational inference approximation of the popular information-theoretic acquisition function, named Max-value Entropy Search. Building on this insight, we propose VES-Gamma, a novel acquisition function that balances the strengths of EI and MES. Extensive empirical evaluations across both low- and high-dimensional synthetic and real-world benchmarks demonstrate that VES-Gamma is competitive with state-of-the-art acquisition functions and in many cases outperforms EI and MES.'}",https://openreview.net{'value': '/pdf/fd2e9ba32b10cc32136446d7c9fa7f28af0e1e00.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=LXILcnYTSl,{'value': 'The Underlying Universal Statistical Structure of Natural Datasets'},Noam Itzhak Levi; Yaron Oz,~Noam_Itzhak_Levi1; ~Yaron_Oz1,"{'value': ['Random Matrix Theory', 'Data Structure', 'Universality', 'Gaussian data Empirical Data Estimation', 'Power Law Scaling']}","{'value': 'We study universal properties in real-world complex and synthetically generated datasets. Our approach is to analogize data to a physical system and employ tools from statistical physics and Random Matrix Theory (RMT) to reveal their underlying structure.\nExamining the local and global eigenvalue statistics of feature-feature covariance matrices, we find: (i) bulk eigenvalue power-law scaling vastly differs between uncorrelated Gaussian and real-world data, (ii) this power law behavior is reproducible using Gaussian data with long-range correlations, (iii) all dataset types exhibit chaotic RMT universality, (iv) RMT statistics emerge at smaller dataset sizes than typical training sets, correlating with power-law convergence, (v) Shannon entropy correlates with RMT structure and requires fewer samples in strongly correlated datasets. These results suggest natural image Gram matrices can be approximated by Wishart random matrices with simple covariance structure, enabling rigorous analysis of neural network behavior.'}",https://openreview.net{'value': '/pdf/bd4ba5b518f7f46026beac410d03fa1bc78bc884.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=LSnpEbs0nA,{'value': 'Enhancing Treatment Effect Estimation via Active Learning: A Counterfactual Covering Perspective'},Hechuan Wen; Tong Chen; Mingming Gong; Li Kheng Chai; Shazia Sadiq; Hongzhi Yin,~Hechuan_Wen1; ~Tong_Chen8; ~Mingming_Gong1; ~Li_Kheng_Chai1; ~Shazia_Sadiq1; ~Hongzhi_Yin2,{'value': ['Causal Inference; Treatment Effect Estimation; Active Learning']},"{'value': 'Although numerous complex algorithms for treatment effect estimation have been developed in recent years, their effectiveness remains limited when handling insufficiently labeled training sets due to the high cost of labeling the post-treatment effect, e.g., the expensive tumor imaging or biopsy procedures needed to evaluate treatment effects. Therefore, it becomes essential to actively incorporate more high-quality labeled data, all while adhering to a constrained labeling budget. To enable data-efficient treatment effect estimation, we formalize the problem through rigorous theoretical analysis within the active learning context, where the derived key measures -- factual and counterfactual covering radii determine the risk upper bound. To reduce the bound, we propose a greedy radius reduction algorithm, which excels under an idealized, balanced data distribution. To generalize to more realistic data distributions, we further propose FCCM, which transforms the optimization objective into the Factual and Counterfactual Coverage Maximization to ensure effective radius reduction during data acquisition. Furthermore, benchmarking FCCM against other baselines demonstrates its superiority across both fully synthetic and semi-synthetic datasets. Code: https://github.com/uqhwen2/FCCM.'}",https://openreview.net{'value': '/pdf/fb269b38946db76f5b590274f27824c0dc1642cd.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=LO7ciRpjI5,{'value': 'Sundial: A Family of Highly Capable Time Series Foundation Models'},Yong Liu; Guo Qin; Zhiyuan Shi; Zhi Chen; Caiyin Yang; Xiangdong Huang; Jianmin Wang; Mingsheng Long,~Yong_Liu15; ~Guo_Qin1; ~Zhiyuan_Shi6; ~Zhi_Chen11; ~Caiyin_Yang1; ~Xiangdong_Huang1; ~Jianmin_Wang1; ~Mingsheng_Long5,"{'value': ['Time Series', 'Foundation Models']}","{'value': ""We introduce Sundial, a family of native, flexible, and scalable time series foundation models. To predict the next-patch's distribution, we propose a TimeFlow Loss based on flow-matching, which facilitates native pre-training of Transformers on continuous-valued time series without discrete tokenization. Conditioned on arbitrary-length time series, our models are pre-trained without specifying any prior distribution and can generate multiple probable predictions, achieving more flexibility in representation learning than using parametric densities. Towards time series foundation models, we leverage minimal but crucial adaptations of Transformers and curate TimeBench with one trillion time points, comprising mostly real-world datasets and synthetic data. By mitigating mode collapse via TimeFlow Loss, we pre-train a family of Sundial models on TimeBench, which achieve unprecedented model capacity and generalization performance. In addition to excellent scalability, Sundial achieves state-of-the-art results on both point and probabilistic forecasting benchmarks with a just-in-time inference speed, i.e., making zero-shot predictions within a few milliseconds. We believe that Sundial's pioneering generative forecasting capability can improve model reliability in real-world decision-making. Code is available at: https://github.com/thuml/Sundial.""}",https://openreview.net{'value': '/pdf/359f0dd1433a9c20f280a309b1da1c946e1ef8a6.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=LLk1qYQatJ,{'value': 'LETS Forecast: Learning Embedology for Time Series Forecasting'},Abrar Majeedi; Viswanatha Reddy Gajjala; Satya Sai Srinath Namburi GNVV; Nada Magdi Elkordi; Yin Li,~Abrar_Majeedi1; ~Viswanatha_Reddy_Gajjala1; ~Satya_Sai_Srinath_Namburi_GNVV1; ~Nada_Magdi_Elkordi1; ~Yin_Li3,"{'value': ['Time series forecasting', 'dynamical modeling']}","{'value': ""Real-world time series are often governed by complex nonlinear dynamics. Understanding these underlying dynamics is crucial for precise future prediction. While deep learning has achieved major success in time series forecasting, many existing approaches do not explicitly model the dynamics. To bridge this gap, we introduce DeepEDM, a framework that integrates nonlinear dynamical systems modeling with deep neural networks. Inspired by empirical dynamic modeling (EDM) and rooted in Takens' theorem, DeepEDM presents a novel deep model that learns a latent space from time-delayed embeddings, and employs kernel regression to approximate the underlying dynamics, while leveraging efficient implementation of softmax attention and allowing for accurate prediction of future time steps. To evaluate our method, we conduct comprehensive experiments on synthetic data of nonlinear dynamical systems as well as real-world time series across domains. Our results show that DeepEDM is robust to input noise, and outperforms state-of-the-art methods in forecasting accuracy. Our code is available at: https://abrarmajeedi.github.io/deep_edm.""}",https://openreview.net{'value': '/pdf/1004c3ba26eb987badcd5c501d666a61b2e9ba1a.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=LCr6CIAEye,{'value': 'Preference Adaptive and Sequential Text-to-Image Generation'},Ofir Nabati; Guy Tennenholtz; ChihWei Hsu; Moonkyung Ryu; Deepak Ramachandran; Yinlam Chow; Xiang Li; Craig Boutilier,~Ofir_Nabati1; ~Guy_Tennenholtz2; ~ChihWei_Hsu2; ~Moonkyung_Ryu1; ~Deepak_Ramachandran2; ~Yinlam_Chow1; ~Xiang_Li120; ~Craig_Boutilier2,"{'value': ['text-to-image generation', 'reinforcement learning', 'diffusion models', 'multi-modal large language models', 'human-in-the-loop', 'sequential decision making']}","{'value': ""We address the problem of interactive text-to-image (T2I) generation, designing a reinforcement learning (RL) agent which iteratively improves a set of generated images for a user through a sequence of prompt expansions. Using human raters, we create a novel dataset of sequential preferences, which we leverage, together with large-scale open-source (non-sequential) datasets. We construct user-preference and user-choice models using an EM strategy and identify varying user preference types. We then leverage a large multimodal language model (LMM) and a value-based RL approach to suggest an adaptive and diverse slate of prompt expansions to the user. Our Preference Adaptive and Sequential Text-to-image Agent (PASTA) extends T2I models with adaptive multi-turn capabilities, fostering collaborative co-creation and addressing uncertainty or underspecification in a user's intent. We evaluate PASTA using human raters, showing significant improvement compared to baseline methods. We also open-source our sequential rater dataset and simulated user-rater interactions to support future research in user-centric multi-turn T2I systems.""}",https://openreview.net{'value': '/pdf/c0346a68098a504153fd8f37e05962dc7d8efe87.pdf'},{'abstract_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=LB5F02kwAv,{'value': 'LangDAug: Langevin Data Augmentation for Multi-Source Domain Generalization in Medical Image Segmentation'},Piyush Tiwary; Kinjawl Bhattacharyya; Prathosh AP,~Piyush_Tiwary1; ~Kinjawl_Bhattacharyya1; ~Prathosh_AP1,"{'value': ['Medical Image Segmentation', 'Domain Generalization', 'Energy-based Models']}","{'value': 'Medical image segmentation models often struggle to generalize across different domains due to various reasons. Domain Generalization (DG) methods overcome this either through representation learning or data augmentation (DA). While representation learning methods seek domain-invariant features, they often rely on ad-hoc techniques and lack formal guarantees. DA methods, which enrich model representations through synthetic samples, have shown comparable or superior performance to representation learning approaches. We propose LangDAug, a novel **Lang**evin **D**ata **Aug**mentation for multi-source domain generalization in 2D medical image segmentation. LangDAug leverages Energy-Based Models (EBMs) trained via contrastive divergence to traverse between source domains, generating intermediate samples through Langevin dynamics. Theoretical analysis shows that LangDAug induces a regularization effect, and for GLMs, it upper-bounds the Rademacher complexity by the intrinsic dimensionality of the data manifold. Through extensive experiments on Fundus segmentation and 2D MRI prostate segmentation benchmarks, we show that LangDAug outperforms state-of-the-art domain generalization methods and effectively complements existing domain-randomization approaches. The codebase for our method is available at https://github.com/backpropagator/LangDAug.'}",https://openreview.net{'value': '/pdf/1c537e6ffbb2a5ddaf9d0ef3218f05ed09760150.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=L6U7nYc4ah,{'value': 'Provably Improving Generalization of Few-shot models with Synthetic Data'},Lan-Cuong Nguyen; Quan Nguyen-Tri; Bang Tran Khanh; Dung D. Le; Long Tran-Thanh; Khoat Than,~Lan-Cuong_Nguyen1; ~Quan_Nguyen-Tri1; ~Bang_Tran_Khanh1; ~Dung_D._Le2; ~Long_Tran-Thanh1; ~Khoat_Than1,"{'value': ['Synthetic data', 'Few-Shot learning', 'Robustness', 'Generalization bounds']}","{'value': 'Few-shot image classification remains challenging due to the scarcity of labeled training examples. Augmenting them with synthetic data has emerged as a promising way to alleviate this issue, but models trained on synthetic samples often face performance degradation due to the inherent gap between real and synthetic distributions. To address this limitation, we develop a theoretical framework that quantifies the impact of such distribution discrepancies on supervised learning, specifically in the context of image classification. More importantly, *our framework suggests practical ways to generate good synthetic samples and to train a predictor with high generalization ability*. Building upon this framework, we propose a novel theoretical-based algorithm that integrates prototype learning to optimize both data partitioning and model training, effectively bridging the gap between real few-shot data and synthetic data. Extensive experiments results show that our approach demonstrates superior performance compared to state-of-the-art methods, outperforming them across multiple datasets.'}",https://openreview.net{'value': '/pdf/0e2a2a4ab9b66270dcf8131fe51085215bb8457d.pdf'},{'title_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=L1Bm396P0X,{'value': 'The Butterfly Effect: Neural Network Training Trajectories Are Highly Sensitive to Initial Conditions'},Gül Sena Altıntaş; Devin Kwok; Colin Raffel; David Rolnick,~Gül_Sena_Altıntaş1; ~Devin_Kwok1; ~Colin_Raffel1; ~David_Rolnick1,"{'value': ['early training', 'linear mode connectivity', 'loss landscape', 'perturbation sensitivity', 'permutation symmetry']}","{'value': 'Neural network training is inherently sensitive to initialization and the randomness induced by stochastic gradient descent. However, it is unclear to what extent such effects lead to meaningfully different networks, either in terms of the models\' weights or the underlying functions that were learned. In this work, we show that during the initial ""chaotic"" phase of training, even extremely small perturbations reliably causes otherwise identical training trajectories to diverge-an effect that diminishes rapidly over training time. We quantify this divergence through (i) $L^2$ distance between parameters, (ii) the loss barrier when interpolating between networks, (iii) $L^2$ and barrier between parameters after permutation alignment, and (iv) representational similarity between intermediate activations; revealing how perturbations across different hyperparameter or fine-tuning settings drive training trajectories toward distinct loss minima. Our findings provide insights into neural network training stability, with practical implications for fine-tuning, model merging, and diversity of model ensembles.'}",https://openreview.net{'value': '/pdf/d205813b4e92b73b3a80142ad9f5984b9f050490.pdf'},{'title_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=KhCKypSaqx,{'value': 'Learning Time-Aware Causal Representation for Model Generalization in Evolving Domains'},Zhuo He; Shuang Li; Wenze Song; Longhui Yuan; Jian Liang; Han Li; Kun Gai,~Zhuo_He1; ~Shuang_Li6; ~Wenze_Song1; ~Longhui_Yuan1; ~Jian_Liang3; ~Han_Li11; ~Kun_Gai1,"{'value': ['Evolving Domain Generalization', 'Causal Representation Learning']}","{'value': 'Endowing deep models with the ability to generalize in dynamic scenarios is of vital significance for real-world deployment, given the continuous and complex changes in data distribution. Recently, evolving domain generalization (EDG) has emerged to address distribution shifts over time, aiming to capture evolving patterns for improved model generalization. However, existing EDG methods may suffer from spurious correlations by modeling only the dependence between data and targets across domains, creating a shortcut between task-irrelevant factors and the target, which hinders generalization. To this end, we design a time-aware structural causal model (SCM) that incorporates dynamic causal factors and the causal mechanism drifts, and propose **S**tatic-D**YN**amic **C**ausal Representation Learning (**SYNC**), an approach that effectively learns time-aware causal representations.  Specifically, it integrates specially designed information-theoretic objectives into a sequential VAE framework which captures evolving patterns, and produces the desired representations by preserving intra-class compactness of causal factors both across and within domains. Moreover, we theoretically show that our method can yield the optimal causal predictor for each time domain. Results on both synthetic and real-world datasets exhibit that SYNC can achieve superior temporal generalization performance.'}",https://openreview.net{'value': '/pdf/c76d2647fe20ba825258a1bf0371344fe668880f.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=KaukiEQcbk,{'value': 'VerbalTS: Generating Time Series from Texts'},Shuqi Gu; Chuyue Li; Baoyu Jing; Kan Ren,~Shuqi_Gu1; ~Chuyue_Li1; ~Baoyu_Jing1; ~Kan_Ren1,"{'value': ['time series', 'conditional generation', 'diffusion model', 'multi-modality']}","{'value': 'Time series synthesis has become a foundational task in modern society, underpinning decision-making across various scenes. Recent approaches primarily generate time series from structured conditions, such as attribute-based metadata. However, these methods struggle to capture the full complexity of time series, as the predefined structures often fail to reflect intricate temporal dynamics or other nuanced characteristics. Moreover, constructing structured metadata requires expert knowledge, making large-scale data labeling costly and impractical. In this paper, we introduce VerbalTS, a novel framework for generating time series from unstructured textual descriptions, offering a more expressive and flexible solution to time series synthesis. To bridge the gap between unstructured text and time series data, VerbalTS employs a multi-focal alignment and generation framework, effectively modeling their complex relationships. Experiments on two synthetic and four real-world datasets demonstrate that VerbalTS outperforms existing methods in both generation quality and semantic alignment with textual conditions.'}",https://openreview.net{'value': '/pdf/0af3259f9a17a06d47092010d2d60b153a002846.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=KWzddk0Ejx,{'value': 'Hybrid Quantum-Classical Multi-Agent Pathfinding'},Thore Gerlach; Loong Kuan Lee; Frederic BARBARESCO; Nico Piatkowski,~Thore_Gerlach1; ~Loong_Kuan_Lee1; ~Frederic_BARBARESCO1; ~Nico_Piatkowski1,"{'value': ['QUBO', 'MAPF', 'Column Generation', 'Optimal', 'Quantum Computing', 'ILP', 'Operations Research']}","{'value': 'Multi-Agent Path Finding (MAPF) focuses on determining conflict-free paths for multiple agents navigating through a shared space to reach specified goal locations.  This problem becomes computationally challenging, particularly when handling large numbers of agents, as frequently encountered in practical applications like coordinating autonomous vehicles. Quantum Computing (QC) is a promising candidate in overcoming such limits. However, current quantum hardware is still in its infancy and thus limited in terms of computing power and error robustness. In this work, we present the first optimal hybrid quantum-classical MAPF algorithms which are based on branch-and-cut-and-prize. QC is integrated by iteratively solving QUBO problems, based on conflict graphs. Experiments on actual quantum hardware and results on benchmark data suggest that our approach dominates previous QUBO formulations and state-of-the-art MAPF solvers.'}",https://openreview.net{'value': '/pdf/0f45d828ecf43686b02e11407d732deea05ebd89.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=KPRIwWhqAZ,{'value': 'DeFoG: Discrete Flow Matching for Graph Generation'},Yiming QIN; Manuel Madeira; Dorina Thanou; Pascal Frossard,~Yiming_QIN2; ~Manuel_Madeira1; ~Dorina_Thanou1; ~Pascal_Frossard1,"{'value': ['Graph Generation', 'Flow Matching']}","{'value': ""Graph generative models are essential across diverse scientific domains by capturing complex distributions over relational data. Among them, graph diffusion models achieve superior performance but face inefficient sampling and limited flexibility due to the tight coupling between training and sampling stages. We introduce DeFoG, a novel graph generative framework that disentangles sampling from training, enabling a broader design space for more effective and efficient model optimization. DeFoG employs a discrete flow-matching formulation that respects the inherent symmetries of graphs. We theoretically ground this disentangled formulation by explicitly relating the training loss to the sampling algorithm and showing that DeFoG faithfully replicates the ground truth graph distribution. Building on these foundations, we thoroughly investigate DeFoG's design space and propose novel sampling methods that significantly enhance performance and reduce the required number of refinement steps. Extensive experiments demonstrate state-of-the-art performance across synthetic, molecular, and digital pathology datasets, covering both unconditional and conditional generation settings. It also outperforms most diffusion-based models with just 5–10\\% of their sampling steps.""}",https://openreview.net{'value': '/pdf/eefffca0938717f462a0228a57f36b28cc6809b5.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=KFMuaSG7eB,{'value': 'GradPS: Resolving Futile Neurons in Parameter Sharing Network for Multi-Agent Reinforcement Learning'},Haoyuan Qin; Zhengzhu Liu; Chenxing Lin; Chennan Ma; Songzhu Mei; Siqi Shen; Cheng Wang,~Haoyuan_Qin1; ~Zhengzhu_Liu1; ~Chenxing_Lin1; ~Chennan_Ma1; ~Songzhu_Mei1; ~Siqi_Shen5; ~Cheng_Wang2,{'value': ['multi agent reinforcement learning; parameter sharing; gradient conflict']},"{'value': ""Parameter-sharing (PS) techniques have been widely adopted in cooperative Multi-Agent Reinforcement Learning (MARL). In PS, all the agents share a policy network with identical parameters, which enjoys good sample efficiency. However, PS could lead to homogeneous policies that limit MARL performance. We tackle this problem from the angle of gradient conflict among agents. We find that the existence of futile neurons whose update is canceled out by gradient conflicts among agents leads to poor learning efficiency and diversity. To address this deficiency, we propose GradPS, a gradient-based PS method. It dynamically creates multiple clones for each futile neuron. For each clone, a group of agents with low gradient-conflict shares the neuron's parameters.\nOur method can enjoy good sample efficiency by sharing the gradients among agents of the same clone neuron. Moreover, it can encourage diverse behaviors through independently updating an exclusive clone neuron. Through extensive experiments, we show that GradPS can learn diverse policies with promising performance. The source code for GradPS is available in \\url{https://github.com/xmu-rl-3dv/GradPS}.""}",https://openreview.net{'value': '/pdf/d2fc90dc3abc6960011bf01a1620f0b5662f6929.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=K4N9UvsuNB,{'value': 'Improving Model Alignment Through Collective Intelligence of Open-Source Models'},Junlin Wang; Roy Xie; Shang Zhu; Jue WANG; Ben Athiwaratkun; Bhuwan Dhingra; Shuaiwen Leon Song; Ce Zhang; James Zou,~Junlin_Wang1; ~Roy_Xie1; ~Shang_Zhu1; ~Jue_WANG1; ~Ben_Athiwaratkun1; ~Bhuwan_Dhingra1; ~Shuaiwen_Leon_Song1; ~Ce_Zhang1; ~James_Zou1,"{'value': ['Alignment', 'Open-Source Model', 'Mixture of Agents']}","{'value': 'Building helpful and harmless large language models (LLMs) requires effective model alignment approach based on human instructions and feedback, which necessitates high-quality human-labeled data. Constructing such datasets is often expensive and hard to scale, and may face potential limitations on diversity and generalization. To address these challenges, we introduce Mixture of Agents Alignment (MoAA), that leverages the collective strengths of various language models to provide high-quality data for model alignment. By employing MoAA, we enhance both supervised fine-tuning and preference optimization, leading to improved performance compared to using a single model alone to generate alignment data (e.g. using GPT-4o alone). Evaluation results show that our approach can improve win rate of LLaMA-3.1-8B-Instruct from 19.5 to 48.3 on Arena-Hard and from 22.33 to 57.23 on AlpacaEval2, highlighting a promising direction for model alignment through this new scalable and diverse synthetic data recipe. Furthermore, we demonstrate that MoAA enables a self-improvement pipeline, where models fine-tuned on MoA-generated data surpass their own initial capabilities, providing evidence that our approach can push the frontier of open-source LLMs without reliance on stronger external supervision. Data and code will be released.'}",https://openreview.net{'value': '/pdf/4a7a309af39d9ecaf56e0f0999f759945b1189d3.pdf'},{'abstract_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=JsmfjEEKqX,{'value': 'Understanding and Mitigating Memorization in Diffusion Models for Tabular Data'},Zhengyu Fang; Zhimeng Jiang; Huiyuan Chen; Xiao Li; Jing Li,~Zhengyu_Fang1; ~Zhimeng_Jiang1; ~Huiyuan_Chen1; ~Xiao_Li3; ~Jing_Li4,"{'value': ['Memorization', 'Tabular Data', 'Diffusion Models']}","{'value': 'Tabular data generation has attracted significant research interest in recent years, with the tabular diffusion models greatly improving the quality of synthetic data. However, while memorization—where models inadvertently replicate exact or near-identical training data—has been thoroughly investigated in image and text generation, its effects on tabular data remain largely unexplored. In this paper, we conduct the first comprehensive investigation of memorization phenomena in diffusion models for tabular data. Our empirical analysis reveals that memorization appears in tabular diffusion models and increases with larger training epochs. We further examine the influence of factors such as dataset sizes, feature dimensions, and different diffusion models on memorization. Additionally, we provide a theoretical explanation for why memorization occurs in tabular diffusion models. To address this issue, we propose TabCutMix, a simple yet effective data augmentation technique that exchanges randomly selected feature segments between random same-class training sample pairs. Building upon this, we introduce TabCutMixPlus, an enhanced method that clusters features based on feature correlations and ensures that features within the same cluster are exchanged together during augmentation. This clustering mechanism mitigates out-of-distribution (OOD) generation issues by maintaining feature coherence. Experimental results across various datasets and diffusion models demonstrate that TabCutMix effectively mitigates memorization while maintaining high-quality data generation. Our code is available at https://github.com/fangzy96/TabCutMix.'}",https://openreview.net{'value': '/pdf/c1e40cc6821f5fe1ebfce35975e5011519686173.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=JsPyLqCgks,{'value': 'A Mixed-Curvature based Pre-training Paradigm for Multi-Task Vehicle Routing Solver'},Suyu Liu; Zhiguang Cao; Shanshan Feng; Yew-Soon Ong,~Suyu_Liu2; ~Zhiguang_Cao1; ~Shanshan_Feng1; ~Yew-Soon_Ong1,"{'value': ['Combinatorial Optimization', 'Constrained Optimization', 'Vehicle Routing Problems', 'Deep Reinforcement Learning']}","{'value': 'Solving various types of vehicle routing problems (VRPs) using a unified neural solver has garnered significant attentions in recent years. Despite their effectiveness, existing neural multi-task solvers often fail to account for the geometric structures inherent in different tasks, which may result in suboptimal performance. To address this limitation, we propose a curvature-aware pre-training framework. Specifically, we leverage mixed-curvature spaces during the feature fusion stage, encouraging the model to capture the underlying geometric properties of each instance. Through extensive experiments, we evaluate the proposed pre-training strategy on existing neural multi-task solvers across a variety of testing scenarios. The results demonstrate that the curvature-aware pre-training approach not only enhances the generalization capabilities of existing neural VRP solvers on synthetic datasets but also improves solution quality on real-world benchmarks.'}",https://openreview.net{'value': '/pdf/f945772d8ca38c8809ee056bb14575fc468c4a47.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=JjhnSLb2wO,{'value': 'Reconstructing Cell Lineage Trees from Phenotypic Features with Metric Learning'},Da Kuang; GuanWen Qiu; Junhyong Kim,~Da_Kuang2; ~GuanWen_Qiu1; ~Junhyong_Kim1,"{'value': ['Metric learning', 'Cell lineage reconstruction', 'scRNA-seq', 'Representation learning']}","{'value': ""How a single fertilized cell gives rise to a complex array of specialized cell types in development is a central question in biology. The cells replicate to generate cell lineages and acquire differentiated characteristics through poorly understood molecular processes. A key approach to studying developmental processes is to infer the tree graph of cell lineage histories, which provides an analytical framework for dissecting individual cells' molecular decisions during replication and differentiation (i.e., acquisition of specialized traits). Although genetically engineered lineage-tracing methods have advanced the field, they are either infeasible or ethically constrained in many organisms. By contrast, modern single-cell technologies can measure high-content molecular profiles (*e.g.*, transcriptomes) in a wide range of biological systems. Here, we introduce *CellTreeQM*, a novel deep learning method based on transformer architectures that learns an embedding space with geometric properties optimized for tree-graph inference. By formulating the lineage reconstruction problem as tree-metric learning, we systematically explore weakly supervised training settings at different levels of information and present the *Cell Lineage Reconstruction Benchmark* to facilitate comprehensive evaluation. This benchmark includes (1) synthetic data modeled via Brownian motion with independent noise and spurious signals; (2) lineage-resolved single-cell RNA sequencing datasets. Experimental results show that *CellTreeQM* recovers lineage structures with minimal supervision and limited data, offering a scalable framework for uncovering cell lineage relationships. To our knowledge, this is the first method to cast cell lineage inference explicitly as a metric learning task, paving the way for future computational models aimed at uncovering the molecular dynamics of cell lineage. Code and benchmarks are available at: https://kuang-da.github.io/CellTreeQM-page""}",https://openreview.net{'value': '/pdf/4db283f9c09772ec27df939caa4f593221311f63.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=JiFfij5iv0,{'value': 'MedRAX: Medical Reasoning Agent for Chest X-ray'},Adibvafa Fallahpour; Jun Ma; Alif Munim; Hongwei Lyu; BO WANG,~Adibvafa_Fallahpour1; ~Jun_Ma1; ~Alif_Munim1; ~Hongwei_Lyu1; ~BO_WANG11,"{'value': ['healthcare', 'agent', 'multimodal', 'chest X-ray', 'benchmark']}","{'value': 'Chest X-rays (CXRs) play an integral role in driving critical decisions in disease management and patient care. While recent innovations have led to specialized models for various CXR interpretation tasks, these solutions often operate in isolation, limiting their practical utility in clinical practice. We present MedRAX, the first versatile AI agent that seamlessly integrates state-of-the-art  CXR analysis tools and multimodal large language models into a unified framework. MedRAX dynamically leverages these models to address complex medical queries without requiring additional training. To rigorously evaluate its capabilities, we introduce ChestAgentBench, a comprehensive benchmark containing 2,500 complex medical queries across 7 diverse categories. Our experiments demonstrate that MedRAX achieves state-of-the-art performance compared to both open-source and proprietary models, representing a significant step toward the practical deployment of automated CXR interpretation systems. Data and code have been publicly available at https://github.com/bowang-lab/MedRAX'}",https://openreview.net{'value': '/pdf/1580e44a1680e04391fba60b36323eff71dd2620.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=JgUBM5hwcM,{'value': 'Accelerating Spectral Clustering under Fairness Constraints'},Francesco Tonin; Alex Lambert; Johan Suykens; Volkan Cevher,~Francesco_Tonin1; ~Alex_Lambert1; ~Johan_Suykens1; ~Volkan_Cevher1,"{'value': ['fairness', 'spectral clustering', 'difference of convex', 'scalability']}","{'value': 'Fairness of decision-making algorithms is an increasingly important issue. In this paper, we focus on spectral clustering with group fairness constraints, where every demographic group is represented in each cluster proportionally as in the general population. We present a new efficient method for fair spectral clustering (Fair SC) by casting the Fair SC problem within the difference of convex functions (DC) framework. To this end, we introduce a novel variable augmentation strategy and employ an alternating direction method of multipliers type of algorithm adapted to DC problems. We show that each associated subproblem can be solved efficiently, resulting in higher computational efficiency compared to prior work, which required a computationally expensive eigendecomposition. Numerical experiments\ndemonstrate the effectiveness of our approach on both synthetic and real-world benchmarks, showing significant speedups in computation time over prior art, especially as the problem size grows. This work thus represents a considerable step forward towards the adoption of fair clustering in real-world applications.'}",https://openreview.net{'value': '/pdf/323f13cb6e842f61b7a3e48c2ff867cde48e3fa9.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=JPkJAyutW0,{'value': 'Revisiting Cooperative Off-Policy Multi-Agent Reinforcement Learning'},Yueheng Li; Guangming Xie; Zongqing Lu,~Yueheng_Li1; ~Guangming_Xie1; ~Zongqing_Lu2,"{'value': ['cooperative multi-agent reinforcement learning', 'off-policy multi-agent reinforcement learning', 'value factorization', 'extrapolation error']}","{'value': 'Cooperative Multi-Agent Reinforcement Learning (MARL) has become a critical tool for addressing complex real-world problems. \nHowever, off-policy MARL methods, which rely on joint Q-functions, face significant scalability challenges due to the exponentially growing joint action space.\nIn this work, we highlight a critical yet often overlooked issue: erroneous Q-target estimation, primarily caused by extrapolation error.\nOur analysis reveals that this error becomes increasingly severe as the number of agents grows, leading to unique challenges in MARL due to its expansive joint action space and the decentralized execution paradigm.\nTo address these challenges, we propose a suite of techniques tailored for off-policy MARL, including annealed multi-step bootstrapping, averaged Q-targets, and restricted action representation. Experimental results demonstrate that these methods effectively mitigate erroneous estimations, yielding substantial performance improvements in challenging benchmarks such as SMAC, SMACv2, and Google Research Football.'}",https://openreview.net{'value': '/pdf/b54da94f46d6cf880109d9d512f14e2e0c4fb912.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=JN8O01IZYR,"{'value': 'When, Where and Why to Average Weights?'}",Niccolò Ajroldi; Antonio Orvieto; Jonas Geiping,~Niccolò_Ajroldi1; ~Antonio_Orvieto3; ~Jonas_Geiping1,"{'value': ['Weight Averaging', 'Checkpoint Averaging', 'Optimization', 'Learning Rate Schedule.']}","{'value': 'Averaging checkpoints along the training trajectory is a simple yet powerful approach to improve the generalization performance of Machine Learning models and reduce training time. Motivated by these potential gains, and in an effort to fairly and thoroughly benchmark this technique, we present an extensive evaluation of averaging techniques in modern Deep Learning, which we perform using AlgoPerf, a large-scale benchmark for optimization algorithms. We investigate whether weight averaging can reduce training time, improve generalization, and replace learning rate decay, as suggested by recent literature. Our evaluation across seven architectures and datasets reveals that averaging significantly accelerates training and yields considerable efficiency gains across all considered workloads, at the price of a minimal implementation and memory cost, while mildly improving generalization. Finally, we explore the relationship between averaging and learning rate annealing and show that combining the two achieves optimal performance.'}",https://openreview.net{'value': '/pdf/0bdbc7492ffc98ae2e915b567a8dd9d6ef46e184.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=J5YGi2LzI7,{'value': 'Enhancing Decision-Making of Large Language Models via Actor-Critic'},Heng Dong; Kefei Duan; Chongjie Zhang,~Heng_Dong1; ~Kefei_Duan1; ~Chongjie_Zhang1,"{'value': ['Large Language Models', 'Decision-Making', 'Actor-Critic']}","{'value': 'Large Language Models (LLMs) have achieved remarkable advancements in natural language processing tasks, yet they encounter challenges in complex decision-making scenarios that require long-term reasoning and alignment with high-level objectives. Existing methods either rely on short-term auto-regressive action generation or face limitations in accurately simulating rollouts and assessing outcomes, leading to sub-optimal decisions. This paper introduces a novel LLM-based Actor-Critic framework, termed LAC, that effectively improves LLM policies with long-term action evaluations in a principled and scalable way. Our approach addresses two key challenges: (1) extracting robust action evaluations by computing Q-values via token logits associated with positive/negative outcomes, enhanced by future trajectory rollouts and reasoning; and (2) enabling efficient policy improvement through a gradient-free mechanism. Experiments across diverse environments -- including high-level decision-making (ALFWorld), low-level action spaces (BabyAI-Text), and large action spaces (WebShop) -- demonstrate the framework’s generality and superiority over state-of-the-art methods. Notably, our approach achieves competitive performance using 7B/8B parameter LLMs, even outperforming baseline methods employing GPT-4 in complex tasks. These results underscore the potential of integrating structured policy optimization with LLMs’ intrinsic knowledge to advance decision-making capabilities in multi-step environments.'}",https://openreview.net{'value': '/pdf/3f678faf995b0e4210a0f0882ec792f6f0f9be10.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=J16AIOkjjY,{'value': 'Causal Abstraction Learning based on the Semantic Embedding Principle'},Gabriele D'Acunto; Fabio Massimo Zennaro; Yorgos Felekis; Paolo Di Lorenzo,~Gabriele_D'Acunto1; ~Fabio_Massimo_Zennaro1; ~Yorgos_Felekis1; ~Paolo_Di_Lorenzo1,"{'value': ['structural causal models', 'causal abstraction', 'semantic embedding principle', 'Stiefel manifold', 'Riemannian optimization']}","{'value': 'Structural causal models (SCMs) allow us to investigate complex systems at multiple levels of resolution.\nThe causal abstraction (CA) framework formalizes the mapping between high- and low-level SCMs. \nWe address CA learning in a challenging and realistic setting, where SCMs are inaccessible, interventional data is unavailable, and sample data is misaligned.\nA key principle of our framework is *semantic embedding*, formalized as the high-level distribution lying on a subspace of the low-level one. \nThis principle naturally links linear CA to the geometry of the *Stiefel manifold*.\nWe present a category-theoretic approach to SCMs that enables the learning of a CA by finding a morphism between the low- and high-level probability measures, adhering to the semantic embedding principle.\nConsequently, we formulate a general CA learning problem.\nAs an application, we solve the latter problem for linear CA; considering Gaussian measures and the Kullback-Leibler divergence as an objective.\nGiven the nonconvexity of the learning task, we develop three algorithms building upon existing paradigms for Riemannian optimization.\nWe demonstrate that the proposed methods succeed on both synthetic and real-world brain data with different degrees of prior information about the structure of CA.'}",https://openreview.net{'value': '/pdf/ffd5c2360ef492c4ab5d740bb6140bc1764f92ac.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=IyVcxU0RKI,{'value': 'MedXpertQA: Benchmarking Expert-Level Medical Reasoning and Understanding'},Yuxin Zuo; Shang Qu; Yifei Li; Zhang-Ren Chen; Xuekai Zhu; Ermo Hua; Kaiyan Zhang; Ning Ding; Bowen Zhou,~Yuxin_Zuo1; ~Shang_Qu1; ~Yifei_Li22; ~Zhang-Ren_Chen1; ~Xuekai_Zhu1; ~Ermo_Hua1; ~Kaiyan_Zhang1; ~Ning_Ding5; ~Bowen_Zhou8,"{'value': ['Medicine', 'Benchmark', 'Multimodal']}","{'value': 'We introduce MedXpertQA, a highly challenging and comprehensive benchmark to evaluate expert-level medical knowledge and advanced reasoning. MedXpertQA includes 4,460 questions spanning 17 specialties and 11 body systems. It includes two subsets, Text for text evaluation and MM for multimodal evaluation. Notably, MM introduces expert-level exam questions with diverse images and rich clinical information, including patient records and examination results, setting it apart from traditional medical multimodal benchmarks with simple QA pairs generated from image captions. MedXpertQA applies rigorous filtering and augmentation to address the insufficient difficulty of existing benchmarks like MedQA, and incorporates specialty board questions to improve clinical relevance and comprehensiveness. We perform data synthesis to mitigate data leakage risk and conduct multiple rounds of expert reviews to ensure accuracy and reliability. We evaluate 18 leading models on MedXpertQA. Moreover, medicine is deeply connected to real-world decision-making, providing a rich and representative setting for assessing reasoning abilities beyond mathematics and code. To this end, we develop a reasoning-oriented subset to facilitate the assessment of o1-like models.'}",https://openreview.net{'value': '/pdf/614e9662f4ae335ff72a8c3b40752f536039ff37.pdf'},{'abstract_filter': 'Data Synthesis'},ICML.cc,2025,Conference
https://openreview.net/forum?id=Inrv8EXylW,{'value': 'Discrete Neural Algorithmic Reasoning'},Gleb Rodionov; Liudmila Prokhorenkova,~Gleb_Rodionov1; ~Liudmila_Prokhorenkova1,"{'value': ['neural algorithmic reasoning', 'graph neural networks']}","{'value': ""Neural algorithmic reasoning aims to capture computations with neural networks by training models to imitate the execution of classical algorithms. While common architectures are expressive enough to contain the correct model in the weight space, current neural reasoners struggle to generalize well on out-of-distribution data. On the other hand, classical computations are not affected by distributional shifts as they can be described as transitions between discrete computational states. In this work, we propose to force neural reasoners to maintain the execution trajectory as a combination of finite predefined states. To achieve this, we separate discrete and continuous data flows and describe the interaction between them. Trained with supervision on the algorithm's state transitions, such models are able to perfectly align with the original algorithm. To show this, we evaluate our approach on multiple algorithmic problems and achieve perfect test scores both in single-task and multitask setups. Moreover, the proposed architectural choice allows us to prove the correctness of the learned algorithms for any test data.""}",https://openreview.net{'value': '/pdf/1ffacbd33b69e40b7c64653cb6c7401b7b79f73f.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=IiVM70BgSV,{'value': 'Feature Importance Metrics in the Presence of Missing Data'},Henrik von Kleist; Joshua Wendland; Ilya Shpitser; Carsten Marr,~Henrik_von_Kleist1; ~Joshua_Wendland2; ~Ilya_Shpitser1; ~Carsten_Marr1,"{'value': ['feature importance', 'missing data', 'leave-one-covariate-out', 'feature acquisition', 'full data', 'observed data']}","{'value': 'Feature importance metrics are critical for interpreting machine learning models and understanding the relevance of individual features. However, real-world data often exhibit missingness, thereby complicating how feature importance should be evaluated.  We introduce the distinction between two evaluation frameworks under missing data: (1) feature importance under the full data, as if every feature had been fully measured, and (2) feature importance under the observed data, where missingness is governed by the current measurement policy. While the full data perspective offers insights into the data generating process, it often relies on unrealistic assumptions and cannot guide decisions when missingness persists at model deployment. Since neither framework directly informs improvements in data collection, we additionally introduce the feature measurement importance gradient (FMIG), a novel, model-agnostic metric that identifies features that should be measured more frequently to enhance predictive performance. Using synthetic data, we illustrate key differences between these metrics and the risks of conflating them.'}",https://openreview.net{'value': '/pdf/a5f706e5d96b9bfac05b8ead0359382503281f45.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=IKCfxWtTsu,{'value': 'PCEvolve: Private Contrastive Evolution for Synthetic Dataset Generation via Few-Shot Private Data and Generative APIs'},Jianqing Zhang; Yang Liu; JIE FU; Yang Hua; Tianyuan Zou; Jian Cao; Qiang Yang,~Jianqing_Zhang1; ~Yang_Liu59; ~JIE_FU9; ~Yang_Hua2; ~Tianyuan_Zou1; ~Jian_Cao1; ~Qiang_Yang1,"{'value': ['synthetic data generation', 'differential privacy', 'evolution algorithm']}","{'value': 'The rise of generative APIs has fueled interest in privacy-preserving synthetic data generation. While the Private Evolution (PE) algorithm generates Differential Privacy (DP) synthetic images using diffusion model APIs, it struggles with few-shot private data due to the limitations of its DP-protected similarity voting approach. In practice, the few-shot private data challenge is particularly prevalent in specialized domains like healthcare and industry. To address this challenge, we propose a novel API-assisted algorithm, Private Contrastive Evolution (PCEvolve), which iteratively mines inherent inter-class contrastive relationships in few-shot private data beyond individual data points and seamlessly integrates them into an adapted Exponential Mechanism (EM) to optimize DP’s utility in an evolution loop. We conduct extensive experiments on four specialized datasets, demonstrating that PCEvolve outperforms PE and other API-assisted baselines. These results highlight the potential of leveraging API access with private data for quality evaluation, enabling the generation of high-quality DP synthetic images and paving the way for more accessible and effective privacy-preserving generative API applications. Our code is available at https://github.com/TsingZ0/PCEvolve.'}",https://openreview.net{'value': '/pdf/a5f344dd5e9457d65c7a51d5e0530fe4cfbf5bb6.pdf'},{'title_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=IF9VXY4YRl,{'value': 'Beyond Confidence: Exploiting Homogeneous Pattern for Semi-Supervised Semantic Segmentation'},Rui Sun; Huayu Mai; Wangkai Li; Yujia Chen; Naisong Luo; Yuan Wang; Tianzhu Zhang,~Rui_Sun5; ~Huayu_Mai1; ~Wangkai_Li1; ~Yujia_Chen4; ~Naisong_Luo1; ~Yuan_Wang16; ~Tianzhu_Zhang1,{'value': ['Semantic Segmentation']},"{'value': ""The critical challenge of semi-supervised semantic segmentation lies in how to fully exploit a large volume of unlabeled data to improve the model's generalization performance for robust segmentation. Existing methods mainly rely on confidence-based scoring functions in the prediction space to filter pseudo labels, which suffer from the inherent trade-off between true and false positive rates. In this paper, we carefully design an agent construction strategy to build clean sets of correct (positive) and incorrect (negative) pseudo labels, and propose the Agent Score function (AgScore)  to measure the consensus between candidate pixels and these sets. In this way, AgScore takes a step further to capture homogeneous patterns in the embedding space, conditioned on clean positive/negative agents stemming from the prediction space, without sacrificing the merits of confidence score, yielding better trad-off. We provide theoretical analysis to understand the mechanism of AgScore, and demonstrate its effectiveness by integrating it into three semi-supervised segmentation frameworks on Pascal VOC, Cityscapes, and COCO datasets, showing consistent improvements across all data partitions.""}",https://openreview.net{'value': '/pdf/25d6703844f7e7c91e184fa5b70d04475c6d99a9.pdf'},{'abstract_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=I8DVh2jnEA,{'value': 'FairPFN: A Tabular Foundation Model for Causal Fairness'},Jake Robertson; Noah Hollmann; Samuel Müller; Noor Awad; Frank Hutter,~Jake_Robertson1; ~Noah_Hollmann1; ~Samuel_Müller1; ~Noor_Awad1; ~Frank_Hutter1,"{'value': ['Causal Fairness', 'Foundation Models', 'In-Context-Learning', 'Prior-Fitted-Networks']}","{'value': ""Machine learning (ML) systems are utilized in critical sectors such as healthcare, law enforcement, and finance, but often rely on historical data that contains demographic biases, leading to decisions that perpetuate or intensify existing inequalities. Causal and counterfactual fairness provide a transparent, human-in-the-loop framework to mitigate algorithmic discrimination, aligning closely with legal doctrines of direct and indirect discrimination. However, current causal fairness frameworks hold a key limitation in that they assume prior knowledge of the correct causal model, restricting their applicability in complex fairness scenarios where causal models are unknown or difficult to identify. To bridge this gap, we propose FairPFN, a tabular foundation model pre-trained on synthetic causal fairness data to identify and mitigate the causal effects of protected attributes in its predictions. FairPFN's key contribution is that it requires no knowledge of the causal model and demonstrates strong performance across a diverse set of hand-crafted and real-world causal scenarios relative to robust baseline methods. FairPFN paves the way for a promising direction for future research, making causal fairness more accessible to a wider variety of complex fairness problems.""}",https://openreview.net{'value': '/pdf/cc5d7763bcfa2e111d88cd946acd470c65ccdcab.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=HjVhSL76GM,{'value': 'WMarkGPT: Watermarked Image Understanding via Multimodal Large Language Models'},Songbai Tan; Xuerui Qiu; Yao Shu; Gang Xu; Linrui Xu; Xiangyu Xu; Huiping Zhuang; Ming Li; Fei Yu,~Songbai_Tan2; ~Xuerui_Qiu1; ~Yao_Shu1; ~Gang_Xu2; ~Linrui_Xu1; ~Xiangyu_Xu3; ~Huiping_Zhuang2; ~Ming_Li21; ~Fei_Yu13,{'value': ['Watermarked image understanding']},"{'value': 'Invisible watermarking is widely used to protect digital images from unauthorized use. Accurate assessment of watermarking efficacy is crucial for advancing algorithmic development. However, existing statistical metrics, such as PSNR, rely on access to original images, which are often unavailable in text-driven generative watermarking and fail to capture critical aspects of watermarking, particularly visibility. More importantly, these metrics fail to account for potential corruption of image content. To address these limitations, we propose WMarkGPT, the first multimodal large language model (MLLM) specifically designed for comprehensive watermarked image understanding, without accessing original images. WMarkGPT not only predicts watermark visibility but also generates detailed textual descriptions of its location, content, and impact on image semantics, enabling a more nuanced interpretation of watermarked images. Tackling the challenge of precise location description and understanding images with vastly different content, we construct three visual question-answering (VQA) datasets: an object location-aware dataset, a synthetic watermarking dataset, and a real watermarking dataset. We introduce a meticulously designed three-stage learning pipeline to progressively equip WMarkGPT with the necessary abilities. Extensive experiments on synthetic and real watermarking QA datasets demonstrate that WMarkGPT outperforms existing MLLMs, achieving significant improvements in visibility prediction and content description. The datasets and code are released at https://github.com/TanSongBai/WMarkGPT.'}",https://openreview.net{'value': '/pdf/3f4b912158ee1d8e3c7e605369f524c021791d86.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=HZdK1aj22X,{'value': 'Learning Robust Neural Processes with Risk-Averse Stochastic Optimization'},Huafeng Liu; Yiran Fu; Liping Jing; Hui Li; Shuyang Lin; Jingyue Shi; Deqiang Ouyang; Jian Yu,~Huafeng_Liu3; ~Yiran_Fu2; ~Liping_Jing3; ~Hui_Li38; ~Shuyang_Lin4; ~Jingyue_Shi1; ~Deqiang_Ouyang2; ~Jian_Yu1,"{'value': ['neural process', 'robust learning']}","{'value': 'Neural processes (NPs) are a promising paradigm to enable skill transfer learning across tasks with the aid of the distribution of functions. The previous NPs employ the empirical risk minimization principle in optimization. However, the fast adaption ability to different tasks can vary widely, and the worst fast adaptation can be catastrophic in risk-sensitive tasks. To achieve robust neural processes modeling, we consider the problem of training models in a risk-averse manner, which can control the worst fast adaption cases at a certain probabilistic level. By transferring the risk minimization problem to a two-level finite sum minimax optimization problem, we can easily solve it via a double-looped stochastic mirror prox algorithm with a task-aware variance reduction mechanism via sampling samples across all tasks. The mirror prox technique ensures better handling of complex constraint sets and non-Euclidean geometries, making the optimization adaptable to various tasks. The final solution, by aggregating prox points with the adaptive learning rates, enables a stable and high-quality output. The proposed learning strategy can work with various NPs flexibly and achieves less biased approximation with a theoretical guarantee. To illustrate the superiority of the proposed model, we perform experiments on both synthetic and real-world data, and the results demonstrate that our approach not only helps to achieve more accurate performance but also improves model robustness.'}",https://openreview.net{'value': '/pdf/00a711d288a5bf759810655c292d3c6aee9976bb.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=HMequFD3Uz,{'value': 'Fixed-Confidence Multiple Change Point Identification under Bandit Feedback'},Joseph Lazzaro; Ciara Pike-Burke,~Joseph_Lazzaro1; ~Ciara_Pike-Burke2,"{'value': ['bandits', 'pure exploration', 'fixed confidence', 'change points']}","{'value': 'Piecewise constant functions describe a variety of real-world phenomena in domains ranging from chemistry to manufacturing. In practice, it is often required to confidently identify the locations of the abrupt changes in these functions as quickly as possible. For this, we introduce a fixed-confidence piecewise constant bandit problem. Here, we sequentially query points in the domain and receive noisy evaluations of the function under bandit feedback. We provide instance-dependent lower bounds for the complexity of change point identification in this problem. These lower bounds illustrate that an optimal method should focus its sampling efforts adjacent to each of the change points, and the number of samples around each change point should be inversely proportional to the magnitude of the change.\nBuilding on this, we devise a simple and computationally efficient variant of Track-and-Stop and prove that it is asymptotically optimal in many regimes. We support our theoretical findings with experimental results in synthetic environments demonstrating the efficiency of our method.'}",https://openreview.net{'value': '/pdf/24c1a764cb267972d0d9b036b5a457bdbf465328.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=HHwGfLOKxq,{'value': 'Scaling Laws for Pre-training Agents and World Models'},Tim Pearce; Tabish Rashid; David Bignell; Raluca Georgescu; Sam Devlin; Katja Hofmann,~Tim_Pearce1; ~Tabish_Rashid1; ~David_Bignell1; ~Raluca_Georgescu1; ~Sam_Devlin2; ~Katja_Hofmann1,"{'value': ['world modeling', 'imitation learning', 'scaling laws']}","{'value': ""The performance of embodied agents has been shown to improve by increasing model parameters, dataset size, and compute. This has been demonstrated in domains from robotics to video games, when generative learning objectives on offline datasets (pre-training) are used to model an agent's behavior (imitation learning) or their environment (world modeling). This paper characterizes the role of scale in these tasks more precisely. Going beyond the simple intuition that `bigger is better', we show that the same types of power laws found in language modeling also arise in world modeling and imitation learning (e.g. between loss and optimal model size). However, the coefficients of these laws are heavily influenced by the tokenizer, task \\& architecture -- this has important implications on the optimal sizing of models and data.""}",https://openreview.net{'value': '/pdf/a7a58483e4908d16dd8e656927a0b474fb4781dd.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=H76PMm7hf2,{'value': 'Towards Efficient Online Tuning of VLM Agents via Counterfactual Soft Reinforcement Learning'},Lang Feng; Weihao Tan; Zhiyi Lyu; Longtao Zheng; Haiyang Xu; Ming Yan; Fei Huang; Bo An,~Lang_Feng1; ~Weihao_Tan1; ~Zhiyi_Lyu1; ~Longtao_Zheng1; ~Haiyang_Xu1; ~Ming_Yan2; ~Fei_Huang2; ~Bo_An2,"{'value': ['vision-language model', 'agent', 'reinforcement learning', 'online fine-tuning', 'counterfactual']}","{'value': ""Online fine-tuning vision-language model (VLM) agents with reinforcement learning (RL) has shown promise for equipping agents with multi-step, goal-oriented capabilities in dynamic environments. However, their open-ended textual action space and non-end-to-end nature of action generation present significant challenges to effective online exploration in RL, e.g., explosion of the exploration space. We propose a novel online fine-tuning method, Counterfactual Soft Reinforcement Learning (CoSo), better suited to the textual output space of VLM agents. Compared to prior methods that assign uniform uncertainty to all tokens, CoSo leverages counterfactual reasoning to dynamically assess the causal influence of individual tokens on post-processed actions. By prioritizing the exploration of action-critical tokens while reducing the impact of semantically redundant or low-impact tokens, CoSo enables a more targeted and efficient online rollout process. We provide theoretical analysis proving CoSo's convergence and policy improvement guarantees, and extensive empirical evaluations supporting CoSo's effectiveness. Our results across a diverse set of agent tasks, including Android device control, card gaming, and embodied AI, highlight its remarkable ability to enhance exploration efficiency and deliver consistent performance gains. The code is available at https://github.com/langfengQ/CoSo.""}",https://openreview.net{'value': '/pdf/79d7c13badf6250286deb9e558c99bb7b0f69a20.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=H4UMsoQrdI,{'value': 'Benign Overfitting in Token Selection of Attention Mechanism'},Keitaro Sakamoto; Issei Sato,~Keitaro_Sakamoto1; ~Issei_Sato2,"{'value': ['Attention mechanism', 'token selection', 'benign overfitting', 'gradient descent', 'over-parameterization']}","{'value': ""Attention mechanism is a fundamental component of the transformer model and plays a significant role in its success.\nHowever, the theoretical understanding of how attention learns to select tokens is still an emerging area of research.\nIn this work, we study the training dynamics and generalization ability of the attention mechanism, under classification problems with label noise.\nWe show that, with the characterization of signal-to-noise ratio (SNR), the token selection of attention mechanism achieves ``benign overfitting'', i.e., maintaining high generalization performance despite fitting label noise.\nOur work also demonstrates an interesting delayed acquisition of generalization after an initial phase of overfitting.\nFinally, we provide experiments to support our theoretical analysis using both synthetic and real-world datasets.""}",https://openreview.net{'value': '/pdf/30cbd9b5d805a848728f6e00faabfaca9f8a8977.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=GzFKZctIzj,{'value': 'KoNODE: Koopman-Driven Neural Ordinary Differential Equations with Evolving Parameters for Time Series Analysis'},Hanru Bai; Weiyang Ding,~Hanru_Bai2; ~Weiyang_Ding1,{'value': ['Neural ODE; Koopman Operators; Parameter Modeling; Time Series Analysis; Dynamics Modeling;']},"{'value': 'Neural ordinary differential equations (NODEs) have demonstrated strong capabilities in modeling time series. However, existing NODE- based methods often focus solely on the surface-level dynamics derived from observed states, which limits their ability to capture more complex underlying behaviors. To overcome this challenge, we propose KoNODE, a Koopman-driven NODE framework that explicitly models the evolution of ODE parameters over time to encode deep-level information. KoNODE captures the essential yet simple intrinsic linear dynamics that govern the surface dynamics by employing Koopman operators. Our framework operates at three hierarchical levels: the observed state dynamics, the parameter dynamics, and the Koopman linear dynamics, representing the fundamental driving rules of the state dynamics. The proposed approach offers significant improvements in two critical time series tasks: long-term prediction (enabled by the simple linear dynamics) and generalization to new data (driven by the evolving ODE parameters). We validate KoNODE through experiments on synthetic data from complex dynamic systems and real-world datasets, demonstrating its effectiveness in practical scenarios.'}",https://openreview.net{'value': '/pdf/726d7730fb55b80aa187a07d4aa6aa385ef8ef9b.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=Ggt3iu0Zni,{'value': 'Efficient Quantification of Multimodal Interaction at Sample Level'},Zequn Yang; Hongfa Wang; Di Hu,~Zequn_Yang2; ~Hongfa_Wang2; ~Di_Hu1,"{'value': ['Multimodal interactions', 'Information measurement', 'Information decomposition']}","{'value': ""Interactions between modalities—redundancy, uniqueness, and synergy—collectively determine the composition of multimodal information. Understanding these interactions is crucial for analyzing information dynamics in multimodal systems, yet their accurate sample-level quantification presents significant theoretical and computational challenges. To address this, we introduce the Lightweight Sample-wise Multimodal Interaction (LSMI) estimator, rigorously grounded in pointwise information theory. We first develop a redundancy estimation framework, employing an appropriate pointwise information measure to quantify this most decomposable and measurable interaction.\nBuilding upon this, we propose a general interaction estimation method that employs efficient entropy estimation, specifically tailored for sample-wise estimation in continuous distributions. Extensive experiments on synthetic and real-world datasets validate LSMI's precision and efficiency. Crucially, our sample-wise approach reveals fine-grained sample- and category-level dynamics within multimodal data, enabling practical applications such as redundancy-informed sample partitioning, targeted knowledge distillation, and interaction-aware model ensembling. The code is available at https://github.com/GeWu-Lab/LSMI_Estimator.""}",https://openreview.net{'value': '/pdf/a57fdde7511feafb18776b143b7909b15751e11d.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=Gdcwm4LLfb,{'value': 'Morse: Dual-Sampling for Lossless Acceleration of Diffusion Models'},Chao Li; Jiawei Fan; Anbang Yao,~Chao_Li16; ~Jiawei_Fan1; ~Anbang_Yao1,"{'value': ['Diffusion models', 'image generation', 'text-to-image generation', 'model acceleration']}","{'value': 'In this paper, we present $Morse$, a simple dual-sampling framework for accelerating diffusion models losslessly. The key insight of Morse is to reformulate the iterative generation (from noise to data) process via taking advantage of fast jump sampling and adaptive residual feedback strategies. Specifically, Morse involves two models called $Dash$ and $Dot$ that interact with each other. The Dash model is just the pre-trained diffusion model of any type, but operates in a jump sampling regime, creating sufficient space for sampling efficiency improvement. The Dot model is significantly faster than the Dash model, which is learnt to generate residual feedback conditioned on the observations at the current jump sampling point on the trajectory of the Dash model, lifting the noise estimate to easily match the next-step estimate of the Dash model without jump sampling. By chaining the outputs of the Dash and Dot models run in a time-interleaved fashion, Morse exhibits the merit of flexibly attaining desired image generation performance while improving overall runtime efficiency. With our proposed weight sharing strategy between the Dash and Dot models, Morse is efficient for training and inference. Our method shows a lossless speedup of 1.78$\\times$ to 3.31$\\times$ on average over a wide range of sampling step budgets relative to 9 baseline diffusion models on 6 image generation tasks. Furthermore, we show that our method can be also generalized to improve the Latent Consistency Model (LCM-SDXL, which is already accelerated with consistency distillation technique) tailored for few-step text-to-image synthesis. The code and models are available at https://github.com/deep-optimization/Morse.'}",https://openreview.net{'value': '/pdf/e5734722bd2e9dc46c4568ff16de0d9f7a2e844d.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=GdYg0Ohx0k,{'value': 'LSCD: Lomb--Scargle Conditioned Diffusion for Time series Imputation'},Elizabeth Fons; Alejandro Sztrajman; Yousef El-Laham; Luciana Ferrer; Svitlana Vyetrenko; Manuela Veloso,~Elizabeth_Fons1; ~Alejandro_Sztrajman1; ~Yousef_El-Laham1; ~Luciana_Ferrer1; ~Svitlana_Vyetrenko1; ~Manuela_Veloso1,"{'value': ['time series', 'diffusion models', 'frequency spectrum']}","{'value': 'Time series with missing or irregularly sampled data are a persistent challenge in machine learning. Many methods operate on the frequency-domain, relying on the Fast Fourier Transform (FFT) which assumes uniform sampling, therefore requiring prior interpolation that can distort the spectra. To address this limitation, we introduce a differentiable Lomb--Scargle layer that enables a reliable computation of the power spectrum of irregularly sampled data.\nWe integrate this layer into a novel score-based diffusion model (LSCD) for time series imputation conditioned on the entire signal spectrum. \nExperiments on synthetic and real-world benchmarks demonstrate that our method recovers missing data more accurately than purely time-domain baselines, while simultaneously producing consistent frequency estimates. Crucially, our method can be easily integrated into learning frameworks, enabling broader adoption of spectral guidance in machine learning approaches involving incomplete or irregular data.'}",https://openreview.net{'value': '/pdf/12163661cd94ad6155e664a40a68f76bbc2a817c.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=GazlTYxZss,{'value': 'Which Agent Causes Task Failures and When? On Automated Failure Attribution of LLM Multi-Agent Systems'},Shaokun Zhang; Ming Yin; Jieyu Zhang; Jiale Liu; Zhiguang Han; Jingyang Zhang; Beibin Li; Chi Wang; Huazheng Wang; Yiran Chen; Qingyun Wu,~Shaokun_Zhang2; ~Ming_Yin6; ~Jieyu_Zhang1; ~Jiale_Liu2; ~Zhiguang_Han1; ~Jingyang_Zhang2; ~Beibin_Li1; ~Chi_Wang3; ~Huazheng_Wang1; ~Yiran_Chen1; ~Qingyun_Wu2,"{'value': ['failure attribution', 'multi-agent systems.']}","{'value': ""Failure attribution in LLM multi-agent systems—identifying the agent and step responsible for task failures—provides crucial clues for systems debugging but remains underexplored and labor-intensive. \nIn this paper, we propose and formulate a new research area: automated failure attribution for LLM multi-agent systems.\nTo support this initiative, we introduce the Who\\&When dataset, comprising extensive failure logs from 127 LLM multi-agent systems with fine-grained annotations linking failures to specific agents and decisive error steps.\nUsing the Who\\&When, we develop and evaluate three automated failure attribution methods, summarizing their corresponding pros and cons.  The best method achieves 53.5\\% accuracy in identifying failure-responsible agents but only 14.2\\% in pinpointing failure steps, with some methods performing below random.  Even SOTA reasoning models, such as OpenAI o1 and DeepSeek R1, fail to achieve practical usability. These results highlight the task's complexity and the need for further research in this area. Code and dataset are available in https://github.com/mingyin1/Agents_Failure_Attribution.""}",https://openreview.net{'value': '/pdf/ff66e9a98409dd3de0dd970b8433fae8c26a3674.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=GQ6epWZqdS,{'value': 'Prediction-Aware Learning in Multi-Agent Systems'},Aymeric Capitaine; Etienne Boursier; Eric Moulines; Michael I. Jordan; Alain Oliviero Durmus,~Aymeric_Capitaine1; ~Etienne_Boursier1; ~Eric_Moulines1; ~Michael_I._Jordan2; ~Alain_Oliviero_Durmus1,"{'value': ['Learning in Games', 'Multi-agent systems', 'Online Learning', 'Equilibrium', 'Social Welfare', 'Time-varying games']}","{'value': 'The framework of uncoupled online learning in multiplayer games has made significant progress in recent years. In particular, the development of  time-varying games has considerably expanded its modeling capabilities. However, current regret bounds quickly become vacuous when the game undergoes significant variations over time, even when these variations are easy to predict. Intuitively, the ability of players to forecast future payoffs should lead to tighter guarantees, yet existing approaches fail to incorporate this aspect. This work aims to fill this gap by introducing a novel prediction-aware framework for time-varying games, where agents can forecast future payoffs and adapt their strategies accordingly. In this framework, payoffs depend on an underlying state of nature that agents predict in an online manner. To leverage these predictions, we propose the POMWU algorithm, a contextual extension of the optimistic Multiplicative Weight Update algorithm, for which we establish theoretical guarantees on social welfare and convergence to equilibrium. Our results demonstrate that, under bounded prediction errors, the proposed framework achieves performance comparable to the static setting. Finally, we empirically demonstrate the effectiveness of POMWU in a traffic routing experiment.'}",https://openreview.net{'value': '/pdf/1aa617fc600434a55e567545cd8f3f65f9ea835d.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=GHyvvWu1XC,{'value': 'Trajectory Inference with Smooth Schrödinger Bridges'},Wanli Hong; Yuliang Shi; Jonathan Niles-Weed,~Wanli_Hong1; ~Yuliang_Shi2; ~Jonathan_Niles-Weed1,"{'value': ['Trajectory Inference', 'Schrodinger Bridge', 'Message Passing', 'Probabilisitic Graphical Models']}","{'value': 'Motivated by applications in trajectory inference and particle tracking, we introduce **Smooth Schrödinger Bridges**. Our proposal generalizes prior work by allowing the reference process in the multi-marginal Schrödinger Bridge problem to be a smooth Gaussian process, leading to more regular and interpretable trajectories in applications. Though naïvely smoothing the reference process leads to a computationally intractable problem, we identify a class of processes (including the Matérn processes) for which the resulting Smooth Schrödinger Bridge problem can be *lifted* to a simpler problem on phase space, which can be solved in polynomial time. We develop a practical approximation of this algorithm that outperforms existing methods on numerous simulated and real single-cell RNAseq datasets.'}",https://openreview.net{'value': '/pdf/69a0afc7a1ba941841ddac26bc8095942e24b2b1.pdf'},{'title_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=G3grccIXIg,{'value': 'Smoothed Preference Optimization via ReNoise Inversion for Aligning Diffusion Models with Varied Human Preferences'},Yunhong Lu; Qichao Wang; Hengyuan Cao; Xiaoyin Xu; Min Zhang,~Yunhong_Lu3; ~Qichao_Wang2; ~Hengyuan_Cao1; ~Xiaoyin_Xu2; ~Min_Zhang8,"{'value': ['diffusion models', 'human preference', 'preference optimization']}","{'value': 'Direct Preference Optimization (DPO) aligns text-to-image (T2I) generation models with human preferences using pairwise preference data. Although substantial resources are expended in collecting and labeling datasets, a critical aspect is often neglected: *preferences vary across individuals and should be represented with more granularity.* To address this, we propose SmPO-Diffusion, a novel method for modeling preference distributions to improve the DPO objective, along with a numerical upper bound estimation for the diffusion optimization objective. First, we introduce a smoothed preference distribution to replace the original binary distribution. We employ a reward model to simulate human preferences and apply preference likelihood averaging to improve the DPO loss, such that the loss function approaches zero when preferences are similar. Furthermore, we utilize an inversion technique to simulate the trajectory preference distribution of the diffusion model, enabling more accurate alignment with the optimization objective. Our approach effectively mitigates issues of excessive optimization and objective misalignment present in existing methods through straightforward modifications. Experimental results demonstrate that our method achieves state-of-the-art performance in preference evaluation tasks, surpassing baselines across various metrics, while reducing the training costs.'}",https://openreview.net{'value': '/pdf/21a90834af3e7c75c15c1ea75b496c0cdfcf1c16.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=G2mAZTpJcz,{'value': 'On Explaining Equivariant Graph Networks via Improved Relevance Propagation'},Hongyi Ling; Haiyang Yu; Zhimeng Jiang; Na Zou; Shuiwang Ji,~Hongyi_Ling1; ~Haiyang_Yu6; ~Zhimeng_Jiang1; ~Na_Zou2; ~Shuiwang_Ji1,"{'value': ['equivariant GNNs', 'XAI']}","{'value': 'We consider explainability in equivariant graph neural networks for 3D geometric graphs. While many XAI methods have been developed for analyzing graph neural networks, they predominantly target 2D graph structures. The complex nature of 3D data and the sophisticated architectures of equivariant GNNs present unique challenges. Current XAI techniques either struggle to adapt to equivariant GNNs or fail to effectively handle positional data and evaluate the significance of geometric features adequately. \n  To address these challenges, we introduce a novel method, known as EquiGX, which uses the Deep Taylor decomposition framework to extend the layer-wise relevance propagation rules tailored for spherical equivariant GNNs. Our approach decomposes prediction scores and back-propagates the relevance scores through each layer to the input space. Our decomposition rules provide a detailed explanation of each layer’s contribution to the network’s predictions, thereby enhancing our understanding of how geometric and positional data influence the model’s outputs. \n  Through experiments on both synthetic and real-world datasets, our method demonstrates its capability to identify critical geometric structures and outperform alternative baselines. These results indicate that our method provides significantly enhanced explanations for equivariant GNNs. Our code has been released as part of the AIRS library (https://github.com/divelab/AIRS/).'}",https://openreview.net{'value': '/pdf/0389b811260d4d5a6a6e3d0921bc1716d41aa2d8.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=FvBYG5jA7k,{'value': 'Identifying and Understanding Cross-Class Features in Adversarial Training'},Zeming Wei; Steven Y. Guo; Yisen Wang,~Zeming_Wei1; ~Steven_Y._Guo2; ~Yisen_Wang1,"{'value': ['adversarial training', 'robust overfitting', 'feature attribution', 'training dynamics']}","{'value': 'Adversarial training (AT) has been considered one of the most effective methods for making deep neural networks robust against adversarial attacks, while the training mechanisms and dynamics of AT remain open research problems. In this paper, we present a novel perspective on studying AT through the lens of class-wise feature attribution. Specifically, we identify the impact of a key family of features on AT that are shared by multiple classes, which we call cross-class features. These features are typically useful for robust classification, which we offer theoretical evidence to illustrate through a synthetic data model. Through systematic studies across multiple model architectures and settings, we find that during the initial stage of AT, the model tends to learn more cross-class features until the best robustness checkpoint. As AT further squeezes the training robust loss and causes robust overfitting, the model tends to make decisions based on more class-specific features.  Based on these discoveries, we further provide a unified view of two existing properties of AT, including the advantage of soft-label training and robust overfitting. Overall, these insights refine the current understanding of AT mechanisms and provide new perspectives on studying them. Our code is available at https://github.com/PKU-ML/Cross-Class-Features-AT.'}",https://openreview.net{'value': '/pdf/1a3b3559a8e348528e53d42f63af89101f628423.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=Fpdx6GtAqM,{'value': 'Near-optimal Regret Using Policy Optimization in Online MDPs with Aggregate Bandit Feedback'},Tal Lancewicki; Yishay Mansour,~Tal_Lancewicki1; ~Yishay_Mansour2,"{'value': ['Online MDPs', 'Policy Optimization', 'Aggregate Bandit Feedback', 'Full-bandit feedback', 'Reinforcement Learning', 'Regret Minimization', 'Adversarial MDPs']}","{'value': 'We study online finite-horizon Markov Decision Processes with adversarially changing loss and aggregate bandit feedback (a.k.a full-bandit). Under this type of feedback, the agent observes only the total loss incurred over the entire trajectory, rather than the individual losses at each intermediate step within the trajectory. We introduce the first Policy Optimization algorithms for this setting. In the known-dynamics case, we achieve the first *optimal* regret bound of $\\tilde \\Theta(H^2\\sqrt{SAK})$, where $K$ is the number of episodes, $H$ is the episode horizon, $S$ is the number of states, and $A$ is the number of actions. In the unknown dynamics case we establish regret bound of $\\tilde O(H^3 S \\sqrt{AK})$, significantly improving the best known result by a factor of $H^2 S^5 A^2$.'}",https://openreview.net{'value': '/pdf/7fd01c879d24b453e431ebe08f053cd1df78d873.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=FgNYqzjVLg,{'value': 'Generative Intervention Models for Causal Perturbation Modeling'},Nora Schneider; Lars Lorch; Niki Kilbertus; Bernhard Schölkopf; Andreas Krause,~Nora_Schneider1; ~Lars_Lorch1; ~Niki_Kilbertus1; ~Bernhard_Schölkopf1; ~Andreas_Krause1,"{'value': ['Causality', 'Causal Inference', 'Causal Modeling', 'Interventions', 'Perturbations', 'Generalization', 'Interpretability']}","{'value': 'We consider the problem of predicting perturbation effects via causal models. In many applications, it is a priori unknown which mechanisms of a system are modified by an external perturbation, even though the features of the perturbation are available. For example, in genomics, some properties of a drug may be known, but not their causal effects on the regulatory pathways of cells. We propose a generative intervention model (GIM) that learns to map these perturbation features to distributions over atomic interventions in a jointly-estimated causal model. Contrary to prior approaches, this enables us to predict the distribution shifts of unseen perturbation features while gaining insights about their mechanistic effects in the underlying data-generating process. On synthetic data and scRNA-seq drug perturbation data, GIMs achieve robust out-of-distribution predictions on par with unstructured approaches, while effectively inferring the underlying perturbation mechanisms, often better than other causal inference methods.'}",https://openreview.net{'value': '/pdf/02b04345ed8420d14d669984c8d580c699246923.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=Fa0aFZ9LZi,{'value': 'From Pixels to Perception: Interpretable Predictions via Instance-wise Grouped Feature Selection'},Moritz Vandenhirtz; Julia E Vogt,~Moritz_Vandenhirtz1; ~Julia_E_Vogt1,"{'value': ['instance-wise feature selection', 'feature selection', 'interpretability', 'perception-adhering masking']}","{'value': ""Understanding the decision-making process of machine learning models provides valuable insights into the task, the data, and the reasons behind a model's failures. In this work, we propose a method that performs inherently interpretable predictions through the instance-wise sparsification of input images. To align the sparsification with human perception, we learn the masking in the space of semantically meaningful pixel regions rather than on pixel-level. Additionally, we introduce an explicit way to dynamically determine the required level of sparsity for each instance. We show empirically on semi-synthetic and natural image datasets that our inherently interpretable classifier produces more meaningful, human-understandable predictions than state-of-the-art benchmarks.""}",https://openreview.net{'value': '/pdf/1525877726525569d0c0535100b6a41fab964a91.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=FSlTEObdLl,{'value': 'CombiMOTS: Combinatorial Multi-Objective Tree Search for Dual-Target Molecule Generation'},Thibaud Southiratn; Bonil Koo; Yijingxiu Lu; Sun Kim,~Thibaud_Southiratn1; ~Bonil_Koo1; ~Yijingxiu_Lu1; ~Sun_Kim2,"{'value': ['Dual-target Molecule Generation', 'Fragment-based Drug Discovery', 'Monte-Carlo Tree Search', 'Pareto Optimization', 'Search Space Reduction']}","{'value': 'Dual-target molecule generation, which focuses on discovering compounds capable of interacting with two target proteins, has garnered significant attention due to its potential for improving therapeutic efficiency, safety and resistance mitigation.\nExisting approaches face two critical challenges.\nFirst, by simplifying the complex dual-target optimization problem to scalarized combinations of individual objectives, they fail to capture important trade-offs between target engagement and molecular properties. \nSecond, they typically do not integrate synthetic planning into the generative process.\nThis highlights a need for more appropriate objective function design and synthesis-aware methodologies tailored to the dual-target molecule generation task.\nIn this work, we propose CombiMOTS, a Pareto Monte Carlo Tree Search (PMCTS) framework that generates dual-target molecules.\nCombiMOTS is designed to explore a synthesizable fragment space while employing vectorized optimization constraints to encapsulate target affinity and physicochemical properties.\nExtensive experiments on real-world databases demonstrate that CombiMOTS produces novel dual-target molecules with high docking scores, enhanced diversity, and balanced pharmacological characteristics, showcasing its potential as a powerful tool for dual-target drug discovery.\nThe code and data is accessible through \\url{https://github.com/Tibogoss/CombiMOTS}.'}",https://openreview.net{'value': '/pdf/28bbf6e4e551d760dc2420b58e3e4ad675bb40d0.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=FCm4laCLiH,{'value': 'Synthesizing Privacy-Preserving Text Data via Finetuning *without* Finetuning Billion-Scale LLMs'},Bowen Tan; Zheng Xu; Eric P. Xing; Zhiting Hu; Shanshan Wu,~Bowen_Tan2; ~Zheng_Xu2; ~Eric_Xing1; ~Zhiting_Hu3; ~Shanshan_Wu1,"{'value': ['synthetic data', 'language model', 'differential privacy']}","{'value': 'Synthetic data offers a promising path to train models while preserving data privacy. Differentially private (DP) finetuning of large language models (LLMs) as data generator is effective, but is impractical when computation resources are limited. Meanwhile, prompt-based methods such as private evolution depend heavily on the manual prompts, and ineffectively use private information in their iterative data selection process. To overcome these limitations, we propose CTCL (Data Synthesis with **C**on**T**rollability and **CL**ustering), a novel framework for generating privacy-preserving synthetic data without extensive prompt engineering or billion-scale LLM finetuning. CTCL pretrains a lightweight 140M conditional generator and a  clustering-based topic model on large-scale public data. To further adapt to the private domain, the generator is DP finetuned on private data for fine-grained textual information, while the topic model extracts a DP histogram representing distributional information. The DP generator then samples according to the DP histogram to synthesize a desired number of data examples. Evaluation across five diverse domains demonstrates the effectiveness of our framework, particularly in the strong privacy regime. Systematic ablation validates the design of each framework component and highlights the scalability of our approach.'}",https://openreview.net{'value': '/pdf/548113d0b2933b3152d762217356337791546a95.pdf'},{'abstract_filter': 'Data Synthesis'},ICML.cc,2025,Conference
https://openreview.net/forum?id=FCZ3jVzmTZ,{'value': 'Idiosyncrasies in Large Language Models'},Mingjie Sun; Yida Yin; Zhiqiu Xu; J Zico Kolter; Zhuang Liu,~Mingjie_Sun1; ~Yida_Yin1; ~Zhiqiu_Xu1; ~J_Zico_Kolter1; ~Zhuang_Liu1,{'value': ['Large Language Models; Idiosyncrasies; Dataset bias; Synthetic data;']},"{'value': ""In this work, we unveil and study idiosyncrasies in Large Language Models (LLMs) -- unique patterns in their outputs that can be used to distinguish the models. To do so, we consider a simple classification task: given a particular text output, the objective is to predict the source LLM that generates the text. We evaluate this synthetic task across various groups of LLMs and find that simply fine-tuning text embedding models on LLM-generated texts yields excellent classification accuracy. Notably, we achieve 97.1\\% accuracy on held-out validation data in the five-way classification problem involving ChatGPT, Claude, Grok, Gemini, and DeepSeek. Our further investigation reveals that these idiosyncrasies are rooted in word-level distributions. These patterns persist even when the texts are rewritten, translated, or summarized by an external LLM, suggesting that they are also encoded in the semantic content. Additionally, we leverage LLM as judges to generate detailed, open-ended descriptions of each model's idiosyncrasies. Finally, we discuss the broader implications of our findings, including training on synthetic data, inferring model similarity, and robust evaluation of LLMs.""}",https://openreview.net{'value': '/pdf/80852be297c8f0457f76e850b9dcf6926f3723ad.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=F0sinjQMnv,{'value': 'Identifying Causal Direction via Variational Bayesian Compression'},Quang-Duy Tran; Bao Duong; Phuoc Nguyen; Thin Nguyen,~Quang-Duy_Tran1; ~Bao_Duong1; ~Phuoc_Nguyen3; ~Thin_Nguyen1,"{'value': ['causal discovery', 'neural networks', 'variational Bayesian code']}","{'value': 'Telling apart the cause and effect between two random variables with purely observational data is a challenging problem that finds applications in various scientific disciplines. A key principle utilized in this task is the algorithmic Markov condition, which postulates that the joint distribution, when factorized according to the causal direction, yields a more succinct codelength compared to the anti-causal direction. Previous approaches approximate these codelengths by relying on simple functions or Gaussian processes (GPs) with easily evaluable complexity, compromising between model fitness and computational complexity. To address these limitations, we propose leveraging the variational Bayesian learning of neural networks as an interpretation of the codelengths. This allows the improvement of model fitness, while maintaining the succinctness of the codelengths, and the avoidance of the significant computational complexity of the GP-based approaches. Extensive experiments on both synthetic and real-world benchmarks in cause-effect identification demonstrate the effectiveness of our proposed method, showing promising performance enhancements on several datasets in comparison to most related methods.'}",https://openreview.net{'value': '/pdf/5a26deb73b81e67499d6762ecb6895e29f1b73a4.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=EscpGI2XAx,{'value': 'Online Clustering of Dueling Bandits'},Zhiyong Wang; Jiahang Sun; Mingze Kong; Jize Xie; Qinghua Hu; John C.S. Lui; Zhongxiang Dai,~Zhiyong_Wang9; ~Jiahang_Sun1; ~Mingze_Kong1; ~Jize_Xie1; ~Qinghua_Hu1; ~John_C.S._Lui2; ~Zhongxiang_Dai1,"{'value': ['Multi-armed bandits', 'dueling bandits', 'clustering of bandits']}","{'value': 'The contextual multi-armed bandit (MAB) is a widely used framework for problems requiring sequential decision-making under uncertainty, such as recommendation systems. In applications involving a large number of users, the performance of contextual MAB can be significantly improved by facilitating collaboration among multiple users. This has been achieved by the clustering of bandits (CB) methods, which adaptively group the users into different clusters and achieve collaboration by allowing the users in the same cluster to share data. However, classical CB algorithms typically rely on numerical reward feedback, which may not be practical in certain real-world applications.  For instance, in recommendation systems, it is more realistic and reliable to solicit preference feedback between pairs of recommended items rather than absolute rewards. To address this limitation, we introduce the first ""clustering of dueling bandit algorithms"" to enable collaborative decision-making based on preference feedback. We propose two novel algorithms: (1) Clustering of Linear Dueling Bandits (COLDB) which models the user reward functions as linear functions of the context vectors, and (2) Clustering of Neural Dueling Bandits (CONDB) which uses a neural network to model complex, non-linear user reward functions. Both algorithms are supported by rigorous theoretical analyses, demonstrating that user collaboration leads to improved regret bounds. Extensive empirical evaluations on synthetic and real-world datasets further validate the effectiveness of our methods, establishing their potential in real-world applications involving multiple users with preference-based feedback.'}",https://openreview.net{'value': '/pdf/b448140249947dcf10c58430a92b7624a17d3bcd.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=EhStXG4dCS,{'value': 'Wrapped Gaussian on the manifold of Symmetric Positive Definite Matrices'},Thibault de Surrel; Fabien Lotte; Sylvain Chevallier; Florian Yger,~Thibault_de_Surrel1; ~Fabien_Lotte1; ~Sylvain_Chevallier1; ~Florian_Yger1,"{'value': ['Gaussian distribution', 'Wrapped distributions', 'Symmetric positive definite matrices', 'estimation', 'classification', 'Riemannian geometry', 'density estimation']}","{'value': 'Circular and non-flat data distribution are prevalent across diverse domains of data science, yet their specific geometric structures often remain underutilized in machine learning frameworks.\nA principled approach to accounting for the underlying geometry of such data is pivotal, particularly when extending statistical models, like the pervasive Gaussian distribution.\nIn this work, we tackle those issue by focusing on the manifold of symmetric positive definite matrices, a key focus in information geometry.\nWe introduced a non-isotropic wrapped Gaussian by leveraging the exponential map, we derive theoretical properties of this distribution and propose a maximum likelihood framework for parameter estimation. Furthermore, we reinterpret established classifiers on SPD through a probabilistic lens and introduce new classifiers based on the wrapped Gaussian model.\nExperiments on synthetic and real-world datasets demonstrate the robustness and flexibility of this geometry-aware distribution, underscoring its potential to advance manifold-based data analysis.\nThis work lays the groundwork for extending classical machine learning and statistical methods to more complex and structured data.'}",https://openreview.net{'value': '/pdf/f143a56361b0be4e9b1f7d51a66ef8e235787d65.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=EY6pXIDi3G,{'value': 'Learning-Order Autoregressive Models with Application to Molecular Graph Generation'},Zhe Wang; Jiaxin Shi; Nicolas Heess; Arthur Gretton; Michalis Titsias,~Zhe_Wang13; ~Jiaxin_Shi1; ~Nicolas_Heess1; ~Arthur_Gretton1; ~Michalis_Titsias1,"{'value': ['Generative Modeling', 'Variational Inference', 'Autoregressive Model', 'Graph Generation', 'Molecule Generation']}","{'value': 'Autoregressive models (ARMs) have become the workhorse for sequence generation tasks, since many problems can be modeled as next-token prediction. While there appears to be a natural ordering for text (i.e., left-to-right), for many data types, such as graphs, the canonical ordering is less obvious. To address this problem, we introduce a variant of ARM that generates high-dimensional data using a probabilistic ordering that is sequentially inferred from data. This model incorporates a trainable probability distribution, referred to as an order-policy, that dynamically decides the autoregressive order in a state-dependent manner. To train the model, we introduce a variational lower bound on the exact log-likelihood, which we optimize with stochastic gradient estimation. We demonstrate experimentally that our method can learn meaningful autoregressive orderings in image and graph generation. On the challenging domain of molecular graph generation, we achieve state-of-the-art results on the QM9 and ZINC250k benchmarks, evaluated using the Fréchet ChemNet Distance (FCD), Synthetic Accessibility Score (SAS), Quantitative Estimate of Drug-likeness (QED).'}",https://openreview.net{'value': '/pdf/0d2d853d7b7b99ef4101e0c3a42b18436c2c9700.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=EXds2NBOoq,{'value': 'Posterior Inference with Diffusion Models for High-dimensional Black-box Optimization'},Taeyoung Yun; Kiyoung Om; Jaewoo Lee; Sujin Yun; Jinkyoo Park,~Taeyoung_Yun1; ~Kiyoung_Om1; ~Jaewoo_Lee3; ~Sujin_Yun1; ~Jinkyoo_Park1,"{'value': ['Diffusion Models', 'Posterior Inference', 'High-dimensional Black-box Optimization']}","{'value': 'Optimizing high-dimensional and complex black-box functions is crucial in numerous scientific applications.\nWhile Bayesian optimization (BO) is a powerful method for sample-efficient optimization, it struggles with the curse of dimensionality and scaling to thousands of evaluations. \nRecently, leveraging generative models to solve black-box optimization problems has emerged as a promising framework.\nHowever, those methods often underperform compared to BO methods due to limited expressivity and difficulty of uncertainty estimation in high-dimensional spaces.\nTo overcome these issues, we introduce \\textbf{DiBO}, a novel framework for solving high-dimensional black-box optimization problems.\nOur method iterates two stages. First, we train a diffusion model to capture the data distribution and deep ensembles to predict function values with uncertainty quantification.\nSecond, we cast the candidate selection as a posterior inference problem to balance exploration and exploitation in high-dimensional spaces. Concretely, we fine-tune diffusion models to amortize posterior inference.\nExtensive experiments demonstrate that our method outperforms state-of-the-art baselines across synthetic and real-world tasks. Our code is publicly available \\href{https://github.com/umkiyoung/DiBO}{here}.'}",https://openreview.net{'value': '/pdf/bce3f090d33239284acf4acbd531c7e768c50f06.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=EVwMw2lVlw,{'value': 'SK-VQA: Synthetic Knowledge Generation at Scale for Training Context-Augmented Multimodal LLMs'},Xin Su; Man Luo; Kris W Pan; Tien Pei Chou; Vasudev Lal; Phillip Howard,~Xin_Su2; ~Man_Luo2; ~Kris_W_Pan1; ~Tien_Pei_Chou1; ~Vasudev_Lal1; ~Phillip_Howard1,"{'value': ['Multimodal', 'retrieval augmented generation', 'data generation']}","{'value': 'Multimodal retrieval-augmented generation (RAG) plays a crucial role in domains such as knowledge-based visual question answering (KB-VQA), where models should effectively integrate additional knowledge to generate a response. However, existing vision and language models (VLMs) are not inherently designed for context-augmented generation, limiting their effectiveness in such tasks. While synthetic data generation has recently gained attention for training large VLMs, its application for context-augmented generation remains underexplored. To address this gap, we introduce SKVQA, a large-scale synthetic multimodal dataset containing over 2 million visual question-answer pairs, each associated with external knowledge sources to determine the final answer. Compared to previous datasets, SKVQA exhibits 11× more unique questions, greater domain diversity, and a broader spectrum of image sources. Through human evaluations, we confirm the high quality of the generated question-answer pairs and their contextual relevance. Extensive experiments show that SKVQA serves both as a challenging benchmark for knowledge-based VQA and as an effective training resource for adapting generative multimodal models to context-augmented generation. Our results further indicate that models trained on SKVQA demonstrate enhanced generalization in both context-aware VQA and multimodal RAG settings.'}",https://openreview.net{'value': '/pdf/88652df237833e0ec6593b18c2796026898f4c8f.pdf'},{'title_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=ETIsFhZwhJ,{'value': 'Unbiased Evaluation of Large Language Models from a Causal Perspective'},Meilin Chen; Jian Tian; Liang Ma; Di Xie; Weijie Chen; Jiang Zhu,~Meilin_Chen1; ~Jian_Tian1; ~Liang_Ma2; ~Di_Xie1; ~Weijie_Chen1; ~Jiang_Zhu3,"{'value': ['Agents-as-an-Evaluator', 'LLM Evaluation', 'Evaluation Bias']}","{'value': 'Benchmark contamination has become a significant concern in the LLM evaluation community. Previous Agents-as-an-Evaluator address this issue by involving agents in the generation of questions. Despite their success, the biases in Agents-as-an-Evaluator methods remain largely unexplored. In this paper, we present a theoretical formulation of evaluation bias, providing valuable insights into designing unbiased evaluation protocols. Furthermore, we identify two type of bias in Agents-as-an-Evaluator through carefully designed probing tasks on a minimal Agents-as-an-Evaluator setup. To address these issues, we propose the Unbiased Evaluator, an evaluation protocol that delivers a more comprehensive, unbiased, and interpretable assessment of LLMs. Extensive experiments reveal significant room for improvement in current LLMs. Additionally, we demonstrate that the Unbiased Evaluator not only offers strong evidence of benchmark contamination but also provides interpretable evaluation results.'}",https://openreview.net{'value': '/pdf/c81da8f83ab232b5ab62827cc8eabb1c3a3ea3e0.pdf'},{'abstract_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=ERU7QgD6gc,{'value': 'Can Diffusion Models Learn Hidden Inter-Feature Rules Behind Images?'},Yujin Han; Andi Han; Wei Huang; Chaochao Lu; Difan Zou,~Yujin_Han1; ~Andi_Han1; ~Wei_Huang6; ~Chaochao_Lu1; ~Difan_Zou1,"{'value': ['Diffusion Model', 'Deep Generative Model']}","{'value': ""Despite the remarkable success of diffusion models (DMs) in data generation, they exhibit specific failure cases with unsatisfactory outputs. We focus on one such limitation: the ability of DMs to learn hidden rules between image features. Specifically, for image data with dependent features ($\\mathbf{x}$) and ($\\mathbf{y}$) (e.g., the height of the sun ($\\mathbf{x}$) and the length of the shadow ($\\mathbf{y}$)), we investigate whether DMs can accurately capture the inter-feature rule ($p(\\mathbf{y}|\\mathbf{x})$). Empirical evaluations on mainstream DMs (e.g., Stable Diffusion 3.5) reveal consistent failures, such as inconsistent lighting-shadow relationships and mismatched object-mirror reflections. Inspired by these findings, we design four synthetic tasks with strongly correlated features to assess DMs' rule-learning abilities. Extensive experiments show that while DMs can identify coarse-grained rules, they struggle with fine-grained ones. Our theoretical analysis demonstrates that DMs trained via denoising score matching (DSM) exhibit constant errors in learning hidden rules, as the DSM objective is not compatible with rule conformity. To mitigate this, we introduce a common technique - incorporating additional classifier guidance during sampling, which achieves (limited) improvements. Our analysis reveals that the subtle signals of fine-grained rules are challenging for the classifier to capture, providing insights for future exploration.""}",https://openreview.net{'value': '/pdf/069dfc1e42a40b21762178bb3698973e69b8fdd9.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=EHG5Iv1mmb,{'value': 'Local Manifold Approximation and Projection for Manifold-Aware Diffusion Planning'},Kyowoon Lee; Jaesik Choi,~Kyowoon_Lee1; ~Jaesik_Choi1,"{'value': ['Offline Reinforcement Learning', 'Trajectory Optimization', 'Diffusion Models', 'Sequential Decision Making']}","{'value': 'Recent advances in diffusion-based generative modeling have demonstrated significant promise in tackling long-horizon, sparse-reward tasks by leveraging offline datasets. While these approaches have achieved promising results, their reliability remains inconsistent due to the inherent stochastic risk of producing infeasible trajectories, limiting their applicability in safety-critical applications. We identify that the primary cause of these failures is inaccurate guidance during the sampling procedure, and demonstrate the existence of manifold deviation by deriving a lower bound on the guidance gap. To address this challenge, we propose *Local Manifold Approximation and Projection* (LoMAP), a *training-free* method that projects the guided sample onto a low-rank subspace approximated from offline datasets, preventing infeasible trajectory generation. We validate our approach on standard offline reinforcement learning benchmarks that involve challenging long-horizon planning. Furthermore, we show that, as a standalone module, LoMAP can be incorporated into the hierarchical diffusion planner, providing further performance enhancements.'}",https://openreview.net{'value': '/pdf/afaa0b7c332be94f19504a08ed1ab531dcc9454e.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=EGpueKe6TP,{'value': 'Causality-Aware Contrastive Learning for Robust Multivariate Time-Series Anomaly Detection'},HyunGi Kim; Jisoo Mok; Dongjun Lee; Jaihyun Lew; Sungjae Kim; Sungroh Yoon,~HyunGi_Kim1; ~Jisoo_Mok1; ~Dongjun_Lee5; ~Jaihyun_Lew1; ~Sungjae_Kim3; ~Sungroh_Yoon1,"{'value': ['Multivarite Time Series Anomaly Detection', 'Time Series', 'Contrastive Learning', 'Causality', 'One-class Classification']}","{'value': 'Utilizing the complex inter-variable causal relationships within multivariate time-series provides a promising avenue toward more robust and reliable multivariate time-series anomaly detection (MTSAD) but remains an underexplored area of research. This paper proposes Causality-Aware contrastive learning for RObust multivariate Time-Series (CAROTS), a novel MTSAD pipeline that incorporates the notion of causality into contrastive learning. CAROTS employs two data augmentors to obtain causality-preserving and -disturbing samples that serve as a wide range of normal variations and synthetic anomalies, respectively. With causality-preserving and -disturbing samples as positives and negatives, CAROTS performs contrastive learning to train an encoder whose latent space separates normal and abnormal samples based on causality. Moreover, CAROTS introduces a similarity-filtered one-class contrastive loss that encourages the contrastive learning process to gradually incorporate more semantically diverse samples with common causal relationships. Extensive experiments on five real-world and two synthetic datasets validate that the integration of causal relationships endows CAROTS with improved MTSAD capabilities. The code is available at https://github.com/kimanki/CAROTS.'}",https://openreview.net{'value': '/pdf/c95c49f95e3a09a85b3d8ee2ae1757fcab548a35.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=EFLPHl5RGJ,{'value': 'Differentially Private Federated $k$-Means Clustering with Server-Side Data'},Jonathan Scott; Christoph H. Lampert; David Saulpic,~Jonathan_Scott1; ~Christoph_H._Lampert6; ~David_Saulpic1,"{'value': ['Federated Learning', 'k-Means Clustering', 'Differential Privacy']}","{'value': 'Clustering is a cornerstone of data analysis that is particularly suited to identifying coherent subgroups or substructures in unlabeled data, as are generated continuously in large amounts these days. However, in many cases traditional clustering methods are not applicable, because data are increasingly being produced and stored in a distributed way, e.g. on edge devices, and privacy concerns prevent it from being transferred to a central server. To address this challenge, we present FedDP-KMeans, a new algorithm for $k$-means clustering that is fully-federated as well as differentially private. Our approach leverages (potentially small and out-of-distribution) server-side data to overcome the primary challenge of differentially private clustering methods: the need for a good initialization. Combining our initialization with a simple federated DP-Lloyds algorithm we obtain an algorithm that achieves excellent results on synthetic and real-world benchmark tasks. We also provide a theoretical analysis of our method that provides bounds on the convergence speed and cluster identification success.'}",https://openreview.net{'value': '/pdf/7062deb6bb9980b4bd4b1352d0221edfe6e9835b.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=Dqp6IMI3gQ,{'value': 'When Will It Fail?: Anomaly to Prompt for Forecasting Future Anomalies in Time Series'},Min-Yeong Park; Won-Jeong Lee; Seong Tae Kim; Gyeong-Moon Park,~Min-Yeong_Park1; ~Won-Jeong_Lee1; ~Seong_Tae_Kim1; ~Gyeong-Moon_Park1,"{'value': ['Time series forecasting', 'time series anomaly detection']}","{'value': 'Recently, forecasting future abnormal events has emerged as an important scenario to tackle realworld necessities. However, the solution of predicting specific future time points when anomalies will occur, known as Anomaly Prediction (AP), remains under-explored. Existing methods dealing with time series data fail in AP, focusing only on immediate anomalies or failing to provide precise predictions for future anomalies. To address AP, we propose a novel framework called Anomaly to Prompt (A2P), comprised of Anomaly-Aware Forecasting (AAF) and Synthetic Anomaly Prompting (SAP). To enable the forecasting model to forecast abnormal time points, we adopt a strategy to learn the relationships of anomalies. For the robust detection of anomalies, our proposed SAP introduces a learnable Anomaly Prompt Pool (APP) that simulates diverse anomaly patterns using signal-adaptive prompt. Comprehensive experiments on multiple real-world datasets demonstrate the superiority of A2P over state-of-the-art methods, showcasing its ability to predict future anomalies.'}",https://openreview.net{'value': '/pdf/4a719cd370dbee97e8a4d985b1b58bfa27ba71a6.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=DqlN1yFyxN,{'value': 'Distributionally Robust Multi-Agent Reinforcement Learning for Dynamic Chute Mapping'},Guangyi Liu; Suzan Iloglu; Michael Caldara; Joseph W Durham; Michael M. Zavlanos,~Guangyi_Liu5; ~Suzan_Iloglu1; ~Michael_Caldara1; ~Joseph_W_Durham1; ~Michael_M._Zavlanos2,"{'value': ['Distributionally Robust Reinforcement Learning', 'Multi-agent Reinforcement Learning', 'Group Distributionally Robust Optimization', 'Robotic Sortation Warehouse']}","{'value': 'In Amazon robotic warehouses, the destination-to-chute mapping problem is crucial for efficient package sorting. Often, however, this problem is complicated by uncertain and dynamic package induction rates, which can lead to increased package recirculation. To tackle this challenge, we introduce a Distributionally Robust Multi-Agent Reinforcement Learning (DRMARL) framework that learns a destination-to-chute mapping policy that is resilient to adversarial variations in induction rates. Specifically, DRMARL relies on group distributionally robust optimization (DRO) to learn a policy that performs well not only on average but also on each individual subpopulation of induction rates within the group that capture, for example, different seasonality or operation modes of the system. This approach is then combined with a novel contextual bandit-based estimator of the worst-case induction distribution for each state-action pair, significantly reducing the cost of exploration and thereby increasing the learning efficiency and scalability of our framework. Extensive simulations demonstrate that DRMARL achieves robust chute mapping in the presence of varying induction distributions, reducing package recirculation by an average of 80% in the simulation scenario.'}",https://openreview.net{'value': '/pdf/01c14cc5a48785546cc056d4a8383d7afc94fd36.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=DpPUIOPY7C,{'value': 'Inverse Flow and Consistency Models'},Yuchen Zhang; Jian Zhou,~Yuchen_Zhang14; ~Jian_Zhou4,"{'value': ['consistency models', 'flow matching', 'diffusion models', 'inverse problem']}","{'value': ""Inverse generation problems, such as denoising without ground truth observations, is a critical challenge in many scientific inquiries and real-world applications. While recent advances in generative models like diffusion models, conditional flow matching, and consistency models achieved impressive results by casting generation as denoising problems, they cannot be directly used for inverse generation without access to clean data. Here we introduce Inverse Flow (IF), a novel framework that enables using these generative models for inverse generation problems including denoising without ground truth. Inverse Flow can be flexibly applied to nearly any continuous noise distribution and allows complex dependencies. We propose two algorithms for learning Inverse Flows, Inverse Flow Matching (IFM) and Inverse Consistency Model (ICM). Notably, to derive the computationally efficient, simulation-free inverse consistency model objective, we generalized consistency training to any forward diffusion processes or conditional flows, which have applications beyond denoising. We demonstrate the effectiveness of IF on synthetic and real datasets, outperforming prior approaches while enabling noise distributions that previous methods cannot support. Finally, we showcase applications of our techniques to fluorescence microscopy and single-cell genomics data, highlighting IF's utility in scientific problems. Overall, this work expands the applications of powerful generative models to inversion generation problems.""}",https://openreview.net{'value': '/pdf/81cbfa0a78a8f90f6143fe662dc704ae42a88793.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=DoaqUv7YQy,{'value': 'Provable Maximum Entropy Manifold Exploration via Diffusion Models'},Riccardo De Santi; Marin Vlastelica; Ya-Ping Hsieh; Zebang Shen; Niao He; Andreas Krause,~Riccardo_De_Santi1; ~Marin_Vlastelica1; ~Ya-Ping_Hsieh1; ~Zebang_Shen1; ~Niao_He3; ~Andreas_Krause1,"{'value': ['diffusion models', 'exploration', 'fine-tuning', 'maximum state entropy reinforcement learning']}","{'value': 'Exploration is critical for solving real-world decision-making problems such as scientific discovery, where the objective is to generate truly novel designs rather than mimic existing data distributions.  In this work, we address the challenge of leveraging the representational power of generative models for exploration without relying on explicit uncertainty quantification. We introduce a novel framework that casts exploration as entropy maximization over the approximate data manifold implicitly defined by a pre-trained diffusion model. Then, we present a novel principle for exploration based on density estimation, a problem well-known to be challenging in practice. To overcome this issue and render this method truly scalable, we leverage a fundamental connection between the entropy of the density induced by a diffusion model and its score function. Building on this, we develop an algorithm based on mirror descent that solves the exploration problem as sequential fine-tuning of a pre-trained diffusion model. We prove its convergence to the optimal exploratory diffusion model under realistic assumptions by leveraging recent understanding of mirror flows. Finally, we empirically evaluate our approach on both synthetic and high-dimensional text-to-image diffusion, demonstrating promising results.'}",https://openreview.net{'value': '/pdf/e089376992cedf22b8e64c02ab9936b95adbd5e8.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=DoDXFkF10S,{'value': 'Enforcing Latent Euclidean Geometry in Single-Cell VAEs for Manifold Interpolation'},Alessandro Palma; Sergei Rybakov; Leon Hetzel; Stephan Günnemann; Fabian J Theis,~Alessandro_Palma1; ~Sergei_Rybakov1; ~Leon_Hetzel1; ~Stephan_Günnemann1; ~Fabian_J_Theis1,"{'value': ['scRNA-seq', 'Riemannian geometry', 'representation learning', 'trajectory inference', 'VAEs', 'statistical manifolds']}","{'value': 'Latent space interpolations are a powerful tool for navigating deep generative models in applied settings. An example is single-cell RNA sequencing, where existing methods model cellular state transitions as latent space interpolations with variational autoencoders, often assuming linear shifts and Euclidean geometry. However, unless explicitly enforced, linear interpolations in the latent space may not correspond to geodesic paths on the data manifold, limiting methods that assume Euclidean geometry in the data representations. We introduce FlatVI, a novel training framework that regularises the latent manifold of discrete-likelihood variational autoencoders towards Euclidean geometry, specifically tailored for modelling single-cell count data. By encouraging straight lines in the latent space to approximate geodesic interpolations on the decoded single-cell manifold, FlatVI enhances compatibility with downstream approaches that assume Euclidean latent geometry. Experiments on synthetic data support the theoretical soundness of our approach, while applications to time-resolved single-cell RNA sequencing data demonstrate improved trajectory reconstruction and manifold interpolation.'}",https://openreview.net{'value': '/pdf/e885ada63810802939e93974c6d1852d021eb5e8.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=DkRYImuQA9,{'value': 'ShieldAgent: Shielding Agents via Verifiable Safety Policy Reasoning'},Zhaorun Chen; Mintong Kang; Bo Li,~Zhaorun_Chen1; ~Mintong_Kang1; ~Bo_Li19,"{'value': ['LLM Agent Safety', 'LLM Guardrail Agent', 'Policy Compliance', 'Automated Logic Reasoning']}","{'value': 'Autonomous agents powered by foundation models have seen widespread adoption across various real-world applications. However, they remain highly vulnerable to malicious instructions and attacks, which can result in severe consequences such as privacy breaches and financial losses. More critically, existing guardrails for LLMs are not applicable due to the complex and dynamic nature of agents. To tackle these challenges, we propose ShieldAgent, the first guardrail agent designed to enforce explicit safety policy compliance for the action trajectory of other protected agents through logical reasoning. Specifically, ShieldAgent first constructs a safety policy model by extracting verifiable rules from policy documents and structuring them into a set of action-based probabilistic rule circuits. Given the action trajectory of the protected agent, ShieldAgent retrieves relevant rule circuits and generates a shielding plan, leveraging its comprehensive tool library and executable code for formal verification. In addition, given the lack of guardrail benchmarks for agents, we introduce ShieldAgent-Bench, a dataset with 3K safety-related pairs of agent instructions and action trajectories, collected via SOTA attacks across 6 web environments and 7 risk categories. Experiments show that ShieldAgent achieves SOTA on ShieldAgent-Bench and three existing benchmarks, outperforming prior methods by 11.3% on average with a high recall of 90.1%. Additionally, ShieldAgent reduces API queries by 64.7% and inference time by 58.2%, demonstrating its high precision and efficiency in safeguarding agents. Our project is available and continuously maintained here: https://shieldagent-aiguard.github.io/'}",https://openreview.net{'value': '/pdf/1ae6319c6cf2bf1431d1dc17567be53632f6966e.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=DiqeZY27XK,{'value': 'Knowledge Retention in Continual Model-Based Reinforcement Learning'},Haotian Fu; Yixiang Sun; Michael Littman; George Konidaris,~Haotian_Fu3; ~Yixiang_Sun2; ~Michael_Littman1; ~George_Konidaris1,"{'value': ['Deep Reinforcement learning', 'Model-based Reinforcement Learning', 'Continual Learning', 'World Models']}","{'value': 'We propose DRAGO, a novel approach for continual model-based reinforcement learning aimed at improving the incremental development of world models across a sequence of tasks that differ in their reward functions but not the state space or dynamics. DRAGO comprises two key components: *Synthetic Experience Rehearsal*, which leverages generative models to create synthetic experiences from past tasks, allowing the agent to reinforce previously learned dynamics without storing data, and *Regaining Memories Through Exploration*, which introduces an intrinsic reward mechanism to guide the agent toward revisiting relevant states from prior tasks. Together, these components enable the agent to maintain a comprehensive and continually developing world model, facilitating more effective learning and adaptation across diverse environments. Empirical evaluations demonstrate that DRAGO is able to preserve knowledge across tasks, achieving superior performance in various continual learning scenarios.'}",https://openreview.net{'value': '/pdf/3ec75dcbe369d83d0f96b50dad3da194571c1555.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=DgGF2LEBPS,{'value': 'EmbodiedBench: Comprehensive Benchmarking Multi-modal Large Language Models for Vision-Driven Embodied Agents'},Rui Yang; Hanyang Chen; Junyu Zhang; Mark Zhao; Cheng Qian; Kangrui Wang; Qineng Wang; Teja Venkat Koripella; Marziyeh Movahedi; Manling Li; Heng Ji; Huan Zhang; Tong Zhang,~Rui_Yang8; ~Hanyang_Chen3; ~Junyu_Zhang3; ~Mark_Zhao2; ~Cheng_Qian4; ~Kangrui_Wang2; ~Qineng_Wang1; ~Teja_Venkat_Koripella1; ~Marziyeh_Movahedi1; ~Manling_Li1; ~Heng_Ji3; ~Huan_Zhang1; ~Tong_Zhang2,"{'value': ['Embodied Agent', 'Multi-modal Large Language Models']}","{'value': 'Leveraging Multi-modal Large Language Models (MLLMs) to create embodied agents offers a promising avenue for tackling real-world tasks. While language-centric embodied agents have garnered substantial attention, MLLM-based embodied agents remain underexplored due to the lack of comprehensive evaluation frameworks. To bridge this gap, we introduce EmbodiedBench, an extensive benchmark designed to evaluate vision-driven embodied agents.\nEmbodiedBench features: (1) a diverse set of 1,128 testing tasks across four environments, ranging from high-level semantic tasks (e.g., household) to low-level tasks involving atomic actions (e.g., navigation and manipulation); and (2) six meticulously curated subsets evaluating essential agent capabilities like commonsense reasoning, complex instruction understanding, spatial awareness, visual perception, and long-term planning.\nThrough extensive experiments, we evaluated 24 leading proprietary and open-source MLLMs within EmbodiedBench. Our findings reveal that: MLLMs excel at high-level tasks but struggle with low-level manipulation, with the best model, GPT-4o, scoring only $28.9\\\\%$ on average. EmbodiedBench provides a multifaceted standardized evaluation platform that not only highlights existing challenges but also offers valuable insights to advance MLLM-based embodied agents. Our code and dataset are available at [https://embodiedbench.github.io](https://embodiedbench.github.io).'}",https://openreview.net{'value': '/pdf/b9e775a028b2a809c09d3c36562f179b9cac55a4.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=DYeVXcPsN6,{'value': 'BARK: A Fully Bayesian Tree Kernel for Black-box Optimization'},Toby Boyne; Jose Pablo Folch; Robert Matthew Lee; Behrang Shafei; Ruth Misener,~Toby_Boyne1; ~Jose_Pablo_Folch1; ~Robert_Matthew_Lee1; ~Behrang_Shafei1; ~Ruth_Misener1,"{'value': ['Bayesian optimization', 'tree kernels', 'Bayesian additive regression trees', 'Gaussian processes']}","{'value': 'We perform Bayesian optimization using a Gaussian process perspective on Bayesian Additive Regression Trees (BART). Our BART Kernel (BARK) uses tree agreement to define a posterior over piecewise-constant functions, and we explore the space of tree kernels using a Markov chain Monte Carlo approach. Where BART only samples functions, the resulting BARK model obtains samples of Gaussian processes defining distributions over functions, which allow us to build acquisition functions for Bayesian optimization. Our tree-based approach enables global optimization over the surrogate, even for mixed-feature spaces. Moreover, where many previous tree-based kernels provide uncertainty quantification over function values, our sampling scheme captures uncertainty over the tree structure itself. Our experiments show the strong performance of BARK on both synthetic and applied benchmarks, due to the combination of our fully Bayesian surrogate and the optimization procedure.'}",https://openreview.net{'value': '/pdf/0539c211f7e3c9f7483555bc48c6f222b80bb53c.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=DMJ3b19RAJ,{'value': 'Measuring Diversity in Synthetic Datasets'},Yuchang Zhu; Huizhe Zhang; Bingzhe Wu; Jintang Li; Zibin Zheng; Peilin Zhao; Liang Chen; Yatao Bian,~Yuchang_Zhu1; ~Huizhe_Zhang1; ~Bingzhe_Wu1; ~Jintang_Li1; ~Zibin_Zheng1; ~Peilin_Zhao2; ~Liang_Chen17; ~Yatao_Bian1,"{'value': ['diversity evaluation', 'synthetic data', 'LLMs']}","{'value': 'Large language models (LLMs) are widely adopted to generate synthetic datasets for various natural language processing (NLP) tasks, such as text classification and summarization. However, accurately measuring the diversity of these synthetic datasets—an aspect crucial for robust model performance—remains a significant challenge. In this paper, we introduce DCScore, a novel method for measuring synthetic dataset diversity from a classification perspective. Specifically, DCScore formulates diversity evaluation as a sample classification task, leveraging mutual relationships among samples. We further provide theoretical verification of the diversity-related axioms satisfied by DCScore, highlighting its role as a principled diversity evaluation method. Experimental results on synthetic datasets reveal that DCScore enjoys a stronger correlation with multiple diversity pseudo-truths of evaluated datasets, underscoring its effectiveness. Moreover, both empirical and theoretical evidence demonstrate that DCScore substantially reduces computational costs compared to existing methods. Code is available at: https://github.com/bluewhalelab/dcscore.'}",https://openreview.net{'value': '/pdf/18d5c7c184190bac102ab5098cd71717a3fb9a75.pdf'},{'title_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=Cq7XU5tmP8,{'value': 'Conformal Anomaly Detection in Event Sequences'},Shuai Zhang; Chuan Zhou; Yang Liu; Peng Zhang; Xixun Lin; Shirui Pan,~Shuai_Zhang23; ~Chuan_Zhou3; ~Yang_Liu104; ~Peng_Zhang55; ~Xixun_Lin3; ~Shirui_Pan1,"{'value': ['Conformal Inference', 'Anomaly Detection', 'Event Sequence', 'Temporal Point Process']}","{'value': 'Anomaly detection in continuous-time event sequences is a crucial task in safety-critical applications. While existing methods primarily focus on developing a superior test statistic, they fail to provide guarantees regarding the false positive rate (FPR), which undermines their reliability in practical deployments. In this paper, we propose CADES (Conformal Anomaly Detection in Event Sequences), a novel test procedure based on conformal inference for the studied task with finite-sample FPR control. Specifically, by using the time-rescaling theorem, we design two powerful non-conformity scores tailored to event sequences, which exhibit complementary sensitivities to different abnormal patterns. CADES combines these scores with Bonferroni correction to leverage their respective strengths and addresses non-identifiability issues of existing methods. Theoretically, we prove the validity of CADES and further provide strong guarantees on calibration-conditional FPR control. Experimental results on synthetic and real-world datasets, covering various types of anomalies, demonstrate that CADES outperforms state-of-the-art methods while maintaining FPR control.'}",https://openreview.net{'value': '/pdf/e38cead0049725b1735fd94806d6c816619f6822.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=Cq1BNvHx74,{'value': 'Training Software Engineering Agents and Verifiers with SWE-Gym'},Jiayi Pan; Xingyao Wang; Graham Neubig; Navdeep Jaitly; Heng Ji; Alane Suhr; Yizhe Zhang,~Jiayi_Pan1; ~Xingyao_Wang1; ~Graham_Neubig1; ~Navdeep_Jaitly1; ~Heng_Ji3; ~Alane_Suhr1; ~Yizhe_Zhang2,"{'value': ['Agents', 'Software Engineering Agents', 'Post-training']}","{'value': 'We present SWE-Gym, the first environment for training real-world software engineering (SWE) agents. SWE-Gym contains 2,438 real-world Python task instances, each comprising a codebase with an executable runtime environment, unit tests, and a task specified in natural language. We use SWE-Gym to train language model based SWE agents, achieving up to 19% absolute gains in resolve rate on the popular SWE-Bench Verified and Lite test sets. We also experiment with inference-time scaling through verifiers trained on agent trajectories sampled from SWE-Gym. When combined with our fine-tuned SWE agents, we achieve 32.0% and 26.0% on SWE-Bench Verified and Lite, respectively, reflecting a new state-of-the-art for open-weight SWE agents. To facilitate further research, we publicly release SWE-Gym, models, and agent trajectories.'}",https://openreview.net{'value': '/pdf/4bc3bab6edd8ebc2434aaa5241e26575c91f1ef7.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=Cf8gsqWrua,{'value': 'Comparing Comparisons: Informative and Easy Human Feedback with Distinguishability Queries'},Xuening Feng; Zhaohui JIANG; Timo Kaufmann; Eyke Hüllermeier; Paul Weng; Yifei Zhu,~Xuening_Feng1; ~Zhaohui_JIANG1; ~Timo_Kaufmann1; ~Eyke_Hüllermeier1; ~Paul_Weng1; ~Yifei_Zhu1,"{'value': ['Reinforcement Learning from Human Feedback', 'Preference-based Reinforcement Learning', 'Human-in-the-loop Machine Learning']}","{'value': 'Learning human objectives from preference feedback has significantly advanced reinforcement learning (RL) in domains where objectives are hard to formalize. \nHowever, traditional methods based on pairwise trajectory comparisons face notable challenges, including the difficulty in comparing trajectories with subtle differences and the limitation of conveying only ordinal information, limiting direct inference of preference strength. \nIn this paper, we introduce a novel *distinguishability query*, enabling humans to express preference strength by comparing two pairs of trajectories. \nLabelers first indicate which of two pairs is easier to distinguish, then provide preference feedback only on the easier pair. \nOur proposed query type directly captures preference strength and is expected to reduce the cognitive load on the labeler. \nWe further connect this query to cardinal utility and difference relations and develop an efficient query selection scheme to achieve a better trade-off between query informativeness and easiness. \nExperimental results demonstrate the potential of our method for faster, data-efficient learning and improved user-friendliness in RLHF benchmarks, particularly in classical control settings where preference strength is critical for expected utility maximization.'}",https://openreview.net{'value': '/pdf/39202c426736823b7f0fb06a5d3d5fa213f104e8.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=CAPNgWkEEk,{'value': 'Optimal Sensor Scheduling and Selection for Continuous-Discrete Kalman Filtering with Auxiliary Dynamics'},Mohamad Al Ahdab; john leth; Zheng-Hua Tan,~Mohamad_Al_Ahdab1; ~john_leth1; ~Zheng-Hua_Tan1,"{'value': ['Kalman Filtering', 'Sensor Scheduling', 'Bayesian State-Space Models', 'Control']}","{'value': 'We study the Continuous-Discrete Kalman Filter (CD-KF) for State-Space Models (SSMs) where continuous-time dynamics are observed via multiple sensors with discrete, irregularly timed measurements. Our focus extends to scenarios in which the measurement process is coupled with the states of an auxiliary SSM. For instance, higher measurement rates may increase energy consumption or heat generation, while a sensor’s accuracy can depend on its own spatial trajectory or that of the measured target. Each sensor thus carries distinct costs and constraints associated with its measurement rate and additional constraints and costs on the auxiliary state. We model measurement occurrences as independent Poisson processes with sensor-specific rates and derive an upper bound on the mean posterior covariance matrix of the CD-KF along the mean auxiliary state. The bound is continuously differentiable with respect to the measurement rates, which enables efficient gradient-based optimization. Exploiting this bound, we propose a finite-horizon optimal control framework to optimize measurement rates and auxiliary-state dynamics jointly. We further introduce a deterministic method for scheduling measurement times from the optimized rates. Empirical results in state-space filtering and dynamic temporal Gaussian process regression demonstrate that our approach achieves improved trade-offs between resource usage and estimation accuracy.'}",https://openreview.net{'value': '/pdf/d6b68e07c0055deec6936d644c06db0989adb22e.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=C3gAIlPhjV,{'value': 'Arrow: Accelerator for Time Series Causal Discovery with Time Weaving'},Yuanyuan Yao; Yuan Dong; Lu Chen; Kun Kuang; Ziquan Fang; Cheng Long; Yunjun Gao; TIANYI LI,~Yuanyuan_Yao1; ~Yuan_Dong9; ~Lu_Chen5; ~Kun_Kuang1; ~Ziquan_Fang1; ~Cheng_Long1; ~Yunjun_Gao1; ~TIANYI_LI4,"{'value': ['time series', 'causal discovery', 'accelerator']}","{'value': 'Current causal discovery methods for time series data can effectively address a variety of scenarios; however, they remain constrained by inefficiencies. The significant inefficiencies arise primarily from the high computational costs associated with binning, the uncertainty in selecting appropriate time lags, and the extensive sets of candidate variables. To achieve both high efficiency and effectiveness of causal discovery, we introduce an accelerator termed ARROW. It incorporates an innovative concept termed “Time Weaving” that efficiently encodes time series data to well capture the dynamic trends, thereby mitigating computational complexity. We also propose a novel time lag discovery strategy utilizing XOR operations, which derives a theorem to obtain the optimal time lag and significantly enhances the efficiency using XOR operations. To optimize the search space for causal relationships, we design an efficient pruning strategy that intelligently identifies the most relevant candidate variables, enhancing the efficiency and accuracy of causal discovery. We applied ARROW to four different types of time series causal discovery algorithms and evaluated it on 25 synthetic and real-world datasets. The results demonstrate that, compared to the original algorithms, ARROW achieves up to 153x speedup while achieving higher accuracy in most cases.'}",https://openreview.net{'value': '/pdf/372a27dae2775038e9f7d466e773d84bc64a3364.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=BSwxSqqWfN,{'value': 'A Model of Place Field Reorganization During Reward Maximization'},M Ganesh Kumar; Blake Bordelon; Jacob A Zavatone-Veth; Cengiz Pehlevan,~M_Ganesh_Kumar1; ~Blake_Bordelon1; ~Jacob_A_Zavatone-Veth1; ~Cengiz_Pehlevan2,"{'value': ['Reinforcement learning', 'Temporal Difference error', 'Hippocampus', 'Place cells', 'navigation']}","{'value': ""When rodents learn to navigate in a novel environment, a high density of place fields emerges at reward locations, fields elongate against the trajectory, and individual fields change spatial selectivity while demonstrating stable behavior. Why place fields demonstrate these characteristic phenomena during learning remains elusive. We develop a normative framework using a reward maximization objective, whereby the temporal difference (TD) error drives place field reorganization to improve policy learning. Place fields are modeled using Gaussian radial basis functions to represent states in an environment, and directly synapse to an actor-critic for policy learning. Each field's amplitude, center, and width, as well as downstream weights, are updated online at each time step to maximize rewards. We demonstrate that this framework unifies three disparate phenomena observed in navigation experiments. Furthermore, we show that these place field phenomena improve policy convergence when learning to navigate to a single target and relearning multiple new targets. To conclude, we develop a simple normative model that recapitulates several aspects of hippocampal place field learning dynamics and unifies mechanisms to offer testable predictions for future experiments.""}",https://openreview.net{'value': '/pdf/dc31189fcafa146ae92764239b245f9ae68074d7.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=BKOeyZal0x,{'value': 'Representation Shattering in Transformers: A Synthetic Study with Knowledge Editing'},Kento Nishi; Rahul Ramesh; Maya Okawa; Mikail Khona; Hidenori Tanaka; Ekdeep Singh Lubana,~Kento_Nishi1; ~Rahul_Ramesh2; ~Maya_Okawa1; ~Mikail_Khona2; ~Hidenori_Tanaka1; ~Ekdeep_Singh_Lubana1,"{'value': ['mechanistic interpretability', 'knowledge editing', 'transformers']}","{'value': 'Knowledge Editing (KE) algorithms alter models\' weights to perform targeted updates to incorrect, outdated, or otherwise unwanted factual associations. However, recent work has shown that applying KE can adversely affect models\' broader factual recall accuracy and diminish their reasoning abilities. Although these studies give insights into the potential harms of KE algorithms, e.g., performance evaluations on benchmarks, little is understood about why such destructive failures occur. Motivated by this, we define a novel synthetic task in which a Transformer is trained from scratch to internalize a ""structured"" knowledge graph. The structure enforces relationships between entities of the graph, such that editing a factual association has ""trickling effects"" on other entities (e.g., altering X\'s parent is Y to Z affects who X\'s siblings\' parent is). Through evaluations of edited models on this task, we show that KE inadvertently affects representations of entities beyond the targeted one, distorting relevant structures that allow a model to infer unseen knowledge about an entity. We call this phenomenon representation shattering and demonstrate that it degrades models\' factual recall and reasoning performance. We further corroborate our findings in naturalistic settings with pre-trained Llama and Mamba models as well. Overall, our work yields a precise mechanistic hypothesis to explain why KE has adverse effects on model abilities.'}",https://openreview.net{'value': '/pdf/fb88b61bda1267a316fafdb295bbfea75d6bfc37.pdf'},{'title_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=BGpVHG1wiE,{'value': 'Predictive Performance of Deep Quantum Data Re-uploading Models'},Xin Wang; Hanxiao Tao; Rebing Wu,~Xin_Wang115; ~Hanxiao_Tao1; ~Rebing_Wu1,"{'value': ['Quantum machine learning', 'Data re-uploading', 'Predictive performance']}","{'value': 'Quantum machine learning models incorporating data re-uploading circuits have garnered significant attention due to their exceptional expressivity and trainability. However, their ability to generate accurate predictions on unseen data, referred to as the predictive performance, remains insufficiently investigated. This study reveals a fundamental limitation in predictive performance when deep encoding layers are employed within the data re-uploading model. Concretely, we theoretically demonstrate that when processing high-dimensional data with limited-qubit data re-uploading models, their predictive performance progressively degenerates to near random-guessing levels as the number of encoding layers increases. In this context, the repeated data uploading cannot mitigate the performance degradation. These findings are validated through experiments on both synthetic linearly separable datasets and real-world datasets. Our results demonstrate that when processing high-dimensional data, the quantum data re-uploading models should be designed with wider circuit architectures rather than deeper and narrower ones.'}",https://openreview.net{'value': '/pdf/c9a51e6258bce1e86db5e5fcfe7ed6046668774a.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=BDaMEdNejx,"{'value': ""Learning from others' mistakes: Finetuning machine translation models with span-level error annotations""}",Lily H Zhang; Hamid Dadkhahi; Mara Finkelstein; Firas Trabelsi; Jiaming Luo; Markus Freitag,~Lily_H_Zhang1; ~Hamid_Dadkhahi1; ~Mara_Finkelstein1; ~Firas_Trabelsi1; ~Jiaming_Luo2; ~Markus_Freitag2,"{'value': ['machine translation', 'fine-grained annotations', 'multidimensional quality metrics']}","{'value': 'Despite growing interest in incorporating feedback to improve language models, most efforts focus only on sequence-level annotations. In this work, we explore the potential of utilizing fine-grained span-level annotations from offline datasets to improve model quality. We develop a simple finetuning algorithm, called Training with Annotations (TWA), to directly train machine translation models on such annotated data. TWA utilizes targeted span-level error information while also flexibly learning what to penalize within a span. Moreover, TWA considers the overall trajectory of a sequence when deciding which non-error spans to utilize as positive signals. Experiments on English-German and Chinese-English machine translation show that TWA outperforms baselines such as supervised finetuning on sequences filtered for quality and Direct Preference Optimization on pairs constructed from the same data.'}",https://openreview.net{'value': '/pdf/8d18d763d4ff9f35c7946f7396e61ccc00769571.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=AulTigiaMv,{'value': 'Eliciting Language Model Behaviors with Investigator Agents'},Xiang Lisa Li; Neil Chowdhury; Daniel D. Johnson; Tatsunori Hashimoto; Percy Liang; Sarah Schwettmann; Jacob Steinhardt,~Xiang_Lisa_Li1; ~Neil_Chowdhury1; ~Daniel_D._Johnson1; ~Tatsunori_Hashimoto1; ~Percy_Liang1; ~Sarah_Schwettmann2; ~Jacob_Steinhardt1,{'value': ['red teaming; posterior inference']},"{'value': 'Language models exhibit complex, diverse behaviors when prompted with free-form text, making it hard to characterize the space of possible outputs. We study the problem of behavioral elicitation, where the goal is to search for prompts that induce specific target behaviors (e.g., hallucinations, harmful responses) from a target language model. To navigate the exponentially large space of possible prompts, we train amortized investigator models to emulate the posterior distribution over the prompts, conditioned on the target behavior. Specifically, we first fit a reverse model and then use reinforcement learning to optimize likelihood of generating the target behavior. To improve the diversity of the prompt distribution, we further propose a novel iterative training objective based on the Frank-Wolfe algorithm that encourages each iteration to discover different sets of prompts not captured by previous iterations. Our investigator models produce prompts that exhibit a variety of effective and human-interpretable strategies for behavior elicitation, obtaining a 100% attack success rate on AdvBench (Harmful Behaviors) and an 85% hallucination rate.'}",https://openreview.net{'value': '/pdf/7444d9f88020172f83624b8f5483376ea89a0c43.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=Al6qG8BlKg,{'value': 'Learning Progress Driven Multi-Agent Curriculum'},Wenshuai Zhao; Zhiyuan Li; Joni Pajarinen,~Wenshuai_Zhao1; ~Zhiyuan_Li9; ~Joni_Pajarinen2,"{'value': ['Curriculum learning', 'Temporal difference', 'Sparse reward']}","{'value': 'The number of agents can be an effective curriculum variable for controlling the difficulty of multi-agent reinforcement learning (MARL) tasks. Existing work typically uses manually defined curricula such as linear schemes. We identify two potential flaws while applying existing reward-based automatic curriculum learning methods in MARL: (1) The expected episode return used to measure task difficulty has high variance; (2) Credit assignment difficulty can be exacerbated in tasks where increasing the number of agents yields higher returns which is common in many MARL tasks. To address these issues, we propose to control the curriculum by using a TD-error based *learning progress* measure and by letting the curriculum proceed from an initial context distribution to the final task specific one. Since our approach maintains a distribution over the number of agents and measures learning progress rather than absolute performance, which often increases with the number of agents, we alleviate problem (2). Moreover, the learning progress measure naturally alleviates problem (1) by aggregating returns. In three challenging sparse-reward MARL benchmarks, our approach outperforms state-of-the-art baselines.'}",https://openreview.net{'value': '/pdf/0bea28b13912b63f2becebdf806b3cefc66a0247.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=AjbiIcRt6q,{'value': 'Diffuse Everything: Multimodal Diffusion Models on Arbitrary State Spaces'},Kevin Rojas; Yuchen Zhu; Sichen Zhu; Felix X-F. Ye; Molei Tao,~Kevin_Rojas1; ~Yuchen_Zhu3; ~Sichen_Zhu1; ~Felix_X-F._Ye1; ~Molei_Tao1,"{'value': ['Diffusion Model', 'Discrete Diffusion', 'Multimodal', 'Generative Modeling']}","{'value': 'Diffusion models have demonstrated remarkable performance in generating unimodal data across various tasks, including image, video, and text generation. On the contrary, the joint generation of multimodal data through diffusion models is still in the early stages of exploration. Existing approaches heavily rely on external preprocessing protocols, such as tokenizers and variational autoencoders, to harmonize varied data representations into a unified, unimodal format. This process heavily demands the high accuracy of encoders and decoders, which can be problematic for applications with limited data. To lift this restriction, we propose a novel framework for building multimodal diffusion models on arbitrary state spaces, enabling native generation of coupled data across different modalities. By introducing an innovative decoupled noise schedule for each modality, we enable both unconditional and modality-conditioned generation within a single model simultaneously. We empirically validate our approach for text-image generation and mixed-type tabular data synthesis, demonstrating that it achieves competitive performance. Code is available at https://github.com/KevinRojas1499/Diffuse-Everything.'}",https://openreview.net{'value': '/pdf/2bb86586fa26b97034aa7d5e436723e160de151f.pdf'},{'abstract_filter': 'Data Synthesis'},ICML.cc,2025,Conference
https://openreview.net/forum?id=AZT4EiONRQ,{'value': 'Learning Imbalanced Data with Beneficial Label Noise'},Guangzheng Hu; Feng Liu; Mingming Gong; Guanghui Wang; Liuhua Peng,~Guangzheng_Hu2; ~Feng_Liu2; ~Mingming_Gong1; ~Guanghui_Wang6; ~Liuhua_Peng1,"{'value': ['Imbalanced learning', 'beneficial label noise', 'classification accuracy', 'decision boundary']}","{'value': 'Data imbalance is a common factor hindering classifier performance. Data-level approaches for imbalanced learning, such as resampling, often lead to information loss or generative errors. Building on theoretical studies of imbalance ratio in binary classification, it is found that adding suitable label noise can adjust biased decision boundaries and improve classifier performance. This paper proposes the Label-Noise-based Re-balancing (LNR) approach to solve imbalanced learning by employing a novel design of an asymmetric label noise model. In contrast to other data-level methods, LNR alleviates the issues of informative loss and generative errors and can be integrated seamlessly with any classifier or algorithm-level method. We validated the superiority of LNR on synthetic and real-world datasets. Our work opens a new avenue for imbalanced learning, highlighting the potential of beneficial label noise.'}",https://openreview.net{'value': '/pdf/12bf669c7ad83fa5dbf5619b116f3211ba33e903.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=AKvy9a4jho,{'value': 'KABB: Knowledge-Aware Bayesian Bandits for Dynamic Expert Coordination in Multi-Agent Systems'},Jusheng Zhang; Zimeng Huang; Yijia Fan; Ningyuan Liu; Mingyan Li; Zhuojie Yang; Jiawei Yao; Jian Wang; Keze Wang,~Jusheng_Zhang3; ~Zimeng_Huang1; ~Yijia_Fan1; ~Ningyuan_Liu1; ~Mingyan_Li2; ~Zhuojie_Yang1; ~Jiawei_Yao3; ~Jian_Wang10; ~Keze_Wang1,"{'value': ['LLM', 'Agent']}","{'value': 'As scaling large language models faces prohibitive costs, multi-agent systems emerge as a promising alternative, though challenged by static knowledge assumptions and coordination inefficiencies. We introduce Knowledge-Aware Bayesian Bandits (KABB), a novel framework that enhances multi-agent system coordination through semantic understanding and dynamic adaptation. The framework features three key innovations: a customized knowledge distance model for deep semantic understanding, a dual-adaptation mechanism for continuous expert optimization, and a knowledge-aware Thompson Sampling strategy for efficient expert selection. Extensive evaluation demonstrates KABB achieves an optimal cost-performance balance, maintaining high performance while keeping computational demands relatively low in multi-agent coordination.'}",https://openreview.net{'value': '/pdf/fef86ef3f2607c65a7525f944813d72168cf794d.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=9v1eW8HgMU,{'value': 'Archetypal SAE: Adaptive and Stable Dictionary Learning for Concept Extraction in Large Vision Models'},Thomas Fel; Ekdeep Singh Lubana; Jacob S. Prince; Matthew Kowal; Victor Boutin; Isabel Papadimitriou; Binxu Wang; Martin Wattenberg; Demba E. Ba; Talia Konkle,~Thomas_Fel2; ~Ekdeep_Singh_Lubana1; ~Jacob_S._Prince1; ~Matthew_Kowal1; ~Victor_Boutin2; ~Isabel_Papadimitriou1; ~Binxu_Wang1; ~Martin_Wattenberg1; ~Demba_E._Ba1; ~Talia_Konkle1,"{'value': ['Explainability', 'Interpretability', 'Dictionary Learning', 'Computer Vision', 'Archetypal Analysis']}","{'value': 'Sparse Autoencoders (SAEs) have emerged as a powerful framework for machine learning interpretability, enabling the unsupervised decomposition of model representations into a dictionary of abstract, human-interpretable concepts. However, we reveal a fundamental limitation: SAEs exhibit severe instability, as identical models trained on similar datasets can produce sharply different dictionaries, undermining their reliability as an interpretability tool. To address this issue, we draw inspiration from the Archetypal Analysis framework introduced by Cutler & Breiman (1994) and present Archetypal SAEs (A-SAE), wherein dictionary atoms are constrained to the data’s convex hull. This geometric anchoring significantly enhances the stability and plausibility of inferred dictionaries, and their mildly relaxed variants RA-SAEs further match state-of-the-art reconstruction abilities. To rigorously assess dictionary quality learned by SAEs, we introduce two new benchmarks that test (i) plausibility, if dictionaries recover “true” classification directions and (ii) identifiability, if dictionaries disentangle synthetic concept mixtures. Across all evaluations, RA-SAEs consistently yield more structured representations while uncovering novel, semantically meaningful concepts in large-scale vision models.'}",https://openreview.net{'value': '/pdf/a49cb0e1b2ee1ba89915dc93436553a7cd5b115f.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=9rG2oAWj0s,{'value': 'ProDiff: Prototype-Guided Diffusion for Minimal Information Trajectory Imputation'},Tianci Bu; Le Zhou; Wenchuan Yang; Jianhong Mou; Kang Yang; Suoyi Tan; Feng Yao; Jingyuan Wang; Xin Lu,~Tianci_Bu1; ~Le_Zhou4; ~Wenchuan_Yang1; ~Jianhong_Mou2; ~Kang_Yang7; ~Suoyi_Tan1; ~Feng_Yao2; ~Jingyuan_Wang2; ~Xin_Lu12,"{'value': ['Minimal Information Trajectory Imputation', 'Prototype Learning', 'Diffusion Model']}","{'value': 'Trajectory data is crucial for various applications but often suffers from incompleteness due to device limitations and diverse collection scenarios. Existing imputation methods rely on sparse trajectory or travel information, such as velocity, to infer missing points. However, these approaches assume that sparse trajectories retain essential behavioral patterns, which place significant demands on data acquisition and overlook the potential of large-scale human trajectory embeddings.\nTo address this, we propose ProDiff, a trajectory imputation framework that uses only two endpoints as minimal information. It integrates prototype learning to embed human movement patterns and a denoising diffusion probabilistic model for robust spatiotemporal reconstruction. Joint training with a tailored loss function ensures effective imputation.\nProDiff outperforms state-of-the-art methods, improving accuracy by 6.28\\% on FourSquare and 2.52\\% on WuXi. Further analysis shows a 0.927 correlation between generated and real trajectories, demonstrating the effectiveness of our approach.'}",https://openreview.net{'value': '/pdf/0e58b25ae0248adba19f3c600c554d103ae8abcc.pdf'},{'title_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=9ppSGIfpzq,{'value': 'Accelerating Unbiased LLM Evaluation via Synthetic Feedback'},Zhaoyi Zhou; Yuda Song; Andrea Zanette,~Zhaoyi_Zhou1; ~Yuda_Song2; ~Andrea_Zanette1,"{'value': ['LLM evaluation', 'synthetic evaluation', 'variance reduction']}","{'value': 'When developing new large language models (LLMs), a key step is evaluating their final performance, often by computing the win-rate against a reference model based on external feedback. Human feedback is the gold standard, particularly for capturing nuanced qualities like coherence, readability, and alignment with human expectations. However, human evaluations are costly—even for large tech companies—and when conducted with active users, they may negatively impact user experience.\nA promising alternative is synthetic feedback, where evaluations are conducted by other large language models, including reward models. While this eliminates the need for costly human annotations, it introduces biases that may distort the evaluation process.\nIn this work, we propose a statistically principled framework that integrates human and synthetic feedback to reduce reliance on human annotations while maintaining unbiased win-rate calculations. \nOur experiments demonstrate a reduction in human annotations by up to 12.2\\% with an off-the-shelf synthetic evaluator and up to 24.8\\% with a finetuned variant. Apart from being generalizable, scalable, and free of hyper-parameter tuning, our method offers predictable annotation savings, which can be estimated based on data-dependent characteristics.'}",https://openreview.net{'value': '/pdf/c703278d8c2670c7a4bad5856852ac13f9579363.pdf'},{'title_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=9P5e6iE4WK,{'value': 'OptMATH: A Scalable Bidirectional Data Synthesis Framework for Optimization Modeling'},Hongliang Lu; Zhonglin Xie; Yaoyu Wu; Can Ren; Yuxuan Chen; Zaiwen Wen,~Hongliang_Lu3; ~Zhonglin_Xie1; ~Yaoyu_Wu1; ~Can_Ren1; ~Yuxuan_Chen22; ~Zaiwen_Wen1,"{'value': ['Optimization', 'LLM', 'Optimization Modeling', 'Synthetic Data']}","{'value': ""Despite the rapid development of large language models (LLMs), a fundamental challenge persists: the lack of high-quality optimization modeling datasets hampers LLMs' robust modeling of practical optimization problems from natural language descriptions (NL). This data scarcity also contributes to the generalization difficulties experienced by learning-based methods.\nTo address these challenges, we propose a scalable framework for synthesizing a high-quality dataset, named OptMATH. Starting from curated seed data with mathematical formulations (MF), this framework automatically generates problem data (PD) with controllable complexity. Then, a back-translation step is employed to obtain NL. To verify the correspondence between the NL and the PD, a forward modeling step followed by rejection sampling is used. The accepted pairs constitute the training part of OptMATH. Then a collection of rejected pairs is identified and further filtered. This collection serves as a new benchmark for optimization modeling, containing difficult instances whose lengths are much longer than these of NL4OPT and MAMO.\nThrough extensive experiments, we demonstrate that models of various sizes (0.5B-32B parameters) trained on OptMATH achieve superior results on multiple modeling benchmarks, thereby validating the effectiveness and scalability of our approach. The OptMATH dataset and related resources are available at \\url{https://github.com/optsuite/OptMATH}.""}",https://openreview.net{'value': '/pdf/e40ee54b3d7a55d67d3286279a0c0835c0b8769f.pdf'},{'title_filter': 'Data Synthesis'},ICML.cc,2025,Conference
https://openreview.net/forum?id=9NVm1Bf7CS,{'value': 'WikiBigEdit: Understanding the Limits of Lifelong Knowledge Editing in LLMs'},Lukas Thede; Karsten Roth; Matthias Bethge; Zeynep Akata; Thomas Hartvigsen,~Lukas_Thede1; ~Karsten_Roth1; ~Matthias_Bethge1; ~Zeynep_Akata1; ~Thomas_Hartvigsen1,"{'value': ['LLM', 'Knowledge Editing', 'Lifelong Learning']}","{'value': ""Keeping large language models factually up-to-date is crucial for deployment, yet costly retraining remains a challenge. Knowledge editing offers a promising alternative, but methods are only tested on small-scale or synthetic edit benchmarks. In this work, we aim to bridge research into lifelong knowledge editing to real-world edits at practically relevant scale. We first introduce \\texttt{WikiBigEdit}; a large-scale benchmark of real-world Wikidata edits, built to automatically extend lifelong for future-proof benchmarking. In its first instance, it includes over 500K question-answer pairs for knowledge editing alongside a comprehensive evaluation pipeline. Finally, we use \\texttt{WikiBigEdit} to study existing knowledge editing techniques' ability to incorporate large volumes of real-world facts and contrast their capabilities to generic modification techniques such as retrieval augmentation and continual finetuning to acquire a complete picture of the practical extent of current lifelong knowledge editing.""}",https://openreview.net{'value': '/pdf/77032cfce8ffcfda8d237129bbc459ba28fd498f.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=8lt5776GLB,{'value': 'A Certified Unlearning Approach without Access to Source Data'},Umit Yigit Basaran; Sk Miraj Ahmed; Amit Roy-Chowdhury; Basak Guler,~Umit_Yigit_Basaran1; ~Sk_Miraj_Ahmed1; ~Amit_Roy-Chowdhury2; ~Basak_Guler1,"{'value': ['Certified machine unlearning', 'privacy', 'surrogate data', 'statistical distance', 'noise calibration']}","{'value': ""With the growing adoption of data privacy regulations, the ability to erase private or copyrighted information from trained models has become a crucial requirement. Traditional unlearning methods often assume access to the complete training dataset, which is unrealistic in scenarios where the source data is no longer available. To address this challenge, we propose a certified unlearning framework that enables effective data removal without access to the original training data samples. Our approach utilizes a surrogate dataset that approximates the statistical properties of the source data, allowing for controlled noise scaling based on the statistical distance between the two. While our theoretical guarantees assume knowledge of the exact statistical distance, practical implementations typically approximate this distance, resulting in potentially weaker but still meaningful privacy guarantees. This ensures strong guarantees on the model's behavior post-unlearning while maintaining its overall utility. We establish theoretical bounds, introduce practical noise calibration techniques, and validate our method through extensive experiments on both synthetic and real-world datasets. The results demonstrate the effectiveness and reliability of our approach in privacy-sensitive settings.""}",https://openreview.net{'value': '/pdf/76fa3e40e41bf4c797899837f6acdd83d24bfce2.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=8bGEHOTvmq,"{'value': ""It's My Data Too: Private ML for Datasets with Multi-User Training Examples""}",Arun Ganesh; Ryan McKenna; Hugh Brendan McMahan; Adam Smith; Fan Wu,~Arun_Ganesh1; ~Ryan_McKenna2; ~Hugh_Brendan_McMahan1; ~Adam_Smith1; ~Fan_Wu6,"{'value': ['differential privacy', 'multi-attribution']}","{'value': 'We initiate a study of algorithms for model training with user-level differential privacy (DP), where each example may be attributed to multiple users, which we call the multi-attribution model. We first provide a carefully chosen definition of user-level DP under the multi-attribution model. Training in the multi-attribution model is facilitated by solving the contribution bounding problem, i.e. the problem of selecting a subset of the dataset for which each user is associated with a limited number of examples. We propose a greedy baseline algorithm for the contribution bounding problem. We then empirically study this algorithm for a synthetic logistic regression task and a transformer training task, including studying variants of this baseline algorithm that optimize the subset chosen using different techniques and criteria. We find that the baseline algorithm remains competitive with its variants in most settings, and build a better understanding of the practical importance of a bias-variance tradeoff inherent in solutions to the contribution bounding problem.'}",https://openreview.net{'value': '/pdf/894267e5eddabf221c2fe6168f171ea699b0eb9f.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=8ThnPFhGm8,{'value': 'Free Process Rewards without Process Labels'},Lifan Yuan; Wendi Li; Huayu Chen; Ganqu Cui; Ning Ding; Kaiyan Zhang; Bowen Zhou; Zhiyuan Liu; Hao Peng,~Lifan_Yuan1; ~Wendi_Li1; ~Huayu_Chen1; ~Ganqu_Cui1; ~Ning_Ding5; ~Kaiyan_Zhang1; ~Bowen_Zhou8; ~Zhiyuan_Liu1; ~Hao_Peng4,{'value': ['Process Reward Model']},"{'value': 'Different from its counterpart outcome reward models (ORMs), which evaluate the entire responses, a process reward model (PRM) scores a reasoning trajectory step by step, providing denser and more fine-grained rewards. However, training a PRM requires labels annotated at every intermediate step, presenting significant challenges for both manual and automatic data collection. This paper aims to address this challenge. Both theoretically and empirically, we show that an implicit PRM can be obtained at no additional cost, by simply training an ORM on the cheaper response-level labels. The only assumption is to parameterize the outcome reward as the log-likelihood ratios of the policy and reference models rϕ(y) = β log πϕ(y) πref(y) , which can be optimized regardless of the specific choice of loss objectives. In experiments, we instantiate our implicit PRMs with various objectives and evaluate their performance on MATH. We show that our implicit PRM outperforms a strong MCTS-based baseline á la Math-Shepherd (Wang et al., 2023) using less than 1/38 of the training data. Its performance can be further improved with majority voting. We further find that scaling up instructions and responses benefits our implicit PRM, and the latter brings a larger gain. Particularly, we find that our implicit PRM, when instantiated with the cross-entropy (CE) loss, is more data-efficient and can keep improving generation models even when trained with only one response per instruction, the setup that suffers from extreme data scarcity and imbalance. Further, instructions should be relevant to downstream tasks while the diversity of responses does not bring gains. Surprisingly, training on extra Math-Shepherd step labels brings no further improvements to our implicit PRM trained on only outcome data. We hope that our work will encourage a rethinking of PRM training approaches and contribute to making training PRMs more accessible.'}",https://openreview.net{'value': '/pdf/052eae2278567bbb2ce3dac883c5a308924ad334.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=8S5rzd08FI,{'value': 'BILBO: BILevel Bayesian Optimization'},Ruth Wan Theng Chew; Quoc Phong Nguyen; Bryan Kian Hsiang Low,~Ruth_Wan_Theng_Chew1; ~Quoc_Phong_Nguyen2; ~Bryan_Kian_Hsiang_Low1,"{'value': ['machine learning', 'Bayesian optimization', 'bilevel optimization', 'bilevel Bayesian optimization']}","{'value': 'Bilevel optimization is characterized by a two-level optimization structure, where the upper-level problem is constrained by optimal lower-level solutions, and such structures are prevalent in real-world problems. The constraint by optimal lower-level solutions poses significant challenges, especially in noisy, constrained, and derivative-free settings, as repeating lower-level optimizations is sample inefficient and predicted lower-level solutions may be suboptimal. We present BILevel Bayesian Optimization (BILBO), a novel Bayesian optimization algorithm for general bilevel problems with blackbox functions, which optimizes both upper- and lower-level problems simultaneously, without the repeated lower-level optimization required by existing methods. BILBO samples from confidence-bounds based trusted sets, which bounds the suboptimality on the lower level. Moreover, BILBO selects only one function query per iteration, where the function query selection strategy incorporates the uncertainty of estimated lower-level solutions and includes a conditional reassignment of the query to encourage exploration of the lower-level objective. The performance of BILBO is theoretically guaranteed with a sublinear regret bound for commonly used kernels and is empirically evaluated on several synthetic and real-world problems.'}",https://openreview.net{'value': '/pdf/3dacb8d85233e26b5b4ea45231acb8aec71b06a4.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=8JGwoZceQs,{'value': 'Robust Noise Attenuation via Adaptive Pooling of Transformer Outputs'},Greyson Brothers,~Greyson_Brothers1,"{'value': ['Pooling', 'Attention', 'Vector Quantization', 'AdaPool', 'Transformer', 'Robustness']}","{'value': 'We investigate the design of pooling methods used to summarize the outputs of transformer embedding models, primarily motivated by reinforcement learning and vision applications. This work considers problems where a subset of the input vectors contains requisite information for a downstream task (signal) while the rest are distractors (noise). By framing pooling as vector quantization with the goal of minimizing signal loss, we demonstrate that the standard methods used to aggregate transformer outputs, AvgPool, MaxPool, and ClsToken, are vulnerable to performance collapse as the signal-to-noise ratio (SNR) of inputs fluctuates. We then show that an attention-based *adaptive pooling* method can approximate the signal-optimal vector quantizer within derived error bounds for any SNR. Our theoretical results are first validated by supervised experiments on a synthetic dataset designed to isolate the SNR problem, then generalized to standard relational reasoning, multi-agent reinforcement learning, and vision benchmarks with noisy observations, where transformers with adaptive pooling display superior robustness across tasks.'}",https://openreview.net{'value': '/pdf/74011122d48f91448c1391a5be1449ae3e46221c.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=80mK2Mqaph,"{'value': 'One Arrow, Two Hawks: Sharpness-aware Minimization for Federated Learning via Global Model Trajectory'}",Yuhang Li; Tong Liu; Yangguang Cui; Ming Hu; Xiaoqiang Li,~Yuhang_Li9; ~Tong_Liu5; ~Yangguang_Cui1; ~Ming_Hu2; ~Xiaoqiang_Li2,"{'value': ['Federated learning', 'sharpness-aware minimization']}","{'value': 'Federated learning (FL) presents a promising strategy for distributed and privacy-preserving learning, yet struggles with performance issues in the presence of heterogeneous data distributions. \nRecently, a series of works based on sharpness-aware minimization (SAM) have emerged to improve local learning generality, proving to be effective in mitigating data heterogeneity effects.\nHowever, most SAM-based methods do not directly consider the global objective and require two backward pass per iteration, resulting in diminished effectiveness.\nTo overcome these two bottlenecks, we leverage the global model trajectory to directly measure sharpness for the global objective, requiring only a single backward pass.\nWe further propose a novel and general algorithm FedGMT to overcome data heterogeneity and the pitfalls of previous SAM-based methods.\nWe analyze the convergence of FedGMT and conduct extensive experiments on visual and text datasets in a variety of scenarios, demonstrating that FedGMT achieves competitive accuracy with state-of-the-art FL methods while minimizing computation and communication overhead. \nCode is available at https://github.com/harrylee999/FL-SAM.'}",https://openreview.net{'value': '/pdf/964d708d8c6ccb69bcf297423c2e379c3dc9c8a3.pdf'},{'title_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=7jxa1o8rDW,{'value': 'Fairness on Principal Stratum: A New Perspective on Counterfactual Fairness'},Haoxuan Li; Zeyu Tang; Zhichao Jiang; Zhuangyan Fang; Yue Liu; Zhi Geng; Kun Zhang,~Haoxuan_Li6; ~Zeyu_Tang1; ~Zhichao_Jiang2; ~Zhuangyan_Fang1; ~Yue_Liu9; ~Zhi_Geng1; ~Kun_Zhang1,"{'value': ['Counterfactual fairness', 'Principal strata']}","{'value': 'Fairness in human and algorithmic decision-making is crucial in areas such as criminal justice, education, and social welfare. Recently, counterfactual fairness has drawn increasing research interest, suggesting that decision-making for individuals should remain the same when intervening with different values on protected attributes. Nevertheless, the question of ""which attributes and individuals should be protected"" is rarely discussed in the existing counterfactual fairness literature. For example, when considering leg disability as a protected attribute, the algorithms should not treat individuals with leg disabilities differently in college admissions, but one may naturally consider this factor when selecting runner athletes. In other words, when and how to enforce fairness is expected to depend on the causal relation between the protected attribute and the outcome of interest. Formally, this paper proposes principal counterfactual fairness using the concept of principal stratification from the causal inference literature, focusing on whether an algorithm is counterfactually fair for individuals whose protected attribute has no individual causal effect on the outcome of interest. To examine whether an algorithm satisfies principal counterfactual fairness, we derive the statistical bounds and propose a post-processing approach to achieving principal counterfactual fairness with minimal individual decision changes. Experiments are conducted using synthetic and real-world datasets to verify the effectiveness of our methods.'}",https://openreview.net{'value': '/pdf/6bab5151a78f3a5fcbc832a296f373ebd9f8e61c.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=7epYTVsWEI,{'value': 'PDE-Controller: LLMs for Autoformalization and Reasoning of PDEs'},Mauricio Soroco; Jialin Song; Mengzhou Xia; Kye Emond; Weiran Sun; Wuyang Chen,~Mauricio_Soroco1; ~Jialin_Song3; ~Mengzhou_Xia1; ~Kye_Emond1; ~Weiran_Sun1; ~Wuyang_Chen1,"{'value': ['AI-for-Math', 'Large Language Model', 'Partial Differential Equation']}","{'value': 'We present PDE-Controller, a framework that enables large language models (LLMs) to control systems governed by partial differential equations (PDEs). Traditional LLMs have excelled in commonsense reasoning but fall short in rigorous logical reasoning. While recent AI-for-math has made strides in pure mathematics, areas of applied mathematics, particularly PDEs, remain underexplored despite their significant real-world applications. Our approach enables LLMs to transform informal natural language instructions into formal specifications, and then execute reasoning and planning steps to improve the utility of PDE control. We build a holistic solution comprising datasets (both human-written cases and 2 million synthetic samples), math-reasoning models, and novel evaluation metrics, all of which require significant effort. Our PDE-Controller significantly outperforms the latest open-source and GPT models in reasoning, autoformalization, and program synthesis, achieving up to a 62% improvement in utility gain for PDE control. By bridging the gap between language generation and PDE systems, we demonstrate the potential of LLMs in addressing complex scientific and engineering challenges. We promise to release all data, model checkpoints, and code upon acceptance.'}",https://openreview.net{'value': '/pdf/2a8854d83b0b6addf4d97f99b19138298f4634ab.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=7cNLsEAcmL,{'value': 'Offline Learning for Combinatorial Multi-armed Bandits'},Xutong Liu; Xiangxiang Dai; Jinhang Zuo; Siwei Wang; Carlee Joe-Wong; John C.S. Lui; Wei Chen,~Xutong_Liu1; ~Xiangxiang_Dai2; ~Jinhang_Zuo1; ~Siwei_Wang2; ~Carlee_Joe-Wong1; ~John_C.S._Lui2; ~Wei_Chen10,"{'value': ['Multi-armed bandit', 'combinatorial multi-armed bandit', 'offline learning', 'data coverage']}","{'value': 'The combinatorial multi-armed bandit (CMAB) is a fundamental sequential decision-making framework, extensively studied over the past decade. However, existing work primarily focuses on the online setting, overlooking the substantial costs of online interactions and the readily available offline datasets.\nTo overcome these limitations, we introduce Off-CMAB, the first offline learning framework for CMAB. Central to our framework is the combinatorial lower confidence bound (CLCB) algorithm, which combines pessimistic reward estimations with combinatorial solvers. To characterize the quality of offline datasets, we propose two novel data coverage conditions and prove that, under these conditions, CLCB achieves a near-optimal suboptimality gap, matching the theoretical lower bound up to a logarithmic factor.\nWe validate Off-CMAB through practical applications, including learning to rank, large language model (LLM) caching, and social influence maximization, showing its ability to handle nonlinear reward functions, general feedback models, and out-of-distribution action samples that excludes optimal or even feasible actions. \nExtensive experiments on synthetic and real-world datasets further highlight the superior performance of CLCB.'}",https://openreview.net{'value': '/pdf/f0c2392cd01f247bdacd6624f7948d37c5530feb.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=7bgqx5OoVe,{'value': 'Sassha: Sharpness-aware Adaptive Second-order Optimization with Stable Hessian Approximation'},Dahun Shin; Dongyeop Lee; Jinseok Chung; Namhoon Lee,~Dahun_Shin1; ~Dongyeop_Lee1; ~Jinseok_Chung1; ~Namhoon_Lee1,"{'value': ['deep learning', 'second-order optimization', 'sharpness minimization']}","{'value': 'Approximate second-order optimization methods often exhibit poorer generalization compared to first-order approaches. \nIn this work, we look into this issue through the lens of the loss landscape and find that existing second-order methods tend to converge to sharper minima compared to SGD.\nIn response, we propose Sassha, a novel second-order method designed to enhance generalization by explicitly reducing sharpness of the solution, while stabilizing the computation of approximate Hessians along the optimization trajectory.\nIn fact, this sharpness minimization scheme is crafted also to accommodate lazy Hessian updates, so as to secure efficiency besides flatness.\nTo validate its effectiveness, we conduct a wide range of standard deep learning experiments where Sassha demonstrates its outstanding generalization performance that is comparable to, and mostly better than, other methods.\nWe provide a comprehensive set of analyses including convergence, robustness, stability, efficiency, and cost.'}",https://openreview.net{'value': '/pdf/15066db41be8c0c379127429ea05fc28b2ed0642.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=7aAGBuexh9,"{'value': 'FAB-PPI: Frequentist, Assisted by Bayes, Prediction-Powered Inference'}",Stefano Cortinovis; Francois Caron,~Stefano_Cortinovis1; ~Francois_Caron1,"{'value': ['Confidence intervals', 'Bayesian methods', 'heavy-tailed priors', 'horseshoe', 'mean estimation', 'statistical inference', 'semi-supervised inference.']}","{'value': 'Prediction-powered inference (PPI) enables valid statistical inference by combining experimental data with machine learning predictions. When a sufficient number of high-quality predictions is available, PPI results in more accurate estimates and tighter confidence intervals than traditional methods. In this paper, we propose to inform the PPI framework with prior knowledge on the quality of the predictions. The resulting method, which we call frequentist, assisted by Bayes, PPI (FAB-PPI), improves over PPI when the observed prediction quality is likely under the prior, while maintaining its frequentist guarantees. Furthermore, when using heavy-tailed priors, FAB-PPI adaptively reverts to standard PPI in low prior probability regions. We demonstrate the benefits of FAB-PPI in real and synthetic examples.'}",https://openreview.net{'value': '/pdf/70dd2cf9253cd539964b0ee7f42f8f68dff392e0.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=7TrOBcxSvy,{'value': 'SafeArena: Evaluating the Safety of Autonomous Web Agents'},Ada Defne Tur; Nicholas Meade; Xing Han Lù; Alejandra Zambrano; Arkil Patel; Esin DURMUS; Spandana Gella; Karolina Stanczak; Siva Reddy,~Ada_Defne_Tur1; ~Nicholas_Meade1; ~Xing_Han_Lù1; ~Alejandra_Zambrano1; ~Arkil_Patel1; ~Esin_DURMUS2; ~Spandana_Gella2; ~Karolina_Stanczak1; ~Siva_Reddy1,"{'value': ['Agent Safety', 'Web Agents', 'LLM Alignment', 'Jailbreaking']}","{'value': 'LLM-based agents are becoming increasingly proficient at solving web-based tasks. With this capability comes a greater risk of misuse for malicious purposes, such as posting misinformation in an online forum or selling illicit substances on a website. To evaluate these risks, we propose SafeArena, a benchmark focused on the deliberate misuse of web agents. SafeArena comprises 250 safe and 250 harmful tasks across four websites. We classify the harmful tasks into five harm categories---misinformation, illegal activity, harassment, cybercrime, and social bias, designed to assess realistic misuses of web agents. We evaluate leading LLM-based web agents, including GPT-4o, Claude-3.5 Sonnet, Qwen-2-VL 72B, and Llama-3.2 90B, on our benchmark. To systematically assess their susceptibility to harmful tasks, we introduce the Agent Risk Assessment framework that categorizes agent behavior across four risk levels. We find agents are surprisingly compliant with malicious requests, with GPT-4o and Qwen-2 completing 34.7% and 27.3% of harmful requests, respectively. Our findings highlight the urgent need for safety alignment procedures for web agents.'}",https://openreview.net{'value': '/pdf/57662613448549f715f9ca6392fd53ab078bbd20.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=7OxAdd8BUo,{'value': 'Breaking the $n^{1.5}$ Additive Error Barrier for Private and Efficient Graph Sparsification via Private Expander Decomposition'},Anders Aamand; Justin Y. Chen; Mina Dalirrooyfard; Slobodan Mitrović; Yuriy Nevmyvaka; Sandeep Silwal; Yinzhan Xu,~Anders_Aamand1; ~Justin_Y._Chen1; ~Mina_Dalirrooyfard1; ~Slobodan_Mitrović2; ~Yuriy_Nevmyvaka1; ~Sandeep_Silwal1; ~Yinzhan_Xu2,"{'value': ['Differential privacy', 'graph sparsification', 'graph cuts']}","{'value': ""We study differentially private algorithms for graph cut sparsification, a fundamental problem in algorithms, privacy, and machine learning. While significant progress has been made, the best-known private and efficient cut sparsifiers on $n$-node graphs approximate each cut within $\\widetilde{O}(n^{1.5})$ additive error and $1+\\gamma$ multiplicative error for any $\\gamma > 0$ [Gupta, Roth, Ullman TCC'12]. In contrast, \\emph{inefficient} algorithms, i.e., those requiring exponential time, can achieve an $\\widetilde{O}(n)$ additive error and $1+\\gamma$ multiplicative error [Eliáš,  Kapralov, Kulkarni, Lee SODA'20]. In this work, we break the $n^{1.5}$ additive error barrier for private and efficient cut sparsification. We present an $(\\varepsilon,\\delta)$-DP polynomial time algorithm that, given a non-negative weighted graph, outputs a private synthetic graph approximating all cuts with multiplicative error $1+\\gamma$ and additive error $n^{1.25 + o(1)}$ (ignoring dependencies on $\\varepsilon, \\delta, \\gamma$). At the heart of our approach lies a private algorithm for expander decomposition, a popular and powerful technique in (non-private) graph algorithms.""}",https://openreview.net{'value': '/pdf/449aae47feb930c47fecb5a0b86afea8b684b85e.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=7Daf4TMtX9,{'value': 'On Understanding Attention-Based In-Context Learning for Categorical Data'},Aaron T Wang; William Convertino; Xiang Cheng; Ricardo Henao; Lawrence Carin,~Aaron_T_Wang1; ~William_Convertino1; ~Xiang_Cheng1; ~Ricardo_Henao1; ~Lawrence_Carin2,"{'value': ['attention networks', 'in-context learning', 'Transformers']}","{'value': 'In-context learning based on attention models is examined for data with categorical outcomes, with inference in such models viewed from the perspective of functional gradient descent (GD). We develop a network composed of attention blocks, with each block employing a self-attention layer followed by a cross-attention layer, with associated skip connections. This model can exactly perform multi-step functional GD inference for in-context inference with categorical observations. We perform a theoretical analysis of this setup, generalizing many prior assumptions in this line of work, including the class of attention mechanisms for which it is appropriate. We demonstrate the framework empirically on synthetic data, image classification and language generation.'}",https://openreview.net{'value': '/pdf/63e699150d7029d5dc759acd257bad7f555b49d7.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=7Cxk63lTTm,{'value': 'A Manifold Perspective on the Statistical Generalization of Graph Neural Networks'},Zhiyang Wang; Juan Cervino; Alejandro Ribeiro,~Zhiyang_Wang1; ~Juan_Cervino1; ~Alejandro_Ribeiro1,"{'value': ['graph neural networks', 'generalization']}","{'value': 'Graph Neural Networks (GNNs) extend convolutional neural networks to operate on graphs. Despite their impressive performances in various graph learning tasks, the theoretical understanding of their generalization capability is still lacking. Previous GNN generalization bounds ignore the underlying graph structures, often leading to bounds that increase with the number of nodes – a behavior contrary to the one experienced in practice. In this paper, we take a manifold perspective to establish the statistical generalization theory of GNNs on graphs sampled from a manifold in the spectral domain. As demonstrated empirically, we prove that the generalization bounds of GNNs decrease linearly with the size of the graphs in the logarithmic scale, and increase linearly with the spectral continuity constants of the filter functions. Notably, our theory explains both node-level and graph-level tasks. Our result has two implications: i) guaranteeing the generalization of GNNs to unseen data over manifolds; ii) providing insights into the practical design of GNNs, i.e., restrictions on the discriminability of GNNs are necessary to obtain a better generalization performance. We demonstrate our generalization bounds of GNNs using synthetic and multiple real-world datasets.'}",https://openreview.net{'value': '/pdf/06cbf8e4dc6593aa5edcacf81144119106bb5f63.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=6kGTxbn4Qf,{'value': 'Beyond Minimax Rates in Group Distributionally Robust Optimization via a Novel Notion of Sparsity'},Quan M. Nguyen; Nishant A Mehta; Cristóbal A Guzmán,~Quan_M._Nguyen1; ~Nishant_A_Mehta1; ~Cristóbal_A_Guzmán1,"{'value': ['group distributionally robust optimization', 'two-player zero-sum games', 'non-oblivious multi-armed bandits', 'online convex optimization']}","{'value': 'The minimax sample complexity of group distributionally robust optimization (GDRO) has been determined up to a $\\log(K)$ factor, where $K$ is the number of groups. In this work, we venture beyond the minimax perspective via a novel notion of sparsity that we call $(\\lambda, \\beta)$-sparsity. In short, this condition means that at any parameter $\\theta$, there is a set of at most $\\beta$ groups whose risks at $\\theta$ are all at least $\\lambda$ larger than the risks of the other groups. To find an $\\epsilon$-optimal $\\theta$, we show via a novel algorithm and analysis that the $\\epsilon$-dependent term in the sample complexity can swap a linear dependence on $K$ for a linear dependence on the potentially much smaller $\\beta$. \nThis improvement leverages recent progress in sleeping bandits, showing a fundamental connection between the two-player zero-sum game optimization framework for GDRO and per-action regret bounds in sleeping bandits. \nWe next show an adaptive algorithm which, up to logarithmic factors, obtains a sample complexity bound that adapts to the best $(\\lambda, \\beta)$-sparsity condition that holds. \nWe also show how to obtain a dimension-free semi-adaptive sample complexity bound with a computationally efficient method.\nFinally, we demonstrate the practicality of the $(\\lambda, \\beta)$-sparsity condition and the improved sample efficiency of our algorithms on both synthetic and real-life datasets.'}",https://openreview.net{'value': '/pdf/fe772acd191fc8dac2f8a390637d150a704409e9.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=6k3oFS3Lbl,{'value': 'Reinforce LLM Reasoning through Multi-Agent Reflection'},Yurun Yuan; Tengyang Xie,~Yurun_Yuan1; ~Tengyang_Xie1,"{'value': ['Post-training', 'LLM-based multi-agents', 'Reinforcement learning', 'Mathematical reasoning']}","{'value': 'Leveraging more test-time computation has proven to be an effective way to boost the reasoning capabilities of large language models (LLMs). Among various methods, the verify-and-improve paradigm stands out for enabling dynamic solution exploration and feedback incorporation. However, existing approaches often suffer from restricted feedback spaces and lack of coordinated training of different parties, leading to suboptimal performance. To address this, we model this multi-turn refinement process as a Markov Decision Process and introduce DPSDP (**D**irect **P**olicy **S**earch by **D**ynamic **P**rogramming), a reinforcement learning algorithm that trains an actor-critic LLM system to iteratively refine answers via direct preference learning on self-generated data. Theoretically, DPSDP can match the performance of any policy within the training distribution. Empirically, we instantiate DPSDP with various base models and show improvements on both in- and out-of-distribution benchmarks. For example, on benchmark MATH 500, majority voting over five refinement steps increases first-turn accuracy from 58.2% to 63.2% with Ministral-based models. An ablation study further confirms the benefits of multi-agent collaboration and out-of-distribution generalization.'}",https://openreview.net{'value': '/pdf/50a7e7bd4bf758a62b3349ba2ddd0579de2839e4.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=6UIer20oYA,{'value': 'Understanding the Forgetting of (Replay-based) Continual Learning via Feature Learning: Angle Matters'},Hongyi Wan; Shiyuan Ren; Wei Huang; Miao Zhang; Xiang Deng; Yixin Bao; Liqiang Nie,~Hongyi_Wan1; ~Shiyuan_Ren1; ~Wei_Huang6; ~Miao_Zhang4; ~Xiang_Deng1; ~Yixin_Bao1; ~Liqiang_Nie2,"{'value': ['Continual learning', 'Feature learning theory', 'Replay method']}","{'value': ""Continual learning (CL) is crucial for advancing human-level intelligence, but its theoretical understanding, especially regarding factors influencing forgetting, is still relatively limited. This work aims to build a unified theoretical framework for understanding CL using feature learning theory. Different from most existing studies that analyze forgetting under linear regression model or lazy training, we focus on a more practical two-layer convolutional neural network (CNN) with polynomial ReLU activation for sequential tasks within a signal-noise data model. Specifically, we theoretically reveal how the angle between task signal vectors influences forgetting that: *acute or small obtuse angles lead to benign forgetting, whereas larger obtuse angles result in harmful forgetting*. Furthermore, we demonstrate that the replay method alleviates forgetting by expanding the range of angles corresponding to benign forgetting. Our theoretical results suggest that mid-angle sampling, which selects examples with moderate angles to the prototype, can enhance the replay method's ability to mitigate forgetting. Experiments on synthetic and real-world datasets confirm our theoretical results and highlight the effectiveness of our mid-angle sampling strategy.""}",https://openreview.net{'value': '/pdf/dfbd19a1c440fb2a625e1e3effcaaa3ce993213a.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=6TDSDdgP7Z,{'value': 'SyncMind: Measuring Agent Out-of-Sync Recovery in Collaborative Software Engineering'},Xuehang Guo; Xingyao Wang; Yangyi Chen; Sha Li; Chi Han; Manling Li; Heng Ji,~Xuehang_Guo1; ~Xingyao_Wang1; ~Yangyi_Chen1; ~Sha_Li1; ~Chi_Han1; ~Manling_Li1; ~Heng_Ji3,"{'value': ['Collaborative Software Engineering', 'Collaborative Systems', 'Human-AI Interaction', 'Agent Evaluation', 'Benchmark Construction', 'Large Language Models']}","{'value': ""Software engineering (SE) is increasingly collaborative, with developers working together on shared complex codebases. Effective collaboration in shared environments requires participants---whether humans or AI agents---to stay on the same page as their environment evolves. When a collaborator's understanding diverges from the current state---what we term the *out-of-sync* challenge---the collaborator's actions may fail, leading to integration issues. In this work, we introduce **SyncMind**, a framework that systematically defines the *out-of-sync* problem faced by large language model (LLM) agents in collaborative software engineering (CSE). Based on ***SyncMind***, we create **SyncBench**, a benchmark featuring 24,332 instances of agent *out-of-sync* scenarios in real-world CSE derived from 21 popular *GitHub* repositories with executable verification tests. Experiments on ***SyncBench*** uncover critical insights into existing LLM agents' capabilities and limitations. Besides substantial performance gaps among agents (from *Llama-3.1* agents $\\leq 3.33\\%$ to *Claude-3.5-Sonnet* $\\geq 28.18\\%$), their consistently low collaboration willingness ($\\le 4.86\\%$) suggests fundamental limitations of existing LLM in CSE. However, when collaboration occurs, it positively correlates with *out-of-sync* recovery success. Minimal performance differences in agents' resource-aware *out-of-sync* recoveries further reveal their significant lack of resource awareness and adaptability, shedding light on future development of resource-efficient collaborative systems. Our code and data are openly available on our project website: https://xhguo7.github.io/SyncMind/.""}",https://openreview.net{'value': '/pdf/459416e63ca7008561801619a22a7a580c87df95.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=6EZ3MDDf6p,{'value': 'DISCO: learning to DISCover an evolution Operator for multi-physics-agnostic prediction'},Rudy Morel; Jiequn Han; Edouard Oyallon,~Rudy_Morel1; ~Jiequn_Han1; ~Edouard_Oyallon1,"{'value': ['PDEs', 'prediction', 'hypernetwork', 'transformer', 'neuralPDE']}","{'value': 'We address the problem of predicting the next states of a dynamical system governed by *unknown* temporal partial differential equations (PDEs) using only a short trajectory. While standard transformers provide a natural black-box solution to this task, the presence of a well-structured evolution operator in the data  suggests a more tailored and efficient approach. Specifically, when the PDE is fully known, classical numerical solvers can evolve the state accurately with only a few parameters. Building on this observation, we introduce DISCO, a model that uses a large hypernetwork to process a short trajectory and generate the parameters of a much smaller operator network, which then predicts the next states through time integration. Our framework decouples dynamics estimation -- i.e., DISCovering an evolution Operator from a short trajectory -- from state prediction -- i.e., evolving this operator. Experiments show that pretraining our model on diverse physics datasets achieves state-of-the-art performance while requiring significantly fewer epochs. Moreover, it generalizes well to unseen initial conditions and remains competitive when fine-tuned on downstream tasks.'}",https://openreview.net{'value': '/pdf/ce52570474d85dc3919c4d534538753d9f3a8c32.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=6CAgbrjHTc,{'value': 'Cradle: Empowering Foundation Agents towards General Computer Control'},Weihao Tan; Wentao Zhang; Xinrun Xu; Haochong Xia; Ziluo Ding; Boyu Li; Bohan Zhou; Junpeng Yue; Jiechuan Jiang; Yewen Li; Ruyi An; Molei Qin; Chuqiao Zong; Longtao Zheng; YuJie Wu; Xiaoqiang Chai; Yifei Bi; Tianbao Xie; Pengjie Gu; Xiyun Li; Ceyao Zhang; Long Tian; Chaojie Wang; Xinrun Wang; Börje F. Karlsson; Bo An; Shuicheng YAN; Zongqing Lu,~Weihao_Tan1; ~Wentao_Zhang9; ~Xinrun_Xu1; ~Haochong_Xia1; ~Ziluo_Ding1; ~Boyu_Li4; ~Bohan_Zhou1; ~Junpeng_Yue1; ~Jiechuan_Jiang1; ~Yewen_Li1; ~Ruyi_An1; ~Molei_Qin1; ~Chuqiao_Zong1; ~Longtao_Zheng1; ~YuJie_Wu5; ~Xiaoqiang_Chai1; ~Yifei_Bi1; ~Tianbao_Xie1; ~Pengjie_Gu1; ~Xiyun_Li1; ~Ceyao_Zhang1; ~Long_Tian1; ~Chaojie_Wang1; ~Xinrun_Wang1; ~Börje_F._Karlsson1; ~Bo_An2; ~Shuicheng_YAN3; ~Zongqing_Lu2,"{'value': ['Foundation Agents', 'Large Multimodal Models', 'Decision-making', 'General Computer Control']}","{'value': ""Despite their success in specific scenarios, existing foundation agents still struggle to generalize across various virtual scenarios, mainly due to the dramatically different encapsulations of environments with manually designed observation and action spaces. To handle this issue, we propose the General Computer Control (GCC) setting to restrict foundation agents to interact with software through the most unified and standardized interface, i.e., using screenshots as input and keyboard and mouse actions as output. We introduce Cradle, a modular and flexible LMM-powered framework, as a preliminary attempt towards GCC. Enhanced by six key modules, Information Gathering, Self-Reflection, Task Inference, Skill Curation, Action Planning, and Memory, Cradle is able to understand input screenshots and output executable code for low-level keyboard and mouse control after high-level planning and information retrieval, so that Cradle can interact with any software and complete long-horizon complex tasks without relying on any built-in APIs. Experimental results show that Cradle exhibits remarkable generalizability and impressive performance across four previously unexplored commercial video games (Red Dead Redemption 2, Cities:Skylines, Stardew Valley and Dealer's Life 2), five software applications (Chrome, Outlook, Feishu, Meitu and CapCut), and a comprehensive benchmark, OSWorld. With a unified interface to interact with any software, Cradle greatly extends the reach of foundation agents thus paving the way for generalist agents.""}",https://openreview.net{'value': '/pdf/3d1e188a8d22526e5f74b4daa4e464094b008106.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=5zwF1GizFa,{'value': 'rStar-Math: Small LLMs Can Master Math Reasoning with Self-Evolved Deep Thinking'},Xinyu Guan; Li Lyna Zhang; Yifei Liu; Ning Shang; Youran Sun; Yi Zhu; Fan Yang; Mao Yang,~Xinyu_Guan5; ~Li_Lyna_Zhang1; ~Yifei_Liu6; ~Ning_Shang1; ~Youran_Sun1; ~Yi_Zhu8; ~Fan_Yang28; ~Mao_Yang1,"{'value': ['LLM', 'Reasoning', 'Self-evolution']}","{'value': 'We present rStar-Math to demonstrate that small language models (SLMs) can rival or even surpass the math reasoning capability of  OpenAI o1, without distillation from superior models. rStar-Math achieves this by exercising ``deep thinking\'\' through Monte Carlo Tree Search (MCTS), where a math policy SLM performs test-time search guided by an SLM-based process reward model. rStar-Math introduces three innovations to tackle the challenges in training the two SLMs: (1) a novel code-augmented CoT data synthesis method, which performs extensive MCTS rollouts to generate step-by-step verified reasoning trajectories used to train the policy SLM; (2) a novel process reward model training method that avoids na\\""ive step-level score annotation, yielding a more effective process preference model (PPM); (3) a self-evolution recipe in which the policy SLM and PPM are built from scratch and iteratively evolved to improve reasoning capabilities. Through 4 rounds of self-evolution with millions of synthesized solutions for 747k math problems, rStar-Math boosts SLMs\' math reasoning to state-of-the-art levels. On MATH benchmark, it improves Qwen2.5-Math-7B from 58.8% to 90.0%, surpassing o1-preview by +4.5%. On the USA Math Olympiad (AIME), rStar-Math solves an average of 53.3% (8/15) of problems, ranking among the top 20% of the brightest high school math students. Code and data are available at https://github.com/microsoft/rStar.'}",https://openreview.net{'value': '/pdf/ec6fb0a1e0beb584ae1475977865ea45b4b0ebbe.pdf'},{'abstract_filter': 'Data Synthesis'},ICML.cc,2025,Conference
https://openreview.net/forum?id=5tyvHfhRFZ,{'value': 'Riemannian Diffusion Adaptation for Distributed Optimization on Manifolds'},Xiuheng Wang; Ricardo Augusto Borsoi; Cédric Richard; Ali H. Sayed,~Xiuheng_Wang1; ~Ricardo_Augusto_Borsoi1; ~Cédric_Richard1; ~Ali_H._Sayed1,"{'value': ['Riemannian optimization', 'decentralized optimization', 'intrinsic method', 'diffusion adaptation', 'stochastic gradient descent', 'network agreement', 'non-asymptotic convergence', 'principle component analysis', 'Gaussian mixture model']}","{'value': 'Online distributed optimization is particularly useful for solving optimization problems with streaming data collected by multiple agents over a network. When the solutions lie on a Riemannian manifold, such problems become challenging to solve, particularly when efficiency and continuous adaptation are required. This work tackles these challenges and devises a diffusion adaptation strategy for decentralized optimization over general manifolds. A theoretical analysis shows that the proposed algorithm is able to approach network agreement after sufficient iterations, which allows a non-asymptotic convergence result to be derived. We apply the algorithm to the online decentralized principal component analysis problem and Gaussian mixture model inference. Experimental results with both synthetic and real data illustrate its performance.'}",https://openreview.net{'value': '/pdf/7d016c1ba956935d1d025bfe0d7b36d3a81f62d9.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=5t2TWcPCvS,{'value': 'Learn to Vaccinate: Combining Structure Learning and Effective Vaccination for Epidemic and Outbreak Control'},Sepehr Elahi; Paula Mürmann; Patrick Thiran,~Sepehr_Elahi1; ~Paula_Mürmann1; ~Patrick_Thiran1,"{'value': ['Structure learning', 'SIS models', 'Epidemics', 'Vaccinations', 'Spectral radius minimization', 'Bounded treewidth', 'Dynamic programming', 'Parameterized algorithms']}","{'value': ""The Susceptible-Infected-Susceptible (SIS) model is a widely used model for the spread of information and infectious diseases, particularly non-immunizing ones, on a graph. Given a highly contagious disease, a natural question is how to best vaccinate individuals to minimize the disease's extinction time. While previous works showed that the problem of optimal vaccination is closely linked to the NP-hard *Spectral Radius Minimization* (SRM) problem, they assumed that the graph is known, which is often not the case in practice. In this work, we consider the problem of minimizing the extinction time of an outbreak modeled by an SIS model where the graph on which the disease spreads is unknown and only the infection states of the vertices are observed. To this end, we split the problem into two: learning the graph and determining effective vaccination strategies. We propose a novel inclusion-exclusion-based learning algorithm and, unlike previous approaches, establish its sample complexity for graph recovery. We then detail an optimal algorithm for the SRM problem and prove that its running time is polynomial in the number of vertices for graphs with bounded treewidth. This is complemented by an efficient and effective polynomial-time greedy heuristic for any graph. Finally, we present experiments on synthetic and real-world data that numerically validate our learning and vaccination algorithms.""}",https://openreview.net{'value': '/pdf/0a4761b772d82f1c509220a3a27a98cb93f7193c.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=5ryn8tYWHL,{'value': 'Conservative Offline Goal-Conditioned Implicit V-Learning'},Kaiqiang Ke; Qian Lin; Zongkai Liu; Shenghong He; Chao Yu,~Kaiqiang_Ke1; ~Qian_Lin3; ~Zongkai_Liu1; ~Shenghong_He3; ~Chao_Yu2,{'value': ['Offline Goal-Conditioned Reinforcement Learning; Goal-Stitching Tasks; Value Function Overestimation;']},"{'value': 'Offline goal-conditioned reinforcement learning (GCRL) learns a goal-conditioned value function to train policies for diverse goals with pre-collected datasets. Hindsight experience replay addresses the issue of sparse rewards by treating intermediate states as goals but fails to complete goal-stitching tasks where achieving goals requires stitching different trajectories. While cross-trajectory sampling is a potential solution that associates states and goals belonging to different trajectories, we demonstrate that this direct method degrades performance in goal-conditioned tasks due to the overestimation of values on unconnected pairs. To this end, we propose Conservative Goal-Conditioned Implicit Value Learning (CGCIVL), a novel algorithm that introduces a penalty term to penalize value estimation for unconnected state-goal pairs and leverages the quasimetric framework to accurately estimate values for connected pairs. Evaluations on OGBench, a benchmark for offline GCRL, demonstrate that CGCIVL consistently surpasses state-of-the-art methods across diverse tasks.'}",https://openreview.net{'value': '/pdf/fb75dd8b7df45c8ab1150a840be5b52dac73c988.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=5Wk0L4vjhV,{'value': 'Graph Attention is Not Always Beneficial: A Theoretical Analysis of Graph Attention Mechanisms via Contextual Stochastic Block Models'},Zhongtian Ma; Qiaosheng Zhang; Bocheng Zhou; Yexin Zhang; Shuyue Hu; Zhen Wang,~Zhongtian_Ma1; ~Qiaosheng_Zhang2; ~Bocheng_Zhou1; ~Yexin_Zhang3; ~Shuyue_Hu1; ~Zhen_Wang11,"{'value': ['graph attention mechanisms', 'node classification', 'contextual stochastic block models', 'over-smoothing', 'graph convolution', 'perfect node classification']}","{'value': 'Despite the growing popularity of graph attention mechanisms, their theoretical understanding remains limited. This paper aims to explore the conditions under which these mechanisms are effective in node classification tasks through the lens of Contextual Stochastic Block Models (CSBMs). Our theoretical analysis reveals that incorporating graph attention mechanisms is *not universally beneficial*. Specifically, by appropriately defining *structure noise* and *feature noise* in graphs, we show that graph attention mechanisms can enhance classification performance when structure noise exceeds feature noise. Conversely, when feature noise predominates, simpler graph convolution operations are more effective. Furthermore, we examine the over-smoothing phenomenon and show that, in the high signal-to-noise ratio (SNR) regime, graph convolutional networks suffer from over-smoothing, whereas graph attention mechanisms can effectively resolve this issue. Building on these insights, we propose a novel multi-layer Graph Attention Network (GAT) architecture that significantly outperforms single-layer GATs in achieving *perfect node classification* in CSBMs, relaxing the SNR requirement from $\\omega(\\sqrt{\\log n})$ to $\\omega(\\sqrt{\\log n} / \\sqrt[3]{n})$. To our knowledge, this is the first study to delineate the conditions for perfect node classification using multi-layer GATs. Our theoretical contributions are corroborated by extensive experiments on both synthetic and real-world datasets, highlighting the practical implications of our findings.'}",https://openreview.net{'value': '/pdf/d666d3384ae8d4ef6bd74594cdda15007a81f018.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=5TUa2UXSpp,{'value': 'Learning Optimal Multimodal Information Bottleneck Representations'},Qilong Wu; Yiyang Shao; Jun Wang; Xiaobo Sun,~Qilong_Wu3; ~Yiyang_Shao3; ~Jun_Wang1; ~Xiaobo_Sun1,{'value': ['Multimodal Learning; Information Bottleneck']},"{'value': ""Leveraging high-quality joint representations from multimodal data can greatly enhance model performance in various machine-learning based applications. Recent multimodal learning methods, based on the multimodal information bottleneck (MIB) principle, aim to generate optimal MIB with maximal task-relevant information and minimal superfluous information via regularization. However, these methods often set regularization weights in an *ad hoc* manner and overlook imbalanced task-relevant information across modalities, limiting their ability to achieve optimal MIB. To address this gap, we propose a novel multimodal learning framework, Optimal Multimodal Information Bottleneck (OMIB), whose optimization objective guarantees the achievability of optimal MIB by setting the regularization weight within a theoretically derived bound. OMIB further addresses imbalanced task-relevant information by dynamically adjusting regularization weights per modality, ensuring the inclusion of all task-relevant information. Moreover, we establish a solid information-theoretical foundation for OMIB's optimization and implement it under the variational approximation framework for computational efficiency. Finally, we empirically validate the OMIB’s theoretical properties on synthetic data and demonstrate its superiority over the state-of-the-art benchmark methods in various downstream tasks.""}",https://openreview.net{'value': '/pdf/51968f06d44f548d66c447b36509021f58b1d73b.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=5QAKPBVdFH,{'value': 'Hide & Seek: Transformer Symmetries Obscure Sharpness & Riemannian Geometry Finds It'},Marvin F. da Silva; Felix Dangel; Sageev Oore,~Marvin_F._da_Silva1; ~Felix_Dangel1; ~Sageev_Oore1,"{'value': ['generalization', 'symmetry', 'sharpness', 'flatness', 'riemannian geometry', 'loss landscape']}","{'value': 'The concept of sharpness has been successfully applied to traditional architectures like MLPs and CNNs to predict their generalization. For transformers, however, recent work reported weak correlation between flatness and generalization. We argue that existing sharpness measures fail for transformers, because they have much richer symmetries in their attention mechanism that induce directions in parameter space along which the network or its loss remain identical. We posit that sharpness must account fully for these symmetries, and thus we redefine it on a quotient manifold that results from quotienting out the transformer symmetries, thereby removing their ambiguities. Leveraging tools from Riemannian geometry, we propose a fully general notion of sharpness, in terms of a geodesic ball on the symmetry-corrected quotient manifold. In practice, we need to resort to approximating the geodesics. Doing so up to first order yields existing adaptive sharpness measures, and we demonstrate that including higher-order terms is crucial to recover correlation with generalization. We present results on diagonal networks with synthetic data, and show that our geodesic sharpness reveals strong correlation for real-world transformers on both text and image classification tasks.'}",https://openreview.net{'value': '/pdf/c37e40aed10aa72aed4e76053cecd9e389eeb710.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=5KszXnnkG5,{'value': 'Cowpox: Towards the Immunity of VLM-based Multi-Agent Systems'},YUTONG WU; Jie Zhang; Yiming Li; Chao Zhang; Qing Guo; Han Qiu; Nils Lukas; Tianwei Zhang,~YUTONG_WU3; ~Jie_Zhang11; ~Yiming_Li1; ~Chao_Zhang18; ~Qing_Guo3; ~Han_Qiu3; ~Nils_Lukas1; ~Tianwei_Zhang1,"{'value': ['VLM', 'Adversarial Examples', 'Infectious Attack']}","{'value': ""Vision Language Model (VLM) Agents are stateful, autonomous entities capable of perceiving and interacting with their environments through vision and language.\nMulti-agent systems comprise specialized agents who collaborate to solve a (complex) task. \nA core security property is **robustness**, stating that the system maintains its integrity during adversarial attacks. \nMulti-agent systems lack robustness, as a successful exploit against one agent can spread and **infect** other agents to undermine the entire system's integrity. \nWe propose a defense Cowpox to provably enhance the robustness of a multi-agent system by a distributed mechanism that improves the **recovery rate** of agents by limiting the expected number of infections to other agents.\nThe core idea is to generate and distribute a special *cure sample* that immunizes an agent against the attack before exposure. \nWe demonstrate the effectiveness of Cowpox empirically and provide theoretical robustness guarantees.""}",https://openreview.net{'value': '/pdf/1d6cf7b7260f49ced37bc771dce3b9e8516c66db.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=51x0dfsD8A,"{'value': 'Hierarchical Overlapping Clustering on Graphs: Cost Function, Algorithm and Scalability'}",Yicheng Pan; Renjie Chen; Pengyu Long; Bingchen Fan,~Yicheng_Pan1; ~Renjie_Chen1; ~Pengyu_Long1; ~Bingchen_Fan1,"{'value': ['hierarchical overlapping clustering', 'approximation algorithm', 'scalability']}","{'value': 'Hierarchical and overlapping clustering are two prevalent phenomena that often coexist in real-world system. While numerous studies have examined these two structures separately, characterizing and evaluating their hybrid forms remains an open challenge. To bridge this gap, we initiate the study of hierarchical overlapping clustering on graphs by introducing a new cost function and establishing its rationality through several intuitive properties. We further develop an approximation algorithm that achieves a constant approximation factor for its dual version. Our approach employs a recursive overlapping bipartition framework based on local search, enabling a highly scalable speed-up variant. Experimental results demonstrate that this speed-up algorithm outperforms all baseline methods significantly in both effectiveness (across synthetic and real datasets) and scalability.'}",https://openreview.net{'value': '/pdf/b8245d984a43970d39a9434ff6f29da519f7450c.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=51SFypI0J8,{'value': 'Enhancing Diversity In Parallel Agents: A Maximum State Entropy Exploration Story'},Vincenzo de paola; Riccardo Zamboni; Mirco Mutti; Marcello Restelli,~Vincenzo_de_paola2; ~Riccardo_Zamboni1; ~Mirco_Mutti1; ~Marcello_Restelli1,"{'value': ['Maximum State Entropy', 'Parallel Reinforcement Learning', ""Agents' Diversity""]}","{'value': 'Parallel data collection has redefined Reinforcement Learning (RL), unlocking unprecedented efficiency and powering breakthroughs in large-scale real-world applications. In this paradigm, $N$ identical agents operate in $N$ replicas of an environment simulator, accelerating data collection by a factor of $N$. A critical question arises: *Does specializing the policies of the parallel agents hold the key to surpass the $N$ factor acceleration?*\nIn this paper, we introduce a novel learning framework that maximizes the entropy of collected data in a parallel setting. Our approach carefully balances the entropy of individual agents with inter-agent diversity, effectively minimizing redundancies. The latter idea is implemented with a centralized policy gradient method, which shows promise when evaluated empirically against systems of identical agents, as well as synergy with batch RL techniques that can exploit data diversity.\nFinally, we provide an original concentration analysis that shows faster rates for specialized parallel sampling distributions, which supports our methodology and may be of independent interest.'}",https://openreview.net{'value': '/pdf/6104473df86966e414e52bf7f4dbf999750e9abb.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=4tFSKOY2mT,{'value': 'What Limits Virtual Agent Application? OmniBench: A Scalable Multi-Dimensional Benchmark for Essential Virtual Agent Capabilities'},Wendong Bu; Yang Wu; Qifan Yu; Minghe Gao; Bingchen Miao; Zhenkui Zhang; Kaihang Pan; liyunfei; Mengze Li; Wei Ji; Juncheng Li; Siliang Tang; Yueting Zhuang,~Wendong_Bu1; ~Yang_Wu16; ~Qifan_Yu1; ~Minghe_Gao1; ~Bingchen_Miao1; ~Zhenkui_Zhang1; ~Kaihang_Pan1; ~liyunfei1; ~Mengze_Li2; ~Wei_Ji1; ~Juncheng_Li3; ~Siliang_Tang1; ~Yueting_Zhuang1,{'value': ['Virtual Agent; Digital Agent; Multidimensional Benchmark']},"{'value': 'As multimodal large language models (MLLMs) advance, MLLM-based virtual agents have demonstrated remarkable performance. However, existing benchmarks face significant limitations, including uncontrollable task complexity, extensive manual annotation, and a lack of multidimensional evaluation. In response to these challenges, we introduce OmniBench, a self-generating, graph-based benchmark with an automated pipeline for synthesizing tasks of controllable complexity through subtask composition. To evaluate the diverse capabilities of virtual agents on the graph, we further present OmniEval, a multidimensional evaluation framework that includes subtask-level evaluation, graph-based metrics, and comprehensive tests across 10 capabilities. Our synthesized dataset contains 36k graph-structured tasks across 20 scenarios, achieving a 91% human acceptance rate. Training on our graph-structured data shows that it improves generalization across environments. We conduct multidimensional evaluations for virtual agents, revealing their performance across various capabilities and paving the way for future advancements. Our project is available at https://omni-bench.github.io.'}",https://openreview.net{'value': '/pdf/d5d3691187b9f32f92e8e287e5005d40aa429f80.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=4skvLszxZ1,{'value': 'Ultra-Resolution Adaptation with Ease'},Ruonan Yu; Songhua Liu; Zhenxiong Tan; Xinchao Wang,~Ruonan_Yu1; ~Songhua_Liu2; ~Zhenxiong_Tan1; ~Xinchao_Wang1,"{'value': ['Ultra-Resolution Generation', 'Efficient Tuning', 'Synthetic Data', 'Diffusion Models']}","{'value': 'Text-to-image diffusion models have achieved remarkable progress in recent years. However, training models for high-resolution image generation remains challenging, particularly when training data and computational resources are limited. In this paper, we explore this practical problem from two key perspectives: data and parameter efficiency, and propose a set of key guidelines for ultra-resolution adaptation termed URAE. For data efficiency, we theoretically and empirically demonstrate that synthetic data generated by some teacher models can significantly promote training convergence. For parameter efficiency, we find that tuning minor components of the weight matrices outperforms widely-used low-rank adapters when synthetic data are unavailable, offering substantial performance gains while maintaining efficiency. Additionally, for models leveraging guidance distillation, such as FLUX, we show that disabling classifier-free guidance, i.e., setting the guidance scale to 1 during adaptation, is crucial for satisfactory performance. Extensive experiments validate that URAE achieves comparable 2K-generation performance to state-of-the-art closed-source models like FLUX1.1 [Pro] Ultra with only 3K samples and 2K iterations, while setting new benchmarks for 4K-resolution generation. Codes are available [here](https://github.com/Huage001/URAE).'}",https://openreview.net{'value': '/pdf/4f2acdd2ef9e9782715d761e2c8098d8161f5214.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=4lfmCCYKDY,{'value': 'Learning Likelihood-Free Reference Priors'},Nicholas George Bishop; Daniel Jarne Ornia; Joel Dyer; Ani Calinescu; Michael J. Wooldridge,~Nicholas_George_Bishop1; ~Daniel_Jarne_Ornia1; ~Joel_Dyer1; ~Ani_Calinescu1; ~Michael_J._Wooldridge1,"{'value': ['simulation-based inference', 'objective Bayes', 'reference priors', 'variational approximations', 'mutual information']}","{'value': ""Simulation modeling offers a flexible approach to constructing high-fidelity synthetic representations of complex real-world systems. However, the increased complexity of such models introduces additional complications, for example when carrying out statistical inference procedures. This has motivated a large and growing literature on *likelihood-free* or *simulation-based* inference methods, which approximate (e.g., Bayesian) inference without assuming access to the simulator's intractable likelihood function.  A hitherto neglected problem in the simulation-based Bayesian inference literature is the challenge of constructing minimally informative *reference priors* for complex simulation models. Such priors maximise an expected Kullback-Leibler distance from the prior to the posterior, thereby influencing posterior inferences minimally and enabling an ``objective'' approach to Bayesian inference that does not necessitate the incorporation of strong subjective prior beliefs. In this paper, we propose and test a selection of likelihood-free methods for learning reference priors for simulation models, using variational approximations to these priors and a variety of mutual information estimators. Our experiments demonstrate that good approximations to reference priors for simulation models are in this way attainable, providing a first step towards the development of likelihood-free objective Bayesian inference procedures.""}",https://openreview.net{'value': '/pdf/4afbf5babd19c6c68bec3f3fe69d2b26ea86df4c.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=4aXfSLfM0Z,{'value': 'Compositional Flows for 3D Molecule and Synthesis Pathway Co-design'},Tony Shen; Seonghwan Seo; Ross Irwin; Kieran Didi; Simon Olsson; Woo Youn Kim; Martin Ester,~Tony_Shen1; ~Seonghwan_Seo1; ~Ross_Irwin1; ~Kieran_Didi1; ~Simon_Olsson1; ~Woo_Youn_Kim1; ~Martin_Ester1,"{'value': ['drug discovery', 'synthesizable molecular design', 'GFlowNets', 'flow matching']}","{'value': ""Many generative applications, such as synthesis-based 3D molecular design, involve constructing compositional objects with continuous features.\nHere, we introduce Compositional Generative Flows (CGFlow), a novel framework that extends flow matching to generate objects in compositional steps while modeling continuous states. \nOur key insight is that modeling compositional state transitions can be formulated as a straightforward extension of the flow matching interpolation process.\nWe further build upon the theoretical foundations of generative flow networks (GFlowNets), enabling reward-guided sampling of compositional structures. \nWe apply CGFlow to synthesizable drug design by jointly designing the molecule's synthetic pathway with its 3D binding pose.\nOur approach achieves state-of-the-art binding affinity and synthesizability on all 15 targets from the LIT-PCBA benchmark, and 4.2x improvement in sampling efficiency compared to 2D synthesis-based baseline.\nTo our best knowledge, our method is also the first to achieve state of-art-performance in both Vina Dock (-9.42) and AiZynth success rate (36.1\\%) on the CrossDocked2020 benchmark.""}",https://openreview.net{'value': '/pdf/244d8124865e242a22a5f494a1624c39fb2a15b1.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=4R0pugRyN5,{'value': 'Sparse Autoencoders for Hypothesis Generation'},Rajiv Movva; Kenny Peng; Nikhil Garg; Jon Kleinberg; Emma Pierson,~Rajiv_Movva1; ~Kenny_Peng1; ~Nikhil_Garg2; ~Jon_Kleinberg3; ~Emma_Pierson1,"{'value': ['interpretability', 'hypothesis generation', 'sparse autoencoders', 'computational social science', 'topic modeling']}","{'value': 'We describe HypotheSAEs, a general method to hypothesize interpretable relationships between text data (e.g., headlines) and a target variable (e.g., clicks). HypotheSAEs has three steps: (1) train a sparse autoencoder on text embeddings to produce interpretable features describing the data distribution, (2) select features that predict the target variable, and (3) generate a natural language interpretation of each feature (e.g., *mentions being surprised or shocked*) using an LLM. Each interpretation serves as a hypothesis about what predicts the target variable. Compared to baselines, our method better identifies reference hypotheses on synthetic datasets (at least +0.06 in F1) and produces more predictive hypotheses on real datasets (~twice as many significant findings), despite requiring 1-2 orders of magnitude less compute than recent LLM-based methods. HypotheSAEs also produces novel discoveries on two well-studied tasks: explaining partisan differences in Congressional speeches and identifying drivers of engagement with online headlines.'}",https://openreview.net{'value': '/pdf/b1823f0e5bb2ac30498dffadc3bdbb838cf0da87.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=4QcFfTu6UT,{'value': 'Winner-takes-all for Multivariate Probabilistic Time Series Forecasting'},Adrien Cortes; Remi Rehm; Victor Letzelter,~Adrien_Cortes1; ~Remi_Rehm1; ~Victor_Letzelter1,"{'value': ['Time-series forecasting', 'Quantization', 'Probabilistic methods', 'Conditional Distribution Estimation', 'Winner-takes-all', 'Diversity', 'Multiple Choice Learning']}","{'value': 'We introduce $\\texttt{TimeMCL}$, a method leveraging the Multiple Choice Learning (MCL) paradigm to forecast multiple plausible time series futures. Our approach employs a neural network with multiple heads and utilizes the Winner-Takes-All (WTA) loss to promote diversity among predictions. MCL has recently gained attention due to its simplicity and ability to address ill-posed and ambiguous tasks. We propose an adaptation of this framework for time-series forecasting, presenting it as an efficient method to predict diverse futures, which we relate to its implicit *quantization* objective. We provide insights into our approach using synthetic data and evaluate it on real-world time series, demonstrating its promising performance at a light computational cost.'}",https://openreview.net{'value': '/pdf/db68225907ef089cca565a5831bf6b0228800932.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=4JyULSyPl6,{'value': 'Learning to Incentivize in Repeated Principal-Agent Problems with Adversarial Agent Arrivals'},Junyan Liu; Arnab Maiti; Artin Tajdini; Kevin Jamieson; Lillian J. Ratliff,~Junyan_Liu1; ~Arnab_Maiti1; ~Artin_Tajdini1; ~Kevin_Jamieson1; ~Lillian_J._Ratliff1,"{'value': ['Principal-agent problem', 'Incentive design', 'Regret Minimization', 'Adversarial', 'Greedy response', 'Lipschitz response']}","{'value': ""We initiate the study of a repeated principal-agent problem over a finite horizon $T$, where a principal sequentially interacts with $K\\geq 2$ types of agents arriving in an *adversarial* order. At each round, the principal strategically chooses one of the $N$ arms to incentivize for an arriving agent of *unknown type*.  The agent then chooses an arm based on its own utility and the provided incentive, and the principal receives a corresponding reward. The objective is to minimize regret against the best incentive in hindsight. Without prior knowledge of agent behavior, we show that the problem becomes intractable, leading to linear regret. We analyze two key settings where sublinear regret is achievable. In the first setting, the principal knows the arm each agent type would select greedily for any given incentive. Under this setting, we propose an algorithm that achieves a regret bound of $\\mathcal{O}(\\min(\\sqrt{KT\\log N},K\\sqrt{T}))$ and provide a matching lower bound up to a $\\log K$ factor. In the second setting, an agent's response varies smoothly with the incentive and is governed by a Lipschitz constant $L$. Under this setting, we show that there is an algorithm with a regret bound of $\\tilde{\\mathcal{O}}((LN)^{1/3}T^{2/3})$ and establish a matching lower bound up to logarithmic factors. Finally, we extend our algorithmic results for both settings by allowing the principal to incentivize multiple arms simultaneously in each round.""}",https://openreview.net{'value': '/pdf/a65fed70ab6f69e55ab9b5b5eca6efb7cd4ff5a1.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=4EYwwVuhtG,{'value': 'Statistical Test for Feature Selection Pipelines by Selective Inference'},Tomohiro Shiraishi; Tatsuya Matsukawa; Shuichi Nishino; Ichiro Takeuchi,~Tomohiro_Shiraishi1; ~Tatsuya_Matsukawa1; ~Shuichi_Nishino1; ~Ichiro_Takeuchi1,"{'value': ['Data Analysis Pipeline', 'AutoML', 'Statistical Test', 'Selective Inference', 'Missing Value Imputation', 'Outlier Detection', 'Feature Selection']}","{'value': 'A data analysis pipeline is a structured sequence of steps that transforms raw data into meaningful insights by integrating various analysis algorithms. In this paper, we propose a novel statistical test to assess the significance of data analysis pipelines. Our approach enables the systematic development of valid statistical tests applicable to any feature selection pipeline composed of predefined components. We develop this framework based on selective inference, a statistical technique that has recently gained attention for data-driven hypotheses. As a proof of concept, we focus on feature selection pipelines for linear models, composed of three missing value imputation algorithms, three outlier detection algorithms, and three feature selection algorithms. We theoretically prove that our statistical test can control the probability of false positive feature selection at any desired level, and demonstrate its validity and effectiveness through experiments on synthetic and real data. Additionally, we present an implementation framework that facilitates testing across any configuration of these feature selection pipelines without extra implementation costs.'}",https://openreview.net{'value': '/pdf/aa1facf7b95d69656bb23618a299c22883e80e45.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=4ESwnU0kCA,{'value': 'Sampling Binary Data by Denoising through Score Functions'},Francis Bach; Saeed Saremi,~Francis_Bach1; ~Saeed_Saremi1,"{'value': ['Langevin MCMC', 'score function', 'Boolean hypercube', 'Bernoulli noise']}","{'value': 'Gaussian smoothing combined with a probabilistic framework for denoising via the empirical Bayes formalism, i.e., the Tweedie-Miyasawa formula (TMF), are the two key ingredients in the success of score-based generative models in Euclidean spaces. Smoothing holds the key for easing the problem of learning and sampling in high dimensions, denoising is needed for recovering the original signal, and TMF ties these together via the score function of noisy data. In this work, we extend this paradigm to the problem of learning and sampling the distribution of binary data on the Boolean hypercube by adopting Bernoulli noise, instead of Gaussian noise, as a smoothing device. We first derive a TMF-like expression for the optimal denoiser for the Hamming loss, where a score function naturally appears. Sampling noisy binary data is then achieved using a Langevin-like sampler which we theoretically analyze for different noise levels. At high Bernoulli noise levels sampling becomes easy, akin to log-concave sampling in Euclidean spaces. In addition, we extend the sequential multi-measurement sampling of Saremi et al. (2024) to the binary setting where we can bring the ""effective noise"" down by sampling multiple noisy measurements at a fixed noise level, without the need for continuous-time stochastic processes. We validate our formalism and theoretical findings by experiments on synthetic data and binarized images.'}",https://openreview.net{'value': '/pdf/41596efdfd27f5295a1035d8d581dedd4819120a.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=4BfaPHfhJ0,{'value': 'Do We Need to Verify Step by Step? Rethinking Process Supervision from a Theoretical Perspective'},Zeyu Jia; Alexander Rakhlin; Tengyang Xie,~Zeyu_Jia1; ~Alexander_Rakhlin1; ~Tengyang_Xie1,"{'value': ['Reinforcement Learning Theory', 'Process Supervision', 'Outcome Supervision', 'Reward Modeling', 'Markov Decision Process']}","{'value': ""Process and outcome supervision represent two fundamental approaches to   reinforcement learning, especially for complex reasoning tasks in large language models. While process supervision offers intuitive advantages for long-term credit assignment, the precise relationship between these paradigms has remained an open question. Conventional wisdom suggests that outcome supervision is fundamentally more challenging due to the trajectory-level coverage problem, leading to significant investment in collecting fine-grained process supervision data.\n\nIn this paper, we provide a possible theoretical resolution to this debate. Perhaps surprisingly, our main theorem shows that: *under standard data coverage assumptions, reinforcement learning through outcome supervision is no more statistically difficult than through process supervision*. At the core of this result lies the novel *Change of Trajectory Measure Lemma*---a powerful technical tool that bridges return-based trajectory measure and step-level distribution shift. Furthermore, for settings with access to a verifier or a rollout capability, we prove that any policy's advantage function can serve as an optimal process reward model, providing a simple yet powerful connection between outcome and process supervision. These findings suggest that the empirically observed performance gap between outcome and process supervision likely stems from algorithmic limitations rather than inherent statistical difficulties, potentially transforming how we approach data and algorithm design for reinforcement learning.""}",https://openreview.net{'value': '/pdf/acb91dfce22c966e1f01bef6896d46118dd34b6b.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=3zWSmhNSa7,{'value': 'Scalable First-order Method for Certifying Optimal k-Sparse GLMs'},Jiachang Liu; Soroosh Shafiee; Andrea Lodi,~Jiachang_Liu1; ~Soroosh_Shafiee1; ~Andrea_Lodi1,"{'value': ['generalized linear models', 'sparse learning', 'proximal method', 'mixed-integer programming']}","{'value': 'This paper investigates the problem of certifying optimality for sparse generalized linear models (GLMs), where sparsity is enforced through an $\\ell_0$ cardinality constraint. While branch-and-bound (BnB) frameworks can certify optimality by pruning nodes using dual bounds, existing methods for computing these bounds are either computationally intensive or exhibit slow convergence, limiting their scalability to large-scale problems. To address this challenge, we propose a first-order proximal gradient algorithm designed to solve the perspective relaxation of the problem within a BnB framework. Specifically, we formulate the relaxed problem as a composite optimization problem and demonstrate that the proximal operator of the non-smooth component can be computed exactly in log-linear time complexity, eliminating the need to solve a computationally expensive second-order cone program. Furthermore, we introduce a simple restart strategy that enhances convergence speed while maintaining low per-iteration complexity. Extensive experiments on synthetic and real-world datasets show that our approach significantly accelerates dual bound computations and is highly effective in providing optimality certificates for large-scale problems.'}",https://openreview.net{'value': '/pdf/28acc0db757beda228af73d80d37749deec3cd16.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=3xznpzabYQ,{'value': 'Deep Neural Cellular Potts Models'},Koen Minartz; Tim D'Hondt; Leon Hillmann; Jörn Starruß; Lutz Brusch; Vlado Menkovski,~Koen_Minartz1; ~Tim_D'Hondt1; ~Leon_Hillmann1; ~Jörn_Starruß1; ~Lutz_Brusch1; ~Vlado_Menkovski2,"{'value': ['Cellular Potts Models', 'Multi-Cell Dynamics', 'Cell Migration', 'Energy-Based Models', 'Simulation']}","{'value': 'The cellular Potts model (CPM) is a powerful computational method for simulating collective spatiotemporal dynamics of biological cells.\nTo drive the dynamics, CPMs rely on physics-inspired Hamiltonians. However, as first principles remain elusive in biology, these Hamiltonians only approximate the full complexity of real multicellular systems.\nTo address this limitation, we propose NeuralCPM, a more expressive cellular Potts model that can be trained directly on observational data.\nAt the core of NeuralCPM lies the Neural Hamiltonian, a neural network architecture that respects universal symmetries in collective cellular dynamics.\nMoreover, this approach enables seamless integration of domain knowledge by combining known biological mechanisms and the expressive Neural Hamiltonian into a hybrid model.\nOur evaluation with synthetic and real-world multicellular systems demonstrates that NeuralCPM is able to model cellular dynamics that cannot be accounted for by traditional analytical Hamiltonians.'}",https://openreview.net{'value': '/pdf/755c7887ffcc629a2ab30ba7d7658eb68955eeb3.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=3xvnJS8H1v,{'value': 'Prediction-Powered Adaptive Shrinkage Estimation'},Sida Li; Nikolaos Ignatiadis,~Sida_Li1; ~Nikolaos_Ignatiadis1,"{'value': ['prediction powered inference', 'shrinkage estimation']}","{'value': 'Prediction-Powered Inference (PPI) is a powerful framework for enhancing statistical estimates by combining limited gold-standard data with machine learning (ML) predictions. While prior work has demonstrated PPI’s benefits for individual statistical problems, modern applications require answering numerous parallel statistical questions. We introduce Prediction-Powered Adaptive Shrinkage ($\\texttt{PAS}$), a method that bridges PPI with empirical Bayes shrinkage to improve estimation of multiple means. $\\texttt{PAS}$ debiases noisy ML predictions $\\textit{within}$ each task and then borrows strength $\\textit{across}$ tasks by using those same predictions as a reference point for shrinkage. The amount of shrinkage is determined by minimizing an unbiased estimate of risk, and we prove that this tuning strategy is asymptotically optimal. Experiments on both synthetic and real-world datasets show that $\\texttt{PAS}$ adapts to the reliability of the ML predictions and outperforms traditional and modern baselines in large-scale applications.'}",https://openreview.net{'value': '/pdf/0d15ec8e8783ce4c3f412a08b71720415365a5c2.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=3rB0bVU6z6,{'value': 'RE-Bench: Evaluating Frontier AI R&D Capabilities of Language Model Agents against Human Experts'},Hjalmar Wijk; Tao Roa Lin; Joel Becker; Sami Jawhar; Neev Parikh; Thomas Broadley; Lawrence Chan; Michael Chen; Joshua M Clymer; Jai Dhyani; Elena Ericheva; Katharyn Garcia; Brian Goodrich; Nikola Jurkovic; Megan Kinniment; Aron Lajko; Seraphina Nix; Lucas Jun Koba Sato; William Saunders; Maksym Taran; Ben West; Elizabeth Barnes,~Hjalmar_Wijk1; ~Tao_Roa_Lin1; ~Joel_Becker1; ~Sami_Jawhar1; ~Neev_Parikh1; ~Thomas_Broadley1; ~Lawrence_Chan2; ~Michael_Chen3; ~Joshua_M_Clymer1; ~Jai_Dhyani1; ~Elena_Ericheva1; ~Katharyn_Garcia1; ~Brian_Goodrich1; ~Nikola_Jurkovic1; ~Megan_Kinniment1; ~Aron_Lajko1; ~Seraphina_Nix1; ~Lucas_Jun_Koba_Sato1; ~William_Saunders1; ~Maksym_Taran1; ~Ben_West1; ~Elizabeth_Barnes3,"{'value': ['Machine Learning', 'LLM evaluations', 'Agents', 'AI R&D', 'Benchmarks']}","{'value': 'Frontier AI safety policies highlight automation of AI research and development (R&D) by AI agents as an important capability to anticipate. However, there exist few evaluations for AI R&D capabilities, and none that are highly realistic and have a direct comparison to human performance. We introduce RE-Bench (Research Engineering Benchmark, V1), which consists of 7 challenging, open-ended ML research engineering environments and data from 71 8-hour attempts by 61 distinct human experts. We confirm that our experts make progress in the environments given 8 hours, with 82% of expert attempts achieving a non-zero score and 24% matching or exceeding our strong reference solutions. We compare humans to several public frontier models through best-of-$k$ with varying time budgets and agent designs, and find that the best AI agents achieve a score 4× higher than human experts when both are given a total time budget of 2 hours per environment. However, humans currently display better returns to increasing time budgets, narrowly exceeding the top AI agent scores given an 8-hour budget, and achieving 2× the score of the top AI agent when both are given 32 total hours (across different attempts).'}",https://openreview.net{'value': '/pdf/4ecca478c42f4d707b818055092b92bfb1094b98.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=3pk0p4NGmQ,{'value': 'CVE-Bench: A Benchmark for AI Agents’ Ability to Exploit Real-World Web Application Vulnerabilities'},Yuxuan Zhu; Antony Kellermann; Dylan Bowman; Philip Li; Akul Gupta; Adarsh Danda; Richard Fang; Conner Jensen; Eric Ihli; Jason Benn; Jet Geronimo; Avi Dhir; Sudhit Rao; Kaicheng Yu; Twm Stone; Daniel Kang,~Yuxuan_Zhu1; ~Antony_Kellermann1; ~Dylan_Bowman1; ~Philip_Li1; ~Akul_Gupta1; ~Adarsh_Danda1; ~Richard_Fang1; ~Conner_Jensen1; ~Eric_Ihli1; ~Jason_Benn1; ~Jet_Geronimo1; ~Avi_Dhir1; ~Sudhit_Rao1; ~Kaicheng_Yu3; ~Twm_Stone1; ~Daniel_Kang1,"{'value': ['benchmark', 'cybersecurity', 'llm', 'agent']}","{'value': 'Large language model (LLM) agents are increasingly capable of autonomously conducting cyberattacks, posing significant threats to existing applications. This growing risk highlights the urgent need for a real-world benchmark to evaluate the ability of LLM agents to exploit web application vulnerabilities. However, existing benchmarks fall short as they are limited to abstracted Capture-the-Flag competitions or lack comprehensive coverage. Building a benchmark for real-world vulnerabilities involves both specialized exper-\ntise to reproduce exploits and a systematic approach to evaluating unpredictable attacks. To address this challenge, we introduce CVE-Bench, a real-world cybersecurity benchmark based on critical-severity Common Vulnerabilities and Exposures. In CVE-Bench, we design a sandbox framework that enables LLM agents to exploit vulnerable web applications in scenarios that mimic real-world conditions, while also providing effective evaluation of their exploits. Our experiments show that the state-of-the-art agent framework can exploit up to 13% of the vulnerabilities.'}",https://openreview.net{'value': '/pdf/4fe6d4584e6e0d41eaa58d72ee90975761e2b771.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=3h80HyStMH,{'value': 'Improving Parallel Program Performance with LLM Optimizers via Agent-System Interfaces'},Anjiang Wei; Allen Nie; Thiago S. F. X. Teixeira; Rohan Yadav; Wonchan Lee; Ke Wang; Alex Aiken,~Anjiang_Wei1; ~Allen_Nie1; ~Thiago_S._F._X._Teixeira1; ~Rohan_Yadav1; ~Wonchan_Lee1; ~Ke_Wang1; ~Alex_Aiken1,"{'value': ['Large language model', 'agent', 'parallel programming', 'performance optimization']}","{'value': 'Modern scientific discovery increasingly relies on high-performance computing for complex modeling and simulation. A key challenge in improving parallel program performance is efficiently mapping tasks to processors and data to memory, a process dictated by intricate, low-level system code known as *mappers*. Developing high-performance mappers demands days of manual tuning, posing a significant barrier for domain scientists without systems expertise. We introduce a framework that automates mapper development with generative optimization, leveraging richer feedback beyond scalar performance metrics. Our approach features the Agent-System Interface, which includes a Domain-Specific Language (DSL) to abstract away the low-level complexity of system code and define a structured search space, as well as AutoGuide, a mechanism that interprets raw execution output into actionable feedback. Unlike traditional reinforcement learning methods such as OpenTuner, which rely solely on scalar feedback, our method finds superior mappers in far fewer iterations. With just 10 iterations, it outperforms OpenTuner even after 1000 iterations, achieving $3.8\\times$ faster performance. Our approach finds mappers that surpass expert-written mappers by up to $1.34\\times$ speedup across nine benchmarks while reducing tuning time from days to minutes.'}",https://openreview.net{'value': '/pdf/1c09d7f36ca58adc31509f59aac3eede212bee62.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=3Jr5Al16MS,{'value': 'Near Optimal Best Arm Identification for Clustered Bandits'},Yash; Avishek Ghosh; Nikhil Karamchandani,~Yash1; ~Avishek_Ghosh2; ~Nikhil_Karamchandani1,"{'value': ['Best Arm Identification', 'Multi-Armed Bandits (MAB)', 'Clustered Bandits', 'Pure Exploration']}","{'value': 'This work investigates the problem of best arm identification for multi-agent multi-armed bandits. We consider $N$ agents grouped into $M$ clusters, where each cluster solves a stochastic bandit problem. The mapping between agents and bandits is \\textit{a priori} unknown. Each bandit is associated with $K$ arms, and the goal is to identify the best arm for each agent under a $\\delta$-probably correct ($\\delta$-PC) framework, while minimizing sample complexity and communication overhead. We propose two novel algorithms: \\emph{Clustering then Best Arm Identification} (\\texttt{Cl-BAI}) and \\emph{Best Arm Identification then Clustering} (\\texttt{BAI-Cl}). \\texttt{Cl-BAI} employs a two-phase approach that first clusters agents based on the bandit problems they are learning, followed by identifying the best arm for each cluster. \\texttt{BAI-Cl} reverses the sequence by identifying the best arms first and then clustering agents accordingly. Both algorithms exploit the successive elimination framework to ensure computational efficiency and high accuracy. Theoretical analysis establishes $\\delta$-PC guarantees for both methods, derives bounds on their sample complexity, and provides a lower bound for the problem class. Moreover, when $M$ is small (a constant), we show that the sample complexity of (a variant of) \\texttt{BAI-Cl} is (order-wise) minimax optimal. Experiments on synthetic and real-world (Movie Lens, Yelp) data demonstrates the superior performance of the proposed algorithms in terms of sample and communication efficiency, particularly in settings where $M \\ll N$.'}",https://openreview.net{'value': '/pdf/e96611b0083dddb092ac4baec4ef8e034b86424b.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=3CiSpY3QdZ,{'value': 'MAS-GPT: Training LLMs to Build LLM-based Multi-Agent Systems'},Rui Ye; Shuo Tang; Rui Ge; Yaxin Du; Zhenfei Yin; Siheng Chen; Jing Shao,~Rui_Ye1; ~Shuo_Tang2; ~Rui_Ge1; ~Yaxin_Du1; ~Zhenfei_Yin2; ~Siheng_Chen1; ~Jing_Shao3,"{'value': ['large language models', 'multi-agent systems']}","{'value': ""LLM-based multi-agent systems (MAS) have shown significant potential in tackling diverse tasks.\nHowever, to design effective MAS, existing approaches heavily rely on manual configurations or multiple calls of advanced LLMs, resulting in inadaptability and high inference costs.\nIn this paper, we simplify the process of building an MAS by reframing it as a generative language task, where the input is a user query and the output is a corresponding MAS.\nTo address this novel task, we unify the representation of MAS as executable code and propose a consistency-oriented data construction pipeline to create a high-quality dataset comprising coherent and consistent query-MAS pairs.\nUsing this dataset, we train MAS-GPT, an open-source medium-sized LLM that is capable of generating query-adaptive MAS within a single LLM inference. The generated MAS can be seamlessly applied to process user queries and deliver high-quality responses. Extensive experiments on 9 benchmarks and 5 LLMs show that the proposed MAS-GPT consistently outperforms 10+ baseline MAS methods on diverse settings, indicating MAS-GPT's high effectiveness, efficiency and strong generalization ability.\nThe codes are released at \\url{https://github.com/rui-ye/MAS-GPT}.""}",https://openreview.net{'value': '/pdf/1f479b93fec4660d50da88780197574d2cb64155.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=3B6fF1PxYD,{'value': 'NextCoder: Robust Adaptation of Code LMs to Diverse Code Edits'},Tushar Aggarwal; Swayam Singh; Abhijeet Awasthi; Aditya Kanade; Nagarajan Natarajan,~Tushar_Aggarwal1; ~Swayam_Singh1; ~Abhijeet_Awasthi1; ~Aditya_Kanade2; ~Nagarajan_Natarajan2,"{'value': ['Code-LMs', 'code-editing', 'code-generation', 'software engineering']}","{'value': ""Software engineering activities frequently involve edits to existing code. However, contemporary code language models (LMs) lack the ability to handle diverse types of code-edit requirements. In this work, we attempt to overcome this shortcoming through (1) a novel synthetic data generation pipeline and (2) a robust model adaptation algorithm. Starting with seed code examples and diverse editing criteria, our pipeline generates high-quality samples comprising original and modified code, along with natural language instructions in different styles and verbosity. Today's code LMs come bundled with strong abilities, such as code generation and instruction following, which should not be lost due to fine-tuning. To ensure this, we propose a novel adaptation algorithm, SeleKT, that (a) leverages a dense gradient-based step to identify the weights that are most important for code editing, and (b) does a sparse projection onto the base model to avoid overfitting. Using our approach, we obtain a new series of models NextCoder (adapted from QwenCoder-2.5) that achieves strong results on five code-editing benchmarks, outperforming comparable size models and even several larger ones. We show the generality of our approach on two model families DeepSeekCoder and QwenCoder), compare against other fine-tuning approaches, and demonstrate robustness by showing retention of code generation and general problem-solving abilities post adaptation. We opensource the models, synthetic dataset, and implementation at http://aka.ms/nextcoder.""}",https://openreview.net{'value': '/pdf/e4c45e8d4642143f7bff681474b7ce9634b0db2d.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=323GZNnGqe,{'value': 'Agent-Centric Actor-Critic for Asynchronous Multi-Agent Reinforcement Learning'},Whiyoung Jung; Sunghoon Hong; Deunsol Yoon; Kanghoon Lee; Woohyung Lim,~Whiyoung_Jung1; ~Sunghoon_Hong2; ~Deunsol_Yoon1; ~Kanghoon_Lee2; ~Woohyung_Lim1,"{'value': ['Multi-Agent Reinforcement Learning', 'Asynchronous Multi-Agent Reinforcement Learning', 'MacDec-POMDP']}","{'value': 'Multi-Agent Reinforcement Learning (MARL) struggles with coordination in sparse reward environments. Macro-actions —sequences of actions executed as single decisions— facilitate long-term planning but introduce asynchrony, complicating Centralized Training with Decentralized Execution (CTDE). Existing CTDE methods use padding to handle asynchrony, risking misaligned asynchronous experiences and spurious correlations. We propose the Agent-Centric Actor-Critic (ACAC) algorithm to manage asynchrony without padding. ACAC uses agent-centric encoders for independent trajectory processing, with an attention-based aggregation module integrating these histories into a centralized critic for improved temporal abstractions. The proposed structure is trained via a PPO-based algorithm with a modified Generalized Advantage Estimation for asynchronous environments. Experiments show ACAC accelerates convergence and enhances performance over baselines in complex MARL tasks.'}",https://openreview.net{'value': '/pdf/4f0126e980ace77d412551d8ae0d8a69db9b18c6.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=2nBcjCZrrP,{'value': 'GuardAgent: Safeguard LLM Agents via Knowledge-Enabled Reasoning'},Zhen Xiang; Linzhi Zheng; Yanjie Li; Junyuan Hong; Qinbin Li; Han Xie; Jiawei Zhang; Zidi Xiong; Chulin Xie; Carl Yang; Dawn Song; Bo Li,~Zhen_Xiang1; ~Linzhi_Zheng1; ~Yanjie_Li7; ~Junyuan_Hong1; ~Qinbin_Li1; ~Han_Xie1; ~Jiawei_Zhang9; ~Zidi_Xiong2; ~Chulin_Xie1; ~Carl_Yang1; ~Dawn_Song1; ~Bo_Li19,"{'value': ['agent', 'large language model', 'guardrail', 'reasoning']}","{'value': 'The rapid advancement of large language model (LLM) agents has raised new concerns regarding their safety and security. In this paper, we propose GuardAgent, the first guardrail agent to protect target agents by dynamically checking whether their actions satisfy given safety guard requests. Specifically, GuardAgent first analyzes the safety guard requests to generate a task plan, and then maps this plan into guardrail code for execution. By performing the code execution, GuardAgent can deterministically follow the safety guard request and safeguard target agents. In both steps, an LLM is utilized as the reasoning component, supplemented by in-context demonstrations retrieved from a memory module storing experiences from previous tasks. In addition, we propose two novel benchmarks: EICU-AC benchmark to assess the access control for healthcare agents and Mind2Web-SC benchmark to evaluate the safety policies for web agents. We show that GuardAgent effectively moderates the violation actions for different types of agents on these two benchmarks with over 98% and 83%\nguardrail accuracies, respectively. Project page: https://guardagent.github.io/'}",https://openreview.net{'value': '/pdf/c7b75b02d57a9809d87b82ad16586b4645b560f8.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=2gpjvMEAMm,{'value': 'Skip the Equations: Learning Behavior of Personalized Dynamical Systems Directly From Data'},Krzysztof Kacprzyk; Julianna Piskorz; Mihaela van der Schaar,~Krzysztof_Kacprzyk1; ~Julianna_Piskorz1; ~Mihaela_van_der_Schaar2,"{'value': ['dynamical systems', 'differential equations', 'ODE discovery', 'interpretability', 'transparency', 'verification']}","{'value': ""While black-box approaches are commonly used for data-driven modeling of dynamical systems, they often obscure a system's underlying behavior and properties, limiting adoption in areas such as medicine and pharmacology. A two-step process of discovering ordinary differential equations (ODEs) and their subsequent mathematical analysis can yield insights into the system's dynamics. However, this analysis may be infeasible for complex equations, and refining the ODE to meet certain behavioral requirements can be challenging. Direct semantic modeling has recently been proposed to address these issues by predicting the system's behavior, such as the trajectory's shape, directly from data, bypassing post-hoc mathematical analysis. In this work, we extend the original instantiation, limited to one-dimensional trajectories and inputs, to accommodate multi-dimensional trajectories with additional personalization, allowing evolution to depend on auxiliary static features (e.g., patient covariates). In a series of experiments, we show how our approach enables practitioners to integrate prior knowledge, understand the dynamics, ensure desired behaviors, and revise the model when necessary.""}",https://openreview.net{'value': '/pdf/b4336bf355cf026db31f9bef596ea7f485aae848.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=2fBcAOi8lO,{'value': 'On Measuring Long-Range Interactions in Graph Neural Networks'},Jacob Bamberger; Benjamin Gutteridge; Scott le Roux; Michael M. Bronstein; Xiaowen Dong,~Jacob_Bamberger1; ~Benjamin_Gutteridge1; ~Scott_le_Roux1; ~Michael_M._Bronstein1; ~Xiaowen_Dong1,"{'value': ['long-range', 'GNNs']}","{'value': ""Long-range graph tasks --- those dependent on interactions between `distant' nodes --- are an open problem in graph neural network research. Real-world benchmark tasks, especially the Long Range Graph Benchmark, have become popular for validating the long-range capability of proposed architectures. However, this is an empirical approach that lacks both robustness and theoretical underpinning; a more principled characterization of the long-range problem is required. \nTo bridge this gap, we formalize long-range interactions in graph tasks, introduce a **range measure** for operators on graphs, and validate it with synthetic experiments. We then leverage our measure to examine commonly used tasks and architectures, and discuss to what extent they are, in fact, long-range.\nWe believe our work advances efforts to define and address the long-range problem on graphs, and that our range measure will aid evaluation of new datasets and architectures.""}",https://openreview.net{'value': '/pdf/ea9f24a5e3798079df0cd66765eeab3a86616fbc.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=2GmDdhBdDk,{'value': 'The Berkeley Function Calling Leaderboard (BFCL): From Tool Use to Agentic Evaluation of Large Language Models'},Shishir G Patil; Huanzhi Mao; Fanjia Yan; Charlie Cheng-Jie Ji; Vishnu Suresh; Ion Stoica; Joseph E. Gonzalez,~Shishir_G_Patil1; ~Huanzhi_Mao1; ~Fanjia_Yan1; ~Charlie_Cheng-Jie_Ji1; ~Vishnu_Suresh1; ~Ion_Stoica1; ~Joseph_E._Gonzalez1,"{'value': ['Function Calling Evaluation', 'Tool use', 'Agentic Evaluation', 'Large Language Models']}","{'value': ""Function calling, also called tool use, refers to an LLM's ability to invoke external functions, APIs, or user-defined tools in response to user queries—an essential capability for agentic LLM applications. Despite its prominence, there did not exist a standard benchmark to evaluate function calling abilities, due to two reasons – the challenging nature of evaluating when a function call is valid, and the challenge of acquiring diverse, real-world functions. We present the Berkeley Function Calling Leaderboard (BFCL), a comprehensive benchmark designed to evaluate function calling capabilities in a wide range of real-world settings. The BFCL benchmark evaluates serial and parallel function calls, across various programming languages using a novel Abstract Syntax Tree (AST) evaluation method that can easily scale to thousands of functions. We construct the benchmark using a combination of expert curated, and user-contributed functions and associated prompts. Finally, BFCL benchmark evaluates the ability of models to abstain and reason in stateful multi-step agentic setting. Evaluating a wide range of models, we observe that while state-of-the-art LLMs excel at singleturn calls, memory, dynamic decision-making, and long-horizon reasoning remain open challenges. Since its preview, BFCL has become the defacto standard for evaluating function-calls, and can be accessed at gorilla.cs.berkeley.edu/leaderboard.html.""}",https://openreview.net{'value': '/pdf/d52a12bb32128210600246f8979d90b892505cca.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=28Essvtvkw,{'value': 'SITCOM: Step-wise Triple-Consistent Diffusion Sampling For Inverse Problems'},Ismail Alkhouri; Shijun Liang; Cheng-Han Huang; Jimmy Dai; Qing Qu; Saiprasad Ravishankar; Rongrong Wang,~Ismail_Alkhouri1; ~Shijun_Liang2; ~Cheng-Han_Huang1; ~Jimmy_Dai1; ~Qing_Qu2; ~Saiprasad_Ravishankar1; ~Rongrong_Wang1,{'value': ['Diffusion Model; Inverse Problems; Image Restoration; MRI']},"{'value': 'Diffusion models (DMs) are a class of generative models that allow sampling from a distribution learned over a training set. When applied to solving inverse problems, the reverse sampling steps are modified to approximately sample from a measurement-conditioned distribution. However, these modifications may be unsuitable for certain settings (e.g., presence of measurement noise) and non-linear tasks, as they often struggle to correct errors from earlier steps and generally require a large number of optimization and/or sampling steps. To address these challenges, we state three conditions for achieving measurement-consistent diffusion trajectories. Building on these conditions, we propose a new optimization-based sampling method that not only enforces standard data manifold measurement consistency and forward diffusion consistency, as seen in previous studies, but also incorporates our proposed step-wise and network-regularized backward diffusion consistency that maintains a diffusion trajectory by optimizing over the input of the pre-trained model at every sampling step. By enforcing these conditions (implicitly or explicitly), our sampler requires significantly fewer reverse steps. Therefore, we refer to our method as **S**tep-w**i**se **T**riple-**Co**nsistent Sa**m**pling (**SITCOM**). Compared to SOTA baselines, our experiments across several linear and non-linear tasks (with natural and medical images) demonstrate that SITCOM achieves competitive or superior results in terms of standard similarity metrics and run-time.'}",https://openreview.net{'value': '/pdf/32ddf141dd848557cc1d48b0c9a16505d5ea6176.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=1bnH3Q3zL6,{'value': 'Gradient Aligned Regression via Pairwise Losses'},Dixian Zhu; Tianbao Yang; Livnat Jerby,~Dixian_Zhu1; ~Tianbao_Yang1; ~Livnat_Jerby1,"{'value': ['Regression', 'Pairwise Losses']}","{'value': 'Regression is a fundamental task in machine learning that has garnered extensive attention over the past decades. The conventional approach for regression involves employing loss functions that primarily concentrate on aligning model prediction with the ground truth for each individual data sample. Recent research endeavors have introduced novel perspectives by incorporating label similarity into regression through the imposition of additional pairwise regularization or contrastive learning on the latent feature space, demonstrating their effectiveness. However, there are two drawbacks to these approaches: (i) their pairwise operations in the latent feature space are computationally more expensive than conventional regression losses; (ii) they lack theoretical insights behind these methods. In this work, we propose GAR (Gradient Aligned Regression) as a competitive alternative method in label space, which is constituted by a conventional regression loss and two pairwise label difference losses for gradient alignment including magnitude and direction. GAR enjoys: i) the same level efficiency as conventional regression loss because the quadratic complexity for the proposed pairwise losses can be reduced to linear complexity; ii) theoretical insights from learning the pairwise label difference to learning the gradient of the ground truth function. We limit our current scope as regression on the clean data setting without noises, outliers or distributional shifts, etc. We demonstrate the effectiveness of the proposed method practically on two synthetic datasets and on eight extensive real-world tasks from six benchmark datasets with other eight competitive baselines. Running time experiments demonstrate the superior efficiency of the proposed GAR compared to existing methods with pairwise regularization or contrastive learning in the latent feature space. Additionally, ablation studies confirm the effectiveness of each component of GAR. The code is open sourced at https://github.com/DixianZhu/GAR.'}",https://openreview.net{'value': '/pdf/e01e9355be073b2146461513b635d62e2a93c2ce.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=1XXqIIsgT3,{'value': 'Reinforcement Learning with Segment Feedback'},Yihan Du; Anna Winnicki; Gal Dalal; Shie Mannor; R. Srikant,~Yihan_Du2; ~Anna_Winnicki1; ~Gal_Dalal2; ~Shie_Mannor2; ~R._Srikant1,"{'value': ['Reinforcement learning (RL)', 'segment feedback', 'binary feedback', 'sum feedback']}","{'value': 'Standard reinforcement learning (RL) assumes that an agent can observe a reward for each state-action pair. However, in practical applications, it is often difficult and costly to collect a reward for each state-action pair. While there have been several works considering RL with trajectory feedback, it is unclear if trajectory feedback is inefficient for learning when trajectories are long. In this work, we consider a model named RL with segment feedback, which offers a general paradigm filling the gap between per-state-action feedback and trajectory feedback. In this model, we consider an episodic Markov decision process (MDP), where each episode is divided into $m$ segments, and the agent observes reward feedback only at the end of each segment. Under this model, we study two popular feedback settings: binary feedback and sum feedback, where the agent observes a binary outcome and a reward sum according to the underlying reward function, respectively. To investigate the impact of the number of segments $m$ on learning performance, we design efficient algorithms and establish regret upper and lower bounds for both feedback settings. Our theoretical and experimental results show that: under binary feedback, increasing the number of segments $m$ decreases the regret at an exponential rate; in contrast, surprisingly, under sum feedback, increasing $m$ does not reduce the regret significantly.'}",https://openreview.net{'value': '/pdf/972d755eea6baee1d73eeeb1b195e308e0be3dde.pdf'},{'abstract_filter': 'Trajectory'},ICML.cc,2025,Conference
https://openreview.net/forum?id=1IyPRv1A0r,{'value': 'A Likelihood Based Approach to Distribution Regression Using Conditional  Deep Generative Models'},Shivam Kumar; Yun Yang; Lizhen Lin,~Shivam_Kumar5; ~Yun_Yang4; ~Lizhen_Lin2,{'value': ['Distribution Regression; Conditional Deep Generative Models; Intrinsic Manifold Structure; Sieve MLE; Wasserstein Convergence.']},"{'value': 'In this work, we explore the theoretical properties of conditional deep generative models under the statistical framework of distribution regression where the response variable lies in a high-dimensional ambient space but concentrates around a potentially lower-dimensional manifold. More specifically, we study the large-sample properties of a likelihood-based approach for estimating these models. Our results lead to the convergence rate of a sieve maximum likelihood estimator (MLE) for estimating the conditional distribution (and its devolved counterpart) of the response given predictors in the Hellinger (Wasserstein) metric. \nOur rates depend solely on the intrinsic dimension and smoothness of the true conditional distribution. These findings provide an explanation of why conditional deep generative models can circumvent the curse of dimensionality from the perspective of statistical foundations and demonstrate that they can learn a broader class of nearly singular conditional distributions. Our analysis also emphasizes the importance of introducing a small noise perturbation to the data when they are supported sufficiently close to a manifold. Finally, in our numerical studies, we demonstrate the effective implementation of the proposed approach using both synthetic and real-world datasets, which also provide complementary validation to our theoretical findings.'}",https://openreview.net{'value': '/pdf/edf3022df101c416067e4fc18a3bb69bcfa3e2df.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=1Iny6XlON0,{'value': 'Wolfpack Adversarial Attack for Robust Multi-Agent Reinforcement Learning'},Sunwoo Lee; Jaebak Hwang; Yonghyeon Jo; Seungyul Han,~Sunwoo_Lee4; ~Jaebak_Hwang1; ~Yonghyeon_Jo1; ~Seungyul_Han1,"{'value': ['Reinforcement Learning', 'Multi-Agent Reinforcement Learning', 'Robustness', 'Adversarial Learning']}","{'value': 'Traditional robust methods in multi-agent reinforcement learning (MARL) often struggle against coordinated adversarial attacks in cooperative scenarios. To address this limitation, we propose the Wolfpack Adversarial Attack framework, inspired by wolf hunting strategies, which targets an initial agent and its assisting agents to disrupt cooperation. Additionally, we introduce the Wolfpack-Adversarial Learning for MARL (WALL) framework, which trains robust MARL policies to defend against the proposed Wolfpack attack by fostering system-wide collaboration. Experimental results underscore the devastating impact of the Wolfpack attack and the significant robustness improvements achieved by WALL. Our code is available at https://github.com/sunwoolee0504/WALL.'}",https://openreview.net{'value': '/pdf/f06511a46d2709d4c7412c1daedb8fa09a265be6.pdf'},{'title_filter': 'Agent'},ICML.cc,2025,Conference
https://openreview.net/forum?id=1Agoo9f41i,{'value': 'Navigating the Social Welfare Frontier: Portfolios for Multi-objective Reinforcement Learning'},Cheol Woo Kim; Jai Moondra; Shresth Verma; Madeleine Pollack; Lingkai Kong; Milind Tambe; Swati Gupta,~Cheol_Woo_Kim1; ~Jai_Moondra1; ~Shresth_Verma1; ~Madeleine_Pollack1; ~Lingkai_Kong1; ~Milind_Tambe1; ~Swati_Gupta1,"{'value': ['Reinforcement learning', 'multi-objective optimization', 'p-means aggregation']}","{'value': 'In many real-world applications of Reinforcement Learning (RL), deployed policies have varied impacts on different stakeholders, creating challenges in reaching consensus on how to effectively aggregate their preferences. Generalized $p$-means form a widely used class of social welfare functions for this purpose, with broad applications in fair resource allocation, AI alignment, and decision-making. This class includes well-known welfare functions such as Egalitarian, Nash, and Utilitarian welfare. However, selecting the appropriate social welfare function is challenging for decision-makers, as the structure and outcomes of optimal policies can be highly sensitive to the choice of $p$. To address this challenge, we study the concept of an $\\alpha$-approximate portfolio in RL, a set of policies that are approximately optimal across the family of generalized $p$-means for all $p \\in [-\\infty, 1]$. We propose algorithms to compute such portfolios and provide theoretical guarantees on the trade-offs among approximation factor, portfolio size, and computational efficiency. Experimental results on synthetic and real-world datasets demonstrate the effectiveness of our approach in summarizing the policy space induced by varying $p$ values, empowering decision-makers to navigate this landscape more effectively.'}",https://openreview.net{'value': '/pdf/cfc6a1136b1b90d9010477e76ecd9e6df8fe15af.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=145So0OrGC,{'value': 'Optimal Task Order for Continual Learning of Multiple Tasks'},Ziyan Li; Naoki Hiratani,~Ziyan_Li2; ~Naoki_Hiratani1,"{'value': ['Lifelong Learning', 'Curriculum Learning']}","{'value': 'Continual learning of multiple tasks remains a major challenge for neural networks. Here, we investigate how task order influences continual learning and propose a strategy for optimizing it. Leveraging a linear teacher-student model with latent factors, we derive an analytical expression relating task similarity and ordering to learning performance. Our analysis reveals two principles that hold under a wide parameter range: (1) tasks should be arranged from the least representative to the most typical, and (2) adjacent tasks should be dissimilar. We validate these rules on both synthetic data and real-world image classification datasets (Fashion-MNIST, CIFAR-10, CIFAR-100), demonstrating consistent performance improvements in both multilayer perceptrons and convolutional neural networks. Our work thus presents a generalizable framework for task-order optimization in task-incremental continual learning.'}",https://openreview.net{'value': '/pdf/ad882b3a9e33bdb33d7dd66ef5614552cac75534.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=0ysC6VS0y3,{'value': 'Emergence and Effectiveness of Task Vectors in In-Context Learning: An Encoder Decoder Perspective'},Seungwook Han; Jinyeop Song; Jeff Gore; Pulkit Agrawal,~Seungwook_Han1; ~Jinyeop_Song1; ~Jeff_Gore1; ~Pulkit_Agrawal1,"{'value': ['in context learning', 'task vectors', 'mechanistic interpretability']}","{'value': 'Autoregressive transformers exhibit adaptive learning through in-context learning (ICL), which begs the question of how. Prior works have shown that transformers represent the ICL tasks as vectors in their representations. In this paper, we leverage the encoding-decoding framework to study how transformers form task vectors during pretraining and how their task encoding quality predicts ICL task performance. On synthetic ICL tasks, we analyze the training dynamics of a small transformer and report the coupled emergence of task encoding and decoding. As the model learns to encode different latent tasks (e.g., ""Finding the first noun in a sentence."") into distinct, separable representations, it concurrently builds conditional decoding algorithms and improves its ICL performance. We validate this phenomenon across pretrained models of varying scales (Gemma-2 2B/9B/27B, Llama-3.1 8B/70B) and over the course of pretraining in OLMo-7B. Further, we demonstrate that the quality of task encoding  inferred from representations predicts ICL performance, and that, surprisingly, finetuning the earlier layers can improve the task encoding and performance more than finetuning the latter layers. Our empirical insights shed light into better understanding the success and failure modes of large language models via their representations.'}",https://openreview.net{'value': '/pdf/3f11ddfccfbd34b08416e9f9efc317adc809c402.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=0rDn6BDNiF,{'value': 'OOD-Chameleon: Is Algorithm Selection for OOD Generalization Learnable?'},Liangze Jiang; Damien Teney,~Liangze_Jiang1; ~Damien_Teney1,"{'value': ['OOD generalization', 'distribution shifts', 'learning to select training algorithms']}","{'value': 'Out-of-distribution (OOD) generalization is challenging because distribution shifts come in many forms. Numerous algorithms exist to address specific settings, but *choosing the right training algorithm for the right dataset* without trial and error is difficult. Indeed, real-world applications often involve multiple types and combinations of shifts that are hard to analyze theoretically.\n\n**Method.**  This work explores the possibility of *learning* the selection of a training algorithm for OOD generalization. We propose a proof of concept (OOD-Chameleon) that formulates the selection as a multi-label classification over candidate algorithms, trained on a *dataset of datasets* representing a variety of shifts. We evaluate the ability of OOD-Chameleon to rank algorithms on unseen shifts and datasets based only on dataset characteristics, i.e., without training models first, unlike traditional model selection.\n\n**Findings.**  Extensive experiments show that the learned selector identifies high-performing algorithms across synthetic, vision, and language tasks. Further inspection shows that it learns non-trivial decision rules, which provide new insights into the applicability of existing algorithms. Overall, this new approach opens the possibility of better exploiting and understanding the plethora of existing algorithms for OOD generalization.'}",https://openreview.net{'value': '/pdf/8e169f8238e0924f28aa7a6f14dabb607f52cfba.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=0pUSBi1BjC,{'value': 'Enhancing Graph Invariant Learning from a Negative Inference Perspective'},Kuo Yang; Zhengyang Zhou; Qihe Huang; Wenjie Du; Limin Li; Wu Jiang; Yang Wang,~Kuo_Yang2; ~Zhengyang_Zhou1; ~Qihe_Huang2; ~Wenjie_Du2; ~Limin_Li3; ~Wu_Jiang2; ~Yang_Wang32,"{'value': ['Graph learning', 'out-of-distribution generalization', 'environment awareness', 'negative inference', 'prompt learning.']}","{'value': 'The out-of-distribution (OOD) generalization challenge is a longstanding problem  in graph learning. Through studying the fundamental cause of data distribution shift, i.e., the changes of environments, significant progress has been achieved in addressing this issue. However, we observe that existing works still fail to effectively address complex environment shifts. Existing practices place excessive attention on extracting causal subgraphs, inevitably treating spurious subgraphs as environment variables. While spurious subgraphs are controlled by environments, the space of environment changes encompass more than the scale of spurious subgraphs. Therefore, existing efforts have a limited inference space for environments,  leading to failure under severe environment changes. To tackle this issue, we propose a negative inference graph OOD framework (NeGo)  to broaden the inference space for environment factors. Inspired by the successful practice of prompt learning in capturing underlying semantics and causal associations in large language models, we design a negative prompt environment inference to extract underlying environment information. We further introduce the environment-enhanced invariant subgraph learning to effectively exploit inferred environment embedding, ensuring the robust extraction of causal subgraph in the environment shifts. Lastly, we conduct a comprehensive evaluation of NeGo on real-world datasets and synthetic datasets across domains. NeGo outperforms baselines on nearly all datasets, which verify the effectiveness of our framework.'}",https://openreview.net{'value': '/pdf/8cee1bd18447067ea924d2df163b9e6d5c7ee760.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=0VvD1PmNzM,{'value': 'TabICL: A Tabular Foundation Model for In-Context Learning on Large Data'},Jingang QU; David Holzmüller; Gaël Varoquaux; Marine Le Morvan,~Jingang_QU1; ~David_Holzmüller1; ~Gaël_Varoquaux1; ~Marine_Le_Morvan2,"{'value': ['Foundation Model', 'In-Context Learning', 'Tabular Data', 'Tabular Classification']}","{'value': 'The long-standing dominance of gradient-boosted decision trees on tabular data is currently challenged by tabular foundation models using In-Context Learning (ICL): setting the training data as context for the test data and predicting in a single forward pass without parameter updates. While TabPFNv2 foundation model excels on tables with up to 10K samples, its alternating column- and row-wise attentions make handling large training sets computationally prohibitive. So, can ICL be effectively scaled and deliver a benefit for larger tables? We introduce TabICL, a tabular foundation model for classification, pretrained on synthetic datasets with up to 60K samples and capable of handling 500K samples on affordable resources. This is enabled by a novel two-stage architecture: a column-then-row attention mechanism to build fixed-dimensional embeddings of rows, followed by a transformer for efficient ICL. Across 200 classification datasets from the TALENT benchmark, TabICL is on par with TabPFNv2 while being systematically faster (up to 10 times), and significantly outperforms all other approaches. On 53 datasets with over 10K samples, TabICL surpasses both TabPFNv2 and CatBoost, demonstrating the potential of ICL for large data. Pretraining code, inference code, and pre-trained models are available at https://github.com/soda-inria/tabicl.'}",https://openreview.net{'value': '/pdf/c8aab432ba86c6c4c025525580fc90720bc26d64.pdf'},{'abstract_filter': 'Synthetic'},ICML.cc,2025,Conference
https://openreview.net/forum?id=0LZRtvK871,{'value': 'Improving the Scaling Laws of Synthetic Data with Deliberate Practice'},Reyhane Askari-Hemmat; Mohammad Pezeshki; Elvis Dohmatob; Florian Bordes; Pietro Astolfi; Melissa Hall; Jakob Verbeek; Michal Drozdzal; Adriana Romero-Soriano,~Reyhane_Askari-Hemmat1; ~Mohammad_Pezeshki1; ~Elvis_Dohmatob1; ~Florian_Bordes1; ~Pietro_Astolfi1; ~Melissa_Hall1; ~Jakob_Verbeek1; ~Michal_Drozdzal1; ~Adriana_Romero-Soriano1,"{'value': ['Synthetic Data', 'Deliberate Practice', 'Active Learning', 'Sample Efficiency', 'Scaling Laws', 'Data Curation', 'Diffusion Models', 'Dataset Pruning']}","{'value': 'Inspired by the principle of deliberate practice in human learning, we propose Deliberate Practice for Synthetic Data Generation (DP), a novel framework that improves sample efficiency through dynamic synthetic data generation. Prior work has shown that scaling synthetic data is inherently challenging, as naively adding new data leads to diminishing returns. To address this, pruning has been identified as a key mechanism for improving scaling, enabling models to focus on the most informative synthetic samples. Rather than generating a large dataset and pruning it afterward, DP efficiently approximates the direct generation of informative samples. We theoretically show how training on challenging, informative examples improves scaling laws and empirically validate that DP achieves better scaling performance with significantly fewer training samples and iterations. On ImageNet-100, DP generates 3.4x fewer samples and requires six times fewer iterations, while on ImageNet-1k, it generates 8x fewer samples with a 30% reduction in iterations, all while achieving superior performance compared to prior work.'}",https://openreview.net{'value': '/pdf/5c501cdc79a2e4a109265b636c96445553efcb4d.pdf'},{'title_filter': 'Synthetic'},ICML.cc,2025,Conference
