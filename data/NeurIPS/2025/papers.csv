forum,title,authors,authorids,keywords,abstract,pdf,match,venue,year,type
https://openreview.net/forum?id=ztVk8XNffY,{'value': 'HAIF-GS: Hierarchical and Induced Flow-Guided Gaussian Splatting for Dynamic Scene'},Jianing Chen; Zehao Li; Yujun Cai; Hao Jiang; Chengxuan Qian; Juyuan Kang; Shuqin Gao; Honglong Zhao; Tianlu Mao; Yucheng Zhang,~Jianing_Chen4; ~Zehao_Li7; ~Yujun_Cai1; ~Hao_Jiang14; ~Chengxuan_Qian1; ~Juyuan_Kang1; ~Shuqin_Gao1; ~Honglong_Zhao1; ~Tianlu_Mao1; ~Yucheng_Zhang7,{'value': ['3D dynamic reconstruction; computer vision']},"{'value': 'Reconstructing dynamic 3D scenes from monocular videos remains a fundamental challenge in 3D vision. While 3D Gaussian Splatting (3DGS) achieves real-time rendering in static settings, extending it to dynamic scenes is challenging due to the difficulty of learning structured and temporally consistent motion representations. This challenge often manifests as three limitations in existing methods: redundant Gaussian updates, insufficient motion supervision, and weak modeling of complex non-rigid deformations. These issues collectively hinder coherent and efficient dynamic reconstruction. To address these limitations, we propose HAIF-GS, a unified framework that enables structured and consistent dynamic modeling through sparse anchor-driven deformation. It first identifies motion-relevant regions via an Anchor Filter to suppress redundant updates in static areas. A self-supervised Induced Flow-Guided Deformation module induces anchor motion using multi-frame feature aggregation, eliminating the need for explicit flow labels. To further handle fine-grained deformations, a Hierarchical Anchor Propagation mechanism increases anchor resolution based on motion complexity and propagates multi-level transformations. Extensive experiments on synthetic and real-world benchmarks validate that HAIF-GS significantly outperforms prior dynamic 3DGS methods in rendering quality, temporal coherence, and reconstruction efficiency.'}",https://openreview.net{'value': '/pdf/7facf9c292a4b0e2f866dfcc0d4639cdddc0822b.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=zssWxiiJZ1,{'value': 'Scalable and Cost-Efficient de Novo Template-Based Molecular Generation'},Piotr Gaiński; Oussama Boussif; Andrei Rekesh; Dmytro Shevchuk; Ali Parviz; Mike Tyers; Robert A. Batey; Michał Koziarski,~Piotr_Gaiński1; ~Oussama_Boussif1; ~Andrei_Rekesh1; ~Dmytro_Shevchuk1; ~Ali_Parviz1; ~Mike_Tyers1; ~Robert_A._Batey1; ~Michał_Koziarski1,"{'value': ['drug discovery', 'generative models', 'GFlowNets', 'synthesizability', 'molecular generation']}","{'value': 'Template-based molecular generation offers a promising avenue for drug design by ensuring generated compounds are synthetically accessible through predefined reaction templates and building blocks. In this work, we tackle three core challenges in template-based GFlowNets: (1) minimizing synthesis cost, (2) scaling to large building block libraries, and (3) effectively utilizing small fragment sets. We propose **Recursive Cost Guidance**, a backward policy framework that employs auxiliary machine learning models to approximate synthesis cost and viability. This guidance steers generation toward low-cost synthesis pathways, significantly enhancing cost-efficiency, molecular diversity, and quality, especially when paired with an **Exploitation Penalty** that balances the trade-off between exploration and exploitation. To enhance performance in smaller building block libraries, we develop a **Dynamic Library** mechanism that reuses intermediate high-reward states to construct full synthesis trees. Our approach establishes state-of-the-art results in template-based molecular generation.'}",https://openreview.net{'value': '/pdf/af99244b754c86531a7dc069f7725ac6ff0851fd.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=zlRvBwWFII,{'value': 'Towards Syn-to-Real IQA: A Novel Perspective on Reshaping Synthetic Data Distributions'},Aobo Li; Jinjian Wu; Yongxu Liu; Leida Li; Weisheng Dong,~Aobo_Li1; ~Jinjian_Wu1; ~Yongxu_Liu2; ~Leida_Li3; ~Weisheng_Dong1,{'value': ['Blind Image Quality Assessment; Data Distribution Reshaping; Synthetic Data']},"{'value': ""Blind Image Quality Assessment (BIQA) has advanced significantly through deep learning, but the scarcity of large-scale labeled datasets remains a challenge. While synthetic data offers a promising solution, models trained on existing synthetic datasets often show limited generalization ability. In this work, we make a key observation that representations learned from synthetic datasets often exhibit a discrete and clustered pattern that hinders regression performance: features of high-quality images cluster around reference images, while those of low-quality images cluster based on distortion types. Our analysis reveals that this issue stems from the distribution of synthetic data rather than model architecture. Consequently, we introduce a novel framework SynDR-IQA, which reshapes synthetic data distribution to enhance BIQA generalization. Based on theoretical derivations of sample diversity and redundancy's impact on generalization error, SynDR-IQA employs two strategies: distribution-aware diverse content upsampling, which enhances visual diversity while preserving content distribution, and density-aware redundant cluster downsampling, which balances samples by reducing the density of densely clustered areas. Extensive experiments across three cross-dataset settings (synthetic-to-authentic, synthetic-to-algorithmic, and synthetic-to-synthetic) demonstrate the effectiveness of our method. The code is available at https://github.com/Li-aobo/SynDR-IQA.""}",https://openreview.net{'value': '/pdf/7e62b007b86b834a9e57cbdc9493baf2769202ad.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=zlMupLoKRf,{'value': 'Causality Meets the Table: Debiasing LLMs for Faithful TableQA via Front-Door Intervention'},Zhen Yang; Ziwei Du; Minghan Zhang; Wei Du; Jie Chen; Fulan Qian; Shu Zhao,~Zhen_Yang14; ~Ziwei_Du1; ~Minghan_Zhang1; ~Wei_Du11; ~Jie_Chen35; ~Fulan_Qian1; ~Shu_Zhao4,"{'value': ['TableQA', 'Causal', 'Large Language Model', 'Question Answering']}","{'value': 'Table Question Answering (TableQA) combines natural language understanding and structured data reasoning, posing challenges in semantic interpretation and logical inference. Recent advances in Large Language Models (LLMs) have improved TableQA performance through Direct Prompting and Agent paradigms. However, these models often rely on spurious correlations, as they tend to overfit to token co-occurrence patterns in pretraining corpora, rather than perform genuine reasoning. To address this issue, we propose Causal Intervention TableQA (CIT), which is based on a structural causal graph and applies front-door adjustment to eliminate bias caused by token co-occurrence. CIT formalizes TableQA as a causal graph and identifies token co-occurrence patterns as confounders. By applying front-door adjustment, CIT guides question variant generation and reasoning to reduce confounding effects. Experiments on multiple benchmarks show that CIT achieves state-of-the-art performance, demonstrating its effectiveness in mitigating bias. Consistent gains across various LLMs further confirm its generalizability.'}",https://openreview.net{'value': '/pdf/6a1e1516933aea7cc761b87682abd0404f891aa2.pdf'},{'abstract_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=zft0zTOFkN,{'value': 'Noisy Multi-Label Learning through Co-Occurrence-Aware Diffusion'},Senyu Hou; Yuru Ren; Gaoxia Jiang; Wenjian Wang,~Senyu_Hou1; ~Yuru_Ren4; ~Gaoxia_Jiang1; ~Wenjian_Wang1,{'value': ['Multi-label classification; Noisy multi-label learning; Diffusion model; Co-occurrence-aware']},"{'value': ""Noisy labels often compel models to overfit, especially in multi-label classification tasks. Existing methods for noisy multi-label learning (NML) primarily follow a discriminative paradigm, which relies on noise transition matrix estimation or small-loss strategies to correct noisy labels. However, they remain substantial optimization difficulties compared to noisy single-label learning. In this paper, we propose a Co-Occurrence-Aware Diffusion (CAD) model, which reformulates NML from a generative perspective. We treat features as conditions and multi-labels as diffusion targets, optimizing the diffusion model for multi-label learning with theoretical guarantees. Benefiting from the diffusion model's strength in capturing multi-object semantics and structured label matrix representation, we can effectively learn the posterior mapping from features to true multi-labels. To mitigate the interference of noisy labels in the forward process, we guide generation using pseudo-clean labels reconstructed from the latent neighborhood space, replacing original point-wise estimates with neighborhood-based proxies. In the reverse process, we further incorporate label co-occurrence constraints to enhance the model's awareness of incorrect generation directions, thereby promoting robust optimization. Extensive experiments on both synthetic (Pascal-VOC, MS-COCO) and real-world (NUS-WIDE) noisy datasets demonstrate that our approach outperforms state-of-the-art methods.""}",https://openreview.net{'value': '/pdf/bb14ff10fa76295b55da8b8f131ed48cbf1fdb61.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=zOFxp98km2,{'value': 'Online Portfolio Selection with ML Predictions'},Ziliang Zhang; Tianming Zhao; Albert Zomaya,~Ziliang_Zhang2; ~Tianming_Zhao1; ~Albert_Zomaya1,"{'value': ['Universal Portfolio', 'Algorithms with Predictions', 'Learning-augmented Algorithms']}","{'value': 'Online portfolio selection seeks to determine a sequence of allocations to maximize capital growth. Classical universal strategies asymptotically match the best constant-rebalanced portfolio but ignore potential forecasts, whereas heuristic methods often collapse when belief fails. We formalize this tension in a learning-augmented setting in which an investor observes (possibly erroneous) predictions prior to each decision moment, and we introduce the Rebalanced Arithmetic Mean portfolio with predictions (RAM). Under arbitrary return sequences, we prove that RAM captures at least a constant fraction of the hindsight-optimal wealth when forecasts are perfect while still exceeding the geometric mean of the sequence even when the predictions are adversarial. Comprehensive experiments on large-scale equity data strengthen our theory, spanning both synthetic prediction streams and production-grade machine-learning models. RAM advantages over universal-portfolio variants equipped with side information across various regimes. These results demonstrate that modest predictive power can be reliably converted into tangible gains without sacrificing worst-case guarantees.'}",https://openreview.net{'value': '/pdf/347d4b89a6029f1128cdfe309b92657d00b3d8e2.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=zOCENGh1Jg,{'value': 'Private Evolution Converges'},Tomás González; Giulia Fanti; Aaditya Ramdas,~Tomás_González1; ~Giulia_Fanti1; ~Aaditya_Ramdas2,"{'value': ['Differential Privacy', 'Synthetic Data', 'Private Evolution']}","{'value': 'Private Evolution (PE) is a promising training-free method for differentially private (DP) synthetic data generation. While it achieves strong performance in some domains (e.g., images and text), its behavior in others (e.g., tabular data) is less consistent. To date, the only theoretical analysis of the convergence of PE depends on unrealistic assumptions about both the algorithm’s behavior and the structure of the sensitive dataset. In this work, we develop a new theoretical framework to understand PE’s practical behavior and identify sufficient conditions for its convergence. For $d$-dimensional sensitive datasets with $n$ data points from a convex and compact domain, we prove that under the right hyperparameter settings and given access to the Gaussian variation API proposed in \\cite{PE23}, PE \nproduces an $(\\varepsilon, \\delta)$-DP synthetic dataset with expected 1-Wasserstein distance $\\tilde{O}(d(n\\varepsilon)^{-1/d})$ from the original; this establishes worst-case convergence of the algorithm as $n \\to \\infty$. Our analysis extends to general Banach spaces as well. We also connect PE to the Private Signed Measure Mechanism, a method for DP synthetic data generation that has thus far not seen much practical adoption. We demonstrate the practical relevance of our theoretical findings in experiments.'}",https://openreview.net{'value': '/pdf/224415e39081ae5cf7ee3813a1639169f65f02ca.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=zDU5sfYK1Z,{'value': 'Curriculum Design for Trajectory-Constrained Agent: Compressing Chain-of-Thought Tokens in LLMs'},Georgios Tzannetos; Parameswaran Kamalaruban; Adish Singla,~Georgios_Tzannetos1; ~Parameswaran_Kamalaruban2; ~Adish_Singla2,"{'value': ['Curriculum Design', 'Large Language Models', 'Reinforcement Learning', 'Chain-of-Thought Reasoning']}","{'value': 'Training agents to operate under strict constraints during deployment, such as limited resource budgets or stringent safety requirements, presents significant challenges, especially when these constraints render the task complex. In this work, we propose a curriculum learning strategy that gradually tightens constraints during training, enabling the agent to incrementally master the deployment requirements. Inspired by self-paced learning techniques in unconstrained reinforcement learning (RL), our approach facilitates a smoother transition to challenging environments by initially training on simplified versions of the constraints and progressively introducing the full deployment conditions. We provide a theoretical analysis using an RL agent in a binary-tree Markov Decision Process (MDP) to demonstrate that our curriculum strategy can accelerate training relative to a baseline approach that imposes the trajectory constraints from the outset. Moreover, we empirically validate the effectiveness and generality of our method across both RL and large language model (LLM) agents in diverse settings, including a binary-tree MDP, a multi-task navigation domain, and a math reasoning task with two benchmarks. These results highlight the potential of curriculum design in enhancing the efficiency and performance of agents operating under complex trajectory constraints during deployment. Moreover, when applied to LLMs, our strategy enables compression of output chain-of-thought tokens, achieving a substantial inference speedup on consumer hardware, demonstrating its effectiveness for resource-constrained deployment.'}",https://openreview.net{'value': '/pdf/3ef59a66c354632e4cb2789380511589795e676c.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=z4AMrCOetn,{'value': 'LogicTree: Improving Complex Reasoning of LLMs via Instantiated Multi-step Synthetic Logical Data'},Zehao Wang; Lin Yang; Jie Wang; Kehan Wang; Hanzhu Chen; Bin Wang; Jianye HAO; Defu Lian; Bin Li; Enhong Chen,~Zehao_Wang10; ~Lin_Yang8; ~Jie_Wang1; ~Kehan_Wang4; ~Hanzhu_Chen1; ~Bin_Wang12; ~Jianye_HAO1; ~Defu_Lian1; ~Bin_Li8; ~Enhong_Chen1,"{'value': ['large language model', 'logical reasoning', 'data synthesis']}","{'value': ""Despite their remarkable performance on various tasks, Large Language Models (LLMs) still struggle with logical reasoning, particularly in complex and multi-step reasoning processes. \nAmong various efforts to enhance LLMs' reasoning capabilities, synthesizing large-scale, high-quality logical reasoning datasets has emerged as a promising direction. \nHowever, existing methods often rely on predefined templates for logical reasoning data generation, limiting their adaptability to real-world scenarios. \nTo address the limitation, we propose **LogicTree**, a novel framework for efficiently synthesizing multi-step logical reasoning dataset that excels in both complexity and instantiation.\nBy iteratively searching for applicable logic rules based on structural pattern matching to perform backward deduction, **LogicTree** constructs multi-step logic trees that capture complex reasoning patterns. \nFurthermore, we employ a two-stage LLM-based approach to instantiate various real-world scenarios for each logic tree, generating consistent real-world reasoning processes that carry contextual significance.   This helps LLMs develop generalizable logical reasoning abilities across diverse scenarios rather than merely memorizing templates.\nExperiments on multiple benchmarks demonstrate that our approach achieves an average improvement of 9.4\\% in accuracy on complex logical reasoning tasks.""}",https://openreview.net{'value': '/pdf/30059572044fffae201f1e0daf92fc78a5aef218.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=yyWeSAsOhs,{'value': 'Reinforcing Spatial Reasoning in Vision-Language Models with Interwoven Thinking and Visual Drawing'},Junfei Wu; Jian Guan; Kaituo Feng; Qiang Liu; Shu Wu; Liang Wang; Wei Wu; Tieniu Tan,~Junfei_Wu1; ~Jian_Guan1; ~Kaituo_Feng1; ~Qiang_Liu8; ~Shu_Wu1; ~Liang_Wang3; ~Wei_Wu1; ~Tieniu_Tan1,"{'value': ['Large Vision-Language Models', 'Spatial Reasoning']}","{'value': ""As textual reasoning with large language models (LLMs) has advanced significant, there has been growing interest in enhancing the multimodal reasoning capabilities of large vision-language models (LVLMs). However, existing methods primarily approach multimodal reasoning in a straightforward, text-centric manner, where both reasoning and answer derivation are conducted purely through text, with the only difference being the presence of multimodal input. As a result, these methods often encounter fundamental limitations in spatial reasoning tasks that demand precise geometric understanding and continuous spatial tracking\\textemdash capabilities that humans achieve through mental visualization and manipulation. To address the limitations, we propose drawing to reason in space, a novel paradigm that enables LVLMs to reason through elementary drawing operations in the visual space. By equipping models with basic drawing operations including annotating bounding boxes and drawing auxiliary lines, we empower them to express and analyze spatial relationships through direct visual manipulation, meanwhile avoiding the performance ceiling imposed by specialized perception tools in previous tool-integrated reasoning approaches. To cultivate this capability, we develop a three-stage training framework: cold-start training with synthetic data to establish basic drawing abilities, reflective rejection sampling to enhance self-reflection behaviors, and reinforcement learning to directly optimize for target rewards. Extensive experiments demonstrate that our model, named \\textsc{Spark}, consistently outperforms existing methods across diverse spatial reasoning benchmarks involving maze navigation, static spatial reasoning, video-based reasoning and multi-view-based reasoning tasks, with an average improvement of 11.5\\%. Ablation studies reveal the critical role of each training stage, with reflective rejection sampling particularly enhancing the model's self-correction capabilities and reasoning potential.""}",https://openreview.net{'value': '/pdf/0da039d9be67a74526e2ce4408db4cde8bdca6f5.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=yst8MHfcgP,{'value': 'A Minimalist Example of Edge-of-Stability and Progressive Sharpening'},Liming Liu; Zixuan Zhang; Simon Shaolei Du; Tuo Zhao,~Liming_Liu2; ~Zixuan_Zhang5; ~Simon_Shaolei_Du1; ~Tuo_Zhao2,"{'value': ['edge of stability', 'progressive sharpening', 'gradient descent', 'training dynamics', 'nonconvex optimization', 'linear network']}","{'value': 'Recent advances in deep learning optimization have unveiled two intriguing phenomena under large learning rates: Edge of Stability (EoS) and Progressive Sharpening (PS), challenging classical Gradient Descent (GD) analyses. Current research approaches, using either generalist frameworks or minimalist examples, face significant limitations in explaining these phenomena. This paper advances the minimalist approach by introducing a two-layer network with a two-dimensional input, where one dimension is relevant to the response and the other is irrelevant. Through this model, we rigorously prove the existence of progressive sharpening and self-stabilization under large learning rates, and establish non-asymptotic analysis of the training dynamics and sharpness along the entire GD trajectory. Besides, we connect our minimalist example to existing works by reconciling the existence of a well-behaved ""stable set"" between minimalist and generalist analyses, and extending the analysis of Gradient Flow Solution sharpness to our two-dimensional input scenario. These findings provide new insights into the EoS phenomenon from both parameter and input data distribution perspectives, potentially informing more effective optimization strategies in deep learning practice.'}",https://openreview.net{'value': '/pdf/a8bf13859ff298eb0eb348ebfa68902f3a79e790.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=yruGxKsZyH,{'value': 'Model Inversion with Layer-Specific Modeling and Alignment for Data-Free Continual Learning'},Ruilin Tong; Haodong Lu; Yuhang Liu; Dong Gong,~Ruilin_Tong1; ~Haodong_Lu2; ~Yuhang_Liu1; ~Dong_Gong1,"{'value': ['Continual learning', 'Model inversion', 'Vision-Language models.']}","{'value': 'Continual learning (CL) aims to incrementally train a model to a sequence of tasks while maintaining performance on previously seen ones. Despite effectiveness in mitigating forgetting, data storage and replay may be infeasible due to privacy or security constraints, and are impractical or unavailable for arbitrary pre-trained models. Data-free or examplar-free CL aims to continually update models with new\ntasks without storing previous data. In addition to regularizing updates, we employ model inversion to synthesize data from the trained model, anchoring learned knowledge through replay without retaining old data. However, model inversion in predictive models faces two key challenges. First, generating inputs (e.g., images) solely from highly compressed output labels (e.g., classes) often causes drift between synthetic and real data. Replaying on such synthetic data can contaminate and erode knowledge learned from real data, further degrading inversion quality over time. Second, performing inversion is usually computationally expensive, as each iteration requires backpropagation through the entire model and many steps are needed for convergence. These problems are more severe with large pre-trained models such as Contrastive Language-Image Pre-training (CLIP) models. To improve model inversion efficiency, we propose Per-layer Model Inversion (PMI) approach inspired by the faster convergence of single-layer optimization. The inputs optimized from PMI provide strong initialization for full-model inversion, significantly reducing the number of iterations required for convergence. To address feature distribution shift, we model class-wise feature distribution using a Gaussian distribution and preserve distributional information with a contrastive model. Sampling features for inversion ensures alignment between synthetic and real feature distributions. Combining PMI and feature modeling, we demonstrate the feasibility of incrementally training models on new classes by generating data from pseudo image features mapped through semantic-aware feature projection. Our method shows strong effectiveness and compatibility across multiple CL settings.'}",https://openreview.net{'value': '/pdf/b975219011d2f075274117ad71ea11352dc3b191.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=yZzhaHygWW,{'value': 'Optimizing Retrieval for RAG via Reinforced Contrastive Learning'},Jiawei Zhou; Lei Chen,~Jiawei_Zhou2; ~Lei_Chen7,"{'value': ['Retrieval-augmented Generation', 'RAG']}","{'value': 'As retrieval-augmented generation (RAG) becomes increasingly widespread, the role of information retrieval (IR) is shifting from retrieving information for human users to retrieving contextual knowledge for artificial intelligence (AI) systems, where relevance becomes difficult to define or annotate beforehand. To address this challenge, we propose R3, a Retrieval framework optimized for RAG through trial-and-feedback Reinforced contrastive learning. Unlike prior approaches that rely on annotated or synthetic data for supervised fine-tuning, R3 enables the retriever to dynamically explore and optimize relevance within the RAG environment. During training, the retrieved results interact with the environment to produce contrastive signals that automatically guide the retriever’s self-improvement. Extensive experiments across diverse tasks demonstrate that R3 improves RAG performance by 5.2% over the original retriever and surpasses state-of-the-art retrievers by 4.9%, while achieving comparable results to LLM-augmented retrieval and RAG systems built on post-trained or instruction-tuned LLMs. It is both efficient and practical, requiring only 4 GPUs and completing training within a single day.'}",https://openreview.net{'value': '/pdf/42f89d981cc18b9ae81274013d5d8f928bc89985.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=yRxXTdElLv,{'value': 'SWE-SQL: Illuminating LLM Pathways to Solve User SQL Issues in Real-World Applications'},Jinyang Li; Xiaolong Li; Ge Qu; Per Jacobsson; Bowen Qin; Binyuan Hui; Shuzheng Si; Nan Huo; Xiaohan Xu; Yue Zhang; Ziwei Tang; Yuanshuai Li; Florensia Widjaja; Xintong Zhu; Feige Zhou; Yongfeng Huang; Yannis Papakonstantinou; Fatma Ozcan; Chenhao Ma; Reynold Cheng,~Jinyang_Li4; ~Xiaolong_Li9; ~Ge_Qu2; ~Per_Jacobsson1; ~Bowen_Qin1; ~Binyuan_Hui1; ~Shuzheng_Si1; ~Nan_Huo1; ~Xiaohan_Xu1; ~Yue_Zhang44; ~Ziwei_Tang1; ~Yuanshuai_Li1; ~Florensia_Widjaja1; ~Xintong_Zhu1; ~Feige_Zhou1; ~Yongfeng_Huang2; ~Yannis_Papakonstantinou3; ~Fatma_Ozcan1; ~Chenhao_Ma1; ~Reynold_Cheng1,"{'value': ['text-to-SQL', 'LLM', 'SQL issues']}","{'value': ""Resolution of complex SQL issues persists as a significant bottleneck in real-world database applications. Current Large Language Models (LLMs), while adept at text-to-SQL translation, have not been rigorously evaluated on the more challenging task of debugging on SQL issues. In order to address this gap, we introduce **BIRD-CRITIC**, a new SQL issue debugging benchmark comprising 530 carefully curated PostgreSQL tasks (**BIRD-CRITIC-PG**) and 570 multi-dialect tasks (**BIRD-CRITIC-Multi**), which are distilled from authentic user issues and replayed within new environments to facilitate rigorous and contamination-free evaluation. Baseline evaluations on BIRD-CRITIC underscore the task's complexity, with the leading reasoning model **O3-Mini** achieving only 38.87% success rate on **BIRD-CRITIC-PG** and 33.33% on **BIRD-CRITIC-Multi**. Meanwhile, realizing open-source models for database tasks is crucial which can empower local development while safeguarding data privacy. Therefore, we present **Six-Gym** (**S**ql-f**IX**-Gym), a training environment for elevating the capabilities of open-source models specifically for SQL issue debugging. This environment leverages **SQL-Rewind** strategy, which automatically generates executable issue-solution datasets by reverse-engineering issues from verified SQLs. However, popular trajectory-based fine-tuning methods do not explore substantial supervisory signals. We further propose *f*-Plan Boosting, which extracts high-level debugging plans automatically from SQL solutions, enabling the teacher LLMs to harvest and produce 73.7% more successful trajectories for training. We integrate these components into an open-source agent, **BIRD-Fixer**. Based on Qwen-2.5-Coder-14B, **BIRD-Fixer** raises its success rate to 38.11% on **BIRD-CRITIC-PG** and 29.65% on **BIRD-CRITIC-Multi**, surpassing many leading proprietary models such as Claude-3.7-Sonnet and GPT-4.1, marking a significant step toward democratizing sophisticated SQL-debugging capabilities for both research and industry.""}",https://openreview.net{'value': '/pdf/066b7a410529cb3aa3b2c501216707391ef9b50a.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=yNVDkAjGjw,{'value': 'Semantic and Visual Crop-Guided Diffusion Models for Heterogeneous Tissue Synthesis in Histopathology'},Saghir Alfasly; Wataru Uegami; MD ENAMUL HOQ; Ghazal Alabtah; Hamid Tizhoosh,~Saghir_Alfasly1; ~Wataru_Uegami1; ~MD_ENAMUL_HOQ1; ~Ghazal_Alabtah1; ~Hamid_Tizhoosh1,"{'value': ['Histopathology', 'Generative models', 'Diffusion models', 'Image synthesis', 'Heterogeneous tissue', 'Self-supervised diffusion model']}","{'value': 'Synthetic data generation in histopathology faces unique challenges: preserving tissue heterogeneity, capturing subtle morphological features, and scaling to unannotated datasets. We present a latent diffusion model that generates realistic heterogeneous histopathology images through a novel dual-conditioning approach combining semantic segmentation maps with tissue-specific visual crops. Unlike existing methods that rely on text prompts or abstract visual embeddings, our approach preserves critical morphological details by directly incorporating raw tissue crops from corresponding semantic regions. For annotated datasets (i.e., Camelyon16, Panda), we extract patches ensuring 20-80% tissue heterogeneity. For unannotated data (i.e., TCGA), we introduce a self-supervised extension that clusters whole-slide images into 100 tissue types using foundation model embeddings, automatically generating pseudo-semantic maps for training. Our method synthesizes high-fidelity images with precise region-wise annotations, achieving superior performance on downstream segmentation tasks. When evaluated on annotated datasets, models trained on our synthetic data show competitive performance to those trained on real data, demonstrating the utility of controlled heterogeneous tissue generation. In quantitative evaluation, prompt‐guided synthesis reduces Fréchet Distance by up to 6× on Camelyon16 (from 430.1 to 72.0) and yields 2–3× lower FD across Panda and TCGA. Downstream DeepLabv3+ models trained solely on synthetic data attain test IoU of 0.71 and 0.95 on Camelyon16 and Panda, within 1–2% of real‐data baselines (0.72 and 0.96). By scaling to 11,765 TCGA whole‐slide images without manual annotations, our framework offers a practical solution for an urgent need for generating diverse, annotated histopathology data, addressing a critical bottleneck in computational pathology.'}",https://openreview.net{'value': '/pdf/36dae182a59f7f066937abff6a9883128f2dbbec.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=yKUwkihcsi,{'value': 'Iterative Tool Usage Exploration for Multimodal Agents via Step-wise Preference Tuning'},Pengxiang Li; Zhi Gao; Bofei Zhang; Yapeng Mi; Xiaojian Ma; Chenrui Shi; Tao Yuan; Yuwei Wu; Yunde Jia; Song-Chun Zhu; Qing Li,~Pengxiang_Li1; ~Zhi_Gao5; ~Bofei_Zhang1; ~Yapeng_Mi1; ~Xiaojian_Ma1; ~Chenrui_Shi1; ~Tao_Yuan6; ~Yuwei_Wu1; ~Yunde_Jia1; ~Song-Chun_Zhu1; ~Qing_Li1,"{'value': ['Tool usage', 'Multimodal agents']}","{'value': 'Multimodal agents, which integrate a controller (e.g., a vision language model) with external tools, have demonstrated remarkable capabilities in tackling complex multimodal tasks.\nExisting approaches for training these agents, both supervised fine-tuning and reinforcement learning, depend on extensive human-annotated task-answer pairs and tool trajectories.\nHowever, for complex multimodal tasks, such annotations are prohibitively expensive or impractical to obtain.\nIn this paper, we propose an iterative tool usage exploration method for multimodal agents without any pre-collected data, namely SPORT, via step-wise preference optimization to refine the trajectories of tool usage. Our method enables multimodal agents to autonomously discover effective tool usage strategies through self-exploration and optimization, eliminating the bottleneck of human annotation.\nSPORT has four iterative components: task synthesis, step sampling, step verification, and preference tuning.\nWe first synthesize multimodal tasks using language models. \nThen, we introduce a novel trajectory exploration scheme, where step sampling and step verification are executed alternately to solve synthesized tasks.\nIn step sampling, the agent tries different tools and obtains corresponding results. \nIn step verification, we employ a verifier to provide AI feedback to construct step-wise preference data. \nThe data is subsequently used to update the controller for tool usage through preference tuning, producing a SPORT agent.\nBy interacting with real environments, the SPORT agent gradually evolves into a more refined and capable system.\nEvaluation in the GTA and GAIA benchmarks shows that the SPORT agent achieves 6.41% and  3.64% improvements, underscoring the generalization and effectiveness introduced by our method.'}",https://openreview.net{'value': '/pdf/a3ae43bcdfe712b2361e4ab5254bbce2bcc0dd95.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=yI55mj6anU,{'value': 'Prompt Tuning Decision Transformers with Structured and Scalable Bandits'},Finn Rietz; Oleg Smirnov; Sara Karimi; Lele Cao,~Finn_Rietz1; ~Oleg_Smirnov1; ~Sara_Karimi2; ~Lele_Cao1,"{'value': ['Reinforcement Learning', 'Decision Transformer', 'Prompt tuning', 'Bandits', 'Multi-task transfer']}","{'value': 'Prompt tuning has emerged as a key technique for adapting large pre-trained Decision Transformers (DTs) in offline Reinforcement Learning (RL), particularly in multi-task and few-shot settings. The Prompting Decision Transformer (PDT) enables task generalization via trajectory prompts sampled uniformly from expert demonstrations -- without accounting for prompt informativeness. In this work, we propose a bandit-based prompt-tuning method that learns to construct optimal trajectory prompts from demonstration data at inference time. We devise a structured bandit architecture operating in the trajectory prompt space, achieving linear rather than combinatorial scaling with prompt size.  Additionally, we show that the pre-trained PDT itself can serve as a powerful feature extractor for the bandit, enabling efficient reward modeling across various environments. We theoretically establish regret bounds and demonstrate empirically that our method consistently enhances performance across a wide range of tasks, high-dimensional environments, and out-of-distribution scenarios, outperforming existing baselines in prompt tuning.'}",https://openreview.net{'value': '/pdf/10302094ac55e3990cb7a824d69f1ebc2e76163c.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=yG8vmj3EAU,{'value': 'Fisher meets Feynman: score-based variational inference with a product of experts'},Diana Cai; Robert M. Gower; David Blei; Lawrence K. Saul,~Diana_Cai1; ~Robert_M._Gower1; ~David_Blei2; ~Lawrence_K._Saul3,"{'value': ['black-box variational inference', 'score matching', 'product of experts', 'multivariate t-distribution', 'Feynman identity', 'Fisher divergence', 'expressive variational family']}","{'value': 'We introduce a highly expressive yet distinctly tractable family for black-box variational inference (BBVI).  Each member of this family is a weighted product of experts (PoE), and each weighted expert in the product is proportional to a multivariate $t$-distribution.  These products of experts can model distributions with skew, heavy tails, and multiple modes, but to use them for BBVI, we must be able to sample from their densities.  We show how to do this by reformulating these products of experts as latent variable models with auxiliary Dirichlet random variables.  These Dirichlet variables emerge from a Feynman identity, originally developed for loop integrals in quantum field theory, that expresses the product of multiple fractions (or in our case, $t$-distributions) as an integral over the simplex. We leverage this simplicial latent space to draw weighted samples from these products of experts---samples which BBVI then uses to find the PoE that best approximates a target density. Given a collection of experts, we derive an iterative procedure to optimize the exponents that determine their geometric weighting in the PoE. At each iteration, this procedure minimizes a regularized Fisher divergence to match the scores of the variational and target densities at a batch of samples drawn from the current approximation.  This minimization reduces to a convex quadratic program, and we prove under general conditions that these updates converge exponentially fast to a near-optimal weighting of experts.  We conclude by evaluating this approach on a variety of synthetic and real-world target distributions.'}",https://openreview.net{'value': '/pdf/283c04eff98c06d71284d62b538af8f6e30cccc7.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=yFerzf9v1b,{'value': 'Distil-E2D: Distilling Image-to-Depth Priors for Event-Based Monocular Depth Estimation'},Jie Long Lee; Gim Hee Lee,~Jie_Long_Lee1; ~Gim_Hee_Lee1,"{'value': ['event camera', 'neuromorphic vision', 'monocular depth estimation']}","{'value': 'Event cameras are neuromorphic vision sensors that asynchronously capture pixel-level intensity changes with high temporal resolution and dynamic range. These make them well suited for monocular depth estimation under challenging lighting conditions. However, progress in event-based monocular depth estimation remains constrained by the quality of supervision: LiDAR-based depth labels are inherently sparse, spatially incomplete, and prone to artifacts. Consequently, these signals are suboptimal for learning dense depth from sparse events. To address this problem, we propose Distil-E2D, a framework that distills depth priors from the image domain into the event domain by generating dense synthetic pseudolabels from co-recorded APS or RGB frames using foundational depth models. These pseudolabels complement sparse LiDAR depths with dense semantically rich supervision informed by large-scale image-depth datasets. To reconcile discrepancies between synthetic and real depths, we introduce a Confidence-Guided Calibrated Depth Loss that learns nonlinear depth alignment and adaptively weights supervision by alignment confidence. Additionally, our architecture integrates past predictions via a Context Transformer and employs a Dual-Decoder Training scheme that enhances encoder representations by jointly learning metric and relative depth abstractions. Experiments on benchmark datasets show that Distil-E2D achieves state-of-the-art performance in event-based monocular depth estimation across both event-only and event+APS settings.'}",https://openreview.net{'value': '/pdf/cc4eaeabc4ad5686aa702592dc45e87a141680d7.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=y9zhXirhCa,{'value': 'Provably Efficient Multi-Task Meta Bandit Learning via Shared Representations'},Jiabin Lin; Shana Moothedath,~Jiabin_Lin1; ~Shana_Moothedath1,"{'value': ['Meta learning', 'Multi-task learning', 'Linear bandits', 'Low dimensional learning', 'Representation learning']}","{'value': 'Learning-to-learn or meta-learning focuses on developing algorithms that leverage prior experience to quickly acquire new skills or adapt to novel environments. A crucial component of meta-learning is representation learning, which aims to construct data representations capable of transferring knowledge across multiple tasks—a critical advantage in data-scarce settings. We study how representation learning can improve the efficiency of bandit problems. We consider $T$ $d$-dimensional linear bandits that share a common low-dimensional linear representation. We provide provably fast, sample-efficient algorithms to address the two key problems in meta-learning: (1) learning a common set of features from multiple related bandit tasks and (2) transferring this knowledge to new, unseen bandit tasks. We validated the theoretical results through numerical experiments using real-world and synthetic datasets, comparing them against benchmark algorithms.'}",https://openreview.net{'value': '/pdf/a50ce19567badf6e5faea2a4a50857b3f670e49a.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=y2eWc6jrlu,{'value': 'Speculative Jacobi-Denoising Decoding for Accelerating Autoregressive Text-to-image Generation'},Yao Teng; Fu-Yun Wang; Xian Liu; Zhekai Chen; Han Shi; Yu Wang; Zhenguo Li; Weiyang Liu; Difan Zou; Xihui Liu,~Yao_Teng1; ~Fu-Yun_Wang1; ~Xian_Liu1; ~Zhekai_Chen1; ~Han_Shi1; ~Yu_Wang3; ~Zhenguo_Li1; ~Weiyang_Liu1; ~Difan_Zou1; ~Xihui_Liu1,"{'value': ['Acceleration', 'Auto-regressive Model', 'Text-to-image Generation']}","{'value': 'As a new paradigm of visual content generation, autoregressive text-to-image models suffer from slow inference due to their sequential token-by-token decoding process, often requiring thousands of model forward passes to generate a single image. To address this inefficiency, we propose Speculative Jacobi-Denoising Decoding (SJD2), a framework that incorporates the denoising process into Jacobi iterations to enable parallel token generation in autoregressive models. Our method introduces a next-clean-token prediction paradigm that enables the pre-trained autoregressive models to accept noise-perturbed token embeddings and predict the next clean tokens through low-cost fine-tuning. This denoising paradigm guides the model towards more stable Jacobi trajectories. During inference, our method initializes token sequences with Gaussian noise and performs iterative next-clean-token-prediction in the embedding space. We employ a probabilistic criterion to verify and accept multiple tokens in parallel, and refine the unaccepted tokens for the next iteration with the denoising trajectory. Experiments show that our method can accelerate generation by reducing model forward passes while maintaining the visual quality of generated images.'}",https://openreview.net{'value': '/pdf/687ac997036b688b5040f3693447ac71e61256b1.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=xs5aoDH3HX,{'value': 'Equi-mRNA: Protein Translation Equivariant Encoding for mRNA Language Models'},Mehdi Yazdani-Jahromi; Ali Khodabandeh Yalabadi; Ozlem Garibay,~Mehdi_Yazdani-Jahromi1; ~Ali_Khodabandeh_Yalabadi1; ~Ozlem_Garibay1,"{'value': ['Geometric Deep Learning', 'Equivariance', 'Group Theory', 'mRNA Sequence Modeling', 'Language Models for Biology']}","{'value': 'The growing importance of mRNA therapeutics and synthetic biology highlights the need for models that capture the latent structure of synonymous codon (different triplets encoding the same amino acid) usage, which subtly modulates translation efficiency and gene expression. While recent efforts incorporate codon-level inductive biases through auxiliary objectives, they often fall short of explicitly modeling the structured relationships that arise from the genetic code’s inherent symmetries. We introduce Equi‑mRNA, the first codon‑level equivariant mRNA language model that explicitly encodes synonymous codon symmetries as cyclic subgroups of 2D Special Orthogonal matrix ($\\mathrm{SO}(2)$). By combining group‑theoretic priors with an auxiliary equivariance loss and symmetry‑aware pooling, Equi‑mRNA learns biologically grounded representations that outperform vanilla baselines across multiple axes. On downstream property‑prediction tasks including expression, stability, and riboswitch switching Equi‑mRNA delivers up to $\\approx$ 10\\% improvements in accuracy. In sequence generation, it produces mRNA constructs that are up to $\\approx$ 4$\\times$ more realistic under Fréchet BioDistance metrics and $\\approx$ 28\\% better preserve functional properties compared to vanilla baseline. Interpretability analyses further reveal that learned codon‑rotation distributions recapitulate known GC‑content biases and tRNA abundance patterns, offering novel insights into codon usage. Equi‑mRNA establishes a new biologically principled paradigm for mRNA modeling, with significant implications for the design of next‑generation therapeutics.'}",https://openreview.net{'value': '/pdf/fb6ecf76f37c7cb3bdcb1b9ef0854c0039cb7678.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=xpjWEgf8zi,{'value': 'VAGEN: Reinforcing World Model Reasoning for Multi-Turn VLM Agents'},Kangrui Wang; Pingyue Zhang; Zihan Wang; Yaning Gao; Linjie Li; Qineng Wang; Hanyang Chen; Yiping Lu; Zhengyuan Yang; Lijuan Wang; Ranjay Krishna; Jiajun Wu; Li Fei-Fei; Yejin Choi; Manling Li,~Kangrui_Wang2; ~Pingyue_Zhang1; ~Zihan_Wang23; ~Yaning_Gao1; ~Linjie_Li1; ~Qineng_Wang1; ~Hanyang_Chen3; ~Yiping_Lu1; ~Zhengyuan_Yang1; ~Lijuan_Wang1; ~Ranjay_Krishna1; ~Jiajun_Wu1; ~Li_Fei-Fei1; ~Yejin_Choi1; ~Manling_Li1,"{'value': ['Visual States', 'World Modeling', 'Multi-turn RL', 'VLM Agents']}","{'value': 'A major challenge in training VLM agents, compared to LLM agents, is that states shift from simple texts to complex visual observations, which introduces partial observability and demands robust world modeling. We ask: can VLM agents build internal world models through explicit visual state reasoning? In this work, we architecturally enforce and reward VLM agent’s reasoning process via reinforcement learning (RL), formulating the problem as a Partially Observable Markov Decision Process (POMDP). We demonstrate that structuring agent’s reasoning into StateEstimation (“what is the current state?”) and TransitionModeling (“what is next?”) is critical by studying five reasoning strategies. Investigating how agents should ground visual states and represent these internal beliefs, we reveal the optimal representations are task-dependent: Natural Language excels at capturing semantic relationships for general tasks, while Structured formats are essential for high-precision manipulation. These insights motivate our approach to reward shaping and credit assignment. We leverage a WorldModeling Reward to densely rewards the agent’s turn-by-turn state predictions, while our Bi-Level General Advantage Estimation (Bi-Level GAE) enables turn-aware credit assignment. Through such world model reasoning, we enable a 3B model to achieve performance of 0.82 on a set of five diverse agent tasks, nearly 3× improvement over its untrained counterpart (0.21) and surpassing proprietary reasoning models like GPT-5 (0.75), Gemini 2.5 Pro (0.67) and Claude 4.5 (0.62). All experiments are supported by our VAGEN framework, a scalable system for training and analyzing multi-turn VLM agents across diverse visual environments'}",https://openreview.net{'value': '/pdf/ed11882b04656406635941c99bb0b5dbf475a088.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=xpY3C8HxNh,{'value': 'Escaping Collapse: The Strength of Weak Data for Large Language Model Training'},Kareem Amin; Sara Babakniya; Alex Bie; Weiwei Kong; Umar Syed; Sergei Vassilvitskii,~Kareem_Amin2; ~Sara_Babakniya1; ~Alex_Bie1; ~Weiwei_Kong1; ~Umar_Syed1; ~Sergei_Vassilvitskii2,"{'value': ['Large-language models', 'synthetic data']}","{'value': 'Synthetically-generated data plays an increasingly larger role in training large language models. However, while synthetic data has been found to be useful, studies have also shown that without proper curation it can cause LLM performance to plateau, or even ""collapse"", after many training iterations. In this paper, we formalize this question and develop a theoretical framework to investigate how much curation is needed in order to ensure that LLM performance continually improves. Our analysis is inspired by boosting, a classic machine learning technique that leverages a very weak learning algorithm to produce an arbitrarily good classifier. The approach we analyze subsumes many recently proposed methods for training LLMs on synthetic data, and thus our analysis sheds light on why they are successful, and also suggests opportunities for future improvement. We present experiments that validate our theory, and show that dynamically focusing labeling resources on the most challenging examples --- in much the same way that boosting focuses the efforts of the weak learner --- leads to improved performance.'}",https://openreview.net{'value': '/pdf/87b7b2555554bc1fda223a1e4acaec6e976ce71b.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=xpVkYQofw9,{'value': 'A Differential and Pointwise Control Approach to Reinforcement Learning'},Minh Phuong Nguyen; Chandrajit L. Bajaj,~Minh_Phuong_Nguyen1; ~Chandrajit_L._Bajaj1,"{'value': ['Hamiltonian Dynamics', 'Policy Optimization', 'Pointwise Convergence', 'Continuous-Time Control', 'Physics-Informed Learning', 'Scientific Computing']}","{'value': 'Reinforcement learning (RL) in continuous state-action spaces remains challenging in scientific computing due to poor sample efficiency and lack of pathwise physical consistency. We introduce Differential Reinforcement Learning (Differential RL), a novel framework that reformulates RL from a continuous-time control perspective via a differential dual formulation. This induces a Hamiltonian structure that embeds physics priors and ensures consistent trajectories without requiring explicit constraints. To implement Differential RL, we develop Differential Policy Optimization (dfPO), a pointwise, stage-wise algorithm that refines local movement operators along the trajectory for improved sample efficiency and dynamic alignment. We establish pointwise convergence guarantees, a property not available in standard RL, and derive a competitive theoretical regret bound of $\\mathcal{O}(K^{5/6})$. Empirically, dfPO outperforms standard RL baselines on representative scientific computing tasks, including surface modeling, grid control, and molecular dynamics, under low-data and physics-constrained conditions.'}",https://openreview.net{'value': '/pdf/0a2ac464f6aaad9e4739d540b11e127d4d8d8e95.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=xmYT1JqVpj,{'value': 'Policy Compatible Skill Incremental Learning via Lazy Learning Interface'},Daehee Lee; Dongsu Lee; TaeYoon Kwack; Wonje Choi; Honguk Woo,~Daehee_Lee1; ~Dongsu_Lee1; ~TaeYoon_Kwack1; ~Wonje_Choi2; ~Honguk_Woo1,"{'value': ['Skill Incremental Learning', 'Imitation Learning']}","{'value': ""Skill Incremental Learning (SIL) is the process by which an embodied agent expands and refines its skill set over time by leveraging experience gained through interaction with its environment or by the integration of additional data. SIL facilitates efficient acquisition of hierarchical policies grounded in reusable skills for downstream tasks. However, as the skill repertoire evolves, it can disrupt compatibility with existing skill-based policies, limiting their reusability and generalization. In this work, we propose SIL-C, a novel framework that ensures skill-policy compatibility, allowing improvements in incrementally learned skills to enhance the performance of downstream policies without requiring policy re-training or structural adaptation. SIL-C employs a bilateral lazy learning-based mapping technique to dynamically align the subtask space referenced by policies with the skill space decoded into agent behaviors. This enables each subtask, derived from the policy's decomposition of a complex task, to be executed by selecting an appropriate skill based on trajectory distribution similarity. We evaluate SIL-C across diverse SIL scenarios and demonstrate that it maintains compatibility between evolving skills and downstream policies while ensuring efficiency throughout the learning process.""}",https://openreview.net{'value': '/pdf/4614d54bd18b90e9e7395a7915beb640b7c67065.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=xlDmm4r98R,{'value': 'FACT: Mitigating Inconsistent Hallucinations in LLMs via Fact-Driven Alternating Code-Text Training'},Xinxin You; Qixin Sun; Chenwei Yan; Xiao Zhang; Chen Ning; Xiangling Fu; Si Liu; Guoping Hu; Shijin Wang; Ji Wu; Xien Liu,~Xinxin_You2; ~Qixin_Sun1; ~Chenwei_Yan1; ~Xiao_Zhang9; ~Chen_Ning1; ~Xiangling_Fu2; ~Si_Liu5; ~Guoping_Hu1; ~Shijin_Wang1; ~Ji_Wu3; ~Xien_Liu4,"{'value': ['Inconsistent Hallucination', 'Fact-Driven Code-Text', 'Alternating Training']}","{'value': 'Inconsistent hallucinations remain a major challenge for large language models (LLMs), undermining the accuracy and reliability of fact-based reasoning in real-world applications. Existing approaches often rely on task-specific training or adaptation, such as hand-crafted synthetic datasets for domain tasks or solutions mainly focused on numerical reasoning, thereby limiting generalizability to broader, unseen NLP tasks. Inspired by the structural rigor and logical consistency of programming languages, we observe that fact-based texts can be mapped to programming structures due to their inherent patterns. We further propose FACT, a novel Fact-driven Alternating Code-text Training framework that alternates between text-to-code and code-to-text prediction. FACT is the first task-agnostic paradigm that embeds code and natural language in a shared semantic space, thereby transferring the logical consistency of code to LLM outputs in NLP tasks. Experiments show that with only a small subset of Wiki-40B-en for training, FACT reduces inconsistent hallucinations by 2.7%–8.0% and improves overall performance by 2.5%–6.1% in three leading LLMs and four diverse datasets covering QA and summarization tasks. This framework offers a new perspective on addressing challenging hallucinations in LLMs, contributing to more reliable AI.'}",https://openreview.net{'value': '/pdf/8f06a63c8a49d0e18846db034cd1bfcf042c535e.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=xkGxogC2mF,{'value': 'Shortcutting Pre-trained Flow Matching Diffusion Models is Almost Free Lunch'},Xu Cai; Yang Wu; Qianli Chen; Haoran Wu; Lichuan Xiang; Hongkai Wen,~Xu_Cai1; ~Yang_Wu12; ~Qianli_Chen3; ~Haoran_Wu13; ~Lichuan_Xiang1; ~Hongkai_Wen1,"{'value': ['diffusion', 'flow-matching', 'distillation', 'fast inference']}","{'value': 'We present an ultra-efficient post-training method for shortcutting large-scale pre-trained flow matching diffusion models into efficient few-step samplers, enabled by novel velocity field self-distillation.  While shortcutting in flow matching, originally introduced by shortcut models, offers flexible trajectory-skipping capabilities, it requires a specialized step-size embedding incompatible with existing models unless retraining from scratch—a process nearly as costly as pretraining itself.\n\nOur key contribution is thus imparting a more aggressive shortcut mechanism to standard flow matching models (e.g., Flux), leveraging a unique distillation principle that obviates the need for step-size embedding.  Working on the velocity field rather than sample space and learning rapidly from self-guided distillation in an online manner, our approach trains efficiently, e.g., producing a 3-step Flux <1 A100 day.  Beyond distillation, our method can be incorporated into the pretraining stage itself, yielding models that inherently learn efficient, few-step flows without compromising quality.  This capability also enables, to our knowledge, the first few-shot distillation method (e.g., 10 text-image pairs) for dozen-billion-parameter diffusion models, delivering state-of-the-art performance at almost free cost.'}",https://openreview.net{'value': '/pdf/bb6661f039bb34b57158cc6e2db47ed9febeb477.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=xj0DXLQZCS,{'value': 'World Models as Reference Trajectories for Rapid Motor Adaptation'},Carlos Stein Brito; Daniel C McNamee,~Carlos_Stein_Brito1; ~Daniel_C_McNamee1,"{'value': ['Motor Adaptation', 'Model-based RL', 'Rapid Adaptation', 'Model Reference Control', 'Data Efficiency', 'Naturalistic Motor Control']}","{'value': 'Learned control policies often fail when deployed in real-world environments with changing dynamics. When system dynamics shift unexpectedly, performance degrades until models are retrained on new data. We introduce Reflexive World Models (RWM), a dual control framework that uses world model predictions as implicit reference trajectories for rapid adaptation. Our method separates the control problem into long-term reward maximization through reinforcement learning and robust motor execution through reward-free rapid control in latent space. This dual architecture achieves significantly faster adaptation with low online computational cost compared to model-based RL baselines, while maintaining near-optimal performance. The approach combines the benefits of flexible policy learning through reinforcement learning with rapid error correction capabilities, providing a theoretically grounded method for maintaining performance in high-dimensional continuous control tasks under varying dynamics.'}",https://openreview.net{'value': '/pdf/e0550b6c170bc81bc5125a7a5a8905a027c2b22a.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=xiP7TZG58o,{'value': 'Context-Aware Regularization with Markovian Integration for Attention-Based Nucleotide Analysis'},Mohammadsaleh Refahi; Mahdi Abavisani; Bahrad A. Sokhansanj; James R. Brown; Gail Rosen,~Mohammadsaleh_Refahi1; ~Mahdi_Abavisani2; ~Bahrad_A._Sokhansanj1; ~James_R._Brown1; ~Gail_Rosen1,"{'value': ['DNA Language Models', 'Markovian Regularization']}","{'value': 'Transformers have revolutionized nucleotide sequence analysis, yet capturing long‑range dependencies remains challenging. Recent studies show that autoregressive transformers often exhibit Markovian behavior by relying on fixed-length context windows for next-token prediction. However, standard self-attention mechanisms are computationally inefficient for long sequences due to their quadratic complexity and do not explicitly enforce global transition consistency.\n\nWe introduce CARMANIA (Context-Aware Regularization with Markovian Integration for Attention-Based Nucleotide Analysis), a self-supervised pretraining framework that augments next-token (NT) prediction with a transition-matrix (TM) loss. The TM loss aligns predicted token transitions with empirically derived n-gram statistics from each input sequence, encouraging the model to capture higher-order dependencies beyond local context. This integration enables CARMANIA to learn organism-specific sequence structures that reflect both evolutionary constraints and functional organization.\n\nWe evaluate  CARMANIA across diverse genomic tasks, including regulatory element prediction, functional gene classification, taxonomic inference, antimicrobial resistance detection, and biosynthetic gene cluster classification. CARMANIA outperforms the previous best long-context model by at least 7\\%, matches state-of-the-art on shorter sequences (exceeding prior results on 20/40 tasks while running $\\sim$2.5$\\times$ faster), and shows particularly strong improvements on enhancer and housekeeping gene classification tasks—including up to a 34\\% absolute gain in Matthews correlation coefficient (MCC) for enhancer prediction. The TM loss boosts accuracy in 33 of 40 tasks, especially where local motifs or regulatory patterns drive prediction. This enables more effective modeling of sequence-dependent biological features while maintaining robustness across non-coding and low-signal regions. Code available at https://github.com/EESI/carmania.'}",https://openreview.net{'value': '/pdf/b7026a98b0b62b04a541294f90c16910b8403da5.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=xgiMK8FtSI,{'value': 'LLM-DAMVC: A Large Language Model Assisted Dynamic Agent for Multi-View Clustering'},HaiMing Xu; Qianqian Wang,~HaiMing_Xu2; ~Qianqian_Wang5,{'value': ['Multi-View Clustering']},"{'value': 'Multi-view clustering integrates the consistency and complementarity of different views to achieve unsupervised data grouping. Existing multi-view clustering methods primarily confront two challenges: i) they generally perform feature extraction in the feature domain, which is sensitive to noise and may neglect cluster-specific information that is indistinguishable in the original space; ii) current dynamic fusion methods adopt static strategies to learn weights, lacking capability to adjust strategies adaptively under complex scenarios according to variations in data distribution and view quality. To address these issues, we propose a large language model assisted dynamic agent for multi-view clustering (LLM-DAMVC), a novel framework that recasts multi-view clustering as a dynamic decision-making problem orchestrated by a large language model. Specifically, each view is equipped with complementary agents dedicated to feature extraction. A dual-domain contrastive module is introduced to optimize feature consistency and enhance cluster separability in both the feature domain and frequency domain. Additionally, an LLM-assisted view fusion mechanism provides a flexible fusion weight learning strategy that can be adaptively applied to complex scenarios and significantly different views. Extensive experimental results validate the effectiveness and superiority of the proposed method.'}",https://openreview.net{'value': '/pdf/d914ffb9e0367b3b16b179576b3f9c84161ec202.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=xTWWKMxY1x,{'value': 'ROSE: Remove Objects with Side Effects in Videos'},Chenxuan Miao; Yutong Feng; Jianshu Zeng; Zixiang Gao; Liu Hantang; Yunfeng Yan; Donglian Qi; Xi Chen; Bin Wang; Hengshuang Zhao,~Chenxuan_Miao1; ~Yutong_Feng2; ~Jianshu_Zeng1; ~Zixiang_Gao1; ~Liu_Hantang1; ~Yunfeng_Yan1; ~Donglian_Qi1; ~Xi_Chen30; ~Bin_Wang35; ~Hengshuang_Zhao2,{'value': ['video inpainting; diffusion transformer; video generation']},"{'value': ""Video object removal has achieved advanced performance due to the recent success of video generative models. However, when addressing the side effects of objects, \\textit{e.g.,} their shadows and reflections, existing works struggle to eliminate these effects for the scarcity of paired video data as supervision. This paper presents \\method, termed \\textbf{R}emove \\textbf{O}bjects with \\textbf{S}ide \\textbf{E}ffects, a framework that systematically studies the object's effects on environment, which can be categorized into five common cases: shadows, reflections, light, translucency and mirror. Given the challenges of curating paired videos exhibiting the aforementioned effects, we leverage a 3D rendering engine for synthetic data generation. We carefully construct a fully-automatic pipeline for data preparation, which simulates a large-scale paired dataset with diverse scenes, objects, shooting angles, and camera trajectories. ROSE is implemented as an video inpainting model built on diffusion transformer. To localize all object-correlated areas, the entire video is fed into the model for reference-based erasing. Moreover, additional supervision is introduced to explicitly predict the areas affected by side effects, which can be revealed through the differential mask between the paired videos. To fully investigate the model performance on various side effect removal, we presents a new benchmark, dubbed ROSE-Bench, incorporating both common scenarios and the five special side effects for comprehensive evaluation. Experimental results demonstrate that \\method achieves superior performance compared to existing video object erasing models and generalizes well to real-world video scenarios.""}",https://openreview.net{'value': '/pdf/5975f8faa8829f509cbd893e918c8569abedd3f6.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=xRb0taq0pD,{'value': 'On Group Sufficiency Under Label Bias'},Haoran Zhang; Olawale Elijah Salaudeen; Marzyeh Ghassemi,~Haoran_Zhang4; ~Olawale_Elijah_Salaudeen1; ~Marzyeh_Ghassemi2,"{'value': ['algorithmic fairness', 'label noise', 'label bias', 'group sufficiency']}","{'value': 'Real-world classification datasets often contain label bias, where observed labels differ systematically from the true labels at different rates for different demographic groups. Machine learning models trained on such datasets may then exhibit disparities in predictive performance across these groups. In this work, we characterize the problem of learning fair classification models with respect to the underlying ground truth labels when given only label biased data. We focus on the particular fairness definition of group sufficiency, i.e. equal calibration of risk scores across protected groups. We theoretically show that enforcing fairness with respect to label biased data necessarily results in group miscalibration with respect to the true labels. We then propose a regularizer which minimizes an upper bound on the sufficiency gap by penalizing a conditional mutual information term. Across experiments on eight tabular, image, and text datasets with both synthetic and real label noise, we find that our method reduces the sufficiency gap by up to 7.2% with no significant decrease in overall accuracy.'}",https://openreview.net{'value': '/pdf/7edfbac351d6df824000dac9d85c25c26244b150.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=xQfZprbSWL,{'value': 'Spectral Compressive Imaging via Chromaticity-Intensity Decomposition'},Xiaodong Wang; Zijun He; Ping Wang; Lishun Wang; Yanan Hu; Xin Yuan,~Xiaodong_Wang10; ~Zijun_He1; ~Ping_Wang9; ~Lishun_Wang1; ~Yanan_Hu2; ~Xin_Yuan4,"{'value': ['computational imaging', 'computational photography']}","{'value': 'In coded aperture snapshot spectral imaging (CASSI), the captured measurement entangles spatial and spectral information, posing a severely ill-posed inverse problem for hyperspectral images (HSIs) reconstruction. Moreover, the captured radiance inherently depends on scene illumination, making it difficult to recover the intrinsic spectral reflectance that remains invariant to lighting conditions. To address these challenges, we propose a chromaticity-intensity decomposition framework, which disentangles an HSI into a spatially smooth intensity map and a spectrally variant chromaticity cube. The chromaticity encodes lighting-invariant reflectance, enriched with high-frequency spatial details and local spectral sparsity. Building on this decomposition, we develop CIDNet—a Chromaticity-Intensity Decomposition unfolding network within a dual-camera CASSI system. CIDNet integrates a hybrid spatial-spectral Transformer tailored to reconstruct fine-grained and sparse spectral chromaticity and a degradation-aware, spatially-adaptive noise estimation module that captures anisotropic noise across iterative stages. Extensive experiments on both synthetic and real-world CASSI datasets demonstrate that our method achieves superior performance in both spectral and chromaticity fidelity. Code is released at: \\url{https://github.com/xiaodongwo/CIDNet}.'}",https://openreview.net{'value': '/pdf/e93af85f59a95a3556d75c2a12483afbb7276009.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=xLFYd1owiP,{'value': 'Spot the Fake: Large Multimodal Model-Based Synthetic Image Detection with Artifact Explanation'},Siwei Wen; Junyan Ye; Peilin Feng; Hengrui Kang; Zichen Wen; Yize Chen; Jiang Wu; wenjun wu; Conghui He; Weijia Li,~Siwei_Wen5; ~Junyan_Ye1; ~Peilin_Feng1; ~Hengrui_Kang1; ~Zichen_Wen1; ~Yize_Chen2; ~Jiang_Wu7; ~wenjun_wu3; ~Conghui_He2; ~Weijia_Li2,"{'value': ['Synthetic Image Detection', 'Deepfake', 'Large Multimodal Model']}","{'value': 'With the rapid advancement of Artificial Intelligence Generated Content (AIGC) technologies, synthetic images have become increasingly prevalent in everyday life, posing new challenges for authenticity assessment and detection. Despite the effectiveness of existing methods in evaluating image authenticity and locating forgeries, these approaches often lack human interpretability and do not fully address the growing complexity of synthetic data. To tackle these challenges, we introduce FakeVLM, a specialized large multimodal model designed for both general synthetic image and DeepFake detection tasks. FakeVLM not only excels in distinguishing real from fake images but also provides clear, natural language explanations for image artifacts, enhancing interpretability. Additionally, we present FakeClue, a comprehensive dataset containing over 100,000 images across seven categories, annotated with fine-grained artifact clues in natural language. FakeVLM demonstrates performance comparable to expert models while eliminating the need for additional classifiers, making it a robust solution for synthetic data detection. Extensive evaluations across multiple datasets confirm the superiority of FakeVLM in both authenticity classification and artifact explanation tasks, setting a new benchmark for synthetic image detection. The code, model weights, and dataset can be found here: https://github.com/opendatalab/FakeVLM.'}",https://openreview.net{'value': '/pdf/1faa3599271dee156c7eef97f811db5f481541ac.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=xB1ZNgq0Xp,{'value': 'Synthetic Series-Symbol Data Generation for Time Series Foundation Models'},Wenxuan Wang; Kai Wu; Yujian Betterest Li; Dan Wang; Xiaoyu Zhang,~Wenxuan_Wang7; ~Kai_Wu3; ~Yujian_Betterest_Li1; ~Dan_Wang2; ~Xiaoyu_Zhang6,"{'value': ['Time Series Analysis', 'Foundation Model', 'Data Scarcity']}","{'value': 'Foundation models for time series analysis (TSA) have attracted significant attention. However, challenges such as training data scarcity and imbalance continue to hinder their development. Inspired by complex dynamic system theories, we design a series-symbol data generation mechanism, enabling the unrestricted creation of high-quality time series data paired with corresponding symbolic expressions. To leverage series-symbol data pairs with strong correlations, we develop SymTime, a pre-trained foundation model for enhancing time series representation using symbolic information. SymTime demonstrates competitive performance across five major TSA tasks when fine-tunes with downstream tasks, rivaling foundation models pre-trained on real-world datasets. This approach underscores the potential of series-symbol data generation and pretraining mechanisms in overcoming data scarcity and enhancing task performance. The code is available at https://github.com/wwhenxuan/SymTime.'}",https://openreview.net{'value': '/pdf/1f5bda16d8f6ad7f41cdcb6cc4a41ecc4a79cd44.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=x9XepNPGJ5,{'value': 'DeepHalo: A Neural Choice Model with Controllable Context Effects'},Shuhan Zhang; Zhi Wang; Rui Gao; Shuang Li,~Shuhan_Zhang4; ~Zhi_Wang12; ~Rui_Gao3; ~Shuang_Li3,"{'value': ['Choice Model', 'Preference Learning', 'Deep Learning']}","{'value': 'Modeling human decision-making is central to applications such as recommendation, preference learning, and human-AI alignment. While many classic models assume context-independent choice behavior, a large body of behavioral research shows that preferences are often influenced by the composition of the choice set itself---a phenomenon known as the context effect or Halo effect. These effects can manifest as pairwise (first-order) or even higher-order interactions among the available alternatives.\nRecent models that attempt to capture such effects either focus on the featureless setting or, in the feature-based setting, rely on restrictive interaction structures or entangle interactions across all orders, which limits interpretability. \nIn this work, we propose DeepHalo, a neural modeling framework that incorporates features while enabling explicit control over interaction order and principled interpretation of context effects.\nOur model enables systematic identification of interaction effects by order and serves as a universal approximator of context-dependent choice functions when specialized to a featureless setting.\nExperiments on synthetic and real-world datasets demonstrate strong predictive performance while providing greater transparency into the drivers of choice.'}",https://openreview.net{'value': '/pdf/db79ba397b3f6bed54c73279f40e86d03f8b7d43.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=x7EjzpW5XC,{'value': 'Rectifying Soft-Label Entangled Bias in Long-Tailed Dataset Distillation'},Chenyang Jiang; Hang Zhao; Xinyu Zhang; Zhengcen Li; Qiben Shan; Shaocong Wu; Jingyong Su,~Chenyang_Jiang1; ~Hang_Zhao4; ~Xinyu_Zhang15; ~Zhengcen_Li1; ~Qiben_Shan2; ~Shaocong_Wu1; ~Jingyong_Su3,{'value': ['dataset distillation; long-tailed recognition']},"{'value': 'Dataset distillation compresses large-scale datasets into compact, highly informative synthetic data, significantly reducing storage and training costs. However, existing research primarily focuses on balanced datasets and struggles to perform under real-world long-tailed distributions. In this work, we emphasize the critical role of soft labels in long-tailed dataset distillation and uncover the underlying mechanisms contributing to performance degradation.\nSpecifically, we derive an imbalance-aware generalization bound for model trained on distilled dataset. We then identify two primary sources of soft-label bias, which originate from the distillation model and the distilled images, through systematic perturbation of the data imbalance levels.\nTo address this, we propose ADSA, an Adaptive Soft-label Alignment module that calibrates the entangled biases. This lightweight module integrates seamlessly into existing distillation pipelines and consistently improves performance. On ImageNet-1k-LT with EDC and IPC=50, ADSA improves tail-class accuracy by up to 11.8\\% and raises overall accuracy to 41.4\\%. \nExtensive experiments demonstrate that ADSA provides a robust and generalizable solution under limited label budgets and across a range of distillation techniques.'}",https://openreview.net{'value': '/pdf/9b5a8c74febdc6f655af1b5ac3e18eb6674b02be.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=x5KUOlYKQr,{'value': 'Listwise Preference Diffusion Optimization for User Behavior Trajectories Prediction'},Hongtao Huang; Chengkai Huang; Junda Wu; Tong Yu; Julian McAuley; Lina Yao,~Hongtao_Huang1; ~Chengkai_Huang1; ~Junda_Wu1; ~Tong_Yu3; ~Julian_McAuley1; ~Lina_Yao2,"{'value': ['User Behavior Prediction', 'Diffusion Models']}","{'value': 'Forecasting multi-step user behavior trajectories requires reasoning over structured preferences across future actions, a challenge overlooked by traditional sequential recommendation. This problem is critical for applications such as personalized commerce and adaptive content delivery, where anticipating a user’s complete action sequence enhances both satisfaction and business outcomes. We identify an essential limitation of existing paradigms: their inability to capture global, listwise dependencies among sequence items. To address this, we formulate User Behavior Trajectory Prediction (UBTP) as a new task setting that explicitly models longterm user preferences. We introduce Listwise Preference Diffusion Optimization (LPDO), a diffusion-based training framework that directly optimizes structured preferences over entire item sequences. LPDO incorporates a Plackett–Luce supervision signal and derives a tight variational lower bound aligned with listwise ranking likelihoods, enabling coherent preference generation across denoising steps and overcoming the independent-token assumption of prior diffusion methods. To rigorously evaluate multi-step prediction quality, we propose the task-specific metric: Sequential Match (SeqMatch), which measures exact trajectory agreement, and adopt Perplexity (PPL), which assesses probabilistic fidelity. Extensive experiments on real-world user behavior benchmarks demonstrate that LPDO consistently outperforms state-of-the-art baselines, establishing a new benchmark for structured preference learning with diffusion models.'}",https://openreview.net{'value': '/pdf/7dcb1ebe911a27afce46273677bc64b0cdc0f97c.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=x2Rk0lSQra,{'value': 'AutoData: A Multi-Agent System for Open Web Data Collection'},Tianyi Ma; Yiyue Qian; Zheyuan Zhang; Zehong Wang; Xiaoye Qian; Feifan Bai; Yifan Ding; Xuwei Luo; Shinan Zhang; Keerthiram Murugesan; Chuxu Zhang; Yanfang Ye,~Tianyi_Ma3; ~Yiyue_Qian2; ~Zheyuan_Zhang5; ~Zehong_Wang2; ~Xiaoye_Qian1; ~Feifan_Bai1; ~Yifan_Ding2; ~Xuwei_Luo1; ~Shinan_Zhang1; ~Keerthiram_Murugesan1; ~Chuxu_Zhang2; ~Yanfang_Ye1,"{'value': ['Multi-Agents', 'LLMs', 'Web Data Collection']}","{'value': ""The exponential growth of data-driven systems and AI technologies has intensified the demand for high-quality web-sourced datasets. \nWhile existing datasets have proven valuable, conventional web data collection approaches face significant limitations in terms of human effort and scalability. \nCurrent data collecting solutions fall into two categories: wrapper-based methods that struggle with adaptability and reproducibility, and large language model (LLM)-based approaches that incur substantial computational and financial costs. \nTo address these challenges, we propose AutoData, a novel multi-agent system for Automated web Data collection, that requires minimal human intervention, i.e., only necessitating a natural language instruction specifying the desired dataset. \nIn addition, AutoData is designed for a robust multi-agent architecture, featuring a novel oriented message hypergraph coordinated by a central task manager, to efficiently organize agents across research and development squads. \nBesides, we introduce a novel hypergraph cache system to advance the multi-agent collaboration process that enables efficient automated data collection and mitigates the token cost issues prevalent in existing LLM-based systems. \nMoreover, we introduce Instruct2DS, a new benchmark dataset supporting live data collection from web sources across three domains: academic, finance, and sports. \nComprehensive evaluations over Instruct2DS and three existing benchmark datasets demonstrate AutoData's superior performance compared to baseline methods.\nCase studies on challenging tasks such as picture book collection and paper extraction from surveys further validate its applicability.""}",https://openreview.net{'value': '/pdf/066a04337fe56fee38b21d8e6b2366fac00856f4.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=x1wZoyS0rC,{'value': 'SceneWeaver: All-in-One 3D Scene Synthesis with an Extensible and Self-Reflective Agent'},Yandan Yang; Baoxiong Jia; Shujie Zhang; Siyuan Huang,~Yandan_Yang1; ~Baoxiong_Jia1; ~Shujie_Zhang4; ~Siyuan_Huang2,"{'value': ['3D Scene Synthesis', 'Reflective Agents']}","{'value': 'Indoor scene synthesis has become increasingly important with the rise of Embodied AI, which requires 3D environments that are not only visually realistic but also physically plausible and functionally diverse. While recent approaches have advanced visual fidelity, they often remain constrained to fixed scene categories, lack sufficient object-level detail and physical consistency, and struggle to align with complex user instructions. In this work, we present SceneWeaver, a reflective agentic framework that unifies diverse scene synthesis paradigms through tool-based iterative refinement. At its core, SceneWeaver employs a language model-based planner to select from a suite of extensible scene generation tools, ranging from data-driven generative models to visual- and LLM-based methods, guided by self-evaluation of physical plausibility, visual realism, and semantic alignment with user input. This closed-loop reason-act-reflect design enables the agent to identify semantic inconsistencies, invoke targeted tools, and update the environment over successive iterations. Extensive experiments on both common and open-vocabulary room types demonstrate that \\model not only outperforms prior methods on physical, visual, and semantic metrics, but also generalizes effectively to complex scenes with diverse instructions, marking a step toward general-purpose 3D environment generation.'}",https://openreview.net{'value': '/pdf/cc7e3c42e7880c5e04ae7e7bc988371ea51d7ee1.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=wryhlhA8QI,{'value': 'Emergent Risk Awareness in Rational Agents under Resource Constraints'},Daniel Jarne Ornia; Nicholas George Bishop; Joel Dyer; Wei-Chen Lee; Ani Calinescu; J. Doyne Farmer; Michael J. Wooldridge,~Daniel_Jarne_Ornia1; ~Nicholas_George_Bishop1; ~Joel_Dyer1; ~Wei-Chen_Lee1; ~Ani_Calinescu1; ~J._Doyne_Farmer1; ~Michael_J._Wooldridge1,"{'value': ['Decision Making', 'Alignment', 'Interpretability', 'Planning']}","{'value': 'Advanced reasoning models with agentic capabilities (AI agents) are deployed to interact with humans and to solve sequential decision‑making problems under (often approximate) utility functions and internal models. When such problems have resource or failure constraints where action sequences may be forcibly terminated once resources are exhausted, agents face implicit trade‑offs that reshape their utility-driven (rational) behaviour. Additionally, since these agents are typically commissioned by a human principal to act on their behalf, asymmetries in constraint exposure can give rise to previously unanticipated misalignment between human objectives and agent incentives. We formalise this setting through a survival bandit framework, provide theoretical and empirical results that quantify the impact of survival‑driven preference shifts, identify conditions under which misalignment emerges and propose mechanisms to mitigate the emergence of risk-seeking or risk-averse behaviours. As a result, this work aims to increase understanding and interpretability of emergent behaviours of AI agents operating under such survival pressure, and offer guidelines for safely deploying such AI systems in critical resource‑limited environments.'}",https://openreview.net{'value': '/pdf/b721f93c521d624000a1eedbe25a30f679087e56.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=wn3VBRz5GK,{'value': 'Many LLMs Are More Utilitarian Than One'},Anita Keshmirian; Razan Baltaji; Babak Hemmatian; Hadi Asghari; Lav R. Varshney,~Anita_Keshmirian2; ~Razan_Baltaji2; ~Babak_Hemmatian1; ~Hadi_Asghari1; ~Lav_R._Varshney1,"{'value': ['multi-agent systems', 'group moral reasoning', 'collective moral judgement', 'ethical alignment', 'AI ethics', 'emergent behavior', 'large language models']}","{'value': ""Moral judgment is integral to large language models' (LLMs) social reasoning. As multi-agent systems gain prominence, it becomes crucial to understand how LLMs function when collaborating compared to operating as individual agents. In human moral judgment, group deliberation leads to a Utilitarian Boost: a tendency to endorse norm violations that inflict harm but maximize benefits for the greatest number of people. We study whether a similar dynamic emerges in multi-agent LLM systems. We test six models on well-established sets of moral dilemmas across two conditions: (1) Solo, where models reason independently, and (2) Group, where they engage in multi-turn discussions in pairs or triads. In personal dilemmas, where agents decide whether to directly harm an individual for the benefit of others, all models rated moral violations as more acceptable when part of a group, demonstrating a Utilitarian Boost similar to that observed in humans. However, the mechanism for the boost in LLMs differed: While humans in groups become more utilitarian due to heightened sensitivity to decision outcomes, LLM groups showed diverse profiles, for example, reduced sensitivity to norms or enhanced impartiality. We report model differences in when and how strongly the boost manifests. We also discuss prompt and agent compositions that enhance or mitigate the effect. We end with a discussion of the implications for AI alignment, multi-agent design, and artificial moral reasoning. Code available at: https://github.com/baltaci-r/MoralAgents""}",https://openreview.net{'value': '/pdf/11ffe64728aca47ad87dbc980cf2ab76b2b81aa3.pdf'},{'abstract_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=wmweEDugTZ,{'value': 'TreeSynth: Synthesizing Diverse Data from Scratch via Tree-Guided Subspace Partitioning'},Sheng Wang; Pengan CHEN; Jingqi Zhou; Qintong Li; Jingwei Dong; Jiahui Gao; Boyang XUE; Jiyue Jiang; Lingpeng Kong; Chuan Wu,~Sheng_Wang12; ~Pengan_CHEN1; ~Jingqi_Zhou1; ~Qintong_Li1; ~Jingwei_Dong1; ~Jiahui_Gao2; ~Boyang_XUE1; ~Jiyue_Jiang1; ~Lingpeng_Kong1; ~Chuan_Wu1,"{'value': ['Data Synthesis', 'Tree-Guided Space Partitioning', 'Data Diversity Enhancement']}","{'value': 'Model customization necessitates high-quality and diverse datasets, but acquiring such data remains time-consuming and labor-intensive. \nDespite the great potential of large language models (LLMs) for data synthesis, current approaches are constrained by limited seed data, model biases and low-variation prompts, resulting in limited diversity and biased distribution with the increase of data scales.\nTo tackle this challenge, we introduce TreeSynth, a tree-guided subspace-based data synthesis approach inspired by decision trees. \nIt constructs a spatial partitioning tree to recursively divide a task-specific full data space (i.e., root node) into numerous atomic subspaces (i.e., leaf nodes) with mutually exclusive and exhaustive attributes to ensure both distinctiveness and comprehensiveness, before synthesizing samples within each atomic subspace. \nThis globally divide-and-synthesize method finally collects subspace samples into a comprehensive dataset, effectively circumventing repetition and space collapse to ensure the diversity of large-scale data synthesis.\nFurthermore, the spatial partitioning tree enables sample allocation into atomic subspaces, allowing the re-balancing of existing datasets for more balanced and comprehensive distributions.\nEmpirically, extensive experiments across diverse benchmarks consistently validates the superior data diversity, model performance, and robust scalability of TreeSynth compared to both human-crafted datasets and peer data synthesis methods, with the average performance gain reaching 10%.\nBesides, the consistent improvements of TreeSynth-balanced datasets highlight its efficacious application to redistribute existing datasets for more comprehensive coverage and the induced performance enhancement. The code is available at https://github.com/cpa2001/TreeSynth.'}",https://openreview.net{'value': '/pdf/c387c97ed27b2d47ecceda9366fa389a37b17b60.pdf'},{'abstract_filter': 'Data Synthesis'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=weU95NZePs,{'value': 'TITAN: A Trajectory-Informed Technique for Adaptive Parameter Freezing in Large-Scale VQE'},Yifeng Peng; Xinyi Li; Samuel Yen-Chi Chen; Kaining Zhang; Zhiding Liang; Ying Wang; Yuxuan Du,~Yifeng_Peng2; ~Xinyi_Li5; ~Samuel_Yen-Chi_Chen1; ~Kaining_Zhang1; ~Zhiding_Liang1; ~Ying_Wang19; ~Yuxuan_Du2,"{'value': ['Barren Plateau', 'Variational Quantum Algorithms', 'Circuit Optimization', 'Measurement Overhead', 'VQE', 'Parameter Freezing']}","{'value': 'Variational quantum Eigensolver (VQE) is a leading candidate for harnessing quantum computers to advance quantum chemistry and materials simulations, yet its training efficiency deteriorates rapidly for large Hamiltonians. Two issues underlie this bottleneck: (i) the no-cloning theorem imposes a linear growth in circuit evaluations with the number of parameters per gradient step; and (ii) deeper circuits encounter barren plateaus (BPs), leading to exponentially increasing measurement overheads. To address these challenges, here we propose a deep learning framework, dubbed Titan, which identifies and freezes inactive parameters of a given ansätze at initialization for a specific class of Hamiltonians, reducing the optimization overhead without sacrificing accuracy. The motivation of Titan starts with our empirical findings that a subset of parameters consistently has negligible influence on training dynamics. Its design combines a theoretically grounded data construction strategy, ensuring each training example is informative and BP-resilient, with an adaptive neural architecture that generalizes across ansätze of varying sizes. Across benchmark transverse-field Ising models, Heisenberg models, and multiple molecule systems up to $30$ qubits, Titan  achieves up to $3\\times$ faster convergence and $40$–$60\\%$ fewer circuit evaluations than state-of-the-art baselines, while matching or surpassing their estimation accuracy. By proactively trimming parameter space, Titan lowers hardware demands and offers a scalable path toward utilizing VQE to advance practical quantum chemistry and materials science.'}",https://openreview.net{'value': '/pdf/1d965c69668154ad8c4ec7cced9e0c21d806fd56.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=waHF2ekuf2,{'value': 'Straight-Line Diffusion Model for Efficient 3D Molecular Generation'},Yuyan Ni; Shikun Feng; Haohan Chi; Bowen Zheng; Huan-ang Gao; Wei-Ying Ma; Zhi-Ming Ma; Yanyan Lan,~Yuyan_Ni1; ~Shikun_Feng3; ~Haohan_Chi1; ~Bowen_Zheng7; ~Huan-ang_Gao1; ~Wei-Ying_Ma2; ~Zhi-Ming_Ma1; ~Yanyan_Lan2,{'value': ['Molecule generation; Diffusion model']},"{'value': 'Diffusion-based models have shown great promise in molecular generation but often require a large number of sampling steps to generate valid samples. In this paper, we introduce a novel Straight-Line Diffusion Model (SLDM) to tackle this problem, by formulating the diffusion process to follow a linear trajectory. The proposed process aligns well with the noise sensitivity characteristic of molecular structures and uniformly distributes reconstruction effort across the generative process, thus enhancing learning efficiency and efficacy. Consequently, SLDM achieves state-of-the-art performance on 3D molecule generation benchmarks, delivering a 100-fold improvement in sampling efficiency.'}",https://openreview.net{'value': '/pdf/c40b5676c1fed73f42c1e750a2933ce421ea342f.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=wVxIBvUAlj,{'value': 'Bohdi: Heterogeneous LLM Fusion with Automatic Data Exploration'},Junqi Gao; Zhichang Guo; Dazhi Zhang; Dong Li; Runze Liu; Pengfei Li; Kai Tian; Biqing Qi,~Junqi_Gao1; ~Zhichang_Guo1; ~Dazhi_Zhang2; ~Dong_Li20; ~Runze_Liu2; ~Pengfei_Li10; ~Kai_Tian3; ~Biqing_Qi1,"{'value': ['Heterogeneous Model Fusion', 'Large Language Models']}","{'value': ""Heterogeneous Large Language Model (LLM) fusion integrates the strengths of multiple source LLMs with different architectures into a target LLM with low computational overhead. While promising, existing methods suffer from two major limitations: 1) **reliance on real data from limited domain** for knowledge fusion, preventing the target LLM from fully acquiring knowledge across diverse domains, and 2) **fixed data allocation proportions** across domains, failing to dynamically adjust according to the target LLM's varying capabilities across domains, leading to a capability imbalance. To overcome these limitations, we propose Bohdi, a synthetic-data-only heterogeneous LLM fusion framework. Through the organization of knowledge domains into a hierarchical tree structure, Bohdi enables automatic domain exploration and multi-domain data generation through multi-model collaboration, thereby comprehensively extracting knowledge from source LLMs. By formalizing domain expansion and data sampling proportion allocation on the knowledge tree as a Hierarchical Multi-Armed Bandit problem, Bohdi leverages the designed DynaBranches mechanism to adaptively adjust sampling proportions based on the target LLM's performance feedback across domains. Integrated with our proposed Introspection-Rebirth (IR) mechanism, DynaBranches dynamically tracks capability shifts during target LLM's updates via Sliding Window Binomial Likelihood Ratio Testing (SWBLRT), further enhancing its online adaptation capability. Comparative experimental results on a comprehensive suite of benchmarks demonstrate that Bohdi significantly outperforms existing baselines on multiple target LLMs, exhibits higher data efficiency, and virtually eliminates the imbalance in the target LLM's capabilities.""}",https://openreview.net{'value': '/pdf/2450ff0c9195847a41ea55365386d55fb6357f6d.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=wU8IKGLpbi,{'value': 'Graph Persistence goes Spectral'},Mattie Ji; Amauri H Souza; Vikas K Garg,~Mattie_Ji1; ~Amauri_H_Souza1; ~Vikas_K_Garg1,"{'value': ['topological data analysis', 'graph neural networks', 'graph machine learning']}","{'value': 'Including intricate topological information (e.g., cycles) provably enhances the expressivity of message-passing graph neural networks (GNNs) beyond the Weisfeiler-Leman (WL) hierarchy. Consequently, Persistent Homology (PH) methods are increasingly employed for graph representation learning. In this context, recent works have proposed decorating classical PH diagrams with vertex and edge features for improved expressivity. However, these methods still fail to capture basic graph structural information. In this paper, we propose SpectRe --- a new topological descriptor for graphs that integrates spectral information into PH diagrams. Notably, SpectRe is strictly more expressive than existing descriptors on graphs. We also introduce notions of global and local stability to analyze existing descriptors and establish that SpectRe is locally stable. Finally, experiments on synthetic and real-world datasets demonstrate the effectiveness of SpectRe and its potential to enhance the capabilities of graph models in relevant learning tasks.  Code is available at https://github.com/Aalto-QuML/SpectRe/.'}",https://openreview.net{'value': '/pdf/bb00b83d32d4cc186d7db88eec9fccb6d16bd79a.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=wGZPNMEHjP,{'value': 'UnCLe: Towards Scalable Dynamic Causal Discovery in Non-linear Temporal Systems'},Tingzhu Bi; Yicheng Pan; Xinrui Jiang; Huize Sun; Meng Ma; Ping Wang,~Tingzhu_Bi1; ~Yicheng_Pan2; ~Xinrui_Jiang2; ~Huize_Sun1; ~Meng_Ma1; ~Ping_Wang7,"{'value': ['causal discovery', 'dynamic causality', 'time series', 'representation learning']}","{'value': 'Uncovering cause-effect relationships from observational time series is fundamental to understanding complex systems. While many methods infer static causal graphs, real-world systems often exhibit *dynamic causality*—where relationships evolve over time. Accurately capturing these temporal dynamics requires time-resolved causal graphs. We propose UnCLe, a novel deep learning method for scalable dynamic causal discovery. UnCLe employs a pair of Uncoupler and Recoupler networks to disentangle input time series into semantic representations and learns inter-variable dependencies via auto-regressive Dependency Matrices. It estimates dynamic causal influences by analyzing datapoint-wise prediction errors induced by temporal perturbations. Extensive experiments demonstrate that UnCLe not only outperforms state-of-the-art baselines on static causal discovery benchmarks but, more importantly, exhibits a unique capability to accurately capture and represent evolving temporal causality in both synthetic and real-world dynamic systems (e.g., human motion). UnCLe offers a promising approach for revealing the underlying, time-varying mechanisms of complex phenomena.'}",https://openreview.net{'value': '/pdf/e4a798bcbd802b1cc46529956c80a5ec46a88fd5.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=w9xETx7HT1,{'value': 'Solving Inverse Problems with FLAIR'},Julius Erbach; Dominik Narnhofer; Andreas Robert Dombos; Bernt Schiele; Jan Eric Lenssen; Konrad Schindler,~Julius_Erbach1; ~Dominik_Narnhofer1; ~Andreas_Robert_Dombos1; ~Bernt_Schiele1; ~Jan_Eric_Lenssen1; ~Konrad_Schindler1,"{'value': ['inverse problems', 'diffusion models', 'flow models', 'stable diffusion', 'posterior sampling', 'variational inference', 'score distillation sampling']}","{'value': 'Flow-based latent generative models such as Stable Diffusion 3 are able to generate images with remarkable quality, even enabling photorealistic text-to-image generation. Their impressive performance suggests that these models should also constitute powerful priors for inverse imaging problems, but that approach has not yet led to comparable fidelity.\n\nThere are several key obstacles: (i) the data likelihood term is usually intractable; (ii) learned generative models cannot be directly conditioned on the distorted observations, leading to conflicting objectives between data likelihood and prior; and (iii) the reconstructions can deviate from the observed data.\nWe present FLAIR, a novel, training-free variational framework that leverages flow-based generative models as prior for inverse problems. To that end, we introduce a variational objective for flow matching that is agnostic to the type of degradation, and combine it with deterministic trajectory adjustments to guide the prior towards regions which are more likely under the posterior. \nTo enforce exact consistency with the observed data, we decouple the optimization of the data fidelity and regularization terms. Moreover, we introduce a time-dependent calibration scheme in which the strength of the regularization is modulated according to off-line accuracy estimates. \nResults on standard imaging benchmarks demonstrate that FLAIR consistently outperforms existing diffusion- and flow-based methods in terms of reconstruction quality and sample diversity. \nSource code is available at https://inverseflair.github.io/.'}",https://openreview.net{'value': '/pdf/6a88f093347553b644d3849c7184febe1184c2fc.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=w1yccSuVtg,{'value': 'Preference-Based Dynamic Ranking Structure Recognition'},Nan Lu; Jian Shi; Xinyu Tian,~Nan_Lu3; ~Jian_Shi9; ~Xinyu_Tian8,"{'value': ['dynamic ranking', 'Bradley-Terry model', 'structural change detection', 'preference-based data', 'clustering']}","{'value': ""Preference-based data often appear complex and noisy but may conceal underlying homogeneous structures. This paper introduces a novel framework of ranking structure recognition for preference-based data. We first develop an approach to identify dynamic ranking groups by incorporating temporal penalties into a spectral estimation for the celebrated Bradley-Terry model. To detect structural changes, we introduce an innovative objective function and present a practicable algorithm based on dynamic programming. Theoretically, we establish the consistency of ranking group recognition by exploiting properties of a random 'design matrix' induced by a reversible Markov chain. We also tailor a group inverse technique to quantify the uncertainty in item ability estimates. Additionally, we prove the consistency of  structure change recognition, ensuring the robustness of the proposed framework. Experiments on both synthetic and real-world datasets demonstrate the practical utility and interpretability of our approach.""}",https://openreview.net{'value': '/pdf/df229853b1bbfe5d4aae2787d3412dfc7d174952.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=vqLoLqUUNB,{'value': 'Knowledge Starts with Practice: Knowledge-Aware Exercise Generative Recommendation with Adaptive Multi-Agent Cooperation'},Yangtao Zhou; Hua Chu; Yongxiang Chen; Ziwen Wang; Jiacheng Liu; Jianan Li; Yueying Feng; Xiangming Li; Zihan Han; Qingshan Li,~Yangtao_Zhou1; ~Hua_Chu1; ~Yongxiang_Chen1; ~Ziwen_Wang10; ~Jiacheng_Liu18; ~Jianan_Li4; ~Yueying_Feng2; ~Xiangming_Li2; ~Zihan_Han1; ~Qingshan_Li1,"{'value': ['Exercise Generative Recommendation', 'Knowledge State Perception', 'Personalized Learning', 'Multi-agent Cooperation']}","{'value': ""Adaptive learning, which requires the in-depth understanding of students' learning processes and rational planning of learning resources, plays a crucial role in intelligent education. However, how to effectively model these two processes and seamlessly integrate them poses significant implementation challenges for adaptive learning. As core learning resources, exercises have the potential to diagnose students' knowledge states during the learning processes and provide personalized learning recommendations to strengthen students' knowledge, thereby serving as a bridge to boost student-oriented adaptive learning. Therefore, we introduce a novel task called Knowledge-aware Exercise Generative Recommendation (KEGR). It aims to dynamically infer students' knowledge states from their past exercise responses and customizably generate new exercises. To achieve KEGR, we propose an adaptive multi-agent cooperation framework, called ExeGen, inspired by the excellent reasoning and generative capabilities of LLM-based AI agents. Specifically, ExeGen coordinates four specialized agents for supervision, knowledge state perception, exercise generation, and quality refinement through an adaptive loop workflow pipeline. More importantly, we devise two enhancement mechanisms in ExeGen: 1) A human-simulated knowledge perception mechanism mimics students' cognitive processes and generates interpretable knowledge state descriptions via demonstration-based In-Context Learning (ICL). In this mechanism, a dual-matching strategy is further designed to retrieve highly relevant demonstrations for reliable ICL reasoning. 2) An exercise generation-adversarial mechanism collaboratively refines exercise generation leveraging a group of quality evaluation expert agents via iterative adversarial feedback. Finally, a comprehensive evaluation protocol is carefully designed to assess ExeGen. Extensive experiments on real-world educational datasets and a practical deployment in college education demonstrate the effectiveness and superiority of ExeGen. The code is available at https://github.com/dsz532/exeGen.""}",https://openreview.net{'value': '/pdf/1adfc528d571320329046af8a43c2ab665336ec5.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=vmYcNhs8Av,{'value': 'IllumiCraft: Unified Geometry and Illumination Diffusion for Controllable Video Generation'},Yuanze Lin; Yi-Wen Chen; Yi-Hsuan Tsai; Ronald Clark; Ming-Hsuan Yang,~Yuanze_Lin1; ~Yi-Wen_Chen1; ~Yi-Hsuan_Tsai1; ~Ronald_Clark2; ~Ming-Hsuan_Yang1,{'value': ['Diffusion Model; Video Generation']},"{'value': 'Although diffusion-based models can generate high-quality and high-resolution video sequences from textual or image inputs, they lack explicit integration of geometric cues when controlling scene lighting and visual appearance across frames. To address this limitation, we propose IllumiCraft, an end-to-end diffusion framework accepting three complementary inputs: (1) high-dynamic-range (HDR) video maps for detailed lighting control; (2) synthetically relit frames with randomized illumination changes (optionally paired with a static background reference image) to provide appearance cues; and (3) 3D point tracks that capture precise 3D geometry information. By integrating the lighting, appearance, and geometry cues within a unified diffusion architecture, IllumiCraft generates temporally coherent videos aligned with user-defined prompts. It supports the background-conditioned and text-conditioned video relighting and provides better fidelity than existing controllable video generation methods.'}",https://openreview.net{'value': '/pdf/c96871437bd8d8c6a557ac25fb2b13c12abb567d.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=vhzqdxuSB3,{'value': 'EditInfinity: Image Editing with Binary-Quantized Generative Models'},Jiahuan Wang; Yuxin Chen; Jun Yu; Guangming Lu; Wenjie Pei,~Jiahuan_Wang3; ~Yuxin_Chen16; ~Jun_Yu1; ~Guangming_Lu2; ~Wenjie_Pei1,{'value': ['Image Editing; Text-to-Image Generation; Autoregressive Models']},"{'value': 'Adapting pretrained diffusion-based generative models for text-driven image editing with negligible tuning overhead has demonstrated remarkable potential. A classical adaptation paradigm, as followed by these methods, first infers the generative trajectory inversely for a given source image by image inversion, then performs image editing along the inferred trajectory guided by the target text prompts. However, the performance of image editing is heavily limited by the approximation errors introduced during image inversion by diffusion models, which arise from the absence of exact supervision in the intermediate generative steps. To circumvent this issue, we investigate the parameter-efficient adaptation of VQ-based generative models for image editing, and leverage their inherent characteristic that the exact intermediate quantized representations of a source image are attainable, enabling more effective supervision for precise image inversion. Specifically, we propose \\emph{EditInfinity}, which adapts \\emph{Infinity}, a binary-quantized generative model, for image editing. We propose an efficient yet effective image inversion mechanism that integrates text prompting rectification and image style preservation, enabling precise image inversion. Furthermore, we devise a holistic smoothing strategy which allows our \\emph{EditInfinity} to perform image editing with high fidelity to source images and precise semantic alignment to the text prompts. Extensive experiments on the PIE-Bench benchmark across ""add"", ""change"", and ""delete"" editing operations, demonstrate the superior performance of our model compared to state-of-the-art diffusion-based baselines. Code available at: \\url{https://github.com/yx-chen-ust/EditInfinity}.'}",https://openreview.net{'value': '/pdf/b96c3f474964ad436c0e12c59f23023ada7a1416.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=vSLzoUoJt6,{'value': 'OWMM-Agent: Open World Mobile Manipulation With Multi-modal Agentic Data Synthesis'},Junting Chen; Haotian Liang; Lingxiao Du; Weiyun Wang; Mengkang Hu; Yao Mu; Wenhai Wang; Jifeng Dai; Ping Luo; Wenqi Shao; Lin Shao,~Junting_Chen2; ~Haotian_Liang2; ~Lingxiao_Du1; ~Weiyun_Wang2; ~Mengkang_Hu1; ~Yao_Mu1; ~Wenhai_Wang2; ~Jifeng_Dai1; ~Ping_Luo2; ~Wenqi_Shao2; ~Lin_Shao2,"{'value': ['Embodied AI', 'Mobile Manipulation', 'Agentic Data Synthesis', 'Vision-Language Model', 'LLM Agent']}","{'value': 'The rapid progress of navigation, manipulation, and vision models has made mobile manipulators capable in many specialized tasks. \nHowever, the open-world mobile manipulation (OWMM) task remains a challenge due to the need for generalization to open-ended instructions and environments, as well as the systematic complexity to integrate high-level decision making with low-level robot control based on both global scene understanding and current agent state. To address this complexity, we propose a novel multi-modal agent architecture that maintains multi-view scene frames and agent states for decision-making and controls the robot by function calling.\nA second challenge is the hallucination from domain shift. To enhance the agent performance, we further introduce an agentic data synthesis pipeline for the OWMM task to adapt the VLM model to our task domain with instruction fine-tuning. We highlight our fine-tuned OWMM-VLM as the first dedicated foundation model for mobile manipulators with global scene understanding, robot state tracking, and multi-modal action generation in a unified model. Through experiments, we demonstrate that our model achieves SOTA performance compared to other foundation models including GPT-4o and strong zero-shot generalization in real world.\nThe project page is at https://hhyhrhy.github.io/owmm-agent-project.'}",https://openreview.net{'value': '/pdf/b83bcc6b13bf3bed81ebb73be9bae7cc2be710e7.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=vS1M06Px6u,{'value': 'MLE-STAR: Machine Learning Engineering Agent via Search and Targeted Refinement'},Jaehyun Nam; Jinsung Yoon; Jiefeng Chen; Jinwoo Shin; Sercan O Arik; Tomas Pfister,~Jaehyun_Nam2; ~Jinsung_Yoon1; ~Jiefeng_Chen2; ~Jinwoo_Shin1; ~Sercan_O_Arik1; ~Tomas_Pfister1,"{'value': ['Machine Learning Engineering Agents', 'LLM Agents']}","{'value': 'Agents based on large language models (LLMs) for machine learning engineering (MLE) can automatically implement ML models via code generation. However, existing approaches to build such agents often rely heavily on inherent LLM knowledge and employ coarse exploration strategies that modify the entire code structure at once. This limits their ability to select effective task-specific models and perform deep exploration within specific components, such as experimenting extensively with feature engineering options. To overcome these, we propose MLE-STAR, a novel approach to build MLE agents. MLE-STAR first leverages external knowledge by using a search engine to retrieve effective models from the web, forming an initial solution, then iteratively refines it by exploring various strategies targeting specific ML components. This exploration is guided by ablation studies analyzing the impact of individual code blocks. Furthermore, we introduce a novel ensembling method using an effective strategy suggested by MLE-STAR. Our experimental results show that MLE-STAR achieves medals in 64% of the Kaggle competitions on the MLE-bench, significantly outperforming the best alternative.'}",https://openreview.net{'value': '/pdf/516c0c7cfd100775da54d33c97e84faffb80b05d.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=vLYpKbZBkD,{'value': 'Generalization Bound of Gradient Flow through Training Trajectory and Data-dependent Kernel'},Yilan Chen; Zhichao Wang; Wei Huang; Andi Han; Taiji Suzuki; Arya Mazumdar,~Yilan_Chen1; ~Zhichao_Wang3; ~Wei_Huang6; ~Andi_Han1; ~Taiji_Suzuki1; ~Arya_Mazumdar1,"{'value': ['Generalization bound', 'algorithm-dependent bound', 'data-dependent kernel', 'neural tangent kernel']}","{'value': 'Gradient-based optimization methods have shown remarkable empirical success, yet their theoretical generalization properties remain only partially understood. In this paper, we establish a generalization bound for gradient flow that aligns with the classical Rademacher complexity bounds for kernel methods—specifically those based on the RKHS norm and kernel trace—through a data-dependent kernel called the loss path kernel (LPK). Unlike static kernels such as NTK, the LPK captures the entire training trajectory, adapting to both data and optimization dynamics, leading to tighter and more informative generalization guarantees. Moreover, the bound highlights how the norm of the training loss gradients along the optimization trajectory influences the final generalization performance. The key technical ingredients in our proof combine stability analysis of gradient flow with uniform convergence via Rademacher complexity. Our bound recovers existing kernel regression bounds for overparameterized neural networks and shows the feature learning capability of neural networks compared to kernel methods. Numerical experiments on real-world datasets validate that our bounds correlate well with the true generalization gap.'}",https://openreview.net{'value': '/pdf/af0ea9dcf0fa1cc544beb7e368004a6cec2d049e.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=vKyiv67VWa,{'value': 'AutoSciDACT: Automated Scientific Discovery through Contrastive Embedding and Hypothesis Testing'},Samuel Bright-Thonney; Christina Reissel; Gaia Grosso; Nathaniel S. Woodward; Katya Govorkova; Andrzej Novak; Sang Eon Park; Eric A. Moreno; Philip Harris,~Samuel_Bright-Thonney1; ~Christina_Reissel1; ~Gaia_Grosso1; ~Nathaniel_S._Woodward1; ~Katya_Govorkova1; ~Andrzej_Novak1; ~Sang_Eon_Park1; ~Eric_A._Moreno1; ~Philip_Harris1,"{'value': ['anomaly detection', 'contrastive learning', 'scientific discovery', 'hypothesis testing', 'automated discovery']}","{'value': 'Novelty detection in large scientific datasets faces two key challenges: the noisy and high-dimensional nature of experimental data,\nand the necessity of making *statistically robust* statements about any observed outliers. While there is a wealth of literature on anomaly detection via dimensionality reduction, most methods do not produce outputs compatible with quantifiable claims of scientific discovery. In this work we directly address these challenges, presenting the first step towards a unified pipeline for novelty detection adapted for the rigorous statistical demands of science. We introduce AutoSciDACT (Automated Scientific Discovery with Anomalous Contrastive Testing), a general-purpose pipeline for detecting novelty in scientific data. AutoSciDACT begins by creating expressive low-dimensional data representations using a contrastive pre-training, leveraging the abundance of high-quality simulated data in many scientific domains alongside expertise that can guide principled data augmentation strategies. These compact embeddings then enable an extremely sensitive machine learning-based two-sample test using the New Physics Learning Machine (NPLM) framework, which identifies and statistically quantifies deviations in observed data relative to a reference distribution (null hypothesis). We perform experiments across a range of astronomical, physical, biological, image, and synthetic datasets, demonstrating strong sensitivity to small injections of anomalous data across all domains.'}",https://openreview.net{'value': '/pdf/24448e230bc07ab076c1f2c372c05c127a5af6e5.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=vKmWKHlQBe,{'value': 'A Single-Loop Gradient Algorithm for Pessimistic Bilevel Optimization via Smooth Approximation'},Qichao Cao; Shangzhi Zeng; Jin Zhang,~Qichao_Cao2; ~Shangzhi_Zeng1; ~Jin_Zhang8,"{'value': ['Bi-level Optimization', 'Pessimistic Bilevel Optimization', 'Gradient Method', 'Single-loop', 'Value Function', 'Smooth Approximation']}","{'value': 'Bilevel optimization has garnered significant attention in the machine learning community recently, particularly regarding the development of efficient numerical methods. \nWhile substantial progress has been made in developing efficient algorithms for optimistic bilevel optimization, the study of methods for solving Pessimistic Bilevel Optimization (PBO) remains relatively less explored, \nespecially the design of fully first-order, single-loop gradient-based algorithms. This paper aims to bridge this research gap. We first propose a novel smooth approximation to the PBO problem, using penalization and regularization techniques. Building upon this approximation, we then propose SiPBA (Single-loop Pessimistic Bilevel Algorithm), a new gradient-based method specifically designed for PBO which avoids second-order derivative information or inner-loop iterations for subproblem solving. We provide theoretical validation for the proposed smooth approximation scheme and establish theoretical convergence for the algorithm SiPBA. Numerical experiments on synthetic examples and practical applications demonstrate the effectiveness and efficiency of SiPBA.'}",https://openreview.net{'value': '/pdf/36e63cded24b89fe6d4b836ccc6e1a5635ddea0f.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=vDV912fa3t,{'value': 'TrackingWorld: World-centric Monocular 3D Tracking of Almost All Pixels'},Jiahao Lu; Weitao Xiong; Jiacheng Deng; Peng Li; Tianyu Huang; Zhiyang Dou; Cheng Lin; Sai-Kit Yeung; Yuan Liu,~Jiahao_Lu5; ~Weitao_Xiong1; ~Jiacheng_Deng2; ~Peng_Li14; ~Tianyu_Huang3; ~Zhiyang_Dou1; ~Cheng_Lin1; ~Sai-Kit_Yeung3; ~Yuan_Liu3,{'value': ['deep learning; computer vision; 3D point tracking']},"{'value': 'Monocular 3D tracking aims to capture the long-term motion of pixels in 3D space from a single monocular video and has witnessed rapid progress in recent years. However, we argue that the existing monocular 3D tracking methods still fall short in separating the camera motion from foreground dynamic motion and cannot densely track newly emerging dynamic subjects in the videos. To address these two limitations, we propose TrackingWorld, a novel pipeline for dense 3D tracking of almost all pixels within a world-centric 3D coordinate system. First, we introduce a tracking upsampler that efficiently lifts the arbitrary sparse 2D tracks into dense 2D tracks. Then, to generalize the current tracking methods to newly emerging objects, we apply the upsampler to all frames and reduce the redundancy of 2D tracks by eliminating the tracks in overlapped regions. Finally, we present an efficient optimization-based framework to back-project dense 2D tracks into world-centric 3D trajectories by estimating the camera poses and the 3D coordinates of these 2D tracks. Extensive evaluations on both synthetic and real-world datasets demonstrate that our system achieves accurate and dense 3D tracking in a world-centric coordinate frame.'}",https://openreview.net{'value': '/pdf/6a5cd62d3c5cee13be0fef7d614aec24ef83d0e8.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=uvyr9bYwL6,{'value': 'A*-Thought: Efficient Reasoning via Bidirectional Compression for Low-Resource Settings'},Xiaoang Xu; Shuo Wang; Xu Han; Zhenghao Liu; Huijia Wu; Pei Pei Li; Zhiyuan Liu; Maosong Sun; Zhaofeng He,~Xiaoang_Xu1; ~Shuo_Wang13; ~Xu_Han2; ~Zhenghao_Liu2; ~Huijia_Wu1; ~Pei_Pei_Li2; ~Zhiyuan_Liu1; ~Maosong_Sun1; ~Zhaofeng_He1,"{'value': ['long-to-short', 'thought compression', 'reasoning', 'efficient CoT']}","{'value': 'Large Reasoning Models (LRMs) achieve superior performance by extending the thought length. However, a lengthy thinking trajectory leads to reduced efficiency. Most of the existing methods are stuck in the assumption of overthinking and attempt to reason efficiently by compressing the Chain-of-Thought, but this often leads to performance degradation. To address this problem, we introduce A*-Thought, an efficient tree search-based unified framework designed to identify and isolate the most essential thoughts from the extensive reasoning chains produced by these models. It formulates the reasoning process of LRMs as a search tree, where each node represents a reasoning span in the giant reasoning space. By combining the A* search algorithm with a cost function specific to the reasoning path, it can efficiently compress the chain of thought and determine a reasoning path with high information density and low cost. In addition, we also propose a bidirectional importance estimation mechanism, which further refines this search process and enhances its efficiency beyond uniform sampling. Extensive experiments on several advanced math tasks show that A*-Thought effectively balances performance and efficiency over a huge search space. Specifically, A*-Thought can improve the performance of QwQ-32B by 2.39$\\times$ with low-budget and reduce the length of the output token by nearly 50\\% with high-budget. The proposed method is also compatible with several other LRMs, demonstrating its generalization capability. The code can be accessed at: https://github.com/AI9Stars/AStar-Thought.'}",https://openreview.net{'value': '/pdf/38488a17c621dbf0003d6f92b1c2a48bce677a54.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=uvTea5Rfek,{'value': 'Extracting task-relevant preserved dynamics from contrastive aligned neural recordings'},Yiqi Jiang; Kaiwen Sheng; Yujia Gao; E. Kelly Buchanan; Yu Shikano; Seung Je Woo; Yixiu Zhao; Tony Hyun Kim; Fatih Dinc; Scott Linderman; Mark Schnitzer,~Yiqi_Jiang2; ~Kaiwen_Sheng1; ~Yujia_Gao3; ~E._Kelly_Buchanan1; ~Yu_Shikano1; ~Seung_Je_Woo1; ~Yixiu_Zhao2; ~Tony_Hyun_Kim1; ~Fatih_Dinc1; ~Scott_Linderman1; ~Mark_Schnitzer1,"{'value': ['neural latent embedding', 'neural latent dynamics', 'contrastive learning']}","{'value': 'Recent work indicates that low-dimensional dynamics of neural and behavioral data are often preserved across days and subjects. However, extracting these preserved dynamics remains challenging: high-dimensional neural population activity and the recorded neuron populations vary across recording sessions. While existing modeling tools can improve alignment between neural and behavioral data, they often operate on a per-subject basis or discretize behavior into categories, disrupting its natural continuity and failing to capture the underlying dynamics. We introduce $\\underline{\\text{C}}$ontrastive $\\underline{\\text{A}}$ligned $\\underline{\\text{N}}$eural $\\underline{\\text{D}}$$\\underline{\\text{Y}}$namics (CANDY), an end‑to‑end framework that aligns neural and behavioral data using rank-based contrastive learning, adapted for continuous behavioral variables, to project neural activity from different sessions onto a shared low-dimensional embedding space. CANDY fits a shared linear dynamical system to the aligned embeddings, enabling an interpretable model of the conserved temporal structure in the latent space. We validate CANDY on synthetic and real-world datasets spanning multiple species, behaviors, and recording modalities. Our results show that CANDY is able to learn aligned latent embeddings and preserved dynamics across neural recording sessions and subjects, and it achieves improved cross-session behavior decoding performance. We further show that the latent linear dynamical system generalizes to new sessions and subjects, achieving comparable or even superior behavior decoding performance to models trained from scratch. These advances enable robust cross‑session behavioral decoding and offer a path towards identifying shared neural dynamics that underlie behavior across individuals and recording conditions. The code and two-photon imaging data of striatal neural activity that we acquired here are available at https://github.com/schnitzer-lab/CANDY-public.git.'}",https://openreview.net{'value': '/pdf/0ed3b33d625999258b315d490afb5ed907c9e1d3.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=ur295YVtmt,{'value': 'ReMA: Learning to Meta-Think for LLMs with Multi-agent Reinforcement Learning'},Ziyu Wan; Yunxiang LI; Xiaoyu Wen; Yan Song; Hanjing Wang; Linyi Yang; Mark Schmidt; Jun Wang; Weinan Zhang; Shuyue Hu; Ying Wen,~Ziyu_Wan2; ~Yunxiang_LI3; ~Xiaoyu_Wen2; ~Yan_Song5; ~Hanjing_Wang1; ~Linyi_Yang1; ~Mark_Schmidt1; ~Jun_Wang2; ~Weinan_Zhang1; ~Shuyue_Hu1; ~Ying_Wen1,"{'value': ['Reasoning', 'Large Language Model', 'Multi-Agent', 'Reinforcement Learning']}","{'value': 'Recent research on Reasoning of Large Language Models (LLMs) has sought to further enhance their performance by integrating meta-thinking—enabling models to monitor, evaluate, and control their reasoning processes for more adaptive and effective problem-solving.\nHowever, current single-agent work lacks a specialized design for acquiring meta-thinking, resulting in low efficacy.\nTo address this challenge, we introduce Reinforced Meta-thinking Agents (ReMA), a novel framework that leverages Multi-Agent Reinforcement Learning (MARL) to elicit meta-thinking behaviors, encouraging LLMs to think about thinking.\nReMA decouples the reasoning process into two hierarchical agents: a high-level meta-thinking agent responsible for generating strategic oversight and plans, and a low-level reasoning agent for detailed executions.\nThrough iterative reinforcement learning with aligned objectives, these agents explore and learn collaboration, leading to improved generalization and robustness.\nEmpirical results from single-turn experiments demonstrate that ReMA outperforms single-agent RL baselines on complex reasoning tasks, including competitive-level mathematical benchmarks and LLM-as-a-Judge benchmarks.\nAdditionally, we further extend ReMA to multi-turn interaction settings, leveraging turn-level ratio and parameter sharing to improve efficiency.\nComprehensive ablation studies further illustrate the evolving dynamics of each distinct agent, providing valuable insights into how the meta-thinking reasoning process enhances the reasoning capabilities of LLMs.'}",https://openreview.net{'value': '/pdf/4ef88667f9d6e59455e6805cd91df2e8e519f9d0.pdf'},{'abstract_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=uodE9CAXaF,{'value': 'OSCAR: One-Step Diffusion Codec Across Multiple Bit-rates'},Jinpei Guo; Yifei Ji; Zheng Chen; Kai Liu; Min Liu; Wang Rao; Wenbo Li; Yong Guo; Yulun Zhang,~Jinpei_Guo1; ~Yifei_Ji1; ~Zheng_Chen11; ~Kai_Liu21; ~Min_Liu7; ~Wang_Rao1; ~Wenbo_Li6; ~Yong_Guo1; ~Yulun_Zhang1,"{'value': ['Diffusion Model', 'Image Compression', 'One-step Diffusion']}","{'value': 'Pretrained latent diffusion models have shown strong potential for lossy image compression, owing to their powerful generative priors. Most existing diffusion-based methods reconstruct images by iteratively denoising from random noise, guided by compressed latent representations. While these approaches have achieved high reconstruction quality, their multi-step sampling process incurs substantial computational overhead. Moreover, they typically require training separate models for different compression bit-rates, leading to significant training and storage costs. To address these challenges, we propose a one-step diffusion codec across multiple bit-rates. termed OSCAR. Specifically, our method views compressed latents as noisy variants of the original latents, where the level of distortion depends on the bit-rate. This perspective allows them to be modeled as intermediate states along a diffusion trajectory. By establishing a mapping from the compression bit-rate to a pseudo diffusion timestep, we condition a single generative model to support reconstructions at multiple bit-rates. Meanwhile, we argue that the compressed latents retain rich structural information, thereby making one-step denoising feasible. Thus, OSCAR replaces iterative sampling with a single denoising pass, significantly improving inference efficiency. Extensive experiments demonstrate that OSCAR achieves superior performance in both quantitative and visual quality metrics. The code and models are available at https://github.com/jp-guo/OSCAR/.'}",https://openreview.net{'value': '/pdf/e0eb674d8ae7d16d582c47ca5191d8e013fa3011.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=un1TRwNgiv,{'value': 'Thinking vs. Doing: Improving Agent Reasoning by  Scaling Test-Time Interaction'},Junhong Shen; Hao Bai; Lunjun Zhang; Yifei Zhou; Amrith Setlur; Shengbang Tong; Diego Caples; Nan Jiang; Tong Zhang; Ameet Talwalkar; Aviral Kumar,~Junhong_Shen1; ~Hao_Bai1; ~Lunjun_Zhang1; ~Yifei_Zhou1; ~Amrith_Setlur1; ~Shengbang_Tong1; ~Diego_Caples1; ~Nan_Jiang2; ~Tong_Zhang2; ~Ameet_Talwalkar1; ~Aviral_Kumar2,"{'value': ['LLM Agent', 'Web Agent', 'Reasoning']}","{'value': 'Test-time scaling in agentic tasks often relies on generating long reasoning traces (""think"" more) before acting, but this does not allow agents to acquire new information from the environment or adapt behavior over time. In this work, we propose scaling test-time interaction, an untapped dimension for test-time scaling that increases the agent\'s interaction horizon to enable rich behaviors such as exploration, backtracking, and dynamic re-planning within a single rollout. To demonstrate the promise of this scaling dimension, we situate our study in the domain of web agents. We first show that even prompting-based interaction scaling can improve task success on web benchmarks non-trivially. Building on this, we introduce TTI, a curriculum-based online reinforcement learning (RL) approach that trains agents by adaptively adjusting their interaction lengths during rollout. Using a Gemma 3 12B model, TTI sets a new state-of-the-art among open-source agents trained on public data on WebVoyager and WebArena. Case studies further reveal that TTI enables agents to balance exploration and exploitation adaptively. Our results establish interaction scaling as a powerful, complementary axis to scaling per-action compute, offering new avenues for training robust and adaptive agents.'}",https://openreview.net{'value': '/pdf/20cba89765ebda48a0c183f17ceb68d13f90d0dc.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=um4aiicz3L,{'value': 'Mellow: a small audio language model for reasoning'},Soham Deshmukh; Satvik Dixit; Rita Singh; Bhiksha Raj,~Soham_Deshmukh1; ~Satvik_Dixit1; ~Rita_Singh1; ~Bhiksha_Raj1,"{'value': ['audio-language', 'multimodal learning', 'audio reasoning', 'audio processing']}","{'value': 'Multimodal Audio-Language Models (ALMs) can understand and reason over both audio and text. Typically, reasoning performance correlates with model size, with the best results achieved by models exceeding 8 billion parameters. However, no prior work has explored enabling small audio-language models to perform reasoning tasks, despite the potential applications for edge devices. To address this gap, we introduce Mellow, a small Audio-Language Model specifically designed for reasoning. Mellow achieves state-of-the-art performance among existing small audio-language models and surpasses several larger models in reasoning capabilities. For instance, Mellow scores 52.11 on MMAU, comparable to SoTA Qwen2 Audio (which scores 52.5) while using 50 times fewer parameters and being trained on 60 times less data (audio hrs). To train Mellow, we introduce ReasonAQA, a dataset designed to enhance audio-grounded reasoning in models. It consists of a mixture of existing datasets (30\\% of the data) and synthetically generated data (70\\%). The synthetic dataset is derived from audio captioning datasets, where Large Language Models (LLMs) generate detailed and multiple-choice questions focusing on audio events, objects, acoustic scenes, signal properties, semantics, and listener emotions. To evaluate Mellow’s reasoning ability, we benchmark it on a diverse set of tasks, assessing on both in-distribution and out-of-distribution data, including audio understanding, deductive reasoning, and comparative reasoning. Finally, we conduct extensive ablation studies to explore the impact of projection layer choices, synthetic data generation methods, and language model pretraining on reasoning performance. Our training dataset, findings, and baseline pave the way for developing small ALMs capable of reasoning.'}",https://openreview.net{'value': '/pdf/988b1f67467c24e2ca4afd17d8656a84d73fad4d.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=ujg9XKwqWT,{'value': 'Synthetic-powered predictive inference'},Meshi Bashari; Roy Maor Lotan; Yonghoon Lee; Edgar Dobriban; Yaniv Romano,~Meshi_Bashari1; ~Roy_Maor_Lotan1; ~Yonghoon_Lee2; ~Edgar_Dobriban2; ~Yaniv_Romano1,"{'value': ['Distribution-free Inference', 'Conformal Prediction', 'Uncertainty Quantification', 'Domain Adaptation', 'Generative Models']}","{'value': 'Conformal prediction is a framework for predictive inference with a distribution-free, finite-sample guarantee. However, it tends to provide uninformative prediction sets when calibration data are scarce. This paper introduces Synthetic-powered predictive inference (SPI), a novel framework that incorporates synthetic data---e.g., from a generative model---to improve sample efficiency. At the core of our method is a score transporter: an empirical quantile mapping that aligns nonconformity scores from trusted, real data with those from synthetic data. By carefully integrating the score transporter into the calibration process, SPI provably achieves finite-sample coverage guarantees without making any assumptions about the real and synthetic data distributions. When the score distributions are well aligned, SPI yields substantially tighter and more informative prediction sets than standard conformal prediction. Experiments on image classification---augmenting data with synthetic diffusion-model generated images---and on tabular regression demonstrate notable improvements in predictive efficiency in data-scarce settings.'}",https://openreview.net{'value': '/pdf/9aedafe5e0b1f328e8ffb6bcbdfa842812812e6f.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=udHMDBrfTv,{'value': 'Faithful Dynamic Imitation Learning from Human Intervention with Dynamic Regret Minimization'},Bo Ling; Zhengyu Gan; Wanyuan Wang; Guanyu Gao; Weiwei Wu; Yan Lyu,~Bo_Ling1; ~Zhengyu_Gan1; ~Wanyuan_Wang2; ~Guanyu_Gao1; ~Weiwei_Wu3; ~Yan_Lyu2,"{'value': ['Human-in-the-loop Imitation Learning', 'Dynamic Regret', 'Online Learning', 'Off-policy Imitation Learning']}","{'value': ""Human-in-the-loop (HIL) imitation learning enables agents to learn complex behaviors safely through real-time human intervention. However, existing methods struggle to efficiently leverage agent-generated data due to dynamically evolving trajectory distributions and imperfections caused by human intervention delays, often failing to faithfully imitate the human expert policy. In this work, we propose Faithful Dynamic Imitation Learning (FaithDaIL) to address these challenges. We formulate HIL imitation learning as an online non-convex problem and employ dynamic regret minimization to adapt to the shifting data distribution and track high-quality policy trajectories. \nTo ensure faithful imitation of the human expert despite training on mixed agent and human data, we introduce an unbiased imitation objective and achieve it by weighting the behavior distribution relative to the human expert's as a proxy reward.\nExtensive experiments on MetaDrive and CARLA driving benchmarks demonstrate that FaithDaIL achieves state-of-the-art performance in safety and task success with significantly reduced human intervention data compared to prior HIL baselines.""}",https://openreview.net{'value': '/pdf/6c75c115a126de7f97b99a0434f536fcdcd23332.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=uc1js1lBlB,{'value': 'Learning Provably Improves the Convergence of Gradient Descent'},Qingyu Song; Wei Lin; Hong Xu,~Qingyu_Song1; ~Wei_Lin16; ~Hong_Xu3,"{'value': ['Learn to Optimize', 'Gradient Descent', 'Neural Tangent Kernel']}","{'value': 'Learn to Optimize (L2O) trains deep neural network-based solvers for optimization, achieving success in accelerating convex problems and improving non-convex solutions. However, L2O lacks rigorous theoretical backing for its own training convergence, as existing analyses often use unrealistic assumptions-a gap this work highlights empirically. We bridge this gap by proving the training convergence of L2O models that learn Gradient Descent (GD) hyperparameters for quadratic programming, leveraging the Neural Tangent Kernel (NTK) theory. We propose a deterministic initialization strategy to support our theoretical results and promote stable training over extended optimization horizons by mitigating gradient explosion. \nOur L2O framework demonstrates over 50% better optimality than GD and superior robustness over state-of-the-art L2O methods on synthetic datasets. \nThe code of our method can be found from https://github.com/NetX-lab/MathL2OProof-Official.'}",https://openreview.net{'value': '/pdf/e9bf6e435462ec72ecd45029988c3cfa112cc411.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=uQmUjgR8Er,{'value': 'Estimating Hitting Times Locally at Scale'},Themistoklis Haris; Fabian Christian Spaeh; Spyros Dragazis; Charalampos Tsourakakis,~Themistoklis_Haris1; ~Fabian_Christian_Spaeh1; ~Spyros_Dragazis1; ~Charalampos_Tsourakakis1,"{'value': ['random walks', 'hitting times', 'local algorithms', 'graphs', 'effective resistance', 'markov chains']}","{'value': 'Hitting times provide a fundamental measure of distance in random processes, quantifying the expected number of steps for a random walk starting at node $u$ to reach node $v$. They have broad applications across domains such as network centrality analysis, ranking and recommendation systems, and epidemiology.  \n\nIn this work, we develop local algorithms for estimating hitting times between a pair of vertices $u,v$ without accessing the full graph, overcoming scalability issues of prior global methods. Our first algorithm uses the key insight  that hitting time computations can be truncated at the meeting time of two independent random walks from $u$ and $v$. This leads to an efficient estimator analyzed via the Kronecker product graph and Markov Chain Chernoff bounds. We also present an algorithm extending the work of Peng et al. [2021] that introduces a novel adaptation of the spectral cutoff technique to account for the asymmetry of hitting times. This adaptation captures the directionality of the underlying random walk and requires non-trivial modifications to ensure accuracy and efficiency. In addition to the algorithmic upper bounds, we also provide tight asymptotic lower bounds. \n\nFinally, we reveal a connection between hitting time estimation and distribution testing, and we validate our algorithms using experiments on both real and synthetic data.'}",https://openreview.net{'value': '/pdf/102da3a5170de7bb77acdc882e7083822a3d6e77.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=uIIxKnFmeY,{'value': 'When Additive Noise Meets Unobserved Mediators: Bivariate Denoising Diffusion for Causal Discovery'},Dominik Meier; Sujai Hiremath; PROMIT GHOSAL; Kyra Gan,~Dominik_Meier1; ~Sujai_Hiremath1; ~PROMIT_GHOSAL3; ~Kyra_Gan1,"{'value': ['causal discovery', 'additive noise model', 'diffusion']}","{'value': 'Distinguishing cause and effect from bivariate observational data is a foundational problem in many disciplines, but challenging without additional assumptions. Additive noise models (ANMs) are widely used to enable sample-efficient bivariate causal discovery.\nHowever, conventional ANM-based methods fail when unobserved mediators corrupt the causal relationship between variables. This paper makes three key contributions: first, we rigorously characterize why standard ANM approaches\nbreak down in the presence of unmeasured mediators.  Second, we demonstrate that prior solutions for hidden mediation are brittle in finite sample settings,\nlimiting their practical utility. To address these gaps, we propose Bivariate Denoising Diffusion (BiDD) for causal discovery, a method designed to handle latent noise introduced by unmeasured mediators. Unlike prior methods that infer directionality through mean squared error loss comparisons, our approach introduces a novel independence test statistic: during the noising and denoising processes for each variable, we condition on the other variable as input and evaluate the independence of the predicted noise relative to this input. We prove asymptotic consistency of BiDD under the ANM, and conjecture that it performs well under hidden mediation. Experiments on synthetic and real-world data demonstrate consistent performance, outperforming existing methods in mediator-corrupted settings while maintaining strong performance in mediator-free settings.'}",https://openreview.net{'value': '/pdf/1899953cc394c08f8ec31de65054590585f1a405.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=uG9F00zKJF,{'value': 'Re-coding for Uncertainties: Edge-awareness Semantic Concordance for Resilient Event-RGB Segmentation'},Nan Bao; Yifan Zhao; Lin Zhu; Jia Li,~Nan_Bao1; ~Yifan_Zhao2; ~Lin_Zhu8; ~Jia_Li1,"{'value': ['event camera', 'semantic segmentation', 'event-based segmentation', 'multi-modality fusion', 'uncertainty modeling']}","{'value': 'Semantic segmentation has achieved great success in ideal conditions. However, when facing extreme conditions (e.g., insufficient light, fierce camera motion), most existing methods suffer from significant information loss of RGB, severely damaging segmentation results. Several researches exploit the high-speed and high-dynamic event modality as a complement, but event and RGB are naturally heterogeneous, which leads to feature-level mismatch and inferior optimization of existing multi-modality methods. Different from these researches, we delve into the edge secret of both modalities for resilient fusion and propose a novel Edge-awareness Semantic Concordance framework to unify the multi-modality heterogeneous features with latent edge cues. In this framework, we first propose Edge-awareness Latent Re-coding, which obtains uncertainty indicators while realigning event-RGB features into unified semantic space guided by re-coded distribution, and transfers event-RGB distributions into re-coded features by utilizing a pre-established edge dictionary as clues. We then propose Re-coded Consolidation and Uncertainty Optimization, which utilize re-coded edge features and uncertainty indicators to solve the heterogeneous event-RGB fusion issues under extreme conditions. We establish two synthetic and one real-world event-RGB semantic segmentation datasets for extreme scenario comparisons. Experimental results show that our method outperforms the state-of-the-art by a 2.55% mIoU on our proposed DERS-XS, and possesses superior resilience under spatial occlusion. Our code and datasets are publicly available at https://github.com/iCVTEAM/ESC.'}",https://openreview.net{'value': '/pdf/eecaed959b7bd0ceaa4a0fe64f4828f5a8f12500.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=u7jtLj46i9,{'value': 'MindForge: Empowering Embodied Agents with Theory of Mind for Lifelong Cultural Learning'},Mircea Tudor Lică; Ojas Shirekar; Baptiste Colle; Chirag Raman,~Mircea_Tudor_Lică1; ~Ojas_Shirekar1; ~Baptiste_Colle2; ~Chirag_Raman2,"{'value': ['lifelong learning', 'theory of mind', 'LLMs', 'cultural learning', 'in-context learning']}","{'value': 'Embodied agents powered by large language models (LLMs), such as Voyager, promise open-ended competence in worlds such as Minecraft. However, when powered by open-weight LLMs they still falter on elementary tasks after domain-specific fine-tuning. We propose MindForge, a generative-agent framework for cultural lifelong learning through explicit perspective taking. We introduce three key innovations: (1) a structured theory of mind representation linking percepts, beliefs, desires, and actions; (2) natural inter-agent communication; and (3) a multi-component memory system. Following the cultural learning framework, we test MindForge in both instructive and collaborative settings within Minecraft. In an instructive setting with GPT-4, MindForge agents powered by open-weight LLMs significantly outperform their Voyager counterparts in basic tasks yielding $3\\times$ more tech-tree milestones and collecting $2.3\\times$ more unique items than the Voyager baseline. Furthermore, in fully collaborative settings, we find that the performance of two underachieving agents improves with more communication rounds, echoing the Condorcet Jury Theorem. MindForge agents demonstrate sophisticated behaviors, including expert-novice knowledge transfer, collaborative problem solving, and adaptation to out-of-distribution tasks through accumulated cultural experiences.'}",https://openreview.net{'value': '/pdf/aaff34bc5f2395383d58c98d38975df26262971c.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=u3aRwVkBv1,{'value': 'Convolution Goes Higher-Order:  A Biologically Inspired Mechanism Empowers Image Classification'},Simone Azeglio; Olivier Marre; Peter Neri; Ulisse Ferrari,~Simone_Azeglio1; ~Olivier_Marre2; ~Peter_Neri1; ~Ulisse_Ferrari1,"{'value': ['Higher-order convolution', 'Biologically inspired neural networks', 'Image classification', 'Convolutional Neural Networks', 'Biological visual processing', 'Neural representations']}","{'value': 'We propose a novel enhancement to Convolutional Neural Networks (CNNs) by incorporating learnable higher-order convolutions inspired by nonlinear biological visual processing. Our model extends the classical convolution operator using a Volterra-like expansion to capture multiplicative interactions observed in biological vision. Through extensive evaluation on standard benchmarks and synthetic datasets, we demonstrate that our architecture consistently outperforms traditional CNN baselines, achieving optimal performance with 3rd/4th order expansions. Systematic perturbation analysis and Representational Similarity Analysis reveal that different orders of convolution process distinct aspects of visual information, aligning with the statistical properties of natural images. This biologically-inspired approach offers both improved performance and deeper insights into visual information processing.'}",https://openreview.net{'value': '/pdf/7ea8196662e132fb960740c5a718a009f46a1fe1.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=u3a2AX0icx,{'value': 'Let LRMs Break Free from Overthinking via Self-Braking Tuning'},Haoran Zhao; Yuchen Yan; Yongliang Shen; Haolei Xu; Wenqi Zhang; Kaitao Song; Jian Shao; Weiming Lu; Jun Xiao; Yueting Zhuang,~Haoran_Zhao8; ~Yuchen_Yan4; ~Yongliang_Shen1; ~Haolei_Xu1; ~Wenqi_Zhang2; ~Kaitao_Song1; ~Jian_Shao1; ~Weiming_Lu1; ~Jun_Xiao1; ~Yueting_Zhuang1,"{'value': ['Large Reasoning Models', 'Efficient Reasoning']}","{'value': 'Large reasoning models (LRMs), such as OpenAI o1 and DeepSeek-R1, have significantly enhanced their reasoning capabilities by generating longer chains of thought, demonstrating outstanding performance across a variety of tasks. However, this performance gain comes at the cost of a substantial increase in redundant reasoning during the generation process, leading to high computational overhead and exacerbating the issue of overthinking.\nAlthough numerous existing approaches aim to address the problem of overthinking, they often rely on external interventions.\nIn this paper, we propose a novel framework, **Self-Braking Tuning**(SBT), which tackles overthinking from the perspective of allowing the model to regulate its own reasoning process, thus eliminating the reliance on external control mechanisms. We construct a set of overthinking identification metrics based on standard answers and design a systematic method to detect redundant reasoning. This method accurately identifies unnecessary steps within the reasoning trajectory and generates training signals for learning self-regulation behaviors. Building on this foundation, we develop a complete strategy for constructing data with adaptive reasoning lengths and introduce an innovative braking prompt mechanism that enables the model to naturally learn when to terminate reasoning at an appropriate point.\nExperiments across mathematical benchmarks (AIME, AMC, MATH500, GSM8K) demonstrate that our method reduces token consumption by up to 60\\% while maintaining comparable accuracy to unconstrained models.'}",https://openreview.net{'value': '/pdf/4c46c75db6ad985f7af95045a49aa09dd5eb0bc7.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=u1lNQH5upa,{'value': 'SpatialLM: Training Large Language Models for Structured Indoor Modeling'},Yongsen Mao; Junhao Zhong; Chuan Fang; Jia Zheng; Rui Tang; Hao Zhu; Ping Tan; Zihan Zhou,~Yongsen_Mao1; ~Junhao_Zhong2; ~Chuan_Fang1; ~Jia_Zheng1; ~Rui_Tang1; ~Hao_Zhu19; ~Ping_Tan2; ~Zihan_Zhou2,"{'value': ['Structured Indoor Modeling', 'Large Language Models', 'Spatial Understanding', '3D Reconstruction']}","{'value': 'SpatialLM is a large language model designed to process 3D point cloud data and generate structured 3D scene understanding outputs. These outputs include architectural elements like walls, doors, windows, and oriented object boxes with their semantic categories. Unlike previous methods which exploit task-specific network designs, our model adheres to the standard multimodal LLM architecture and is fine-tuned directly from open-source LLMs.\n\nTo train SpatialLM, we collect a large-scale, high-quality synthetic dataset consisting of the point clouds of 12,328 indoor scenes (54,778 rooms) with ground-truth 3D annotations, and conduct a careful study on various modeling and training decisions. On public benchmarks, our model gives state-of-the-art performance in layout estimation and competitive results in 3D object detection. With that, we show a feasible path for enhancing the spatial understanding capabilities of modern LLMs for applications in augmented reality, embodied robotics, and more.'}",https://openreview.net{'value': '/pdf/22f930c6b44c852e1c53aa7784df786168735e5d.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=u0rNHqMpFD,{'value': 'Stochastic Principal-Agent Problems: Computing and Learning Optimal History-Dependent Policies'},Jiarui Gan; R Majumdar; Debmalya Mandal; Goran Radanovic,~Jiarui_Gan1; ~R_Majumdar1; ~Debmalya_Mandal2; ~Goran_Radanovic1,"{'value': ['stochastic games', 'Markov games', 'Stackelberg games', 'information design', 'mechanism design']}","{'value': ""We study a stochastic principal-agent model. A principal and an agent interact in a stochastic environment, each privy to observations about the state not available to the other. The principal has the power of commitment, both to elicit information from the agent and to signal her own information. The players communicate with each other and then select actions independently. \nBoth players are {\\em far-sighted}, aiming to maximize their total payoffs over the entire time horizon. \nWe consider both the computation and learning of the principal's optimal policy. \nThe key challenge lies in enabling {\\em history-dependent} policies, which are essential for achieving optimality in this model but difficult to cope with because of the exponential growth of possible histories as the size of the model increases; explicit representation of history-dependent policies is infeasible as a result.\nTo address this challenge, we develop algorithmic techniques based on the concept of {\\em inducible value set}. The techniques yield an efficient algorithm that computes an $\\epsilon$-approximate optimal policy in time polynomial in $1/\\epsilon$. \nWe also present an efficient learning algorithm for an episodic reinforcement learning setting with unknown transition probabilities. The algorithm achieves sublinear regret $\\widetilde{\\mathcal{O}}(T^{2/3})$ for both players over $T$ episodes.""}",https://openreview.net{'value': '/pdf/2fbc7d10a63e1167402a84aef602f141e5300ee5.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=tuA2R6gZEA,{'value': 'LongMagpie: A Self-synthesis Method for Generating Large-scale Long-context Instructions'},Chaochen Gao; Xing W; Zijia Lin; Debing Zhang; Songlin Hu,~Chaochen_Gao1; ~Xing_W1; ~Zijia_Lin1; ~Debing_Zhang1; ~Songlin_Hu2,"{'value': ['Long-context Model', 'Synthesis Data']}","{'value': ""High-quality long-context instruction data is essential for aligning long-context large language models (LLMs). Despite the public release of models like Qwen and Llama, their long-context instruction data remains proprietary. Human annotation is costly and challenging, while template-based synthesis methods limit scale, diversity, and quality. We introduce LongMagpie, a self-synthesis framework that automatically generates large-scale long-context instruction data. Our key insight is that aligned long-context LLMs, when presented with a document followed by special tokens preceding a user turn, auto-regressively generate contextually relevant queries. By harvesting these document-query pairs and the model's responses, LongMagpie produces high-quality instructions without human effort. Experiments on HELMET, RULER, and Longbench v2 demonstrate that LongMagpie achieves leading performance on long-context tasks while maintaining competitive performance on short-context tasks, establishing it as a simple and effective approach for open, diverse, and scalable long-context instruction data synthesis.""}",https://openreview.net{'value': '/pdf/ed87797f943163aff0337ae4824c26f2e347ea6a.pdf'},{'abstract_filter': 'Data Synthesis'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=tq9lyV9Cml,{'value': 'Thought Communication in Multiagent Collaboration'},Yujia Zheng; Zhuokai Zhao; Zijian Li; Yaqi Xie; Mingze Gao; Lizhu Zhang; Kun Zhang,~Yujia_Zheng1; ~Zhuokai_Zhao1; ~Zijian_Li1; ~Yaqi_Xie1; ~Mingze_Gao2; ~Lizhu_Zhang2; ~Kun_Zhang1,"{'value': ['multiagent system', 'inter-agent communication', 'latent variable models', 'foundation models']}","{'value': 'Natural language has long enabled human cooperation, but its lossy, ambiguous, and indirect nature limits the potential of collective intelligence. While machines are not subject to these constraints, most LLM-based multi-agent systems still rely solely on natural language, exchanging tokens or their embeddings. To go beyond language, we introduce a new paradigm, *thought communication*, which enables agents to interact directly mind-to-mind, akin to telepathy. To uncover these latent thoughts in a principled way, we formalize the process as a general latent variable model, where agent states are generated by an unknown function of underlying thoughts. We prove that, in a nonparametric setting without auxiliary information, both shared and private latent thoughts between any pair of agents can be identified. Moreover, the global structure of thought sharing, including which agents share which thoughts and how these relationships are structured, can also be recovered with theoretical guarantees. Guided by the established theory, we develop a framework that extracts latent thoughts from all agents prior to communication and assigns each agent the relevant thoughts, along with their sharing patterns. This paradigm naturally extends beyond LLMs to all modalities, as most observational data arise from hidden generative processes. Experiments on both synthetic and real-world benchmarks validate the theory and demonstrate the collaborative advantages of thought communication. We hope this work illuminates the potential of leveraging the hidden world, as many challenges remain unsolvable through surface-level observation alone, regardless of compute or data scale.'}",https://openreview.net{'value': '/pdf/7e84ecbda8064983f20c395751d38019a0ab3981.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=theJ4Qiz55,{'value': 'Look Before You Leap: A GUI-Critic-R1 Model for Pre-Operative Error Diagnosis in GUI Automation'},Yuyang Wanyan; Xi Zhang; Haiyang Xu; Haowei Liu; Junyang Wang; Jiabo Ye; Yutong Kou; Ming Yan; Fei Huang; Xiaoshan Yang; Weiming Dong; Changsheng Xu,~Yuyang_Wanyan3; ~Xi_Zhang11; ~Haiyang_Xu1; ~Haowei_Liu1; ~Junyang_Wang1; ~Jiabo_Ye1; ~Yutong_Kou1; ~Ming_Yan2; ~Fei_Huang2; ~Xiaoshan_Yang2; ~Weiming_Dong1; ~Changsheng_Xu1,"{'value': ['GUI agent', 'critic models', 'RL', 'GRPO']}","{'value': ""In recent years, Multimodal Large Language Models (MLLMs) have been extensively utilized for multimodal reasoning tasks, including Graphical User Interface (GUI) automation. Unlike general offline multimodal tasks, GUI automation is executed in online interactive environments, necessitating step-by-step decision-making based on the real-time status of the environment. This task has a lower tolerance for decision-making errors at each step, as any mistakes may cumulatively disrupt the process and potentially lead to irreversible outcomes like deletions or payments. To address these issues, we introduce a pre-operative critic mechanism that provides effective feedback prior to the actual execution, by reasoning about the potential outcome and correctness of actions. Specifically, we propose a Suggestion-aware Group Relative Policy Optimization (S-GRPO) strategy to construct our pre-operative critic model GUI-Critic-R1, incorporating a novel suggestion reward to enhance the reliability of the model's feedback. Furthermore, we develop a reasoning-bootstrapping based data collection pipeline to create a GUI-Critic-Train and a GUI-Critic-Test, filling existing gaps in GUI critic data. Static experiments on the GUI-Critic-Test across both mobile and web domains reveal that our GUI-Critic-R1 offers significant advantages in critic accuracy compared to current MLLMs. Dynamic evaluation on GUI automation benchmark further highlights the effectiveness and superiority of our model, as evidenced by improved success rates and operational efficiency. The code is available at https://github.com/X-PLUG/MobileAgent/tree/main/GUI-Critic-R1.""}",https://openreview.net{'value': '/pdf/32e820341da512a9f80f54f09f19da69409d75c7.pdf'},{'abstract_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=tgwjgDoaQq,{'value': 'Time-Evolving Dynamical System for Learning Latent Representations of Mouse Visual Neural Activity'},Liwei Huang; Zhengyu Ma; Liutao Yu; Huihui Zhou; Yonghong Tian,~Liwei_Huang1; ~Zhengyu_Ma1; ~Liutao_Yu1; ~Huihui_Zhou1; ~Yonghong_Tian1,"{'value': ['Visual Cortex', 'Latent Variable Models', 'Dynamical System']}","{'value': 'Seeking high-quality representations with latent variable models (LVMs) to reveal the intrinsic correlation between neural activity and behavior or sensory stimuli has attracted much interest. In the study of the biological visual system, naturalistic visual stimuli are inherently high-dimensional and time-dependent, leading to intricate dynamics within visual neural activity. However, most work on LVMs has not explicitly considered neural temporal relationships. To cope with such conditions, we propose Time-Evolving Visual Dynamical System (TE-ViDS), a sequential LVM that decomposes neural activity into low-dimensional latent representations that evolve over time. To better align the model with the characteristics of visual neural activity, we split latent representations into two parts and apply contrastive learning to shape them. Extensive experiments on synthetic datasets and real neural datasets from the mouse visual cortex demonstrate that TE-ViDS achieves the best decoding performance on naturalistic scenes/movies, extracts interpretable latent trajectories that uncover clear underlying neural dynamics, and provides new insights into differences in visual information processing between subjects and between cortical regions. In summary, TE-ViDS is markedly competent in extracting stimulus-relevant embeddings from visual neural activity and contributes to the understanding of visual processing mechanisms. Our codes are available at https://github.com/Grasshlw/Time-Evolving-Visual-Dynamical-System.'}",https://openreview.net{'value': '/pdf/059c186dd26cd255f27020b6229aa6e51f83b36b.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=tfbu0ITAez,{'value': 'SIGMA: Refining Large Language Model Reasoning via Sibling-Guided Monte Carlo Augmentation'},Yanwei Ren; Haotian Zhang; Fuxiang Wu; Jiayan Qiu; Jiaxing Huang; Baosheng Yu; Liu Liu,~Yanwei_Ren1; ~Haotian_Zhang19; ~Fuxiang_Wu1; ~Jiayan_Qiu1; ~Jiaxing_Huang2; ~Baosheng_Yu1; ~Liu_Liu8,"{'value': ['Large Language Models (LLMs)', 'Monte Carlo Tree Search (MCTS)', 'Data Augmentation', 'Large Language Models (LLMs)', 'Sibling Guidance']}","{'value': 'Enhancing large language models by simply scaling up datasets has begun to yield diminishing returns, shifting the spotlight to data quality. Monte Carlo Tree Search (MCTS) has emerged as a powerful technique for generating high-quality chain-of-thought data, yet conventional approaches typically retain only the top-scoring trajectory from the search tree, discarding sibling nodes that often contain valuable partial insights, recurrent error patterns, and alternative reasoning strategies. This unconditional rejection of non-optimal reasoning branches may waste vast amounts of informative data in the whole search tree. We propose SIGMA (Sibling Guided Monte Carlo Augmentation), a novel framework that reintegrates these discarded sibling nodes to refine LLM reasoning. SIGMA forges semantic links among sibling nodes along each search path and applies a two-stage refinement: a critique model identifies overlooked strengths and weaknesses across the sibling set, and a revision model conducts text-based backpropagation to refine the top-scoring trajectory in light of this comparative feedback. By recovering and amplifying the underutilized but valuable signals from non-optimal reasoning branches, SIGMA substantially improves reasoning trajectories. On the challenging MATH benchmark, our SIGMA-tuned 7B model achieves 54.92\\% accuracy using only 30K samples, outperforming state-of-the-art models trained on 590K samples. This result highlights that our sibling-guided optimization not only significantly reduces data usage but also significantly boosts LLM reasoning.'}",https://openreview.net{'value': '/pdf/a978edf76ad31a09fe972e0025c16b74e6292abf.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=tahkGZjjWA,{'value': 'Constrained Diffusers for Safe Planning and Control'},Jichen Zhang; Liqun Zhao; Antonis Papachristodoulou; Jack Umenberger,~Jichen_Zhang1; ~Liqun_Zhao1; ~Antonis_Papachristodoulou1; ~Jack_Umenberger2,"{'value': ['Diffusion Models', 'Constrained Optimization']}","{'value': 'Diffusion models have shown remarkable potential in planning and control tasks due to their ability to represent multimodal distributions over actions and trajectories. However, ensuring safety under constraints remains a critical challenge for diffusion models. This paper proposes Constrained Diffusers, an extended framework for planning and control that incorporates distribution-level constraints into pre-trained diffusion models without retraining or architectural modifications. Inspired by constrained optimization, we apply a constrained Langevin samplingfor the reverse diffusion process that jointly optimizes the trajectory and realizes constraint satisfaction through three iterative algorithms: projected method, primal-dual method and augmented Lagrangian methods. In addition, we incorporate discrete control barrier functions as constraints for constrained diffusers to guarantee safety in online implementation, following a receding-horizon control that we generate a short-horizon plan and execute only the first action before replanning. Experiments in Maze2D, locomotion, and PyBullet ball running tasks demonstrate that our proposed methods achieve constraint satisfaction with less computation time, and are competitive with existing methods in environments with static and time-varying constraints.'}",https://openreview.net{'value': '/pdf/78f7bb744aa3cdc0ac0f5569db0fb9e436b2bae1.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=tY8ctrD4W2,{'value': 'Compiler-R1: Towards Agentic Compiler Auto-tuning with Reinforcement Learning'},Haolin Pan; Hongyu Lin; Haoran Luo; Yang Liu; Kaichun Yao; Libo Zhang; Mingjie Xing; Yanjun Wu,~Haolin_Pan2; ~Hongyu_Lin2; ~Haoran_Luo1; ~Yang_Liu128; ~Kaichun_Yao1; ~Libo_Zhang1; ~Mingjie_Xing1; ~Yanjun_Wu1,"{'value': ['LLM', 'Compiler Tuning', 'Reinforcement Learning', 'Agent', 'Compilation Pass']}","{'value': 'Compiler auto-tuning optimizes pass sequences to improve performance metrics such as Intermediate Representation (IR) instruction count. Although recent advances leveraging Large Language Models (LLMs) have shown promise in automating compiler tuning, two significant challenges still remain: the absence of high-quality reasoning datasets for agents training, and limited effective interactions with the compilation environment. In this work, we introduce Compiler-R1, the first reinforcement learning (RL)-driven framework specifically augmenting LLM capabilities for compiler auto-tuning. Compiler-R1 features a curated, high-quality reasoning dataset and a novel two-stage end-to-end RL training pipeline, enabling efficient environment exploration and learning through an outcome-based reward. Extensive experiments across seven datasets demonstrate Compiler-R1 achieving an average 8.46\\% IR instruction count reduction compared to opt -Oz, showcasing the strong potential of RL-trained LLMs for compiler optimization. Our code and datasets are publicly available at https://github.com/Panhaolin2001/Compiler-R1.'}",https://openreview.net{'value': '/pdf/303fceb426c0c5822e872a2040a0410e2abc2e82.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=tXqLxHlb8Z,{'value': 'AgentNet: Decentralized Evolutionary Coordination for LLM-based Multi-Agent Systems'},Yingxuan Yang; Huacan Chai; Shuai Shao; Yuanyi Song; Siyuan Qi; Renting Rui; Weinan Zhang,~Yingxuan_Yang1; ~Huacan_Chai1; ~Shuai_Shao11; ~Yuanyi_Song1; ~Siyuan_Qi3; ~Renting_Rui1; ~Weinan_Zhang1,"{'value': ['LLM Agent', 'MAS', 'RAG', 'DAG']}","{'value': 'The rapid advancement of Large Language Models (LLMs) has catalyzed the development of multi-agent systems, where multiple LLM-based agents collaborate to solve complex tasks.   However, existing systems predominantly rely on centralized coordination, which introduces scalability bottlenecks, limits adaptability, and creates single points of failure.   Additionally, concerns over privacy and proprietary knowledge sharing hinder cross-organizational collaboration, leading to siloed expertise.   To address these challenges, we propose AgentNet, a decentralized, Retrieval-Augmented Generation (RAG)-based framework that enables LLM-based agents to autonomously evolve their capabilities and collaborate efficiently in a Directed Acyclic Graph (DAG)-structured network.   Unlike traditional multi-agent systems that depend on static role assignments or centralized control, AgentNet allows agents to specialize dynamically, adjust their connectivity, and route tasks without relying on predefined workflows.\nAgentNet’s core design is built upon several key innovations: (1) Fully Decentralized Paradigm: Removing the central orchestrator, allowing agents to coordinate and specialize autonomously, fostering fault tolerance and emergent collective intelligence. (2) Dynamically Evolving Graph Topology: Real-time adaptation of agent connections based on task demands, ensuring scalability and resilience.\n(3) Adaptive Learning for Expertise Refinement: A retrieval-based memory system that enables agents to continuously update and refine their specialized skills.\nBy eliminating centralized control, AgentNet enhances fault tolerance, promotes scalable specialization, and enables privacy-preserving collaboration across organizations.      Through decentralized coordination and minimal data exchange, agents can leverage diverse knowledge sources while safeguarding sensitive information.      Experimental results demonstrate that AgentNet outperforms traditional centralized multi-agent systems, significantly improving efficiency, adaptability, and scalability in dynamic environments, making it a promising foundation for next-generation autonomous, privacy-respecting multi-agent ecosystems.'}",https://openreview.net{'value': '/pdf/38bdf6e7191adba7391b1fde1ad37e27887b2bac.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=tWhkNXPshv,{'value': 'Multiresolution Analysis and Statistical Thresholding on Dynamic Networks'},Raphael Romero; Tijl De Bie; Nick Heard; Alexander Modell,~Raphael_Romero1; ~Tijl_De_Bie1; ~Nick_Heard1; ~Alexander_Modell1,"{'value': ['Dynamic Networks', 'Multiresolution Analysis', 'Changepoint Detection']}","{'value': 'Detecting structural change in dynamic network data has wide-ranging applications. Existing approaches typically divide the data into time bins, extract network features within each bin, and then compare these features over time. This introduces an inherent tradeoff between temporal resolution and the statistical stability of the extracted features. \n   Despite this tradeoff, reminiscent of time–frequency tradeoffs in signal processing, most methods rely on a \\emph{fixed temporal resolution}.  Choosing an appropriate resolution parameter is typically difficult, and can be especially problematic in domains like cybersecurity, where anomalous behavior may emerge at multiple time scales.\n   We address this challenge by proposing ANIE ($\\textbf{A}$daptive $\\textbf{N}$etwork $\\textbf{I}$ntensity $\\textbf{E}$stimation), a multi-resolution framework designed to automatically identify the time scales at which network structure evolves, enabling the joint detection of both rapid and gradual changes.\n   Modeling interactions as Poisson processes, our method proceeds in two steps: (1) estimating a low-dimensional subspace of node behavior, and (2) deriving a set of novel *empirical affinity coefficients* that measure change in interaction intensity between latent factors and support statistical testing for structural change across time scales.\n   We provide theoretical guarantees for subspace estimation and the asymptotic behavior of the affinity coefficients, enabling model-based change detection. Experiments on synthetic networks show that ANIE adapts to the appropriate time resolution, and is able to capture sharp structural changes while remaining robust to noise. Furthermore, applications to real-world data showcase the practical benefits of ANIE’s multiresolution approach to detecting structural change over fixed resolution methods.\n    An open-source implementation of the method is available at [https://github.com/aida-ugent/anie].'}",https://openreview.net{'value': '/pdf/0a2a8537f598c9b2aea8bbdea17c00eb6eebe985.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=tT3EQdFHtX,{'value': 'The Flood Complex: Large-Scale Persistent Homology on Millions of Points'},Florian Graf; Paolo Pellizzoni; Martin Uray; Stefan Huber; Roland Kwitt,~Florian_Graf2; ~Paolo_Pellizzoni1; ~Martin_Uray1; ~Stefan_Huber2; ~Roland_Kwitt1,"{'value': ['persistent homology', 'topological data analysis']}","{'value': 'We consider the problem of computing persistent homology (PH) for large-scale Euclidean point cloud data, aimed at downstream machine learning tasks, where the exponential growth of the most widely-used Vietoris-Rips complex imposes serious computational limitations. Although more scalable alternatives such as the Alpha complex or sparse Rips approximations exist, they often still result in a prohibitively large number of simplices. This poses challenges in the complex construction and in the subsequent PH computation, prohibiting their use on large-scale point clouds. To mitigate these issues, we introduce the Flood complex, inspired by the advantages of the Alpha and Witness complex constructions. Informally, at a given filtration value $r\\geq 0$, the Flood complex contains all simplices from a Delaunay triangulation of a small subset of a point cloud $X$ that are fully covered by the union of balls of radius $r$ emanating from $X$, a process we call flooding. Our construction allows for efficient PH computation, possesses several desirable theoretical properties, and is amenable to GPU parallelization. Scaling experiments on 3D point cloud data show that we can compute PH of up to dimension 2 on several millions of points. Importantly, when evaluating object classification performance on real-world and synthetic data, we provide evidence that this scaling capability is needed, especially if objects are geometrically or topologically complex, yielding performance superior to other PH-based methods and neural networks for point cloud data.\n\nSource code is available on GitHub: https://github.com/plus-rkwitt/flooder'}",https://openreview.net{'value': '/pdf/72adc0380001bc2b997943901e6b4748116cb7fa.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=tRXt10xKc5,{'value': 'ContextAgent: Context-Aware Proactive LLM Agents with Open-world Sensory Perceptions'},Bufang Yang; Lilin Xu; Liekang Zeng; Kaiwei Liu; Siyang Jiang; Wenrui Lu; Hongkai Chen; Xiaofan Jiang; Guoliang Xing; Zhenyu Yan,~Bufang_Yang1; ~Lilin_Xu1; ~Liekang_Zeng1; ~Kaiwei_Liu1; ~Siyang_Jiang1; ~Wenrui_Lu3; ~Hongkai_Chen3; ~Xiaofan_Jiang1; ~Guoliang_Xing2; ~Zhenyu_Yan2,"{'value': ['LLM Agents', 'Proactive Agent', 'Human-centric AI', 'Personal Assistant']}","{'value': 'Recent advances in Large Language Models (LLMs) have propelled intelligent agents from reactive responses to proactive support. \nWhile promising, existing proactive agents either rely exclusively on observations from enclosed environments (e.g., desktop UIs) with direct LLM inference or employ rule-based proactive notifications, leading to suboptimal user intent understanding and limited functionality for proactive service. In this paper, we introduce ContextAgent, the first context-aware proactive agent that incorporates extensive sensory contexts surrounding humans to enhance the proactivity of LLM agents. ContextAgent first extracts multi-dimensional contexts from massive sensory perceptions on wearables (e.g., video and audio) to understand user intentions. ContextAgent then leverages the sensory contexts and personas from historical data to predict the necessity for proactive services. When proactive assistance is needed, ContextAgent further automatically calls the necessary tools to assist users unobtrusively. To evaluate this new task, we curate ContextAgentBench, the first benchmark for evaluating context-aware proactive LLM agents, covering 1,000 samples across nine daily scenarios and twenty tools. Experiments on ContextAgentBench show that ContextAgent outperforms baselines by achieving up to 8.5% and 6.0% higher accuracy in proactive predictions and tool calling, respectively. We hope our research can inspire the development of more advanced, human-centric, proactive AI assistants. The code and dataset are publicly available at https://github.com/openaiotlab/ContextAgent.'}",https://openreview.net{'value': '/pdf/8c61939b607693d9b13cc1df27793d844f3648f5.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=tQZK5frjVU,{'value': 'Data Mixing Can Induce Phase Transitions in Knowledge Acquisition'},Xinran Gu; Kaifeng Lyu; Jiazheng Li; Jingzhao Zhang,~Xinran_Gu2; ~Kaifeng_Lyu2; ~Jiazheng_Li5; ~Jingzhao_Zhang2,"{'value': ['knowledge acquisition', 'memorization', 'scaling laws', 'LLMs']}","{'value': 'Large Language Models (LLMs) are typically trained on data mixtures: most data come from web scrapes, while a small portion is curated from high-quality sources with dense domain-specific knowledge.\nIn this paper, we show that when training LLMs on such data mixtures, knowledge acquisition from knowledge-dense datasets—unlike training exclusively on knowledge-dense data—does not always follow a smooth scaling law but can exhibit phase transitions with respect to the mixing ratio and model size. Through controlled experiments on a synthetic biography dataset mixed with web-scraped data, we demonstrate that: (1) as we increase the model size to a critical value, the model suddenly transitions from memorizing very few to most of the biographies; (2) below a critical mixing ratio, the model memorizes almost nothing even with extensive training, but beyond this threshold, it rapidly memorizes more biographies. We attribute these phase transitions to a capacity allocation phenomenon: a model with bounded capacity must act like a knapsack problem solver to minimize the overall test loss, and the optimal allocation across datasets can change discontinuously as the model size or mixing ratio varies. We formalize this intuition in an information-theoretic framework and reveal that these phase transitions are predictable, with the critical mixing ratio following a power-law relationship with the model size. Our findings highlight a concrete case where a good mixing recipe for large models may not be optimal for small models, and vice versa.'}",https://openreview.net{'value': '/pdf/95bd21460976cad8c6926b5c9ab1243abb9dfdbf.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=tIA46eoqhn,{'value': 'Hyperbolic Dataset Distillation'},Wenyuan Li; Guang Li; Keisuke Maeda; Takahiro Ogawa; Miki Haseyama,~Wenyuan_Li4; ~Guang_Li2; ~Keisuke_Maeda1; ~Takahiro_Ogawa1; ~Miki_Haseyama1,"{'value': ['Dataset Distillation', 'Hyperbolic Space', 'Distribution Matching']}","{'value': 'To address the computational and storage challenges posed by large-scale datasets in deep learning, dataset distillation has been proposed to synthesize a compact dataset that replaces the original while maintaining comparable model performance. Unlike optimization-based approaches that require costly bi-level optimization, distribution matching (DM) methods improve efficiency by aligning the distributions of synthetic and original data, thereby eliminating nested optimization. DM achieves high computational efficiency and has emerged as a promising solution. However, existing DM methods, constrained to Euclidean space, treat data as independent and identically distributed points, overlooking complex geometric and hierarchical relationships. To overcome this limitation, we propose a novel hyperbolic dataset distillation method, termed HDD. Hyperbolic space, characterized by negative curvature and exponential volume growth with distance, naturally models hierarchical and tree-like structures. HDD embeds features extracted by a shallow network into the Lorentz hyperbolic space, where the discrepancy between synthetic and original data is measured by the hyperbolic (geodesic) distance between their centroids. By optimizing this distance, the hierarchical structure is explicitly integrated into the distillation process, guiding synthetic samples to gravitate towards the root-centric regions of the original data distribution while preserving their underlying geometric characteristics. Furthermore, we find that pruning in hyperbolic space requires only 20\\% of the distilled core set to retain model performance, while significantly improving training stability. Notably, HDD is seamlessly compatible with most existing DM methods, and extensive experiments on different datasets validate its effectiveness. To the best of our knowledge, this is the first work to incorporate the hyperbolic space into the dataset distillation process. The code is available at https://github.com/Guang000/HDD.'}",https://openreview.net{'value': '/pdf/2e1999a89ecf586b61bfe572c8ce7fc6613a5d6a.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=tBQEPRFT60,{'value': 'UtilGen: Utility-Centric Generative Data Augmentation with Dual-Level Task Adaptation'},Jiyu Guo; Shuo Yang; Yiming Huang; Yancheng Long; Xiaobo Xia; Xiu Su; Bo Zhao; Zeke Xie; Liqiang Nie,~Jiyu_Guo1; ~Shuo_Yang5; ~Yiming_Huang7; ~Yancheng_Long1; ~Xiaobo_Xia1; ~Xiu_Su1; ~Bo_Zhao4; ~Zeke_Xie1; ~Liqiang_Nie2,"{'value': ['Data Augmentation', 'Diffusion Models', 'Training Data Valuation', 'Few-Shot Learning']}","{'value': 'Data augmentation using generative models has emerged as a powerful paradigm for enhancing performance in computer vision tasks. However, most existing augmentation approaches primarily focus on optimizing intrinsic data attributes -- such as fidelity and diversity -- to generate visually high-quality synthetic data, while often neglecting task-specific requirements. Yet, it is essential for data generators to account for the needs of downstream tasks, as training data requirements can vary significantly across different tasks and network architectures. \nTo address these limitations, we propose UtilGen, a novel utility-centric data augmentation framework that adaptively optimizes the data generation process to produce task-specific, high-utility training data via downstream task feedback. Specifically, we first introduce a weight allocation network to evaluate the task-specific utility of each synthetic sample. Guided by these evaluations, UtilGen iteratively refines the data generation process using a dual-level optimization strategy to maximize the synthetic data utility: (1) model-level optimization tailors the generative model to the downstream task, and (2) instance-level optimization adjusts generation policies -- such as prompt embeddings and initial noise -- at each generation round. \nExtensive experiments on eight benchmark datasets of varying complexity and granularity demonstrate that UtilGen consistently achieves superior performance, with an average accuracy improvement of 3.87\\% over previous SOTA. Further analysis of data influence and distribution reveals that UtilGen produces more impactful and task-relevant synthetic data, validating the effectiveness of the paradigm shift from visual characteristics-centric to task utility-centric data augmentation.'}",https://openreview.net{'value': '/pdf/0993b9f757331efef1e04fb187683b58f4f2a78f.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=t8YRsWY6HM,{'value': 'Mitra: Mixed Synthetic Priors for Enhancing Tabular Foundation Models'},Xiyuan Zhang; Danielle C. Maddix; Junming Yin; Nick Erickson; Abdul Fatir Ansari; Boran Han; Shuai Zhang; Leman Akoglu; Christos Faloutsos; Michael W. Mahoney; Cuixiong Hu; Huzefa Rangwala; George Karypis; Bernie Wang,~Xiyuan_Zhang2; ~Danielle_C._Maddix1; ~Junming_Yin1; ~Nick_Erickson1; ~Abdul_Fatir_Ansari2; ~Boran_Han1; ~Shuai_Zhang7; ~Leman_Akoglu3; ~Christos_Faloutsos1; ~Michael_W._Mahoney1; ~Cuixiong_Hu1; ~Huzefa_Rangwala2; ~George_Karypis1; ~Bernie_Wang1,"{'value': ['tabular foundation model', 'synthetic priors']}","{'value': 'Since the seminal work of TabPFN, research on tabular foundation models (TFMs) based on in-context learning (ICL) has challenged long-standing paradigms in machine learning. Without seeing any real-world data, models pretrained on purely synthetic datasets generalize remarkably well across diverse datasets, often using only a moderate number of in-context examples. This shifts the focus in tabular machine learning from model architecture design to the design of synthetic datasets, or, more precisely, to the prior distributions that generate them. Yet the guiding principles for prior design remain poorly understood. This work marks the first attempt to address the gap. We systematically investigate and identify key properties of synthetic priors that allow pretrained TFMs to generalize well. Based on these insights, we introduce Mitra, a TFM trained on a curated mixture of synthetic priors selected for their diversity, distinctiveness, and performance on real-world tabular data. Mitra consistently outperforms state-of-the-art TFMs, such as TabPFNv2 and TabICL, across both classification and regression benchmarks, with better sample efficiency.'}",https://openreview.net{'value': '/pdf/ae98156ca2b3267d0484a0bc1ee985c21b06beb2.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=t4aN2G7Ucc,{'value': 'Dimension-adapted Momentum Outscales SGD'},Damien Ferbach; Katie Everett; Gauthier Gidel; Elliot Paquette; Courtney Paquette,~Damien_Ferbach1; ~Katie_Everett1; ~Gauthier_Gidel1; ~Elliot_Paquette1; ~Courtney_Paquette1,"{'value': ['power-law random features', 'scaling laws', 'momentum', 'random matrix theory', 'acceleration', 'stochastic optimization', 'compute-optimal']}","{'value': ""We investigate scaling laws for stochastic momentum algorithms on the power law random features model, parameterized by data complexity, target complexity, and model size. When trained with a stochastic momentum algorithm, our analysis reveals four distinct loss curve shapes determined by varying data-target complexities. While traditional stochastic gradient descent with momentum (SGD-M) yields identical scaling law exponents to SGD, dimension-adapted Nesterov acceleration (DANA) improves these exponents by scaling momentum hyperparameters based on model size and data complexity. This outscaling phenomenon, which also improves compute-optimal scaling behavior, is achieved by DANA across a broad range of data and target complexities, while traditional methods fall short. Extensive experiments on high-dimensional synthetic quadratics validate our theoretical predictions and large-scale text experiments with LSTMs show DANA's improved loss exponents over SGD hold in a practical setting.""}",https://openreview.net{'value': '/pdf/36c24d1442a849b3e459665031ee565e31badae8.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=t3NzYXXICp,{'value': 'Empirical Study on Robustness and Resilience in Cooperative Multi-Agent Reinforcement Learning'},Simin Li; Zihao Mao; Hanxiao Li; Zonglei Jing; Zhuohang bian; Jun Guo; Li Wang; Zhuoran Han; Ruixiao Xu; Xin Yu; Chengdong Ma; Yuqing Ma; Bo An; Yaodong Yang; Weifeng Lv; Xianglong Liu,~Simin_Li5; ~Zihao_Mao3; ~Hanxiao_Li1; ~Zonglei_Jing1; ~Zhuohang_bian1; ~Jun_Guo6; ~Li_Wang29; ~Zhuoran_Han2; ~Ruixiao_Xu1; ~Xin_Yu7; ~Chengdong_Ma1; ~Yuqing_Ma2; ~Bo_An2; ~Yaodong_Yang1; ~Weifeng_Lv1; ~Xianglong_Liu3,"{'value': ['Multi-Agent Reinforcement Learning', 'Trustworthy AI']}","{'value': 'In cooperative Multi-Agent Reinforcement Learning (MARL), it is a common practice to tune hyperparameters in ideal simulated environments to maximize cooperative performance. However, policies tuned for cooperation often fail to maintain robustness and resilience under real-world uncertainties. Building trustworthy MARL systems requires a deep understanding of \\emph{robustness}, which ensures stability under uncertainties, and \\emph{resilience}, the ability to recover from disruptions—a concept extensively studied in control systems but largely overlooked in MARL. In this paper, we present a large-scale empirical study comprising over 82,620 experiments to evaluate cooperation, robustness, and resilience in MARL across 4 real-world environments, 13 uncertainty types, and 15 hyperparameters. Our key findings are: (1) Under mild uncertainty, optimizing cooperation improves robustness and resilience, but this link weakens as perturbations intensify. Robustness and resilience also varies by algorithm and uncertainty type. (2) Robustness and resilience do not generalize across uncertainty modalities or agent scopes: policies robust to action noise for all agents may fail under observation noise on a single agent. (3) Hyperparameter tuning is critical for trustworthy MARL: surprisingly, standard practices like parameter sharing, GAE, and PopArt can hurt robustness, while early stopping, high critic learning rates, and Leaky ReLU consistently help. By optimizing hyperparameters only, we observe substantial improvement in cooperation, robustness and resilience across all MARL backbones, with the phenomenon also generalizing to robust MARL methods across these backbones.'}",https://openreview.net{'value': '/pdf/4943492287e7c1ae1f7aeebd0dc1cd9ece61bdbc.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=t3CfT2y2Ag,"{'value': ""Wukong's 72 Transformations: High-fidelity Textured 3D Morphing via Flow Models""}",Minghao Yin; Yukang Cao; Kai Han,~Minghao_Yin2; ~Yukang_Cao2; ~Kai_Han1,"{'value': ['3D morphing', '3D interpolation', 'Rectified flow']}","{'value': 'We present WUKONG, a novel training-free framework for high-fidelity textured 3D morphing that takes a pair of source and target prompts (text or images) as input. Unlike conventional methods -- which rely on manual correspondence matching and deformation trajectory estimation (limiting generalization and requiring costly preprocessing) -- WUKONG leverages the generative prior of flow-based transformers to produce high-fidelity 3D transitions with rich texture details. To ensure smooth shape transitions, we exploit the inherent continuity of flow-based generative processes and formulate morphing as an optimal transport barycenter problem. We further introduce a sequential initialization strategy to prevent abrupt geometric distortions and preserve identity coherence. For faithful texture preservation, we propose a similarity-guided semantic consistency mechanism that selectively retains high-frequency details and enables precise control over blending dynamics. This avoids common artifacts like oversmoothing while maintaining semantic fidelity. Through extensive quantitative and qualitative evaluations, we demonstrate that WUKONG significantly outperforms state-of-the-art methods, achieving superior results across diverse geometry and texture variations.'}",https://openreview.net{'value': '/pdf/d90d2f06d426bb27bb3dfc224750e771c5d759c3.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=sye27MizdM,{'value': 'Topology-aware Graph Diffusion Model with Persistent Homology'},Joonhyuk Park; Donghyun Lee; Yujee Song; Guorong Wu; Won Hwa Kim,~Joonhyuk_Park1; ~Donghyun_Lee6; ~Yujee_Song2; ~Guorong_Wu1; ~Won_Hwa_Kim4,"{'value': ['Graph Generation', 'Diffusion', 'Topology', 'Brain Network']}","{'value': 'Generating realistic graphs faces challenges in estimating accurate distribution of graphs in an embedding space while preserving structural characteristics. However, existing graph generation methods primarily focus on approximating the joint distribution of nodes and edges, often overlooking topological properties such as connected components and loops, hindering accurate representation of global structures. To address this issue, we propose a Topology-Aware diffusion-based Graph Generation (TAGG), which aims to sample synthetic graphs that closely resemble the structural characteristics of the original graph based on persistent homology. Specifically, we suggest two core components: 1) Persistence Diagram Matching (PDM) loss which ensures high topological fidelity of generated graphs, and 2) topology-aware attention module (TAM) which induces the denoising network to capture the homological characteristics of the original graphs. Extensive experiments on conventional graph benchmarks demonstrate the effectiveness of our approach demonstrating high generation performance across various metrics, while achieving closer alignment with the distribution of topological features observed in the original graphs. Furthermore, application to real brain network data showcases its potential for complex and real graph applications.'}",https://openreview.net{'value': '/pdf/72bdeb175c74739bd71db96679700189412c2573.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=stiJen3iNI,{'value': 'K-DeCore: Facilitating Knowledge Transfer in Continual Structured Knowledge Reasoning via Knowledge Decoupling'},Yongrui Chen; Yi Huang; Yunchang Liu; Shenyu Zhang; Junhao He; Tongtong Wu; Guilin Qi; Tianxing Wu,~Yongrui_Chen1; ~Yi_Huang3; ~Yunchang_Liu1; ~Shenyu_Zhang1; ~Junhao_He3; ~Tongtong_Wu1; ~Guilin_Qi2; ~Tianxing_Wu1,"{'value': ['structured knowledge reasoning', 'continual learning', 'large language models']}","{'value': ""Continual Structured Knowledge Reasoning (CSKR) focuses on training models to handle sequential tasks, where each task involves translating natural language questions into structured queries grounded in structured knowledge. Existing general continual learning approaches face significant challenges when applied to this task, including poor generalization to heterogeneous structured knowledge and inefficient reasoning due to parameter growth as tasks increase. To address these limitations, we propose a novel CSKR framework, \\textsc{K-DeCore}, which operates with a fixed number of tunable parameters. \nUnlike prior methods, \\textsc{K-DeCore} introduces a knowledge decoupling mechanism that disentangles the reasoning process into task-specific and task-agnostic stages, effectively bridging the gaps across diverse tasks. Building on this foundation, \\textsc{K-DeCore} integrates a dual-perspective memory consolidation mechanism for distinct stages and introduces a structure-guided pseudo-data synthesis strategy to further enhance the model's generalization capabilities.\nExtensive experiments on four benchmark datasets demonstrate the superiority of \\textsc{K-DeCore} over existing continual learning methods across multiple metrics, leveraging various backbone large language models.""}",https://openreview.net{'value': '/pdf/033befdb4246ce4baf0c8d260af0964cbdcb781e.pdf'},{'abstract_filter': 'Data Synthesis'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=skS03tzYNw,"{'value': 'ShapeCraft: LLM Agents for Structured, Textured and Interactive 3D Modeling'}",Shuyuan Zhang; Chenhan Jiang; Zuoou Li; Jiankang Deng,~Shuyuan_Zhang6; ~Chenhan_Jiang1; ~Zuoou_Li1; ~Jiankang_Deng1,"{'value': ['Text-to-3D Generation', 'LLM Agents', '3D Modeling']}","{'value': ""3D generation from natural language offers significant potential to reduce expert manual modeling efforts and enhance accessibility to 3D assets. However, existing methods often yield unstructured meshes and exhibit poor interactivity, making them impractical for artistic workflows. To address these limitations, we represent 3D assets as shape programs and introduce ShapeCraft, a novel multi-agent framework for text-to-3D generation. At its core, we propose a Graph-based Procedural Shape (GPS) representation that decomposes complex natural language into a structured graph of sub-tasks, thereby facilitating accurate LLM comprehension and interpretation of spatial relationships and semantic shape details. Specifically, LLM agents hierarchically parse user input to initialize GPS, then iteratively refine procedural modeling and painting to produce structured, textured, and interactive 3D assets. Qualitative and quantitative experiments demonstrate ShapeCraft's superior performance in generating geometrically accurate and semantically rich 3D assets compared to existing LLM-based agents. We further show the versatility of ShapeCraft through examples of animated and user-customized editing, highlighting its potential for broader interactive applications.""}",https://openreview.net{'value': '/pdf/59fcd010a8212ae3bab53aa4724ff5534767041f.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=shMjc5zvqL,{'value': 'Scalable inference of functional neural connectivity at submillisecond timescales'},Arina Medvedeva; Edoardo Balzani; Alex H Williams; Stephen L Keeley,~Arina_Medvedeva1; ~Edoardo_Balzani1; ~Alex_H_Williams1; ~Stephen_L_Keeley1,"{'value': ['Generalized linear model', 'functional connectivity', 'poisson point process', 'stochastic optimization']}","{'value': 'The Poisson Generalized Linear Model (GLM) is a foundational tool for analyzing neural spike train data.\nHowever, standard implementations rely on discretizing spike times into binned count data, limiting temporal resolution and scalability. Here, we develop stochastic optimization methods and polynomial approximations to the continuous-time analog of these models, and show them to be advantageous over their discrete-time counterparts. Further, we propose using a set of exponentially scaled Laguerre polynomials as an orthogonal temporal basis, which improves filter identification and yields closed-form integral solutions under the polynomial approximation. Applied to both synthetic and real spike-time data from rodent hippocampus, our methods demonstrate superior accuracy and scalability compared to traditional binned GLMs, enabling functional connectivity inference in large-scale neural recordings that are temporally precise on the order of synaptic dynamical timescales. We provide open-source implementations of both MC and PA estimators, optimized for GPU acceleration, to facilitate adoption in the neuroscience community.'}",https://openreview.net{'value': '/pdf/1d9a539f4a3ac7d45178e03e10042e85b9d18de9.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=shFhW4zqd6,{'value': 'EF-3DGS: Event-Aided Free-Trajectory 3D Gaussian Splatting'},Bohao Liao; Wei Zhai; Zengyu Wan; Zhixin Cheng; Wenfei Yang; Yang Cao; Tianzhu Zhang; Zheng-Jun Zha,~Bohao_Liao1; ~Wei_Zhai1; ~Zengyu_Wan1; ~Zhixin_Cheng1; ~Wenfei_Yang2; ~Yang_Cao5; ~Tianzhu_Zhang1; ~Zheng-Jun_Zha2,{'value': ['3D Gaussian Splatting (3DGS); Novel View Synthesis (NVS)']},"{'value': 'Scene reconstruction from casually captured videos has wide real-world applications. Despite recent progress, existing methods relying on traditional cameras tend to fail in high-speed scenarios due to insufficient observations and inaccurate pose estimation. Event cameras, inspired by biological vision, record pixel-wise intensity changes asynchronously with high temporal resolution and low latency, providing valuable scene and motion information in blind inter-frame intervals. In this paper, we introduce the event cameras to aid scene construction from a casually captured video for the first time, and propose Event-Aided Free-Trajectory 3DGS, called EF-3DGS, which seamlessly integrates the advantages of event cameras into 3DGS through three key components. First, we leverage the Event Generation Model (EGM) to fuse events and frames, enabling continuous supervision between discrete frames. Second, we extract motion information through Contrast Maximization (CMax) of warped events, which calibrates camera poses and provides gradient-domain constraints for 3DGS. Third, to address the absence of color information in events, we combine photometric bundle adjustment (PBA) with a Fixed-GS training strategy that separates structure and color optimization, effectively ensuring color consistency across different views. We evaluate our method on the public Tanks and Temples benchmark and a newly collected real-world dataset, RealEv-DAVIS. Our method achieves up to 3dB higher PSNR and 40% lower Absolute Trajectory Error (ATE) compared to state-of-the-art methods under challenging high-speed scenarios.'}",https://openreview.net{'value': '/pdf/e373ef019f77ed2e11d4cc612a58176b79e60bd4.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=sfTtFZXINg,{'value': 'Spectral Analysis of Representational Similarity with Limited Neurons'},Hyunmo Kang; Abdulkadir Canatar; SueYeon Chung,~Hyunmo_Kang1; ~Abdulkadir_Canatar1; ~SueYeon_Chung1,"{'value': ['representational similarity', 'centered kernel alignment', 'random matrix theory', 'computational neuroscience']}","{'value': 'Understanding representational similarity between neural recordings and computational models is essential for neuroscience, yet remains challenging to measure reliably due to the constraints on the number of neurons that can be recorded simultaneously. In this work, we apply tools from Random Matrix Theory to investigate how such limitations affect similarity measures, focusing on Centered Kernel Alignment (CKA) and Canonical Correlation Analysis (CCA). We propose an analytical framework for representational similarity analysis that relates measured similarities to the spectral properties of the underlying representations. We demonstrate that neural similarities are systematically underestimated under finite neuron sampling, mainly due to eigenvector delocalization. To overcome this, we introduce a denoising method to infer population-level similarity, enabling accurate analysis even with small neuron samples. Theoretical predictions are validated on synthetic and real datasets, offering practical strategies for interpreting neural data under finite sampling constraints.'}",https://openreview.net{'value': '/pdf/2608034379ed954209edeb18f2dbb4266fc4845d.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=sdlLycSeZl,{'value': 'Learning Memory-Enhanced Improvement Heuristics for Flexible Job Shop Scheduling'},Jiaqi Wang; Zhiguang Cao; Peng Zhao; Rui Cao; Yubin Xiao; Yuan Jiang; You Zhou,~Jiaqi_Wang21; ~Zhiguang_Cao1; ~Peng_Zhao14; ~Rui_Cao12; ~Yubin_Xiao1; ~Yuan_Jiang7; ~You_Zhou5,"{'value': ['Flexible Job-Shop Scheduling Problem', 'Graph Neural Network', 'Reinforcement Learning', 'Combinatorial Optimization']}","{'value': 'The rise of smart manufacturing under Industry 4.0 introduces mass customization and dynamic production, demanding more advanced and flexible scheduling techniques. The flexible job-shop scheduling problem (FJSP) has attracted significant attention due to its complex constraints and strong alignment with real-world production scenarios. Current deep reinforcement learning (DRL)-based approaches to FJSP predominantly employ constructive methods. While effective, they often fall short of reaching (near-)optimal solutions. In contrast, improvement-based methods iteratively explore the neighborhood of initial solutions and are more effective in approaching optimality. However, the flexible machine allocation in FJSP poses significant challenges to the application of this framework, including accurate state representation, effective policy learning, and efficient search strategies. To address these challenges, this paper proposes a $\\textbf{M}$emory-enhanced $\\textbf{I}$mprovement $\\textbf{S}$earch framework with he$\\textbf{t}$erogeneous gr$\\textbf{a}$ph $\\textbf{r}$epresentation—$\\textit{MIStar}$. It employs a novel heterogeneous disjunctive graph that explicitly models the operation sequences on machines to accurately represent scheduling solutions. Moreover, a memory-enhanced heterogeneous graph neural network (MHGNN) is designed for feature extraction, leveraging historical trajectories to enhance the decision-making capability of the policy network. Finally, a parallel greedy search strategy is adopted to explore the solution space, enabling superior solutions with fewer iterations. Extensive experiments on synthetic data and public benchmarks demonstrate that $\\textit{MIStar}$ significantly outperforms both traditional handcrafted improvement heuristics and state-of-the-art DRL-based constructive methods.'}",https://openreview.net{'value': '/pdf/96181f1631a0b6949264366ad18fedfa77532f72.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=sdK5Ufoo2d,{'value': 'Curious Causality-Seeking Agents in Open-ended Worlds'},Zhiyu Zhao; Haoxuan Li; Haifeng Zhang; Jun Wang; Francesco Faccio; Jürgen Schmidhuber; Mengyue Yang,~Zhiyu_Zhao1; ~Haoxuan_Li6; ~Haifeng_Zhang3; ~Jun_Wang2; ~Francesco_Faccio1; ~Jürgen_Schmidhuber1; ~Mengyue_Yang1,"{'value': ['Causality', 'World Model']}","{'value': ""When building a world model, a common assumption is that the environment has a single, unchanging underlying causal rule, like applying Newton's laws to every situation. However, in truly open-ended environments, the apparent causal mechanism may drift over time because the agent continually encounters novel contexts and operates within a limited observational window. This brings about a problem that, when building a world model, even subtle shifts in policy or environment states can alter the very observed causal mechanisms.\nIn this work, we introduce the Meta-Causal Graph as world models for open-ended environments, a minimal unified representation that efficiently encodes the transformation rules governing how causal structures shift across different latent world states. A single Meta-Causal Graph is composed of multiple causal subgraphs, each triggered by meta state, which is in the latent state space. Building on this representation, we introduce a Causality-Seeking Agent whose objectives are to (1) identify the meta states that trigger each subgraph, (2) discover the corresponding causal relationships by agent curiosity-driven intervention policy, and (3) iteratively refine the Meta-Causal Graph through ongoing curiosity-driven exploration and agent experiences. Experiments on both synthetic tasks and a challenging robot arm manipulation task demonstrate that our method robustly captures shifts in causal dynamics and generalizes effectively to previously unseen contexts.""}",https://openreview.net{'value': '/pdf/4445ec123339778db9f6d34f44f2fcdc927ebd3d.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=sYfIpZzojf,{'value': 'Outcome-Based Online Reinforcement Learning: Algorithms and Fundamental Limits'},Fan Chen; Zeyu Jia; Alexander Rakhlin; Tengyang Xie,~Fan_Chen4; ~Zeyu_Jia1; ~Alexander_Rakhlin1; ~Tengyang_Xie1,"{'value': ['reinforcement learning theory', 'online exploration', 'outcome-based RL', 'sample efficient RL']}","{'value': 'Reinforcement learning with outcome-based feedback faces a fundamental challenge: when rewards are only observed at trajectory endpoints, how do we assign credit to the right actions? This paper provides the first comprehensive analysis of this problem in online RL with general function approximation. We develop a provably sample-efficient algorithm achieving $\\widetilde{O}({C_{\\rm cov} H^3}/{\\varepsilon^2})$ sample complexity, where $C_{\\rm cov}$ is the coverability coefficient of the underlying MDP. By leveraging general function approximation, our approach works effectively in large or infinite state spaces where tabular methods fail, requiring only that value functions and reward functions can be represented by appropriate function classes. Our results also characterize when outcome-based feedback is statistically separated from per-step rewards, revealing an unavoidable exponential separation for certain MDPs. For deterministic MDPs, we show how to eliminate the completeness assumption, dramatically simplifying the algorithm. We further extend our approach to preference-based feedback settings, proving that equivalent statistical efficiency can be achieved even under more limited information. Together, these results constitute a theoretical foundation for understanding the statistical properties of outcome-based reinforcement learning.'}",https://openreview.net{'value': '/pdf/ead39a0dea938d2741cc647d22199076cba4844b.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=sT1U2enBh0,{'value': 'Interactive and Hybrid Imitation Learning: Provably Beating Behavior Cloning'},Yichen Li; Chicheng Zhang,~Yichen_Li3; ~Chicheng_Zhang1,"{'value': ['imitation learning', 'online learning', 'reinforcement learning']}","{'value': 'Imitation learning (IL) is a paradigm for learning sequential decision-making policies from experts, leveraging offline demonstrations, interactive annotations, or both. Recent advances show that when annotation cost is tallied per trajectory, Behavior Cloning (BC)—which relies solely on offline demonstrations—cannot be improved in general, leaving limited conditions for interactive methods such as DAgger to help. We revisit this conclusion and prove that when the annotation cost is measured per state, algorithms using interactive annotations can provably outperform BC. Specifically: (1) we show that Stagger, a one‑sample‑per‑round variant of DAgger, provably beats BC under low-recovery-cost settings; (2) we initiate the study of hybrid IL where the agent learns from offline demonstrations and interactive annotations. We propose Warm-Stagger whose learning guarantee is not much worse than using either data source alone. Furthermore, motivated by compounding error and cold‑start problem in imitation learning practice, we give an MDP example in which Warm-Stagger has significant better annotation cost; (3) experiments on MuJoCo continuous‑control tasks confirm that, with modest cost ratio between interactive and offline annotations, interactive and hybrid approaches consistently outperform BC. To the best of our knowledge, our work is the first to highlight the benefit of state‑wise interactive annotation and hybrid feedback in imitation learning.'}",https://openreview.net{'value': '/pdf/a70ef66f2c0da4dc0a4fd872517584d9b5c87aff.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=sJl73HJGNj,{'value': 'AiDE-Q: Synthetic Labeled Datasets Can Enhance Learning Models for Quantum Property Estimation'},Xinbiao Wang; Yuxuan Du; Zihan Lou; Yang Qian; Kaining Zhang; Yong Luo; Bo Du; Dacheng Tao,~Xinbiao_Wang1; ~Yuxuan_Du2; ~Zihan_Lou1; ~Yang_Qian1; ~Kaining_Zhang1; ~Yong_Luo2; ~Bo_Du3; ~Dacheng_Tao1,"{'value': ['Quantum Computing', 'Quantum Property Estimation', 'Data Engine', 'Quantum Many-body Problems', 'Deep Learning']}","{'value': 'Quantum many-body problems are central to various scientific disciplines, yet their ground-state properties are intrinsically challenging to estimate. Recent advances in deep learning (DL) offer potential solutions in this field, complementing prior purely classical and quantum approaches. However, existing DL-based models typically assume access to a large-scale and noiseless labeled dataset collected by infinite sampling. This idealization raises fundamental concerns about their practical utility, especially given the limited availability of quantum hardware in the near term. To unleash the power of these DL-based models, we propose AiDE-Q (\\underline{a}utomat\\underline{i}c \\underline{d}ata \\underline{e}ngine for \\underline{q}uantum property estimation), an effective framework that addresses this challenge by iteratively generating high-quality synthetic labeled datasets. Specifically, AiDE-Q utilizes a confidence-check method to assess the quality of synthetic labels and continuously improves the employed DL models with the identified high-quality synthetic dataset. To verify the effectiveness of AiDE-Q, we conduct extensive numerical simulations on a diverse set of quantum many-body and molecular systems, with up to 50 qubits. The results show that AiDE-Q enhances prediction performance for various reference learning models, with improvements of up to $14.2\\\\%$. Moreover, we exhibit that a basic supervised learning model integrated with AiDE-Q outperforms advanced reference models, highlighting the importance of a synthetic dataset. Our work paves the way for more efficient and practical applications of DL for quantum property estimation.'}",https://openreview.net{'value': '/pdf/1c9cb0f41d3d6d731d4beaec44131c9f94c98101.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=sJbA3xMx1B,{'value': 'FraPPE: Fast and Efficient Preference-Based Pure Exploration'},Udvas Das; Apurv Shukla; Debabrota Basu,~Udvas_Das1; ~Apurv_Shukla1; ~Debabrota_Basu1,"{'value': ['Bandits', 'Pareto Set Identification', 'Pure Exploration', 'Fixed Confidence', 'Sample Complexity', 'Preference Cone']}","{'value': 'Preference-based Pure Exploration (PrePEx) aims to identify with a given confidence level the set of Pareto optimal arms in a vector-valued (aka multi-objective) bandit, where the reward vectors are ordered via a (given) preference cone $\\mathcal C$. Though PrePEx and its variants are well-studied, there does not exist a *computationally efficient* algorithm that can *optimally* track the existing lower bound (Shukla and Basu, 2024) for arbitrary preference cones. We successfully fill this gap by efficiently solving the minimisation and maximisation problems in the lower bound. First, we derive three structural properties of the lower bound that yield a computationally tractable reduction of the minimisation problem. Then, we deploy a Frank-Wolfe optimiser to accelerate the maximisation problem in the lower bound. Together, these techniques solve the maxmin optimisation problem in $\\mathcal O(KL^{2})$ time for a bandit instance with $K$ arms and $L$ dimensional reward, which is a significant acceleration over the literature. We further prove that our proposed PrePEx algorithm, **FraPPE**, asymptotically achieves the optimal sample complexity. Finally, we perform numerical experiments across synthetic and real datasets demonstrating that **FraPPE** achieves the lowest sample complexities to identify the exact Pareto set among the existing algorithms.'}",https://openreview.net{'value': '/pdf/930e06f0fc65f236925717468784570fbdf31318.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=sCgYsBVIVG,{'value': 'Multi-modal contrastive learning adapts to intrinsic dimensions of shared latent variables'},Yu Gui; Cong Ma; Zongming Ma,~Yu_Gui1; ~Cong_Ma1; ~Zongming_Ma2,{'value': ['contrastive learning; multi-modal learning; machine learning theory;']},"{'value': 'Multi-modal contrastive learning as a self-supervised representation learning technique has achieved great success in foundation model training, such as CLIP~\\citep{radford2021learning}. \nIn this paper, we study the theoretical properties of the learned representations from multi-modal contrastive learning beyond linear representations and specific data distributions. \nOur analysis reveals that, enabled by temperature optimization, multi-modal contrastive learning not only maximizes mutual information between modalities but also adapts to intrinsic dimensions of data, which can be much lower than user-specified dimensions for representation vectors. \nExperiments on both synthetic and real-world datasets demonstrate the ability of contrastive learning to learn low-dimensional and informative representations, bridging theoretical insights and practical performance.'}",https://openreview.net{'value': '/pdf/3bd40d4c7c5d084d32ddaa3f4bba0e7f6a34d42c.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=s9NkfkUuEr,{'value': 'Iterative Self-Incentivization Empowers Large Language Models as Agentic Searchers'},Zhengliang Shi; Lingyong Yan; Dawei Yin; Suzan Verberne; Maarten de Rijke; Zhaochun Ren,~Zhengliang_Shi1; ~Lingyong_Yan1; ~Dawei_Yin1; ~Suzan_Verberne1; ~Maarten_de_Rijke1; ~Zhaochun_Ren1,"{'value': ['information retrieval', 'large language model', 'retrieval-augmented generation']}","{'value': 'Large language models (LLMs) have been widely integrated into information retrieval to advance traditional techniques. However, effectively enabling LLMs to seek accurate knowledge in complex tasks remains a challenge due to the complexity of multi-hop queries as well as the irrelevant retrieved content. To address these limitations, we propose ExSearch, an agentic search framework, where the LLM learns to retrieve useful information as the reasoning unfolds through a self-incentivized process. At each step, the LLM decides what to retrieve (thinking), triggers an external retriever (search), and extracts fine-grained evidence (recording) to support next-step reasoning.  To enable LLM with this capability, we adopts a Generalized Expectation-Maximization algorithm. In the E-step, the LLM generates multiple search trajectories and assigns an importance weight to each; the M-step trains the LLM on them with a re-weighted loss function. This creates a self-incentivized loop, where the LLM iteratively learns from its own generated data, progressively improving itself for search. We further theoretically analyze this training process, establishing convergence guarantees. Extensive experiments on four knowledge-intensive benchmarks show that ExSearchS substantially outperforms baselines, e.g., +7.8% improvement on exact match score. Motivated by these promising results, we introduce ExSearch-Zoo, an extension that extends our method to broader scenarios, to facilitate future work.'}",https://openreview.net{'value': '/pdf/f6244ed69adb4a0f1c375503deb1e23c39a8ac15.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=s91i4zNebu,{'value': 'SRSR: Enhancing Semantic Accuracy in Real-World Image Super-Resolution with Spatially Re-Focused Text-Conditioning'},Chen Chen; Majid Abdolshah; Violetta Shevchenko; Hongdong Li; Chang Xu; Pulak Purkait,~Chen_Chen39; ~Majid_Abdolshah1; ~Violetta_Shevchenko1; ~Hongdong_Li1; ~Chang_Xu4; ~Pulak_Purkait1,"{'value': ['Real-World Image Super-Resolution', 'Diffusion Models', 'Attention Mechanism']}","{'value': 'Existing diffusion-based super-resolution approaches often exhibit semantic ambiguities due to inaccuracies and incompleteness in their text conditioning, coupled with the inherent tendency for cross-attention to divert towards irrelevant pixels. These limitations can lead to semantic misalignment and hallucinated details in the generated high-resolution outputs. To address these, we propose a novel, plug-and-play *spatially re-focused super-resolution (SRSR)* framework that consists of two core components: first, we introduce Spatially Re-focused Cross-Attention (SRCA), which refines text conditioning at inference time by applying visually-grounded segmentation masks to guide cross-attention. Second, we introduce a Spatially Targeted Classifier-Free Guidance (STCFG) mechanism that selectively bypasses text influences on ungrounded pixels to prevent hallucinations. Extensive experiments on both synthetic and real-world datasets demonstrate that SRSR consistently outperforms seven state-of-the-art baselines in standard fidelity metrics (PSNR and SSIM) across all datasets, and in perceptual quality measures (LPIPS and DISTS) on two real-world benchmarks, underscoring its effectiveness in achieving both high semantic fidelity and perceptual quality in super-resolution.'}",https://openreview.net{'value': '/pdf/69c43041532873d3caf5f29afea956eb39a93d03.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=s3Uk3lrfjy,{'value': 'INC: An Indirect Neural Corrector for Auto-Regressive Hybrid PDE Solvers'},Hao Wei; Aleksandra Franz; Björn Malte List; Nils Thuerey,~Hao_Wei9; ~Aleksandra_Franz1; ~Björn_Malte_List1; ~Nils_Thuerey1,"{'value': ['machine learning for science', 'hybrid PDE solvers', 'autoregressive error analysis', 'differentiable physics']}","{'value': 'When simulating partial differential equations, hybrid solvers combine coarse numerical solvers with learned correctors. They promise accelerated simulations while adhering to physical constraints. However, as shown in our theoretical framework, directly applying learned corrections to solver outputs leads to significant autoregressive errors, which originate from amplified perturbations that accumulate during long-term rollouts, especially in chaotic regimes. To overcome this, we propose the Indirect Neural Corrector ($\\mathrm{INC}$), which integrates learned corrections into the governing equations rather than applying direct state updates. Our key insight is that $\\mathrm{INC}$ reduces the error amplification on the order of $\\Delta t^{-1} + L$, where $\\Delta t$ is the timestep and $L$ the Lipschitz constant. At the same time, our framework poses no architectural requirements and integrates seamlessly with arbitrary neural networks and solvers. We test $\\mathrm{INC}$ in extensive benchmarks, covering numerous differentiable solvers, neural backbones, and test cases ranging from a 1D chaotic system to 3D turbulence. INC improves the long-term trajectory performance ($R^2$) by up to 158.7\\%, stabilizes blowups under aggressive  coarsening, and for complex 3D turbulence cases yields speed-ups of several orders of magnitude. INC thus enables stable, efficient PDE emulation with formal error reduction, paving the way for faster scientific and engineering simulations with reliable physics guarantees.'}",https://openreview.net{'value': '/pdf/27e9d67a2e01f3cfc9109236ea4f25f3f769bc1a.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=s3LMqrwwHJ,{'value': 'FANS: A Flatness-Aware Network Structure for Generalization in Offline Reinforcement Learning'},Da Wang; Yi Ma; Ting Guo; Hongyao Tang; Wei Wei; Jiye Liang,~Da_Wang2; ~Yi_Ma5; ~Ting_Guo3; ~Hongyao_Tang1; ~Wei_Wei13; ~Jiye_Liang1,"{'value': ['offline reinforcement learning', 'generalization', 'structuration']}","{'value': 'Offline reinforcement learning (RL) aims to learn optimal policies from static datasets while enhancing generalization to out-of-distribution (OOD) data. To mitigate overfitting to suboptimal behaviors in offline datasets, existing methods often relax constraints on policy and data or extract informative patterns through data-driven techniques. However, there has been limited exploration into structurally guiding the optimization process toward flatter regions of the solution space that offer better generalization. Motivated by this observation, we present \\textit{FANS}, a generalization-oriented structured network framework that promotes flatter and robust policy learning by guiding the optimization trajectory through modular architectural design. FANS comprises four key components: (1) Residual Blocks, which facilitate compact and expressive representations; (2) Gaussian Activation, which promotes smoother gradients; (3) Layer Normalization, which mitigates overfitting; and (4) Ensemble Modeling, which reduces estimation variance. By integrating FANS into a standard actor-critic framework, we highlight that this remarkably simple architecture achieves superior performance across various tasks compared to many existing advanced methods. Moreover, we validate the effectiveness of FANS in mitigating overestimation and promoting generalization, demonstrating the promising potential of architectural design in advancing offline RL.'}",https://openreview.net{'value': '/pdf/b5ca1654e85097d39812badac441c59a6f621690.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=s2hidSUFdj,{'value': 'Automatic Synthetic Data and Fine-grained Adaptive Feature Alignment for Composed Person Retrieval'},Delong Liu; Haiwen Li; Zhaohui Hou; Zhicheng Zhao; Fei Su; Yuan Dong,~Delong_Liu1; ~Haiwen_Li1; ~Zhaohui_Hou1; ~Zhicheng_Zhao1; ~Fei_Su1; ~Yuan_Dong1,"{'value': ['Composed Person Retrieval', 'Synthetic Data Generation', 'Fine-grained Feature Alignment', 'Multimodal Retrieval']}","{'value': 'Person retrieval has attracted rising attention. Existing methods are mainly divided into two retrieval modes, namely image-only and text-only. However, they are unable to make full use of the available information and are difficult to meet diverse application requirements. To address the above limitations, we propose a new Composed Person Retrieval (CPR) task, which combines visual and textual queries to identify individuals of interest from large-scale person image databases. Nevertheless, the foremost difficulty of the CPR task is the lack of available annotated datasets. Therefore, we first introduce a scalable automatic data synthesis pipeline, which decomposes complex multimodal data generation into the creation of textual quadruples followed by identity-consistent image synthesis using fine-tuned generative models. Meanwhile, a multimodal filtering method is designed to ensure the resulting SynCPR dataset retains 1.15 million high-quality and fully synthetic triplets. Additionally, to improve the representation of composed person queries, we propose a novel Fine-grained Adaptive Feature Alignment (FAFA) framework through fine-grained dynamic alignment and masked feature reasoning. Moreover, for objective evaluation, we manually annotate the Image-Text Composed Person Retrieval (ITCPR) test set. The extensive experiments demonstrate the effectiveness of the SynCPR dataset and the superiority of the proposed FAFA framework when compared with the state-of-the-art methods. All code and data will be provided at https://github.com/Delong-liu-bupt/Composed_Person_Retrieval.'}",https://openreview.net{'value': '/pdf/2be8dce95fba6eb553cbffb05a07cb02e1d102b4.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=rwmVd8BKW5,{'value': 'Universal Sequence Preconditioning'},Annie Marsden; Elad Hazan,~Annie_Marsden1; ~Elad_Hazan1,"{'value': ['sequence prediction', 'time series', 'pre-conditioning']}","{'value': 'We study the problem of preconditioning in the setting of sequential prediction. From the theoretical lens of linear dynamical systems, we show that applying a convolution to the input sequence translates to applying a polynomial to the unknown transition matrix in the hidden space. With this insight, we develop a novel preconditioning method that convolves the input sequence with the coefficients of the Chebyshev or Legendre polynomials. We formally prove that this improves the regret of a wide family of prediction methods. \n\nWe proceed to apply this preconditioning technique to the method of spectral filtering. This gives the first sublinear regret bound that is also hidden-dimension free (up to logarithmic factors) even when the hidden transition matrix is asymmetric.\n\nFrom rigorous experiments on synthetic data we show that our simple preconditioning method generalizes to both 1) settings where the data is \\emph{not} from a linear dynamical system and 2) a broad range of learning algorithms, including recurrent neural networks.'}",https://openreview.net{'value': '/pdf/9af6798b0d24d7760f71d6afe6dd5973072b535f.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=rqXEiXZT6C,{'value': 'What do you know? Bayesian knowledge inference for navigating agents'},Matthias Schultheis; Jana-Sophie Schönfeld; Constantin A. Rothkopf; Heinz Koeppl,~Matthias_Schultheis1; ~Jana-Sophie_Schönfeld1; ~Constantin_A._Rothkopf1; ~Heinz_Koeppl1,"{'value': ['Bayesian reinforcement learning', 'computational cognitive science', 'human behavior', 'inverse reinforcement learning', 'theory of mind']}","{'value': ""Human behavior is characterized by continuous learning to reduce uncertainties about the world in pursuit of goals. When trying to understand such behavior from observations, it is essential to account for this adaptive nature and reason about the uncertainties that may have led to seemingly suboptimal decisions. Nevertheless, most inverse approaches to sequential decision-making focus on inferring cost functions underlying stationary behavior or are limited to low-dimensional tasks. In this paper, we address this gap by considering the problem of inferring an agent's knowledge or awareness about the environment based on a given trajectory. We assume that the agent aims to reach a goal in an environment they only partially know, and integrates new information into their plan as they act. We propose a Bayesian approach to infer their latent knowledge state, leveraging an approximate navigation model that optimistically incorporates partial information while accounting for uncertainty. By combining sample-based Bayesian inference with dynamic graph algorithms, we achieve an efficient method for computing posterior beliefs about the agent's knowledge. Empirical validation using simulated behavioral data and human data from an online experiment demonstrates that our model effectively captures human navigation under uncertainty and reveals interpretable insights into their environmental knowledge.""}",https://openreview.net{'value': '/pdf/9a41c4f384199af50adf497c6bf1ba922015bbb4.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=rldWzb0E7G,"{'value': 'PolyJuice Makes It Real: Black-Box, Universal Red Teaming for Synthetic Image Detectors'}",Sepehr Dehdashtian; Mashrur M. Morshed; Jacob H Seidman; Gaurav Bharaj; Vishnu Boddeti,~Sepehr_Dehdashtian1; ~Mashrur_M._Morshed1; ~Jacob_H_Seidman1; ~Gaurav_Bharaj1; ~Vishnu_Boddeti1,"{'value': ['Red Teaming', 'Diffusion Models', 'Generative Models', 'Synthetic Image Detection', 'Text-to-Image Models', 'Concept Steering']}","{'value': 'Synthetic image detectors (SIDs) are a key defense against the risks posed by the growing realism of images from text-to-image (T2I) models. Red teaming improves SID’s effectiveness by identifying and exploiting their failure modes via misclassified synthetic images. However, existing red-teaming solutions (i) require white-box access to SIDs, which is infeasible for proprietary state-of-the-art detectors, and (ii) generate image-specific attacks through expensive online optimization. To address these limitations, we propose PolyJuice, the first black-box, image-agnostic red-teaming method for SIDs, based on an observed distribution shift in the T2I latent space between samples correctly and incorrectly classified by the SID. PolyJuice generates attacks by (i) identifying the direction of this shift through a lightweight offline process that only requires black-box access to the SID, and (ii) exploiting this direction by universally steering all generated images towards the SID’s failure modes. PolyJuice-steered T2I models are significantly more effective at deceiving SIDs (up to 84%) compared to their unsteered counterparts. We also show that the steering directions can be estimated efficiently at lower resolutions and transferred to higher resolutions using simple interpolation, reducing computational overhead. Finally, tuning SID models on PolyJuice-augmented datasets notably enhances the performance of the detectors (up to 30%).'}",https://openreview.net{'value': '/pdf/813e9268b6fa415c9c118b79582a497793c58734.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=rgajBQxbC7,{'value': 'ESCORT: Efficient Stein-variational and Sliced Consistency-Optimized Temporal Belief Representation for POMDPs'},Yunuo Zhang; Baiting Luo; Ayan Mukhopadhyay; Gabor Karsai; Abhishek Dubey,~Yunuo_Zhang1; ~Baiting_Luo1; ~Ayan_Mukhopadhyay1; ~Gabor_Karsai1; ~Abhishek_Dubey1,"{'value': ['POMDPs', 'Particle-based Variational Inference', 'Reinforcement Learning']}","{'value': ""In Partially Observable Markov Decision Processes (POMDPs), maintaining and updating belief distributions over possible underlying states provides a principled way to summarize action-observation history for effective decision-making under uncertainty. As environments grow more realistic, belief distributions develop complexity that standard mathematical models cannot accurately capture, creating a fundamental challenge in maintaining representational accuracy. Despite advances in deep learning and probabilistic modeling, existing POMDP belief approximation methods fail to accurately represent complex uncertainty structures such as high-dimensional, multi-modal belief distributions, resulting in estimation errors that lead to suboptimal agent behaviors. To address this challenge, we present ESCORT (Efficient Stein-variational and sliced Consistency-Optimized Representation for Temporal beliefs), a particle-based framework for capturing complex, multi-modal distributions in high-dimensional belief spaces. ESCORT extends SVGD with two key innovations: correlation-aware projections that model dependencies between state dimensions, and temporal consistency constraints that stabilize updates while preserving correlation structures. This approach retains SVGD's attractive-repulsive particle dynamics while enabling accurate modeling of intricate correlation patterns. Unlike particle filters prone to degeneracy or parametric methods with fixed representational capacity, ESCORT dynamically adapts to belief landscape complexity without resampling or restrictive distributional assumptions. We demonstrate ESCORT's effectiveness through extensive evaluations on both POMDP domains and synthetic multi-modal distributions of varying dimensionality, where it consistently outperforms state-of-the-art methods in terms of belief approximation accuracy and downstream decision quality.""}",https://openreview.net{'value': '/pdf/9f5d11f38629d4b3a81218e57a6ba2823aa4b3e1.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=rbYPITgH4Z,{'value': 'Channel Simulation and Distributed Compression with Ensemble Rejection Sampling'},Buu Phan; Ashish J Khisti,~Buu_Phan3; ~Ashish_J_Khisti1,"{'value': ['Channel Simmulation', 'Distributed Compression', 'Probabilistic Method']}","{'value': 'We study channel simulation and distributed matching, two fundamental problems with several applications to machine learning, using a recently introduced generalization of the standard rejection sampling (RS) algorithm known as Ensemble Rejection Sampling (ERS). For channel simulation, we propose a new coding scheme based on ERS that achieves a near-optimal coding rate. In this process, we demonstrate that standard RS can also achieve a near-optimal coding rate and generalize the result of Braverman and Garg (2014) to the continuous alphabet setting. Next, as our main contribution, we present a distributed matching lemma for ERS, which serves as the rejection sampling counterpart to the Poisson Matching Lemma (PML) introduced by Li and Anantharam (2021). Our result also generalizes a recent work on importance matching lemma (Phan et al, 2024) and, to our knowledge, is the first result on distributed matching in the family of rejection sampling schemes where the matching probability is close to PML. We demonstrate the practical significance of our approach over prior works by applying it to distributed compression. The effectiveness of our proposed scheme is validated through experiments involving synthetic Gaussian sources and distributed image compression using the MNIST dataset.'}",https://openreview.net{'value': '/pdf/6dfb14a4067cc2916cb689888a7e3b9af4b3f1d9.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=rWW5wdECl8,{'value': 'On the Edge of Memorization in Diffusion Models'},Sam Buchanan; Druv Pai; Yi Ma; Valentin De Bortoli,~Sam_Buchanan1; ~Druv_Pai1; ~Yi_Ma4; ~Valentin_De_Bortoli1,"{'value': ['diffusion models', 'memorization', 'generalization', 'phase transition', 'denoising']}","{'value': 'When do diffusion models reproduce their training data, and when are they able to generate samples beyond it? A practically relevant theoretical understanding of this interplay between memorization and generalization may significantly impact real-world deployments of diffusion models with respect to issues such as copyright infringement and data privacy. In this paper, we propose a scientific and\nmathematical “laboratory” for investigating memorization and generalization in diffusion models trained on fully synthetic or natural image-like structured data. Within this setting, we theoretically characterize a crossover point wherein the weighted training loss of a fully generalizing model becomes greater than that of an underparameterized memorizing model at a critical value of model (under)parameterization. We then demonstrate via carefully-designed experiments that the location of this crossover predicts a phase transition in diffusion models trained via gradient descent, as our theory enables us to analytically predict the model size at which memorization becomes predominant. Our work provides an analytically tractable and practically meaningful setting for future theoretical and empirical investigations. Code for our experiments is available at https://github.com/DruvPai/diffusion_mem_gen.'}",https://openreview.net{'value': '/pdf/a1f0b7293900ebc3dad553f668f15fddd60dd15e.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=rVT1GK60Nt,{'value': 'On the Optimal Construction of Unbiased Gradient Estimators for Zeroth-Order Optimization'},Shaocong Ma; Heng Huang,~Shaocong_Ma1; ~Heng_Huang1,"{'value': ['zeroth-order optimization', 'stochastic optimization', 'stochastic gradient descent']}","{'value': 'Zeroth-order optimization (ZOO) is an important framework for stochastic optimization when gradients are unavailable or expensive to compute. A potential limitation of existing ZOO methods is the bias inherent in most gradient estimators unless the perturbation stepsize vanishes. In this paper, we overcome this biasedness issue by proposing a novel family of *unbiased* gradient estimators based solely on function evaluations. By reformulating directional derivatives as a telescoping series and sampling from carefully designed distributions, we construct estimators that eliminate bias while maintaining favorable variance. We analyze their theoretical properties, derive optimal scaling distributions and perturbation stepsizes of four specific constructions, and prove that SGD using the proposed estimators achieves optimal complexity for smooth non-convex objectives. Experiments on synthetic tasks and language model fine-tuning confirm the superior accuracy and convergence of our approach compared to standard methods.'}",https://openreview.net{'value': '/pdf/a0caf475913d19c4bcf9b0441bdc51991b81bd36.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=rRxFIOoEeF,{'value': 'Revisiting Multi-Agent World Modeling from a Diffusion-Inspired Perspective'},Yang Zhang; Xinran Li; Jianing Ye; Shuang Qiu; Delin Qu; Xiu Li; Chongjie Zhang; Chenjia Bai,~Yang_Zhang49; ~Xinran_Li3; ~Jianing_Ye1; ~Shuang_Qiu2; ~Delin_Qu1; ~Xiu_Li1; ~Chongjie_Zhang1; ~Chenjia_Bai2,"{'value': ['Multi-Agent Model-based Reinforcement Learning', 'World Models', 'Learning in Imaginations', 'Diffusion Models']}","{'value': ""World models have recently attracted growing interest in Multi-Agent Reinforcement Learning (MARL) due to their ability to improve sample efficiency for policy learning. However, accurately modeling environments in MARL is challenging due to the exponentially large joint action space and highly uncertain dynamics inherent in multi-agent systems. To address this, we reduce modeling complexity by shifting from jointly modeling the entire state-action transition dynamics to focusing on the state space alone at each timestep through sequential agent modeling. Specifically, our approach enables the model to progressively resolve uncertainty while capturing the structured dependencies among agents, providing a more accurate representation of how agents influence the state. Interestingly, this sequential revelation of agents' actions in a multi-agent system aligns with the reverse process in diffusion models—a class of powerful generative models known for their expressiveness and training stability compared to autoregressive or latent variable models. Leveraging this insight, we develop a flexible and robust world model for MARL using diffusion models. Our method, \\textbf{D}iffusion-\\textbf{I}nspired \\textbf{M}ulti-\\textbf{A}gent world model (DIMA), achieves state-of-the-art performance across multiple multi-agent control benchmarks, significantly outperforming prior world models in terms of final return and sample efficiency, including MAMuJoCo and Bi-DexHands. DIMA establishes a new paradigm for constructing multi-agent world models, advancing the frontier of MARL research. Codes are open-sourced at \\url{https://github.com/breez3young/DIMA}.""}",https://openreview.net{'value': '/pdf/df4c6c99112ef5c7b413554d69cc4728b21f6aa1.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=rPsUx09RJV,{'value': 'Auditing Meta-Cognitive Hallucinations in Reasoning Large Language Models'},Haolang Lu; Yilian Liu; Jingxin Xu; Guoshun Nan; Yuanlong Yu; Zhican Chen; Kun Wang,~Haolang_Lu1; ~Yilian_Liu1; ~Jingxin_Xu2; ~Guoshun_Nan1; ~Yuanlong_Yu3; ~Zhican_Chen1; ~Kun_Wang15,"{'value': ['hallucination', 'Chain-of-Thought', 'reasoning', 'Metacognition']}","{'value': ""The development of Reasoning Large Language Models (RLLMs) has significantly improved multi-step reasoning capabilities, but it has also made hallucination problems more frequent and harder to eliminate. While existing approaches address hallucination through external knowledge integration, model parameter analysis, or self-verification mechanisms, they fail to provide a comprehensive insight into how hallucinations **emerge** and **evolve** throughout the reasoning chain. In this work, we investigate hallucination causality under constrained knowledge domains by auditing the Chain-of-Thought (CoT) trajectory and assessing the model's cognitive confidence in potentially erroneous or biased claims.\nAnalysis reveals that in long-CoT settings, RLLMs may iteratively reinforce biases and errors through flawed reflective processes, ultimately inducing hallucinated reasoning paths.\nCounterintuitively, even with interventions at hallucination origins, reasoning chains display pronounced ''chain disloyalty'', resisting correction and sustaining flawed trajectories.\nWe further point out that existing hallucination detection methods are *less reliable and interpretable than previously assumed*, especially in complex multi-step reasoning contexts.\nUnlike Anthropic's circuit tracing that requires access to model parameters, our auditing **enables more interpretable long-chain hallucination attribution in black-box settings**, demonstrating stronger generalizability and practical utility.\nOur code is available at [this link](https://github.com/Winnie-Lian/AHa_Meta_Cognitive).""}",https://openreview.net{'value': '/pdf/01f218bf5bcd201302e5e37e9a0bf157f4309147.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=rMQvbxxmLe,{'value': 'From Forecasting to Planning: Policy World Model for Collaborative State-Action Prediction'},Zhida Zhao; Talas Fu; Yifan Wang; Lijun Wang; Huchuan Lu,~Zhida_Zhao1; ~Talas_Fu1; ~Yifan_Wang5; ~Lijun_Wang1; ~Huchuan_Lu1,"{'value': ['World model', 'Autonomous driving', 'End-to-end planning']}","{'value': 'Despite remarkable progress in driving world models, their potential for autonomous systems remains largely untapped: the world models are mostly learned for world simulation and decoupled from trajectory planning. While recent efforts aim to unify world modeling and planning in a single framework, the synergistic facilitation mechanism of world modeling for planning still requires further exploration. In this work, we introduce a new driving paradigm named Policy World Model (PWM), which not only integrates world modeling and trajectory planning within a unified architecture, but is also able to benefit planning using the learned world knowledge through the proposed action-free future state forecasting scheme. Through collaborative state-action prediction, PWM can mimic the human-like anticipatory perception, yielding more reliable planning performance. To facilitate the efficiency of video forecasting, we further introduce a parallel token generation mechanism, equipped with a context-guided tokenizer and an adaptive dynamic focal loss. Despite utilizing only front camera input, our method matches or exceeds state-of-the-art approaches that rely on multi-view and multi-modal inputs.  Code will be released at https://github.com/6550Zhao/Policy-World-Model.'}",https://openreview.net{'value': '/pdf/dbe78cc8fdf28b0340af74010ec4ad766aca831b.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=rIudtwY0VM,{'value': 'Bridging Arbitrary and Tree Metrics via Differentiable Gromov Hyperbolicity'},Pierre Houédry; Nicolas Courty; Florestan Martin-Baillon; Laetitia Chapel; Titouan Vayer,~Pierre_Houédry1; ~Nicolas_Courty1; ~Florestan_Martin-Baillon1; ~Laetitia_Chapel1; ~Titouan_Vayer1,"{'value': ['tree metric learning', 'delta-hyperbolicity', 'geometrical machine learning', 'differentiation']}","{'value': 'Trees and the associated shortest-path tree metrics provide a powerful framework for representing hierarchical and combinatorial structures in data. Given an arbitrary metric space, its deviation from a tree metric can be quantified by Gromov’s $\\delta$-hyperbolicity. Nonetheless, designing algorithms that bridge an arbitrary metric to its closest tree metric is still a vivid subject of interest, as most common approaches are either heuristical and lack guarantees, or perform moderately well. In this work, we introduce a novel differentiable optimization framework, coined DeltaZero, that solves this problem. Our method leverages a smooth surrogate for Gromov’s $\\delta$-hyperbolicity which enables a gradient-based optimization, with a tractable complexity. The corresponding optimization procedure is derived from a problem with better worst case guarantees than existing bounds, and is justified statistically. Experiments on synthetic and real-world datasets demonstrate that our method consistently achieves state-of-the-art distortion.'}",https://openreview.net{'value': '/pdf/e9d5c152e2edb2daccc091a6a8642471cbe2d0b1.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=rHt6tt5RNF,{'value': 'Multi-Modal Interactive Agent Layer for Few-Shot Universal Cross-Domain Retrieval and Beyond'},Kaixiang Chen; Pengfei Fang; Hui Xue,~Kaixiang_Chen1; ~Pengfei_Fang1; ~Hui_Xue6,"{'value': ['Few-Shot Universal Cross Domain Retrieval', 'Vision-Language Models', 'Cross-Domain Interaction', 'Agent Layer']}","{'value': 'This paper firstly addresses the challenge of few-shot universal cross-domain retrieval (FS-UCDR), enabling machines trained with limited data to generalize to novel retrieval scenarios, with queries from entirely unknown domains and categories. To achieve this, we first formally define the FS-UCDR task and propose the Multi-Modal Interactive Agent Layer (MAIL), which enhances the cross-modal interaction in vision-language models (VLMs) by aligning the parameter updates of target layer pairs across modalities.\nSpecifically, MAIL freezes the selected target layer pair and introduces a trainable agent layer pair to approximate localized parameter updates. A bridge function is then introduced to couple the agent layer pair, enabling gradient communication across modalities to facilitate update alignment. The proposed MAIL offers four key advantages: 1) its cross-modal interaction mechanism improves knowledge acquisition from limited data, making it highly effective in low-data scenarios; 2) during inference, MAIL integrates seamlessly into the VLM via reparameterization, preserving inference complexity; 3) extensive experiments validate the superiority of MAIL, which achieves substantial performance gains over data-efficient UCDR methods while requiring significantly fewer training samples; 4) beyond UCDR, MAIL also performs competitively on few-shot classification tasks, underscoring its strong generalization ability. Code.'}",https://openreview.net{'value': '/pdf/7e65c805a0d59f3c090025c801f2f7907fcede97.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=rH0aOLyjYQ,{'value': 'NoisyGRPO: Incentivizing Multimodal CoT Reasoning via Noise Injection and Bayesian Estimation'},Longtian Qiu; Shan Ning; Jiaxuan Sun; Xuming He,~Longtian_Qiu1; ~Shan_Ning1; ~Jiaxuan_Sun1; ~Xuming_He3,"{'value': ['Multimodal Large Language Model', 'Reinforcement learning']}","{'value': 'Reinforcement learning (RL) has shown promise in enhancing the general Chain-of-Thought (CoT) reasoning capabilities of multimodal large language models (MLLMs). However, when applied to improve general CoT reasoning, existing RL frameworks often struggle to generalize beyond the training distribution.  To address this, we propose NoisyGRPO, a systematic multimodal RL framework that introduces controllable noise into visual inputs for enhanced exploration and explicitly models the advantage estimation process via a Bayesian framework.\nSpecifically, NoisyGRPO improves RL training by: (1) \\textbf{Noise-Injected Exploration Policy}: Perturbing visual inputs with Gaussian noise to encourage exploration across a wider range of visual scenarios; and (2) \\textbf{Bayesian Advantage Estimation}: Formulating advantage estimation as a principled Bayesian inference problem, where the injected noise level serves as a prior and the observed trajectory reward as the likelihood. This Bayesian modeling fuses both sources of information to compute a robust posterior estimate of trajectory advantage, effectively guiding MLLMs to prefer visually grounded trajectories over noisy ones.\nExperiments on standard CoT quality, general capability, and hallucination benchmarks demonstrate that NoisyGRPO substantially improves generalization and robustness, especially in RL settings with small-scale MLLMs such as Qwen2.5-VL 3B.'}",https://openreview.net{'value': '/pdf/96f8ac8e6e7af57f7d1898ceced0a9d165735c5e.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=rGMaZkn1ve,{'value': 'MetaMind: Modeling Human Social Thoughts with Metacognitive Multi-Agent Systems'},Xuanming Zhang; Yuxuan Chen; Samuel Yeh; Sharon Li,~Xuanming_Zhang3; ~Yuxuan_Chen6; ~Samuel_Yeh1; ~Sharon_Li1,"{'value': ['LLM', 'multi-agent system', 'social cognition']}","{'value': ""Human social interactions depend on the ability to infer others' unspoken intentions, emotions, and beliefs—a cognitive skill grounded in the psychological concept of Theory of Mind (ToM). While large language models (LLMs) excel in semantic understanding tasks, they struggle with the ambiguity and contextual nuance inherent in human communication. To bridge this gap, we introduce **MetaMind**, a multi-agent framework inspired by psychological theories of metacognition, designed to emulate human-like social reasoning. MetaMind decomposes social understanding into three collaborative stages: (1) a *Theory-of-Mind Agent* generates hypotheses about user mental states (e.g., intent, emotion), (2) a *Moral Agent* refines these hypotheses using cultural norms and ethical constraints, and (3) a *Response Agent* generates contextually appropriate responses while validating alignment with inferred intent.\nOur framework achieves state-of-the-art performance across three challenging benchmarks, with 35.7% improvement in real-world social scenarios and 6.2% gain in ToM reasoning. Notably, it enables LLMs to match human-level performance on key ToM tasks for the first time. Ablation studies confirm the necessity of all components, which showcase the framework’s ability to balance contextual plausibility, social appropriateness, and user adaptation. This work advances AI systems toward human-like social intelligence, with applications in empathetic dialogue and culturally sensitive interactions. Code is available at https://github.com/XMZhangAI/MetaMind.""}",https://openreview.net{'value': '/pdf/29a73113409f297f7381c7e12c760e66f10a7ba2.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=rDqZjKIeda,{'value': 'Can Dependencies Induced by LLM-Agent Workflows Be Trusted?'},Yu Yao; Yiliao Song; Yian Xie; Mengdan Fan; Mingyu Guo; Tongliang Liu,~Yu_Yao3; ~Yiliao_Song2; ~Yian_Xie1; ~Mengdan_Fan2; ~Mingyu_Guo1; ~Tongliang_Liu1,{'value': ['Multi-LLM-Agent System']},"{'value': 'LLM-agent systems often decompose high-level objectives into subtask dependency graphs, assuming that each subtask’s output is reliable and conditionally independent of others given its parent responses. \nHowever, this assumption frequently breaks during execution, as ground-truth responses are inaccessible, leading to inter-agent misalignment—failures caused by inconsistencies and coordination breakdowns among agents. \nTo address this, we propose SeqCV, a dynamic framework for reliable execution under violated conditional independence. \nSeqCV executes subtasks sequentially, each conditioned on all prior verified responses, and performs consistency checks immediately after agents generate short token sequences. \nAt each checkpoint, a token sequence is accepted only if it represents shared knowledge consistently supported across diverse LLM models; otherwise, it is discarded, triggering recursive subtask decomposition for finer-grained reasoning. \nDespite its sequential nature, SeqCV avoids repeated corrections on the same misalignment and achieves higher effective throughput than parallel pipelines. \nAcross multiple reasoning and coordination tasks, SeqCV improves accuracy by up to 30\\% over existing LLM-agent systems.\nCode is available at https://github.com/tmllab/2025_NeurIPS_SeqCV.'}",https://openreview.net{'value': '/pdf/d84e4a86a34dd41d3f1e6d33048f4c075db78d62.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=r4BrtJRmy9,{'value': 'Missing Data Imputation by Reducing Mutual Information with Rectified Flows'},Jiahao Yu; Qizhen Ying; Leyang Wang; Ziyue Jiang; Song Liu,~Jiahao_Yu4; ~Qizhen_Ying1; ~Leyang_Wang1; ~Ziyue_Jiang2; ~Song_Liu1,"{'value': ['missing data', 'imputation', 'rectified flow', 'generative model']}","{'value': 'This paper introduces a novel iterative method for missing data imputation that sequentially reduces the mutual information between data and the corresponding missingness mask. Inspired by GAN-based approaches that train generators to decrease the predictability of missingness patterns, our method explicitly targets this reduction in mutual information.\nSpecifically, our algorithm iteratively minimizes the KL divergence between the joint distribution of the imputed data and missingness mask, and the product of their marginals from the previous iteration. \nWe show that the optimal imputation under this framework can be achieved by solving an ODE whose velocity field minimizes a rectified flow training objective. \nWe further illustrate that some existing imputation techniques can be interpreted as approximate special cases of our mutual-information-reducing framework. Comprehensive experiments on synthetic and real-world datasets validate the efficacy of our proposed approach, demonstrating its superior imputation performance. Our implementation is available at \\url{https://github.com/yujhml/MIRI-Imputation}.'}",https://openreview.net{'value': '/pdf/b51848c5f9ad724e3a2e5f89c68946ee78f8eff8.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=r2ykUnzuGt,{'value': 'ReCAP: Recursive Context-Aware Reasoning and Planning for Large Language Model Agents'},Zhenyu Zhang; Tianyi Chen; Weiran Xu; Alex Pentland; Jiaxin Pei,~Zhenyu_Zhang13; ~Tianyi_Chen14; ~Weiran_Xu3; ~Alex_Pentland1; ~Jiaxin_Pei1,"{'value': ['Large Language Model', 'Long-Horizon Reasoning', 'LLM Agent', 'LLM Reasoning']}","{'value': 'Long-horizon tasks requiring multi-step reasoning and dynamic re-planning remain challenging for large language models (LLMs). Sequential prompting methods are prone to context drift, loss of goal information, and recurrent failure cycles, while hierarchical prompting methods often weaken cross-level continuity or incur substantial runtime overhead. We introduce ReCAP (Recursive Context-Aware Reasoning and Planning), a hierarchical framework with shared context for reasoning and planning in LLMs. ReCAP combines three key mechanisms: (i) plan-ahead decomposition, in which the model generates a full subtask list, executes the first item, and refines the remainder; (ii) structured re-injection of parent plans, maintaining consistent multi-level context during recursive return; and (iii) memory-efficient execution, bounding the active prompt so costs scale linearly with task depth. Together these mechanisms align high-level goals with low-level actions, reduce redundant prompting, and preserve coherent context updates across recursion. Experiments demonstrate that ReCAP substantially improves subgoal alignment and success rates on various long-horizon reasoning benchmarks, achieving a 32\\% gain on synchronous Robotouille and a 29\\% improvement on asynchronous Robotouille under the strict pass@1 protocol.'}",https://openreview.net{'value': '/pdf/311841e491eca81acc49d5288503e9b7819788d6.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=r2jhtAD0yZ,{'value': 'Demystifying Spectral Feature Learning for Instrumental Variable Regression'},Dimitri Meunier; Antoine Moulin; Jakub Wornbard; Vladimir R Kostic; Arthur Gretton,~Dimitri_Meunier1; ~Antoine_Moulin1; ~Jakub_Wornbard1; ~Vladimir_R_Kostic1; ~Arthur_Gretton1,"{'value': ['instrumental variable regression', 'NPIV', 'nonparametric statistics', 'feature learning', 'causal inference', 'operator learning']}","{'value': ""We address the problem of causal effect estimation in the presence of hidden confounders, using nonparametric instrumental variable (IV) regression.\nA leading strategy employs \\emph{spectral features} - that is, learned features spanning the top eigensubspaces of the operator linking treatments to instruments.\nWe derive a generalization error bound for a two-stage least squares estimator based on  spectral features, and gain insights into the method's performance and failure modes. We show that  performance depends on two key factors, leading to a clear taxonomy of outcomes. In a \\emph{good} scenario, the approach is optimal. This occurs with strong \\emph{spectral alignment}, meaning the structural function is well-represented by the top eigenfunctions of the conditional operator, coupled with this operator's slow eigenvalue decay, indicating a strong instrument. Performance degrades in a \\emph{bad} scenario:  spectral alignment remains strong, but rapid eigenvalue decay (indicating a weaker instrument) demands significantly more samples for effective feature learning. Finally, in the \\emph{ugly} scenario, weak spectral alignment causes the method to fail, regardless of the eigenvalues' characteristics. Our synthetic experiments empirically validate this taxonomy. We further introduce a practical procedure to estimate these spectral properties from data, allowing practitioners to diagnose which regime a given problem falls into. We apply this method to the dSprites dataset, demonstrating its utility.""}",https://openreview.net{'value': '/pdf/5a245cd8f73eabafe9639faf5e21c192dd73decd.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=qu6mRbSnUs,{'value': 'On Feasible Rewards in Multi-Agent Inverse Reinforcement Learning'},Till Freihaut; Giorgia Ramponi,~Till_Freihaut1; ~Giorgia_Ramponi1,"{'value': ['Reinforcement Learning', 'Multi-Agent Reinforcement Learning', 'Inverse Reinforcement Learning', 'Multi-Agent Inverse Reinforcement Learning']}","{'value': ""Multi-agent inverse reinforcement learning (MAIRL) aims to recover agent reward functions from expert demonstrations. We characterize the feasible reward set in Markov games, identifying all reward functions that rationalize a given equilibrium. However, equilibrium-based observations are often ambiguous: a single Nash equilibrium can correspond to many reward structures, potentially changing the game's nature in multi-agent systems. We address this by introducing entropy-regularized Markov games, which yield a unique equilibrium while preserving strategic incentives. For this setting, we provide a sample complexity analysis detailing how errors affect learned policy performance. Our work establishes theoretical foundations and practical insights for MAIRL.""}",https://openreview.net{'value': '/pdf/da0667e6f3c1016bf860dd8622ddb179be811029.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=qqEfm8tlCM,{'value': 'FAST: Foreground‑aware Diffusion with Accelerated Sampling Trajectory for Segmentation‑oriented Anomaly Synthesis'},Xichen Xu; Yanshu Wang; Jinbao Wang; XiaoNing Lei; Guoyang Xie; GUANNAN JIANG; Zhichao Lu,~Xichen_Xu1; ~Yanshu_Wang2; ~Jinbao_Wang1; ~XiaoNing_Lei1; ~Guoyang_Xie1; ~GUANNAN_JIANG1; ~Zhichao_Lu1,"{'value': ['Anomaly synthesis', 'anomaly segmentation']}","{'value': 'Industrial anomaly segmentation relies heavily on pixel-level annotations, yet real-world anomalies are often scarce, diverse, and costly to label. Segmentation-oriented industrial anomaly synthesis (SIAS) has emerged as a promising alternative; however, existing methods struggle to balance sampling efficiency and generation quality. Moreover, most approaches treat all spatial regions uniformly, overlooking the distinct statistical differences between anomaly and background areas. This uniform treatment hinders the synthesis of controllable, structure-specific anomalies tailored for segmentation tasks. In this paper, we propose FAST, a foreground-aware diffusion framework featuring two novel modules: the Anomaly-Informed Accelerated Sampling (AIAS) and the Foreground-Aware Reconstruction Module (FARM). AIAS is a training-free sampling algorithm specifically designed for segmentation-oriented industrial anomaly synthesis, which accelerates the reverse process through coarse-to-fine aggregation and enables the synthesis of state-of-the-art segmentation-oriented anomalies in as few as 10 steps. Meanwhile, FARM adaptively adjusts the anomaly-aware noise within the masked foreground regions at each sampling step, preserving localized anomaly signals throughout the denoising trajectory. Extensive experiments on multiple industrial benchmarks demonstrate that FAST consistently outperforms existing anomaly synthesis methods in downstream segmentation tasks. We release the code in https://github.com/Chhro123/fast-foreground-aware-anomaly-synthesis.'}",https://openreview.net{'value': '/pdf/8f4193f9035d49109b655ad51f9a8b8f057579b0.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=qmvEe6nd2I,{'value': 'Hephaestus: Mixture Generative Modeling with Energy Guidance for Large-scale QoS Degradation'},Nguyen Hoang Khoi Do; Bach Ngo; Youval Kashuv; Canh V. Pham; Hanghang Tong; My T. Thai,~Nguyen_Hoang_Khoi_Do1; ~Bach_Ngo3; ~Youval_Kashuv1; ~Canh_V._Pham1; ~Hanghang_Tong3; ~My_T._Thai2,"{'value': ['Combinatorial Optimization', 'Reinforcement learning', 'Generative AI']}","{'value': 'We study the Quality of Service Degradation (QoSD) problem, in which an adversary perturbs edge weights to degrade network performance. This setting arises in both network infrastructures and distributed ML systems, where communication quality, not just connectivity, determines functionality. While classical methods rely on combinatorial optimization, and recent ML approaches address only restricted linear variants with small-size networks, no prior model directly tackles the QoSD problem under nonlinear edge-weight functions. This work proposes Hephaestus, a self-reinforcing generative framework that synthesizes feasible solutions in latent space, to fill this gap. Our method includes three phases: (1) Forge: a Predictive Path-Stressing (PPS) algorithm that uses graph learning and approximation to produce feasible solutions with performance guarantee, (2) Morph: a new theoretically grounded training paradigm for Mixture of Conditional VAEs guided by an energy-based model to capture solution feature distributions, and (3) Refine: a reinforcement learning agent that explores this space to generate progressively near-optimal solutions using our designed differentiable reward function. Experiments on both synthetic and real-world networks show that our approach consistently outperforms classical and ML baselines, particularly in scenarios with nonlinear cost functions where traditional methods fail to generalize.'}",https://openreview.net{'value': '/pdf/662a28acbcb800f560d21c8dfadc72c1ff9680c3.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=qcFTezC4x9,{'value': 'Event-based HDR Structured Light'},Jiacheng Fu; Yue Li; Xin Dong; Wenming Weng; Yueyi Zhang; Zhiwei Xiong,~Jiacheng_Fu1; ~Yue_Li11; ~Xin_Dong15; ~Wenming_Weng1; ~Yueyi_Zhang2; ~Zhiwei_Xiong1,"{'value': ['3D Reconstruction', 'HDR Structured Light', 'Event Camera']}","{'value': 'Event-based structured light (SL) systems have attracted increasing attention for their potential in high-performance 3D measurement. Despite the inherent HDR capability of event cameras, reflective and absorptive surfaces still cause event cluttering and absence, which produce overexposed and underexposed regions that degrade the reconstruction quality. In this work, we present the first HDR 3D measurement framework specifically designed for event-based SL systems. First, we introduce a multi-contrast HDR coding strategy that facilitates imaging of areas with different reflectance. Second, to alleviate inter-frame interference caused by overexposed and underexposed areas, we propose a universal confidence-driven stereo matching strategy. Specifically, we estimate a confidence map as the fusion weight for features via an energy-guided confidence estimation. Further, we propose the confidence propagation volume, an innovative cost volume that offers both effective suppression of inter-frame interference and strong representation capability. Third, we contribute an event-based SL simulator and propose the first event-based HDR SL dataset. We also collect a real-world benchmarking dataset with ground truth. We validate the effectiveness of our method with the proposed confidence-driven strategy on both synthetic and real-world datasets. Experimental results demonstrate that our proposed HDR framework enables accurate 3D measurement even under extreme conditions.'}",https://openreview.net{'value': '/pdf/990777b910644771ea1591928c8cc7fb52573746.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=qYSgnmT3dp,{'value': 'Non-Markovian Discrete Diffusion with Causal Language Models'},Yangtian Zhang; Sizhuang He; Daniel Levine; Lawrence Zhao; David Zhang; Syed A Rizvi; Shiyang Zhang; Emanuele Zappala; Rex Ying; David van Dijk,~Yangtian_Zhang1; ~Sizhuang_He1; ~Daniel_Levine2; ~Lawrence_Zhao1; ~David_Zhang7; ~Syed_A_Rizvi1; ~Shiyang_Zhang1; ~Emanuele_Zappala1; ~Zhitao_Ying1; ~David_van_Dijk1,"{'value': ['Generative Model', 'Causal Language Model']}","{'value': 'Discrete diffusion models offer a flexible, controllable approach to structured sequence generation, yet they still lag behind causal language models in expressive power. A key limitation lies in their reliance on the Markovian assumption, which restricts each step to condition only on the current state, leading to potential uncorrectable error accumulation.\nIn this paper, We introduce CaDDi, a discrete diffusion model that conditions on the entire generative trajectory, thereby lifting the Markov constraint and allowing the model to revisit and improve past states. By unifying sequential (causal) and temporal (diffusion) reasoning in a single non‑Markovian transformer, CaDDi also treats standard causal language models as a special case and permits the direct reuse of pretrained LLM weights with no architectural changes. Empirically, CaDDi outperforms state‑of‑the‑art discrete diffusion baselines on natural‑language benchmarks, substantially narrowing the remaining gap to large autoregressive transformers.'}",https://openreview.net{'value': '/pdf/e5aeb1f0ea65eb4eed5112fbeb936bfc00bc30be.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=qTUZJUXt0J,{'value': '3D-Prover: Diversity Driven Theorem Proving With Determinantal Point Processes'},Sean Lamont; Christian Walder; Amir Dezfouli; Paul Montague; Michael Norrish,~Sean_Lamont1; ~Christian_Walder1; ~Amir_Dezfouli2; ~Paul_Montague1; ~Michael_Norrish1,"{'value': ['theorem proving', 'proof search', 'diversity', 'representation learning']}","{'value': 'A key challenge in automated formal reasoning is the intractable search space, which grows exponentially with the depth of the proof. This branching is caused by the large number of candidate proof tactics which can be applied to a given goal. Nonetheless, many of these tactics are semantically similar or lead to an execution error, wasting valuable resources in both cases. We address the problem of effectively pruning this search, using only synthetic data generated from previous proof attempts. We first demonstrate that it is possible to generate semantically aware tactic representations which capture the effect on the proving environment, likelihood of success, and execution time. We then propose a novel filtering mechanism which leverages these representations to select semantically diverse and high quality tactics, using Determinantal Point Processes. Our approach, 3D-Prover, is designed to be general, and to augment any underlying tactic generator. We demonstrate the effectiveness of 3D-Prover on the miniF2F and LeanDojo benchmarks by augmenting popular open source proving LLMs. We show that our approach leads to an increase in the overall proof rate, as well as a significant improvement in the tactic success\n rate, execution time and diversity. We make our code available at https://github.com/sean-lamont/3D-Prover.'}",https://openreview.net{'value': '/pdf/bde5df5b7d335e39bffb3a70e0854df06f859e3b.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=qS3WgmGs9s,{'value': 'SketchMind:  A Multi-Agent Cognitive Framework for Assessing Student-Drawn Scientific Sketches'},Ehsan Latif; Zirak Khan; Xiaoming Zhai,~Ehsan_Latif1; ~Zirak_Khan1; ~Xiaoming_Zhai1,"{'value': ['Educational AI', 'Multimodal Learning', 'Scientific Reasoning', 'Cognitive Modeling', 'Sketch-Based Assessment']}","{'value': ""Scientific sketches (e.g., models) offer a powerful lens into students' conceptual understanding, yet AI-powered automated assessment of such free-form, visually diverse artifacts remains a critical challenge. Existing solutions often treat sketch evaluation as either an image classification task or monolithic vision-language models, which lack interpretability, pedagogical alignment, and adaptability across cognitive levels. To address these limitations, we present SketchMind, a cognitively grounded, multi-agent framework for evaluating and improving student-drawn scientific sketches. SketchMind introduces Sketch Reasoning Graphs (SRGs), semantic graph representations that embed domain concepts and Bloom's taxonomy-based cognitive labels. The system comprises modular agents responsible for rubric parsing, sketch perception, cognitive alignment, and iterative feedback with sketch modification, enabling personalized and transparent evaluation. We evaluate SketchMind on a curated dataset of 3,575 student-generated sketches across six science assessment items with different highest order of Bloom's level that require students to draw models to explain phenomena. Compared to baseline GPT-4o performance without SRG (average accuracy: 55.6%), the model with SRG integration achieves 77.1% average accuracy (+21.4% average absolute gain). We also demonstrate that multi-agent orchestration with SRG enhances SketchMind performance, for example, SketchMind with GPT-4.1 gains an average 8.9% increase in sketch prediction accuracy, outperforming single-agent pipelines across all items. Human evaluators rated the feedback and co-created sketches generated by SketchMind with GPT-4.1, which achieved an average of 4.1 out of 5, significantly higher than those of baseline models (e.g., 2.3 for GPT-4o). Experts noted the system’s potential to meaningfully support conceptual growth through guided revision. Our code and (pending approval) dataset will be released to support reproducibility and future research in AI-driven education.""}",https://openreview.net{'value': '/pdf/1f29ebbf550ce3d0ac8e2654e8faf2819c05fa9b.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=qO7j8ymv5I,{'value': 'SSIMBaD: Sigma Scaling with SSIM-Guided Balanced Diffusion for AnimeFace Colorization'},Junpyo Seo; HanbinKoo; Jieun Yook; Byung-Ro Moon,~Junpyo_Seo3; ~HanbinKoo1; ~Jieun_Yook1; ~Byung-Ro_Moon1,"{'value': ['Diffusion Models', 'Noise Scheduling', 'Perceptual Consistency', 'Reference-guided Generation', 'Conditional Diffusion Models', 'Generative Modeling', 'Sketch-to-Image Translation', 'Structural Similarity Index']}","{'value': 'We propose a novel diffusion-based framework for automatic colorization of Anime-style facial sketches, which preserves the structural fidelity of the input sketch while effectively transferring stylistic attributes from a reference image. Our approach builds upon recent continuous-time diffusion models, but departs from traditional methods that rely on predefined noise schedules, which often fail to maintain perceptual consistency across the generative trajectory. To address this, we introduce SSIMBaD (Sigma Scaling with SSIM-Guided Balanced Diffusion), a sigma-space transformation that ensures linear alignment of perceptual degradation, as measured by structural similarity. This perceptual scaling enforces uniform visual difficulty across timesteps, enabling more balanced and faithful reconstructions. On a large-scale Anime face dataset, SSIMBaD attains state-of-the-art structural fidelity and strong perceptual quality, with robust generalization to diverse styles and structural variations.'}",https://openreview.net{'value': '/pdf/3b274a2687fc67042e1018be94fd3d96789d00b4.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=qI95wZZCWh,{'value': 'Think or Not? Selective Reasoning via Reinforcement Learning for Vision-Language Models'},Jiaqi WANG; Kevin Qinghong Lin; James Cheng; Mike Zheng Shou,~Jiaqi_WANG11; ~Kevin_Qinghong_Lin1; ~James_Cheng2; ~Mike_Zheng_Shou1,"{'value': ['Vision-Language Models', 'Reinforcement Learning']}","{'value': 'Reinforcement Learning (RL) has proven to be an effective post-training strategy for enhancing reasoning in vision–language models (VLMs). Group Relative Policy Optimization (GRPO) is a recent prominent method that encourages models to generate complete reasoning traces before answering, leading to increased token usage and computational cost. Inspired by the human-like thinking process—where people skip reasoning for easy questions but think carefully when needed—we explore how to enable VLMs to first decide *when reasoning is necessary*.\nTo realize this, we propose \\ours, a two-stage training strategy:\n**(i)** a supervised fine-tuning (SFT) stage with a simple yet effective “**thought dropout**” operation, where reasoning traces are randomly replaced with empty thoughts. This introduces a think-or-not format that serves as a cold start for selective reasoning;  **(ii)** a GRPO stage that enables the model to freely explore when to think or not, while maximizing task-aware outcome rewards.\nExperimental results show that \\ours can *reduce the completion length by up to **90%** compared to vanilla GRPO, without sacrificing performance or even improving it*. Further evaluations across LLM (GSM8K), VLM (CLEVR, Super-CLEVR, GeoQA), and Agentic (AITZ) tasks—covering a range of reasoning difficulties under both 3B and 7B models—consistently reveal that the \\textit{model progressively learns to bypass unnecessary reasoning steps as training advances}.\nThese findings shed light on the path toward human-like reasoning patterns in RL approaches.\nOur code is available at https://github.com/kokolerk/TON.'}",https://openreview.net{'value': '/pdf/62bc8f6585ecc381363cf32ea8c833c4ef08d00e.pdf'},{'abstract_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=qEfgajdKea,{'value': 'Efficient Preference-Based Reinforcement Learning: Randomized Exploration meets Experimental Design'},Andreas Schlaginhaufen; Reda Ouhamma; Maryam Kamgarpour,~Andreas_Schlaginhaufen1; ~Reda_Ouhamma2; ~Maryam_Kamgarpour1,"{'value': ['RLHF', 'Preference learning', 'RL', 'Optimal design']}","{'value': 'We study reinforcement learning from human feedback in general Markov decision processes, where agents learn from trajectory-level preference comparisons. A central challenge in this setting is to design algorithms that select informative preference queries to identify the underlying reward while ensuring theoretical guarantees. We propose a meta-algorithm based on randomized exploration, which avoids the computational challenges associated with optimistic approaches and remains tractable. We establish both regret and last-iterate guarantees under mild reinforcement learning oracle assumptions. To improve query complexity, we introduce and analyze an improved algorithm that collects batches of trajectory pairs and applies optimal experimental design to select informative comparison queries. The batch structure also enables parallelization of preference queries, which is relevant in practical deployment as feedback can be gathered concurrently. Empirical evaluation confirms that the proposed method is competitive with reward-based reinforcement learning while requiring a small number of preference queries.'}",https://openreview.net{'value': '/pdf/496e4b94b22e33aa8ed0badc8d9f6405e55b4913.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=qE3knKF1rz,{'value': 'PANDA: Towards Generalist Video Anomaly Detection via Agentic AI Engineer'},Zhiwei Yang; Chen Gao; Mike Zheng Shou,~Zhiwei_Yang3; ~Chen_Gao4; ~Mike_Zheng_Shou1,"{'value': ['Video Anomaly  Detection', 'AI Agent', 'Agentic AI Engineer', 'Multimodal Large Language Model']}","{'value': 'Video anomaly detection (VAD) is a critical yet challenging task due to the complex and diverse nature of real-world scenarios. Previous methods typically rely on domain-specific training data and manual adjustments when applying to new scenarios and unseen anomaly types, suffering from high labor costs and limited generalization. Therefore, we aim to achieve generalist VAD, \\ie, automatically handle any scene and any anomaly types without training data or human involvement. In this work, we propose PANDA, an agentic AI engineer based on MLLMs. Specifically, we achieve PANDA by comprehensively devising four key capabilities: (1) self-adaptive scene-aware strategy planning, (2) goal-driven heuristic reasoning, (3) tool-augmented self-reflection, and (4) self-improving chain-of-memory. Concretely, we develop a self-adaptive scene-aware RAG mechanism, enabling PANDA to retrieve anomaly-specific knowledge for anomaly detection strategy planning. Next, we introduce a latent anomaly-guided heuristic prompt strategy to enhance reasoning precision. Furthermore, PANDA employs a progressive reflection mechanism alongside a suite of context-aware tools to iteratively refine decision-making in complex scenarios. Finally, a chain-of-memory mechanism enables PANDA to leverage historical experiences for continual performance improvement. Extensive experiments demonstrate that PANDA achieves state-of-the-art performance in multi-scenario, open-set, and complex scenario settings without training and manual involvement, validating its generalizable and robust anomaly detection capability. Code is released at https://github.com/showlab/PANDA.'}",https://openreview.net{'value': '/pdf/467380f59815c312492797fd471737efc6228947.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=qB1UKvjO0N,{'value': 'Towards Predicting Any Human Trajectory In Context'},Ryo Fujii; Hideo Saito; Ryo Hachiuma,~Ryo_Fujii2; ~Hideo_Saito2; ~Ryo_Hachiuma1,"{'value': ['In-Context Learning', 'pedestrian trajectory forecasting', 'trajectory prediction']}","{'value': 'Predicting accurate future trajectories of pedestrians is essential for autonomous systems but remains a challenging task due to the need for adaptability in different environments and domains. A common approach involves collecting scenario-specific data and performing fine-tuning via backpropagation. However, the need to fine-tune for each new scenario is often impractical for deployment on edge devices. To address this challenge, we introduce TrajICL, an In-Context Learning (ICL) framework for pedestrian trajectory prediction that enables adaptation without fine-tuning on the scenario-specific data at inference time without requiring weight updates. We propose a spatio-temporal similarity-based example selection (STES) method that selects relevant examples from previously observed trajectories within the same scene by identifying similar motion patterns at corresponding locations. To further refine this selection, we introduce prediction-guided example selection (PG-ES), which selects examples based on both the past trajectory and the predicted future trajectory, rather than relying solely on the past trajectory. This approach allows the model to account for long-term dynamics when selecting examples. Finally, instead of relying on small real-world datasets with limited scenario diversity, we train our model on a large-scale synthetic dataset to enhance its prediction ability by leveraging in-context examples. Extensive experiments demonstrate that TrajICL achieves remarkable adaptation across both in-domain and cross-domain scenarios, outperforming even fine-tuned approaches across multiple public benchmarks.'}",https://openreview.net{'value': '/pdf/da08cd5bb2b08b484195bc720c3b833a7fd3bab6.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=q8oLLyA34Q,{'value': 'Pareto Optimal Risk-Agnostic Distributional Bandits with Heavy-Tail Rewards'},Kyungjae Lee; Dohyeong Kim; Taehyun Cho; Chaeyeon Kim; Yunkyung Ko; Seungyub Han; Seokhun Ju; Dohyeok Lee; Sungbin Lim,~Kyungjae_Lee1; ~Dohyeong_Kim1; ~Taehyun_Cho1; ~Chaeyeon_Kim2; ~Yunkyung_Ko1; ~Seungyub_Han1; ~Seokhun_Ju1; ~Dohyeok_Lee1; ~Sungbin_Lim1,"{'value': ['Multi-Objective Bandits', 'Bandits with Heavy-Tail Rewards', 'Robust Distribution Estimation']}","{'value': 'This paper addresses the problem of multi-risk measure agnostic multi-armed bandits in heavy-tailed reward settings. \nWe propose a framework that leverages novel deviation inequalities for the $1$-Wasserstein distance to construct confidence intervals for Lipschitz risk measures. \nThe distributional LCB (DistLCB) algorithm is introduced, which achieves asymptotic optimality by deriving the first lower bounds for risk measure aware bandits with explicit sub-optimality gap dependencies.\nThe DistLCB is further extended to multi-risk objectives, which enables Pareto-optimal solutions that consider multiple aspects of reward distributions.\nAdditionally, we provide a regret analysis that includes both gap-dependent and gap-independent bounds for multi-risk settings. \nExperiments validate the effectiveness of the proposed methods in synthetic and real-world applications.'}",https://openreview.net{'value': '/pdf/a5ed9aea7a84df335eb3f4b222712e2168814909.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=peYBx7AiKw,{'value': 'Learning to Route: Per-Sample Adaptive Routing for Multimodal Multitask Prediction'},Marzieh Ajirak; Oded Bein; Ellen Rose Bowen; Dora Kanellopoulos; Avital Falk; FAITH M. GUNNING; Nili Solomonov; Logan Grosenick,~Marzieh_Ajirak1; ~Oded_Bein1; ~Ellen_Rose_Bowen1; ~Dora_Kanellopoulos1; ~Avital_Falk1; ~FAITH_M._GUNNING1; ~Nili_Solomonov1; ~Logan_Grosenick1,"{'value': ['multimodal learning', 'multitask learning', 'adaptive routing', 'per-sample adaptation', 'heterogeneous data', 'clinical applications', 'routing networks']}","{'value': 'We propose a unified framework for adaptive routing in multitask, multimodal prediction settings where data heterogeneity and task interactions vary across samples. We introduce a routing-based architecture that dynamically selects modality processing pathways and task-sharing strategies on a per-sample basis. Our model defines multiple modality paths, including raw and fused representations of text and numeric features, and learns to route each input through the most informative modality-task expert combination. Task-specific predictions are produced by shared or independent heads depending on the routing decision, and the entire system is trained end-to-end. We evaluate the model on both synthetic data and real-world psychotherapy notes, predicting depression and anxiety outcomes. Our experiments show that our method consistently outperforms fixed multitask or single-task baselines, and that the learned routing policy provides interpretable insights into modality relevance and task structure. This addresses critical challenges in personalized healthcare by providing per-subject adaptive information processing that accounts for data and task correlation heterogeneity.'}",https://openreview.net{'value': '/pdf/f74cf9d8f7bf25a117974c799282f19cd4a42a5a.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=pdc0yEoOj6,{'value': 'Leveraging robust optimization for llm alignment under distribution shifts'},Mingye Zhu; Yi Liu; Zheren Fu; Yongdong Zhang; Zhendong Mao,~Mingye_Zhu1; ~Yi_Liu14; ~Zheren_Fu1; ~Yongdong_Zhang2; ~Zhendong_Mao1,"{'value': ['preference alignment', 'distribution shifts', 'robust optimization']}","{'value': 'Preference alignment methods are increasingly critical for steering large language models (LLMs) to generate outputs consistent with human values. While recent approaches often rely on synthetic data generated by LLMs for scalability and cost-efficiency reasons, this reliance can introduce distributional shifts that undermine the nuanced representation of human preferences needed for desirable outputs. In this paper, we propose a novel distribution-aware optimization framework that improves preference alignment despite such shifts. Our approach first leverages well-learned classifiers to assign a calibration value to each training sample, quantifying its alignment with the target human-preferred distribution. These values are then incorporated into a robust optimization objective that minimizes the worst-case loss over regions of the data space most relevant to human preferences. By explicitly focusing optimization on the target distribution, our approach mitigates the impact of distributional mismatch and improves the generation of responses that better reflect intended values.'}",https://openreview.net{'value': '/pdf/df148ea36b63ff72a94648b59eb6a1e53caf5989.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=pcwI5cNFJK,{'value': 'What Does It Take to Build a Performant Selective Classifier?'},Stephan Rabanser; Nicolas Papernot,~Stephan_Rabanser1; ~Nicolas_Papernot1,"{'value': ['selective prediction', 'selective classification', 'calibration', 'ranking', 'abstention', 'rejection', 'uncertainty quantification']}","{'value': 'Selective classifiers improve model reliability by abstaining on inputs the model deems uncertain. However, few practical approaches achieve the gold-standard performance of a perfect-ordering oracle that accepts examples exactly in order of correctness. Our work formalizes this shortfall as the selective-classification gap and present the first finite-sample decomposition of this gap to five distinct sources of looseness: Bayes noise, approximation error, ranking error, statistical noise, and implementation- or shift-induced slack. Our analysis reveals that monotone post-hoc calibration—often believed to strengthen selective classifiers—has limited impact on closing this gap, since it rarely alters the model’s underlying score ranking. Bridging the gap therefore requires scoring mechanisms that can effectively reorder predictions rather than merely rescale them. We validate our decomposition on synthetic two-moons data and on real-world vision and language benchmarks, isolating each error component through controlled experiments. Our results show that (i) Bayes noise and limited model capacity can account for substantial gaps, (ii) only non-monotone or feature-aware calibrators consistently reduce the ranking term, and (iii) distribution shift introduces a separate slack that demands distributionally robust training. Together, our decomposition yields a quantitative error budget as well as actionable design guidelines that practitioners can use to build selective classifiers which approximate ideal oracle behavior more closely.'}",https://openreview.net{'value': '/pdf/e1f21826f3ce8febdab12afb9fb421b56f175cf0.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=pY65QWWFlm,{'value': 'Lessons Learned: A Multi-Agent Framework for Code LLMs to Learn and Improve'},Yuanzhe Liu; Ryan Deng; Tim Kaler; Xuhao Chen; Charles Leiserson; Yao Ma; Jie Chen,~Yuanzhe_Liu1; ~Ryan_Deng1; ~Tim_Kaler1; ~Xuhao_Chen1; ~Charles_Leiserson1; ~Yao_Ma3; ~Jie_Chen1,"{'value': ['Multi Agent', 'Large Language Model', 'Code Optimization']}","{'value': ""Recent studies show that LLMs possess different skills and specialize in different tasks. In fact, we observe that their varied performance occur in several levels of granularity. For example, in the code optimization task, code LLMs excel at different optimization categories and no one dominates others. This observation prompts the question of how one leverages multiple LLM agents to solve a coding problem without knowing their complementary strengths a priori. We argue that a team of agents can learn from each other's successes and failures so as to improve their own performance. Thus, a lesson is the knowledge produced by an agent and passed on to other agents in the collective solution process. We propose a lesson-based collaboration framework, design the lesson solicitation--banking--selection mechanism, and demonstrate that a team of small LLMs with lessons learned can outperform a much larger LLM and other multi-LLM collaboration methods.""}",https://openreview.net{'value': '/pdf/11bc550a62e76a702248f346f36018dce79624fb.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=pRYGjhirkY,{'value': 'TrajMamba: An Efficient and Semantic-rich Vehicle Trajectory Pre-training Model'},Yichen Liu; Yan Lin; Shengnan Guo; Zeyu Zhou; Youfang Lin; Huaiyu Wan,~Yichen_Liu7; ~Yan_Lin1; ~Shengnan_Guo1; ~Zeyu_Zhou3; ~Youfang_Lin1; ~Huaiyu_Wan1,"{'value': ['Trajectory Representation Learning', 'Spatio-Temporal Data Mining', 'Self-supervised']}","{'value': 'Vehicle GPS trajectories record how vehicles move over time, storing valuable travel semantics, including movement patterns and travel purposes. Learning travel semantics effectively and efficiently is crucial for real-world applications of trajectory data, which is hindered by two major challenges. First, travel purposes are tied to the functions of the roads and points-of-interest (POIs) involved in a trip. Such information is encoded in textual addresses and descriptions and introduces heavy computational burden to modeling. Second, real-world trajectories often contain redundant points, which harm both computational efficiency and trajectory embedding quality. To address these challenges, we propose TrajMamba, a novel approach for efficient and semantically rich vehicle trajectory learning. TrajMamba introduces a Traj-Mamba Encoder that captures movement patterns by jointly modeling both GPS and road perspectives of trajectories, enabling robust representations of continuous travel behaviors. It also incorporates a Travel Purpose-aware Pre-training procedure to integrate travel purposes into the learned embeddings without introducing extra overhead to embedding calculation. To reduce redundancy in trajectories, TrajMamba features a Knowledge Distillation Pre-training scheme to identify key trajectory points through a learnable mask generator and obtain effective compressed trajectory embeddings. Extensive experiments on two real-world datasets and three downstream tasks show that TrajMamba outperforms state-of-the-art baselines in both efficiency and accuracy.'}",https://openreview.net{'value': '/pdf/c2a6761d658ee3b6fd146e2dfa65615af526eaaf.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=pIZxEOZCId,{'value': 'TabDPT: Scaling Tabular Foundation Models on Real Data'},Junwei Ma; Valentin Thomas; Rasa Hosseinzadeh; Alex Labach; Jesse C. Cresswell; Keyvan Golestan; Guangwei Yu; Anthony L. Caterini; Maksims Volkovs,~Junwei_Ma1; ~Valentin_Thomas1; ~Rasa_Hosseinzadeh2; ~Alex_Labach1; ~Jesse_C._Cresswell1; ~Keyvan_Golestan1; ~Guangwei_Yu1; ~Anthony_L._Caterini1; ~Maksims_Volkovs3,"{'value': ['Tabular Foundation Models', 'In-Context Learning', 'Self Supervised Learning']}","{'value': 'Tabular data is one of the most ubiquitous sources of information worldwide, spanning a wide variety of domains. This inherent heterogeneity has slowed the development of Tabular Foundation Models (TFMs) capable of fast generalization to unseen datasets. In-Context Learning (ICL) has recently emerged as a promising solution for TFMs, enabling dynamic adaptation to new tasks without additional tuning. While many studies have attempted to re-purpose large language models for tabular ICL, they have had limited success, so recent works have focused on developing tabular-specific foundation models. In this work, we propose an approach to combine ICL-based retrieval with self supervised learning to train tabular foundation models. We also investigate the utility of real vs. synthetic data for model pre-training, and show that real data can contain useful signal not easily captured in synthetic training. Specifically, we show that incorporating real data during the pre-training phase can lead to significantly faster training and better downstream generalization to unseen data. Our resulting model, **TabDPT**, achieves strong performance on both regression (CTR23) and classification (CC18) benchmarks. Importantly, we also demonstrate that with our pre-training procedure, scaling both model and data size leads to consistent performance improvements that follow power laws. This echoes scaling laws in LLMs and other foundation models, and suggests that large-scale TFMs can be achievable.\nWe open-source our full pipeline: inference code including trained model weights can be found [here](https://github.com/layer6ai-labs/TabDPT-inference), and the training code to reproduce experiments can be found [here](https://github.com/layer6ai-labs/TabDPT-training).'}",https://openreview.net{'value': '/pdf/b8dc320a71d818902507edde5effab326d6726f0.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=pFL7RThdFN,{'value': 'Network two-sample test for block models'},Chung Kyong Nguen; Arash A. Amini; OSCAR HERNAN MADRID PADILLA,~Chung_Kyong_Nguen1; ~Arash_A._Amini2; ~OSCAR_HERNAN_MADRID_PADILLA2,"{'value': ['Stochastic block model', 'SBM', 'two-sample test', 'spectral graph matching']}","{'value': 'We consider the two-sample testing problem for networks, where the goal is to determine whether two sets of networks originated from the same stochastic model. Assuming no vertex correspondence and allowing for different numbers of nodes, we address a fundamental network testing problem that goes beyond simple adjacency matrix comparisons. We adopt the stochastic block model (SBM) for network distributions, due to their interpretability and the potential to approximate more general models. The lack of meaningful node labels and vertex correspondence translate to a graph matching challenge when developing a test for SBMs.\nWe introduce an efficient algorithm to match estimated network parameters, allowing us to properly combine and contrast information within and across samples, leading to a powerful test. We show that the matching algorithm, and the overall test are consistent, under mild conditions on the sparsity of the networks and the sample sizes, and derive a chi-squared asymptotic null distribution for the test.\nThrough a mixture of theoretical insights and empirical validations, including experiments with both synthetic and real-world data, this study advances robust statistical inference for complex network data.'}",https://openreview.net{'value': '/pdf/6230e7907f001975adf613431b83e9cdff6840d7.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=om2CpclG4y,{'value': 'Compositional Monte Carlo Tree Diffusion for Extendable Planning'},Jaesik Yoon; Hyeonseo Cho; Sungjin Ahn,~Jaesik_Yoon1; ~Hyeonseo_Cho1; ~Sungjin_Ahn1,"{'value': ['Diffusion', 'MCTS', 'Long-term Planning', 'Offline RL', 'Goal-conditioned RL', 'Stitching sub-plans']}","{'value': 'Monte Carlo Tree Diffusion (MCTD) integrates diffusion models with structured tree search to enable effective trajectory exploration through stepwise reasoning. However, MCTD remains fundamentally limited by training trajectory lengths. While periodic replanning allows plan concatenation for longer plan generation, the planning process remains locally confined, as MCTD searches within individual trajectories without access to global context. We propose Compositional Monte Carlo Tree Diffusion (C-MCTD), a framework that elevates planning from individual trajectory optimization to reasoning over complete plan compositions. C-MCTD introduces three complementary components: (1) Online Composer, which performs globally-aware planning by searching across entire plan compositions; (2) Distributed Composer, which reduces search complexity through parallel exploration from multiple starting points; and (3) Preplan Composer, which accelerates inference by leveraging cached plan graphs.'}",https://openreview.net{'value': '/pdf/21e821aabb5e4ced741e605743d33fca8afcb21b.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=oeZZusZheP,{'value': 'AutoToM: Scaling Model-based Mental Inference via Automated Agent Modeling'},Zhining Zhang; Chuanyang Jin; Mung Yao Jia; Shunchi Zhang; Tianmin Shu,~Zhining_Zhang1; ~Chuanyang_Jin2; ~Mung_Yao_Jia1; ~Shunchi_Zhang1; ~Tianmin_Shu1,"{'value': ['Theory of Mind', 'Agent Modeling', 'Bayesian Inverse Planning', 'Large Language Models', 'Cognitive Modeling']}","{'value': ""Theory of Mind (ToM), the ability to understand people's minds based on their behavior, is key to developing socially intelligent agents. Current approaches to ToM reasoning either rely on prompting Large Language Models (LLMs), which are prone to systematic errors, or use handcrafted, rigid agent models for model-based inference, which are more robust but fail to generalize across domains. In this work, we introduce *AutoToM*, an automated agent modeling method for scalable, robust, and interpretable mental inference. Given a ToM problem, *AutoToM* first proposes an initial agent model and then performs automated Bayesian inverse planning based on this model, leveraging an LLM backend. Guided by inference uncertainty, it iteratively refines the model by introducing additional mental variables and/or incorporating more timesteps in the context. Across five diverse benchmarks, *AutoToM* outperforms existing ToM methods and even large reasoning models. Additionally, we show that *AutoToM* can produce human‐like confidence estimates and enable online mental inference for embodied decision-making.""}",https://openreview.net{'value': '/pdf/97d508cdb6040e0326e1f3e82a7473020de10424.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=odWYytUjl1,{'value': 'Counterfactual reasoning: an analysis of in-context emergence'},Moritz Miller; Bernhard Schölkopf; Siyuan Guo,~Moritz_Miller1; ~Bernhard_Schölkopf1; ~Siyuan_Guo1,{'value': ['In-context learning; transformers; reasoning; causality']},"{'value': 'Large-scale neural language models exhibit remarkable performance in in-context learning: the ability to learn and reason about the input context on the fly. This work studies in-context counterfactual reasoning in language models, that is, the ability to predict consequences of a hypothetical scenario. We focus on a well-defined, synthetic linear regression task that requires noise abduction. Accurate prediction is based on (1) inferring an unobserved latent concept and (2) copying contextual noise from factual observations. We show that language models are capable of counterfactual reasoning. Further, we enhance existing identifiability results and reduce counterfactual reasoning for a broad class of functions to a transformation on in-context observations. In Transformers, we find that self-attention, model depth and pre-training data diversity drive performance. Moreover, we provide mechanistic evidence that the latent concept is linearly represented in the residual stream and we introduce designated *noise abduction heads* central to performing counterfactual reasoning. Lastly, our findings extend to counterfactual reasoning under SDE dynamics and reflect that Transformers can perform noise abduction on sequential data, providing preliminary evidence on the potential for counterfactual story generation. Our code is available under *https://github.com/mrtzmllr/iccr*.'}",https://openreview.net{'value': '/pdf/94255f9f374c1c8987130333640df5f6b55fd57b.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=ocBuEUl6Yz,{'value': 'Extremely Simple Multimodal Outlier Synthesis for Out-of-Distribution Detection and Segmentation'},Moru Liu; Hao Dong; Jessica Ivy Kelly; Olga Fink; Mario Trapp,~Moru_Liu1; ~Hao_Dong4; ~Jessica_Ivy_Kelly1; ~Olga_Fink1; ~Mario_Trapp2,"{'value': ['Outlier Synthesis', 'Multimodal Learning', 'OOD Detection', 'OOD Segmentation']}","{'value': 'Out-of-distribution (OOD) detection and segmentation are crucial for deploying machine learning models in safety-critical applications such as autonomous driving and robot-assisted surgery. While prior research has primarily focused on unimodal image data, real-world applications are inherently multimodal, requiring the integration of multiple modalities for improved OOD detection. A key challenge is the lack of supervision signals from unknown data, leading to overconfident predictions on OOD samples. To address this challenge, we propose Feature Mixing, an extremely simple and fast method for synthesizing multimodal outliers with theoretical support, which can be further optimized to help the model better distinguish between in-distribution (ID) and OOD data. Feature Mixing is modality-agnostic and applicable to various modality combinations. Additionally, we introduce CARLA-OOD, a new multimodal dataset for OOD segmentation, featuring synthetic OOD objects across diverse scenes and weather conditions. Extensive experiments on SemanticKITTI, nuScenes, CARLA-OOD datasets, and the MultiOOD benchmark demonstrate that Feature Mixing achieves state-of-the-art performance with a $10 \\times$ to $370 \\times$ speedup. Our source code and dataset are available at https://github.com/mona4399/FeatureMixing.'}",https://openreview.net{'value': '/pdf/9ea07381fafcc7924e43dcd1c46f127ec5c94318.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=oYIXUwmNig,{'value': 'Prediction-Powered Semi-Supervised Learning with Online Power Tuning'},Noa Shoham; Ron Dorfman; Shalev Shaer; Kfir Yehuda Levy; Yaniv Romano,~Noa_Shoham1; ~Ron_Dorfman2; ~Shalev_Shaer2; ~Kfir_Yehuda_Levy1; ~Yaniv_Romano1,"{'value': ['Semi-Supervised Learning', 'Pseudo-Labeling', 'Online Learning', 'Prediction-Powered Inference', 'Debiasing']}","{'value': 'Prediction-Powered Inference (PPI) is a recently proposed statistical inference technique for parameter estimation that leverages pseudo-labels on both labeled and unlabeled data to construct an unbiased, low-variance estimator.\nIn this work, we extend its core idea to semi-supervised learning (SSL) for model training, introducing a novel unbiased gradient estimator. \nThis extension addresses a key challenge in SSL: while unlabeled data can improve model performance, its benefit heavily depends on the quality of pseudo-labels. Inaccurate pseudo-labels can introduce bias, leading to suboptimal models.\nTo balance the contributions of labeled and pseudo-labeled data, we utilize an interpolation parameter and tune it on the fly, alongside the model parameters, using a one-dimensional online learning algorithm. \nWe verify the practical advantage of our approach through experiments on both synthetic and real datasets, demonstrating improved performance over classic SSL baselines and PPI methods that tune the interpolation parameter offline.'}",https://openreview.net{'value': '/pdf/f93159a2a35da8e51205a744744c5b9bfa1411cd.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=oY1Xnt83oJ,{'value': 'DRIFT: Dynamic Rule-Based Defense with Injection Isolation for Securing LLM Agents'},Hao Li; Xiaogeng Liu; CHIU Hung Chun; Dianqi Li; Ning Zhang; Chaowei Xiao,~Hao_Li21; ~Xiaogeng_Liu1; ~CHIU_Hung_Chun1; ~Dianqi_Li1; ~Ning_Zhang2; ~Chaowei_Xiao2,"{'value': ['Prompt Injection Attack', 'Defense', 'LLM Agent']}","{'value': ""Large Language Models (LLMs) are increasingly central to agentic systems due to their strong reasoning and planning capabilities. By interacting with external environments through predefined tools, these agents can carry out complex user tasks. Nonetheless, this interaction also introduces the risk of prompt injection attacks, where malicious inputs from external sources can mislead the agent’s behavior, potentially resulting in economic loss, privacy leakage, or system compromise.\nSystem-level defenses have recently shown promise by enforcing static or predefined policies, but they still face two key challenges: the ability to dynamically update security rules and the need for memory stream isolation. To address these challenges, we propose DRIFT, a Dynamic Rule-based Isolation Framework for Trustworthy agentic systems, which enforces both control- and data-level constraints.\nA Secure Planner first constructs a minimal function trajectory and a JSON-schema-style parameter checklist for each function node based on the user query. A Dynamic Validator then monitors deviations from the original plan, assessing whether changes comply with privilege limitations and the user's intent. Finally, an \\textit{Injection Isolator} detects and masks any instructions that may conflict with the user query from the memory stream to mitigate long-term risks.\nWe empirically validate the effectiveness of DRIFT on the AgentDojo and ASB benchmark, demonstrating its strong security performance while maintaining high utility across diverse models—showcasing both its robustness and adaptability. The code is released at https://github.com/SaFoLab-WISC/DRIFT.""}",https://openreview.net{'value': '/pdf/7e05f767d463d43be3b045378b14be5760ea2fc1.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=oRMfTkP6kC,{'value': 'MOBO-OSD: Batch Multi-Objective Bayesian Optimization via Orthogonal Search Directions'},Lam Ngo; Huong Ha; Jeffrey Chan; Hongyu Zhang,~Lam_Ngo1; ~Huong_Ha3; ~Jeffrey_Chan1; ~Hongyu_Zhang1,"{'value': ['Bayesian optimization', 'multi-objective optimization', 'Gaussian process']}","{'value': 'Bayesian Optimization (BO) is a powerful tool for optimizing expensive black-box objective functions. While extensive research has been conducted on the single-objective optimization problem, the multi-objective optimization problem remains challenging. In this paper, we propose MOBO-OSD, a multi-objective Bayesian Optimization algorithm designed to generate a diverse set of Pareto optimal solutions by solving multiple constrained optimization problems, referred to as MOBO-OSD subproblems, along orthogonal search directions (OSDs) defined with respect to an approximated convex hull of individual objective minima. By employing a well-distributed set of OSDs, MOBO-OSD ensures broad coverage of the objective space, enhancing both solution diversity and hypervolume performance. To further improve the density of the set of the Pareto optimal candidate solutions without requiring an excessive number of subproblems, we leverage a Pareto Front Estimation technique to generate additional solutions in the neighborhood of existing solutions. Additionally, MOBO-OSD supports batch optimization, enabling parallel function evaluations to accelerate the optimization process when resources are available. Through extensive experiments and analysis on a variety of synthetic and real-world benchmark functions with two to six objectives, we demonstrate that MOBO-OSD consistently outperform the state-of-the-art algorithms.'}",https://openreview.net{'value': '/pdf/f11d0c6cd055a90079ba632e01bd65e72866f416.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=oQYq9L1NVT,{'value': 'Deep Video Discovery: Agentic Search with Tool Use for Long-form Video Understanding'},Xiaoyi Zhang; Zhaoyang Jia; Zongyu Guo; Jiahao Li; Bin Li; Houqiang Li; Yan Lu,~Xiaoyi_Zhang3; ~Zhaoyang_Jia1; ~Zongyu_Guo1; ~Jiahao_Li3; ~Bin_Li10; ~Houqiang_Li1; ~Yan_Lu7,"{'value': ['agent', 'computer vision', 'long video understanding']}","{'value': 'Long-form video understanding presents significant challenges due to extensive temporal-spatial complexity and the difficulty of question answering under such extended contexts. \nWhile Large Language Models (LLMs) have demonstrated considerable advancements in video analysis capabilities and long context handling, they continue to exhibit limitations when processing information-dense hour-long videos. \nTo overcome such limitations, we propose the $\\textbf{D}eep \\ \\textbf{V}ideo \\ \\textbf{D}iscovery \\ (\\textbf{DVD})$ agent to leverage an $\\textit{agentic search}$ strategy over segmented video clips. Different from previous video agents manually designing a rigid workflow, our approach emphasizes the autonomous nature of agents.\nBy providing a set of search-centric tools on multi-granular video database,\nour DVD agent leverages the advanced reasoning capability of LLM to plan on its current observation state, strategically selects tools to orchestrate adaptive workflow for different queries in light of the gathered information.\nWe perform comprehensive evaluation on multiple long video understanding benchmarks that demonstrates our advantage.\nOur DVD agent achieves state-of-the-art performance on the challenging LVBench dataset, reaching an accuracy of $\\textbf{74.2\\%}$, which substantially surpasses all prior works, and further improves to $\\textbf{76.0\\%}$ with transcripts.'}",https://openreview.net{'value': '/pdf/e088d8522092e965e16cd0d0f7a994ed5ea27435.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=oLGtPYdRzU,{'value': 'Attractive Metadata Attack: Inducing LLM Agents to Invoke Malicious Tools'},Kanghua Mo; Li Hu; Yucheng Long; Zhihao li,~Kanghua_Mo3; ~Li_Hu1; ~Yucheng_Long1; ~Zhihao_li20,"{'value': ['Attractive Metadata Attack', 'Tool Metadata Manipulation', 'LLM Agent Security']}","{'value': 'Large language model (LLM) agents have demonstrated remarkable capabilities in complex reasoning and decision-making by leveraging external tools. However, this tool-centric paradigm introduces a previously underexplored attack surface, where adversaries can manipulate tool metadata---such as names, descriptions, and parameter schemas---to influence agent behavior. We identify this as a new and stealthy threat surface that allows malicious tools to be preferentially selected by LLM agents, without requiring prompt injection or access to model internals. To demonstrate and exploit this vulnerability, we propose the Attractive Metadata Attack (AMA), a black-box in-context learning framework that generates highly attractive but syntactically and semantically valid tool metadata through iterative optimization. The proposed attack integrates seamlessly into standard tool ecosystems and requires no modification to the agent’s execution framework. \nExtensive experiments across ten realistic, simulated tool-use scenarios and a range of popular LLM agents demonstrate consistently high attack success rates (81\\%-95\\%) and significant privacy leakage, with negligible impact on primary task execution. Moreover, the attack remains effective even against prompt-level defenses, auditor-based detection, and structured tool-selection protocols such as the Model Context Protocol, revealing systemic vulnerabilities in current agent architectures.\nThese findings reveal that metadata manipulation constitutes a potent and stealthy attack surface. \nNotably, AMA is orthogonal to injection attacks and can be combined with them to achieve stronger attack efficacy, highlighting the need for execution-level defenses beyond prompt-level and auditor-based mechanisms.\nCode is available at \\url{https://github.com/SEAIC-M/AMA}.'}",https://openreview.net{'value': '/pdf/58fd047ac6ca0bee4f61d85fc98df7a5c5b55e31.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=oIpRvQkrH9,{'value': 'Neptune-X: Active X-to-Maritime Generation for Universal Maritime Object Detection'},Yu Guo; Shengfeng He; Yuxu Lu; Haonan An; Yihang Tao; Huilin Zhu; Jingxian Liu; Yuguang Fang,~Yu_Guo7; ~Shengfeng_He1; ~Yuxu_Lu1; ~Haonan_An1; ~Yihang_Tao1; ~Huilin_Zhu1; ~Jingxian_Liu2; ~Yuguang_Fang2,"{'value': ['Image Generation', 'Object Detection', 'Computer Vision']}","{'value': 'Maritime object detection is essential for navigation safety, surveillance, and autonomous operations, yet constrained by two key challenges: the scarcity of annotated maritime data and poor generalization across various maritime attributes (e.g., object category, viewpoint, location, and imaging environment). To address these challenges, we propose Neptune-X, a data-centric generative-selection framework that enhances training effectiveness by leveraging synthetic data generation with task-aware sample selection. From the generation perspective, we develop X-to-Maritime, a multi-modality-conditioned generative model that synthesizes diverse and realistic maritime scenes. A key component is the Bidirectional Object-Water Attention module, which captures boundary interactions between objects and their aquatic surroundings to improve visual fidelity. To further improve downstream tasking performance, we propose Attribute-correlated Active Sampling, which dynamically selects synthetic samples based on their task relevance. To support robust benchmarking, we construct the Maritime Generation Dataset, the first dataset tailored for generative maritime learning, encompassing a wide range of semantic conditions. Extensive experiments demonstrate that our approach sets a new benchmark in maritime scene synthesis, significantly improving detection accuracy, particularly in challenging and previously underrepresented settings. The code is available at https://github.com/gy65896/Neptune-X.'}",https://openreview.net{'value': '/pdf/f889110bdee12ecb7d80620038ffe4bbac443310.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=oBikm5Rshc,{'value': 'Learning the Wrong Lessons: Syntactic-Domain Spurious Correlations in Language Models'},Chantal Shaib; Vinith Menon Suriyakumar; Byron C Wallace; Marzyeh Ghassemi,~Chantal_Shaib1; ~Vinith_Menon_Suriyakumar1; ~Byron_C_Wallace1; ~Marzyeh_Ghassemi2,"{'value': ['templates', 'compositionality', 'language models']}","{'value': 'For an LLM to correctly respond to an instruction it must understand both the semantics and the domain (i.e., subject area) of a given task-instruction pair. However, syntax can also convey implicit information. Recent work shows that \\textit{syntactic templates}---frequent sequences of Part-of-Speech (PoS) tags---are prevalent in training data and often appear in model outputs. In this work we characterize syntactic templates, domain, and semantics in task-instruction pairs. We identify cases of spurious correlations between syntax and domain, where models learn to associate a domain with syntax during training; this can sometimes override prompt semantics. Using a synthetic training dataset, we find that the syntactic-domain correlation can lower performance (mean 0.51 +/- 0.06) on entity knowledge tasks in OLMo-2 models (1B-13B). We introduce an evaluation framework to detect this phenomenon in trained models, and show that it occurs on a subset of the FlanV2 dataset in open (OLMo-2-7B; Llama-4-Maverick),  and closed (GPT-4o) models. Finally, we present a case study on the implications for LLM security, showing that unintended syntactic-domain correlations can be used to bypass refusals in OLMo-2-7B Instruct and GPT-4o. Our findings highlight two needs: (1) to explicitly test for syntactic-domain correlations, and (2) to ensure \\textit{syntactic} diversity in training data, specifically within domains, to prevent such spurious correlations.'}",https://openreview.net{'value': '/pdf/a7a915ae7ebc0d2f9e2be3f23af7d08fbf3e7308.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=o8n5oNDsiq,{'value': 'MM-Agent: LLM as Agents for Real-world Mathematical Modeling Problem'},Fan Liu; Zhe-Rui Yang; Cancheng Liu; Tianrui SONG; Xiaofeng Gao; Hao Liu,~Fan_Liu5; ~Zhe-Rui_Yang1; ~Cancheng_Liu1; ~Tianrui_SONG1; ~Xiaofeng_Gao2; ~Hao_Liu17,"{'value': ['Mathematical Modeling Agent', 'LLM Agent', 'LLM']}","{'value': 'Mathematical modeling is a cornerstone of scientific discovery and engineering practice, enabling the translation of real-world problems into formal systems across domains such as physics, biology, and economics. Unlike mathematical reasoning, which assumes a predefined formulation, modeling requires open-ended problem analysis, abstraction, and principled formalization. While Large Language Models (LLMs) have shown strong reasoning capabilities, they fall short in rigorous model construction, limiting their utility in real-world problem-solving. To this end, we formalize the task of LLM-powered real-world mathematical modeling, where agents must analyze problems, construct domain-appropriate formulations, and generate complete end-to-end solutions.We introduce MM-Bench, a curated benchmark of 111 problems from the Mathematical Contest in Modeling (MCM/ICM), spanning the years 2000 to 2025 and across ten diverse domains such as physics, biology, and economics.  To tackle this task, we propose MM-Agent, an expert-inspired framework that decomposes mathematical modeling into four stages: open-ended problem analysis, structured model formulation, computational problem solving, and report generation.Experiments on MM-Bench show that MM-Agent significantly outperforms baseline agents, achieving an 11.88\\% improvement over human expert solutions while requiring only 15 minutes and \\$0.88 per task using GPT-4o. Furthermore, under official MCM/ICM protocols, MM-Agent assisted two undergraduate teams in winning the Finalist Award (\\textbf{top 2.0\\% among 27,456 teams}) in MCM/ICM 2025, demonstrating its practical effectiveness as a modeling copilot.'}",https://openreview.net{'value': '/pdf/e01a39be0de98c2f808394f7affa2bfb004c68a5.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=o3x3RV8XHd,{'value': 'Federated Multi-armed Bandits with Efficient Bit-Level Communications'},Haoran Zhang; Yang Xu; Xuchuang Wang; Hao-Xu Chen; Hao Qiu; Lin Yang; Yang Gao,~Haoran_Zhang21; ~Yang_Xu14; ~Xuchuang_Wang1; ~Hao-Xu_Chen1; ~Hao_Qiu2; ~Lin_Yang11; ~Yang_Gao3,"{'value': ['federated multi-armed bandit', 'communication-efficient algorithm']}","{'value': 'In this work, we study the federated multi-armed bandit (FMAB) problem, where a set of distributed agents collaboratively aim to minimize cumulative regret while interacting with a shared set of arms. Unlike traditional centralized bandit models, agents in FMAB settings are connected via a communication graph and cannot share data freely due to bandwidth limitations or privacy constraints. This raises a fundamental challenge: how to achieve optimal learning performance under stringent communication budgets.\nWe propose a novel communication-efficient algorithm that decouples the learning process into two phases: one for eliminating suboptimal arms through early and frequent communication of key decisions, and another for refining global estimates using buffered, quantized, and differentially transmitted statistics. By carefully balancing the communication frequency and precision of shared information, our algorithm achieves the optimal individual regret bound $O(N^{-1}\\log T)$ while significantly reducing the total number of communication rounds and transmitted bits.\nTheoretically, we derive tight upper bounds on both individual cumulative regret and group regret, and prove that our method asymptotically matches the lower bound of regret in federated settings. Experimental results on synthetic data validate the effectiveness of the proposed approach in various graph topologies and under heterogeneous feedback.'}",https://openreview.net{'value': '/pdf/5f96ef255b49c39617501b2036eab006a423be37.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=nw6Kx91J48,{'value': 'LuxDiT: Lighting Estimation with Video Diffusion Transformer'},Ruofan Liang; Kai He; Zan Gojcic; Igor Gilitschenski; Sanja Fidler; Nandita Vijaykumar; Zian Wang,~Ruofan_Liang1; ~Kai_He5; ~Zan_Gojcic1; ~Igor_Gilitschenski1; ~Sanja_Fidler1; ~Nandita_Vijaykumar1; ~Zian_Wang1,"{'value': ['Lighting estimation', 'Inverse rendering', 'Video diffusion models']}","{'value': 'Estimating scene lighting from a single image or video remains a longstanding challenge in computer vision and graphics. Learning-based approaches are constrained by the scarcity of ground-truth HDR environment maps, which are expensive to capture and limited in diversity. While recent generative models offer strong priors for image synthesis, lighting estimation remains difficult due to its reliance on indirect visual cues, the need to infer global (non-local) context, and the recovery of high-dynamic-range outputs. We propose LuxDiT, a novel data-driven approach that fine-tunes a video diffusion transformer to generate HDR environment maps conditioned on visual input. Trained on a large synthetic dataset with diverse lighting conditions, our model learns to infer illumination from indirect visual cues and generalizes effectively to real-world scenes. To improve semantic alignment between the input and the predicted environment map, we introduce a low-rank adaptation finetuning strategy using a collected dataset of HDR panoramas. Our method produces accurate lighting predictions with realistic angular high-frequency details, outperforming existing state-of-the-art techniques in both quantitative and qualitative evaluations.'}",https://openreview.net{'value': '/pdf/aa4a5d76653bbad409c6efa47480816a246217c3.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=nufqobhME7,{'value': 'Revealing Multimodal Causality with Large Language Models'},Jin Li; Shoujin Wang; Qi Zhang; Feng Liu; Tongliang Liu; Longbing Cao; Shui Yu; Fang Chen,~Jin_Li5; ~Shoujin_Wang1; ~Qi_Zhang25; ~Feng_Liu2; ~Tongliang_Liu1; ~Longbing_Cao1; ~Shui_Yu1; ~Fang_Chen3,"{'value': ['Multimodal Learning', 'Large Language Models', 'Causal Discovery']}","{'value': 'Uncovering cause-and-effect mechanisms from data is fundamental to scientific progress. While large language models (LLMs) show promise for enhancing causal discovery (CD) from unstructured data, their application to the increasingly prevalent multimodal setting remains a critical challenge. Even with the advent of multimodal LLMs (MLLMs), their efficacy in multimodal CD is hindered by two primary limitations: (1) difficulty in exploring intra- and inter-modal interactions for comprehensive causal variable identification; and (2) insufficiency to handle structural ambiguities with purely observational data. To address these challenges, we propose MLLM-CD, a novel framework for multimodal causal discovery from unstructured data. It consists of three key components: (1) a novel contrastive factor discovery module to identify genuine multimodal factors based on the interactions explored from contrastive sample pairs; (2) a statistical causal structure discovery module to infer causal relationships among discovered factors; and (3) an iterative multimodal counterfactual reasoning module to refine the discovery outcomes iteratively by incorporating the world knowledge and reasoning capabilities of MLLMs. Extensive experiments on both synthetic and real-world datasets demonstrate the effectiveness of the proposed MLLM-CD in revealing genuine factors and causal relationships among them from multimodal unstructured data. The implementation code and data are available at https://github.com/JinLi-i/MLLM-CD.'}",https://openreview.net{'value': '/pdf/6fd0ed368b98ef83e704c98c8326dd77b764dd02.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=noiiyIk3hh,{'value': 'Frame In-N-Out: Unbounded Controllable Image-to-Video Generation'},Boyang Wang; Xuweiyi Chen; Matheus Gadelha; Zezhou Cheng,~Boyang_Wang2; ~Xuweiyi_Chen1; ~Matheus_Gadelha1; ~Zezhou_Cheng1,"{'value': ['Video Generation', 'Image Generation', 'Diffusion Model']}","{'value': 'Controllability, temporal coherence, and detail synthesis remain the most critical challenges in video generation. In this paper, we focus on a commonly used yet underexplored cinematic technique known as Frame In and Frame Out. Specifically, starting from image-to-video generation, users can control the objects in the image to naturally leave the scene or provide breaking new identity references to enter the scene, guided by a user-specified motion trajectory. To support this task, we introduce a new dataset that is curated semi-automatically, an efficient identity-preserving motion-controllable video Diffusion Transformer architecture, and a comprehensive evaluation protocol targeting this task. Our evaluation shows that our proposed approach significantly outperforms existing baselines.'}",https://openreview.net{'value': '/pdf/eb2a3aef23e8688e6a85d816ec1c9369134a21cd.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=nlQRra0OLH,{'value': 'A Unified Solution to Video Fusion: From Multi-Frame Learning to Benchmarking'},Zixiang Zhao; Haowen Bai; Bingxin Ke; Yukun Cui; Lilun Deng; Yulun Zhang; Kai Zhang; Konrad Schindler,~Zixiang_Zhao1; ~Haowen_Bai1; ~Bingxin_Ke1; ~Yukun_Cui2; ~Lilun_Deng1; ~Yulun_Zhang1; ~Kai_Zhang8; ~Konrad_Schindler1,"{'value': ['image fusion', 'video fusion', 'low-level vision']}","{'value': 'The real world is dynamic, yet most image fusion methods process static frames independently, ignoring temporal correlations in videos and leading to flickering and temporal inconsistency. To address this, we propose Unified Video Fusion (UniVF), a novel and unified framework for video fusion that leverages multi-frame learning and optical flow-based feature warping for informative, temporally coherent video fusion. To support its development, we also introduce Video Fusion Benchmark (VF-Bench), the first comprehensive benchmark covering four video fusion tasks: multi-exposure, multi-focus, infrared-visible, and medical fusion. VF-Bench provides high-quality, well-aligned video pairs obtained through synthetic data generation and rigorous curation from existing datasets, with a unified evaluation protocol that jointly assesses the spatial quality and temporal consistency of video fusion. Extensive experiments show that UniVF achieves state-of-the-art results across all tasks on VF-Bench. Project page: [vfbench.github.io](https://vfbench.github.io).'}",https://openreview.net{'value': '/pdf/3be8a4552d3ed6bbb9450ff92e910b021cd42198.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=nfxTpNiSMH,{'value': 'SPAZER: Spatial-Semantic Progressive Reasoning Agent for Zero-shot 3D Visual Grounding'},Zhao Jin; Rong-Cheng Tu; Jingyi Liao; Wenhao Sun; Xiao Luo; Shunyu Liu; Dacheng Tao,~Zhao_Jin2; ~Rong-Cheng_Tu1; ~Jingyi_Liao1; ~Wenhao_Sun1; ~Xiao_Luo3; ~Shunyu_Liu1; ~Dacheng_Tao1,"{'value': ['3D Visual Grounding', 'Multi-modal Agent', 'Zero-shot']}","{'value': '3D Visual Grounding (3DVG) aims to localize target objects within a 3D scene based on natural language queries. To alleviate the reliance on costly 3D training data, recent studies have explored zero-shot 3DVG by leveraging the extensive knowledge and powerful reasoning capabilities of pre-trained LLMs and VLMs. However, existing paradigms tend to emphasize either spatial (3D-based) or semantic (2D-based) understanding, limiting their effectiveness in complex real-world applications. In this work, we introduce SPAZER — a VLM-driven agent that combines both modalities in a progressive reasoning framework. It first holistically analyzes the scene and produces a 3D rendering from the optimal  viewpoint. Based on this, anchor-guided candidate screening is conducted to perform a coarse-level localization of potential objects. Furthermore, leveraging retrieved relevant 2D camera images, 3D-2D joint decision-making is efficiently performed to determine the best-matching object. By bridging spatial and semantic reasoning neural streams, SPAZER achieves robust zero-shot grounding without training on 3D-labeled data. Extensive experiments on ScanRefer and Nr3D benchmarks demonstrate that SPAZER significantly outperforms previous state-of-the-art zero-shot methods, achieving notable gains of $\\mathbf{9.0\\}$% and $\\mathbf{10.9\\}$% in accuracy.'}",https://openreview.net{'value': '/pdf/b0522ba8737e40b1714bc1adc199fcfa47a3dd5d.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=nfhmjdZUbQ,{'value': 'Adaptive Prediction-Powered AutoEval with Reliability and Efficiency Guarantees'},Sangwoo Park; Matteo Zecchin; Osvaldo Simeone,~Sangwoo_Park1; ~Matteo_Zecchin1; ~Osvaldo_Simeone2,"{'value': ['AutoEval', 'LLM judge', 'game-theoretic statistics', 'hypothesis testing', 'semi-supervised inference', 'prediction-powered inference']}","{'value': 'Selecting  artificial intelligence (AI) models, such as large language models (LLMs), from multiple candidates requires accurate performance estimation. This is ideally achieved through empirical evaluations involving abundant real-world data. However, such evaluations are costly and impractical at scale. To address this challenge, autoevaluation methods leverage synthetic data produced by automated evaluators, such as LLMs-as-judges, reducing variance but potentially introducing bias. Recent approaches have employed semi-supervised prediction-powered inference ($\\texttt{PPI}$) to correct for the bias of autoevaluators. However, the use of autoevaluators may lead in practice to a degradation in sample efficiency compared to conventional  methods using only real-world data. In this paper, we propose $\\texttt{R-AutoEval+}$, a novel framework that provides finite-sample reliability guarantees on the model evaluation, while also ensuring an enhanced (or at least no worse) sample efficiency  compared to conventional methods. The key innovation of $\\texttt{R-AutoEval+}$ is an  adaptive construction of the model evaluation variable, which dynamically tunes its reliance on synthetic data, reverting to conventional methods when the autoevaluator is insufficiently accurate. Experiments on the use of LLMs-as-judges for the optimization of quantization settings for the weights of an LLM,  for prompt design in LLMs, and for test-time reasoning budget allocation in LLMs confirm the reliability and efficiency of $\\texttt{R-AutoEval+}$.'}",https://openreview.net{'value': '/pdf/42cf5e1bbaeccd15c151a00a71cb2d9ecef2aa6f.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=nOZSYSdzOP,{'value': 'Unveiling Environmental Sensitivity of Individual Gains in Influence Maximization'},Xinyan Su; Zhiheng Zhang; Jiyan Qiu; Zhaojuan Yue; Jun Li,~Xinyan_Su1; ~Zhiheng_Zhang1; ~Jiyan_Qiu1; ~Zhaojuan_Yue1; ~Jun_Li35,{'value': ['influence maximization; causal inference; social networks']},"{'value': 'Influence Maximization (IM) seeks a seed set to maximize information dissemination in a network. Elegant IM algorithms could naturally extend to cases where each node is equipped with a specific weight, reflecting individual gains to measure its importance. In prevailing literature, these gains are typically assumed to remain constant throughout diffusion and are solvable through explicit formulas based on node characteristics and network topology. However, this assumption is not always feasible due to two key challenges: 1) \\textit{Unobservability}: The individual gains of each node are primarily evaluated by the difference between the outputs in the activated and non-activated states. In practice, we can only observe one of these states, with the other remaining unobservable post-propagation. 2) \\textit{Environmental sensitivity}: Beyond nodes’ inherent properties, individual gains are also sensitive to the activation status of surrounding nodes, which change dynamically during propagation even when the network topology is fixed. To address these uncertainties, we introduce a Causal Influence Maximization (CauIM) framework, leveraging causal inference techniques to model dynamic individual gains. We propose two algorithms, G-CauIM and A-CauIM, where the latter incorporates a novel acceleration technique. Theoretically, we establish the generalized lower bound of influence spread and provide robustness analysis. Empirically, experiments on synthetic and real-world datasets validate the effectiveness and reliability of our approach.'}",https://openreview.net{'value': '/pdf/3ac9b5d4bb850e9b251b2d3722e329a9abdb808b.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=nJ5GhQO35W,{'value': 'Walking the Schrödinger Bridge: A Direct Trajectory for Text-to-3D Generation'},Ziying Li; Xuequan Lu; Xinkui Zhao; Guanjie Cheng; Shuiguang Deng; Jianwei Yin,~Ziying_Li1; ~Xuequan_Lu1; ~Xinkui_Zhao1; ~Guanjie_Cheng1; ~Shuiguang_Deng1; ~Jianwei_Yin1,"{'value': ['Generative Models', 'Text-to-3D', '3D Gaussian Splatting', 'Diffusion Models']}","{'value': ""Recent advancements in optimization-based text-to-3D generation heavily rely on distilling knowledge from pre-trained text-to-image diffusion models using techniques like Score Distillation Sampling (SDS), which often introduce artifacts such as over-saturation and over-smoothing into the generated 3D assets. In this paper, we address this essential problem by formulating the generation process as learning an optimal, direct transport trajectory between the distribution of the current rendering and the desired target distribution, thereby enabling high-quality generation with smaller Classifier-free Guidance (CFG) values. At first, we theoretically establish SDS as a simplified instance of the Schrödinger Bridge framework. We prove that SDS employs the reverse process of an Schrödinger Bridge, which, under specific conditions (e.g., a Gaussian noise as one end), collapses to SDS's score function of the pre-trained diffusion model. Based upon this, we introduce Trajectory-Centric Distillation (TraCe), a novel text-to-3D generation framework, which reformulates the mathematically trackable framework of Schrödinger Bridge to explicitly construct a diffusion bridge from the current rendering to its text-conditioned, denoised target, and trains a LoRA-adapted model on this trajectory's score dynamics for robust 3D optimization. Comprehensive experiments demonstrate that TraCe consistently achieves superior quality and fidelity to state-of-the-art techniques. Our code will be released to the community.""}",https://openreview.net{'value': '/pdf/cbd774fb221ea45dd918c48bbc278a4612176548.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=nG0URHBvFW,{'value': 'Valid Inference with Imperfect Synthetic Data'},Yewon Byun; Shantanu Gupta; Zachary Chase Lipton; Rachel Leah Childers; Bryan Wilder,~Yewon_Byun1; ~Shantanu_Gupta2; ~Zachary_Chase_Lipton1; ~Rachel_Leah_Childers1; ~Bryan_Wilder2,"{'value': ['Human-AI Collaboration', 'Statistical Inference', 'LLMs for Computational Social Sciences']}","{'value': 'Predictions and generations from large language models are increasingly being explored as an aid in limited data regimes, such as in computational social science and human subjects research. \nWhile prior technical work has mainly explored the potential to use model-predicted labels for unlabeled data in a principled manner, there is increasing interest in using large language models to generate entirely new synthetic samples (e.g., synthetic simulations), such as in responses to surveys. However, it remains unclear \nby what means practitioners can combine such data with real data\nand yet produce statistically valid conclusions upon them.\nIn this paper, we introduce a new estimator based on generalized method of moments, providing a hyperparameter-free solution with strong theoretical guarantees to address this challenge. Intriguingly, we find that interactions between the moment residuals of synthetic data and those of real data (i.e., when they are predictive of each other) can greatly improve estimates of the target parameter.\nWe validate the finite-sample performance of our estimator across different tasks in computational social science applications, demonstrating large empirical gains.'}",https://openreview.net{'value': '/pdf/31c62b786c16bf6e8d1a58dd0f150826e98bcbbc.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=n7yVbKH7c3,{'value': 'A Unified Framework for Variable Selection in Model-Based Clustering with Missing Not at Random'},Binh Huu Ho; Long Nguyen Chi; TrungTin Nguyen; Van Ha Hoang; Binh T. Nguyen; Christopher Drovandi,~Binh_Huu_Ho2; ~Long_Nguyen_Chi1; ~TrungTin_Nguyen1; ~Van_Ha_Hoang1; ~Binh_T._Nguyen1; ~Christopher_Drovandi1,"{'value': ['Variable Selection', 'Finite Mixture Models', 'Model-Based Clustering', 'Missing Data', 'Asymptotic Selection Consistency']}","{'value': 'Model-based clustering integrated with variable selection is a powerful tool for uncovering latent structures within complex data. However, its effectiveness is often hindered by challenges such as identifying relevant variables that define heterogeneous subgroups and handling data that are missing not at random, a prevalent issue in fields like transcriptomics. While several notable methods have been proposed to address these problems, they typically tackle each issue in isolation, thereby limiting their flexibility and adaptability. This paper introduces a unified framework designed to address these challenges simultaneously. Our approach incorporates a data-driven penalty matrix into penalized clustering to enable more flexible variable selection, along with a mechanism that explicitly models the relationship between missingness and latent class membership. We demonstrate that, under certain regularity conditions, the proposed framework achieves both asymptotic consistency and selection consistency, even in the presence of missing data. This unified strategy significantly enhances the capability and efficiency of model-based clustering, advancing methodologies for identifying informative variables that define homogeneous subgroups in the presence of complex missing data patterns. The performance of the framework, including its computational efficiency, is evaluated through simulations and demonstrated using both synthetic and real-world transcriptomic datasets.'}",https://openreview.net{'value': '/pdf/a31b36f3c6cac592f8b1d65f58665ee986ad0167.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=n4nmiIq3qj,{'value': 'CSGO: Content-Style Composition in Text-to-Image Generation'},Peng Xing; Haofan Wang; Yanpeng Sun; wangqixun; Baixu; Hao Ai; Jen-Yuan Huang; Zechao Li,~Peng_Xing1; ~Haofan_Wang1; ~Yanpeng_Sun1; ~wangqixun2; ~Baixu1; ~Hao_Ai3; ~Jen-Yuan_Huang1; ~Zechao_Li1,"{'value': ['image generation', 'style transfer']}","{'value': 'The advancement of image style transfer has been fundamentally constrained by the absence of large-scale, high-quality datasets with explicit content-style-stylized supervision. Existing methods predominantly adopt training-free paradigms (e.g., image inversion), which limit controllability and generalization due to the lack of structured triplet data. To bridge this gap, we design a scalable and automated pipeline that constructs and purifies high-fidelity content-style-stylized image triplets. Leveraging this pipeline, we introduce IMAGStyle—the first large-scale dataset of its kind, containing 210K diverse and precisely aligned triplets for style transfer research. Empowered by IMAGStyle, we propose CSGO, a unified, end-to-end trainable framework that decouples content and style representations via independent feature injection. CSGO jointly supports image-driven style transfer, text-driven stylized generation, and text-editing-driven stylized synthesis within a single architecture. Extensive experiments show that CSGO achieves state-of-the-art controllability and fidelity, demonstrating the critical role of structured synthetic data in unlocking robust and generalizable style transfer. Source code: \\url{https://github.com/instantX-research/CSGO}'}",https://openreview.net{'value': '/pdf/d438c627406c42fd50e004336f2dc1fa64b08228.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=n4V3MSqK77,{'value': 'Agentic Plan Caching: Test-Time Memory for Fast and Cost-Efficient LLM Agents'},Qizheng Zhang; Michael Wornow; Kunle Olukotun,~Qizheng_Zhang1; ~Michael_Wornow1; ~Kunle_Olukotun1,"{'value': ['Caching', 'Memory', 'Serving', 'LLM Agents']}","{'value': 'LLM-based agent applications have shown increasingly remarkable capabilities in complex workflows but incur substantial costs and latency due to extensive planning and reasoning requirements. \nExisting LLM caching techniques (like context caching and semantic caching), primarily designed for serving chatbots, are insufficient for agent applications where outputs depend on external data and environmental contexts. \nWe propose **Agentic Plan Caching (APC)**, a novel **test-time memory** that extracts, stores, adapts, and reuses structured plan templates from planning stages of agent applications across semantically similar tasks to reduce the cost and latency of serving. \nUnlike traditional semantic caching, our system extracts plan templates from completed agent executions at test-time, employs keyword extraction to match new requests against cached plans, and utilizes lightweight models to adapt these templates to task-specific plans with contexts. \nEvaluation across multiple real-world agent applications shows that our system can reduce costs by 50.31\\% and latency by 27.28\\% on average while maintaining performance, offering a more efficient solution for serving LLM-based agents that complements existing LLM serving infrastructures.'}",https://openreview.net{'value': '/pdf/2362f2d245503d9d209dde5a45fbfbf3fb6a5990.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=n1NFpViAhp,{'value': 'The Price of Opportunity Fairness in Matroid Allocation Problems'},Rémi Castera; Felipe Garrido; Patrick Loiseau; Simon Mauras; Mathieu Molina; Vianney Perchet,~Rémi_Castera1; ~Felipe_Garrido1; ~Patrick_Loiseau1; ~Simon_Mauras1; ~Mathieu_Molina1; ~Vianney_Perchet3,"{'value': ['Bipartite Matching', 'Opportunity Fairness', 'Matroids', 'Price of Fairness']}","{'value': ""We consider matroid allocation problems under \\textit{opportunity fairness} constraints: resources need to be allocated to a set of agents under matroid constraints (which includes classical problems such as bipartite matching). Agents are divided into $C$ groups according to a sensitive attribute, and an allocation is opportunity-fair if each group receives the same share proportional to the maximum feasible allocation it could achieve in isolation. We study the Price of Fairness (PoF), i.e., the ratio between maximum size allocations and maximum size opportunity-fair allocations. We first provide a characterization of the PoF leveraging the underlying polymatroid structure of the allocation problem. Based on this characterization, we prove bounds on the PoF in various settings from fully adversarial (worst-case) to fully random. Notably, one of our main results considers an arbitrary matroid structure with agents randomly divided into groups. In this setting, we prove a PoF bound as a function of the (relative) size of the largest group. Our result implies that, as long as there is no dominant group (i.e., the largest group is not too large), opportunity fairness constraints do not induce any loss of social welfare (defined as the allocation size). Overall, our results give insights into which aspects of the problem's structure affect the trade-off between opportunity fairness and social welfare.""}",https://openreview.net{'value': '/pdf/4f5d3e6ea032f6b4b98ac4982d8b2b74e164b8d0.pdf'},{'abstract_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=n0QvMU2kON,{'value': 'From Shortcut to Induction Head: How Data Diversity Shapes Algorithm Selection in Transformers'},Ryotaro Kawata; Yujin Song; Alberto Bietti; Naoki Nishikawa; Taiji Suzuki; Samuel Vaiter; Denny Wu,~Ryotaro_Kawata1; ~Yujin_Song1; ~Alberto_Bietti1; ~Naoki_Nishikawa1; ~Taiji_Suzuki1; ~Samuel_Vaiter1; ~Denny_Wu2,"{'value': ['Transformers', 'induction head', 'training dynamics']}","{'value': 'Transformers can implement both generalizable algorithms (e.g., induction heads) and simple positional shortcuts (e.g., memorizing fixed output positions). In this work, we study how the choice of pretraining data distribution steers a shallow transformer toward one behavior or the other. Focusing on a minimal trigger-output prediction task -- copying the token immediately following a special trigger upon its second occurrence -- we present a rigorous analysis of gradient-based training of a single-layer transformer. In both the infinite and finite sample regimes, we prove a transition in the learned mechanism: if input sequences exhibit sufficient diversity, measured by a low “max-sum” ratio of trigger-to-trigger distances, the trained model implements an induction head and generalizes to unseen contexts; by contrast, when this ratio is large, the model resorts to a positional shortcut and fails to generalize out-of-distribution (OOD). We also reveal a trade-off between the pretraining context length and OOD generalization, and derive the optimal pretraining distribution that minimizes computational cost per sample. Finally, we validate our theoretical predictions with controlled synthetic experiments, demonstrating that broadening context distributions robustly induces induction heads and enables OOD generalization. Our results shed light on the algorithmic biases of pretrained transformers and offer conceptual guidelines for data-driven control of their learned behaviors.'}",https://openreview.net{'value': '/pdf/04b3d77a5877df40c7456bf58e5251098fea056b.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=mmIAp3cVS0,{'value': 'G-Memory: Tracing Hierarchical Memory for Multi-Agent Systems'},Guibin Zhang; Muxin Fu; Kun Wang; Guancheng Wan; Miao Yu; Shuicheng YAN,~Guibin_Zhang1; ~Muxin_Fu1; ~Kun_Wang15; ~Guancheng_Wan1; ~Miao_Yu8; ~Shuicheng_YAN3,"{'value': ['Multi-agent systems', 'agent memory', 'LLM agent']}","{'value': 'Large language model (LLM)-powered multi-agent systems (MAS) have demonstrated cognitive and execution capabilities that far exceed those of single LLM agents, yet their capacity for self-evolution remains hampered by underdeveloped memory architectures. Upon close inspection, we are alarmed to discover that prevailing MAS memory mechanisms (1) are overly simplistic, completely disregarding the nuanced inter-agent collaboration trajectories, and (2) lack cross-trial and agent-specific customization, in stark contrast to the expressive memory developed for single agents. To bridge this gap, we introduce G-Memory, a hierarchical, agentic memory system for MAS inspired by organizational memory theory, which manages the lengthy MAS interaction via a three-tier graph hierarchy: insight, query, and interaction graphs. Upon receiving a new user query, G-Memory performs bi-directional memory traversal to retrieve both \\textit{high-level, generalizable insights} that enable the system to leverage cross-trial knowledge, and \\textit{fine-grained, condensed interaction trajectories} that compactly encode prior collaboration experiences. Upon task execution, the entire hierarchy evolves by assimilating new collaborative trajectories, nurturing the progressive evolution of agent teams. Extensive experiments across five benchmarks, three LLM backbones, and three popular MAS frameworks demonstrate that G-Memory improves success rates in embodied action and accuracy in knowledge QA by up to $20.89\\\\%$ and $10.12\\\\%$, respectively, without any modifications to the original frameworks.'}",https://openreview.net{'value': '/pdf/52f961783a3212459f228b4ec297f523ba2d0c95.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=mlU9KqdZUS,{'value': 'AgentBreeder: Mitigating the AI Safety Risks of Multi-Agent Scaffolds via Self-Improvement'},J Rosser; Jakob Nicolaus Foerster,~J_Rosser1; ~Jakob_Nicolaus_Foerster1,"{'value': ['AI Safety', 'Multi-Agent Systems', 'LLMs', 'Large Language Models', 'Jailbreaking', 'Agent Scaffolds']}","{'value': 'Scaffolding Large Language Models (LLMs) into multi-agent systems often improves performance on complex tasks, but the safety impact of such scaffolds has not been thoroughly explored. We introduce AgentBreeder, a framework for multi-objective self-improving evolutionary search over scaffolds. We evaluate discovered scaffolds on widely recognized reasoning, mathematics, and safety benchmarks and compare them with popular baselines. In ""blue"" mode, we see a 79.4% average uplift in safety benchmark performance while maintaining or improving capability scores. In ""red"" mode, we find adversarially weak scaffolds emerging concurrently with capability optimization. Our work demonstrates the risks of multi-agent scaffolding and provides a framework for mitigating them. Code is available at \\url{https://github.com/jrosseruk/AgentBreeder}.'}",https://openreview.net{'value': '/pdf/237ca0099a7a95299cd0bae4b495038b19873e08.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=mcYO3DccbQ,{'value': 'From stability of Langevin diffusion to convergence of proximal MCMC for non-log-concave sampling'},Marien Renaud; Valentin De Bortoli; Arthur Leclaire; Nicolas Papadakis,~Marien_Renaud1; ~Valentin_De_Bortoli1; ~Arthur_Leclaire1; ~Nicolas_Papadakis3,"{'value': ['Sampling', 'Langevin diffusion', 'Monte Carlo Markov Chain', 'Inverse Problem']}","{'value': 'We consider the problem of sampling distributions stemming from non-convex potentials with Unadjusted Langevin Algorithm (ULA). We prove the stability of the discrete-time ULA to drift approximations under the assumption that the potential is strongly convex at infinity. In many context, e.g. imaging inverse problems, potentials are non-convex and non-smooth.  Proximal Stochastic Gradient Langevin Algorithm (PSGLA) is a popular algorithm to handle such potentials. It combines the forward-backward optimization algorithm with a ULA step. Our main stability result combined with properties of the Moreau envelope allows us to derive the first proof of convergence of the PSGLA for non-convex potentials. We empirically validate our methodology on synthetic data and in the context of imaging inverse problems. In particular, we observe that PSGLA exhibits faster convergence rates than Stochastic Gradient Langevin Algorithm for posterior sampling while preserving its restoration properties.'}",https://openreview.net{'value': '/pdf/30b5e789f465f52c8979f3e633ee034a9a82382f.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=mUcUY0f4u9,{'value': 'BIPNN: Learning to Solve Binary Integer Programming via Hypergraph Neural Networks'},Sen Bai; Chunqi Yang; Xin Bai; Xin Zhang; Zhengang Jiang,~Sen_Bai1; ~Chunqi_Yang1; ~Xin_Bai3; ~Xin_Zhang80; ~Zhengang_Jiang4,"{'value': ['binary integer program', 'hypergraph neural network', 'nonlinear integer programming']}","{'value': 'Binary (0-1) integer programming (BIP) is pivotal in scientific domains requiring discrete decision-making. As the advance of AI computing, recent works explore neural network-based solver for integer linear programming (ILP) problems. Yet, they lack scalability for tackling nonlinear challenges. To handle nonlinearities, state-of-the-art Branch-and-Cut solvers employ linear relaxations, leading to exponential growth in auxiliary variables and severe computation limitations. To overcome these limitations, we propose BIPNN, an unsupervised learning framework to solve BIP problems via hypergraph neural networks (HyperGNN). Specifically, (i) BIPNN reformulates BIPs-constrained, discrete, and nonlinear (sin, log, exp) optimization problems-into unconstrained, differentiable, and polynomial loss functions. The reformulation stems from the observation of a precise one-to-one mapping between polynomial BIP objectives and hypergraph structures, enabling the unsupervised training of HyperGNN to optimize BIP problems in an end-to-end manner. On this basis, (ii) we propose a GPU-accelerated and continuous-annealing-enhanced training pipeline for BIPNN. The pipeline enables BIPNN to optimize large-scale nonlinear terms in BIPs fully in parallel via straightforward gradient descent, thus significantly reducing the training cost while ensuring the generation of discrete, high-quality solutions. Extensive experiments on synthetic and real-world datasets highlight the superiority of our approach.'}",https://openreview.net{'value': '/pdf/edc5d81e74b1a2e81ca5adb7a76a7c417dc6a2fa.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=mUJU8LmhZY,{'value': 'Adaptive Frontier Exploration on Graphs with Applications to Network-Based Disease Testing'},Davin Choo; Yuqi Pan; Tonghan Wang; Milind Tambe; Alastair van Heerden; Cheryl Johnson,~Davin_Choo1; ~Yuqi_Pan1; ~Tonghan_Wang1; ~Milind_Tambe1; ~Alastair_van_Heerden1; ~Cheryl_Johnson1,"{'value': ['sequential decision making', 'graphs', 'branching bandits', 'gittins index', 'network-based testing', 'public health']}","{'value': 'We study a sequential decision-making problem on a $n$-node graph $\\mathcal{G}$ where each node has an unknown label from a finite set $\\mathbf{\\Omega}$, drawn from a joint distribution $\\mathcal{P}$ that is Markov with respect to $\\mathcal{G}$. At each step, selecting a node reveals its label and yields a label-dependent reward. The goal is to adaptively choose nodes to maximize expected accumulated discounted rewards. We impose a frontier exploration constraint, where actions are limited to neighbors of previously selected nodes, reflecting practical constraints in settings such as contact tracing and robotic exploration. We design a Gittins index-based policy that applies to general graphs and is provably optimal when $\\mathcal{G}$ is a forest. Our implementation runs in $\\mathcal{O}(n^2 \\cdot |\\mathbf{\\Omega}|^2)$ time while using $\\mathcal{O}(n \\cdot |\\mathbf{\\Omega}|^2)$ oracle calls to $\\mathcal{P}$ and $\\mathcal{O}(n^2 \\cdot |\\mathbf{\\Omega}|)$ space. Experiments on synthetic and real-world graphs show that our method consistently outperforms natural baselines, including in non-tree, budget-limited, and undiscounted settings. For example, in HIV testing simulations on real-world sexual interaction networks, our policy detects nearly all positive cases with only half the population tested, substantially outperforming other baselines.'}",https://openreview.net{'value': '/pdf/b018b26a33b731fde0f56c94534af0a0a344c613.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=mQOaC3uH2r,{'value': 'When Does Closeness in Distribution Imply Representational Similarity? An Identifiability Perspective'},Beatrix Miranda Ginn Nielsen; Emanuele Marconato; Andrea Dittadi; Luigi Gresele,~Beatrix_Miranda_Ginn_Nielsen1; ~Emanuele_Marconato1; ~Andrea_Dittadi1; ~Luigi_Gresele1,"{'value': ['Identifiability', 'Representational Similarity', 'Distributional Distance', 'Robustness', 'Representation Learning']}","{'value': 'When and why representations learned by different deep neural networks are similar is an active research topic. \n    We choose to address these questions from the perspective of identifiability theory, which suggests that a measure of representational similarity should be invariant to transformations that leave the model distribution unchanged.\n    Focusing on a model family which includes several popular pre-training approaches, e.g., autoregressive language models, we explore when models which generate distributions that are close have similar representations. We prove that a small Kullback--Leibler divergence between the model distributions does not guarantee that the corresponding representations are similar. This has the important corollary that models with near-maximum data likelihood can still learn dissimilar representations---a phenomenon mirrored in our experiments with models trained on CIFAR-10.\n    We then define a distributional distance for which closeness implies representational similarity, and in synthetic experiments, we find that wider networks learn distributions which are closer with respect to our distance and have more similar representations. Our results thus clarify the link between closeness in distribution and representational similarity.'}",https://openreview.net{'value': '/pdf/e04eeaff2ecdcb98d9a9f6f9f586a967cdb25e1b.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=mLVqiNH0aA,{'value': 'ViDAR: Video Diffusion-Aware 4D Reconstruction From Monocular Inputs'},Michal Nazarczuk; Sibi Catley-Chandar; Thomas Tanay; Zhensong Zhang; Gregory Slabaugh; Eduardo Pérez-Pellitero,~Michal_Nazarczuk1; ~Sibi_Catley-Chandar1; ~Thomas_Tanay1; ~Zhensong_Zhang2; ~Gregory_Slabaugh2; ~Eduardo_Pérez-Pellitero1,"{'value': ['monocular reconstruction', 'diffusion guidance']}","{'value': 'Dynamic Novel View Synthesis aims to generate photorealistic views of moving subjects from arbitrary viewpoints. This task is particularly challenging when relying on monocular video, where disentangling structure from motion is ill-posed and supervision is scarce. We introduce Video Diffusion-Aware Reconstruction (ViDAR), a novel 4D reconstruction framework that leverages personalised diffusion models to synthesise a pseudo multi-view supervision signal for training a Gaussian splatting representation. By conditioning on scene-specific features, ViDAR recovers fine-grained appearance details while mitigating artefacts introduced by monocular ambiguity. To address the spatio-temporal inconsistency of diffusion-based supervision, we propose a diffusion-aware loss function and a camera pose optimisation strategy that aligns synthetic views with the underlying scene geometry. Experiments on DyCheck, a challenging benchmark with extreme viewpoint variation, show that ViDAR outperforms all state-of-the-art baselines in visual quality and geometric consistency. We further highlight ViDAR’s strong improvement over baselines on dynamic regions and provide a new benchmark to compare performance in reconstructing motion-rich parts of the scene.'}",https://openreview.net{'value': '/pdf/a9f10447c0bec5fd517816cfff4cd22230101591.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=mE74JKHTCE,{'value': 'Tracing the Roots: Leveraging Temporal Dynamics in Diffusion Trajectories for Origin Attribution'},Andreas Floros; Seyed-Mohsen Moosavi-Dezfooli; Pier Luigi Dragotti,~Andreas_Floros1; ~Seyed-Mohsen_Moosavi-Dezfooli1; ~Pier_Luigi_Dragotti2,"{'value': ['Generative Models', 'Diffusion Models', 'Data Provenance']}","{'value': 'Diffusion models have transformed image synthesis through iterative denoising, by defining trajectories from noise to coherent data. While their capabilities are widely celebrated, a critical challenge remains unaddressed: ensuring responsible use by verifying whether an image originates from a model\'s training set, its novel generations or external sources. We introduce a framework that analyzes diffusion trajectories for this purpose. Specifically, we demonstrate that temporal dynamics across the entire trajectory allow for more robust classification and challenge the widely-adopted ""Goldilocks zone"" conjecture, which posits that membership inference is effective only within narrow denoising stages. More fundamentally, we expose critical flaws in current membership inference practices by showing that representative methods fail under distribution shifts or when model-generated data is present. For model attribution, we demonstrate a first white-box approach directly applicable to diffusion. Ultimately, we propose the unification of data provenance into a single, cohesive framework tailored to modern generative systems.'}",https://openreview.net{'value': '/pdf/b3ae50c7ca9fa59ee665a379b7628f142d8fdb2f.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=m7uj1vIZ62,{'value': 'Retrosynthesis Planning via Worst-path Policy Optimisation in Tree-structured MDPs'},Mianchu Wang; Giovanni Montana,~Mianchu_Wang2; ~Giovanni_Montana1,"{'value': ['Retrosynthesis planning', 'reinforcement learning', 'self-imitation learning']}","{'value': 'Retrosynthesis planning aims to decompose target molecules into available building blocks, forming a synthetic tree where each internal node represents an intermediate compound and each leaf ideally corresponds to a purchasable reactant. However, this tree becomes invalid if any leaf node is not a valid building block, making the planning process vulnerable to the ""weakest link"" in the synthetic route. Existing methods often optimise for average performance across branches, failing to account for this worst-case sensitivity. \nIn this paper, we reframe retrosynthesis as a worst-path optimisation problem within tree-structured Markov Decision Processes (MDPs). We prove that this formulation admits a unique optimal solution and provides monotonic improvement guarantees. Building on this insight, we introduce Interactive Retrosynthesis Planning (InterRetro), a method that interacts with the tree MDP, learns a value function for worst-path outcomes, and improves its policy through self-imitation, preferentially reinforcing past decisions with high estimated advantage. \nEmpirically, InterRetro achieves state-of-the-art results — solving 100\\% of targets on the Retro*-190 benchmark, shortening synthetic routes by 4.9\\%, and achieving promising performance using only 10\\% of the training data.'}",https://openreview.net{'value': '/pdf/d1e77fb97b9b2c8f80e9edfc7b594bf3a37b7b94.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=ly5DnRIgCZ,{'value': 'QiMeng-CodeV-R1: Reasoning-Enhanced Verilog Generation'},Yaoyu Zhu; Di Huang; Hanqi Lyu; Xiaoyun Zhang; Chongxiao Li; Wenxuan Shi; Yutong Wu; Jianan Mu; Jinghua Wang; Yang zhao; Pengwei Jin; Shuyao Cheng; shengwen Liang; Xishan Zhang; Rui Zhang; Zidong Du; Qi Guo; Xing Hu; Yunji Chen,~Yaoyu_Zhu1; ~Di_Huang5; ~Hanqi_Lyu2; ~Xiaoyun_Zhang3; ~Chongxiao_Li1; ~Wenxuan_Shi4; ~Yutong_Wu9; ~Jianan_Mu1; ~Jinghua_Wang4; ~Yang_zhao36; ~Pengwei_Jin1; ~Shuyao_Cheng1; ~shengwen_Liang1; ~Xishan_Zhang1; ~Rui_Zhang1; ~Zidong_Du1; ~Qi_Guo4; ~Xing_Hu3; ~Yunji_Chen1,"{'value': ['LLM', 'Code Generation', 'Verilog']}","{'value': 'Large language models (LLMs) trained via reinforcement learning with verifiable reward (RLVR) have achieved breakthroughs on tasks with explicit, automatable verification, such as software programming and mathematical problems. Extending RLVR to electronic design automation (EDA), especially automatically generating hardware description languages (HDLs) like Verilog from natural-language (NL) specifications, however, poses three key challenges: the lack of automated and accurate verification environments, the scarcity of high-quality NL-code pairs, and the prohibitive computation cost of RLVR. To this end, we introduce CodeV-R1, an RLVR framework for training Verilog generation LLMs. First, we develop a rule-based testbench generator that performs robust equivalence checking against golden references. Second, we propose a round-trip data synthesis method that pairs open-source Verilog snippets with LLM-generated NL descriptions, verifies code–NL–code consistency via the generated testbench, and filters out inequivalent examples to yield a high-quality dataset. Third, we employ a two-stage ""distill-then-RL"" training pipeline: distillation for the cold start of reasoning abilities, followed by adaptive DAPO, our novel RLVR algorithm that can reduce training cost by adaptively adjusting sampling rate. The resulting model, CodeV-R1-7B, achieves 68.6 \\% and 72.9 \\% pass@1 on VerilogEval v2 and RTLLM v1.1, respectively, surpassing prior state-of-the-art by 12$\\sim$20 \\%, while even exceeding the performance of 671B DeepSeek-R1 on RTLLM. We have released our model, training code, and dataset to facilitate research in EDA and LLM communities.'}",https://openreview.net{'value': '/pdf/d8c56839b04b28b0b8cf304db2a8b3d12509386e.pdf'},{'abstract_filter': 'Data Synthesis'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=lscdYmLJ5v,{'value': 'On the creation of narrow AI: hierarchy and nonlocality of neural network skills'},Eric J Michaud; Asher Parker-Sartori; Max Tegmark,~Eric_J_Michaud1; ~Asher_Parker-Sartori1; ~Max_Tegmark1,"{'value': ['safety', 'mechanistic interpretability', 'theory', 'curriculum learning', 'pruning', 'connectionism', 'unlearning']}","{'value': 'We study the problem of creating strong, yet narrow, AI systems. While recent AI progress has been driven by the training of large general-purpose foundation models, the creation of smaller models specialized for narrow domains could be valuable for both efficiency and safety. In this work, we explore two challenges involved in creating such systems, having to do with basic properties of how neural networks learn and structure their representations. The first challenge regards when it is possible to train narrow models from scratch. Through experiments on a synthetic task, we find that it is sometimes necessary to train networks on a wide distribution of data to learn certain narrow skills within that distribution. This effect arises when skills depend on each other hierarchically, and training on a broad distribution introduces a curriculum which substantially accelerates learning. The second challenge regards how to transfer particular skills from large general models into small specialized models. We find that model skills are often not perfectly localized to a particular set of prunable components. However, we find that methods based on pruning can still outperform distillation. We investigate the use of a regularization objective to align desired skills with prunable components while unlearning unnecessary skills.'}",https://openreview.net{'value': '/pdf/acbe20f9bc641b606dc9af8b1b83558c5d92fea9.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=lkw2WJLdbh,{'value': 'Graphs Help Graphs: Multi-Agent Graph Socialized Learning'},Jialu Li; Yu Wang; Pengfei Zhu; Wanyu Lin; Xinjie Yao; Qinghua Hu,~Jialu_Li4; ~Yu_Wang33; ~Pengfei_Zhu1; ~Wanyu_Lin1; ~Xinjie_Yao1; ~Qinghua_Hu1,"{'value': ['Graph Neural Network', 'Socialized Learning', 'Graph Collaborative Learning', 'Graph Lifelong Learning']}","{'value': ""Graphs in the real world are fragmented and dynamic, lacking collaboration akin to that observed in human societies. Existing paradigms present collaborative information collapse and forgetting, making collaborative relationships poorly autonomous and interactive information insufficient. Moreover, collaborative information is prone to loss when the graph grows. Effective collaboration in heterogeneous dynamic graph environments becomes challenging. Inspired by social learning, this paper presents a Graph Socialized Learning (GSL) paradigm. We provide insights into graph socialization in GSL and boost the performance of agents through effective collaboration. It is crucial to determine with whom, what, and when to share and accumulate information for effective GSL. Thus, we propose the ''Graphs Help Graphs'' (GHG) method to solve these issues. Specifically, it uses a graph-driven organizational structure to select interacting agents and manage interaction strength autonomously. We produce customized synthetic graphs as an interactive medium based on the demand of agents, then apply the synthetic graphs to build prototypes in the life cycle to help select optimal parameters. We demonstrate the effectiveness of GHG in heterogeneous dynamic graphs by an extensive empirical study. The code is available through https://github.com/Jillian555/GHG.""}",https://openreview.net{'value': '/pdf/7ec31171954174d798510a82a73a14442a632ee6.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=lh5sXuGfk8,{'value': 'Securing the Language of Life: Inheritable Watermarks from DNA Language Models to Proteins'},ZAIXI ZHANG; Ruofan Jin; Le Cong; Mengdi Wang,~ZAIXI_ZHANG2; ~Ruofan_Jin1; ~Le_Cong2; ~Mengdi_Wang1,"{'value': ['Watermark', 'LLMs', 'DNA', 'AI for Science', 'AI Safety']}","{'value': 'DNA language models have revolutionized our ability to design and manipulate DNA sequences—the fundamental language of life—with unprecedented precision, enabling transformative applications in therapeutics, synthetic biology, and gene editing. However, this capability also poses significant dual-use risks, including the potential creation of harmful biological agents. To address these biosecurity challenges, we introduce two innovative watermarking techniques: DNAMark and CentralMark. DNAMark employs synonymous codon substitutions to embed robust watermarks in DNA sequences while preserving the function of encoded proteins. CentralMark advances this by creating inheritable watermarks that transfer from DNA to translated proteins, leveraging protein embeddings to ensure detection across the central dogma. Both methods utilize state-of-the-art embeddings to generate watermark logits, enhancing resilience against natural mutations, synthesis errors, and adversarial attacks. Evaluated on a therapeutic DNA benchmark, DNAMark and CentralMark achieve F1 detection scores above 0.85 under diverse conditions, while maintaining over 60\\% sequence similarity to ground truth and degeneracy scores below 15\\%. A case study on a CRISPR-Cas9 system underscores CentralMark’s utility in real-world synthetic biology. This work establishes a vital framework for securing DNA language models, balancing innovation with accountability to mitigate biosecurity risks.'}",https://openreview.net{'value': '/pdf/47b24d1d0558040ba864deb61c165f45273f34e0.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=lg51XnHt2H,{'value': 'Conformal Prediction in The Loop: A Feedback-Based Uncertainty Model for Trajectory Optimization'},Han Wang; Chao Ning,~Han_Wang49; ~Chao_Ning2,"{'value': ['Conformal prediction', 'Feedback', 'Trajectory optimization', 'Uncertainty quantification', 'Risk allocation']}","{'value': 'Conformal Prediction (CP) is a powerful statistical machine learning tool to construct uncertainty sets with coverage guarantees, which has fueled its extensive adoption in generating prediction regions for decision-making tasks, e.g., Trajectory Optimization (TO) in uncertain environments. However, existing methods predominantly employ a sequential scheme, where decisions rely unidirectionally on the prediction regions, and consequently the information from decision-making fails to be fed back to instruct CP. In this paper, we propose a novel Feedback-Based CP (Fb-CP) framework for shrinking-horizon TO with a joint risk constraint over the entire mission time. Specifically, a CP-based posterior risk calculation method is developed by fully leveraging the realized trajectories to adjust the posterior allowable risk, which is then allocated to future times to update prediction regions. In this way, the information in the realized trajectories is continuously fed back to the CP, enabling attractive feedback-based adjustments of the prediction regions and a provable online improvement in trajectory performance. Furthermore, we theoretically prove that such adjustments consistently maintain the coverage guarantees of the prediction regions, thereby ensuring provable safety. Additionally, we develop a decision-focused iterative risk allocation algorithm with theoretical convergence analysis for allocating the posterior allowable risk which closely aligns with Fb-CP. Furthermore, we extend the proposed method to handle distribution shift. The effectiveness and superiority of the proposed method are demonstrated through benchmark experiments.'}",https://openreview.net{'value': '/pdf/49a440238b31f213e97ee3907cea1d9295006660.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=lUHwUuQGdV,{'value': 'Towards Unified Multimodal Interleaved Generation via Group Relative Policy Optimization'},Ming Nie; Chunwei Wang; Jianhua Han; Hang Xu; Li Zhang,~Ming_Nie1; ~Chunwei_Wang1; ~Jianhua_Han1; ~Hang_Xu1; ~Li_Zhang5,"{'value': ['multimodal interleaved generation', 'unified models', 'reinforcement learning']}","{'value': 'Unified vision-language models have made significant progress in multimodal understanding and generation, yet they largely fall short in producing multimodal interleaved outputs, which is a crucial capability for tasks like visual storytelling and step-by-step visual reasoning.\nIn this work, we propose a reinforcement learning-based post-training strategy to unlock this capability in existing unified models, without relying on large-scale multimodal interleaved datasets.\nWe begin with a warm-up stage using a hybrid dataset comprising curated interleaved sequences and limited data for multimodal understanding and text-to-image generation, which exposes the model to interleaved generation patterns while preserving its pretrained capabilities.\nTo further refine interleaved generation, we propose a unified policy optimization framework that extends Group Relative Policy Optimization (GRPO) to the multimodal setting.\nOur approach jointly models text and image generation within a single decoding trajectory and optimizes it with our novel hybrid rewards covering textual relevance, visual-text alignment, and structural fidelity.\nAdditionally, we incorporate process-level rewards to provide step-wise guidance, enhancing training efficiency in complex multimodal tasks.\nExperiments on MMIE and InterleavedBench demonstrate that our approach significantly enhances the quality and coherence of multimodal interleaved generation.'}",https://openreview.net{'value': '/pdf/be81012c4b8d2224b305eb1f109bd4f030fe2ac2.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=lTEjpeTXIo,{'value': 'LaM-SLidE: Latent Space Modeling of Spatial Dynamical Systems via Linked Entities'},Florian Sestak; Artur P. Toshev; Andreas Fürst; Günter Klambauer; Andreas Mayr; Johannes Brandstetter,~Florian_Sestak1; ~Artur_P._Toshev1; ~Andreas_Fürst1; ~Günter_Klambauer1; ~Andreas_Mayr2; ~Johannes_Brandstetter1,"{'value': ['diffusion models', 'flow-matching', 'latent space models', 'latent diffusion models', 'dynamical systems', 'simulation', 'generative modeling', 'molecular dynamics', 'unified representations']}","{'value': 'Generative models are spearheading recent progress in deep learning, showcasing strong promise for trajectory sampling in dynamical systems as well. However, whereas latent space modeling paradigms have transformed image and video generation, similar approaches are more difficult for most dynamical systems. Such systems -- from chemical molecule structures to collective human behavior -- are described by interactions of entities, making them inherently linked to connectivity patterns, entity conservation, and the traceability of entities over time. Our approach, LaM-SLidE (Latent Space Modeling of Spatial Dynamical Systems via Linked Entities), bridges the gap between: (1) keeping the traceability of individual entities in a latent system representation, and (2) leveraging the efficiency and scalability of recent advances in image and video generation, where pre-trained encoder and decoder enable generative modeling directly in latent space. The core idea of LaM-SLidE is the introduction of identifier representations (IDs) that enable the retrieval of entity properties and entity composition from latent system representations, thus fostering traceability. Experimentally, across different domains, we show that LaM-SLidE performs favorably in terms of speed, accuracy, and generalizability. Code is available at https://github.com/ml-jku/LaM-SLidE.'}",https://openreview.net{'value': '/pdf/356823b2931b30ff4caffc86e5574c5822e8e775.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=lTAtQW1Ufi,{'value': 'From Human Attention to Diagnosis: Semantic Patch-Level Integration of Vision-Language Models in Medical Imaging'},Dmitry Lvov; Ilya Pershin,~Dmitry_Lvov1; ~Ilya_Pershin1,"{'value': ['Gaze prediction', 'medical image analysis', 'CXR', 'deep learning', 'fixation modeling', 'attention mechanisms', 'visual attention', 'neural networks']}","{'value': 'Predicting human eye movements during goal-directed visual search is critical for enhancing interactive AI systems. In medical imaging, such prediction can support radiologists in interpreting complex data, such as chest X-rays. Many existing methods rely on generic vision--language models and saliency-based features, which can limit their ability to capture fine-grained clinical semantics and integrate domain knowledge effectively. We present \\textbf{LogitGaze-Med}, a state-of-the-art multimodal transformer framework that unifies (1) domain-specific visual encoders (e.g., CheXNet), (2) textual embeddings of diagnostic labels, and (3) semantic priors extracted via the logit-lens from an instruction-tuned medical vision--language model (LLaVA-Med). By directly predicting continuous fixation coordinates and dwell durations, our model generates clinically meaningful scanpaths. Experiments on the GazeSearch dataset and synthetic scanpaths generated from MIMIC-CXR and validated by experts demonstrate that LogitGaze-Med improves scanpath similarity metrics by 20--30\\% over competitive baselines and yields over 5\\% gains in downstream pathology classification when incorporating predicted fixations as additional training data.'}",https://openreview.net{'value': '/pdf/835a298338161d99309182c449ce6e3dc9f4d06c.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=lRs6qSMKH1,{'value': 'SplitFlow: Flow Decomposition for Inversion-Free Text-to-Image Editing'},Sung-Hoon Yoon; Minghan Li; Gaspard Beaudouin; Congcong Wen; Muhammad Rafay Azhar; Mengyu Wang,~Sung-Hoon_Yoon1; ~Minghan_Li1; ~Gaspard_Beaudouin1; ~Congcong_Wen1; ~Muhammad_Rafay_Azhar1; ~Mengyu_Wang4,"{'value': ['Image Editing', 'Flow Matching', 'Rectified Flow']}","{'value': 'Rectified flow models have become a $\\textit{de facto}$ standard in image generation due to their stable sampling trajectories and high-fidelity outputs. Despite their strong generative capabilities, they face critical limitations in image editing tasks: inaccurate inversion processes for mapping real images back into the latent space, and gradient entanglement issues during editing often result in outputs that do not faithfully reflect the target prompt. Recent efforts have attempted to directly map source and target distributions via ODE-based approaches without inversion; however, these methods still yield suboptimal editing quality. In this work, we propose a flow decomposition-and-aggregation framework built upon an inversion-free formulation to address these limitations. Specifically, we semantically decompose the target prompt into multiple sub-prompts, compute an independent flow for each, and aggregate them to form a unified editing trajectory. While we empirically observe that decomposing the original flow enhances diversity in the target space, generating semantically aligned outputs still requires consistent guidance toward the full target prompt. To this end, we design a projection and soft-aggregation mechanism for flow, inspired by gradient conflict resolution in multi-task learning. This approach adaptively weights the sub-target velocity fields, suppressing semantic redundancy while emphasizing distinct directions, thereby preserving both diversity and consistency in the final edited output. Experimental results demonstrate that our method outperforms existing zero-shot editing approaches in terms of semantic fidelity and attribute disentanglement. The code is available at https://github.com/Harvard-AI-and-Robotics-Lab/SplitFlow.'}",https://openreview.net{'value': '/pdf/91d262d0bdb14ba7e4dc8350a057789e5f706cf9.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=lHW93LKaUk,{'value': 'Wan-Move: Motion-controllable Video Generation via Latent Trajectory Guidance'},Ruihang Chu; Yefei He; Zhekai Chen; Shiwei Zhang; Xiaogang Xu; Bin Xia; Dingdong WANG; Hongwei Yi; Xihui Liu; Hengshuang Zhao; Yu Liu; Yingya Zhang; Yujiu Yang,~Ruihang_Chu1; ~Yefei_He1; ~Zhekai_Chen1; ~Shiwei_Zhang2; ~Xiaogang_Xu2; ~Bin_Xia2; ~Dingdong_WANG1; ~Hongwei_Yi1; ~Xihui_Liu1; ~Hengshuang_Zhao2; ~Yu_Liu23; ~Yingya_Zhang3; ~Yujiu_Yang2,"{'value': ['Video generation', 'Motion-controllable video generation', 'Diffusion models']}","{'value': ""We present Wan-Move, a simple and scalable framework that brings motion control to video generative models. Existing motion-controllable methods typically suffer from coarse control granularity and limited scalability, leaving their outputs insufficient for practical use. We narrow this gap by achieving precise and high-quality motion control. Our core idea is to directly make the original condition features motion-aware for guiding video synthesis. To this end, we first represent object motions with dense point trajectories, allowing fine-grained control over the scene. We then project these trajectories into latent space and propagate the first frame's features along each trajectory, producing an aligned spatiotemporal feature map that tells how each scene element should move. This feature map serves as the updated latent condition, which is naturally integrated into the off-the-shelf image-to-video model, e.g., Wan-I2V-14B, as motion guidance without any architecture change. It removes the need for auxiliary motion encoders and makes fine-tuning base models easily scalable. Through scaled training, Wan-Move generates 5-second, 480p videos whose motion controllability rivals Kling 1.5 Pro's commercial Motion Brush, as indicated by user studies. To support comprehensive evaluation, we further design MoveBench, a rigorously curated benchmark featuring diverse content categories and hybrid-verified annotations. It is distinguished by larger data volume, longer video durations, and high-quality motion annotations. Extensive experiments on MoveBench and the public dataset consistently show Wan-Move's superior motion quality. Code, models, and benchmark data are made available.""}",https://openreview.net{'value': '/pdf/8dcf3896dd7ef7fe46407741db4d743030e72971.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=lEsvczuPVj,{'value': 'REDOUBT: Duo Safety Validation for Autonomous Vehicle Motion Planning'},Shuguang Wang; Qian Zhou; Kui Wu; Dapeng Wu; Wei-Bin Lee; Jianping Wang,~Shuguang_Wang5; ~Qian_Zhou3; ~Kui_Wu1; ~Dapeng_Wu1; ~Wei-Bin_Lee1; ~Jianping_Wang1,"{'value': ['autonomous driving', 'motion planning']}","{'value': ""Safety validation, which assesses the safety of an autonomous system's motion planning decisions, is critical for the safe deployment of autonomous vehicles. Existing input validation techniques from other machine learning domains, such as image classification, face unique challenges in motion planning due to its contextual properties, including complex inputs and one-to-many mapping. Furthermore, current output validation methods in autonomous driving primarily focus on open-loop trajectory prediction, which is ill-suited for the closed-loop nature of motion planning. We introduce REDOUBT, the first systematic safety validation framework for autonomous vehicle motion planning that employs a duo mechanism, simultaneously inspecting input distributions and output uncertainty. REDOUBT identifies previously overlooked unsafe modes arising from the interplay of In-Distribution/Out-of-Distribution (OOD) scenarios and certain/uncertain planning decisions. We develop specialized solutions for both OOD detection via latent flow matching and decision uncertainty estimation via an energy-based approach. Our extensive experiments demonstrate that both modules outperform existing approaches, under both open-loop and closed-loop evaluation settings. Our codes are available at: https://github.com/sgNicola/Redoubt.""}",https://openreview.net{'value': '/pdf/92aa8d7ef55c93f7f4108592e032c5e99bee9468.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=lDh9wSb9nP,{'value': 'Regret Lower Bounds for Decentralized Multi-Agent Stochastic Shortest Path Problems'},Utkarsh U. Chavan; Prashant Trivedi; Nandyala Hemachandra,~Utkarsh_U._Chavan1; ~Prashant_Trivedi1; ~Nandyala_Hemachandra1,"{'value': ['Lower Bounds', 'Decentralized MARL', 'Stochastic Shortest Path', 'Reinforcement Learning', 'Feature Design']}","{'value': 'Multi-agent systems (MAS) are central to applications such as swarm robotics and traffic routing, where agents must coordinate in a decentralized manner to achieve a common objective. Stochastic Shortest Path (SSP) problems provide a natural framework for modeling decentralized control in such settings. While the problem of learning in SSP has been extensively studied in single-agent settings, the decentralized multi-agent variant remains largely unexplored. In this work, we take a step towards addressing that gap.  We study decentralized multi-agent SSPs (Dec-MASSPs) under linear function approximation, where the transition dynamics and costs are represented using linear models. Applying novel symmetry-based arguments, we identify the structure of optimal policies. Our main contribution is the first regret lower bound for this setting based on the construction of hard-to-learn instances  for any number of agents, $n$. Our regret lower bound of $\\Omega(\\sqrt{K})$, over $K$ episodes, highlights the inherent learning difficulty in Dec-MASSPs. These insights clarify the learning complexity of decentralized control and can further guide the design of efficient learning algorithms in multi-agent systems.'}",https://openreview.net{'value': '/pdf/b5996aa6d83934ec2186c2ef1a9d00158e9b0143.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=lClK4uBxSG,{'value': 'ModHiFi: Identifying High Fidelity predictive components for Model Modification'},Dhruva Kashyap; Chaitanya Murti; Pranav K Nayak; Tanay Narshana; Chiranjib Bhattacharyya,~Dhruva_Kashyap1; ~Chaitanya_Murti1; ~Pranav_K_Nayak1; ~Tanay_Narshana1; ~Chiranjib_Bhattacharyya2,"{'value': ['Pruning', 'Machine Unlearning']}","{'value': 'Modifying well-trained models for purposes such as pruning or unlearning, without access to training data or the original loss function, is a challenging problem. While techniques exist for such modification, they often require training data, are computationally expensive, or are architecture-specific. To address this, we investigate the fundamental question of identifying components that are critical to the model’s predictive performance, without access to either gradients or the loss function, and with only distributional access such as synthetic data. \n    We theoretically demonstrate that the global reconstruction error is linearly bounded by local reconstruction errors for Lipschitz-continuous networks such as CNNs and well-trained Transformers (which, contrary to existing literature, we find exhibit Lipschitz continuity). This motivates using the locally reconstructive behavior of component subsets to quantify their global importance, via a metric that we term *Subset Fidelity*. In the uncorrelated features setting, selecting individual components via their Subset Fidelity scores is optimal, which we use to propose **ModHiFi**, an algorithm for model modification that requires no training data or loss function access. **ModHiFi-P**, for structured pruning, achieves an 11% speedup over the current state of the art on ImageNet models and competitive performance on language models. **ModHiFi-U**, for classwise unlearning, achieves complete unlearning on CIFAR-10 without fine-tuning and demonstrates competitive performance on Swin Transformers.'}",https://openreview.net{'value': '/pdf/e8b0a7733f128946bbbf4c9b65ec1c7014eb64b0.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=l2YPV99mnB,{'value': 'Individually Fair Diversity Maximization'},Ruien Li; Yanhao Wang,~Ruien_Li1; ~Yanhao_Wang1,"{'value': ['fairness', 'diversity maximization']}","{'value': ""We consider the problem of diversity maximization from the perspective of individual fairness: given a set $P$ of $n$ points in a metric space, we aim to extract a subset $S$ of size $k$ from $P$ so that (1) the diversity of $S$ is maximized and (2) $S$ is \\emph{individually fair} in the sense that every point in $P$ has at least one of its $\\frac{n}{k}$-nearest neighbors as its ``representative'' in $S$. We propose $\\left(O(1), 3\\right)$-bicriteria approximation algorithms for the individually fair variants of the three most common diversity maximization problems, namely, max-min diversification, max-sum diversification, and sum-min diversification. Specifically, the proposed algorithms provide a set of points where every point in the dataset finds a point within a distance at most $3$ times its distance to its $\\frac{n}{k}$-nearest neighbor while achieving a diversity value at most $O(1)$ times lower than the optimal solution. Numerical experiments on real-world and synthetic datasets demonstrate that the proposed algorithms generate solutions that are individually fairer than those produced by unconstrained algorithms and incur only modest losses in diversity.""}",https://openreview.net{'value': '/pdf/1be5bf1af03d90699fd1fc5c5227b6f8bc2ffe98.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=kxv0M6I7Ud,"{'value': 'Physics of Language Models: Part 4.1, Architecture Design and the Magic of Canon Layers'}",Zeyuan Allen-Zhu,~Zeyuan_Allen-Zhu1,"{'value': ['language model', 'architecture design']}","{'value': ""Understanding architectural differences in language models is challenging, especially at academic-scale pretraining (e.g., 1.3B parameters, 100B tokens), where results are often dominated by noise and randomness. To overcome this, we introduce controlled synthetic pretraining tasks that isolate and evaluate core model capabilities. Within this framework, we discover \\emph{Canon layers}: lightweight architectural components—named after the musical term ``canon''—that promote horizontal information flow across neighboring tokens. Canon layers compute weighted sums of nearby token representations and integrate seamlessly into Transformers, linear attention, state-space models, or any sequence architecture.\n\nWe present 12 key results. This includes how Canon layers enhance reasoning depth (e.g., by $2\\times$), reasoning breadth, knowledge manipulation, etc. They lift weak architectures like NoPE to match RoPE, and linear attention to rival SOTA linear models like Mamba2/GDN—validated both through synthetic tasks and real-world academic-scale pretraining.\nThis synthetic playground offers an \\emph{economical, principled path} to isolate core model capabilities often obscured at academic scales. Equipped with infinite high-quality data, it may even \\emph{predict} how future architectures will behave as training pipelines improve—e.g., through better data curation or RL-based post-training—unlocking deeper reasoning and hierarchical inference.""}",https://openreview.net{'value': '/pdf/56709bf597f52ab914bed46cc002d280d0802236.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=kvI0QTVRQD,{'value': 'Equivariance by Contrast: Identifiable Equivariant Embeddings from Unlabeled Finite Group Actions'},Tobias Schmidt; Steffen Schneider; Matthias Bethge,~Tobias_Schmidt1; ~Steffen_Schneider1; ~Matthias_Bethge1,"{'value': ['equivariance', 'identifiability', 'representation learning', 'group theory']}","{'value': 'We propose Equivariance by Contrast (EbC) to learn equivariant embeddings from observation pairs $(\\mathbf{y}, g \\cdot \\mathbf{y})$, where $g$ is drawn from a finite group acting on the data. Our method jointly learns a latent space and a group representation in which group actions correspond to invertible linear maps—without relying on group-specific inductive biases. We validate our approach on the infinite dSprites dataset with structured transformations defined by the finite group $G:= (R_m \\times \\mathbb{Z}_n \\times \\mathbb{Z}_n)$, combining discrete rotations and periodic translations. The resulting embeddings exhibit high-fidelity equivariance, with group operations faithfully reproduced in latent space. On synthetic data, we further validate the approach on the non-abelian orthogonal group $O(n)$ and the general linear group $GL(n)$. We also provide a theoretical proof for identifiability. While broad evaluation across diverse group types on real-world data remains future work, our results constitute the first successful demonstration of general-purpose encoder-only equivariant learning from group action observations alone, including non-trivial non-abelian groups and a product group motivated by modeling affine equivariances in computer vision.'}",https://openreview.net{'value': '/pdf/79cf0718a8cf24f4e11dd458d8438e17fac442f7.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=krG6UHAvYr,{'value': 'MisoDICE: Multi-Agent Imitation from Mixed-Quality Demonstrations'},The Viet Bui; Tien Anh Mai; Thanh Hong Nguyen,~The_Viet_Bui1; ~Tien_Anh_Mai1; ~Thanh_Hong_Nguyen1,"{'value': ['Multi-Agent Reinforcement Learning', 'Offline Imitation Learning', 'Large Language Models', 'Value Factorization']}","{'value': 'We study offline imitation learning (IL) in cooperative multi-agent settings, where demonstrations have unlabeled mixed quality - containing both expert and suboptimal trajectories. Our proposed solution is structured in two stages: trajectory labeling and multi-agent imitation learning, designed jointly to enable effective learning from heterogeneous, unlabeled data. In the first stage, we combine advances in large language models and preference-based reinforcement learning to construct a progressive labeling pipeline that distinguishes expert-quality trajectories. In the second stage, we introduce MisoDICE, a novel multi-agent IL algorithm that leverages these labels to learn robust policies while addressing the computational complexity of large joint state-action spaces. By extending the popular single-agent DICE framework to multi-agent settings with a new value decomposition and mixing architecture, our method yields a convex policy optimization objective and ensures consistency between global and local policies. We evaluate MisoDICE on multiple standard multi-agent RL benchmarks and demonstrate superior performance, especially when expert data is scarce.'}",https://openreview.net{'value': '/pdf/4b2409e02a7e2d01eabd842a20cb992608dc0256.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=koG76YqOwo,{'value': 'HiFlow: Training-free High-Resolution Image Generation with Flow-Aligned Guidance'},Jiazi Bu; Pengyang Ling; Yujie Zhou; Pan Zhang; Tong Wu; Xiaoyi Dong; Yuhang Zang; Yuhang Cao; Dahua Lin; Jiaqi Wang,~Jiazi_Bu1; ~Pengyang_Ling1; ~Yujie_Zhou6; ~Pan_Zhang1; ~Tong_Wu2; ~Xiaoyi_Dong1; ~Yuhang_Zang1; ~Yuhang_Cao3; ~Dahua_Lin1; ~Jiaqi_Wang1,"{'value': ['high-resolution generation', 'text-to-image generation']}","{'value': ""Text-to-image (T2I) diffusion/flow models have drawn considerable attention recently due to their remarkable ability to deliver flexible visual creations. Still, high-resolution image synthesis presents formidable challenges due to the scarcity and complexity of high-resolution content. Recent approaches have investigated training-free strategies to enable high-resolution image synthesis with pre-trained models. However, these techniques often struggle with generating high-quality visuals and tend to exhibit artifacts or low-fidelity details, as they typically rely solely on the endpoint of the low-resolution sampling trajectory while neglecting intermediate states that are critical for preserving structure and synthesizing finer detail. To this end,  we present HiFlow, a training-free and model-agnostic framework to unlock the resolution potential of pre-trained flow models. Specifically, HiFlow establishes a virtual reference flow within the high-resolution space that effectively captures the characteristics of low-resolution flow information, offering guidance for high-resolution generation through three key aspects: initialization alignment for low-frequency consistency, direction alignment for structure preservation, and acceleration alignment for detail fidelity. By leveraging such flow-aligned guidance, HiFlow substantially elevates the quality of high-resolution image synthesis of T2I models and demonstrates versatility across their personalized variants. Extensive experiments validate HiFlow's capability in achieving superior high-resolution image quality over state-of-the-art methods.""}",https://openreview.net{'value': '/pdf/54cd3b7681e9b6aac8f25483a2894979905b44fe.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=klOr9y9nMU,{'value': 'CORE: Reducing UI Exposure in Mobile Agents via Collaboration Between Cloud and Local LLMs'},Gucongcong Fan; Chaoyue Niu; chengfei lv; Fan Wu; Guihai Chen,~Gucongcong_Fan1; ~Chaoyue_Niu1; ~chengfei_lv1; ~Fan_Wu10; ~Guihai_Chen3,"{'value': ['Mobile Agents', 'Large Language Models', 'Collaboration', 'UI Exposure Reduction']}","{'value': 'Mobile agents rely on Large Language Models (LLMs) to plan and execute tasks on smartphone user interfaces (UIs). While cloud-based LLMs achieve high task accuracy, they require uploading the full UI state at every step, exposing unnecessary and often irrelevant information. In contrast, local LLMs avoid UI uploads but suffer from limited capacity, resulting in lower task success rates. We propose $\\textbf{CORE}$, a $\\textbf{CO}$llaborative framework that combines the strengths of cloud and local LLMs to $\\textbf{R}$educe UI $\\textbf{E}$xposure, while maintaining task accuracy for mobile agents. CORE comprises three key components: (1) $\\textbf{Layout-aware block partitioning}$, which groups semantically related UI elements based on the XML screen hierarchy; (2) $\\textbf{Co-planning}$, where local and cloud LLMs collaboratively identify the current sub-task; and (3) $\\textbf{Co-decision-making}$, where the local LLM ranks relevant UI blocks, and the cloud LLM selects specific UI elements within the top-ranked block. CORE further introduces a multi-round accumulation mechanism to mitigate local misjudgment or limited context. Experiments across diverse mobile apps and tasks show that CORE reduces UI exposure by up to 55.6\\% while maintaining task success rates slightly below cloud-only agents, effectively mitigating unnecessary privacy exposure to the cloud. The code is available at https://github.com/Entropy-Fighter/CORE.'}",https://openreview.net{'value': '/pdf/5b9c63b9b600fd293798deb51960a50373bb0faf.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=kXieirlPjF,{'value': 'Agentic RL Scaling Law: Spontaneous Code Execution for Mathematical Problem Solving'},Xinji Mai; Haotian Xu; Xing W; Weinong Wang; Yingying Zhang; Wenqiang Zhang,~Xinji_Mai1; ~Haotian_Xu1; ~Xing_W1; ~Weinong_Wang1; ~Yingying_Zhang2; ~Wenqiang_Zhang1,"{'value': ['Agentic RL', 'Code Execution', 'LLMs', 'Math']}","{'value': 'Large Language Models (LLMs) often struggle with mathematical reasoning tasks requiring precise, verifiable computation. While Reinforcement Learning (RL) from outcome-based rewards  enhances text-based reasoning, understanding how agents autonomously learn to leverage external tools like code execution remains crucial. We investigate RL from outcome-based rewards for Tool-Integrated Reasoning, ZeroTIR, training base LLMs to spontaneously generate and execute Python code for mathematical problems without supervised tool-use examples. Our central contribution is we demonstrate that as RL training progresses, key metrics scale predictably. Specifically, we observe strong positive correlations where increased training steps lead to increases in the spontaneous code execution frequency, the average response length, and, critically, the final task accuracy. This suggests a quantifiable relationship between computational effort invested in training and the emergence of effective, tool-augmented reasoning strategies. We implement a robust framework featuring a decoupled code execution environment and validate our findings across standard RL algorithms and frameworks. Experiments show ZeroTIR significantly surpasses non-tool ZeroRL baselines on challenging math benchmarks. Our findings provide a foundational understanding of how autonomous tool use is acquired and scales within Agent RL, offering a reproducible benchmark for future studies. Code is released at \\href{https://github.com/yyht/openrlhf_async_pipline}{https://github.com/yyht/openrlhf\\_async\\_pipline}.'}",https://openreview.net{'value': '/pdf/6d8a6cfbc785966d9381495a786eea81de48d681.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=kVz9uvqUna,{'value': 'On the Closed-Form of Flow Matching: Generalization Does Not Arise from Target Stochasticity'},Quentin Bertrand; Anne Gagneux; Mathurin Massias; Rémi Emonet,~Quentin_Bertrand1; ~Anne_Gagneux1; ~Mathurin_Massias1; ~Rémi_Emonet1,"{'value': ['flow matching', 'generalization', 'memorization']}","{'value': 'Modern deep generative models can now produce high-quality synthetic samples that are often indistinguishable from real training data. A growing body of research aims to understand why recent methods, such as diffusion and flow matching techniques, generalize so effectively. Among the proposed explanations are the inductive biases of deep learning architectures and the stochastic nature of the conditional flow matching loss. In this work, we rule out the noisy nature of the loss as a key factor driving generalization in flow matching.\nFirst, we empirically show that in high-dimensional settings, the stochastic and closed-form versions of the flow matching loss yield nearly equivalent losses. Then, using state-of-the-art flow matching models on standard image datasets, we demonstrate that both variants achieve comparable statistical performance, with the surprising observation that using the closed-form can even improve performance.'}",https://openreview.net{'value': '/pdf/891239399aeb4629291513a63696bb354288ee3c.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=kThBNZTMaw,{'value': 'Learning Across the Gap: Hybrid Multi-armed Bandits with Heterogeneous Offline and Online Data'},Qijia He; Minghan Wang; Xutong Liu; Zhiyong Wang; Fang Kong,~Qijia_He2; ~Minghan_Wang2; ~Xutong_Liu1; ~Zhiyong_Wang9; ~Fang_Kong2,"{'value': ['online learning', 'multi-armed bandit', 'dueling bandit', 'hybrid feedback']}","{'value': 'The multi-armed bandit (MAB) is a fundamental online decision-making framework that has been extensively studied over the past two decades. To mitigate the high cost and slow convergence of purely online learning, modern MAB approaches have explored _hybrid_ paradigms that leverage offline data to warm-start online learning. However, existing approaches face a significant limitation by assuming that the offline and online data are homogeneous—they share the same feedback structure and are drawn from the same underlying distribution. This assumption is often violated in practice, where offline data often originate from diverse sources and evolving environments, resulting in feedback heterogeneity and distributional shifts. In this work, we tackle the challenge of learning across this offline-online gap by developing a general hybrid bandit framework that incorporates heterogeneous offline data to improve online performance. We study two hybrid settings: (1) using reward-based offline data to accelerate online learning in preference-based bandits (i.e., dueling bandits), and (2) using preference-based offline data to improve online standard MAB algorithms. For both settings, we design novel algorithms and derive tight regret bounds that match or improve upon existing benchmarks despite heterogeneity. Empirical evaluations on both synthetic and real-world datasets show that our proposed methods significantly outperform baseline algorithms.'}",https://openreview.net{'value': '/pdf/121995235cb773f4f096ef906d2b93a37cc4db0d.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=kRZVz1qEqa,{'value': 'Teaching Language Models to Reason with Tools'},Chengpeng Li; Zhengyang Tang; Ziniu Li; Mingfeng Xue; Keqin Bao; Tian Ding; Ruoyu Sun; Benyou Wang; Xiang Wang; Junyang Lin; Dayiheng Liu,~Chengpeng_Li1; ~Zhengyang_Tang1; ~Ziniu_Li1; ~Mingfeng_Xue1; ~Keqin_Bao1; ~Tian_Ding1; ~Ruoyu_Sun1; ~Benyou_Wang2; ~Xiang_Wang6; ~Junyang_Lin1; ~Dayiheng_Liu1,"{'value': ['Tool-integrated Reasoning', 'Large Reasoning Model', 'Long Chain-of-Thought']}","{'value': ""Large reasoning models (LRMs) like OpenAI-o1 have shown impressive capabilities in natural language reasoning. However, these models frequently demonstrate inefficiencies or inaccuracies when tackling complex mathematical operations. While integrating computational tools such as Code Interpreters (CIs) offers a promising solution, it introduces a critical challenge: a conflict between the model's internal, probabilistic reasoning and the external, deterministic knowledge provided by the CI, which often leads models to unproductive deliberation. To overcome this, we introduce CoRT (Code-Optimized Reasoning Training), a  post-training framework designed to teach LRMs to effectively utilize CIs. We propose **Hint-Engineering**, a new data synthesis strategy that strategically injects diverse hints at optimal points within reasoning paths. This approach generates high-quality, code-integrated reasoning data specifically tailored to optimize LRM-CI interaction. Using this method, we have synthesized 30 high-quality samples to post-train models ranging from 1.5B to 32B parameters through supervised fine-tuning. CoRT further refines the multi-round interleaving of external CI usage and internal thinking by employing rejection sampling and reinforcement learning. Our experimental evaluations demonstrate CoRT's effectiveness, yielding absolute improvements of 4\\% and 8\\% on DeepSeek-R1-Distill-Qwen-32B and DeepSeek-R1-Distill-Qwen-1.5B, respectively, across five challenging mathematical reasoning datasets. Moreover, CoRT significantly enhances efficiency, reducing token usage by approximately 30\\% for the 32B model and 50\\% for the 1.5B model compared to pure natural language reasoning baselines. The models and code are available at: [this url](https://github.com/ChengpengLi1003/CoRT).""}",https://openreview.net{'value': '/pdf/406d2cc67059647e62684368005578debbc188e9.pdf'},{'abstract_filter': 'Data Synthesis'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=kN0YHWGDPH,"{'value': 'Effortless, Simulation-Efficient Bayesian Inference using Tabular Foundation Models'}",Julius Vetter; Manuel Gloeckler; Daniel Gedon; Jakob H. Macke,~Julius_Vetter2; ~Manuel_Gloeckler1; ~Daniel_Gedon1; ~Jakob_H._Macke1,"{'value': ['simulation-based inference', 'foundation models', 'Bayesian inference', 'density estimation']}","{'value': 'Simulation-based inference (SBI) offers a flexible and general approach to performing Bayesian inference: In SBI, a neural network is trained on synthetic data simulated from a model and used to rapidly infer posterior distributions for observed data. \nA key goal for SBI is to achieve accurate inference with as few simulations as possible, especially for expensive simulators. \nIn this work, we address this challenge by repurposing recent probabilistic foundation models for tabular data: We show how tabular foundation models---specifically TabPFN---can be used as pre-trained autoregressive conditional density estimators for SBI. \nWe propose Neural Posterior Estimation with Prior-data Fitted Networks (NPE-PFN) and show that it is competitive with current SBI approaches in terms of accuracy for both benchmark tasks and two complex scientific inverse problems. Crucially, it often substantially outperforms them in terms of simulation efficiency, sometimes requiring orders of magnitude fewer simulations. NPE-PFN eliminates the need for selecting and training an inference network and tuning its hyperparameters. We also show that it exhibits superior robustness to model misspecification and can be scaled to simulation budgets that exceed the context size limit of TabPFN.\nNPE-PFN provides a new direction for SBI, where training-free, general-purpose inference models offer efficient, easy-to-use, and flexible solutions for a wide range of stochastic inverse problems.'}",https://openreview.net{'value': '/pdf/52786bb300fd88af191588dc910352e9698707f3.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=kL2pnzClyD,{'value': 'Efficient Parametric SVD of Koopman Operator for Stochastic Dynamical Systems'},Minchan Jeong; Jongha Jon Ryu; Se-Young Yun; Gregory W. Wornell,~Minchan_Jeong1; ~Jongha_Jon_Ryu1; ~Se-Young_Yun1; ~Gregory_W._Wornell1,"{'value': ['Koopman operator', 'spectral decomposition', 'singular value decomposition', 'neural networks', 'low-rank approximation', 'DMD', 'VAMP', 'DPNets']}","{'value': 'The Koopman operator provides a principled framework for analyzing nonlinear dynamical systems through linear operator theory. Recent advances in dynamic mode decomposition (DMD) have shown that trajectory data can be used to identify dominant modes of a system in a data-driven manner. Building on this idea, deep learning methods such as VAMPnet and DPNet have been proposed to learn the leading singular subspaces of the Koopman operator. \nHowever, these methods require backpropagation through potentially numerically unstable operations on empirical second moment matrices, such as singular value decomposition and matrix inversion, during objective computation, which can introduce biased gradient estimates and hinder scalability to large systems.\nIn this work, we propose a scalable and conceptually simple method for learning the top-$k$ singular functions of the Koopman operator for stochastic dynamical systems based on the idea of low-rank approximation. Our approach eliminates the need for unstable linear-algebraic operations and integrates easily into modern deep learning pipelines. Empirical results demonstrate that the learned singular subspaces are both reliable and effective for downstream tasks such as eigen-analysis and multi-step prediction.'}",https://openreview.net{'value': '/pdf/a0a37f9f8b45f6d757dee34d70dd4d1da6f1106b.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=kGMRb4jbTP,{'value': 'ConTextTab: A Semantics-Aware Tabular In-Context Learner'},Marco Spinaci; Marek Polewczyk; Maximilian Schambach; Sam Thelin,~Marco_Spinaci1; ~Marek_Polewczyk1; ~Maximilian_Schambach1; ~Sam_Thelin1,"{'value': ['tabular learning', 'semantics', 'in-context learning', 'deep learning']}","{'value': 'Tabular in-context learning (ICL) has recently achieved state-of-the-art (SOTA) performance on several tabular prediction tasks. Previously restricted to classification problems on small tables, recent advances such as TabPFN and TabICL have extended its use to larger datasets. Although current table-native ICL architectures are architecturally efficient and well-adapted to tabular data structures, their exclusive training on synthetic data limits their ability to fully leverage the rich semantics and world knowledge contained in real-world tabular data. At the other end of the spectrum, tabular ICL models based on pretrained large language models such as TabuLa-8B integrate deep semantic understanding and world knowledge but are only able to make use of a small amount of context due to inherent architectural limitations. With the aim to combine the best of both these worlds, we introduce ConTextTab, integrating semantic understanding and alignment into a table-native ICL framework. By employing specialized embeddings for different data modalities and by training on large-scale real-world tabular data, our model is competitive with SOTA across a broad set of benchmarks while setting a new standard on the semantically rich CARTE benchmark. Code and model checkpoints are available at: https://github.com/SAP-samples/contexttab .'}",https://openreview.net{'value': '/pdf/eb222da4482a3a2e1f2ed0951eba25925ac9781c.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=kE4XEY7Bbc,{'value': 'Model–Behavior Alignment under Flexible Evaluation: When the Best-Fitting Model Isn’t the Right One'},Itamar Avitan; Tal Golan,~Itamar_Avitan1; ~Tal_Golan1,{'value': ['Representational Alignment; Model Recovery; Deep Neural Networks; Similarity Judgments;Representational Geometry;Cognitve Computational modeling']},"{'value': 'Linearly transforming stimulus representations of deep neural networks yields\nhigh-performing models of behavioral and neural responses to complex stimuli.\nBut does the test accuracy of such predictions identify genuine representational\nalignment? We addressed this question through a large-scale model-recovery study.\nTwenty diverse vision models were linearly aligned to 4.5 million behavioral judg-\nments from the THINGS odd-one-out dataset and calibrated to reproduce human\nresponse variability. For each model in turn, we sampled synthetic responses\nfrom its probabilistic predictions, fitted all candidate models to the synthetic data,\nand tested whether the data-generating model would re-emerge as the best predictor of the simulated data. Model recovery accuracy improved with training-set\nsize but plateaued below 80%, even at millions of simulated trials. Regression\nanalyses linked misidentification primarily to shifts in representational geometry\ninduced by the linear transformation, as well as to the effective dimensionality\nof the transformed features. These findings demonstrate that, even with massive\nbehavioral data, overly flexible alignment metrics may fail to guide us toward artificial representations that are genuinely more human-aligned. Model comparison\nexperiments must be designed to balance the trade-off between predictive accuracy\nand identifiability—ensuring that the best-fitting model is also the right one.'}",https://openreview.net{'value': '/pdf/9c226c781bde9394b2d0d061544eb50e2f42ca96.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=k5TbfYPYuc,{'value': 'Generating Multi-Table Time Series EHR from Latent Space with Minimal Preprocessing'},Eunbyeol Cho; Jiyoun Kim; Minjae Lee; Sungjin Park; Edward Choi,~Eunbyeol_Cho1; ~Jiyoun_Kim1; ~Minjae_Lee2; ~Sungjin_Park1; ~Edward_Choi1,"{'value': ['Electronic Health Records (EHR)', 'EHR synthesis', 'time-series EHR', 'multi-table data']}","{'value': 'Electronic Health Records (EHR) are time-series relational databases that record patient interactions and medical events over time, serving as a critical resource for healthcare research and applications. However, privacy concerns and regulatory restrictions limit the sharing and utilization of such sensitive data, necessitating the generation of synthetic EHR datasets.\nUnlike previous EHR synthesis methods—which typically generate medical records consisting of expert-chosen features (e.g., a few vital signs, structured codes only)—we introduce RawMed, the first framework to synthesize multi-table, time-series EHR data that closely resembles raw EHRs.\nUsing text-based representation and compression techniques, RawMed captures complex structures and temporal dynamics with minimal lossy preprocessing. \nWe also propose a new evaluation framework for multi-table time-series synthetic EHRs, assessing distributional similarity, inter-table relationships, temporal dynamics, and privacy. Validated on two open-source EHR datasets, RawMed outperforms baseline models in fidelity and utility. The code is available at [https://github.com/eunbyeol-cho/RawMed](https://github.com/eunbyeol-cho/RawMed)'}",https://openreview.net{'value': '/pdf/11edb3f9631b6570878f623f49461b1de07dc165.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=k1fbdnwjCH,{'value': 'Heterogeneous Graph Transformers for Simultaneous Mobile Multi-Robot Task Allocation and Scheduling under Temporal Constraints'},Batuhan Altundas; Shengkang Chen; Shivika Singh; Shivangi Deo; Minwoo Cho; Matthew Craig Gombolay,~Batuhan_Altundas1; ~Shengkang_Chen1; ~Shivika_Singh1; ~Shivangi_Deo1; ~Minwoo_Cho2; ~Matthew_Craig_Gombolay1,"{'value': ['Task Allocation and Scheduling', 'Multi-Agent Coordination', 'Graph Neural Networks']}","{'value': 'Coordinating large teams of heterogeneous mobile agents to perform complex tasks efficiently has scalability bottlenecks in feasible and optimal task scheduling, with critical applications in logistics, manufacturing, and disaster response. Existing task allocation and scheduling methods, including heuristics and optimization-based solvers, often fail to scale and overlook inter-task dependencies and agent heterogeneity. We propose a novel Simultaneous Decision-Making model for Heterogeneous Multi-Agent Task Allocation and Scheduling (HM-MATAS), built on a Residual Heterogeneous Graph Transformer with edge and node-level attention. Our model encodes agent capabilities, travel times, and temporospatial constraints into a rich graph representation and is trainable via reinforcement learning. Trained on small-scale problems (10 agents, 20 tasks), our model generalizes effectively to significantly larger scenarios (up to 40 agents and 200 tasks), enabling fast, one-shot task assignment and scheduling. Our simultaneous model outperforms classical heuristics by assigning 164.10\\% more feasible tasks given temporal constraints in 3.83\\% of the time, metaheuristics by 201.54\\% in 0.01\\% of the time and exact solver by 231.73\\% in 0.03\\% of the time, while achieving $20\\times$-to-$250\\times$ speedup from prior graph-based methods across scales.'}",https://openreview.net{'value': '/pdf/c132589a72ce5fd8c489d67b73b34261d138def2.pdf'},{'abstract_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=k0wyi4cOGy,{'value': 'KARMA: Leveraging Multi-Agent LLMs for Automated Knowledge Graph Enrichment'},Yuxing Lu; Wei Wu; Xukai Zhao; Rui Peng; Jinzhuo Wang,~Yuxing_Lu1; ~Wei_Wu28; ~Xukai_Zhao1; ~Rui_Peng3; ~Jinzhuo_Wang1,"{'value': ['Knowledge Graphs', 'Multi Agent System']}","{'value': 'Maintaining comprehensive and up-to-date knowledge graphs (KGs) is critical for modern AI systems, but manual curation struggles to scale with the rapid growth of scientific literature. This paper presents KARMA, a novel framework employing multi-agent large language models (LLMs) to automate KG enrichment through structured analysis of unstructured text. Our approach employs nine collaborative agents, spanning entity discovery, relation extraction, schema alignment, and conflict resolution that iteratively parse documents, verify extracted knowledge, and integrate it into existing graph structures while adhering to domain-specific schema. Experiments on 1,200 PubMed articles from three different domains demonstrate the effectiveness of KARMA in knowledge graph enrichment, with the identification of up to 38,230 new entities while achieving 83.1\\% LLM-verified correctness and reducing conflict edges by 18.6\\% through multi-layer assessments.'}",https://openreview.net{'value': '/pdf/307d3a55037031950ed1e7b9a84ab6abf7eb8f4b.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=jvq8nzOUp8,{'value': 'Safe + Safe = Unsafe? Exploring How Safe Images Can Be Exploited to Jailbreak Large Vision-Language Models'},Chenhang Cui; Gelei Deng; An Zhang; Jingnan Zheng; Yicong Li; Lianli Gao; Tianwei Zhang; Tat-Seng Chua,~Chenhang_Cui1; ~Gelei_Deng1; ~An_Zhang2; ~Jingnan_Zheng1; ~Yicong_Li1; ~Lianli_Gao1; ~Tianwei_Zhang1; ~Tat-Seng_Chua2,{'value': ['Large Vision-Language Models; Jailbreak Attack']},"{'value': ""Recent advances in Large Vision-Language Models (LVLMs) have showcased strong reasoning abilities across multiple modalities, achieving significant breakthroughs in various real-world applications.\nDespite this great success, the safety guardrail of LVLMs may not cover the unforeseen domains introduced by the visual modality. \nExisting studies primarily focus on eliciting LVLMs to generate harmful responses via carefully crafted image-based jailbreaks designed to bypass alignment defenses.\nIn this study, we reveal that a safe image can be exploited to achieve the same jailbreak consequence when combined with additional safe images and prompts.\nThis stems from two fundamental properties of LVLMs: universal reasoning capabilities and safety snowball effect.\nBuilding on these insights, we propose Safety Snowball Agent (SSA), a novel agent-based framework leveraging agents' autonomous and tool-using abilities to jailbreak LVLMs.\nSSA operates through two principal stages: (1) initial response generation, where tools generate or retrieve jailbreak images based on potential harmful intents, and (2) harmful snowballing, where refined subsequent prompts induce progressively harmful outputs.\nOur experiments demonstrate that SSA can use nearly any image to induce LVLMs to produce unsafe content, achieving high success jailbreaking rates against the latest LVLMs. \nUnlike prior works that exploit alignment flaws, SSA leverages the inherent properties of LVLMs, presenting a profound challenge for enforcing safety in generative multimodal systems.""}",https://openreview.net{'value': '/pdf/8babb592735eb9e46455028c5428dfc816f08161.pdf'},{'abstract_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=jvObbvshjE,{'value': 'T-REGS: Minimum Spanning Tree Regularization for Self-Supervised Learning'},Julie Mordacq; David Loiseaux; Vicky Kalogeiton; Steve Oudot,~Julie_Mordacq1; ~David_Loiseaux1; ~Vicky_Kalogeiton2; ~Steve_Oudot1,"{'value': ['self-supervised learning', 'minimum spanning tree', 'dimensional collapse', 'dimension estimation', 'topological data analysis']}","{'value': 'Self-supervised learning (SSL) has emerged as a powerful paradigm for learning representations without labeled data, often by enforcing invariance to input transformations such as rotations or blurring.\nRecent studies have highlighted two pivotal properties for effective representations: (i) avoiding dimensional collapse-where the learned features occupy only a low-dimensional subspace, and (ii) enhancing uniformity of the induced distribution.\nIn this work, we introduce T-REGS, a simple regularization framework for SSL based on the length of the Minimum Spanning Tree (MST) over the learned representation.\nWe provide theoretical analysis demonstrating that T-REGS simultaneously mitigates dimensional collapse and promotes distribution uniformity on arbitrary compact Riemannian manifolds.\nSeveral experiments on synthetic data and on classical SSL benchmarks validate the effectiveness of our approach at enhancing representation quality.'}",https://openreview.net{'value': '/pdf/07ba9b5383d27ba34f5436301740cd7c6ec3ee70.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=jusQeCotOF,{'value': 'Uncertainty-Calibrated Prediction of Randomly-Timed Biomarker Trajectories with Conformal Bands'},Vasiliki Tassopoulou; Charis Stamouli; Haochang Shou; George J. Pappas; Christos Davatzikos,~Vasiliki_Tassopoulou1; ~Charis_Stamouli1; ~Haochang_Shou1; ~George_J._Pappas1; ~Christos_Davatzikos5,"{'value': ['Biomarker Trajectories', 'Conformal Prediction', 'Uncertainty Quantification']}","{'value': 'We introduce a novel conformal prediction framework for constructing conformal prediction bands with high probability around biomarker trajectories observed at subject-specific, randomly-timed follow-up visits. Existing conformal methods typically assume fixed time grids, limiting their applicability in longitudinal clinical studies. Our approach addresses this limitation by defining a time-varying nonconformity score that normalizes prediction errors using model-derived uncertainty estimates, enabling conformal inference at arbitrary time points. We evaluate our method on two well-established brain biomarkers—hippocampal and ventricular volume—using a range of standard and state-of-the-art predictors. Across models, our conformalized predictors consistently achieve nominal coverage with tighter prediction intervals compared to baseline uncertainty estimates. To further account for population heterogeneity, we develop group-conditional conformal bands with formal coverage guarantees across clinically relevant and high-risk subgroups. Finally, we demonstrate the clinical utility of our approach in identifying subjects at risk of progression to Alzheimer’s disease. We introduce an uncertainty-aware progression metric based on the lower conformal bound and show that it enables the identification of 17.5\\% more high-risk subjects compared to standard slope-based methods, highlighting the value of uncertainty calibration in real-world clinical decision making. We make the code available at \\href{https://github.com/vatass/ConformalBiomarkerTrajectories}{\\texttt{github.com/vatass/ConformalBiomarkerTrajectories}}.'}",https://openreview.net{'value': '/pdf/9810b8cb9f78683d770f9c706688f4b26e7a1d01.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=jtMDzggo6M,{'value': 'Learning Sparse Approximate Inverse Preconditioners for Conjugate Gradient Solvers on GPUs'},Zherui Yang; Zhehao Li; Kangbo Lyu; Yixuan Li; Tao Du; Ligang Liu,~Zherui_Yang1; ~Zhehao_Li2; ~Kangbo_Lyu1; ~Yixuan_Li18; ~Tao_Du1; ~Ligang_Liu1,"{'value': ['Graph Neural Networks', 'Preconditioning', 'GPU Computing', 'Iterative Solvers', 'Scientific Computing']}","{'value': ""The conjugate gradient solver (CG) is a prevalent method for solving symmetric and positive definite linear systems $\\mathbf{Ax} = \\mathbf{b}$, where effective preconditioners are crucial for fast convergence. Traditional preconditioners rely on prescribed algorithms to offer rigorous theoretical guarantees, while limiting their ability to exploit optimization from data. Existing learning-based methods often utilize Graph Neural Networks (GNNs) to improve the performance and speed up the construction. However, their reliance on incomplete factorization leads to significant challenges: the associated triangular solve hinders GPU parallelization in practice, and introduces long-range dependencies which are difficult for GNNs to model. To address these issues, we propose a learning-based method to generate GPU-friendly preconditioners, particularly using GNNs to construct Sparse Approximate Inverse (SPAI) preconditioners, which avoids triangular solves and requires only two matrix-vector products at each CG step. The locality of matrix-vector product is compatible with the local propagation mechanism of GNNs. The flexibility of GNNs also allows our approach to be applied in a wide range of scenarios. Furthermore, we introduce a statistics-based scale-invariant loss function. Its design matches CG's property that the convergence rate depends on the condition number, rather than the absolute scale of $\\mathbf{A}$, leading to improved performance of the learned preconditioner. Evaluations on three PDE-derived datasets and one synthetic dataset demonstrate that our method outperforms standard preconditioners (Diagonal, IC, and traditional SPAI) and previous learning-based preconditioners on GPUs. We reduce solution time on GPUs by 40%-53% (68%-113% faster), along with better condition numbers and superior generalization performance.""}",https://openreview.net{'value': '/pdf/af810ce4ea38e0582b81eea5c66014732023a636.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=jmLCBLeEC4,{'value': 'AdvEDM: Fine-grained Adversarial Attack against VLM-based Embodied Agents'},Yichen Wang; Hangtao Zhang; Hewen Pan; Ziqi Zhou; Xianlong Wang; Peijin Guo; Lulu Xue; Shengshan Hu; Minghui Li; Leo Yu Zhang,~Yichen_Wang8; ~Hangtao_Zhang1; ~Hewen_Pan1; ~Ziqi_Zhou2; ~Xianlong_Wang1; ~Peijin_Guo2; ~Lulu_Xue1; ~Shengshan_Hu1; ~Minghui_Li2; ~Leo_Yu_Zhang1,"{'value': ['Adversarial Attack', 'Vision-Language Model', 'Embodied AI']}","{'value': ""Vision-Language Models (VLMs), with their strong reasoning and planning capabilities, are widely used in embodied decision-making (EDM) tasks in embodied agents, such as autonomous driving and robotic manipulation. Recent research has increasingly explored adversarial attacks on VLMs to reveal their vulnerabilities. However, these attacks either rely on overly strong assumptions, requiring full knowledge of the victim VLM, which is impractical for attacking VLM-based agents, or exhibit limited effectiveness. The latter stems from disrupting most semantic information in the image, which leads to a misalignment between the perception and the task context defined by system prompts. This inconsistency interrupts the VLM's reasoning process, resulting in invalid outputs that fail to affect interactions in the physical world. To this end, we propose a fine-grained adversarial attack framework, AdvEDM, which modifies the VLM's perception of only a few key objects while preserving the semantics of the remaining regions. This attack effectively reduces conflicts with the task context, making VLMs output valid but incorrect decisions and affecting the actions of agents, thus posing a more substantial safety threat in the physical world. We design two variants of based on this framework, AdvEDM-R and AdvEDM-A, which respectively remove the semantics of a specific object from the image and add the semantics of a new object into the image. The experimental results in both general scenarios and EDM tasks demonstrate  fine-grained control and excellent attack performance.""}",https://openreview.net{'value': '/pdf/60a128518fe424bd2b402f8e71d6a205bf71aa89.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=jj0nJQYFlW,{'value': 'Simultaneous Modeling of Protein Conformation and Dynamics via Autoregression'},Yuning Shen; Lihao Wang; Huizhuo Yuan; Yan Wang; Bangji Yang; Quanquan Gu,~Yuning_Shen1; ~Lihao_Wang1; ~Huizhuo_Yuan1; ~Yan_Wang46; ~Bangji_Yang1; ~Quanquan_Gu1,"{'value': ['Protein Conformation', 'Generative Modeling', 'Molecular Dynamics', 'Diffusion Models', 'Language Models']}","{'value': 'Understanding protein dynamics is critical for elucidating their biological functions. \nThe increasing availability of molecular dynamics (MD) data enables the training of deep generative models to efficiently explore the conformational space of proteins.\nHowever, existing approaches either fail to explicitly capture the temporal dependencies between conformations or do not support direct generation of time-independent samples.\nTo address these limitations, we introduce *ConfRover*, an autoregressive model that simultaneously learns protein conformation and dynamics from MD trajectory data, supporting both time-dependent and time-independent sampling.\nAt the core of our model is a modular architecture comprising: (i) an *encoding layer*, adapted from protein folding models, that embeds protein-specific information and conformation at each time frame into a latent space; (ii) a *temporal module*, a sequence model that captures conformational dynamics across frames; and (iii) an SE(3) diffusion model as the *structure decoder*, generating conformations in continuous space.\nExperiments on ATLAS, a large-scale protein MD dataset of diverse structures, demonstrate the effectiveness of our model in learning conformational dynamics and supporting a wide range of downstream tasks. \n*ConfRover* is the first model to sample both protein conformations and trajectories within a single framework, offering a novel and flexible approach for learning from protein MD data.'}",https://openreview.net{'value': '/pdf/8049776790397ae4bd55dbc09aa3105a978e06ea.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=ja3p9Dylmh,{'value': 'HairFree: Compositional 2D Head Prior for Text-Driven 360° Bald Texture Synthesis'},Mirela Ostrek; Michael J. Black; Justus Thies,~Mirela_Ostrek1; ~Michael_J._Black1; ~Justus_Thies1,"{'value': ['Text-to-Image Synthesis', 'Human Head Texturing', '3D Face Synthesis', 'Facial Texture Generation', 'FLAME Head Mesh Texturing', 'Generative Texture Models', '3D Texture Mapping', 'Image Synthesis', 'Bald Textures']}","{'value': 'Synthesizing high-quality 3D head textures is crucial for gaming, virtual reality, and digital humans. Achieving seamless 360° textures typically requires expensive multi-view datasets with precise tracking. However, traditional methods struggle without back-view data or precise geometry, especially for human heads, where even minor inconsistencies disrupt realism. We introduce HairFree, an unsupervised texturing framework guided by textual descriptions and 2D diffusion priors, producing high-consistency 360° bald head textures—including non-human skin with fine details—without any texture, back-view, bald, non-human, or synthetic training data. We fine-tune a diffusion prior on a dataset of mostly frontal faces, conditioned on predicted 3D head geometry and face parsing. During inference, HairFree uses precise skin masks and 3D FLAME geometry as input conditioning, ensuring high 3D consistency and alignment. We synthesize the full 360° texture by first generating a frontal RGB image aligned to the 3D FLAME pose and mapping it to UV space. As the virtual camera moves, we inpaint and merge missing regions. A built-in semantic prior enables precise region separation—particularly for isolating and removing hair—allowing seamless integration with various assets like customizable 3D hair, eyeglasses, jewelry, etc. We evaluate HairFree quantitatively and qualitatively, demonstrating its superiority over state-of-the-art 3D head avatar generation methods. https://hairfree.is.tue.mpg.de/'}",https://openreview.net{'value': '/pdf/cba7487fc290676c7631899a90b68e9d64f05d67.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=jVwIfsJLvh,{'value': 'Generalized Top-k Mallows Model for Ranked Choices'},Shahrzad Haddadan; Sara Ahmadian,~Shahrzad_Haddadan1; ~Sara_Ahmadian1,"{'value': ['Mallows Model', 'choice modeling', 'top-k sampling']}","{'value': 'The classic Mallows model is a foundational tool for modeling user preferences. However, it has limitations in capturing real-world scenarios, where users often focus only on a limited set of preferred items and are indifferent to the rest. To address this, extensions such as the top-$k$ Mallows model have been proposed, aligning better with practical applications.\nIn this paper, we address several challenges related to the generalized top-$k$ Mallows model, with a focus on analyzing buyer choices. Our key contributions are: (1) a novel sampling scheme tailored to generalized top-$k$ Mallows models, (2) an efficient algorithm for computing choice probabilities under this model, and (3) an active learning algorithm for estimating the model parameters from observed choice data. These contributions provide new tools for analysis and prediction in critical decision-making scenarios.\nWe present a rigorous mathematical analysis for the performance of our algorithms. Furthermore, through extensive experiments on synthetic data and real-world data, we demonstrate the scalability and accuracy of our proposed methods, and we compare the predictive power of Mallows model for top-$k$ lists compared to the simpler Multinomial Logit model.'}",https://openreview.net{'value': '/pdf/f4ab547d461e988517cfc6457e688ef0645b25cc.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=jTCiQpV0Lx,{'value': 'Unlocker: Disentangle the Deadlock of Learning between Label-noisy and Long-tailed Data'},Chen Shu; HongJun Xu; Ruichi Zhang; Mengke Li; Yonggang Zhang; Yang Lu; Bo Han; Yiu-ming Cheung; Hanzi Wang,~Chen_Shu2; ~HongJun_Xu1; ~Ruichi_Zhang3; ~Mengke_Li3; ~Yonggang_Zhang1; ~Yang_Lu5; ~Bo_Han1; ~Yiu-ming_Cheung1; ~Hanzi_Wang1,"{'value': ['Long-tail learning', 'Noisy label learning']}","{'value': 'In real world, the observed label distribution of a dataset often mismatches its true distribution due to noisy labels. \n        In this situation, noisy labels learning (NLL) methods directly integrated with long-tail learning (LTL) methods tend to fail due to a dilemma: NLL methods normally rely on unbiased model predictions to recover true distribution by selecting and correcting noisy labels; while LTL methods like logit adjustment depends on true distributions to adjust biased predictions, leading to a deadlock of mutual dependency defined in this paper.  \n        To address this, we propose \\texttt{Unlocker}, a bilevel optimization framework that integrates NLL methods and LTL methods to iteratively disentangle this deadlock. The inner optimization leverages NLL to train the model, incorporating LTL methods to fairly select and correct noisy labels. The outer optimization adaptively determines an adjustment strength, mitigating model bias from over- or under-adjustment. We also theoretically prove that this bilevel optimization problem is convergent by transferring the outer optimization target to an equivalent problem with a closed-form solution. \n        Extensive experiments on synthetic and real-world datasets demonstrate the effectiveness of our method in alleviating model bias and handling long-tailed noisy label data. Code is available at \\url{https://anonymous.4open.science/r/neurips-2025-anonymous-1015/}.'}",https://openreview.net{'value': '/pdf/ded539fb0a689a4e8692dc88162c621c4e9b33b3.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=jSc7HD7mPj,{'value': 'BADiff: Bandwidth Adaptive Diffusion Model'},Xi Zhang; Hanwei Zhu; Yan Zhong; Jiamang Wang; Weisi Lin,~Xi_Zhang7; ~Hanwei_Zhu1; ~Yan_Zhong2; ~Jiamang_Wang1; ~Weisi_Lin1,"{'value': ['Bandwidth-aware generation', 'diffusion models', 'image compression']}","{'value': 'In this work, we propose a novel framework to enable diffusion models to adapt their generation quality based on real-time network bandwidth constraints. Traditional diffusion models produce high-fidelity images by performing a fixed number of denoising steps, regardless of downstream transmission limitations. However, in practical cloud-to-device scenarios, limited bandwidth often necessitates heavy compression, leading to loss of fine textures and wasted computation. To address this, we introduce a joint end-to-end training strategy where the diffusion model is conditioned on a target quality level derived from the available bandwidth. During training, the model learns to adaptively modulate the denoising process, enabling early-stop sampling that maintains perceptual quality appropriate to the target transmission condition. Our method requires minimal architectural changes and leverages a lightweight quality embedding to guide the denoising trajectory. Experimental results demonstrate that our approach significantly improves the visual fidelity of bandwidth-adapted generations compared to naive early-stopping, offering a promising solution for efficient image delivery in bandwidth-constrained environments. Code is available at: https://github.com/xzhang9308/BADiff.'}",https://openreview.net{'value': '/pdf/afa9b94f43dfb386d8137d4222ce518292b289bb.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=jNQ40aw5qL,{'value': 'Amortized Active Generation of Pareto Sets'},Daniel M. Steinberg; Asiri Wijesinghe; Rafael Oliveira; Piotr Koniusz; Cheng Soon Ong; Edwin V. Bonilla,~Daniel_M._Steinberg1; ~Asiri_Wijesinghe1; ~Rafael_Oliveira1; ~Piotr_Koniusz1; ~Cheng_Soon_Ong1; ~Edwin_V._Bonilla1,"{'value': ['multi-objective optimization', 'multi-objective generation', 'black-box optimization', 'guided generation', 'multi-objective Bayesian optimization', 'discrete optimization', 'variational inference', 'reinforce', 'active generation', 'online black-box optimization']}","{'value': 'We introduce active generation of Pareto sets (A-GPS), a new framework for online discrete black-box multi-objective optimization (MOO). A-GPS learns a generative model of the Pareto set that supports a-posteriori conditioning on user preferences. The method employs a class probability estimator (CPE) to predict non-dominance relations and to condition the generative model toward high-performing regions of the search space. We also show that this non-dominance CPE implicitly estimates the probability of hypervolume improvement (PHVI). To incorporate subjective trade-offs, A-GPS introduces _preference direction vectors_ that encode user-specified preferences in objective space. At each iteration, the model is updated using both Pareto membership and alignment with these preference directions, producing an amortized generative model capable of sampling across the Pareto front without retraining. The result is a simple yet powerful approach\nthat achieves high-quality Pareto set approximations, avoids explicit hypervolume computation, and flexibly captures user preferences. Empirical results on synthetic benchmarks and protein design tasks demonstrate strong sample efficiency and effective preference incorporation.'}",https://openreview.net{'value': '/pdf/60b448da2ea9182ef373cea14d233022264c65a6.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=jH9TtAhMkp,{'value': 'OrdShap: Feature Position Importance for Sequential Black-Box Models'},Davin Hill; Brian L. Hill; Aria Masoomi; Vijay S Nori; Robert E. Tillman; Jennifer Dy,~Davin_Hill1; ~Brian_L._Hill1; ~Aria_Masoomi1; ~Vijay_S_Nori1; ~Robert_E._Tillman1; ~Jennifer_Dy1,"{'value': ['Interpretability', 'Explainability', 'XAI', 'Shapley']}","{'value': ""Sequential deep learning models excel in domains with temporal or sequential dependencies, but their complexity necessitates post-hoc feature attribution methods for understanding their predictions. While existing techniques quantify feature importance, they inherently assume fixed feature ordering — conflating the effects of (1) feature values and (2) their positions within input sequences. To address this gap, we introduce OrdShap, a novel attribution method that disentangles these effects by quantifying how a model's predictions change in response to permuting feature position. We establish a game-theoretic connection between OrdShap and Sanchez-Bergantiños values, providing a theoretically grounded approach to position-sensitive attribution. Empirical results from health, natural language, and synthetic datasets highlight OrdShap's effectiveness in capturing feature value and feature position attributions, and provide deeper insight into model behavior.""}",https://openreview.net{'value': '/pdf/b76729a7877400a1409bf98157a1e8f6ff272997.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=j42rziWq1n,{'value': 'ViCrit: A Verifiable Reinforcement Learning Proxy Task for Visual Perception in VLMs'},Xiyao Wang; Zhengyuan Yang; Chao Feng; Yuhang Zhou; Xiaoyu Liu; Yongyuan Liang; Ming Li; Ziyi Zang; Linjie Li; Chung-Ching Lin; Kevin Lin; Furong Huang; Lijuan Wang,~Xiyao_Wang1; ~Zhengyuan_Yang1; ~Chao_Feng4; ~Yuhang_Zhou1; ~Xiaoyu_Liu3; ~Yongyuan_Liang1; ~Ming_Li18; ~Ziyi_Zang1; ~Linjie_Li1; ~Chung-Ching_Lin2; ~Kevin_Lin3; ~Furong_Huang1; ~Lijuan_Wang1,{'value': ['Visual reasoning; Vision-Language Model; Visual captioning; Reward Model; Visual Hallucination']},"{'value': 'Reinforcement learning (RL) has shown great effectiveness for fine-tuning large language models (LLMs) using tasks that are challenging yet easily verifiable, such as math reasoning or code generation. However, extending this success to visual perception in vision–language models (VLMs) has been impeded by the scarcity of vision-centric tasks that are simultaneously challenging and unambiguously verifiable. To this end, we introduce \\textbf{ViCrit} (\\textit{Visual Caption Hallucination Critic}), an RL proxy task that trains VLMs to localize a subtle, synthetic visual hallucination injected into paragraphs of human-written image captions. Starting from a 200-word captions, we inject a single, subtle visual description error—altering a few words on objects, attributes, counts, or spatial relations—and task the model to pinpoint the corrupted span given the image and the modified caption. This formulation preserves the full perceptual difficulty while providing a binary, exact-match reward that is easy to compute and unambiguous. Models trained with the \\textbf{ViCrit Task} exhibit substantial gains across a variety of VL benchmarks. Crucially, the improvements transfer beyond natural-image training data to abstract image reasoning and visual math, showing promises of learning to perceive rather than barely memorizing seen objects. To facilitate evaluation, we further introduce \\textbf{ViCrit-Bench}, a category-balanced diagnostic benchmark that systematically probes perception errors across diverse image domains and error types. Together, our results demonstrate that fine-grained hallucination criticism is an effective and generalizable objective for enhancing visual perception in VLMs.'}",https://openreview.net{'value': '/pdf/631a654bdd1aa99c3357feb56e89859a66512702.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=j0D69KmUYQ,{'value': 'PALQO: Physics-informed model for Accelerating  Large-scale Quantum Optimization'},Yiming Huang; Yajie Hao; Yuxuan Du; Jing Zhou; Xiao Yuan; Xiaoting Wang,~Yiming_Huang3; ~Yajie_Hao2; ~Yuxuan_Du2; ~Jing_Zhou11; ~Xiao_Yuan4; ~Xiaoting_Wang4,"{'value': ['quantum optimization', 'physics-informed machine learning', 'machine learning']}","{'value': 'Variational Quantum Algorithms (VQAs) are emerging as leading strategies with the potential to unlock practical applications and deliver significant advantages in the investigation of many-body quantum systems and quantum chemistry. \nA key challenge hindering the application of VQAs to large-scale problems is rooted in the no-cloning theorem in quantum mechanics, precluding standard backpropagation and leading to prohibitive quantum resource expenditure such as measurement cost.\nTo address this challenge, we reformulate the training dynamics of VQAs as a non-linear partial differential equation and propose a novel protocol that leverages physics-informed neural networks (PINNs) to model this dynamical system efficiently. Given a small amount of training trajectory data collected from quantum devices, our protocol predicts the parameter updates of VQAs over multiple iterations on the classical side, dramatically reducing quantum resource costs. Through systematic numerical experiments, we demonstrate that our method achieves up to a 30x speedup compared to conventional methods and reduces quantum resource costs by as much as 90\\% for tasks involving up to 40 qubits, including ground state preparation of different quantum systems, while maintaining competitive accuracy. Our approach complements existing techniques aimed at improving the efficiency of VQAs and further strengthens their potential for practical applications.'}",https://openreview.net{'value': '/pdf/3560c2de8145322096e9ebfe9e2dd782927d618a.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=isAYKdLwtB,{'value': 'Effective Policy Learning for Multi-Agent Online Coordination Beyond Submodular Objectives'},Qixin Zhang; Yan Sun; Can Jin; Xikun ZHANG; Yao Shu; Puning Zhao; Li Shen; Dacheng Tao,~Qixin_Zhang1; ~Yan_Sun3; ~Can_Jin1; ~Xikun_ZHANG2; ~Yao_Shu1; ~Puning_Zhao1; ~Li_Shen1; ~Dacheng_Tao1,"{'value': ['Multi-Agent Coordination', 'Policy Learning', 'Continuous Relaxation', 'Online Non-Submodular Maximization', 'Surrogate Functions']}","{'value': 'In this paper, we present two effective  policy learning algorithms for multi-agent online coordination(MA-OC) problem. The first one, **MA-SPL**,  not only can achieve the optimal $(1-\\frac{c}{e})$-approximation guarantee for the MA-OC problem with submodular objectives but also can handle the unexplored  $\\alpha$-weakly DR-submodular and $(\\gamma,\\beta)$-weakly submodular scenarios, where $c$ is the curvature of the investigated submodular functions, $\\alpha$ denotes the diminishing-return(DR) ratio and the tuple$(\\gamma,\\beta)$ represents the submodularity ratios.  Subsequently, in order to reduce the reliance on the unknown parameters $\\alpha,\\gamma,\\beta$ inherent in the **MA-SPL** algorithm, we then introduce the second online algorithm named **MA-MPL**. This **MA-MPL** algorithm is entirely *parameter-free* and simultaneously can maintain the same approximation ratio as the first  **MA-SPL** algorithm. The core of our **MA-SPL** and **MA-MPL** algorithms is a novel continuous-relaxation technique term as policy-based continuous extension. Compared with the well-established multi-linear extension, a notable advantage of this new policy-based continuous extension is its ability to provide a lossless rounding scheme for any set function, thereby enabling us to tackle the challenging  weakly submodular objective functions. Finally, extensive simulations are conducted to demonstrate the effectiveness of our proposed algorithms.'}",https://openreview.net{'value': '/pdf/e263c6fd3be55a1d82c662af01c25377c42f9cf5.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=isATAFP71B,{'value': 'SE-Agent: Self-Evolution Trajectory Optimization in Multi-Step Reasoning with LLM-Based Agents'},Yifu Guo; Jiaye Lin; Huacan Wang; Yuzhen Han; Sen Hu; Ziyi Ni; Licheng Wang; Mingguang Chen,~Yifu_Guo1; ~Jiaye_Lin1; ~Huacan_Wang1; ~Yuzhen_Han1; ~Sen_Hu2; ~Ziyi_Ni1; ~Licheng_Wang3; ~Mingguang_Chen1,"{'value': ['LLM-Based Agents', 'Self-Evolution', 'Multi-Step Reasoning']}","{'value': ""Large Language Model (LLM)-based agents have recently shown impressive capabilities in complex reasoning and tool use via multi-step interactions with their environments. While these agents have the potential to tackle complicated tasks, their problem-solving process—agents' interaction trajectory leading to task completion—remains underexploited. These trajectories contain rich feedback that can navigate agents toward the right directions for solving problems correctly. Although prevailing approaches, such as Monte Carlo Tree Search (MCTS), can effectively balance exploration and exploitation, they ignore the interdependence among various trajectories and lack the diversity of search spaces, which leads to redundant reasoning and suboptimal outcomes. To address these challenges, we propose SE-Agent, a Self-Evolution framework that enables Agents to optimize their reasoning processes iteratively. Our approach revisits and enhances former pilot trajectories through three key operations: revision, recombination, and refinement. This evolutionary mechanism enables two critical advantages: (1) it expands the search space beyond local optima by intelligently exploring diverse solution paths guided by previous trajectories, and (2) it leverages cross-trajectory inspiration to efficiently enhance performance while mitigating the impact of suboptimal reasoning paths. Through these mechanisms, SE-Agent achieves continuous self-evolution that incrementally improves reasoning quality. We evaluate SE-Agent on SWE-bench Verified to resolve real-world GitHub issues. Experimental results across five strong LLMs show that integrating SE-Agent delivers up to 55% relative improvement, achieving state-of-the-art performance among all open-source agents on SWE-bench Verified.""}",https://openreview.net{'value': '/pdf/814cd78232da3150c1f91b29920f4f2e4d70fb3c.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=ipEqdzO2IT,{'value': 'Robust and Diverse Multi-Agent Learning via Rational Policy Gradient'},Niklas Lauffer; Ameesh Shah; Micah Carroll; Sanjit A. Seshia; Stuart Russell; Michael D Dennis,~Niklas_Lauffer1; ~Ameesh_Shah1; ~Micah_Carroll1; ~Sanjit_A._Seshia1; ~Stuart_Russell1; ~Michael_D_Dennis1,"{'value': ['reinforcement learning', 'adversarial training', 'robustness', 'multi-agent learning', 'opponent shaping', 'general-sum']}","{'value': ""Adversarial optimization algorithms that explicitly search for flaws in agents' policies have been successfully applied to finding robust and diverse policies in the context of multi-agent learning. However, the success of adversarial optimization has been largely limited to zero-sum settings because its naive application in cooperative settings leads to a critical failure mode: agents are irrationally incentivized to *self-sabotage*, blocking the completion of tasks and halting further learning. To address this, we introduce *Rationality-preserving Policy Optimization (RPO)*, a formalism for adversarial optimization that avoids self-sabotage by ensuring agents remain *rational*—that is, their policies are optimal with respect to some possible partner policy. To solve RPO, we develop *Rational Policy Gradient (RPG)*, which trains agents to maximize their own reward in a modified version of the original game in which we use *opponent shaping* techniques to optimize the adversarial objective. RPG enables us to extend a variety of existing adversarial optimization algorithms that, no longer subject to the limitations of self-sabotage, can find adversarial examples, improve robustness and adaptability, and learn diverse policies. We empirically validate that our approach achieves strong performance in several popular cooperative and general-sum environments. Our project page can be found at https://rational-policy-gradient.github.io.""}",https://openreview.net{'value': '/pdf/863d9c70f1f3a89891b232d1e846828a6a08dd36.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=iooQFm2qHf,{'value': 'Handling Label Noise via Instance-Level Difficulty Modeling and Dynamic Optimization'},Kuan Zhang; Chengliang Chai; Jingzhe Xu; Chi Zhang; Han Han; Ye Yuan; Guoren Wang; Lei Cao,~Kuan_Zhang1; ~Chengliang_Chai1; ~Jingzhe_Xu1; ~Chi_Zhang62; ~Han_Han4; ~Ye_Yuan15; ~Guoren_Wang1; ~Lei_Cao1,"{'value': ['computer vision', 'learning with noisy labels', 'robustness']}","{'value': 'Recent studies indicate that deep neural networks degrade in generalization performance under noisy supervision. Existing methods focus on isolating clean subsets or correcting noisy labels, facing limitations such as high computational costs, heavy hyperparameter tuning process, and coarse-grained optimization. To address these challenges, we propose a novel two-stage noisy learning framework that enables instance-level optimization through a dynamically weighted loss function, avoiding hyperparameter tuning. To obtain stable and accurate information about noise modeling, we introduce a simple yet effective metric, termed $\\textit{wrong event}$, which dynamically models the cleanliness and difficulty of individual samples while maintaining computational costs. Our framework first collects $\\textit{wrong event}$ information and builds a strong base model. Then we perform noise-robust training on the base model, using a probabilistic model to handle the $\\textit{wrong event}$ information of samples. Experiments on six synthetic and real-world LNL benchmarks demonstrate our method surpasses state-of-the-art methods in performance, achieves a nearly 75\\% reduction in storage and computational time, strongly improving model scalability. Our code is available at https://github.com/iTheresaApocalypse/IDO.'}",https://openreview.net{'value': '/pdf/b951f9fb60133b691f0191feb4244915bad8d33d.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=igB289kbej,{'value': 'EraseFlow: Learning Concept Erasure Policies via GFlowNet-Driven Alignment'},Naga Sai Abhiram kusumba; Maitreya Patel; Kyle Min; Changhoon Kim; Chitta Baral; Yezhou Yang,~Naga_Sai_Abhiram_kusumba1; ~Maitreya_Patel2; ~Kyle_Min1; ~Changhoon_Kim1; ~Chitta_Baral1; ~Yezhou_Yang1,"{'value': ['Safe generation', 'Text-to-image generation', 'Flow models', 'GFlowNets']}","{'value': ""Erasing harmful or proprietary concepts from powerful text‑to‑image generators is an emerging safety requirement, yet current ``concept erasure'' techniques either collapse image quality, rely on brittle adversarial losses, or demand prohibitive retraining cycles. We trace these limitations to a myopic view of the denoising trajectories that govern diffusion‑based generation. We introduce EraseFlow, the first framework that casts concept unlearning as exploration in the space of denoising paths and optimizes it with a GFlowNets equipped with the trajectory‑balance objective. By sampling entire trajectories rather than single end states, EraseFlow learns a stochastic policy that steers generation away from target concepts while preserving the model’s prior. EraseFlow eliminates the need for carefully crafted reward models and by doing this, it generalizes effectively to unseen concepts and avoids hackable rewards while improving the performance. Extensive empirical results demonstrate that EraseFlow outperforms existing baselines and achieves an optimal trade-off between performance and prior preservation.""}",https://openreview.net{'value': '/pdf/377618c1b12d0c813d0e22a6bb6080cf23462dc8.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=ifsyZYYDNs,{'value': 'SCAN: Self-Denoising Monte Carlo Annotation for Robust Process Reward Learning'},Yuyang Ding; Xinyu Shi; Juntao Li; xiaobo liang; Zhaopeng Tu; Min Zhang,~Yuyang_Ding1; ~Xinyu_Shi4; ~Juntao_Li2; ~xiaobo_liang1; ~Zhaopeng_Tu1; ~Min_Zhang9,"{'value': ['LLM Reasoning', 'Process Supervision', 'Robust Learning']}","{'value': 'Process reward models (PRMs) offer fine-grained, step-level evaluations that facilitate deeper reasoning processes in large language models (LLMs), proving effective in complex tasks like mathematical reasoning. \nHowever, developing PRMs is challenging due to the high cost and limited scalability of human-annotated data.\nSynthetic data from Monte Carlo (MC) estimation is a promising alternative but suffers from a high noise ratio, which can cause overfitting and hinder large-scale training.\nIn this work, we conduct a preliminary study on the noise distribution in synthetic data from MC estimation, identifying that annotation models tend to both underestimate and overestimate step correctness due to limitations in their annotation capabilities. \nBuilding on these insights, we propose {\\bf S}elf-Denoising Monte {\\bf C}arlo {\\bf An}notation (\\textsc{Scan}), an efficient data synthesis and noise-tolerant learning framework.\nOur key findings indicate that:\n(1) Even lightweight models (e.g., 1.5B parameters) can produce high-quality annotations through self-denoising strategy, enabling PRMs to achieve superior performance with only 6\\% the inference cost required by vanilla MC estimation.\n(2) With our robust learning strategy, PRMs can effectively learn from this weak supervision, achieving a 39.2 F1 score improvement (from 19.9 to 59.1) in ProcessBench.\nDespite using only a compact synthetic dataset, our models surpass strong baselines, including those trained on large-scale human-annotated datasets such as PRM800K.\nFurthermore, performance continues to improve as we scale up the synthetic data, highlighting the potential of \\textsc{Scan} for scalable, cost-efficient, and robust PRM training.'}",https://openreview.net{'value': '/pdf/90e683c8f88b8fe14fd41acb175f70e1cbcdd305.pdf'},{'abstract_filter': 'Data Synthesis'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=ifavjJaKQa,{'value': 'Temporal Logic-Based Multi-Vehicle Backdoor Attacks against Offline RL Agents in End-to-end Autonomous Driving'},Xuan Chen; Shiwei Feng; Zikang Xiong; Shengwei An; Yunshu Mao; Lu Yan; Guanhong Tao; Wenbo Guo; Xiangyu Zhang,~Xuan_Chen3; ~Shiwei_Feng1; ~Zikang_Xiong1; ~Shengwei_An1; ~Yunshu_Mao1; ~Lu_Yan1; ~Guanhong_Tao1; ~Wenbo_Guo1; ~Xiangyu_Zhang3,{'value': ['backdoor attack; autonomous driving security; offline RL']},"{'value': ""Assessing the safety of autonomous driving (AD) systems against security threats, particularly backdoor attacks, is a stepping stone for real-world deployment. However, existing works mainly focus on pixel-level triggers which are impractical to deploy in the real world. We address this gap by introducing a novel backdoor attack against the end-to-end AD systems that leverage one or more other vehicles' trajectories as triggers. To generate precise trigger trajectories, we first use temporal logic (TL) specifications to define the behaviors of attacker vehicles. Configurable behavior models are then used to generate these trajectories, which are quantitatively evaluated and iteratively refined based on the TL specifications. We further develop a negative training strategy by incorporating patch trajectories that are similar to triggers but are designated not to activate the backdoor. \nIt enhances the stealthiness of the attack and refines the system’s responses to trigger scenarios. \nThrough extensive experiments on 5 offline reinforcement learning (RL) driving agents with 6 trigger patterns and target actions combinations, we demonstrate the flexibility and effectiveness of our proposed attack, showing the under-exploration of existing end-to-end AD systems' vulnerabilities to such trajectory-based backdoor attacks.\nVideos of our attack are available at: https://sites.google.com/view/tlbackdoor/home.""}",https://openreview.net{'value': '/pdf/d7e3778249cef68e14886abf7d5a507977ffd6f4.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=ifMZw5fm7K,{'value': 'Abstract Counterfactuals for Language Model Agents'},Edoardo Pona; Milad Kazemi; Yali Du; David Watson; Nicola Paoletti,~Edoardo_Pona1; ~Milad_Kazemi1; ~Yali_Du1; ~David_Watson2; ~Nicola_Paoletti1,"{'value': ['causal inference', 'counterfactual inference', 'language models', 'agents', 'causality', 'interpretability']}","{'value': 'Counterfactual inference is a powerful tool for analysing and evaluating autonomous agents, but its application to language model (LM) agents remains challenging. Existing work on counterfactuals in LMs has primarily focused on token-level counterfactuals, which are often inadequate for LM agents due to their open-ended action spaces. \nUnlike traditional agents with fixed, clearly defined action spaces, the actions of LM agents are often implicit in the strings they output, making their action spaces difficult to define and interpret. \nFurthermore, the meanings of individual tokens can shift depending on the context, adding complexity to token-level reasoning and sometimes leading to biased or meaningless counterfactuals.\nWe introduce \\emph{Abstract Counterfactuals}, a framework that emphasises high-level characteristics of actions and interactions within an environment, enabling counterfactual reasoning tailored to user-relevant features. \nOur experiments demonstrate that the approach produces consistent and meaningful counterfactuals while minimising the undesired side effects of token-level methods.\nWe conduct experiments on text-based games and counterfactual text generation, while considering both token-level and latent-space interventions.'}",https://openreview.net{'value': '/pdf/c39308d32f99302b4eb8a97c6d7eae5b2e2c4466.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=idnW3BiZcV,{'value': 'CAR-Flow: Condition-Aware Reparameterization Aligns Source and Target for Better Flow Matching'},Chen Chen; Pengsheng Guo; Liangchen Song; Jiasen Lu; Rui Qian; Tsu-Jui Fu; Xinze Wang; Wei Liu; Yinfei Yang; Alex Schwing,~Chen_Chen38; ~Pengsheng_Guo1; ~Liangchen_Song1; ~Jiasen_Lu2; ~Rui_Qian1; ~Tsu-Jui_Fu2; ~Xinze_Wang3; ~Wei_Liu1; ~Yinfei_Yang1; ~Alex_Schwing1,"{'value': ['image generation', 'diffusion model', 'flow matching']}","{'value': 'Conditional generative modeling aims to learn a conditional data distribution from samples containing data-condition pairs. For this, diffusion and flow-based methods have attained compelling results. These methods use a learned (flow) model to transport an initial standard Gaussian noise that ignores the condition to the conditional data distribution. The model is hence required to learn both mass transport \\emph{and} conditional injection. To ease the demand on the model, we propose \\emph{Condition-Aware Reparameterization for Flow Matching} (CAR-Flow) -- a lightweight, learned \\emph{shift} that conditions the source, the target, or both distributions. By relocating these distributions, CAR-Flow shortens the probability path the model must learn, leading to faster training in practice. On low-dimensional synthetic data, we visualize and quantify the effects of CAR-Flow. On higher-dimensional natural image data (ImageNet-256), equipping SiT-XL/2 with CAR-Flow reduces FID from 2.07 to 1.68, while introducing less than \\(0.6\\%\\) additional parameters.'}",https://openreview.net{'value': '/pdf/ae30b31a95c7616fac0a1c220c54915dcc14ab79.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=ib0aV2hphN,{'value': 'High-Order Flow Matching: Unified Framework and Sharp Statistical Rates'},Maojiang Su; Jerry Yao-Chieh Hu; Yi-Chen Lee; Ning Zhu; Jui-Hui Chung; Shang Wu; Zhao Song; Minshuo Chen; Han Liu,~Maojiang_Su1; ~Jerry_Yao-Chieh_Hu1; ~Yi-Chen_Lee1; ~Ning_Zhu4; ~Jui-Hui_Chung1; ~Shang_Wu2; ~Zhao_Song3; ~Minshuo_Chen1; ~Han_Liu4,"{'value': ['Flow Matching', 'Generative Model', 'Generative AI', 'Minimax Optimal']}","{'value': 'Flow matching is an emerging generative modeling framework that learns continuous-time dynamics to map noise into data.\nTo enhance expressiveness and sampling efficiency, recent works have explored incorporating high-order trajectory information. \nDespite the empirical success, a holistic theoretical foundation is still lacking. \nWe present a unified framework for standard and high-order flow matching that incorporates trajectory derivatives up to an arbitrary order $K$. \nOur key innovation is establishing the marginalization technique that converts the intractable $K$-order loss into a simple conditional regression with exact gradients and identifying the consistency constraint.\nWe establish sharp statistical rates of the $K$-order flow matching implemented with transformer networks. With $n$ samples, flow matching estimates nonparametric distributions at a rate $\\tilde{O}(n^{-\\Theta(1/d )})$, matching minimax lower bounds up to logarithmic factors.'}",https://openreview.net{'value': '/pdf/1ae050edfa6399ba60ed02cbedcb97793f897940.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=iZy3ZgoHrD,{'value': 'ZeroPatcher: Training-free Sampler for Video Inpainting and Editing'},Shaoshu Yang; Yingya Zhang; Ran He,~Shaoshu_Yang1; ~Yingya_Zhang3; ~Ran_He1,"{'value': ['Video editing', 'video inpainting', 'diffusion model']}","{'value': 'Video inpainting and editing have long been challenging tasks in the video generation community, requiring extensive computational resources and large datasets to train models with satisfactory performance. Recent breakthroughs in large-scale video foundation models have greatly enhanced text-to-video generation capabilities. This naturally leads to the idea of leveraging the prior knowledge from these powerful generators to facilitate video inpainting and editing. In this work, we investigate the feasibility of employing pre-trained text-to-video foundation models for high-quality video inpainting and editing without additional training. Specifically, we introduce a model-agnostic denoising sampler that optimizes the trajectory by maximizing the log-likelihood expectation conditioned on the known video segments. To enable efficient dynamic object removal and replacement, we propose a latent mask fuser that performs accurate video masking directly in latent space, eliminating the need for explicit VAE decoding and encoding. We implement our approach in widely-used foundation generators such as CogVideoX and HunyuanVideo, demonstrating the model-agnostic nature of our sampler. Comprehensive quantitative and qualitative evaluations confirm that our method achieves outstanding video inpainting and editing performance in a plug-and-play fashion.'}",https://openreview.net{'value': '/pdf/9fbcf206b76f5b4f9293a57b33e6d9715e20e206.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=iXjVis9Cwn,{'value': 'Dynamic Configuration for Cutting Plane Separators via Reinforcement Learning on Incremental Graph'},Mingxuan Ye; Jie Wang; Fangzhou Zhu; Zhihai Wang; Yufei Kuang; Xijun Li; Weilin Luo; Jianye HAO; Feng Wu,~Mingxuan_Ye1; ~Jie_Wang1; ~Fangzhou_Zhu1; ~Zhihai_Wang1; ~Yufei_Kuang1; ~Xijun_Li1; ~Weilin_Luo2; ~Jianye_HAO1; ~Feng_Wu1,{'value': ['mixed-integer Linear Programming; cutting plane separator; reinforcement Learning; incremental graph']},"{'value': 'Cutting planes (cuts) are essential for solving mixed-integer linear programming (MILP) problems, as they tighten the feasible solution space and accelerate the solving process. Modern MILP solvers offer diverse cutting plane separators to generate cuts, enabling users to leverage their potential complementary strengths to tackle problems with different structures. Recent machine learning approaches learn to configure separators based on problem-specific features, selecting effective separators and deactivating ineffective ones to save unnecessary computing time. However, they ignore the dynamics of separator efficacy at different stages of cut generation and struggle to adapt the configurations for the evolving problems after multiple rounds of cut generation. To address this challenge, we propose a novel **dyn**amic **sep**arator configuration (**DynSep**) method that models separator configuration in different rounds as a reinforcement learning task, making decisions based on an incremental triplet graph updated by iteratively added cuts. Specifically, we tokenize the incremental subgraphs and utilize a decoder-only Transformer as our policy to autoregressively predict when to halt separation and which separators to activate at each round. Evaluated on synthetic and large-scale real-world MILP problems, DynSep speeds up average solving time by 64% on easy and medium datasets, and reduces primal-dual gap integral within the given time limit by 16% on hard datasets. Moreover, experiments demonstrate that DynSep well generalizes to MILP instances of significantly larger sizes than those seen during training.'}",https://openreview.net{'value': '/pdf/b4990c5766256fc5c41e612c4b0b53b2b22d7d9c.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=iUjGNJzrF1,{'value': 'Debate or Vote: Which Yields Better Decisions in Multi-Agent Large Language Models?'},Hyeong Kyu Choi; Jerry Zhu; Sharon Li,~Hyeong_Kyu_Choi1; ~Jerry_Zhu1; ~Sharon_Li1,"{'value': ['multi-agent debate', 'majority voting', 'LLM', 'Agentic AI']}","{'value': 'Multi-Agent Debate (MAD) has emerged as a promising paradigm for improving the performance of large language models through collaborative reasoning. Despite recent advances, the key factors driving MAD’s effectiveness remain unclear. In this work, we disentangle MAD into two key components–Majority Voting and inter-agent Debate–and assess their respective contributions. Through extensive experiments across seven NLP benchmarks, we find that Majority Voting alone accounts for most of the performance gains typically attributed to MAD. To explain this, we propose a theoretical framework that models debate as a stochastic process. We prove that it induces a martingale over agents’ belief trajectories, implying that debate alone does not improve expected correctness. Guided by these insights, we demonstrate that targeted interventions, by biasing the belief update toward correction, can meaningfully enhance debate effectiveness. Overall, our findings suggest that while MAD has potential, simple ensembling methods remain strong and more reliable alternatives in many practical settings. Code is released in https://github.com/deeplearning-wisc/debate-or-vote.'}",https://openreview.net{'value': '/pdf/cf23542e165c5a7e0a313adf0f13edae69ee5138.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=iSvAAHGFSw,{'value': 'A Theoretical Framework for Grokking: Interpolation followed by Riemannian Norm Minimisation'},Etienne Boursier; Scott Pesme; Radu-Alexandru Dragomir,~Etienne_Boursier1; ~Scott_Pesme1; ~Radu-Alexandru_Dragomir1,{'value': ['grokking; non-convex optimisation; dynamic perturbed systems; theory of neural networks; Riemannian optimisation']},"{'value': 'We study the dynamics of gradient flow with small weight decay on general training losses $F: \\mathbb{R}^d \\to \\mathbb{R}$. Under mild regularity assumptions and assuming convergence of the unregularised gradient flow, we show that the trajectory with weight decay $\\lambda$ exhibits a two-phase behaviour as $\\lambda \\to 0$. During the initial fast phase, the trajectory follows the unregularised gradient flow and converges to a manifold of critical points of $F$. Then, at time of order $1/\\lambda$, the trajectory enters a slow drift phase and follows a Riemannian gradient flow minimising the $\\ell_2$-norm of the parameters. This purely optimisation-based phenomenon offers a natural explanation for the \\textit{grokking} effect observed in deep learning, where the training loss rapidly reaches zero while the test loss plateaus for an extended period before suddenly improving. We argue that this generalisation jump can be attributed to the slow norm reduction induced by weight decay, as explained by our analysis. We validate this mechanism empirically on several synthetic regression tasks.'}",https://openreview.net{'value': '/pdf/42b7941e44a83f02fe39587b02fa277eda3e0a31.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=iE0oCRx81h,{'value': 'TRIM: Scalable 3D Gaussian Diffusion Inference with Temporal and Spatial Trimming'},Zeyuan Yin; Xiaoming Liu,~Zeyuan_Yin1; ~Xiaoming_Liu2,"{'value': ['3D Generation', 'Gaussian Splatting', 'Stable Diffusion', 'Inference-Time Scaling']}","{'value': 'Recent advances in 3D Gaussian diffusion models suffer from time-intensive denoising and post-denoising processing due to the massive number of Gaussian primitives, resulting in slow generation and limited scalability along sampling trajectories.\nTo improve the efficiency of 3D diffusion models, \nwe propose $\\textbf{TRIM}$ ($\\textbf{T}$rajectory $\\textbf{R}$eduction and $\\textbf{I}$nstance $\\textbf{M}$ask denoising), a post-training approach that incorporates both temporal and spatial trimming strategies, to accelerate inference without compromising output quality while supporting the inference-time scaling for Gaussian diffusion models.\nInstead of scaling denoising trajectories in a costly end-to-end manner, we develop a lightweight selector model to evaluate latent Gaussian primitives derived from multiple sampled noises, enabling early trajectory reduction by selecting candidates with high-quality potential.\nFurthermore, we introduce instance mask denoising to prune learnable Gaussian primitives by filtering out redundant background regions, reducing inference computation at each denoising step.\nExtensive experiments and analysis demonstrate that TRIM significantly improves both the efficiency and quality of 3D generation.'}",https://openreview.net{'value': '/pdf/ab3c7ae2a921aadc60a22f58fedda1732eccd2a5.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=iBLAYaEKdL,{'value': 'Constrained Posterior Sampling: Time Series Generation with Hard Constraints'},Sai Shankar Narasimhan; Shubhankar Agarwal; Litu Rout; Sanjay Shakkottai; Sandeep P. Chinchali,~Sai_Shankar_Narasimhan1; ~Shubhankar_Agarwal1; ~Litu_Rout1; ~Sanjay_Shakkottai1; ~Sandeep_P._Chinchali1,"{'value': ['Time Series Generation', 'Posterior Sampling', 'Diffusion Models', 'Controlled Generation', 'Generative Models']}","{'value': 'Generating realistic time series samples is crucial for stress-testing models and protecting user privacy by using synthetic data. In engineering and safety-critical applications, these samples must meet certain hard constraints that are domain-specific or naturally imposed by physics or nature. Consider, for example, generating electricity demand patterns with constraints on peak demand times. This can be used to stress-test the functioning of power grids during adverse weather conditions. Existing approaches for generating constrained time series are either not scalable or degrade sample quality. To address these challenges, we introduce Constrained Posterior Sampling (CPS), a diffusion-based sampling algorithm that aims to project the posterior mean estimate into the constraint set after each denoising update. Notably, CPS scales to a large number of constraints ($\\sim100$) without requiring additional training. We provide theoretical justifications highlighting the impact of our projection step on sampling. Empirically, CPS outperforms state-of-the-art methods in sample quality and similarity to real time series by around 70\\% and 22\\%, respectively, on real-world stocks, traffic, and air quality datasets.'}",https://openreview.net{'value': '/pdf/f790f46f7dfa7d1362b66e40661939fa1ec8745c.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=i5rApSWC9E,{'value': 'Enhancing Deep Batch Active Learning for Regression with Imperfect Data Guided Selection'},Yinjie Min; Furong Xu; Xinyao Li; Changliang Zou; Yongdao Zhou,~Yinjie_Min1; ~Furong_Xu2; ~Xinyao_Li1; ~Changliang_Zou2; ~Yongdao_Zhou1,{'value': ['Batch mode deep active learning; Auxiliary data; Regression']},"{'value': 'Active learning (AL) reduces annotation costs by  selecting the most informative samples based on both model sensitivity and predictive uncertainty. While sensitivity can be measured through parameter gradients in an unsupervised manner, predictive uncertainty can hardly be estimated without true labels especially for  regression tasks, reducing the informativeness of actively selected samples. This paper proposes the concept of \\textit{auxiliary data} to aid the uncertainty estimation for regression tasks. With detailed theoretical analysis, we reveal that auxiliary data, despite potential distribution shifts, can provide a promising uncertainty surrogate when properly weighted. Such finding inspires our design of AGBAL, a novel AL framework that recalibrates auxiliary data losses through density ratio weighting to obtain reliable uncertainty estimates for sample selection. Extensive experiments show that AGBAL consistently outperforms existing approaches without auxiliary data across diverse synthetic and real-world datasets.'}",https://openreview.net{'value': '/pdf/5713c56e4809e80e5f27c7476700542f9905ee03.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=i3sWs5614Y,{'value': 'Transfer Learning on Edge Connecting Probability Estimation Under Graphon Model'},Yuyao Wang; Yu-Hung Cheng; Debarghya Mukherjee; Huimin Cheng,~Yuyao_Wang3; ~Yu-Hung_Cheng1; ~Debarghya_Mukherjee1; ~Huimin_Cheng1,"{'value': ['Graphon Estimation', 'Transfer Learning', 'Gromov-Wasserstein Transport', 'Neighborhood Smoothing', 'Adaptive Debiasing']}","{'value': 'Graphon models provide a flexible nonparametric framework for estimating latent connectivity probabilities in networks, enabling a range of downstream applications such as link prediction and data augmentation. However, accurate graphon estimation typically requires a large graph, whereas in practice, one often only observes a small-sized network. One approach to addressing this issue is to adopt a transfer learning framework, which aims to improve estimation in a small target graph by leveraging structural information from a larger, related source graph. In this paper, we propose a novel method, namely GTRANS, a transfer learning framework that integrates neighborhood smoothing and Gromov-Wasserstein optimal transport to align and transfer structural patterns between graphs. To prevent negative transfer, GTRANS includes an adaptive debiasing mechanism that identifies and corrects for target-specific deviations via residual smoothing. We provide theoretical guarantees on the stability of the estimated alignment matrix and demonstrate the effectiveness of GTRANS in improving the accuracy of target graph estimation through extensive synthetic and real data experiments. These improvements translate directly to enhanced performance in downstream applications, such as the graph classification task and the link prediction task.'}",https://openreview.net{'value': '/pdf/9fdf0bec54b67ea8e157e38dff92c95be29345c0.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=hzMkfIrdDT,"{'value': ""Know What You Don't Know: Uncertainty Calibration of Process Reward Models""}",Young-Jin Park; Kristjan Greenewald; Kaveh Alim; Hao Wang; Navid Azizan,~Young-Jin_Park1; ~Kristjan_Greenewald1; ~Kaveh_Alim1; ~Hao_Wang22; ~Navid_Azizan1,"{'value': ['process reward model', 'calibration', 'inference-time-scaling', 'instance-adaptive scaling']}","{'value': 'Process reward models (PRMs) play a central role in guiding inference-time scaling algorithms for large language models (LLMs).\nHowever, we observe that even state-of-the-art PRMs can be poorly calibrated. \nSpecifically, they tend to overestimate the success probability that a partial reasoning step will lead to a correct final answer, particularly when smaller LLMs are used to complete the reasoning trajectory.\nTo address this, we present a calibration approach—performed via quantile regression—that adjusts PRM outputs to better align with true success probabilities. \nLeveraging these calibrated success estimates and their associated confidence bounds, we introduce an instance-adaptive scaling (IAS) framework that dynamically adjusts the compute budget based on the estimated likelihood that a partial reasoning trajectory will yield a correct final answer.\nUnlike conventional methods that allocate a fixed number of reasoning trajectories per query, this approach adapts to each instance and reasoning step when using our calibrated PRMs. Experiments on mathematical reasoning benchmarks show that (i) our PRM calibration method achieves small calibration error, outperforming the baseline methods, (ii) calibration is crucial for enabling effective IAS, and (iii) the proposed IAS strategy reduces inference costs while maintaining final answer accuracy, utilizing less compute on more confident problems as desired.'}",https://openreview.net{'value': '/pdf/18533f919a9403854c7955628ad3488bf682b694.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=hsD30Qljz0,{'value': 'Causality-Induced Positional Encoding for Transformer-Based Representation Learning of Non-Sequential Features'},Kaichen Xu; Yihang Du; Mianpeng Liu; Zimu Yu; Xiaobo Sun,~Kaichen_Xu1; ~Yihang_Du1; ~Mianpeng_Liu2; ~Zimu_Yu1; ~Xiaobo_Sun1,{'value': ['Representation Learning; Causal Inference; Positional Encoding']},"{'value': ""Positional encoding is essential for supplementing transformer with positional information of tokens. Existing positional encoding methods demand predefined token/feature order, rendering them unsuitable for real-world data with non-sequential yet causally-related features. To address this limitation, we propose CAPE, a novel method that identifies underlying causal structure over non-sequential features as a weighted directed acyclic graph (DAG) using generalized structural equation modeling. The DAG is then embedded in hyperbolic space where its geometric structure is well-preserved using a hyperboloid model-based approach that effectively captures two important causal graph properties (causal strength & causal specificity). This step yields causality-aware positional encodings for the features, which are converted into their rotary form for integrating with transformer's self-attention mechanism. Theoretical analysis reveals that CAPE-generated rotary positional encodings possess three valuable properties for enhanced self-attention, including causal distance-induced attenuation, causal generality-induced attenuation, and robustness to positional disturbances.  We evaluate CAPE over both synthetic and real-word datasets, empirically demonstrating its theoretical properties and effectiveness in enhancing transformer for data with non-sequential features. Our code is available at https://github.com/Catchxu/CAPE.""}",https://openreview.net{'value': '/pdf/342d5680d60cef14e3f5e3bbe68b44ad46badc46.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=hiiaHn3pWd,{'value': 'Chain-of-Action: Trajectory Autoregressive Modeling for Robotic Manipulation'},Wenbo Zhang; Tianrun Hu; Hanbo Zhang; Yanyuan Qiao; Yuchu Qin; Yang Li; Jiajun Liu; Tao Kong; Lingqiao Liu; Xiao Ma,~Wenbo_Zhang9; ~Tianrun_Hu1; ~Hanbo_Zhang1; ~Yanyuan_Qiao1; ~Yuchu_Qin2; ~Yang_Li17; ~Jiajun_Liu1; ~Tao_Kong3; ~Lingqiao_Liu3; ~Xiao_Ma2,{'value': ['Robotic Manipulation']},"{'value': 'We present Chain-of-Action (CoA), a novel visuomotor policy paradigm built upon Trajectory Autoregressive Modeling. Unlike conventional approaches that predict next step action(s) forward, CoA generates an entire trajectory by explicit backward reasoning with task-specific goals through an action-level Chain-of-Thought (CoT) process. This process is unified within a single autoregressive structure: (1) the first token corresponds to a stable keyframe action that encodes the task-specific goals;  and (2) subsequent action tokens are generated autoregressively, conditioned on the initial keyframe and previously predicted actions. This backward action reasoning enforces a global-to-local structure, allowing each local action to be tightly constrained by the final goal. To further realize the action reasoning structure, CoA incorporates four complementary designs: continuous action token representation; dynamic stopping for variable-length trajectory generation; reverse temporal ensemble; and multi-token prediction to balance action chunk modeling  with global structure. As a result, CoA gives strong spatial generalization capabilities while preserving the flexibility and simplicity of a visuomotor policy. Empirically, we observe that CoA outperforms representative imitation learning algorithms such as ACT and Diffusion Policy across 60 RLBench tasks and 8 real-world tasks.'}",https://openreview.net{'value': '/pdf/d774e097a2d325f2723c0fa7c5aff730a6ab3a0e.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=hgJQcuDwm1,{'value': 'SQL-R1: Training Natural Language to SQL Reasoning Model By Reinforcement Learning'},Peixian MA; Xialie Zhuang; Chengjin Xu; Xuhui Jiang; Ran Chen; Jian Guo,~Peixian_MA1; ~Xialie_Zhuang1; ~Chengjin_Xu1; ~Xuhui_Jiang1; ~Ran_Chen4; ~Jian_Guo2,"{'value': ['NL2SQL', 'Reinforcement Learning', 'Synthetic Data', 'Model Reasoning']}","{'value': 'Natural Language to SQL (NL2SQL) enables intuitive interactions with databases by transforming natural language queries into structured SQL statements.  Despite recent advancements in enhancing human-computer interaction within database applications, significant challenges persist, particularly regarding the inference performance in complex scenarios involving multi-table joins and nested queries.   Current methodologies primarily utilize supervised fine-tuning (SFT) to train the NL2SQL model, which may limit adaptability and interpretability in new environments (e.g., finance and healthcare).\nIn order to enhance the reasoning performance of the NL2SQL model in the above complex situations, we introduce SQL-R1, a novel NL2SQL reasoning model trained by the reinforcement learning (RL) algorithms.\nWe design a specialized RL-based reward function tailored for NL2SQL tasks and discussed the impact of cold start and synthetic data on the effectiveness of intensive training. In addition, we achieve competitive accuracy using only a tiny amount of synthetic NL2SQL data for augmented training and further explore data engineering for RL. In existing experiments, SQL-R1 achieves execution accuracy of 88.6\\% and 67.1\\% on the benchmark Spider and BIRD, respectively. The code is available at https://github.com/IDEA-FinAI/SQL-R1.'}",https://openreview.net{'value': '/pdf/2548f35c650ff2f0700b176c0e8b75932c07da3f.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=hfOgywCQ8j,{'value': 'Taming generative video models for zero-shot optical flow extraction'},Seungwoo Kim; Khai Loong Aw; Klemen Kotar; Cristobal Eyzaguirre; Wanhee Lee; Yunong Liu; Jared Watrous; Stefan Stojanov; Juan Carlos Niebles; Jiajun Wu; Daniel LK Yamins,~Seungwoo_Kim2; ~Khai_Loong_Aw1; ~Klemen_Kotar1; ~Cristobal_Eyzaguirre1; ~Wanhee_Lee1; ~Yunong_Liu1; ~Jared_Watrous1; ~Stefan_Stojanov1; ~Juan_Carlos_Niebles1; ~Jiajun_Wu1; ~Daniel_LK_Yamins1,"{'value': ['optical flow', 'generative models']}","{'value': 'Extracting optical flow from videos remains a core computer vision problem. Motivated by the recent success of large general-purpose models, we ask whether frozen self-supervised video models trained only to predict future frames can be prompted, without fine-tuning, to output flow. Prior attempts to read out depth or illumination from video generators required fine-tuning; that strategy is ill-suited for flow, where labeled data is scarce and synthetic datasets suffer from a sim-to-real gap. Inspired by the Counterfactual World Model (CWM) paradigm, which can obtain point-wise correspondences by injecting a small tracer perturbation into a next-frame predictor and tracking its propagation, we extend this idea to generative video models for zero-shot flow extraction. We explore several popular architectures and find that successful zero-shot flow extraction in this manner is aided by three model properties: (1) distributional prediction of future frames (avoiding blurry or noisy outputs); (2) factorized latents that treat each spatio-temporal patch independently; and (3) random-access decoding that can condition on any subset of future pixels. These properties are uniquely present in the recently introduced Local Random Access Sequence (LRAS) architecture. Building on LRAS, we propose KL-tracing: a novel test-time inference procedure that injects a localized perturbation into the first frame, rolls out the model one step, and computes the Kullback–Leibler divergence between perturbed and unperturbed predictive distributions. Without any flow-specific fine-tuning, our method is competitive with state-of-the-art, task-specific models on the real-world TAP-Vid DAVIS benchmark and the synthetic TAP-Vid Kubric. Our results show that counterfactual prompting of controllable generative video models is an effective alternative to supervised or photometric-loss methods for high-quality flow.'}",https://openreview.net{'value': '/pdf/219c5fcbac7114e94529f6970b124876e0a9e9ad.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=hTZ0SJCGQX,{'value': 'Learning from Reward-Free Offline Data: A Case for Planning with Latent Dynamics Models'},Vlad Sobal; Wancong Zhang; Kyunghyun Cho; Randall Balestriero; Tim G. J. Rudner; Yann LeCun,~Vlad_Sobal1; ~Wancong_Zhang1; ~Kyunghyun_Cho1; ~Randall_Balestriero1; ~Tim_G._J._Rudner2; ~Yann_LeCun1,"{'value': ['self-supervised learning', 'representation learning', 'dynamic learning', 'offline rl', 'reward-free RL', 'goal-conditoined RL', 'zero-shot RL']}","{'value': 'A long-standing goal in AI is to develop agents capable of solving diverse tasks across a range of environments, including those never seen during training. Two dominant paradigms address this challenge: (i) reinforcement learning (RL), which learns policies via trial and error, and (ii) optimal control, which plans actions using a known or learned dynamics model. However, their comparative strengths in the offline setting—where agents must learn from reward-free trajectories—remain underexplored. In this work, we systematically evaluate RL and control-based methods on a suite of navigation tasks, using offline datasets of varying quality. On the RL side, we consider goal-conditioned and zero-shot methods. On the control side, we train a latent dynamics model using the Joint Embedding Predictive Architecture (JEPA) and employ it for planning. We investigate how factors such as data diversity, trajectory quality, and environment variability influence the performance of these approaches. Our results show that model-free RL benefits most from large amounts of high-quality data, whereas model-based planning generalizes better to unseen layouts and is more data-efficient, while achieving trajectory stitching performance comparable to leading model-free methods. Notably, planning with a latent dynamics model proves to be a strong approach for handling suboptimal offline data and adapting to diverse environments.'}",https://openreview.net{'value': '/pdf/5233ea1b8598dfd1eed771e087de919731ced5a1.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=hTGqC1h8Ig,{'value': 'Structural Entropy Guided Agent for Detecting and Repairing Knowledge Deficiencies in LLMs'},Yifan Wei; Xiaoyan Yu; Tengfei Pan; Angsheng Li; Li Du,~Yifan_Wei1; ~Xiaoyan_Yu1; ~Tengfei_Pan1; ~Angsheng_Li1; ~Li_Du3,"{'value': ['Synthetic Data Generation', 'llm-agents', 'self-inprovement', 'MCTS']}","{'value': 'Large language models (LLMs) have achieved unprecedented performance by leveraging vast pretraining corpora, yet their performance remains suboptimal in knowledge-intensive domains such as medicine and scientific research, where high factual precision is required.\nWhile synthetic data provides a promising avenue for augmenting domain knowledge, \nexisting methods frequently generate redundant samples that do not align with the model’s true knowledge gaps. \nTo overcome this limitation, \nwe propose a novel Structural Entropy-guided Knowledge Navigator (SENATOR) framework that addresses the intrinsic knowledge deficiencies of LLMs. \nOur approach employs the Structure Entropy (SE) metric to quantify uncertainty along knowledge graph paths and leverages Monte Carlo Tree Search (MCTS) to selectively explore regions where the model lacks domain-specific knowledge. \nGuided by these insights, the framework generates targeted synthetic data for supervised fine-tuning, enabling continuous self-improvement. \nExperimental results on LLaMA-3 and Qwen2 across multiple domain-specific benchmarks show that SENATOR effectively detects and repairs knowledge deficiencies, achieving notable performance improvements.'}",https://openreview.net{'value': '/pdf/9d7794ec03b519d23816b2e75862acc50acda2da.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=hPfICQIDOm,{'value': 'Vicinal Label Supervision for Reliable Aleatoric and Epistemic Uncertainty Estimation'},Linye Li; Yufei Chen; Xiaodong Yue,~Linye_Li1; ~Yufei_Chen1; ~Xiaodong_Yue2,{'value': ['evidentail deep learning; uncertainty estimation']},"{'value': 'Uncertainty estimation is crucial for ensuring the reliability of machine learning models in safety-critical applications. Evidential Deep Learning (EDL) offers a principled framework by modeling predictive uncertainty through Dirichlet distributions over class probabilities. However, existing EDL methods predominantly rely on level-0 hard labels, which supervised a uncertainty-aware model with full certainty. We argue that hard labels not only fail to capture epistemic uncertainty but also obscure the aleatoric uncertainty arising from inherent data noise and label ambiguity.\n  As a result, EDL models often produce degenerate Dirichlet distributions that collapse to near-deterministic outputs. \n  To overcome these limitations, we propose a vicinal risk minimization paradigm for EDL by incorporating level-1 supervision in the form of vicinally smoothed conditional label distributions. This richer supervision exposes the model to local label uncertainty, enhancing aleatoric uncertainty quantification, while also mitigating the degeneration of the Dirichlet distribution into a Dirac delta function, thereby improving epistemic uncertainty modeling.\n\tExtensive experiments show that our approach consistently outperforms standard EDL baselines across synthetic datasets, covariate-shifted out-of-distribution generalization tasks, and out-of-distribution detection benchmarks, providing more reliable uncertainty estimates.'}",https://openreview.net{'value': '/pdf/7787802812faee4d48ce8dcd994598556850b99e.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=h60y6zlPyl,{'value': 'TwinMarket: A Scalable Behavioral and Social Simulation for Financial Markets'},Yuzhe YANG; Yifei Zhang; Minghao Wu; Kaidi Zhang; Yunmiao Zhang; Honghai Yu; Yan Hu; Benyou Wang,~Yuzhe_YANG3; ~Yifei_Zhang17; ~Minghao_Wu2; ~Kaidi_Zhang2; ~Yunmiao_Zhang1; ~Honghai_Yu1; ~Yan_Hu7; ~Benyou_Wang2,"{'value': ['LLM Agent', 'Multi-Agent System', 'Human-Behavior', 'Computational Social Science', 'Computational Finance', 'Market Impact', 'Financial Market Simulation']}","{'value': 'The study of social emergence has long been a central focus in social science. Traditional modeling approaches, such as rule-based Agent-Based Models (ABMs), struggle to capture the diversity and complexity of human behavior, particularly the irrational factors emphasized in behavioral economics. Recently, large language model (LLM) agents have gained traction as simulation tools for modeling human behavior in social science and role-playing applications. Studies suggest that LLMs can account for cognitive biases, emotional fluctuations, and other non-rational influences, enabling more realistic simulations of socio-economic dynamics. In this work, we introduce TwinMarket, a novel multi-agent framework that leverages LLMs to simulate socio-economic systems. Specifically, we examine how individual behaviors, through interactions and feedback mechanisms, give rise to collective dynamics and emergent phenomena. Through experiments in a simulated stock market environment, we demonstrate how individual actions can trigger group behaviors, leading to emergent outcomes such as financial bubbles and recessions. Our approach provides valuable insights into the complex interplay between individual decision-making and collective socio-economic patterns.'}",https://openreview.net{'value': '/pdf/cefb01d52e462ade9c6e1daafffb65ed49bcaa23.pdf'},{'abstract_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=h3dbocj7po,{'value': 'GraphMaster: Automated Graph Synthesis via LLM Agents in Data-Limited Environments'},Enjun Du; Xunkai Li; Tian Jin; Zhihan Zhang; Rong-Hua Li; Guoren Wang,~Enjun_Du1; ~Xunkai_Li1; ~Tian_Jin6; ~Zhihan_Zhang7; ~Rong-Hua_Li2; ~Guoren_Wang2,"{'value': ['Graph data synthesis', 'text-attributed graphs', 'multi-agent framework', 'large language models', 'retrieval-augmented generation', 'data-limited environments']}","{'value': 'The era of foundation models has revolutionized AI research, yet Graph Foundation Models (GFMs) remain constrained by the scarcity of large-scale graph corpora. Traditional graph data synthesis techniques primarily focus on simplistic structural operations, lacking the capacity to generate semantically rich nodes with meaningful textual attributes—a critical limitation for real-world applications. While large language models (LLMs) demonstrate exceptional text generation capabilities, their direct application to graph synthesis is impeded by context window limitations, hallucination phenomena, and structural consistency challenges. To address these issues, we introduce \\textbf{GraphMaster}—the first multi-agent framework specifically designed for graph data synthesis in data-limited environments. GraphMaster orchestrates four specialized LLM agents (Manager, Perception, Enhancement, and Evaluation) that collaboratively optimize the synthesis process through iterative refinement, ensuring both semantic coherence and structural integrity. To rigorously evaluate our approach, we create new data-limited “Sub” variants of six standard graph benchmarks, specifically designed to test synthesis capabilities under realistic constraints. Additionally, we develop a novel interpretability assessment framework that combines human evaluation with a principled Grassmannian manifold-based analysis, providing both qualitative and quantitative measures of semantic coherence. Experimental results demonstrate that GraphMaster significantly outperforms traditional synthesis methods across multiple datasets, establishing a strong foundation for advancing GFMs in data-scarce environments.'}",https://openreview.net{'value': '/pdf/e15247fbacf803da9beef26d39153bd1afd55fe6.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=h3LlJ6Bh4S,{'value': 'Process vs. Outcome Reward: Which is Better for Agentic RAG Reinforcement Learning'},Wenlin Zhang; Xiangyang Li; Kuicai Dong; Yichao Wang; Pengyue Jia; Xiaopeng Li; Yingyi Zhang; Derong Xu; Zhaocheng Du; Huifeng Guo; Ruiming Tang; Xiangyu Zhao,~Wenlin_Zhang5; ~Xiangyang_Li5; ~Kuicai_Dong1; ~Yichao_Wang3; ~Pengyue_Jia1; ~Xiaopeng_Li11; ~Yingyi_Zhang4; ~Derong_Xu1; ~Zhaocheng_Du1; ~Huifeng_Guo1; ~Ruiming_Tang2; ~Xiangyu_Zhao1,"{'value': ['Process-Supervision', 'Agentic RAG']}","{'value': 'Retrieval-augmented generation (RAG) enhances large language models (LLMs) by integrating external knowledge, yet traditional RAG systems struggle with static workflows and limited adaptability for complex, multistep reasoning tasks. Agentic RAG systems, such as DeepResearch, address these issues through dynamic retrieval, iterative context refinement, and adaptive workflows. However, recent methods like Search-R1, which rely on outcome-based reinforcement learning, face challenges such as low exploration efficiency, gradient conflict, and sparse reward signals. To tackle these limitations, we introduce ReasonRAG, a novel method that leverages RAG-ProGUIDE—a high-quality dataset providing fine-grained, process-level rewards for query generation, evidence extraction, and answer generation. By employing process-supervised reinforcement learning, ReasonRAG enhances LLMs’ autonomous capabilities in search, query generation, evidence extraction, and answer synthesis. Experimental results show that ReasonRAG, utilizing RAG-ProGUIDE, outperforms existing approaches like Search-R1 and traditional RAG systems, achieving superior performance on five benchmark datasets with only 5k training instances—significantly fewer than the 90k required by Search-R1. Our code is available at https://github.com/Applied-Machine-Learning-Lab/ReasonRAG.'}",https://openreview.net{'value': '/pdf/6bf9cbff8f3341f3eda2ce07fa1fc7546b09b5a0.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=gnRgO4ZHrN,{'value': 'Understanding Fairness and Prediction Error through Subspace Decomposition and Influence Analysis'},Enze Shi; Pankaj Bhagwat; Zhixian Yang; Linglong Kong; Bei Jiang,~Enze_Shi1; ~Pankaj_Bhagwat1; ~Zhixian_Yang2; ~Linglong_Kong2; ~Bei_Jiang1,"{'value': ['Algorithmic Fairness', 'Fairness–Utility Trade-off', 'Sufficient Dimension Reduction', 'Influence Functions']}","{'value': 'Machine learning models have achieved widespread success but often inherit and amplify historical biases, resulting in unfair outcomes. Traditional fairness methods typically impose constraints at the prediction level, without addressing underlying biases in data representations. In this work, we propose a principled framework that adjusts data representations to balance predictive utility and fairness. Using sufficient dimension reduction, we decompose the feature space into target-relevant, sensitive, and shared components, and control the fairness–utility trade-off by selectively removing sensitive information. We provide a theoretical analysis of how prediction error and fairness gaps evolve as shared subspaces are added, and employ influence functions to quantify their effects on the asymptotic behavior of parameter estimates. Experiments on both synthetic and real-world datasets validate our theoretical insights and show that the proposed method effectively improves fairness while preserving predictive performance.'}",https://openreview.net{'value': '/pdf/b9718a3a833e8ba1c98b69a5400dbfdce2329998.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=gkG8JOOUF4,{'value': 'Adaptive Preference Arithmetic: A Personalized Agent with Adaptive Preference Arithmetic for Dynamic Preference Modeling'},Hongyi Nie; Yaqing Wang; Mingyang Zhou; Feiyang Pan; Quanming Yao; Zhen Wang,~Hongyi_Nie2; ~Yaqing_Wang2; ~Mingyang_Zhou3; ~Feiyang_Pan1; ~Quanming_Yao3; ~Zhen_Wang11,"{'value': ['Personalized LLM Agents', 'Dynamic Preference Modeling', 'Adaptive Preference Arithmetic']}","{'value': ""As large language models (LLMs) are increasingly used as personalized user assistants, effectively adapting to users' evolving preferences is critical for delivering high-quality personalized responses. While user preferences are often stable in content, their relative strengths shift over time due to changing goals and contexts. Therefore, modeling these dynamic preference strengths can enable finer-grained personalization. However, current methods face two major challenges: (i) limited user feedback makes it difficult to estimate preference strengths accurately, and (ii) natural language ambiguity limits the controllability of preference-guided generation. To address these issues, we propose AdaPA-Agent, a LLM-agent personalization framework that models dynamic preference strengths via Adaptive Preference Arithmetic. First,  instead of requiring additional user feedback, AdaPA-Agent employs an alignment-based strength estimation module to estimate the strength of user preferences from the existing user-agent interaction. Then, it guides controllable personalized generation by linearly combining next-token distributions, weighted by the estimated strengths of individual preferences. Experiments on two personalization tasks-conversational recommendation and personalized web interaction-demonstrate that AdaPA-Agent better aligning with users' changing intents, and has achieved over 18.9\\% and 14.2\\% improvements compared to ReAct, the widely-used agent framework.""}",https://openreview.net{'value': '/pdf/b4c1b22b6f2525c2e8b3988cbd3955898ddcb6b5.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=gfXBNBKx02,{'value': 'Option-aware Temporally Abstracted Value for Offline Goal-Conditioned Reinforcement Learning'},Hongjoon Ahn; Heewoong Choi; Jisu Han; Taesup Moon,~Hongjoon_Ahn2; ~Heewoong_Choi1; ~Jisu_Han1; ~Taesup_Moon1,"{'value': ['Reinforcement learning', 'Offline RL', 'Goal-conditioned RL', 'Hierarchical RL', 'Temporal Abstraction']}","{'value': 'Offline goal-conditioned reinforcement learning (GCRL) offers a practical learning paradigm in which goal-reaching policies are trained from abundant state–action trajectory datasets without additional environment interaction. However, offline GCRL still struggles with long-horizon tasks, even with recent advances that employ hierarchical policy structures, such as HIQL. Identifying the root cause of this challenge, we observe the following insight. Firstly, performance bottlenecks mainly stem from the high-level policy’s inability to generate appropriate subgoals. Secondly, when learning the high-level policy in the long-horizon regime, the sign of the advantage estimate frequently becomes incorrect. Thus, we argue that improving the value function to produce a clear advantage estimate for learning the high-level policy is essential. In this paper, we propose a simple yet effective solution: _**Option-aware Temporally Abstracted**_ value learning, dubbed **OTA**, which incorporates temporal abstraction into the temporal-difference learning process. By modifying the value update to be _option-aware_, our approach contracts the effective horizon length, enabling better advantage estimates even in long-horizon regimes. We experimentally show that the high-level policy learned using the OTA value function achieves strong performance on complex tasks from OGBench, a recently proposed offline GCRL benchmark, including maze navigation and visual robotic manipulation environments. Our code is available at https://github.com/ota-v/ota-v'}",https://openreview.net{'value': '/pdf/c794312c327d0ffe0afafb7de8242608e90e8462.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=geNdDlzKTG,{'value': 'Thinking in Character: Advancing Role-Playing Agents with Role-Aware Reasoning'},Yihong Tang; Kehai Chen; Muyun Yang; Zheng-Yu Niu; Jing Li; Tiejun Zhao; Min Zhang,~Yihong_Tang2; ~Kehai_Chen2; ~Muyun_Yang1; ~Zheng-Yu_Niu2; ~Jing_Li19; ~Tiejun_Zhao1; ~Min_Zhang9,"{'value': ['Role-playing', 'dialogue generation']}","{'value': 'The advancement of Large Language Models (LLMs) has spurred significant interest in Role-Playing Agents (RPAs) for applications such as emotional companionship and virtual interaction. However, recent RPAs are often built on explicit dialogue data, lacking deep, human-like internal thought processes, resulting in superficial knowledge and style expression. While Large Reasoning Models (LRMs) can be employed to simulate character thought, their direct application is hindered by attention diversion (i.e., RPAs forget their role) and style drift (i.e., overly formal and rigid reasoning rather than character-consistent reasoning). To address these challenges, this paper introduces a novel Role-Aware Reasoning (RAR) method, which consists of two important stages: Role Identity Activation (RIA) and Reasoning Style Optimization (RSO). RIA explicitly guides the model with character profiles during reasoning to counteract attention diversion, and then RSO aligns reasoning style with the character and scene via LRM distillation to mitigate style drift. Extensive experiments demonstrate that the proposed RAR significantly enhances the performance of RPAs by effectively addressing attention diversion and style drift.'}",https://openreview.net{'value': '/pdf/13ba9857bac94b2dad63ba3623ac507e152c8b17.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=gd1Dm1gHhg,{'value': 'BioOSS: A Bio-Inspired Oscillatory State System with Spatio-Temporal Dynamics'},Zhongju Yuan; Geraint A. Wiggins; Dick B.M. Botteldooren,~Zhongju_Yuan2; ~Geraint_A._Wiggins1; ~Dick_B.M._Botteldooren1,"{'value': ['oscillatory state system', 'spatio-temporal dynamics', 'bio-inspired model', 'time series tasks']}","{'value': 'Today’s deep learning architectures are primarily based on perceptron models, which do not capture the oscillatory dynamics characteristic of biological neurons. Although oscillatory systems have recently gained attention for their closer resemblance to neural behavior, they still fall short of modeling the intricate spatio-temporal interactions observed in natural neural circuits. In this paper, we propose a bio-inspired oscillatory state system (BioOSS) designed to emulate the wave-like propagation dynamics critical to neural processing, particularly in the prefrontal cortex (PFC), where complex activity patterns emerge. BioOSS comprises two interacting populations of neurons: p neurons, which represent simplified membrane-potential-like units inspired by pyramidal cells in cortical columns, and o neurons, which govern propagation velocities and modulate the lateral spread of activity. Through local interactions, these neurons produce wave-like propagation patterns. The model incorporates trainable parameters for damping and propagation speed, enabling flexible adaptation to task-specific spatio-temporal structures. We evaluate BioOSS on both synthetic and real-world tasks, demonstrating superior performance and enhanced interpretability compared to alternative architectures.'}",https://openreview.net{'value': '/pdf/d8eaa38f1be523a53f114e0dbe741a6582508cdd.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=gZjPllL9jM,{'value': 'Efficient Multi-modal Large Language Models via Progressive Consistency Distillation'},Zichen Wen; Shaobo Wang; Yufa Zhou; Junyuan Zhang; Qintong Zhang; Yifeng Gao; Zhaorun Chen; Bin Wang; Weijia Li; Conghui He; Linfeng Zhang,~Zichen_Wen1; ~Shaobo_Wang1; ~Yufa_Zhou1; ~Junyuan_Zhang2; ~Qintong_Zhang1; ~Yifeng_Gao1; ~Zhaorun_Chen1; ~Bin_Wang21; ~Weijia_Li2; ~Conghui_He2; ~Linfeng_Zhang2,"{'value': ['Efficiency', 'Multi-model Large Language Model', 'Token Compression']}","{'value': 'Visual tokens consume substantial computational resources in multi-modal large models (MLLMs), significantly compromising their efficiency. Recent works have attempted to improve efficiency by compressing visual tokens during training, either through modifications to model components or by introducing additional parameters. However, they often overlook the increased learning difficulty caused by such compression, as the model’s parameter space struggles to quickly adapt to the substantial perturbations in the feature space induced by token compression. In this work, we propose to develop Efficient MLLMs via Progressive Consistency Distillation (EPIC), a progressive learning framework. Specifically, by decomposing the feature space perturbations introduced by token compression along the token-wise and layer-wise dimensions, we introduce token consistency distillation and layer consistency distillation, respectively, aiming to reduce the training difficulty by leveraging guidance from a teacher model and following a progressive learning trajectory. Extensive experiments demonstrate the superior effectiveness, robustness, and generalization capabilities of our proposed framework.'}",https://openreview.net{'value': '/pdf/d9bb428e69188b41f310f8e8ef78a3597af11d4c.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=gRKorMGYlR,{'value': 'TractoTransformer: Diffusion MRI Streamline Tractography using CNN and Transformer Networks'},Itzik Waizman; Yakov Gusakov; Itay Benou; Tammy Riklin Raviv,~Itzik_Waizman1; ~Yakov_Gusakov1; ~Itay_Benou1; ~Tammy_Riklin_Raviv2,"{'value': ['Neuroimaging', 'Diffusion MRI', 'White Matter Tractography', 'Sequential Modeling', 'Transformers', 'Convolutional Neural Networks']}","{'value': 'White matter tractography is an advanced neuroimaging technique that reconstructs the 3D white matter pathways of the brain from diffusion MRI data. It can be framed as a pathfinding problem aiming to infer neural fiber trajectories from noisy and ambiguous measurements, facing challenges such as crossing, merging, and fanning white-matter configurations.\nIn this paper, we propose a novel tractography method that leverages Transformers to model the sequential nature of white matter streamlines, enabling the prediction of fiber directions by integrating both the trajectory context and current diffusion MRI measurements. To incorporate spatial information, we utilize CNNs that extract microstructural features from local neighborhoods around each voxel. By combining these complementary sources of information, our approach improves the precision and completeness of neural pathway mapping compared to traditional tractography models. We evaluate our method with the Tractometer toolkit, achieving competitive performance against state-of-the-art approaches, and present qualitative results on the TractoInferno dataset, demonstrating strong generalization to real-world data. The code attached to this submission will be made publicly available upon acceptance.'}",https://openreview.net{'value': '/pdf/781d121275d3a4fabc6f44735ab713586e8a4fb3.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=gMHLQASj11,{'value': 'Learnable Sampler Distillation for Discrete Diffusion Models'},Feiyang Fu; Tongxian Guo; Zhaoqiang Liu,~Feiyang_Fu2; ~Tongxian_Guo1; ~Zhaoqiang_Liu1,"{'value': ['Discrete diffusion models', 'Efficient sampling', 'Sampler distillation']}","{'value': 'Discrete diffusion models (DDMs) have shown powerful generation ability for discrete data modalities like text and molecules. However, their practical application is hindered by inefficient sampling, requiring a large number of sampling steps. Accelerating DDMs by using larger step sizes typically introduces significant problems in generation quality, as it amplifies the impact of both the compounding decoding error due to factorized predictions and discretization error from numerical approximations, leading to a significant decrease in sampling quality. To address these challenges, we propose learnable sampler distillation (LSD), a novel approach to train fast and high-fidelity samplers for DDMs. LSD employs a distillation approach where a student sampler with a few steps learns to align its intermediate score trajectory with that of a high-quality teacher sampler with numerous steps. This alignment is achieved by optimizing learnable sampler coefficients that adaptively adjust sampling dynamics. Additionally, we further propose LSD+, which also learns time schedules that allocate steps non-uniformly. Experiments across text generation, image generation, and synthetic tasks demonstrate that our proposed approaches outperform existing samplers for DDMs, achieving substantially higher sampling quality with significantly fewer sampling steps.'}",https://openreview.net{'value': '/pdf/f048f8439aafb16ad90b59f9692785006d7ce9ef.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=gJclyLFSdU,{'value': 'The World Is Bigger: A Computationally-Embedded Perspective on the Big World Hypothesis'},Alex Lewandowski; Aditya A. Ramesh; Edan Meyer; Dale Schuurmans; Marlos C. Machado,~Alex_Lewandowski1; ~Aditya_A._Ramesh1; ~Edan_Meyer1; ~Dale_Schuurmans1; ~Marlos_C._Machado1,"{'value': ['big world hypothesis', 'computational constraints', 'continual learning', 'reinforcement learning', 'algorithmic complexity']}","{'value': 'Continual learning is often motivated by the idea, known as the big world hypothesis, that the ""world is bigger"" than the agent. Recent problem formulations capture this idea by explicitly constraining an agent relative to the environment. These constraints lead to solutions in which the agent continually adapts to best use its limited capacity, rather than converging to a fixed solution. However, explicit constraints can be ad hoc, difficult to incorporate, and limiting to the effectiveness of scaling up the agent\'s capacity. In this paper, we characterize a problem setting in which an agent, regardless of its capacity, is implicitly constrained by being embedded in the environment. In particular, we introduce a computationally-embedded perspective that represents an embedded agent as an automaton simulated within a universal (formal) computer. We prove that such an automaton is implicitly constrained and that it is equivalent to an agent that interacts with a partially observable Markov decision process over a countably infinite state-space. We then propose an objective for this setting, which we call interactivity, that measures an agent\'s ability to continually adapt its behaviour and to continually learn new predictions. We develop a reinforcement learning algorithm for maximizing interactivity and a synthetic benchmark to experimentation on continual learning. Our results indicate that deep nonlinear networks struggle to sustain interactivity whereas deep linear networks can achieve higher interactivity as capacity increases.'}",https://openreview.net{'value': '/pdf/463a93594b9e688fecce37543cf3bf45e7f91310.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=gGfWAC7sqg,{'value': 'Coupling Generative Modeling and an Autoencoder with the Causal Bridge'},Ruolin Meng; Ming-Yu Chung; Dhanajit Brahma; Ricardo Henao; Lawrence Carin,~Ruolin_Meng2; ~Ming-Yu_Chung1; ~Dhanajit_Brahma1; ~Ricardo_Henao1; ~Lawrence_Carin2,"{'value': ['Causal Effect Estimation', 'Proxy Causal Learning', 'Causal Bridge']}","{'value': 'We consider inferring the causal effect of a treatment (intervention) on an outcome of interest in situations where there is potentially an unobserved confounder influencing both the treatment and the outcome. This is achievable by assuming access to two separate sets of control (proxy) measurements associated with treatment and outcomes, which are used to estimate treatment effects through a function termed the *causal bridge* (CB). We present a new theoretical perspective, associated assumptions for when estimating treatment effects with the CB is feasible, and a bound on the average error of the treatment effect when the CB assumptions are violated. From this new perspective, we then demonstrate how coupling the CB with an autoencoder architecture allows for the sharing of statistical strength between observed quantities (proxies, treatment, and outcomes), thus improving the quality of the CB estimates. Experiments on synthetic and real-world data demonstrate the effectiveness of the proposed approach relative to state-of-the-art methodology for causal inference with proxy measurements.'}",https://openreview.net{'value': '/pdf/2ead93547197edb702dcd347d27b4155abb34dec.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=g8zr9rxRHm,{'value': 'Synthesize Privacy-Preserving High-Resolution Images via Private Textual Intermediaries'},Haoxiang Wang; Zinan Lin; Da Yu; Huishuai Zhang,~Haoxiang_Wang5; ~Zinan_Lin1; ~Da_Yu1; ~Huishuai_Zhang3,"{'value': ['differential privacy', 'private evolution', 'private text bridges']}","{'value': 'Generating high-fidelity, differentially private (DP) synthetic images offers a promising route to share and analyze sensitive visual data without compromising individual privacy. However, existing DP image synthesis methods struggle to produce high-resolution outputs that faithfully capture the structure of the original data. In this paper, we introduce a novel method, referred to as Synthesis via Private Textual Intermediaries (SPTI), that can generate high-resolution DP images with easy adoptions. The key idea is to shift the challenge of DP image synthesis from the image domain to the text domain by leveraging state-of-the-art DP text generation methods. SPTI first summarizes each private image into a concise textual description using image-to-text models, then applies a modified Private Evolution algorithm to generate DP text, and finally reconstructs images using text-to-image models. Notably, SPTI requires no model training, only inferences with off-the-shelf models. Given a private dataset, SPTI produces synthetic images of substantially higher quality than prior DP approaches. On the LSUN Bedroom dataset, SPTI attains an FID $=$ 26.71 under $\\epsilon=1.0$, improving over Private Evolution’s FID of 40.36. Similarly, on MM-CelebA-HQ, SPTI achieves an FID $=$ 33.27 at $\\epsilon=1.0$, compared to 57.01 from DP fine-tuning baselines. Overall, our results demonstrate that Synthesis via Private Textual Intermediaries provides a resource-efficient and proprietary-model-compatible framework for generating high-resolution DP synthetic images, greatly expanding access to private visual datasets. Our code release: https://github.com/MarkGodrick/SPTI'}",https://openreview.net{'value': '/pdf/f42e2f976d6e90b7c28f0e5bf646d11c3064e2bb.pdf'},{'abstract_filter': 'Data Synthesis'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=g2vViuEVDS,{'value': 'Intrinsic Goals for Autonomous Agents: Model-Based Exploration in Virtual Zebrafish Predicts Ethological Behavior and Whole-Brain Dynamics'},Reece Keller; Alyn Kirsch; Felix Pei; Xaq Pitkow; Leo Kozachkov; Aran Nayebi,~Reece_Keller2; ~Alyn_Kirsch1; ~Felix_Pei1; ~Xaq_Pitkow1; ~Leo_Kozachkov1; ~Aran_Nayebi2,"{'value': ['NeuroAI', 'intrinsic motivation', 'zebrafish', 'neural-glial', 'embodied agents', 'reinforcement learning', 'autonomy.']}","{'value': 'Autonomy is a hallmark of animal intelligence, enabling adaptive and intelligent behavior in complex environments without relying on external reward or task structure. Existing reinforcement learning approaches to exploration in reward-free environments, including a class of methods known as *model-based intrinsic motivation*, exhibit inconsistent exploration patterns and do not converge to an exploratory policy, thus failing to capture robust autonomous behaviors observed in animals. Moreover, systems neuroscience has largely overlooked the neural basis of autonomy, focusing instead on experimental paradigms where animals are motivated by external reward rather than engaging in ethological, naturalistic and task-independent behavior. To bridge these gaps, we introduce a novel model-based intrinsic drive explicitly designed after the principles of autonomous exploration in animals. Our method (3M-Progress) achieves animal-like exploration by tracking divergence between an online world model and a fixed prior learned from an ecological niche. To the best of our knowledge, we introduce the first autonomous embodied agent that predicts brain data entirely from self-supervised optimization of an intrinsic goal—without any behavioral or neural training data—demonstrating that 3M-Progress agents capture the explainable variance in behavioral patterns and whole-brain neural-glial dynamics recorded from autonomously behaving larval zebrafish, thereby providing the first goal-driven, population-level model of neural-glial computation. Our findings establish a computational framework connecting model-based intrinsic motivation to naturalistic behavior, providing a foundation for building artificial agents with animal-like autonomy.'}",https://openreview.net{'value': '/pdf/5ad4cabfd095c88375d5e524dd1a4c36795ebef1.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=fvho95EtPu,{'value': 'SD-KDE: Score-Debiased Kernel Density Estimation'},Elliot L Epstein; Rajat Vadiraj Dwaraknath; Thanawat Sornwanee; John Winnicki; Jerry Weihong Liu,~Elliot_L_Epstein1; ~Rajat_Vadiraj_Dwaraknath1; ~Thanawat_Sornwanee1; ~John_Winnicki1; ~Jerry_Weihong_Liu1,"{'value': ['Kernel Density Estimation', 'Diffusion models', 'Score based models', 'Synthetic Data', 'Probabilistic modeling']}","{'value': 'We propose a method for density estimation that leverages an estimated score function to debias kernel density estimation (SD-KDE).\nIn our approach, each data point is adjusted by taking a single step along the score function with a specific choice of step size, followed by standard KDE with a modified bandwidth.\nThe step size and modified bandwidth are chosen to remove the leading order bias in the KDE, improving the asymptotic convergence rate.\nOur experiments on synthetic tasks in 1D, 2D and on MNIST, demonstrate that our proposed SD-KDE method significantly reduces the mean integrated squared error compared to the standard Silverman KDE, even with noisy estimates in the score function.\nThese results underscore the potential of integrating score-based corrections into nonparametric density estimation.'}",https://openreview.net{'value': '/pdf/537d8f95bd9580d5e74531f990be143f01b2aa1c.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=fnkkY7UGRl,{'value': 'Test-Time Scaling of Diffusion Models via Noise Trajectory Search'},Vignav Ramesh; Morteza Mardani,~Vignav_Ramesh1; ~Morteza_Mardani1,"{'value': ['diffusion model', 'test-time scaling', 'Markov decision process', 'contextual bandit', 'optimization', 'search', 'MCTS', 'epsilon-greedy']}","{'value': 'The iterative and stochastic nature of diffusion models enables *test-time scaling*, whereby spending additional compute during denoising generates higher-fidelity samples. Increasing the number of denoising steps is the primary scaling axis, but this yields quickly diminishing returns. Instead optimizing the *noise trajectory*—the sequence of injected noise vectors—is promising, as the specific noise realizations critically affect sample quality; but this is challenging due to a high-dimensional search space, complex noise-outcome interactions, and costly trajectory evaluations. We address this by first casting diffusion as a Markov Decision Process (MDP) with a terminal reward, showing tree-search methods such as Monte Carlo tree search (MCTS) to be meaningful but impractical. To balance performance and efficiency, we then resort to a relaxation of MDP, where we view denoising as a sequence of independent *contextual bandits*. This allows us to introduce an $\\epsilon$-greedy search algorithm that *globally explores* at extreme timesteps and *locally exploits* during the intermediate steps where de-mixing occurs. Experiments on EDM and Stable Diffusion reveal state-of-the-art scores for class-conditioned/text-to-image generation, exceeding baselines by up to $164$% and matching/exceeding MCTS performance. To our knowledge, this is the first practical method for test-time noise *trajectory* optimization of *arbitrary (non-differentiable)* rewards.'}",https://openreview.net{'value': '/pdf/4d56a24d67622573004b2eff8426471658531684.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=fmnxunacr4,{'value': 'Enigmata:  Scaling Logical Reasoning in Large Language Models with Synthetic Verifiable Puzzles'},Jiangjie Chen; Qianyu He; Siyu Yuan; Aili Chen; Zhicheng Cai; Weinan Dai; Hongli Yu; Jiaze Chen; Xuefeng Li; Qiying Yu; Hao Zhou; Mingxuan Wang,~Jiangjie_Chen1; ~Qianyu_He1; ~Siyu_Yuan2; ~Aili_Chen1; ~Zhicheng_Cai1; ~Weinan_Dai2; ~Hongli_Yu1; ~Jiaze_Chen1; ~Xuefeng_Li6; ~Qiying_Yu1; ~Hao_Zhou5; ~Mingxuan_Wang1,"{'value': ['Reasoning Model', 'Large Language Model', 'Reinforcement Learning', 'Logical Reasoning']}","{'value': 'Large Language Models (LLMs), such as OpenAI’s o1 and DeepSeek’s R1, excel at advanced reasoning tasks like math and coding via Reinforcement Learning with Verifiable Rewards (RLVR), but still struggle with puzzles solvable by humans without domain knowledge. We introduce ENIGMATA, the first comprehensive suite tailored for improving LLMs with puzzle reasoning skills. It includes 36 tasks across 7 categories, each with: 1) a generator that produces unlimited examples with controllable difficulty, and 2) a rule-based verifier for automatic evaluation. This generator-verifier design supports scalable, multi-task RL training, fine-grained analysis, and seamless RLVR integration. We further propose ENIGMATA-Eval, a rigorous benchmark, and develop optimized multi-task RLVR strategies. Our trained model, Qwen2.5-32B-ENIGMATA, consistently surpasses o3-mini-high and o1 on the puzzle reasoning benchmarks like ENIGMATA-Eval, ARC-AGI (32.8%), and ARC-AGI 2 (0.6%). It also generalizes well to out-of-domain puzzle benchmarks and mathematical reasoning, with little multi-tasking trade-off. When trained on larger models like Seed1.5-Thinking (20B activated parameters and 200B total parameters), puzzle data from ENIGMATA further boosts SoTA performance on advanced math and STEM reasoning tasks such as AIME (2024-2025), BeyondAIME and GPQA (Diamond), showing nice generalization benefits of ENIGMATA. This work offers a unified, controllable framework for advancing logical reasoning in LLMs. Project page: https://seed-enigmata.github.io.'}",https://openreview.net{'value': '/pdf/d16d55cfeff749792ae0b093a3f4c0123aa6c09f.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=fkYZKArFLF,{'value': 'BrainFlow: A Holistic Pathway of Dynamic Neural System on Manifold'},Zhixuan Zhou; Tingting Dan; Guorong Wu,~Zhixuan_Zhou3; ~Tingting_Dan1; ~Guorong_Wu1,{'value': ['brain network analysis; flow matching; neuroimaging analysis']},"{'value': 'A fundamental challenge in cognitive neuroscience is understanding how cognition emerges from the interplay between structural connectivity (SC) and dynamic functional connectivity (FC) in the brain. \nNetwork neuroscience has emerged as a powerful framework to understand brain function through a holistic perspective on structure-function relationships. In this context, current machine learning approaches typically seek to establish direct mappings between structural connectivity (SC) and functional connectivity (FC) associated with specific cognitive states.\nHowever, these state-independent methods often yield inconsistent results due to overlapping brain networks across cognitive states. \nTo address this limitation, we conceptualize to uncover the dendritic coupling mechanism between one static SC and multiple FCs by solving a flow problem that bridges the distribution of SC to a mixed distribution of FCs, conditioned on various cognitive states, along a Riemannian manifold of symmetric positive-definite (SPD) manifold.\nWe further prove the equivalence between flow matching on the SPD manifold and on the computationally efficient Cholesky manifold. \nSince a spare of functional connections is shared across cognitive states, we introduce the notion of consensus control to promote the shared kinetic structures between multiple FC-to-SC pathways via synchronized coordination, yielding a biologically meaningful underpinning on SC-FC coupling mechanism.\nTogether, we present BrainFlow, a reversible generative model that achieves state-of-the-art performance on not only synthetic data but also large-scale neuroimaging datasets from UK Biobank and Human Connectome Project.'}",https://openreview.net{'value': '/pdf/bc18c6d7be2a65c9c15584fad1b63927b2682bc7.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=fjBsE0kKk4,{'value': 'ZEUS: Zero-shot Embeddings for Unsupervised Separation of Tabular Data'},Patryk Marszałek; Tomasz Kuśmierczyk; Witold Wydmański; Jacek Tabor; Marek Śmieja,~Patryk_Marszałek1; ~Tomasz_Kuśmierczyk1; ~Witold_Wydmański1; ~Jacek_Tabor1; ~Marek_Śmieja1,"{'value': ['Zero-shot learning', 'clustering', 'representation learning', 'in-context learning', 'tabular data']}","{'value': 'Clustering tabular data remains a significant open challenge in data analysis and machine learning. Unlike for image data, similarity between tabular records often varies across datasets, making the definition of clusters highly dataset-dependent. Furthermore, the absence of supervised signals complicates hyperparameter tuning in deep learning clustering methods, frequently resulting in unstable performance. To address these issues and minimize the need for per-dataset tuning, we adopt an emerging approach in deep learning: zero-shot learning. We propose ZEUS, a self-contained model capable of clustering new datasets without any additional training or fine-tuning. It operates by decomposing complex datasets into meaningful components that can then be clustered effectively. Thanks to pre-training on synthetic datasets generated from a latent-variable prior, it generalizes across various datasets without requiring user intervention. To the best of our knowledge, ZEUS is the first zero-shot method capable of generating embeddings for tabular data in a fully unsupervised manner. \nExperimental results demonstrate that it performs on par with or better than traditional clustering algorithms and recent deep learning-based methods, while being significantly faster and more user-friendly.'}",https://openreview.net{'value': '/pdf/645edf18b11d505d90b76dff059b55310430c19c.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=fi24ry0BX5,{'value': 'Learning and Planning Multi-Agent Tasks via an MoE-based World Model'},Zijie Zhao; Zhongyue Zhao; Kaixuan Xu; Yuqian Fu; Jiajun Chai; Yuanheng Zhu; Dongbin Zhao,~Zijie_Zhao1; ~Zhongyue_Zhao1; ~Kaixuan_Xu1; ~Yuqian_Fu3; ~Jiajun_Chai1; ~Yuanheng_Zhu1; ~Dongbin_Zhao1,"{'value': ['Multi-task learning', 'Multi-agent reinforcement learning', 'Mixture of Experts', 'World model']}","{'value': 'Multi-task multi-agent reinforcement learning (MT-MARL) aims to develop a single model capable of solving a diverse set of tasks. However, existing methods often fall short due to the substantial variation in optimal policies across tasks, making it challenging for a single policy model to generalize effectively. In contrast, we find that many tasks exhibit **bounded similarity** in their underlying dynamics—highly similar within certain groups (e.g., door-open/close) diverge significantly between unrelated tasks (e.g., door-open \\& object-catch). To leverage this property, we reconsider the role of modularity in multi-task learning, and propose **M3W**, a novel approach that applies mixture-of-experts (MoE) to world model instead of policy, enabling both learning and planning. For learning, it uses a SoftMoE-based dynamics model alongside a SparseMoE-based predictor to facilitate knowledge reuse across similar tasks while avoiding gradient conflicts across dissimilar tasks. For planning, it evaluates and optimizes actions using the predicted rollouts from the world model, without relying directly on a explicit policy model, thereby overcoming the limitations of policy-centric methods. As the first MoE-based multi-task world model, M3W demonstrates superior performance, sample efficiency, and multi-task adaptability, as validated on Bi-DexHands with 14 tasks and MA-Mujoco with 24 tasks. The demos and anonymous code are available at \\url{https://github.com/zhaozijie2022/m3w-marl}.'}",https://openreview.net{'value': '/pdf/65f2319daa74010a4d7f5423cb7babf0c464fe05.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=fcLVqvyiqV,{'value': 'HMARL-CBF – Hierarchical Multi-Agent Reinforcement Learning with Control Barrier Functions for Safety-Critical Autonomous Systems'},H M Sabbir Ahmad; Ehsan Sabouni; Alexander Wasilkoff; Param Budhraja; Zijian Guo; Songyuan Zhang; Chuchu Fan; Christos Cassandras; Wenchao Li,~H_M_Sabbir_Ahmad1; ~Ehsan_Sabouni1; ~Alexander_Wasilkoff1; ~Param_Budhraja1; ~Zijian_Guo1; ~Songyuan_Zhang1; ~Chuchu_Fan2; ~Christos_Cassandras1; ~Wenchao_Li1,"{'value': ['Hierarchical RL', 'Multi-Agent RL', 'Safe RL', 'Control Barrier Functions', 'Safety-Critical Systems']}","{'value': 'We address the problem of safe policy learning in multi-agent safety-critical autonomous systems.\nIn such systems, it is necessary for each agent to meet the safety requirements at all times while also cooperating with other agents to accomplish the task. Toward this end, we propose a safe Hierarchical Multi-Agent Reinforcement Learning (HMARL) approach based on Control Barrier Functions (CBFs). Our proposed hierarchical approach decomposes the overall reinforcement learning problem into two levels –- learning joint cooperative behavior at the higher level and learning safe individual behavior at the lower or agent\nlevel conditioned on the high-level policy. Specifically, we propose a skill-based HMARL-CBF algorithm in which the higher-level problem involves learning a joint policy over the skills for all the agents and the lower-level problem involves\nlearning policies to execute the skills safely with CBFs. We validate our approach on challenging environment scenarios whereby a large number of agents have to safely navigate through conflicting road networks. Compared with existing state-of-the-art methods, our approach significantly improves the safety achieving near perfect (within $5\\%$) success/safety rate while also improving performance across all the environments.'}",https://openreview.net{'value': '/pdf/a131ed49c4d39f773fb55d932efc489957f59cc8.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=fbTGCEfztk,{'value': 'PhysDiff-VTON: Cross-Domain Physics Modeling and Trajectory Optimization for Virtual Try-On'},Shibin Mei; Bingbing Ni,~Shibin_Mei2; ~Bingbing_Ni3,"{'value': ['virtual try-on', 'garment deformation modeling', 'physics modeling', 'trajectory optimization']}","{'value': 'We present PhysDiff-VTON, a diffusion-based framework for image-based virtual try-on that systematically addresses the dual challenges of garment deformation modeling and high-frequency detail preservation.  The core innovation lies in integrating physics-inspired mechanisms into the diffusion process: a pose-guided deformable warping module simulates fabric dynamics by predicting spatial offsets conditioned on human pose semantics, while wavelet-enhanced feature decomposition explicitly preserves texture fidelity through frequency-aware attention.  Further enhancing generation quality, a novel sampling strategy optimizes the denoising trajectory via least action principles, enforcing temporal coherence, spatial smoothness, and multi-scale structural consistency.  Comprehensive evaluations across multiple datasets demonstrate significant improvements in both geometric plausibility and perceptual quality compared to existing approaches.  The framework establishes a new paradigm for synthesizing photorealistic try-on images that adhere to physical constraints while maintaining intricate garment details, advancing the practical applicability of diffusion models in fashion technology.'}",https://openreview.net{'value': '/pdf/20d33e19bd479e0186111104656c664afa2a0c39.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=fXG1BvwqGt,{'value': 'Less is More: an Attention-free Sequence Prediction Modeling for Offline Embodied Learning'},Wei Huang; Jianshu Zhang; Leiyu Wang; Heyue Li; Luoyi Fan; Yichen Zhu; Nanyang Ye; Qinying Gu,~Wei_Huang46; ~Jianshu_Zhang4; ~Leiyu_Wang1; ~Heyue_Li1; ~Luoyi_Fan1; ~Yichen_Zhu1; ~Nanyang_Ye1; ~Qinying_Gu1,"{'value': ['Offline Reinforcement Learning', 'Embodied Learning']}","{'value': 'Offline reinforcement learning (offline RL) is increasingly approached as a sequence modeling task, with methods leveraging advanced architectures like Transformers to capture trajectory dependencies. Despite significant progress, the mechanisms underlying their effectiveness and limitations remain insufficiently understood. We conduct a thorough analysis on the representative Decision Transformer (DT) model using an entropy analysis and identify the inconsistencies in state-action-reward ($\\langle s, a, R \\rangle$) distributions causing attention ``dispersal"". To address this, we propose a hierarchical framework that decomposes sequence modeling into intra-step relational modeling—handled by a Token Merger that fuses each $\\langle s, a, R \\rangle$ triplet—and inter-step modeling—handled by a Token Mixer across timesteps. We investigate several Token Merger designs and validate their effectiveness across various offline RL methods. \nFurthermore, our theoretical analysis and experimental results suggest that while Token Mixers are important, lightweight architecture can also achieve even better performance to more complex ones. We therefore propose a parameter-free Average Pooling Token Mixer, which, combined with a convolutional Token Merger, forms our final model, Decision HiFormer (DHi). DHi achieves a \\textbf{73.6\\%} improvement in inference speed and an \\textbf{9.3\\%} gain in policy performance on the D4RL benchmark compared to DT. DHi also generalizes well to real-world robotic manipulation tasks, offering both practical benefits and insights into sequence-based policy design for offline RL. Code and models are public at \\href{https://wei-nijuan.github.io/DecisionHiFormer/}{project page}.'}",https://openreview.net{'value': '/pdf/3845cfa9404b2e3ecb78f14ff172ee55e94408fc.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=fSPRy5uw0R,{'value': 'Bilevel Network Learning via Hierarchically Structured Sparsity'},Jiayi Fan; Jingyuan Yang; Shuangge Ma; Mengyun Wu,~Jiayi_Fan2; ~Jingyuan_Yang8; ~Shuangge_Ma1; ~Mengyun_Wu1,"{'value': ['neural network', 'network estimation', 'hierarchical selection layers', 'sparse regularization']}","{'value': ""Accurate network estimation serves as the cornerstone for understanding complex systems across scientific domains, from decoding gene regulatory networks in systems biology to identifying social relationship patterns in computational sociology. Modern applications demand methods that simultaneously address two critical challenges: capturing nonlinear dependencies between variables and reconstructing inherent hierarchical structures where higher-level entities coordinate lower-level components (e.g., functional pathways organizing gene clusters). Traditional Gaussian graphical models fundamentally fail in these aspects due to their restrictive linear assumptions and flat network representations. We propose NNBLNet, a neural network-based learning framework for bi-level network inference. The core innovation lies in hierarchical selection layers that enforce structural consistency between high-level  coordinator groups and their constituent low-level connections via adaptive sparsity constraints. This architecture is integrated with a compositional neural network architecture that learn cross-level association patterns through constrained nonlinear transformations, explicitly preserving hierarchical dependencies while overcoming the representational limitations of linear methods. Crucially, we establish formal theoretical guarantees for the consistent recovery of both high-level connections and their internal low-level structures under general statistical regimes. Extensive validation demonstrates NNBLNet's effectiveness across synthetic and real-world scenarios, achieving superior F1 scores compared to competitive methods and particularly beneficial for complex systems analysis through its interpretable bi-level structure discovery.""}",https://openreview.net{'value': '/pdf/f61d8ce8f4d4be6de50aea4ee91d7a1b4ac9d013.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=fPPfFMVTZo,{'value': 'Continuous Simplicial Neural Networks'},Aref Einizade; Dorina Thanou; Fragkiskos D. Malliaros; Jhony H. Giraldo,~Aref_Einizade1; ~Dorina_Thanou1; ~Fragkiskos_D._Malliaros1; ~Jhony_H._Giraldo1,"{'value': ['Simplicial Neural Networks', 'Partial Differential Equations', 'Over-smoothing', 'Stability']}","{'value': ""Simplicial complexes provide a powerful framework for modeling higher-order interactions in structured data, making them particularly suitable for applications such as trajectory prediction and mesh processing. However, existing simplicial neural networks (SNNs), whether convolutional or attention-based, rely primarily on discrete filtering techniques, which can be restrictive. In contrast, partial differential equations (PDEs) on simplicial complexes offer a principled approach to capture continuous dynamics in such structures. In this work, we introduce continuous simplicial neural network (COSIMO), a novel SNN architecture derived from PDEs on simplicial complexes. We provide theoretical and experimental justifications of COSIMO's stability under simplicial perturbations. Furthermore, we investigate the over-smoothing phenomenon—a common issue in geometric deep learning—demonstrating that COSIMO offers better control over this effect than discrete SNNs. Our experiments on real-world datasets demonstrate that COSIMO achieves competitive performance compared to state-of-the-art SNNs in complex and noisy environments. The implementation codes are available in https://github.com/ArefEinizade2/COSIMO.""}",https://openreview.net{'value': '/pdf/8294f52956a76573f9123263b55c8affc9e44ed5.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=fNOCsycDG4,{'value': 'Regret-Optimal Q-Learning with Low Cost for Single-Agent and Federated Reinforcement Learning'},Haochen Zhang; Zhong Zheng; Lingzhou Xue,~Haochen_Zhang8; ~Zhong_Zheng3; ~Lingzhou_Xue1,"{'value': ['Reinforcement Learning', 'Federated Learning', 'Regret', 'Policy Switching Cost', 'Communication Cost']}","{'value': 'Motivated by real-world settings where data collection and policy deployment&mdash;whether for a single agent or across multiple agents&mdash;are costly, we study the problem of on-policy single-agent reinforcement learning (RL) and federated RL (FRL) with a focus on minimizing burn-in costs (the sample sizes needed to reach near-optimal regret) and policy switching or communication costs. In parallel finite-horizon episodic Markov Decision Processes (MDPs) with $S$ states and $A$ actions, existing methods either require superlinear burn-in costs in $S$ and $A$ or fail to achieve logarithmic switching or communication costs. We propose two novel model-free RL algorithms&mdash;Q-EarlySettled-LowCost and FedQ-EarlySettled-LowCost&mdash;that are the first in the literature to simultaneously achieve: (i) the best near-optimal regret among all known model-free RL or FRL algorithms, (ii) low burn-in cost that scales linearly with $S$ and $A$, and (iii) logarithmic policy switching cost for single-agent RL or communication cost for FRL. Additionally, we establish gap-dependent theoretical guarantees for both regret and switching/communication costs, improving or matching the best-known gap-dependent bounds.'}",https://openreview.net{'value': '/pdf/9fdf381a6fd2375639fa023f4e0cbc445526c5ab.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=fGuTN7huo5,{'value': 'Self-Supervised Learning of Motion Concepts by Optimizing Counterfactuals'},Stefan Stojanov; David Wendt; Seungwoo Kim; Rahul Mysore Venkatesh; Kevin Feigelis; Klemen Kotar; Khai Loong Aw; Jiajun Wu; Daniel LK Yamins,~Stefan_Stojanov1; ~David_Wendt1; ~Seungwoo_Kim2; ~Rahul_Mysore_Venkatesh1; ~Kevin_Feigelis1; ~Klemen_Kotar1; ~Khai_Loong_Aw1; ~Jiajun_Wu1; ~Daniel_LK_Yamins1,"{'value': ['self-supervised learning', 'motion understanding', 'visual tracking', 'video foundation modeling']}","{'value': ""Estimating motion primitives from video (e.g., optical flow and occlusion) is a critically important computer vision problem with many downstream applications, including controllable video generation and robotics. Current solutions are primarily supervised on synthetic data or require tuning of situation-specific heuristics, which inherently limits these models' capabilities in real-world contexts. A natural solution to transcend these limitations would be to deploy large-scale, self-supervised video models, which can be trained scalably on unrestricted real-world video datasets. However, despite recent progress, motion-primitive extraction from large pretrained video models remains relatively underexplored. In this work, we describe Opt-CWM, a self-supervised flow and occlusion estimation technique from a pretrained video prediction model. Opt-CWM uses ``counterfactual probes'' to extract motion information from a base video model in a zero-shot fashion. The key problem we solve is optimizing the quality of these probes, using a combination of an efficient parameterization of the space counterfactual probes, together with a novel generic sparse-prediction principle for learning the probe-generation parameters in a self-supervised fashion. Opt-CWM achieves state-of-the-art performance for motion estimation on real-world videos while requiring no labeled data.""}",https://openreview.net{'value': '/pdf/36a12f29e35681fa89c3555b64c08147a32d9d44.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=fGOZjuzvJb,"{'value': 'Generative Data Augmentation via Diffusion Distillation, Adversarial Alignment, and Importance Reweighting'}",Ruyi An; Haicheng Huang; Huangjie Zheng; Mingyuan Zhou,~Ruyi_An1; ~Haicheng_Huang1; ~Huangjie_Zheng1; ~Mingyuan_Zhou1,"{'value': ['Generative Data Augmentation', 'Diffusion Model Distillation']}","{'value': ""Generative data augmentation (GDA) leverages generative models to enrich training sets with entirely new samples drawn from the modeled data distribution to achieve performance gains. However, the usage of the mighty contemporary diffusion models in GDA remains impractical: *i)* their thousand-step sampling loop inflates wall-time and energy cost per image augmentation; and *ii)* the divergence between synthetic and real distributions is unknown--classifiers trained on synthetic receive biased gradients.\nWe propose DAR-GDA, a three-stage augmentation pipeline that unites model **D**istillation, **A**dversarial alignment, and importance **R**eweighting that makes diffusion-quality augmentation both fast and optimized for improving downstream learning outcomes. \nIn particular, a teacher diffusion model is compressed into a one-step student via score distillation, slashing the time per-image cost by $>100\\times$ while preserving FID.\nDuring this distillation (D), the student model additionally undergoes adversarial alignment (A) by receiving direct training signals against real images, supplementing the teacher's guidance to better match the true data distribution.\nThe discriminator from this adversarial process inherently learns to assess the synthetic-to-real data gap. Its calibrated probabilistic outputs are then employed in reweighting (R) by importance weights that quantify the distributional gap and adjust the classification loss when training downstream models; we show that reweighting yields an unbiased stochastic estimator of the real-data risk, fostering training dynamics akin to those of genuine samples.\nExperiments validate DAR-GDA's synergistic design through progressive accuracy gains with each D-A-R stage. Our approach not only surpasses conventional non-foundation-model GDA baselines but also remarkably matches or exceeds the GDA performance of large, web-pretrained text-to-image models, despite using solely in-domain data.\nDAR-GDA thus offers diffusion-fidelity GDA samples efficiently, while correcting synthetic-to-real bias to benefit downstream tasks.""}",https://openreview.net{'value': '/pdf/42d7eb4b57a7fa885b84b0b62a12278f421cf9a9.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=fCirUh6FRb,{'value': 'FutureSightDrive: Thinking Visually with Spatio-Temporal CoT for Autonomous Driving'},Shuang Zeng; Xinyuan Chang; Mengwei Xie; Xinran Liu; Yifan Bai; Zheng Pan; Mu Xu; Xing Wei,~Shuang_Zeng4; ~Xinyuan_Chang3; ~Mengwei_Xie1; ~Xinran_Liu7; ~Yifan_Bai2; ~Zheng_Pan3; ~Mu_Xu1; ~Xing_Wei5,"{'value': ['Autonomous driving', 'Visual language action models', 'Chain of thought', 'Autoregressive image generation', 'Visual reasoning', 'Unified generation understanding']}","{'value': 'Vision–Language–Action (VLA) models are increasingly used for end-to-end driving due to their world knowledge and reasoning ability. Most prior work, however, inserts textual chains-of-thought (CoT) as intermediate steps tailored to the current scene. Such symbolic compressions can blur spatio-temporal relations and discard fine visual cues, creating a cross-modal gap between perception and planning.\nWe propose FSDrive, a visual spatio-temporal CoT framework that enables VLAs to think in images. The model first acts as a world model to generate a unified future frame that overlays coarse but physically-plausible priors—future lane dividers and 3D boxes—on the predicted future image. This unified frame serves as the visual CoT, capturing both spatial structure and temporal evolution. The same VLA then functions as an inverse-dynamics model, planning trajectories from current observations and the visual CoT.\nTo equip VLAs with image generation while preserving understanding, we introduce a unified pre-training paradigm that expands the vocabulary to include visual tokens and jointly optimizes VQA (for semantics) and future-frame prediction (for dynamics). A progressive easy-to-hard scheme first predicts lane/box priors to enforce physical constraints, then completes full future frames for fine details.\nOn nuScenes and NAVSIM, FSDrive improves trajectory accuracy and reduces collisions under both ST-P3 and UniAD metrics, and attains competitive FID for future-frame generation despite using lightweight autoregression. It also advances scene understanding on DriveLM. Together, these results indicate that visual CoT narrows the cross-modal gap and yields safer, more anticipatory planning.\nCode is available at https://github.com/MIV-XJTU/FSDrive.'}",https://openreview.net{'value': '/pdf/fbba0847160a598188317e0885484ad6c0596097.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=f3sZjkQbv2,{'value': 'ReasonFlux-PRM: Trajectory-Aware PRMs for Long Chain-of-Thought Reasoning in LLMs'},Jiaru Zou; Ling Yang; Jingwen Gu; Jiahao Qiu; Ke Shen; Jingrui He; Mengdi Wang,~Jiaru_Zou1; ~Ling_Yang1; ~Jingwen_Gu1; ~Jiahao_Qiu1; ~Ke_Shen2; ~Jingrui_He1; ~Mengdi_Wang1,"{'value': ['Process Reward Models', 'Inference Scaling', 'LLMs', 'Reasoning Trajectories Selection']}","{'value': 'Process Reward Models (PRMs) have recently emerged as a powerful framework for supervising intermediate reasoning steps in large language models (LLMs). Previous PRMs are primarily trained on model final output responses and struggle to evaluate intermediate thinking trajectories robustly, especially in the emerging setting of trajectory–response outputs generated by frontier reasoning models like Deepseek-R1.  In this work, we introduce ReasonFlux-PRM, a novel trajectory-aware PRM explicitly designed to evaluate the trajectory-response type of reasoning traces. ReasonFlux-PRM incorporates both step-level and trajectory-level supervision, enabling fine-grained reward assignment aligned with structured chain-of-thought data. We adapt ReasonFlux-PRM to support reward supervision under both offline and online settings, including (i) selecting high-quality model distillation data for downstream supervised fine-tuning of smaller models, (ii) providing dense process-level rewards for policy optimization during reinforcement learning, and (iii) enabling reward-guided Best-of-N test-time scaling.  Empirical results on challenging downstream benchmarks such as AIME, MATH500, and GPQA-Diamond demonstrate that ReasonFlux-PRM-7B selects higher quality data than strong PRMs (e.g., Qwen2.5-Math-PRM-72B) and human-curated baselines. Furthermore, ReasonFlux-PRM-7B yields consistent performance improvements, achieving average gains of 12.1\\% in supervised fine-tuning, 4.5\\% in reinforcement learning, and 6.3\\% in test-time scaling. We also release an efficient ReasonFlux-PRM-1.5B for resource-constrained applications and edge deployment. Our code and models are released at https://github.com/Gen-Verse/ReasonFlux.'}",https://openreview.net{'value': '/pdf/88d9323f85c36e29c52ce3a3cae948c2b2598eb2.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=eumRwpgdMU,{'value': 'ARIA: Training Language Agents with Intention-driven Reward Aggregation'},Ruihan Yang; Yikai Zhang; Aili Chen; Xintao Wang; Jiangjie Chen; Siyu Yuan; Deqing Yang; Yanghua Xiao,~Ruihan_Yang3; ~Yikai_Zhang6; ~Aili_Chen1; ~Xintao_Wang2; ~Jiangjie_Chen1; ~Siyu_Yuan2; ~Deqing_Yang1; ~Yanghua_Xiao1,"{'value': ['Language Agent', 'Agent Learning', 'Reinforcement Learning']}","{'value': 'Large language models (LLMs) have enabled agents to perform complex reasoning and decision-making through free-form language interactions. However, in open-ended language action environments (e.g., negotiation or question-asking games), the action space can be formulated as a joint distribution over tokens, resulting in an extremely large and combinatorial action space. Sampling actions in such a space can lead to extreme reward sparsity, which brings large reward variance, hindering effective reinforcement learning (RL). To address this, we propose **ARIA**, a method that **A**ggregates **R**ewards in **I**ntention space to enable efficient and effective language **A**gents training. ARIA aims to project natural language actions from the high-dimensional joint token distribution space into a low-dimensional intention space, where semantically similar actions are clustered and assigned shared rewards. This intention-aware reward aggregation reduces reward variance by densifying reward signals, fostering efficient and effective policy optimization. Extensive experiments demonstrate that ARIA not only significantly reduces gradient variance, but also delivers substantial performance gains of average 9.95% across four downstream tasks (e.g., negotiation and text-based games), consistently outperforming strong offline and online RL baselines.'}",https://openreview.net{'value': '/pdf/61e6b62ea781f638b7b6cae2c3ea12b7e42ed96d.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=eszmES7j1F,{'value': 'Flatten Graphs as Sequences: Transformers are Scalable Graph Generators'},Dexiong Chen; Markus Krimmel; Karsten Borgwardt,~Dexiong_Chen1; ~Markus_Krimmel1; ~Karsten_Borgwardt2,"{'value': ['graph generation', 'transformers', 'autoregressive modeling', 'language models', 'LLMs']}","{'value': 'We introduce AutoGraph, a scalable autoregressive model for attributed graph generation using decoder-only transformers. By flattening graphs into random sequences of tokens through a reversible process, AutoGraph enables modeling graphs as sequences without relying on additional node features that are expensive to compute, in contrast to diffusion-based approaches. This results in sampling complexity and sequence lengths that scale optimally linearly with the number of edges, making it scalable and efficient for large, sparse graphs. A key success factor of AutoGraph is that its sequence prefixes represent induced subgraphs, creating a direct link to sub-sentences in language modeling. Empirically, AutoGraph achieves state-of-the-art performance on synthetic and molecular benchmarks, with up to 100x faster generation and 3x faster training than leading diffusion models. It also supports substructure-conditioned generation without fine-tuning and shows promising transferability, bridging language modeling and graph generation to lay the groundwork for graph foundation models. Our code is available at https://github.com/BorgwardtLab/AutoGraph.'}",https://openreview.net{'value': '/pdf/64095e8c5db33e1399f248defa3088a459a067e4.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=ei20AX8EkP,{'value': 'Measure-Theoretic Anti-Causal Representation Learning'},Arman Behnam; Binghui Wang,~Arman_Behnam1; ~Binghui_Wang2,"{'value': ['Representation Learning', 'Causality', 'Measure Theory']}","{'value': 'Causal representation learning in the anti-causal setting—labels cause features rather than the reverse—presents unique challenges requiring specialized approaches. We propose Anti-Causal Invariant Abstractions (ACIA), a novel measure-theoretic framework for anti-causal representation learning.  ACIA employs a two-level design: low-level representations capture how labels generate observations, while high-level representations learn stable causal patterns across environment-specific variations. ACIA addresses key limitations of existing approaches by: (1) accommodating prefect and imperfect interventions through interventional kernels, (2) eliminating dependency on explicit causal structures, (3) handling high-dimensional data effectively, and (4) providing theoretical guarantees for out-of-distribution generalization. Experiments on synthetic  and real-world medical datasets demonstrate that ACIA consistently outperforms state-of-the-art methods in both accuracy and invariance metrics. Furthermore, our theoretical results establish tight bounds on performance gaps between training and unseen environments, confirming the efficacy of our approach for robust anti-causal learning. {{Code is available at \\url{https://github.com/ArmanBehnam/ACIA}}}.'}",https://openreview.net{'value': '/pdf/a628763de31b91eef449293f5ccd808405d746f2.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=eb71SNTjux,{'value': 'Right for the Right Reasons: Avoiding Reasoning Shortcuts via Prototypical Neurosymbolic AI'},Luca Andolfi; Eleonora Giunchiglia,~Luca_Andolfi1; ~Eleonora_Giunchiglia1,"{'value': ['neurosymbolic AI', 'reasoning shortcuts']}","{'value': 'Neurosymbolic AI is growing in popularity thanks to its ability to combine neural perception and symbolic reasoning in end-to-end trainable models. However, recent findings reveal these are prone to shortcut reasoning, i.e., to learning unindented concepts--or neural predicates--which exploit spurious correlations to satisfy the symbolic constraints. In this paper, we address reasoning shortcuts at their root cause and we introduce prototypical neurosymbolic architectures. These models are able to satisfy the symbolic constraints (be right) because they have learnt the correct basic concepts (for the right reasons) and not because of spurious correlations, even in extremely low data regimes. Leveraging the theory of prototypical learning, we demonstrate that we can effectively avoid reasoning shortcuts by training the models to satisfy the background knowledge while taking into account the similarity of the input with respect to the handful of labelled datapoints. We extensively validate our approach on the recently proposed rsbench benchmark suite in a variety of settings and tasks with very scarce supervision: we show significant improvements in learning the right concepts both in synthetic tasks (MNIST-EvenOdd and Kand-Logic) and real-world, high-stake ones (BDD-OIA). Our findings pave the way to prototype grounding as an effective, annotation-efficient strategy for safe and reliable neurosymbolic learning.'}",https://openreview.net{'value': '/pdf/84d2f5373daff534dde49d69f2d8c59328773580.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=eXckZbaYma,{'value': 'SCOUT: Teaching Pre-trained Language Models to Enhance Reasoning via Flow Chain-of-Thought'},Guanghao Li; Wenhao Jiang; Mingfeng Chen; Yan Li; Hao Yu; Shuting Dong; Tao Ren; Ming Tang; Chun Yuan,~Guanghao_Li1; ~Wenhao_Jiang1; ~Mingfeng_Chen1; ~Yan_Li18; ~Hao_Yu20; ~Shuting_Dong1; ~Tao_Ren2; ~Ming_Tang5; ~Chun_Yuan1,"{'value': ['Recursive reasoning', 'Flow Chain-of-Thought']}","{'value': 'Chain-of-Thought (CoT) prompting improves the reasoning performance of large language models (LLMs) by encouraging step-by-step thinking. However, CoT-based methods depend on  intermediate reasoning steps, which limits scalability and generalization. Recent work explores recursive reasoning, where LLMs reuse internal layers across iterations to refine latent representations without explicit CoT supervision. While promising, these approaches often require costly pretraining and lack a principled framework for how reasoning should evolve across iterations.\nWe address this gap by introducing **Flow Chain-of-Thought (Flow CoT)**, a reasoning paradigm that models recursive inference as a progressive trajectory of latent cognitive states. Flow CoT frames each iteration as a distinct cognitive stage—deepening reasoning across iterations without relying on manual supervision. To realize  this, we propose **SCOUT** (*Stepwise Cognitive Optimization Using Teachers*), a lightweight fine-tuning framework that enables Flow CoT-style reasoning without the need for pretraining. SCOUT uses progressive distillation to align each iteration with a teacher of appropriate capacity, and a cross-attention-based retrospective module that integrates outputs from previous iterations while preserving the model’s original computation flow.\nExperiments across eight reasoning benchmarks show that SCOUT consistently improves both accuracy and explanation quality, achieving up to 1.8\\% gains under fine-tuning. Qualitative analyses further reveal that SCOUT enables progressively deeper reasoning across iterations—refining both belief formation and explanation granularity. These results not only validate the effectiveness of SCOUT, but also demonstrate the practical viability of Flow CoT as a scalable framework for enhancing reasoning in LLMs.'}",https://openreview.net{'value': '/pdf/e31dcc29db400a0d8f2b23e4dca55cc1663442a1.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=eXO6g7BmOA,{'value': 'OSVI-WM: One-Shot Visual Imitation for Unseen Tasks using World-Model-Guided Trajectory Generation'},Raktim Gautam Goswami; Prashanth Krishnamurthy; Yann LeCun; Farshad Khorrami,~Raktim_Gautam_Goswami1; ~Prashanth_Krishnamurthy1; ~Yann_LeCun1; ~Farshad_Khorrami1,"{'value': ['One-Shot Visual Imitation Learning', 'World Model', 'Robot Learning']}","{'value': 'Visual imitation learning enables robotic agents to acquire skills by observing expert demonstration videos. In the one-shot setting, the agent generates a policy after observing a single expert demonstration without additional fine-tuning. Existing approaches typically train and evaluate on the same set of tasks, varying only object configurations, and struggle to generalize to unseen tasks with different semantic or structural requirements. While some recent methods attempt to address this, they exhibit low success rates on hard test tasks that, despite being visually similar to some training tasks, differ in context and require distinct responses. Additionally, most existing methods lack an explicit model of environment dynamics, limiting their ability to reason about future states. To address these limitations, we propose a novel framework for one-shot visual imitation learning via world-model-guided trajectory generation. Given an expert demonstration video and the agent’s initial observation, our method leverages a learned world model to predict a sequence of latent states and actions. This latent trajectory is then decoded into physical waypoints that guide the agent’s execution. Our method is evaluated on two simulated benchmarks and three real-world robotic platforms, where it consistently outperforms prior approaches, with over 30% improvement in some cases.'}",https://openreview.net{'value': '/pdf/dad65bc9e6ed1e1f68070820040f812d82f42adb.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=eX5aXfJQZc,{'value': 'Force Prompting: Video Generation Models Can Learn And Generalize Physics-based Control Signals'},Nate Gillman; Charles Herrmann; Michael Freeman; Daksh Aggarwal; Evan Luo; Deqing Sun; Chen Sun,~Nate_Gillman1; ~Charles_Herrmann1; ~Michael_Freeman1; ~Daksh_Aggarwal1; ~Evan_Luo2; ~Deqing_Sun2; ~Chen_Sun1,"{'value': ['controllable video generation', 'physical forces', 'synthetic data']}","{'value': 'Recent advances in video generation models have sparked interest in world models capable of simulating realistic environments.\nWhile navigation has been well-explored, physically meaningful interactions that mimic real-world forces remain largely understudied. \nIn this work, we investigate using physical forces as a control signal for video generation and propose force prompts which enable users to interact with images through both localized point forces, such as poking a plant, and global wind force fields, such as wind blowing on fabric. We demonstrate that these force prompts can enable videos to respond realistically to physical control signals by leveraging the physical prior in the original pretrained model, without using any 3D asset or physics simulator at inference. The primary challenge of force prompting is the difficulty in obtaining high quality paired force-video training data, both in the real world due to the difficulty of obtaining force signals, and in synthetic data due to limitations in the visual quality and domain diversity of physics simulators. Our key finding is that video generation models can *generalize* remarkably well when adapted to follow physical force conditioning from videos synthesized by Blender, even with limited demonstrations of few objects (e.g., flying flags, rolling balls, etc.). Our method can generate videos which simulate forces across diverse geometries, settings, and materials. We also try to understand the source of this generalization and perform ablations on the training data that reveal two key elements: visual diversity and the use of specific text keywords during training. Our approach is trained on only around 15k training examples for a single day on four A100 GPUs, and outperforms existing methods on force adherence and physics realism, bringing world models closer to real-world physics interactions. All datasets, code, and model weights will be open-sourced. Video examples can be found at https://sites.google.com/view/force-prompting-neurips2025'}",https://openreview.net{'value': '/pdf/83f23aff6d59602e22432a48c3869c9f56b4bba9.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=eOZFqyE9Ok,{'value': 'Plasticity as the Mirror of Empowerment'},David Abel; Michael Bowling; Andre Barreto; Will Dabney; Shi Dong; Steven Stenberg Hansen; Anna Harutyunyan; Khimya Khetarpal; Clare Lyle; Razvan Pascanu; Georgios Piliouras; Doina Precup; Jonathan Richens; Mark Rowland; Tom Schaul; Satinder Singh,~David_Abel1; ~Michael_Bowling1; ~Andre_Barreto1; ~Will_Dabney1; ~Shi_Dong1; ~Steven_Stenberg_Hansen1; ~Anna_Harutyunyan1; ~Khimya_Khetarpal1; ~Clare_Lyle1; ~Razvan_Pascanu1; ~Georgios_Piliouras1; ~Doina_Precup1; ~Jonathan_Richens1; ~Mark_Rowland1; ~Tom_Schaul2; ~Satinder_Singh2,"{'value': ['Plasticity', 'Empowerment', 'Agents', 'Reinforcement Learning', 'Continual Reinforcement Learning', 'Information Theory']}","{'value': 'Agents are minimally entities that are influenced by their past observations and act to influence future observations. This latter capacity is captured by empowerment, which has served as a vital framing concept across artificial intelligence and cognitive science. This former capacity, however, is equally foundational: In what ways, and to what extent, can an agent be influenced by what it observes? In this paper, we ground this concept in a universal agent-centric measure that we refer to as plasticity, and reveal a fundamental connection to empowerment. Following a set of desiderata on a suitable definition, we define plasticity using a new information-theoretic quantity we call the generalized directed information. We show that this new quantity strictly generalizes the directed information introduced by Massey (1990) while preserving all of its desirable properties. Under this definition, we find that plasticity is well thought of as the mirror of empowerment: The two concepts are defined using the same measure, with only the direction of influence reversed. Our main result establishes a tension between the plasticity and empowerment of an agent, suggesting that agent design needs to be mindful of both characteristics. We explore the implications of these findings, and suggest that plasticity, empowerment, and their relationship are essential to understanding agency.'}",https://openreview.net{'value': '/pdf/1da0f949b4feb28e9cc758652d9baf74687e823a.pdf'},{'abstract_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=eLHIERUitQ,{'value': 'FAME: Adaptive Functional Attention with Expert Routing for Function-on-Function Regression'},Yifei Gao; Yong Chen; Chen Zhang,~Yifei_Gao5; ~Yong_Chen5; ~Chen_Zhang2,{'value': ['Functional Attention; Function-on-Function Regression;Bidirectional NCDE;Mixture-of-Experts']},"{'value': 'Functional data play a pivotal role across science and engineering, yet their infinite-dimensional nature makes representation learning challenging. Conventional statistical models depend on pre-chosen basis expansions or kernels, limiting the flexibility of data-driven discovery, while many deep-learning pipelines treat functions as fixed-grid vectors, ignoring inherent continuity. In this paper, we introduce Functional Attention with a Mixture-of-Experts (FAME), an end-to-end, fully data-driven framework for function-on-function regression. FAME forms continuous attention by coupling a bidirectional neural controlled differential equation with MoE-driven vector fields to capture intra-functional continuity, and further fuses change to inter-functional dependencies via multi-head cross attention. Extensive experiments on synthetic and real-world functional regression benchmarks show that FAME achieves state-of-the-art accuracy and strong robustness to arbitrarily sampled discrete observations of functions.'}",https://openreview.net{'value': '/pdf/38c2191440f50d4ca7cc121075e1caf2423da876.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=eIf9GNcA5n,{'value': 'DriveDPO: Policy Learning via Safety DPO For End-to-End Autonomous Driving'},ShuYao Shang; Yuntao Chen; Yuqi Wang; Yingyan Li; Zhaoxiang Zhang,~ShuYao_Shang1; ~Yuntao_Chen1; ~Yuqi_Wang3; ~Yingyan_Li1; ~Zhaoxiang_Zhang3,"{'value': ['End-to-End Autonomous Driving', 'Direct Preference Optimization', 'Imitation Learning']}","{'value': 'End-to-end autonomous driving has substantially progressed by directly predicting future trajectories from raw perception inputs, which bypasses traditional modular pipelines. However, mainstream methods trained via imitation learning suffer from critical safety limitations, as they fail to distinguish between trajectories that appear human-like but are potentially unsafe. Some recent approaches attempt to address this by regressing multiple rule-driven scores but decoupling supervision from policy optimization, resulting in suboptimal performance. To tackle these challenges, we propose DriveDPO, a Safety Direct Preference Optimization Policy Learning framework. First, we distill a unified policy distribution from human imitation similarity and rule-based safety scores for direct policy optimization. Further, we introduce an iterative Direct Preference Optimization stage formulated as trajectory-level preference alignment. Extensive experiments on the NAVSIM benchmark demonstrate that DriveDPO achieves a new state-of-the-art PDMS of 90.0. Furthermore, qualitative results across diverse challenging scenarios highlight DriveDPO’s ability to produce safer and more reliable driving behaviors.'}",https://openreview.net{'value': '/pdf/00ea894a65a86a5201d08e0a2adfe1a8fcd28ed4.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=eFB9VlI3ew,{'value': 'Place Cells as Multi-Scale Position Embeddings: Random Walk Transition Kernels for Path Planning'},Minglu Zhao; Dehong Xu; Deqian Kong; Wenhao Zhang; Ying Nian Wu,~Minglu_Zhao1; ~Dehong_Xu1; ~Deqian_Kong1; ~Wenhao_Zhang3; ~Ying_Nian_Wu1,"{'value': ['place cells', 'population coding', 'position embedding', 'random walk transition kernels', 'path planning', 'spatial navigation', 'cognitive map']}","{'value': 'The hippocampus supports spatial navigation by encoding cognitive maps through collective place cell activity. We model the place cell population as non-negative spatial embeddings derived from the spectral decomposition of multi-step random walk transition kernels. In this framework, inner product or equivalently Euclidean distance between embeddings encode similarity between locations in terms of their transition probability across multiple scales, forming a cognitive map of adjacency. The combination of non-negativity and inner-product structure naturally induces sparsity, providing a principled explanation for the localized firing fields of place cells without imposing explicit constraints. The temporal parameter that defines the diffusion scale also determines field size, aligning with the hippocampal dorsoventral hierarchy. Our approach constructs global representations efficiently through recursive composition of local transitions, enabling smooth, trap-free navigation and preplay-like trajectory generation. Moreover, theta phase arises intrinsically as the angular relation between embeddings, linking spatial and temporal coding within a single representational geometry.'}",https://openreview.net{'value': '/pdf/2ab40a17165afa77b822b09b615f4fcf88f18946.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=e0HQiao2F0,{'value': 'Mixed-Sample SGD: an End-to-end Analysis of Supervised Transfer Learning'},Yuyang Deng; Samory Kpotufe,~Yuyang_Deng3; ~Samory_Kpotufe3,"{'value': ['Transfer learning', 'domain adaptation']}","{'value': 'Theoretical works on supervised transfer learning (STL)---where the learner has access to labeled samples from both source and target distributions---have for the most part focused on statistical aspects of the problem, while efficient optimization has received less attention. \nWe consider the problem of designing an SGD procedure \nfor STL that alternates sampling between source and target data, while maintaining statistical transfer guarantees without prior knowledge of the quality of the source data. \nA main algorithmic difficulty is in understanding how to design such an adaptive sub-sampling mechanism at each SGD step, to automatically gain from the source when it is informative, or bias towards the target and avoid negative transfer when the source is less informative. \n \n We show that, such a mixed-sample SGD procedure is feasible for general prediction tasks with convex losses, rooted in tracking an abstract sequence of constrained convex programs that serve to maintain the desired transfer guarantees. \n We instantiate these results in the concrete setting of linear regression with square loss, and show that the procedure converges, with $1/\\sqrt{T}$ rate, to a solution whose statistical performance on the target is adaptive to the a priori unknown quality of the source. Experiments with synthetic and real datasets support the theory.'}",https://openreview.net{'value': '/pdf/5d8db50f45b9d42db10d8b0d0fd2b885d05b3d11.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=e0Dn7dg395,{'value': 'A Practical Guide for Incorporating Symmetry in Diffusion Policy'},Dian Wang; Boce Hu; Shuran Song; Robin Walters; Robert Platt,~Dian_Wang1; ~Boce_Hu1; ~Shuran_Song3; ~Robin_Walters1; ~Robert_Platt1,"{'value': ['Robotic Manipulation', 'Equivariance', 'Diffusion Model']}","{'value': 'Recently, equivariant neural networks for policy learning have shown promising improvements in sample efficiency and generalization, however, their wide adoption faces substantial barriers due to implementation complexity. Equivariant architectures typically require specialized mathematical formulations and custom network design, posing significant challenges when integrating with modern policy frameworks like diffusion-based models. In this paper, we explore a number of straightforward and practical approaches to incorporate symmetry benefits into diffusion policies without the overhead of full equivariant designs. Specifically, we investigate (i) invariant representations via relative trajectory actions and eye-in-hand perception, (ii) integrating equivariant vision encoders, and (iii) symmetric feature extraction with pretrained encoders using Frame Averaging. We first prove that combining eye-in-hand perception with relative or delta action parameterization yields inherent SE(3)-invariance, thus improving policy generalization. We then perform a systematic experimental study on those design choices for integrating symmetry in diffusion policies, and conclude that an invariant representation with equivariant feature extraction significantly improves the policy performance. Our method achieves performance on par with or exceeding fully equivariant architectures while greatly simplifying implementation.'}",https://openreview.net{'value': '/pdf/d427614c2e0af617651f92377543e95e25c8cd46.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=dye9w8IOV0,{'value': 'Collaborative Reasoner: Self-Improving Social Agents with Synthetic Conversations'},Ansong Ni; Ruta Desai; Yang Li; Xinjie Lei; Dong Wang; Jiemin Zhang; Jane Yu; Ramya Raghavendra; Gargi Ghosh; Shang-Wen Li; Asli Celikyilmaz,~Ansong_Ni1; ~Ruta_Desai1; ~Yang_Li112; ~Xinjie_Lei1; ~Dong_Wang43; ~Jiemin_Zhang1; ~Jane_Yu1; ~Ramya_Raghavendra1; ~Gargi_Ghosh3; ~Shang-Wen_Li1; ~Asli_Celikyilmaz1,"{'value': ['collaborative reasoning', 'social agents', 'synthetic data', 'self-improvement']}","{'value': 'With increasingly powerful large language models (LLMs) and LLM-based agents tackling an ever-growing list of tasks, we envision a future where numerous LLM agents work seamlessly with other AI agents and humans to solve complex problems and enhance daily life. To achieve these goals, LLM agents must develop collaborative skills such as effective persuasion, assertion and disagreement, which are often overlooked in the prevalent single-turn training and evaluation of LLMs. In this work, we present Collaborative Reasoner (Coral), a framework to evaluate and improve the collaborative reasoning abilities of language models. In particular, tasks and metrics in Coral necessitate agents to disagree with incorrect solutions, convince their partners of a correct solution, and ultimately agree as a team to commit to a final solution, all through a natural multi-turn conversation. Through comprehensive evaluation on six collaborative reasoning tasks covering domains of coding, math, scientific QA and social reasoning, we show that current models cannot effectively collaborate due to undesirable social behaviors, collapsing even on problems that they can solve singlehandedly. To improve the collaborative reasoning capabilities of LLMs, we propose a self-play method to generate synthetic multi-turn preference data and further train the language models to be better collaborators. Experiments with Llama-3.1, Ministral and Qwen-2.5 models show that our proposed self-improvement approach consistently outperforms finetuned chain-of-thought performance of the same base model, yielding gains up to 16.7% absolute. Human evaluations show that the models exhibit more effective disagreement and produce more natural conversations after training on our synthetic interaction data.'}",https://openreview.net{'value': '/pdf/42a338bca40ea896002753679729eb2240bf62b3.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=drmIBh6v2U,{'value': 'Disentangling misreporting from genuine adaptation in strategic settings: a causal approach'},Dylan Zapzalka; Trenton Chang; Lindsay Warrenburg; Sae-Hwan Park; Daniel K Shenfeld; Ravi B Parikh; Jenna Wiens; Maggie Makar,~Dylan_Zapzalka1; ~Trenton_Chang1; ~Lindsay_Warrenburg1; ~Sae-Hwan_Park1; ~Daniel_K_Shenfeld1; ~Ravi_B_Parikh1; ~Jenna_Wiens1; ~Maggie_Makar1,"{'value': ['Causal Inference', 'Machine Learning', 'Strategic Adaptation', 'Misreporting']}","{'value': 'In settings where ML models are used to inform the allocation of resources, agents affected by the allocation decisions might have an incentive to strategically change their features to secure better outcomes. While prior work has studied strategic responses broadly, disentangling misreporting from genuine adaptation remains a fundamental challenge. In this paper, we propose a causally-motivated approach to identify and quantify how much an agent misreports on average by distinguishing deceptive changes in their features from genuine adaptation. Our key insight is that, unlike genuine adaptation, misreported features do not causally affect downstream variables (i.e., causal descendants). We exploit this asymmetry by comparing the causal effect of misreported features on their causal descendants as derived from manipulated datasets against those from unmanipulated datasets. We formally prove identifiability of the misreporting rate and characterize the variance of our estimator. We empirically validate our theoretical results using a semi-synthetic and real Medicare dataset with misreported data, demonstrating that our approach can be employed to identify misreporting in real-world scenarios.'}",https://openreview.net{'value': '/pdf/c72ad2b78f0c77b12c12ef146eb4bfbcf509c387.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=dpllevHMbc,{'value': 'Functional Scaling Laws in Kernel Regression: Loss Dynamics and Learning Rate Schedules'},Binghui Li; Fengling Chen; Zixun Huang; Lean Wang; Lei Wu,~Binghui_Li1; ~Fengling_Chen2; ~Zixun_Huang4; ~Lean_Wang1; ~Lei_Wu1,"{'value': ['Scaling Laws', 'Learning Rate Schedule', 'Kernel Regression', 'LLM Pre-Training', 'Loss Dynamics']}","{'value': 'Scaling laws have emerged as a unifying lens for understanding and guiding the training of large language models (LLMs).  However, existing studies predominantly focus on the final-step loss, leaving open whether the entire $\\textit{loss dynamics}$ obey similar laws and, crucially, how the $\\textit{learning rate schedule}$ (LRS) shapes them. We address these gaps in a controlled theoretical setting by analyzing stochastic gradient descent (SGD) on a power-law kernel regression model. The key insight is a novel $\\textbf{intrinsic-time}$ viewpoint, which captures the training progress more faithfully than iteration count. We then establish a $\\textbf{Functional Scaling Law (FSL)}$ that captures the full loss trajectory under arbitrary LRSs, with the schedule’s influence entering through a simple convolutional functional. We further instantiate the theory for three representative LRSs---constant, exponential decay, and warmup–stable–decay (WSD)---and derive explicit scaling relations in both data- and compute-limited regimes. These comparisons explain key empirical phenomena: (i) higher-capacity models are more data- and compute-efficient; (ii) learning-rate decay improves training efficiency; and (iii) WSD-type schedules outperform pure decay. Finally, experiments on LLMs ranging from 0.1B to 1B parameters demonstrate the practical relevance of FSL as a surrogate model for fitting and predicting loss trajectories in large-scale pre-training.'}",https://openreview.net{'value': '/pdf/4db46b2ba3f9713e509ad6852a99e0a0e72f0637.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=dlQ1iUpQNf,{'value': 'Human-assisted Robotic Policy Refinement via Action Preference Optimization'},Wenke Xia; Yichu Yang; Hongtao Wu; Xiao Ma; Tao Kong; Di Hu,~Wenke_Xia1; ~Yichu_Yang1; ~Hongtao_Wu2; ~Xiao_Ma2; ~Tao_Kong3; ~Di_Hu1,"{'value': ['interactive imitation learning', 'robotic manipulaiton', 'preference alignment optimization']}","{'value': 'Establishing a reliable and iteratively refined robotic system is essential for deploying real-world applications. \n    While Vision-Language-Action (VLA) models are widely recognized as the foundation model for such robotic deployment, their reliance on offline expert demonstrations critically limits their capacity for post-deployment refinement. \n    To mitigate this limitation, we introduce Action Preference Optimization (APO), a method designed to refine VLA models by human-assisted preference alignment gathered through interaction with environments.\n    This method begins with a human-robot collaboration framework for reliable failure correction and interaction trajectory collection through human intervention.  \n    However, directly leveraging these interaction trajectories for preference optimization is non-trivial due to the challenges of irreversible robotic actions and token distribution mismatch. To solve this, APO proposes an adaptive reweighting algorithm with binary desirability signals derived from interaction, empowering VLA models effectively suppress failure-prone actions while enhancing corrective action adaptation.\n    Ultimately, APO equips VLA models with the crucial capability to learn from failure, paving the way for their iterative refinement and reliable deployment in dynamic environments.\n    The experiments conducted in simulation and real-world scenarios prove superior generalization and robustness of our human-assisted framework across a variety of manipulation tasks. We believe this work could bring insights for efficient and stable optimization of VLA models through human-robot collaboration. The code and dataset are released at https://github.com/GeWu-Lab/Action-Preference-Optimization.'}",https://openreview.net{'value': '/pdf/fbfb0f6c741acb4bb1764ec47a8e0eb7071d5993.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=dkXDyM66ce,{'value': 'Convergence of the Gradient Flow for Shallow ReLU Networks on Weakly Interacting Data'},Léo Dana; Loucas Pillaud-Vivien; Francis Bach,~Léo_Dana1; ~Loucas_Pillaud-Vivien1; ~Francis_Bach1,"{'value': ['Shallow Neural Networks', 'Gradient Flow', 'High-dimension', 'Convergence rate']}","{'value': 'We analyse the convergence of one-hidden-layer ReLU networks trained by gradient flow on $n$ data points. Our main contribution leverages the high dimensionality of the ambient space, which implies low correlation of the input samples, to demonstrate that a network with width of order $\\log(n)$ neurons suffices for global convergence with high probability. Our analysis uses a Polyak–Łojasiewicz viewpoint along the gradient-flow trajectory, which provides an exponential rate of convergence of $\\frac{1}{n}$. When the data are exactly orthogonal, we give further refined characterizations of the convergence speed, proving its asymptotic behavior lies between the orders $\\frac{1}{n}$ and $\\frac{1}{\\sqrt{n}}$, and exhibiting a phase-transition phenomenon in the convergence rate, during which it evolves from the lower bound to the upper, and in a relative time of order $\\frac{1}{\\log(n)}$.'}",https://openreview.net{'value': '/pdf/f913b67ff609c2f2934f00adeb62048b0a8b43a6.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=de3kwOXQ9e,{'value': 'Low Rank Gradients and Where to Find Them'},Rishi Sonthalia; Michael Murray; Guido Montufar,~Rishi_Sonthalia1; ~Michael_Murray3; ~Guido_Montufar1,"{'value': ['One step gradient', 'low-rank gradients', 'two-layer neural networks', 'spiked covariance', 'regularization', 'high dimensional probability']}","{'value': 'This paper investigates low-rank structure in the gradients of the training loss for two-layer neural networks while relaxing the usual isotropy assumptions on the training data and parameters. We consider a spiked data model in which the bulk can be anisotropic and ill-conditioned, we do not require independent data and weight matrices and we also analyze both the mean-field and neural-tangent-kernel scalings. We show that the gradient with respect to the input weights is approximately low rank and is dominated by two rank-one terms: one aligned with the bulk data–residue, and another aligned with the rank one spike in the input data. We characterize how properties of the training data, the scaling regime and the activation function govern the balance between these two components. Additionally, we also demonstrate that standard regularizers, such as weight decay, input noise and Jacobian penalties, also selectively modulate these components. Experiments on synthetic and real data corroborate our theoretical predictions.'}",https://openreview.net{'value': '/pdf/4123af6660405c89fa3846de9c38102f316e3205.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=dbaYQyruY2,{'value': 'Limited Preference Data? Learning Better Reward Model with Latent Space Synthesis'},Leitian Tao; Xuefeng Du; Sharon Li,~Leitian_Tao1; ~Xuefeng_Du1; ~Sharon_Li1,{'value': ['Large language model;reward modeling; latent space synthesis']},"{'value': ""Reward modeling, crucial for aligning large language models (LLMs) with human preferences, is often bottlenecked by the high cost of preference data. Existing textual data synthesis methods are computationally expensive. We propose a novel framework LENS for synthesizing preference data directly in the LLM's latent embedding space. Our method employs a Variational Autoencoder (VAE) to learn a structured latent representation of response embeddings. By performing controlled perturbations in this latent space and decoding back to the embedding space, we efficiently generate diverse, semantically consistent synthetic preference pairs, bypassing costly text generation and annotation. We provide theoretical guarantees that our synthesized pairs approximately preserve original preference ordering and improve reward model generalization. Empirically, our latent-space synthesis significantly outperforms text-based augmentation on standard benchmarks, achieving superior results while being 18× faster in generation and using a 16,000× smaller model. Our work offers a scalable and effective alternative for enhancing reward modeling through efficient data augmentation. Code is publicly available at https://github.com/deeplearning-wisc/lens.""}",https://openreview.net{'value': '/pdf/12e779439c922ba09d37907c04e017559b3a804c.pdf'},{'abstract_filter': 'Data Synthesis'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=dZ94ZS410X,{'value': 'RF-Agent: Automated Reward Function Design via Language Agent Tree Search'},Ning Gao; Xiuhui Zhang; Xingyu Jiang; Mukang You; Mohan Zhang; Yue Deng,~Ning_Gao5; ~Xiuhui_Zhang1; ~Xingyu_Jiang2; ~Mukang_You1; ~Mohan_Zhang6; ~Yue_Deng4,"{'value': ['Reward Design', 'Reinforcement Learning', 'Large Language Models', 'Language Agent', 'Monte Carlo Tree Search']}","{'value': 'Designing efficient reward functions for low-level control tasks is a challenging problem. Recent research aims to reduce reliance on expert experience by using Large Language Models (LLMs) with task information to generate dense reward functions. These methods typically rely on training results as feedback, iteratively generating new reward functions with greedy or evolutionary algorithms. However, they suffer from poor utilization of historical feedback and inefficient search, resulting in limited improvements in complex control tasks. To address this challenge, we propose RF-Agent, a framework that treats LLMs as language agents and frames reward function design as a sequential decision-making process, enhancing optimization through better contextual reasoning. RF-Agent integrates Monte Carlo Tree Search (MCTS) to manage the reward design and optimization process, leveraging the multi-stage contextual reasoning ability of LLM. This approach better utilizes historical information and improves search efficiency to identify promising reward functions. Outstanding experimental results in 17 diverse low-level control tasks demonstrate the effectiveness of our method.'}",https://openreview.net{'value': '/pdf/062acc1493b646a44c8215cf3fd64f0900f393e8.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=dOGXKBL7IE,{'value': 'Seeing What Matters: Generalizable AI-generated Video Detection with Forensic-Oriented Augmentation'},Riccardo Corvi; Davide Cozzolino; Ekta Prashnani; Shalini De Mello; Koki Nagano; Luisa Verdoliva,~Riccardo_Corvi1; ~Davide_Cozzolino1; ~Ekta_Prashnani1; ~Shalini_De_Mello1; ~Koki_Nagano1; ~Luisa_Verdoliva1,"{'value': ['generative AI', 'media forensics', 'synthetic video detection']}","{'value': 'Synthetic video generation is progressing very rapidly. The latest models can produce very realistic high-resolution videos that are virtually indistinguishable from real ones. Although several video forensic detectors have been recently proposed, they often exhibit poor generalization, which limits their applicability in a real-world scenario. Our key insight to overcome this issue is to guide the detector towards _seeing_ _what_ _really_ _matters_. In fact, a well-designed forensic classifier should focus on identifying intrinsic low-level artifacts introduced by a generative architecture rather than relying on high-level semantic flaws that characterize a specific model. In this work, first, we study different generative architectures, searching and identifying discriminative features that are unbiased, robust to impairments, and shared across models. Then, we introduce a novel forensic-oriented data augmentation strategy based on the wavelet decomposition and replace specific frequency-related bands to drive the model to exploit more relevant forensic cues. Our novel training paradigm improves the generalizability of AI-generated video detectors, without the need for complex algorithms and large datasets that include multiple synthetic generators. To evaluate our approach, we train the detector using data from a single generative model and test it against videos produced by a wide range of other models. Despite its simplicity, our method achieves a significant accuracy improvement over state-of-the-art detectors and obtains excellent results even on very recent generative models, such as NOVA and FLUX.'}",https://openreview.net{'value': '/pdf/72a37f839a6014646cbf8b8d667a051f66fb46b9.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=dBC55QIEnq,{'value': 'Orthogonal Contrastive Learning for Multi-Representation fMRI Analysis'},Tony Yousefnezhad,~Tony_Yousefnezhad1,"{'value': ['fMRI analysis', 'Contrastive Learning', 'Functional Alignment', 'Transfer Learning', 'Multi-Representation fMRI Analysis']}","{'value': 'Task-based functional magnetic resonance imaging (fMRI) provides invaluable insights into human cognition but faces critical hurdles—low signal-to-noise ratio, high dimensionality, limited sample sizes, and costly data acquisition—that are amplified when integrating datasets across subjects or sites. This paper introduces orthogonal contrastive learning (OCL), a unified multi-representation framework for multi-subject fMRI analysis that aligns neural responses without requiring temporal preprocessing or uniform time-series lengths across subjects or sites. OCL employs two identical encoders: an online network trained with a contrastive loss that pulls together same-stimulus responses and pushes apart different-stimulus responses, and a target network whose weights track the online network via exponential moving average to stabilize learning. Each OCL network layer combines QR decomposition for orthogonal feature extraction, locality-sensitive hashing (LSH) to produce compact subject-specific signatures, positional encoding to embed temporal structure alongside spatial features, and a transformer encoder to generate discriminative, stimulus-aligned embeddings. We further enhance OCL with an unsupervised pretraining stage on fMRI-like synthetic data and demonstrate a transfer-learning workflow for multi-site studies. Across extensive experiments on multi-subject and multi-site fMRI benchmarks, OCL consistently outperforms state-of-the-art alignment and analysis methods in both representation quality and downstream classification accuracy.'}",https://openreview.net{'value': '/pdf/f9b55c1cd13086bdfedefe9c6e80615d399193b7.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=dAwKePZvcN,{'value': 'SEEA-R1: Tree-Structured Reinforcement Fine-Tuning for Self-Evolving Embodied Agents'},Wanxin Tian; Shijie Zhang; Kevin Zhang; Xiaowei Chi; Chun-Kai Fan; Junyu Lu; Yulin Luo; Qiang Zhou; Yiming Zhao; Ning Liu; Siyu Lin; Zhiyuan Qin; Xiaozhu Ju; Shanghang Zhang; Jian Tang,~Wanxin_Tian1; ~Shijie_Zhang7; ~Kevin_Zhang5; ~Xiaowei_Chi1; ~Chun-Kai_Fan1; ~Junyu_Lu7; ~Yulin_Luo2; ~Qiang_Zhou6; ~Yiming_Zhao15; ~Ning_Liu4; ~Siyu_Lin1; ~Zhiyuan_Qin1; ~Xiaozhu_Ju1; ~Shanghang_Zhang4; ~Jian_Tang5,"{'value': ['Embodied AI', 'Agents', 'Generative Reward']}","{'value': 'Self-evolution, the ability of agents to autonomously improve their reasoning and behavior, is essential for the embodied domain with long-horizon, real-world tasks. Despite current advancements in reinforcement fine-tuning (RFT) showing strong performance in enhancing reasoning in LLMs, its potential to enable self-evolving embodied intelligence with multi-modal interactions remains largely unexplored. Specifically, reinforcement fine-tuning faces two fundamental obstacles in embodied settings: (i) the lack of accessible intermediate rewards in multi-step reasoning tasks limits effective learning signals, and (ii) reliance on hand-crafted reward functions restricts generalization to novel tasks and environments. To address these challenges, we present *Self-Evolving Embodied Agents-R1*, **SEEA-R1**, the first RFT framework designed for enabling the self-evolving capabilities of embodied agents. Specifically, to convert sparse delayed rewards into denser intermediate signals that improve multi-step reasoning, we propose Tree-based group relative policy optimization (**Tree-GRPO**) integrates Monte Carlo Tree Search into GRPO. To generalize reward estimation across tasks and scenes, supporting autonomous adaptation and reward-driven self-evolution, we further introduce Multi-modal Generative Reward Model (**MGRM**). To holistically evaluate the effectiveness of SEEA-R1, we evaluate on the ALFWorld benchmark, surpassing state-of-the-art methods with scores of 85.07\\% (textual) and 46.27\\% (multi-modal), outperforming prior models including GPT-4o. SEEA-R1 also achieves scores of 80.3\\% (textual) and 44.03\\% (multi-modal) without ground truth reward, surpassing all open-source baselines and highlighting its scalability as a self-evolving embodied agent. Additional experiments and qualitative analysis further support the potential of SEEA-R1 for future research in scalable embodied intelligence. Project page is at https://seea-r1.github.io/.'}",https://openreview.net{'value': '/pdf/d934e1858b206a0ba8fe1fb5281ee9f117238785.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=cuhQZdh2Oq,{'value': 'Crucible: Quantifying the Potential of Control Algorithms through LLM Agents'},Lianchen Jia; Chaoyang Li; Qian Houde; Tianchi Huang; Jiangchuan Liu; Lifeng Sun,~Lianchen_Jia1; ~Chaoyang_Li2; ~Qian_Houde1; ~Tianchi_Huang1; ~Jiangchuan_Liu1; ~Lifeng_Sun2,"{'value': ['Control Algorithms', 'Large Language Models', 'Agent', 'Potential']}","{'value': ""Control algorithms in production environments typically require domain experts to tune their parameters and logic for specific scenarios. However, existing research predominantly focuses on algorithmic performance under ideal or default configurations, overlooking the critical aspect of Tuning Potential. To bridge this gap, we introduce \\texttt{Crucible}, an agent that employs an LLM-driven, multi-level expert simulation to turn algorithms and defines a formalized metric to quantitatively evaluate their Tuning Potential. We demonstrate \\texttt{Crucible}'s effectiveness across a wide spectrum of case studies, from classic control tasks to complex computer systems, and validate its findings in a real-world deployment. Our experimental results reveal that \\texttt{Crucible} systematically quantifies the tunable space across different algorithms. Furthermore, \\texttt{Crucible} provides a new dimension for algorithm analysis and design, which ultimately leads to performance improvements. Our code is available at https://github.com/thu-media/Crucible.""}",https://openreview.net{'value': '/pdf/57ded8a1d0ced3d709538c631817f7d1a501017b.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=cuUsD5FJbe,{'value': 'Enhancing GUI Agent with Uncertainty-Aware Self-Trained Evaluator'},Gongwei Chen; Lirong Jie; Lexiao Zou; Weili Guan; Miao Zhang; Liqiang Nie,~Gongwei_Chen1; ~Lirong_Jie1; ~Lexiao_Zou1; ~Weili_Guan4; ~Miao_Zhang4; ~Liqiang_Nie2,"{'value': ['Multimodal Large Language Model', 'GUI', 'Agent', 'Automatic Evaluation']}","{'value': 'Benefiting from the availability of extensive navigation trajectories, both manually and automatically annotated, current graphical user interface (GUI) agents have achieved remarkable advancements in performance. However, these annotated datasets often contain substantial noise, which impedes effective agent training and underscores the necessity for rigorous trajectory quality assessment. In contrast to existing prompting-based evaluators that rely on proprietary multimodal large language models (MLLMs), we propose an Uncertainty-aware Reinforced Self-Training (URST) framework to train lightweight MLLMs for efficient and reliable trajectory evaluation. URST iteratively fine-tunes MLLMs using their own generated thoughts and judgments to enable self-improvement, while its uncertainty-aware sampling strategy ensures the selection of the most informative training examples. To further enhance reasoning and judgment capabilities, we propose a simplified group policy optimization approach that effectively leverages diverse positive and negative samples for evaluator learning. Our evaluator demonstrates superior judgment performance across both in-domain and out-of-domain datasets. When used to filter navigation datasets, it consistently leads to performance improvements in training GUI agents.'}",https://openreview.net{'value': '/pdf/cfde294195618eb5cb09657b1cae5861b553151e.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=cnUq7GkS6d,{'value': 'Retrieval is Not Enough: Enhancing RAG through Test-Time Critique and Optimization'},Jiaqi Wei; Hao Zhou; Xiang Zhang; Di Zhang; Zijie Qiu; Noah Wei; Jinzhe Li; Wanli Ouyang; Siqi Sun,~Jiaqi_Wei1; ~Hao_Zhou41; ~Xiang_Zhang17; ~Di_Zhang8; ~Zijie_Qiu1; ~Noah_Wei1; ~Jinzhe_Li1; ~Wanli_Ouyang1; ~Siqi_Sun2,"{'value': ['Retrieval-Augmented Generation (RAG)', 'Test-time Scaling']}","{'value': ""Retrieval-augmented generation (RAG) has become a widely adopted paradigm for enabling knowledge-grounded large language models (LLMs). However, standard RAG pipelines often fail to ensure that model reasoning remains consistent with the evidence retrieved, leading to factual inconsistencies or unsupported conclusions. In this work, we reinterpret RAG as \\textit{Retrieval-Augmented Reasoning} and identify a central but underexplored problem: \\textit{Reasoning Misalignment}—the divergence between an LLM's internal reasoning trajectory and the evidential constraints provided by retrieval. To address this issue, we propose \\textsc{AlignRAG}, a novel iterative framework grounded in \\textit{Critique-Driven Alignment (CDA)}. We further introduce \\textsc{AlignRAG-auto}, an autonomous variant that dynamically terminates refinement, removing the need to pre-specify the number of critique iterations. At the heart of \\textsc{AlignRAG} lies a \\textit{contrastive critique synthesis} mechanism that generates retrieval-sensitive critiques while mitigating self-bias. This mechanism trains a dedicated retrieval-augmented \\textit{Critic Language Model (CLM)} using labeled critiques that distinguish between evidence-aligned and misaligned reasoning. Empirical evaluations show that our approach significantly improves reasoning fidelity. Our 8B-parameter CLM improves performance over the Self-Refine baseline by \\textbf{12.1\\%} on out-of-domain tasks and outperforms a standard 72B-parameter CLM by \\textbf{2.2\\%}. Furthermore, \\textsc{AlignRAG-auto} achieves this state-of-the-art performance while dynamically determining the optimal number of refinement steps, enhancing efficiency and usability. \\textsc{AlignRAG} remains compatible with existing RAG architectures as a \\textit{plug-and-play} module and demonstrates strong robustness under both informative and noisy retrieval scenarios. Overall, \\textsc{AlignRAG} offers a principled solution for aligning model reasoning with retrieved evidence, substantially improving the factual reliability and robustness of RAG systems. Our source code is provided at \\href{https://github.com/upup-wei/RAG-ReasonAlignment}{link}.""}",https://openreview.net{'value': '/pdf/8606a3895d103fd477981ea00360b7f1d93ae0ea.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=cldPfIoRiA,{'value': '$\\text{G}^2\\text{M}$: A Generalized Gaussian Mirror Method to Boost Feature Selection Power'},Hongyu Shen; Zhizhen Zhao,~Hongyu_Shen1; ~Zhizhen_Zhao2,"{'value': ['Feature Selection', 'FDR Control', 'Hypothesis Testing; Gaussian Mirror; Boosting Power']}","{'value': 'Recent advances in false discovery rate (FDR)-controlled feature selection methods have improved reliability by effectively limiting false positives, making them well-suited for complex applications. A popular FDR-controlled framework called data splitting uses the ""mirror statistics"" to select features. However, we find that the unit variance assumption on mirror statistics could potentially limit the feature selection power. To address this, we generalize the mirror statistics in the Gaussian mirror framework and introduce a new approach called ""generalized Gaussian mirror"" ($\\text{G}^2\\text{M}$), which adaptively learns the variance and forms new test statistics.  We demonstrate both theoretically and empirically that the proposed test statistics achieve higher power than those of Gaussian mirror and data splitting. Comparisons with other FDR-controlled frameworks on synthetic, semi-synthetic, and real datasets highlight the superior performance of the $\\text{G}^2\\text{M}$ method in achieving higher power while maintaining FDR control. These findings suggest the potential for the $\\text{G}^2\\text{M}$ method for practical applications in real-world problems. Code is available in https://github.com/skyve2012/G2M.'}",https://openreview.net{'value': '/pdf/6fd4edbf133fc27608a82bfe04ff7c54d6171fbf.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=ckW70ls93V,{'value': 'Consistent Paths Lead to Truth: Self-Rewarding Reinforcement Learning for LLM Reasoning'},Kongcheng Zhang; QI YAO; Shunyu Liu; Yingjie Wang; Baisheng Lai; Jieping Ye; Mingli Song; Dacheng Tao,~Kongcheng_Zhang1; ~QI_YAO4; ~Shunyu_Liu1; ~Yingjie_Wang1; ~Baisheng_Lai1; ~Jieping_Ye4; ~Mingli_Song1; ~Dacheng_Tao1,"{'value': ['Self-Rewarding', 'Reinforcement Learning', 'Large Language Models']}","{'value': 'Recent advances of Reinforcement Learning (RL) have highlighted its potential in complex reasoning tasks, yet effective training often relies on external supervision, which limits the broader applicability. In this work, we propose a novel self-rewarding reinforcement learning framework to enhance Large Language Model (LLM) reasoning by leveraging the consistency of intermediate reasoning states across different reasoning trajectories. Our key insight is that correct responses often exhibit consistent trajectory patterns in terms of model likelihood: their intermediate reasoning states tend to converge toward their own final answers (*high consistency*) with minimal deviation toward other candidates (*low volatility*). Inspired by this observation, we introduce CoVo, an intrinsic reward mechanism that integrates ***Co***nsistency and ***Vo***latility via a robust vector-space aggregation strategy, complemented by a curiosity bonus to promote diverse exploration. CoVo enables LLMs to perform RL in a self-rewarding manner, offering a scalable pathway for learning to reason without external supervision. Extensive experiments on diverse reasoning benchmarks show that CoVo achieves performance comparable to or even surpassing supervised RL. Our code is available at https://github.com/sastpg/CoVo.'}",https://openreview.net{'value': '/pdf/4c696fcdaaa5b6e8b53a1bf9e94c8993ee0cd433.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=cjjPn1EIwq,{'value': 'ESCA: Contextualizing Embodied Agents via Scene-Graph Generation'},Jiani Huang; Amish Sethi; Matthew Kuo; Mayank Keoliya; Neelay Velingker; JungHo Jung; Ser-Nam Lim; Ziyang Li; Mayur Naik,~Jiani_Huang1; ~Amish_Sethi1; ~Matthew_Kuo1; ~Mayank_Keoliya1; ~Neelay_Velingker1; ~JungHo_Jung1; ~Ser-Nam_Lim3; ~Ziyang_Li2; ~Mayur_Naik1,"{'value': ['neurosymbolic', 'scene graph', 'multimodal', 'MLLM agents']}","{'value': 'Multi-modal large language models (MLLMs) are making rapid progress toward general-purpose embodied agents. However, existing MLLMs do not reliably capture fine-grained links between low-level visual features and high-level textual semantics, leading to weak grounding and inaccurate perception. To overcome this challenge, we propose ESCA, a framework that contextualizes embodied agents by grounding their perception in spatial-temporal scene graphs. At its core is SGCLIP, a novel, open-domain, promptable foundation model for generating scene graphs that is based on CLIP.  SGCLIP is trained on 87K+ open-domain videos using a neurosymbolic pipeline that aligns automatically generated captions with scene graphs produced by the model itself, eliminating the need for human-labeled annotations. We demonstrate that SGCLIP excels in both prompt-based inference and task-specific fine-tuning, achieving state-of-the-art results on scene graph generation and action localization benchmarks. ESCA with SGCLIP improves perception for embodied agents based on both open-source and commercial MLLMs, achieving state of-the-art performance across two embodied environments. Notably, ESCA significantly reduces agent perception errors and enables open-source models to surpass proprietary baselines. We release the source code for SGCLIP model training at https://github.com/video-fm/LASER and for the embodied agent at https://github.com/video-fm/ESCA.'}",https://openreview.net{'value': '/pdf/32e384d1b7bff0817b05af22b3999df7789e5b8d.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=ceCJPoZOKJ,{'value': 'In-Context Learning of Stochastic Differential Equations with Foundation Inference Models'},Patrick Seifner; Kostadin Cvejoski; David Berghaus; Cesar Ojeda; Ramses J Sanchez,~Patrick_Seifner1; ~Kostadin_Cvejoski1; ~David_Berghaus1; ~Cesar_Ojeda1; ~Ramses_J_Sanchez1,"{'value': ['SDE inference', 'equation discovery', 'zero-shot inference', 'in-context learning', 'zero-shot parameter estimation', 'inference of diffusion process', 'stochastic differential equations', 'diffusion process', 'foundation models']}","{'value': 'Stochastic differential equations (SDEs) describe dynamical systems where deterministic flows, governed by a drift function, are superimposed with random fluctuations, dictated by a diffusion function. The accurate estimation (*or discovery*) of these functions from data is a central problem in machine learning, with wide application across the natural and social sciences. Yet current solutions either rely heavily on prior knowledge of the dynamics or involve intricate training procedures. We introduce FIM-SDE (Foundation Inference Model for SDEs), a pretrained recognition model that delivers accurate *in-context* (or zero-shot) estimation of the drift and diffusion functions of *low-dimensional* SDEs, from noisy time series data, and allows rapid *finetuning* to target datasets. Leveraging concepts from amortized inference and neural operators, we (pre)train FIM-SDE in a supervised fashion to map a large set of noisy, discretely observed SDE paths onto the space of drift and diffusion functions. We demonstrate that FIM-SDE achieves robust *in-context* function estimation across a wide range of synthetic and real-world processes --- from canonical SDE systems (*e.g*., double-well dynamics or weakly perturbed Lorenz attractors) to stock price recordings and oil-price and wind-speed fluctuations --- while matching the performance of symbolic, Gaussian process and Neural SDE baselines trained on the target datasets. When *finetuned* to the target processes, we show that FIM-SDE consistently outperforms all these baselines.'}",https://openreview.net{'value': '/pdf/dc3146a2d696eba051609c5ba0a62c1b0b2e0c14.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=cdgVrsu7T5,{'value': 'RETRO SYNFLOW: Discrete Flow-Matching for Accurate and Diverse Single-Step Retrosynthesis'},Robin Yadav; Qi Yan; Guy Wolf; Joey Bose; Renjie Liao,~Robin_Yadav1; ~Qi_Yan2; ~Guy_Wolf1; ~Joey_Bose1; ~Renjie_Liao1,"{'value': ['retrosynthesis', 'flow matching', 'discrete data']}","{'value': 'A fundamental challenge in organic chemistry is identifying and predicting the sequence of reactions that synthesize a desired target molecule. Due to the combinatorial nature of the chemical search space, single-step reactant prediction—i.e., single-step retrosynthesis—remains difficult, even for state-of-the-art template-free generative methods. These models often struggle to produce an accurate yet diverse set of feasible reactions in a chemically rational manner. In this paper, we propose RETRO SYNFLOW (RSF), a discrete flow-matching framework that formulates single-step retrosynthesis as a Markov bridge between a given product molecule and its corresponding reactants. Unlike prior approaches, RSF introduces a reaction center identification step to extract intermediate structures, or synthons, which serve as a more informative and structured source distribution for the discrete flow model. To further improve the diversity and chemical feasibility of generated samples, RSF incorporates Feynman-Kac (FK) steering with Sequential Monte Carlo (SMC) resampling at inference time. This approach leverages a learned forward-synthesis reward oracle to guide the generation process toward more promising reactant candidates. Empirically, RSF substantially outperforms the previous state-of-the-art methods in top-1 accuracy. In addition, FK-steering significantly improves round-trip accuracy, demonstrating stronger chemical validity and synthetic feasibility, all while maintaining competitive top-k performance. These results establish RSF as a new leading approach for single-step retrosynthesis prediction.'}",https://openreview.net{'value': '/pdf/05c7a9a651ba04f95453fb74abc857f327901590.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=cRxzKxsKow,{'value': 'Event-Driven Dynamic Scene Depth Completion'},Zhiqiang Yan; Jianhao Jiao; Zhengxue Wang; Gim Hee Lee,~Zhiqiang_Yan1; ~Jianhao_Jiao3; ~Zhengxue_Wang1; ~Gim_Hee_Lee1,"{'value': ['depth completion', 'event guidance', 'dynamic scene']}","{'value': 'Depth completion in dynamic scenes poses significant challenges due to rapid ego-motion and object motion, which can severely degrade the quality of input modalities such as RGB images and LiDAR measurements. Conventional RGB-D sensors often struggle to align precisely and capture reliable depth under such conditions. In contrast, event cameras with their high temporal resolution and\nsensitivity to motion at the pixel level provide complementary cues that are beneficial in dynamic environments. To this end, we propose EventDC, the first event-driven depth completion framework. It consists of two key components: Event-Modulated Alignment (EMA) and Local Depth Filtering (LDF). Both modules adaptively learn the two fundamental components of convolution operations: offsets and weights conditioned on motion-sensitive event streams. In the encoder, EMA leverages events to modulate the sampling positions of RGB-D features to achieve pixel redistribution for improved alignment and fusion. In the decoder, LDF refines depth estimations around moving objects by learning motion-aware masks from events. Additionally, EventDC incorporates two loss terms to further benefit global alignment and enhance local depth recovery. Moreover, we establish the first benchmark for event-based depth completion comprising one real-world and two synthetic datasets to facilitate future research. Extensive experiments on this benchmark demonstrate the superiority of our EventDC. [Project page](https://yanzq95.github.io/projectpage/EventDC/index.html).'}",https://openreview.net{'value': '/pdf/f6e77531a21aec2483b0b8e01e22e0452283d511.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=cQxLCVa9u7,{'value': 'HyGen: Efficient LLM Serving via Elastic Online-Offline Request Co-location'},Ting Sun; Penghan Wang; Fan Lai,~Ting_Sun2; ~Penghan_Wang1; ~Fan_Lai1,"{'value': ['LLM Inference', 'Request Scheduling', 'Machine Learning Systems']}","{'value': 'Large language models (LLMs) have facilitated a wide range of applications with distinct service-level objectives (SLOs), from latency-sensitive online tasks like interactive chatbots to throughput-oriented offline workloads like data synthesis. The existing deployment model, which dedicates machines to each workload, simplifies SLO management but often leads to poor resource utilization. This paper introduces HyGen, an interference-aware LLM serving system that enables efficient co-location of online and offline workloads while preserving SLOs. HyGen incorporates two key innovations: (1) performance control mechanisms, including a latency predictor to estimate batch execution time and an SLO-aware profiler to quantify latency interference, and (2) SLO-aware offline scheduling policies that maximize serving throughput and prevent starvation. Our evaluation on production workloads shows that HyGen achieves up to 3.9-5.8× throughput gains over online and hybrid serving baselines, while ensuring latency SLOs. The code of HyGen is publicly available at https://github.com/UIUC-MLSys/HyGen.'}",https://openreview.net{'value': '/pdf/40f47181fc0983cc4ba51054de34b5d6a4e75e14.pdf'},{'abstract_filter': 'Data Synthesis'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=cPO8dUCJOc,{'value': 'Dense Metric Depth Estimation via Event-based Differential Focus Volume Prompting'},Boyu Li; Peiqi Duan; Zhaojun Huang; Xinyu Zhou; Yifei Xia; Boxin Shi,~Boyu_Li3; ~Peiqi_Duan1; ~Zhaojun_Huang1; ~Xinyu_Zhou6; ~Yifei_Xia1; ~Boxin_Shi3,"{'value': ['Event Camera', 'Depth Estimation', 'Focus Volume']}","{'value': 'Dense metric depth estimation has witnessed great developments in recent years. While single-image-based methods have demonstrated commendable performance in certain circumstances, they may encounter challenges regarding scale ambiguities and visual illusions in real world. Traditional depth-from-focus methods are constrained by low sampling rates during data acquisition. In this paper, we introduce a novel approach to enhance dense metric depth estimation by fusing events with image foundation models via a prompting approach. Specifically, we build Event-based Differential Focus Volumes (EDFV) using events triggered through focus sweeping, which are subsequently transformed into sparse metric depth maps. These maps are then utilized for prompting dense depth estimation via our proposed Event-based Depth Prompting Network. We further construct synthetic and real-captured datasets to facilitate the training and evaluation of both frame-based and event-based methods. Quantitative and qualitative results, including both in-domain and zero-shot experiments, demonstrate the superior performance of our method compared to existing approaches. Code and data will be available at https://github.com/liboyu02/EDFV/.'}",https://openreview.net{'value': '/pdf/a4ffe6d5c4bc0c8bea029c7e7dd531a37d955652.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=cIGfKdfy3N,{'value': 'Learning Diffusion Models with Flexible Representation Guidance'},Chenyu Wang; Cai Zhou; Sharut Gupta; Zongyu Lin; Stefanie Jegelka; Stephen Bates; Tommi Jaakkola,~Chenyu_Wang7; ~Cai_Zhou2; ~Sharut_Gupta1; ~Zongyu_Lin1; ~Stefanie_Jegelka3; ~Stephen_Bates1; ~Tommi_Jaakkola1,"{'value': ['Diffusion Models', 'Representation Learning', 'Image Generation', 'Biomolecule Generation', 'Theoretical Analysis of Generative Model']}","{'value': 'Diffusion models can be improved with additional guidance towards more effective representations of input. Indeed, prior empirical work has already shown that aligning internal representations of the diffusion model with those of pre-trained models improves generation quality. In this paper, we present a systematic framework for incorporating representation guidance into diffusion models. We provide alternative decompositions of denoising models along with their associated training criteria, where the decompositions determine when and how the auxiliary representations are incorporated. Guided by our theoretical insights, we introduce two new strategies for enhancing representation alignment in diffusion models. First, we pair examples with target representations either derived from themselves or arisen from different synthetic modalities, and subsequently learn a joint model over the multimodal pairs. Second, we design an optimal training curriculum that balances representation learning and data generation. Our experiments across image, protein sequence, and molecule generation tasks demonstrate superior performance as well as accelerated training. In particular, on the class-conditional ImageNet $256\\times 256$ benchmark, our guidance results in $23.3$ times faster training than the original SiT-XL as well as four times speedup over the state-of-the-art method REPA.'}",https://openreview.net{'value': '/pdf/e943c91dba378912ac4b72b888e831e9d396f991.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=cGkfMGQdCy,{'value': 'Enhancing the Outcome Reward-based RL Training of MLLMs with Self-Consistency Sampling'},Jiahao Wang; Weiye Xu; Aijun Yang; Wengang Zhou; Lewei Lu; Houqiang Li; Xiaohua Wang; Jinguo Zhu,~Jiahao_Wang32; ~Weiye_Xu1; ~Aijun_Yang1; ~Wengang_Zhou1; ~Lewei_Lu1; ~Houqiang_Li1; ~Xiaohua_Wang1; ~Jinguo_Zhu1,"{'value': ['Self-Consistency', 'Outcome Reward-based RL', 'MLLM']}","{'value': 'Outcome‑reward reinforcement learning (RL) is a common—and increasingly significant—way to refine the step‑by‑step reasoning of multimodal large language models (MLLMs). In the multiple‑choice setting—a dominant format for multimodal reasoning benchmarks—the paradigm faces a significant yet often overlooked obstacle: unfaithful trajectories that guess the correct option after a faulty chain of thought receive the same reward as genuine reasoning, which is a flaw that cannot be ignored. We propose Self‑Consistency Sampling (SCS) to correct this issue. For each question, SCS (i) introduces small visual perturbations and (ii) performs repeated truncation‑and‑resampling of a reference trajectory; agreement among the resulting trajectories yields a differentiable consistency score that down‑weights unreliable traces during policy updates. Plugging SCS into RLOO, GRPO, REINFORCE++ series improves accuracy by up to 7.7 percentage points on six multimodal benchmarks with negligible extra computation, offering a simple, general remedy for outcome‑reward RL in MLLMs.'}",https://openreview.net{'value': '/pdf/29edb9ad7e36190f61e9e0b17ae1d99a6df5fb11.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=cANLnJb1FX,{'value': 'Are Large Reasoning Models Good Translation Evaluators? Analysis and Performance Boost'},Runzhe Zhan; Zhihong Huang; Xinyi Yang; Lidia S. Chao; Min Yang; Derek F. Wong,~Runzhe_Zhan1; ~Zhihong_Huang2; ~Xinyi_Yang5; ~Lidia_S._Chao2; ~Min_Yang4; ~Derek_F._Wong1,"{'value': ['large reasoning model', 'evaluation', 'machine translation', 'analysis']}","{'value': 'Recent advancements in large reasoning models (LRMs) have introduced an intermediate ""thinking"" process prior to generating final answers, improving their reasoning capabilities on complex downstream tasks. However, the potential of LRMs as evaluators for machine translation (MT) quality remains underexplored. We provides the first systematic analysis of LRM-as-a-judge in MT evaluation. We identify key challenges, revealing LRMs require tailored evaluation materials, tend to ""overthink"" simpler instances and have issues with scoring mechanisms leading to overestimation. To address these, we propose to calibrate LRM thinking by training them on synthetic, human-like thinking trajectories. Our experiments on WMT24 Metrics benchmarks demonstrate that this approach largely reduces thinking budgets by ~35x while concurrently improving evaluation performance across different LRM scales from 7B to 32B (e.g., R1-Distill-Qwen-7B achieves a +8.7 correlation point improvement). These findings highlight the potential of efficiently calibrated LRMs to advance fine-grained automatic MT evaluation.'}",https://openreview.net{'value': '/pdf/496a103d9eacba8143b7d8a13098936a351a1a81.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=c768Z1FwDL,{'value': 'NeuralSurv: Deep Survival Analysis with Bayesian Uncertainty Quantification'},Mélodie Monod; Alessandro Micheli; Samir Bhatt,~Mélodie_Monod1; ~Alessandro_Micheli1; ~Samir_Bhatt1,"{'value': ['Survival analysis', 'Variational Inference', 'Deep Learning', 'Bayesian Neural Networks', 'Local Linearization', 'Polya-Gamma']}","{'value': 'We introduce *NeuralSurv*, the first deep survival model to incorporate Bayesian uncertainty quantification. Our non‑parametric, architecture‑agnostic framework flexibly captures time‑varying covariate–risk relationships in continuous time via a novel two‑stage data‑augmentation scheme, for which we establish theoretical guarantees. For efficient posterior inference, we introduce a mean‑field variational algorithm with coordinate‑ascent updates that scale linearly in model size. By locally linearizing the Bayesian neural network, we obtain full conjugacy and derive all coordinate updates in closed form. In experiments, *NeuralSurv* delivers superior calibration compared to state-of-the-art deep survival models, while matching or exceeding their discriminative performance across both synthetic benchmarks and real-world datasets. Our results demonstrate the value of Bayesian principles in data‑scarce regimes by enhancing model calibration and providing robust, well‑calibrated uncertainty estimates for the survival function.'}",https://openreview.net{'value': '/pdf/f963da28337ce73bf5ad03be5e73c9d8064d440c.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=c6RDAutyNE,{'value': 'GPO: Learning from Critical Steps to Improve LLM Reasoning'},Jiahao Yu; Zelei Cheng; Xian Wu; Xinyu Xing,~Jiahao_Yu1; ~Zelei_Cheng1; ~Xian_Wu8; ~Xinyu_Xing3,"{'value': ['Large language model', 'explainable reinforcement learning', 'fine-tuning']}","{'value': ""Large language models (LLMs) are increasingly used in various domains, showing impressive potential on various tasks. \n    Recently, reasoning LLMs have been proposed to improve the \\textit{reasoning} or \\textit{thinking} capabilities of LLMs to solve complex problems. \n    Despite the promising results of reasoning LLMs, enhancing the multi-step reasoning capabilities of LLMs still remains a significant challenge. \n    While existing optimization methods have advanced the LLM reasoning capabilities, they often treat reasoning trajectories as a whole, without considering the underlying critical steps within the trajectory. In this paper, we introduce \\textbf{G}uided \\textbf{P}ivotal \\textbf{O}ptimization (GPO), a novel fine-tuning strategy that dives into the reasoning process to enable more effective improvements. \n    GPO first identifies the `critical step' within a reasoning trajectory - a point that the model must carefully proceed so as to succeed at the problem. We locate the critical step by estimating the advantage function.\n    GPO then resets the policy to the critical step and samples the new rollout and prioritizes learning process on those rollouts. \n    This focus allows the model to learn more effectively from pivotal moments within the reasoning process to improve the reasoning performance.\n    We demonstrate that GPO is not a standalone method, but rather a general strategy that can be integrated with various optimization methods to improve reasoning performance. \n    Besides theoretical analysis, our experiments across challenging reasoning benchmarks show that GPO can consistently and significantly enhances the performance of existing optimization methods, showcasing its effectiveness and generalizability in improving LLM reasoning by concentrating on pivotal moments within the generation process.""}",https://openreview.net{'value': '/pdf/13f0ee90e24b21be9c369212e9e13510ea825e84.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=c6O18DyBBx,{'value': 'Unlocking Dataset Distillation with Diffusion Models'},Brian Bernhard Moser; Federico Raue; Sebastian Palacio; Stanislav Frolov; Andreas Dengel,~Brian_Bernhard_Moser1; ~Federico_Raue1; ~Sebastian_Palacio1; ~Stanislav_Frolov2; ~Andreas_Dengel1,"{'value': ['Dataset Distillation', 'Diffusion Models', 'Latent Diffusion Models', 'Vanishing Gradients', 'Generative Priors']}","{'value': 'Dataset distillation seeks to condense datasets into smaller but highly representative synthetic samples.  While diffusion models now lead all generative benchmarks, current distillation methods avoid them and rely instead on GANs or autoencoders, or, at best, sampling from a fixed diffusion prior. This trend arises because naive backpropagation through the long denoising chain leads to vanishing gradients, which prevents effective synthetic sample optimization. To address this limitation, we introduce Latent Dataset Distillation with Diffusion Models (LD3M), the first method to learn gradient-based distilled latents and class embeddings end-to-end through a pre-trained latent diffusion model. A linearly decaying skip connection, injected from the initial noisy state into every reverse step, preserves the gradient signal across dozens of timesteps without requiring diffusion weight fine-tuning. Across multiple ImageNet subsets at $128\\times128$ and $256\\times256$, LD3M improves downstream accuracy by up to 4.8 percentage points (1 IPC) and 4.2 points (10 IPC) over the prior state-of-the-art. The code for LD3M is provided at https://github.com/Brian-Moser/prune_and_distill.'}",https://openreview.net{'value': '/pdf/44c9f7eaee5e75618e9864928b8dbb3ed887588e.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=btBqWTbf6q,{'value': 'Pre-trained Large Language Models Learn to Predict Hidden Markov Models In-context'},Yijia Dai; Zhaolin Gao; Yahya Sattar; Sarah Dean; Jennifer J. Sun,~Yijia_Dai1; ~Zhaolin_Gao1; ~Yahya_Sattar1; ~Sarah_Dean2; ~Jennifer_J._Sun1,{'value': ['In-context learning; LLM; Hidden Markov models; Neuroscience; Decision-making; Animal behavior.']},"{'value': ""Hidden Markov Models (HMMs) are fundamental tools for modeling sequential data with latent states that follow Markovian dynamics. \nHowever, they present significant challenges in model fitting and computational efficiency on real-world datasets. \nIn this work, we demonstrate that pre-trained large language models (LLMs) can effectively model data generated by HMMs through in-context learning (ICL) — their ability to learn patterns from examples within the input context.\nWe evaluate LLMs' performance on diverse synthetic HMMs, showing that their prediction accuracy converges to the theoretical optimum. We discover novel scaling trends influenced by HMM properties and provide theoretical conjectures for these empirical observations. Furthermore, we present practical guidelines for scientists on using ICL as a diagnostic tool for complex data. Applied to real-world animal decision-making tasks, ICL achieves competitive performance with models designed by human experts. Our results demonstrate potential for advancing understanding of LLMs' capabilities while opening new avenues for scientific discovery of biological mechanisms and hidden structures in real-world phenomena.""}",https://openreview.net{'value': '/pdf/d9c6c3a5ef2b457a99d3851f69c626f9896663ed.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=bt2vhIphJ0,{'value': 'Incentivizing Time-Aware Fairness in Data Sharing'},Jiangwei Chen; Kieu Thao Nguyen Pham; Rachael Hwee Ling Sim; Arun Verma; Zhaoxuan Wu; Chuan-Sheng Foo; Bryan Kian Hsiang Low,~Jiangwei_Chen2; ~Kieu_Thao_Nguyen_Pham1; ~Rachael_Hwee_Ling_Sim1; ~Arun_Verma1; ~Zhaoxuan_Wu1; ~Chuan-Sheng_Foo1; ~Bryan_Kian_Hsiang_Low1,"{'value': ['Cooperative Game Theory', 'Incentives', 'Data Sharing']}","{'value': 'In collaborative data sharing and machine learning, multiple parties aggregate their data resources to train a machine learning model with better model performance. \nHowever, as the parties incur data collection costs, they are only willing to do so when guaranteed incentives, such as fairness and individual rationality. \nExisting frameworks assume that all parties join the collaboration simultaneously, which does not hold in many real-world scenarios. \nDue to the long processing time for data cleaning, difficulty in overcoming legal barriers, or unawareness, the parties may join the collaboration at different times. \nIn this work, we propose the following perspective: \nAs a party who joins earlier incurs higher risk and encourages the contribution from other wait-and-see parties, that party should receive a reward of higher value for sharing data earlier. \nTo this end, we propose a fair and time-aware data sharing framework, including novel time-aware incentives.\nWe develop new methods for deciding reward values to satisfy these incentives. \nWe further illustrate how to generate model rewards that realize the reward values and empirically demonstrate the properties of our methods on synthetic and real-world datasets.'}",https://openreview.net{'value': '/pdf/a65dbb7327d83e9c6079cbed872656de85337fdd.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=bqaiMuNzfK,{'value': 'Fairness-aware Bayes Optimal Functional Classification'},Xiaoyu Hu; Gengyu Xue; Zhenhua Lin; Yi Yu,~Xiaoyu_Hu2; ~Gengyu_Xue1; ~Zhenhua_Lin2; ~Yi_Yu3,"{'value': ['Classification', 'excess risk', 'fairness', 'functional data']}","{'value': 'Algorithmic fairness has become a central topic in machine learning, and mitigating disparities across different subpopulations has emerged as a rapidly growing research area. In this paper, we systematically study the classification of functional data under fairness constraints, ensuring the disparity level of the classifier is controlled below a pre-specified threshold. We propose a unified framework for fairness-aware functional classification, tackling an infinite-dimensional functional space, addressing key challenges from the absence of density ratios and intractability of posterior probabilities, and discussing unique phenomena in functional classification. We further design a post-processing algorithm Fair Functional Linear Discriminant Analysis classifier (Fair-FLDA), which targets at homoscedastic Gaussian processes and achieves fairness via group-wise thresholding. Under weak structural assumptions on eigenspace, theoretical guarantees on fairness and excess risk controls are established. As a byproduct, our results cover the excess risk control of the standard FLDA as a special case, which, to the best of our knowledge, is first time seen. Our theoretical findings are complemented by extensive numerical experiments on synthetic and real datasets, highlighting the practicality of our designed algorithm.'}",https://openreview.net{'value': '/pdf/023359649c3ba68e896e204ce8da117fe30f8bd1.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=bmoGGgSLzB,{'value': 'Is Noise Conditioning Necessary? A Unified Theory of Unconditional Graph Diffusion Models'},Jipeng Li; Yanning Shen,~Jipeng_Li1; ~Yanning_Shen1,"{'value': ['Graph Diffusion Models', 'Unconditional Graph Diffusion', 'Noise Conditioning']}","{'value': 'Explicit noise-level conditioning is widely regarded as essential for the effective operation of Graph Diffusion Models (GDMs). In this work, we challenge this assumption by investigating whether denoisers can implicitly infer noise levels directly from corrupted graph structures, potentially eliminating the need for explicit noise conditioning.  To this end, we develop a theoretical framework centered on Bernoulli edge-flip corruptions and extend it to encompass more complex scenarios involving coupled structure-attribute noise. Extensive empirical evaluations on both synthetic and real-world graph datasets, using models such as GDSS and DiGress, provide strong support for our theoretical findings. Notably, unconditional GDMs achieve performance comparable or superior to their conditioned counterparts, while also offering reductions in parameters (4-6%) and computation time (8-10%). Our results suggest that the high-dimensional nature of graph data itself often encodes sufficient information for the denoising process, opening avenues for simpler, more efficient GDM architectures.'}",https://openreview.net{'value': '/pdf/8bc391d73b3abbd6c62e070d30aba0f8bfcc179f.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=bmH6UgE1z7,{'value': 'Advancing Wasserstein Convergence Analysis of Score-Based Models: Insights from Discretization and Second-Order Acceleration'},Yifeng Yu; Lu Yu,~Yifeng_Yu3; ~Lu_Yu7,"{'value': ['Diffusion model', 'Wasserstein convergence', 'Convergence Analysis']}","{'value': 'Score-based diffusion models have emerged as powerful tools in generative modeling, yet their theoretical foundations remain underexplored. In this work, we focus on the Wasserstein convergence analysis of score-based diffusion models. Specifically, we investigate the impact of various discretization schemes, including Euler discretization, exponential integrators, and midpoint randomization methods. Our analysis provides the first quantitative comparison of these discrete approximations, emphasizing their influence on convergence behavior. Furthermore, we explore scenarios where Hessian information is available and propose an accelerated sampler based on the local linearization method. We establish the first Wasserstein convergence analysis for such a Hessian-based method, showing that it achieves an improved convergence rate of order $\\widetilde{\\mathcal{O}}\\left(\\frac{\\sqrt{d}}{\\varepsilon}\\right)$, which significantly outperforms the standard rate $\\widetilde{\\mathcal{O}}\\left(\\frac{d}{\\varepsilon^2}\\right)$ of vanilla diffusion models. Numerical experiments on synthetic data and the MNIST dataset validate our theoretical insights.'}",https://openreview.net{'value': '/pdf/91a82d034cb7e6abf6ef172e04f50b45eee0be92.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=biM1m6VXSD,{'value': 'Controllable 3D Molecular Generation for Structure-Based Drug Design Through Bayesian Flow Networks and Gradient Integration'},Seungyeon Choi; Hwanhee Kim; Chihyun Park; Dahyeon Lee; Seungyong Lee; Yoonju Kim; Hyoungjoon Park; Sein Kwon; Youngwan Jo; Sanghyun Park,~Seungyeon_Choi1; ~Hwanhee_Kim1; ~Chihyun_Park1; ~Dahyeon_Lee1; ~Seungyong_Lee5; ~Yoonju_Kim1; ~Hyoungjoon_Park1; ~Sein_Kwon1; ~Youngwan_Jo1; ~Sanghyun_Park4,"{'value': ['Structure-based Drug Design', '3D Molecule Generation', 'Generative Model']}","{'value': 'Recent advances in Structure-based Drug Design (SBDD) have leveraged generative models for 3D molecular generation, predominantly evaluating model performance by binding affinity to target proteins. However, practical drug discovery necessitates high binding affinity along with synthetic feasibility and selectivity, critical properties that were largely neglected in previous evaluations. To address this gap, we identify fundamental limitations of conventional diffusion-based generative models in effectively guiding molecule generation toward these diverse pharmacological properties. We propose $\\texttt{CByG}$, a novel framework extending Bayesian Flow Network into a gradient-based conditional generative model that robustly integrates property-specific guidance. Additionally, we introduce a comprehensive evaluation scheme incorporating practical benchmarks for binding affinity, synthetic feasibility, and selectivity, overcoming the limitations of conventional evaluation methods. Extensive experiments demonstrate that our proposed $\\texttt{CByG}$, framework significantly outperforms baseline models across multiple essential evaluation criteria, highlighting its effectiveness and practicality for real-world drug discovery applications.'}",https://openreview.net{'value': '/pdf/8248222af627226352b97aea2fd83be9ff631673.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=baBhSzaSHI,{'value': 'DEXTER: Diffusion-Guided EXplanations with TExtual Reasoning for Vision Models'},Simone Carnemolla; Matteo Pennisi; Sarinda Samarasinghe; Giovanni Bellitto; Simone Palazzo; Daniela Giordano; Mubarak Shah; Concetto Spampinato,~Simone_Carnemolla1; ~Matteo_Pennisi1; ~Sarinda_Samarasinghe1; ~Giovanni_Bellitto1; ~Simone_Palazzo2; ~Daniela_Giordano2; ~Mubarak_Shah3; ~Concetto_Spampinato1,"{'value': ['Explainability', 'Activation Maximization', 'Diffusion Models', 'LLM']}","{'value': ""Understanding and explaining the behavior of machine learning models is essential for building transparent and trustworthy AI systems. We introduce DEXTER, a data-free framework that employs \ndiffusion models and large language models to generate global, textual explanations of visual classifiers. DEXTER operates by optimizing text prompts to synthesize class-conditional images that strongly activate a target classifier. These synthetic samples are then used to elicit detailed natural language reports that describe class-specific decision patterns and biases. Unlike prior work, DEXTER enables natural language explanation \nabout a classifier's decision process without access to training data or ground-truth labels. We demonstrate DEXTER's flexibility across three tasks—activation maximization, slice discovery and debiasing, and bias explanation—each illustrating its ability to uncover the internal mechanisms of visual classifiers. Quantitative and qualitative evaluations, including a user study, show that DEXTER produces accurate, interpretable outputs. Experiments on ImageNet, Waterbirds, CelebA, and FairFaces confirm that DEXTER outperforms existing approaches in global model explanation and class-level bias reporting. Code is available at https://github.com/perceivelab/dexter.""}",https://openreview.net{'value': '/pdf/59500bb799b385310196f77bab6834b1d8862dac.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=bYRSuZteeK,{'value': 'Quantifying Cross-Modality Memorization in Vision-Language Models'},Yuxin Wen; Yangsibo Huang; Tom Goldstein; Ravi Kumar; Badih Ghazi; Chiyuan Zhang,~Yuxin_Wen2; ~Yangsibo_Huang2; ~Tom_Goldstein1; ~Ravi_Kumar1; ~Badih_Ghazi1; ~Chiyuan_Zhang1,"{'value': ['Memorization', 'VLM Memorization']}","{'value': 'Understanding what and how neural networks memorize during training is crucial, both from the perspective of unintentional memorization of potentially sensitive information and from the standpoint of effective knowledge acquisition for real-world, knowledge-intensive tasks. While previous studies primarily investigate memorization within a single modality, such as text memorization in large language models or image memorization in diffusion models, unified multimodal models are becoming increasingly prevalent in practical applications. In this work, we focus on the unique characteristics of cross-modality memorization and conduct a systematic study centered on vision-language models. To facilitate controlled experiments, we first introduce a synthetic persona dataset comprising diverse synthetic person images and textual descriptions. We quantify factual knowledge memorization and cross-modal transferability by training models on a single modality and evaluating their performance in the other. Our results reveal that facts learned in one modality transfer to the other, but a significant gap exists between recalling information in the source and target modalities. Furthermore, we observe that this gap exists across various scenarios, including more capable models, machine unlearning, and the multi-hop case. At the end, we propose a baseline method to mitigate this challenge. We hope our study can inspire future research on developing more robust multimodal learning techniques to enhance cross-modal transferability.'}",https://openreview.net{'value': '/pdf/e5e5cfc7f6638a6081384cd92bec67f1ceee43ab.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=bPNzBXl1n7,{'value': 'Perturbation Bounds for Low-Rank Inverse Approximations under Noise'},Phuc Tran; Nisheeth K. Vishnoi,~Phuc_Tran1; ~Nisheeth_K._Vishnoi2,"{'value': ['Low-rank approximation', 'Pseudoinverse', 'Robustness  Numerical linear algebra', 'Noisy matrices']}","{'value': 'Low-rank pseudoinverses are widely used to approximate matrix inverses in scalable machine learning, optimization, and scientific computing. However, real-world matrices are often observed with noise, arising from sampling, sketching, and quantization. The spectral-norm robustness of low-rank inverse approximations remains poorly understood.  We systematically study the spectral-norm error $\\| \\tilde{A}_p^{-1} - A_p^{-1} \\|$ for an $n\\times n$ symmetric matrix $A$, where $A_p^{-1}$ denotes the best rank-\\(p\\) approximation of $A^{-1}$, and $\\tilde{A} = A + E$ is a noisy observation. Under mild assumptions on the noise, we derive sharp non-asymptotic perturbation bounds that reveal how the error scales with the eigengap, spectral decay, and noise alignment with low-curvature directions of $A$. Our analysis introduces a novel application of contour integral techniques to the \\emph{non-entire} function $f(z) = 1/z$, yielding bounds that improve over naive adaptations of classical full-inverse bounds by up to a factor of $\\sqrt{n}$. Empirically, our bounds closely track the true perturbation error across a variety of real-world and synthetic matrices, while estimates based on classical results tend to significantly overpredict. These findings offer practical, spectrum-aware guarantees for low-rank inverse approximations in noisy computational environments.'}",https://openreview.net{'value': '/pdf/669f28d1f8f911ed5e9075fa167d0060cded09db.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=bMKUD39Vcc,{'value': 'Learning Theory for Kernel Bilevel Optimization'},Fares El Khoury; Edouard Pauwels; Samuel Vaiter; Michael Arbel,~Fares_El_Khoury1; ~Edouard_Pauwels1; ~Samuel_Vaiter1; ~Michael_Arbel1,"{'value': ['bilevel optimization', 'kernel methods', 'learning theory', 'empirical process theory', 'U-statistic', 'generalization error bounds']}","{'value': 'Bilevel optimization has emerged as a technique for addressing a wide range of machine learning problems that involve an outer objective implicitly determined by the minimizer of an inner problem. While prior works have primarily focused on the parametric setting, a learning-theoretic foundation for bilevel optimization in the nonparametric case remains relatively unexplored. In this paper, we take a first step toward bridging this gap by studying Kernel Bilevel Optimization (KBO), where the inner objective is optimized over a reproducing kernel Hilbert space. This setting enables rich function approximation while providing a foundation for rigorous theoretical analysis. In this context, we derive novel finite-sample generalization bounds for KBO, leveraging tools from empirical process theory. These bounds further allow us to assess the statistical accuracy of gradient-based methods applied to the empirical discretization of KBO. We numerically illustrate our theoretical findings on a synthetic instrumental variable regression task.'}",https://openreview.net{'value': '/pdf/9de5c16a945e0a1f0ff047413433c4b61e9e1b84.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=bHCB8H90aZ,{'value': 'Each Complexity Deserves a Pruning Policy'},Hanshi Wang; yuhao xu; Zekun Xu; Jin Gao; Yufan Liu; Weiming Hu; Ke Wang; Zhipeng Zhang,~Hanshi_Wang2; ~yuhao_xu4; ~Zekun_Xu4; ~Jin_Gao1; ~Yufan_Liu1; ~Weiming_Hu1; ~Ke_Wang3; ~Zhipeng_Zhang2,"{'value': ['Vision-Language Models', 'Pruning']}","{'value': ""The established redundancy in visual tokens within large vision–language models (LVLMs) allows for pruning to effectively reduce their substantial computational demands. Empirical evidence from previous works indicates that visual tokens in later decoder stages receive less attention than shallow layers. Then, previous methods typically employ heuristics layer-specific pruning strategies where, although the number of tokens removed may differ across decoder layers, the overall pruning schedule is fixed and applied uniformly to all input samples and tasks, failing to align token elimination with the model’s holistic reasoning trajectory. Cognitive science indicates that human visual processing often begins with broad exploration to accumulate evidence before narrowing focus as the target becomes distinct. Our experiments reveal an analogous pattern in LVLMs. This observation strongly suggests that neither a fixed pruning schedule nor a heuristics layer-wise strategy can optimally accommodate the diverse complexities inherent in different inputs. To overcome this limitation, we introduce Complexity-Adaptive Pruning (AutoPrune), which is a training-free, plug-and-play framework that tailors pruning policies to varying sample and task complexities. Specifically, AutoPrune quantifies the mutual information between visual and textual tokens, and then projects this signal to a budget-constrained logistic retention curve. Each such logistic curve, defined by its unique shape, is shown to effectively correspond with the specific complexity of different tasks, and can easily guarantee adherence to a pre-defined computational constraints. We evaluate AutoPrune not only on standard vision-language tasks but also on Vision-Language-Action (VLA) models for autonomous driving. Notably, when applied to LLaVA-1.5-7B, our method prunes 89% of visual tokens and reduces inference FLOPs by 76.8%, but still retaining 96.7% of the original accuracy averaged over all tasks. This corresponds to a 9.1% improvement over the recent work PDrop (CVPR'2025), demonstrating the effectivenes.  Code is available at https://github.com/AutoLab-SAI-SJTU/AutoPrune.""}",https://openreview.net{'value': '/pdf/9d60bd42e7fc9d510ccac1a6b17d3241e1b96849.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=bEYzeItoOH,{'value': 'BLEUBERI: BLEU is a surprisingly effective reward for instruction following'},Yapei Chang; Yekyung Kim; Michael Krumdick; Amir Zadeh; Chuan Li; Chris Tanner; Mohit Iyyer,~Yapei_Chang1; ~Yekyung_Kim1; ~Michael_Krumdick1; ~Amir_Zadeh1; ~Chuan_Li4; ~Chris_Tanner1; ~Mohit_Iyyer1,"{'value': ['alignment', 'instruction-following', 'LLM', 'RLVR', 'GRPO']}","{'value': 'Reward models are central to aligning LLMs with human preferences, but they are costly to train, requiring large-scale human-labeled preference data and powerful pretrained LLM backbones. Meanwhile, the increasing availability of high-quality synthetic instruction-following datasets raises the question: can simpler, reference-based metrics serve as viable alternatives to reward models during RL-based alignment? In this paper, we show first that BLEU, a basic string-matching metric, surprisingly matches strong reward models in agreement with human preferences on general instruction-following datasets. Based on this insight, we develop BLEUBERI, a method that first identifies challenging instructions and then applies Group Relative Policy Optimization (GRPO) using BLEU directly as the reward function. We demonstrate that BLEUBERI-trained models are competitive with models trained via reward model-guided RL across four challenging instruction-following benchmarks and three different base language models. A human evaluation further supports that the quality of BLEUBERI model outputs is on par with those from reward model-aligned models. Moreover, BLEUBERI models generate outputs that are more factually grounded than competing methods. Overall, we show that given access to high-quality reference outputs (easily obtained via existing instruction-following datasets or synthetic data generation), string matching-based metrics are cheap yet effective proxies for reward models during alignment. We release our code and data at https://github.com/lilakk/BLEUBERI.'}",https://openreview.net{'value': '/pdf/62e5a2c7ddd32238b72c8305a544a7429632dfa2.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=b8j0Gbg4N3,{'value': 'KeeA*: Epistemic Exploratory A* Search via Knowledge Calibration'},Dengwei Zhao; Shikui Tu; Yanan Sun; Lei Xu,~Dengwei_Zhao1; ~Shikui_Tu1; ~Yanan_Sun5; ~Lei_Xu7,"{'value': ['A* search', 'neural guided heuristic search', 'retrosynthesis planning']}","{'value': 'In recent years, neural network-guided heuristic search algorithms, such as Monte-Carlo tree search and A$^\\*$ search, have achieved significant advancements across diverse practical applications. Due to the challenges stemming from high state-space complexity, sparse training datasets, and incomplete environmental modeling, heuristic estimations manifest uncontrolled inherent biases towards the actual expected evaluations, thereby compromising the decision-making quality of search algorithms. Sampling exploration enhanced A$^\\*$ (SeeA$^\\*$) was proposed to improve the efficiency of A$^\\*$ search by constructing an dynamic candidate subset through random sampling, from which the expanded node was selected. However, uniform sampling strategy utilized by SeeA$^\\*$ facilitates exploration exclusively through the injection of randomness, which completely neglects the heuristic knowledge relevant to open nodes. Moreover, the theoretical support of cluster sampling remains ambiguous. Despite the existence of potential biases, heuristic estimations still encapsulate certain valuable information. In this paper, epistemic exploratory A$^\\*$ search (KeeA$^\\*$) is proposed to integrate heuristic knowledge for calibrating the sampling process. We first theoretically demonstrate that SeeA$^\\*$ with cluster sampling outperforms uniform sampling due to the distribution-aware selection with higher variance. Building on this insight, cluster scouting and path-aware sampling are introduced in KeeA$^\\*$ to further exploit heuristic knowledge to increase the sampling mean and variance, respectively, thereby generating higher-quality extreme candidates and enhancing overall decision-making performance. Finally, empirical results on retrosynthetic planning and logic synthesis demonstrate superior performance of KeeA$^*$ compared to state-of-the-art heuristic search algorithms.'}",https://openreview.net{'value': '/pdf/684d0a08e44894fddc9a3a811585dcf3956924b2.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=b8XmjZmsN0,{'value': 'Causal Explanation-Guided Learning for Organ Allocation'},Alessandro Marchese; Jeroen Berrevoets; Sam Verboven,~Alessandro_Marchese1; ~Jeroen_Berrevoets1; ~Sam_Verboven1,"{'value': ['Causal Inference', 'Explanation Supervision', 'Organ Allocation']}","{'value': 'A central challenge in organ transplantation is the extremely low acceptance rate of donor organ offers—typically in the single digits—leading to high discard rates and suboptimal use of available grafts. Current acceptance models embedded in allocation systems are non-causal, trained on observational data, and fail to generalize to policy-relevant counterfactuals. This limits their reliability for both policy evaluation and simulator-based optimization. In this work, we reframe organ offer acceptance as a counterfactual prediction problem and propose a method to learn from routinely recorded—but often overlooked—refusal explanations. These refusal reasons act as direction-only counterfactual signals: for example, a refusal reason such as ""old donor age"" implies acceptance might have occurred had the donor been younger. We formalize this setting and introduce ClexNet, a novel causal  model that learns policy-invariant representations via balanced training and an explanation-guided augmentation loss. On both synthetic and semi-synthetic data, ClexNet outperforms existing acceptance models in predictive performance, generalization, and calibration, offering a robust drop-in improvement for simulators and allocation policy evaluation. Beyond transplantation, our approach provides a general method for incorporating human direction-only explanations as a form of model supervision, improving performance in settings where only observational data is available.'}",https://openreview.net{'value': '/pdf/f8e742d3a329564b3ffba97d179bbee654cf481c.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=b7waOsMnq8,{'value': 'Sharp Gaussian approximations for Decentralized Federated Learning'},Soham Bonnerjee; Sayar Karmakar; Wei Biao Wu,~Soham_Bonnerjee2; ~Sayar_Karmakar1; ~Wei_Biao_Wu2,"{'value': ['Federated Learning', 'Distributed Systems', 'SGD', 'Gaussian approximation']}","{'value': 'Federated Learning has gained traction in privacy-sensitive collaborative environments, with local SGD emerging as a key optimization method in decentralized settings. While its convergence properties are well-studied, asymptotic statistical guarantees beyond convergence remain limited. In this paper, we present two generalized Gaussian approximation results for local SGD and explore their implications. First, we prove a Berry-Esseen theorem for the final local SGD iterates, enabling valid multiplier bootstrap procedures. Second, motivated by robustness considerations, we introduce two distinct time-uniform Gaussian approximations for the entire trajectory of local SGD. The time-uniform approximations support Gaussian bootstrap-based tests for detecting adversarial attacks. Extensive simulations are provided to support our theoretical results.'}",https://openreview.net{'value': '/pdf/24982d06815c91b43ec754cfdd5deb509e3f06b7.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=b4X6cz1F9l,{'value': 'Cross-fluctuation phase transitions reveal sampling dynamics in diffusion models'},Sai Niranjan Ramachandran; Manish Krishan Lal; Suvrit Sra,~Sai_Niranjan_Ramachandran1; ~Manish_Krishan_Lal2; ~Suvrit_Sra1,"{'value': ['Diffusion Models', 'Fluctuation theory', 'Phase Transitions', 'Sampling', 'Markov Chains', 'Interpretability.']}","{'value': 'We analyse how the sampling dynamics of distributions evolve in score-based diffusion models using \\emph{cross-fluctuations}, a centered-moment statistic from statistical physics. Specifically, we show that starting from an unbiased isotropic normal distribution, samples undergo sharp, discrete transitions, eventually forming distinct events of a desired distribution while progressively revealing finer structure. As this process is reversible, these transitions also occur in reverse, where intermediate states progressively merge, tracing a path back to the initial distribution.  We demonstrate that these transitions can be detected as discontinuities in $n^{\\text{th}}$-order cross-fluctuations. For variance-preserving SDEs, we derive a closed-form for these cross-fluctuations that is efficiently computable for the reverse trajectory. %, thus tying cross-fluctuation dynamics to event formation within the desired distribution. \nWe find that detecting these transitions directly boosts sampling efficiency, accelerates class-conditional and rare-class generation, and improves two zero-shot tasks--image classification and style transfer--without expensive grid search or retraining. We also show that this viewpoint unifies classical coupling and mixing from finite Markov chains with continuous dynamics while extending to stochastic SDEs and non Markovian samplers. Our framework therefore bridges discrete Markov chain theory, phase analysis, and modern generative modeling.'}",https://openreview.net{'value': '/pdf/d28681f5c56591543a273de17b530f0b3343037a.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=aywsq2Bkom,{'value': 'Learning-Augmented Online Bipartite Fractional Matching'},Davin Choo; Billy Jin; Yongho Shin,~Davin_Choo1; ~Billy_Jin1; ~Yongho_Shin2,"{'value': ['Learning-augmented algorithms', 'algorithms with predictions', 'algorithms with advice', 'robustness-consistency tradeoff', 'online bipartite matching', 'AdWords', 'online algorithms']}","{'value': ""Online bipartite matching is a fundamental problem in online optimization, extensively studied both in its integral and fractional forms due to its theoretical significance and practical applications, such as online advertising and resource allocation. Motivated by recent progress in learning-augmented algorithms, we study online bipartite fractional matching when the algorithm is given advice in the form of a suggested matching in each iteration. We develop algorithms for both the vertex-weighted and unweighted variants that provably dominate the naive ``coin flip'' strategy of randomly choosing between the advice-following and advice-free algorithms. Moreover, our algorithm for the vertex-weighted setting extends to the AdWords problem under the small bids assumption, yielding a significant improvement over the seminal work of Mahdian, Nazerzadeh, and Saberi (EC 2007, TALG 2012). Complementing our positive results, we establish a hardness bound on the robustness-consistency tradeoff that is attainable by any algorithm. We empirically validate our algorithms through experiments on synthetic and real-world data.""}",https://openreview.net{'value': '/pdf/23e74108c7ee35d67cd28591e6c3bca2ec9379f8.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=auiURbhoYx,{'value': 'Balancing Multimodal Training Through Game-Theoretic Regularization'},Konstantinos Kontras; Thomas Strypsteen; Christos Chatzichristos; Paul Pu Liang; Matthew B. Blaschko; Maarten De Vos,~Konstantinos_Kontras1; ~Thomas_Strypsteen1; ~Christos_Chatzichristos1; ~Paul_Pu_Liang1; ~Matthew_B._Blaschko1; ~Maarten_De_Vos2,"{'value': ['Multimodal Deep Learning', 'Multimodal Competition']}","{'value': 'Multimodal learning holds the promise for richer information extraction by capturing dependencies across data sources. Yet, current training methods often underperform due to modality competition, a phenomenon where modalities contend for training resources, leaving some underoptimized. This raises a pivotal question: how can we address training imbalances, ensure adequate optimization across all modalities, and achieve consistent performance improvements as we transition from unimodal to multimodal data? This paper proposes the Multimodal Competition Regularizer (MCR), inspired by a mutual information (MI) decomposition designed to prevent the adverse effects of competition in multimodal training. Our key contributions are: 1) A game-theoretic framework that adaptively balances modality contributions by encouraging each to maximize its informative role in the final prediction. 2) Refining lower and upper bounds for each MI term to enhance the extraction of both task-relevant unique and shared information across modalities. 3) Proposing latent space permutations for conditional MI estimation, significantly improving computational efficiency. MCR outperforms all previously suggested training strategies and simple baselines, demonstrating that training modalities jointly lead to important performance gains on synthetic and large real-world datasets. We release our code and models at https://github.com/kkontras/MCR.'}",https://openreview.net{'value': '/pdf/30e94c5334327304d4a1201d19acb8c6ba1da42b.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=asS4W7Yw5e,{'value': 'Reinventing Multi-Agent Collaboration through Gaussian-Image Synergy in Diffusion Policies'},Ziye Wang; Li Kang; Yiran Qin; Jiahua Ma; zhanglin peng; LEI BAI; Ruimao Zhang,~Ziye_Wang4; ~Li_Kang2; ~Yiran_Qin1; ~Jiahua_Ma2; ~zhanglin_peng1; ~LEI_BAI1; ~Ruimao_Zhang1,"{'value': ['3D Gaussian Reconstruction', 'Diffusion Policy', '3D Scene Representation', 'Robot Action Generation']}","{'value': 'Despite significant advances in robotic policy generation, effective coordination in embodied multi-agent systems remains a fundamental challenge—particularly in scenarios where agents must balance individual perspectives with global environmental awareness.\nExisting approaches often struggle to balance fine-grained local control with comprehensive scene understanding, resulting in limited scalability and compromised collaboration quality.\nIn this paper, we present GauDP, a novel Gaussian-image synergistic representation that facilitates scalable, perception-aware imitation learning in multi-agent collaborative systems.\nSpecifically, GauDP reconstructs a globally consistent 3D Gaussian field from local-view RGB images, allowing all agents to dynamically query task-relevant features from a shared scene representation. \nThis design facilitates both fine-grained control and globally coherent behavior without requiring additional sensing modalities. \nWe evaluate GauDP on the RoboFactory benchmark, which includes diverse multi-arm manipulation tasks. \nOur method achieves superior performance over existing image-based methods and approaches the effectiveness of point-cloud-driven methods, while maintaining strong scalability as the number of agents increases. \nExtensive ablations and visualizations further demonstrate the robustness and efficiency of our unified local-global perception framework for multi-agent embodied learning.'}",https://openreview.net{'value': '/pdf/31d2d65ea2b64e0aa8bf80c7d1c8684b3210b92e.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=aqpHTPC63N,{'value': 'Spend Wisely: Maximizing Post-Training Gains in Iterative Synthetic Data Bootstrapping'},Pu Yang; Yunzhen Feng; Ziyuan Chen; Yuhang Wu; Zhuoyuan Li,~Pu_Yang3; ~Yunzhen_Feng1; ~Ziyuan_Chen2; ~Yuhang_Wu2; ~Zhuoyuan_Li1,"{'value': ['synthetic data', 'self supervised fine-tuning', 'iterative learning', 'boostrapping', 'budget allocation']}","{'value': ""Modern foundation models often undergo iterative ``bootstrapping'' in their post-training phase: a model generates synthetic data, an external verifier filters out low-quality samples, and the high-quality subset is used for further fine-tuning. Over multiple iterations, the model performance improves, raising a crucial question: How should the total budget for generation and training be allocated across iterations to maximize final performance? \nIn this work, we develop a theoretical framework for analyzing budget allocation strategies. Specifically, we show that constant policies fail to converge with high probability, while increasing policies---particularly exponential growth policies---exhibit significant theoretical advantages. \nExperiments on image denoising with diffusion probabilistic models and math reasoning with large language models show that both exponential and polynomial growth policies consistently outperform constant policies, with exponential policies often providing more stable performance.""}",https://openreview.net{'value': '/pdf/63e35b6d090c274b0de2624b78d0aebfa54c3991.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=aq3tgx5wcu,{'value': 'YEAST: Yet Another Sequential Test'},Alexey Kurennoy; Majed Dodin; Tural Gurbanov; Ana Peleteiro Ramallo,~Alexey_Kurennoy1; ~Majed_Dodin1; ~Tural_Gurbanov1; ~Ana_Peleteiro_Ramallo1,"{'value': ['A/B testing', 'experiment monitoring', 'sequential test', 'early stopping']}","{'value': 'The online evaluation of machine learning models is typically conducted through A/B experiments. Sequential statistical tests are valuable tools for analysing these experiments, as they enable researchers to stop data collection early without increasing the risk of false discoveries. However, existing sequential tests either limit the number of interim analyses or suffer from low statistical power. In this paper, we introduce a novel sequential test designed for the continuous monitoring of A/B experiments. We validate our method using semi-synthetic simulations and demonstrate that it outperforms current state-of-the-art sequential testing approaches. Our method is derived using a new technique that inverts a bound on the probability of threshold crossing, based on a classical maximal inequality.'}",https://openreview.net{'value': '/pdf/2680f7641885ef05cc6d56ce4644b1dbd9098601.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=akhhwQh6UV,{'value': 'TimeWak: Temporal Chained-Hashing Watermark for Time Series Data'},Zhi Wen Soi; Chaoyi Zhu; Fouad Abiad; Aditya Shankar; Jeroen M. Galjaard; Huijuan Wang; Lydia Y. Chen,~Zhi_Wen_Soi1; ~Chaoyi_Zhu2; ~Fouad_Abiad1; ~Aditya_Shankar2; ~Jeroen_M._Galjaard1; ~Huijuan_Wang1; ~Lydia_Y._Chen1,"{'value': ['Watermarking', 'Time Series', 'Diffusion Models']}","{'value': ""Synthetic time series generated by diffusion models enable sharing privacy-sensitive datasets, such as patients' functional MRI records. Key criteria for synthetic data include high data utility and traceability to verify the data source. Recent watermarking methods embed in homogeneous latent spaces, but state-of-the-art time series generators operate in data space, making latent-based watermarking incompatible. This creates the challenge of watermarking directly in data space while handling feature heterogeneity and temporal dependencies. We propose TimeWak, the first watermarking algorithm for multivariate time series diffusion models. To handle temporal dependence and spatial heterogeneity, TimeWak embeds a temporal chained-hashing watermark directly within the temporal-feature data space. The other unique feature is the $\\epsilon$-exact inversion, which addresses the non-uniform reconstruction error distribution across features from inverting the diffusion process to detect watermarks. We derive the error bound of inverting multivariate time series while preserving robust watermark detectability. We extensively evaluate TimeWak on its impact on synthetic data quality, watermark detectability, and robustness under various post-editing attacks, against five datasets and baselines of different temporal lengths. Our results show that TimeWak achieves improvements of 61.96% in context-FID score, and 8.44% in correlational scores against the strongest state-of-the-art baseline, while remaining consistently detectable.""}",https://openreview.net{'value': '/pdf/a6ff7d370c62a27b4fde6fa99aa622b306f56204.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=ajBIcOBcKV,{'value': 'Concentration and excess risk bounds for imbalanced classification with synthetic oversampling'},Touqeer Ahmad; Mohammadreza Mousavi Kalan; François Portier; Gilles Stupfler,~Touqeer_Ahmad2; ~Mohammadreza_Mousavi_Kalan1; ~François_Portier1; ~Gilles_Stupfler1,{'value': ['Synthetic oversampling; Imbalanced classification; Concentration inequality; Excess risk bound; AM-risk']},"{'value': 'Synthetic oversampling of minority examples using SMOTE and its variants is a leading strategy for addressing imbalanced classification problems. Despite the success of this approach in practice, its theoretical foundations remain underexplored. We develop a theoretical framework to analyze the behavior of SMOTE and related methods when classifiers are trained on synthetic data. We first derive a uniform concentration bound on the discrepancy between the empirical risk over synthetic minority samples and the population risk on the true minority distribution. We then provide a nonparametric excess risk guarantee for kernel-based classifiers trained using such synthetic data. These results lead to practical guidelines for better parameter tuning of both SMOTE and the downstream learning algorithm. Numerical experiments are provided to illustrate and support the theoretical findings.'}",https://openreview.net{'value': '/pdf/1a8c301f882c21b9e52a79e0780c1d75a93d53a9.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=aaRYsPAcuE,{'value': 'Local Learning for Covariate Selection in Nonparametric Causal Effect Estimation with Latent Variables'},Zheng Li; Xichen Guo; Feng Xie; Yan Zeng; Hao Zhang; Zhi Geng,~Zheng_Li27; ~Xichen_Guo1; ~Feng_Xie1; ~Yan_Zeng2; ~Hao_Zhang61; ~Zhi_Geng1,"{'value': ['Causal Effect', 'Covariate Selection', 'Latent Variables', 'Local Learning', 'Causal Discovery']}","{'value': 'Estimating causal effects from nonexperimental data is a fundamental problem in many fields of science. A key component of this task is selecting an appropriate set of covariates for confounding adjustment to avoid bias. Most existing methods for covariate selection often assume the absence of latent variables and rely on learning the global causal structure among variables. However, identifying the global structure can be unnecessary and inefficient, especially when our primary interest lies in estimating the effect of a treatment variable on an outcome variable. To address this limitation, we propose a novel local learning approach for covariate selection in nonparametric causal effect estimation, which accounts for the presence of latent variables. Our approach leverages testable independence and dependence relationships among observed variables to identify a valid adjustment set for a target causal relationship, ensuring both soundness and completeness under standard assumptions. We validate the effectiveness of our algorithm through extensive experiments on both synthetic and real-world data.'}",https://openreview.net{'value': '/pdf/2108c826710d2469a3eeecc0d05ed28af9899649.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=aY97JGello,{'value': 'Safe and Stable Control via Lyapunov-Guided Diffusion Models'},Xiaoyuan Cheng; Xiaohang Tang; Yiming Yang,~Xiaoyuan_Cheng1; ~Xiaohang_Tang1; ~Yiming_Yang4,"{'value': ['safe and stable control', 'diffusion for control', 'Lyapunov-guided sampling']}","{'value': 'Diffusion models have made significant strides in recent years, exhibiting strong generalization capabilities in planning and control tasks. However, most diffusion-based policies remain focused on reward maximization or cost minimization, often overlooking critical aspects of safety and stability. In this work, we propose Safe and Stable Diffusion ($S^2$Diff), a model-based framework that explores how diffusion models can ensure safety and stability from a Lyapunov perspective. We demonstrate that $S^2$Diff eliminates the reliance on both complex gradient-based solvers (e.g., quadratic programming, non-convex solvers) and control-affine structures, leading to globally valid control policies driven by the learned certificate functions. Additionally, we uncover intrinsic connections between diffusion sampling and almost Lyapunov theory, enabling the use of trajectory-level control policies to learn better certificate functions for safety and stability guarantees. To validate our approach, we conduct experiments on a wide variety of dynamical control systems, where $S^2$Diff consistently outperforms both certificate-based controllers and model-based diffusion baselines in terms of safety, stability, and overall control performance.'}",https://openreview.net{'value': '/pdf/9b819b96996e8c3443136c499c53ea1c2a1c2f62.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=aXAkNlbnGa,{'value': 'Joint Velocity-Growth Flow Matching for Single-Cell Dynamics Modeling'},Dongyi Wang; Yuanwei Jiang; Zhenyi Zhang; Xiang Gu; Peijie Zhou; Jian Sun,~Dongyi_Wang2; ~Yuanwei_Jiang1; ~Zhenyi_Zhang1; ~Xiang_Gu1; ~Peijie_Zhou1; ~Jian_Sun1,"{'value': ['flow matching', 'single-cell', 'optimal transport', 'dynamics modeling']}","{'value': 'Learning the underlying dynamics of single cells from snapshot data has gained increasing attention in scientific and machine learning research. The destructive measurement technique and cell proliferation/death result in unpaired and unbalanced data between snapshots, making the learning of the underlying dynamics challenging. In this paper, we propose joint Velocity-Growth Flow Matching (VGFM), a novel paradigm that jointly learns state transition and mass growth of single-cell populations via flow matching. VGFM builds an ideal single-cell dynamics containing velocity of state and growth of mass, driven by a presented two-period dynamic understanding of the static semi-relaxed optimal transport, a mathematical tool that seeks the coupling between unpaired and unbalanced data. To enable practical usage, we approximate the ideal dynamics using neural networks, forming our joint velocity and growth matching framework. A distribution fitting loss is also employed in VGFM to further improve the fitting performance for snapshot data. Extensive experimental results on both synthetic and real datasets demonstrate that VGFM can capture the underlying biological dynamics accounting for mass and state variations over time, outperforming existing approaches for single-cell dynamics modeling.'}",https://openreview.net{'value': '/pdf/9f11dcc1529f78a8688417612e15793796038b39.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=aUXiqhLh0S,{'value': 'Balanced Active Inference'},Boyu Chen; Zhixiang Zhou; Liuhua Peng; Zhonglei Wang,~Boyu_Chen13; ~Zhixiang_Zhou1; ~Liuhua_Peng1; ~Zhonglei_Wang1,"{'value': ['asymptotic properties', 'cube method', 'label selection', 'statistical efficiency']}","{'value': 'Limited labeling budget severely impedes data-driven research, such as medical analysis, remote sensing and population census, and active inference is a solution to this problem. Prior works utilizing independent sampling have achieved improvements over uniform sampling, but its insufficient usage of available information undermines its statistical efficiency. In this paper, we propose balanced active inference, a novel algorithm that incorporates balanced constraints based on model uncertainty utilizing the cube method for label selection. Under regularity conditions, we establish its asymptotic properties and also prove that the statistical efficiency of the proposed algorithm is higher than its alternatives. Various numerical experiments, including regression and classification in both synthetic setups and real data analysis, demonstrate that the proposed algorithm outperforms its alternatives while guaranteeing nominal coverage.'}",https://openreview.net{'value': '/pdf/cd6a747266b7634fe95a56e72c160636fa0331a0.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=aSfBbhUJAa,{'value': 'RepoMaster: Autonomous Exploration and Understanding of GitHub Repositories for  Complex Task Solving'},Huacan Wang; Ziyi Ni; Shuo Zhang; Shuo Lu; Sen Hu; Ziyang He; Chen Hu; Jiaye Lin; Yifu Guo; Yuntao Du; Pin Lyu,~Huacan_Wang1; ~Ziyi_Ni1; ~Shuo_Zhang21; ~Shuo_Lu1; ~Sen_Hu2; ~Ziyang_He4; ~Chen_Hu1; ~Jiaye_Lin1; ~Yifu_Guo1; ~Yuntao_Du2; ~Pin_Lyu1,"{'value': ['Repository Comprehension', 'GitHub Integration', 'Efficient Repository Exploration', 'Autonomous Agents']}","{'value': 'The ultimate goal of code agents is to solve complex tasks autonomously. \nAlthough large language models (LLMs) have made substantial progress in code generation, real-world tasks typically demand full-fledged code repositories rather than simple scripts.  Building such repositories from scratch remains a major challenge.  Fortunately, GitHub hosts a vast, evolving collection of open-source repositories, which developers frequently reuse as modular components for complex tasks. Yet, existing frameworks like OpenHands and SWE-Agent still struggle to effectively leverage these valuable resources.\nRelying solely on README files provides insufficient guidance, and deeper exploration reveals two core obstacles: overwhelming information and tangled dependencies of repositories, both constrained by the limited context windows of current LLMs.\nTo tackle these issues, we propose RepoMaster, an autonomous agent framework designed to explore and reuse GitHub repositories for solving complex tasks. \nFor efficient understanding, RepoMaster constructs function-call graphs, module-dependency graphs, and hierarchical code trees to identify essential components, providing only identified core elements to the LLMs rather than the entire repository. \nDuring autonomous execution, it progressively explores related components using our exploration tools and prunes information to optimize context usage.\nEvaluated on the adjusted MLE-bench, RepoMaster achieves a 110\\% relative boost in valid submissions over the strongest baseline OpenHands. \nOn our newly released GitTaskBench, RepoMaster lifts the task-pass rate from 40.7% to 62.9% while reducing token usage by 95%. \nOur code and demonstration materials are publicly available at https://github.com/QuantaAlpha/RepoMaster.'}",https://openreview.net{'value': '/pdf/fea6d1106531a6d10e824159b158dcbffbc07cc2.pdf'},{'abstract_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=aPBBkHDK4W,{'value': 'RiOSWorld: Benchmarking the Risk of Multimodal Computer-Use Agents'},Yang JingYi; Shuai Shao; Dongrui Liu; Jing Shao,~Yang_JingYi1; ~Shuai_Shao11; ~Dongrui_Liu1; ~Jing_Shao3,"{'value': ['Agent Safety', 'Safety Evaluation Benchmark']}","{'value': 'With the rapid development of multimodal large language models (MLLMs), they are increasingly deployed as autonomous computer-use agents capable of accomplishing complex computer tasks. However, a pressing issue arises: Can the safety risk principles designed and aligned for general MLLMs in dialogue scenarios be effectively transferred to real-world computer-use scenarios? \nExisting research on evaluating the safety risks of MLLM-based computer-use agents suffers from several limitations: it either lacks realistic interactive environments, or narrowly focuses on one or a few specific risk types. These limitations ignore the complexity, variability, and diversity of real-world environments, thereby restricting comprehensive risk evaluation for computer-use agents.\nTo this end, we introduce **RiOSWorld**, a benchmark designed to evaluate the potential risks of MLLM-based agents during real-world computer manipulations. Our benchmark includes 492 risky tasks spanning various computer applications, involving web, social media, multimedia, os, email, and office software. We categorize these risks into two major classes based on their risk source: (i) User-originated risks and (ii) Environmental risks. For the evaluation, we evaluate safety risks from two perspectives: (i) Risk goal intention and (ii) Risk goal completion. Extensive experiments with multimodal agents on **RiOSWorld** demonstrate that current computer-use agents confront significant safety risks in real-world scenarios. Our findings highlight the necessity and urgency of safety alignment for computer-use agents in real-world computer manipulation, providing valuable insights for developing trustworthy computer-use agents.'}",https://openreview.net{'value': '/pdf/11ac207fff4f7439cb345f2e79ef2a6fb5611910.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=aLGgz4SOyu,{'value': 'Sherlock: Self-Correcting Reasoning in Vision-Language Models'},Yi Ding; Ruqi Zhang,~Yi_Ding8; ~Ruqi_Zhang1,"{'value': ['Vision-Language Models', 'Self-Correction', 'Reasoning', 'Chain of Thought']}","{'value': 'Reasoning Vision-Language Models (VLMs) have shown promising performance on complex multimodal tasks. However, they still face significant challenges: they are highly sensitive to reasoning errors, require large volumes of annotated data or accurate verifiers, and struggle to generalize beyond specific domains. To address these limitations, we explore self-correction as a strategy to enhance reasoning VLMs. We first conduct an in-depth analysis of reasoning VLMs’ self-correction abilities and identify key gaps. Based on our findings, we introduce \\emph{Sherlock}, a self-correction and self-improvement training framework. \\emph{Sherlock} introduces a trajectory-level self-correction objective, a preference data construction method based on visual perturbation, and a dynamic $\\beta$ for preference tuning. Once the model acquires self-correction capabilities using only 20k randomly sampled annotated data, it continues to self-improve without external supervision. Built on the Llama3.2-Vision-11B model, \\emph{Sherlock} achieves remarkable results across eight benchmarks, reaching an average accuracy of 64.1 with direct generation and 65.4 after self-correction. It outperforms LLaVA-CoT (63.2), Mulberry (63.9), and LlamaV-o1 (63.4) while using less than 20\\% of the annotated data.'}",https://openreview.net{'value': '/pdf/2cca74fc9d7ace7039b552ae0c9713648f96865a.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=aI3d897dgV,{'value': 'Causal Mixture Models: Characterization and Discovery'},Sarah Mameche; Janis Kalofolias; Jilles Vreeken,~Sarah_Mameche1; ~Janis_Kalofolias1; ~Jilles_Vreeken2,"{'value': ['causal discovery', 'mixture modelling']}","{'value': 'Real-world datasets are often a combination of unobserved subpopulations that follow distinct causal generating processes. In an observational study, for example, participants may fall into unknown groups that either (a) respond effectively to a drug, or (b) show no response due to drug resistance. Not accounting for such heterogeneity then risks biased estimates of  drug effectiveness.  \n In this work, we formulate this setting through a causal mixture model,\n in which the data-generating process of each variable depends on latent group membership (a or b). Specifically, we model each variable as a   mixture of structural causal equation models, where latent categorical (mixing) variables index assignment to subpopulations. Unlike prior work, the approach allows  for multiple independent mixing variables, each affecting distinct sets of observed variables. To infer both the graph, mixing variables, and assignments jointly, we integrate mixture modeling into score-based causal discovery; show theoretically that the resulting scoring criterion is consistent; and demonstrate  empirically that the resulting causal discovery approach discovers the causal model in synthetic and real-world evaluations.'}",https://openreview.net{'value': '/pdf/ccff832195f36966f6e37445c6efaa5f900570e8.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=aI3Oacoyi6,{'value': 'Distributed Multi-Agent Bandits Over Erdős-Rényi Random Networks'},Jingyuan Liu; Hao Qiu; Lin Yang; Mengfan Xu,~Jingyuan_Liu3; ~Hao_Qiu2; ~Lin_Yang11; ~Mengfan_Xu1,{'value': ['distributed stochastic bandit']},"{'value': ""We study the distributed multi-agent multi-armed bandit problem with heterogeneous rewards over random communication graphs. Uniquely, at each time step $t$ agents communicate over a time-varying random graph $\\mathcal{G}\\_t$ generated by applying the Erdős–Rényi model to a fixed connected base graph $\\mathcal{G}$ (for classical Erdos-Rényi graphs, $\\mathcal{G}$ is a complete graph), where each potential edge in $\\mathcal{G}$ is randomly and independently present with the link probability $p$. Notably, the resulting random graph is not necessarily connected at each time step. Each agent's arm rewards follow time-invariant distributions, and the reward distribution for the same arm may differ across agents. The goal is to minimize the cumulative expected regret relative to the global mean reward of each arm, defined as the average of that arm’s mean rewards across all agents. To this end, we propose a fully distributed algorithm that integrates the arm elimination strategy with the random gossip algorithm. We theoretically show that the regret upper bound is of order $\\log T$ and is highly interpretable, where $T$ is the time horizon. It includes the optimal centralized regret $\\mathcal O\\left(\\sum_{k: \\Delta_k>0} \\frac{\\log T}{\\Delta_k}\\right)$ and an additional term $\\mathcal O\\left(\\frac{N^2 \\log T}{p \\lambda_{N-1}(\\operatorname{Lap}(\\mathcal{G}))} + \\frac{KN^2 \\log T}{p}\\right)$ where $N$ and $K$ denote the total number of agents and arms, respectively. This term reflects the impact of $\\mathcal G$'s algebraic connectivity $\\lambda_{N-1}(\\operatorname{Lap}(\\mathcal{G}))$ and the link probability $p$, and thus highlights a fundamental trade-off between communication efficiency and regret. As a by-product, we show a nearly optimal regret lower bound. Finally, our numerical experiments not only show the superiority of our algorithm over existing benchmarks, but also validate the theoretical regret scaling with problem complexity.""}",https://openreview.net{'value': '/pdf/77bc35f6c090e8931f1dbb2aa19626ba4ccb3c9a.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=aHAMUEsQLc,{'value': 'Data-Adaptive Exposure Thresholds under Network Interference'},Vydhourie Thiyageswaran; Tyler McCormick; Jennifer Rogers Brennan,~Vydhourie_Thiyageswaran1; ~Tyler_McCormick1; ~Jennifer_Rogers_Brennan1,"{'value': ['Network Interference', 'Experimentation', 'Causal Inference', 'Average Treatment Effect']}","{'value': ""Randomized controlled trials often suffer from interference, a violation of the Stable Unit Treatment Value Assumption (SUTVA), where a unit's outcome is influenced by its neighbors' treatment assignments. This interference biases naive estimators of the average treatment effect (ATE). A popular method to achieve unbiasedness pairs the Horvitz-Thompson estimator of the ATE with a known exposure mapping, a function that identifies units in a given randomization unaffected by interference. For example, an exposure mapping may stipulate that a unit experiences no further interference if at least an $h$-fraction of its neighbors share its treatment status. However, selecting this threshold $h$ is challenging, requiring domain expertise; in its absence, fixed thresholds such as $h = 1$ are often used. In this work, we propose a data-adaptive method to select the $h$-fractional threshold that minimizes the mean-squared-error (MSE) of the Horvitz-Thompson estimator. Our approach estimates the bias and variance of the Horvitz-Thompson estimator paired with candidate thresholds by leveraging a first-order approximation, specifically, linear regression of potential outcomes on exposures. We present simulations illustrating that our method improves upon non-adaptive threshold choices, and an adapted Lepski's method. We further illustrate the performance of our estimator by running experiments with synthetic outcomes on a real village network dataset, and on a publicly-available Amazon product similarity graph. Furthermore, we demonstrate that our method remains robust to deviations from the linear potential outcomes model.""}",https://openreview.net{'value': '/pdf/904d1045a44862791d5e6a1e5749ce3a265addd4.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=aE0bCvXXBt,{'value': 'Transformers Provably Learn Chain-of-Thought Reasoning with Length Generalization'},Yu Huang; Zixin Wen; Aarti Singh; Yuejie Chi; Yuxin Chen,~Yu_Huang3; ~Zixin_Wen1; ~Aarti_Singh2; ~Yuejie_Chi1; ~Yuxin_Chen5,"{'value': ['transformers', 'chain of thought', 'length generalization', 'deep learning theory', 'non-convex optimization']}","{'value': 'The ability to reason lies at the core of artificial intelligence (AI), and challenging problems usually call for deeper and longer reasoning to tackle. A crucial question about AI reasoning is whether models can extrapolate  learned reasoning patterns to solve harder tasks that require longer chain-of-thoughts (CoT).\nIn this work, we present a theoretical analysis of transformers trained via gradient descent on synthetic data for various state tracking tasks, revealing how length-generalizable reasoning can emerge. Specifically, we prove that:\n(i) for tasks with simple algebraic structure such as cyclic-group composition,\ntransformers trained on short, constant-length chains learn a solution pattern\nthat extrapolates to much longer chains; and\n(ii) for more complex tasks such as symmetric-group composition, a recursive\nself-training curriculum bootstraps longer reasoning and generalizes well\nbeyond the training horizon, up to the natural limit of our setting. Our results demonstrate that transformers can learn sequential reasoning skills that scale with problem complexity. Moreover, we provide the first  optimization-based  guarantee demonstrating that constant-depth transformers can learn the state tracking problems in $\\mathsf{NC}^1$, which exceeds the prior barrier limited to $\\mathsf{TC}^0$, unless the famous conjecture $\\mathsf{TC}^0 \\neq \\mathsf{NC}^1$ is false.'}",https://openreview.net{'value': '/pdf/ba051e0f1adb3538f8447d79cab371a4a52ab9a2.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=aDTcN3yZGE,{'value': 'Reinforcing the Diffusion Chain of Lateral Thought with Diffusion Language Models'},Zemin Huang; Zhiyang Chen; Zijun Wang; Tiancheng Li; Guo-Jun Qi,~Zemin_Huang1; ~Zhiyang_Chen2; ~Zijun_Wang8; ~Tiancheng_Li4; ~Guo-Jun_Qi1,"{'value': ['reinforcement learning', 'diffusion language models', 'diffusion chain of lateral thought']}","{'value': 'We introduce the Diffusion Chain of Lateral Thought (DCoLT), a reasoning framework for diffusion language models. DCoLT treats each intermediate step in the reverse diffusion process as a latent ""thinking"" action and optimizes the entire reasoning trajectory to maximize the reward on the correctness of the final answer with outcome-based Reinforcement Learning (RL). Unlike traditional Chain-of-Thought (CoT) methods that follow a causal, linear thinking process, DCoLT allows bidirectional, non-linear reasoning with no strict rule on grammatical correctness amid its intermediate steps of thought. We implement DCoLT on two representative Diffusion Language Models (DLMs). First, we choose SEDD as a representative continuous-time discrete diffusion model, where its concrete score derives a probabilistic policy to maximize the RL reward over the entire sequence of intermediate diffusion steps.  We further consider the discrete-time masked diffusion language model -- LLaDA, and find that the order to predict and unmask tokens plays an essential role to optimize its RL action resulting from the ranking-based Unmasking Policy Module (UPM) defined by the Plackett-Luce model. Experiments on both math and code generation tasks show that using only public data and 16 H800 GPUs, DCoLT-reinforced DLMs outperform other DLMs trained by SFT or RL or even both. Notably, DCoLT-reinforced LLaDA boosts its reasoning accuracy by +9.8%, +5.7%, +11.4%, +19.5% on GSM8K, MATH, MBPP, and HumanEval.'}",https://openreview.net{'value': '/pdf/1f5c3bea979f0704bf41ac9ccc06db12a82e2e28.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=a49F7EAm6l,{'value': 'DexFlyWheel: A Scalable and Self-improving Data Generation Framework for Dexterous Manipulation'},Kefei Zhu; Fengshuo Bai; YuanHao Xiang; Yishuai Cai; Xinglin Chen; Ruochong Li; Xingtao Wang; Hao Dong; Yaodong Yang; Xiaopeng Fan; Yuanpei Chen,~Kefei_Zhu1; ~Fengshuo_Bai1; ~YuanHao_Xiang2; ~Yishuai_Cai1; ~Xinglin_Chen1; ~Ruochong_Li1; ~Xingtao_Wang1; ~Hao_Dong3; ~Yaodong_Yang1; ~Xiaopeng_Fan1; ~Yuanpei_Chen2,"{'value': ['robotic learning', 'dexterous manipulation', 'data flywheel']}","{'value': 'Dexterous manipulation is critical for advancing robot capabilities in real-world applications, yet diverse and high-quality datasets remain scarce. Existing data collection methods either rely on human teleoperation or require significant human engineering, or generate data with limited diversity, which restricts their scalability and generalization. In this paper, we introduce DexFlyWheel, a scalable data generation framework that employs a self-improving cycle to continuously enrich data diversity. Starting from efficient seed demonstrations warmup, DexFlyWheel expands the dataset through iterative cycles. Each cycle follows a closed-loop pipeline that integrates Imitation Learning (IL), residual Reinforcement Learning (RL), rollout trajectory collection, and data augmentation. Specifically, IL extracts human-like behaviors from demonstrations, and residual RL enhances policy generalization. The learned policy is then used to generate trajectories in simulation, which are further augmented across diverse environments and spatial configurations before being fed back into the next cycle. Over successive iterations, a self-improving data flywheel effect emerges, producing datasets that cover diverse scenarios and thereby scaling policy performance. Experimental results demonstrate that DexFlyWheel generates over 2,000 diverse demonstrations across four challenging tasks. Policies trained on our dataset achieve an average success rate of 81.9\\% on the challenge test sets and successfully transfer to the real world through digital twin, achieving a 78.3\\% success rate on dual-arm lift tasks.'}",https://openreview.net{'value': '/pdf/afa7f5544d62b8d426e0a7ab40c16a45776f6efc.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=ZnrM5RGrgR,{'value': 'OptiScene: LLM-driven Indoor Scene Layout Generation via Scaled Human-aligned Data Synthesis and Multi-Stage Preference Optimization'},Yixuan Yang; Zhen Luo; Tongsheng Ding; Junru Lu; Mingqi Gao; Jinyu Yang; Victor Sanchez; Feng Zheng,~Yixuan_Yang6; ~Zhen_Luo2; ~Tongsheng_Ding1; ~Junru_Lu1; ~Mingqi_Gao3; ~Jinyu_Yang1; ~Victor_Sanchez1; ~Feng_Zheng1,"{'value': ['Indoor scene layout generation', 'LLM-based', 'DPO', '3D', 'Synthetic Data']}","{'value': ""Automatic indoor layout generation has attracted increasing attention due to its potential in interior design, virtual environment construction, and embodied AI. Existing methods fall into two categories: prompt-driven approaches that leverage proprietary LLM services (e.g., GPT APIs), and learning-based methods trained on layout data upon diffusion-based models. Prompt-driven methods often suffer from spatial inconsistency and high computational costs, while learning-based methods are typically constrained by coarse relational graphs and limited datasets, restricting their generalization to diverse room categories. In this paper, we revisit LLM-based indoor layout generation and present 3D-SynthPlace, a large-scale dataset that combines synthetic layouts generated via a `GPT synthesize, Human inspect' pipeline, upgraded from the 3D-Front dataset. 3D-SynthPlace contains nearly 17,000 scenes, covering four common room types—bedroom, living room, kitchen, and bathroom—enriched with diverse objects and high-level spatial annotations. We further introduce OptiScene, a strong open-source LLM optimized for indoor layout generation, fine-tuned based on our 3D-SynthPlace dataset through our two-stage training. For the warum-up stage I, we adopt supervised fine-tuning (SFT), which is taught to first generate high-level spatial descriptions then conditionally predict concrete object placements. For the reinforcing stage II, to better align the generated layouts with human design preferences, we apply multi-turn direct preference optimization (DPO), which significantly improving layout quality and generation success rates. Extensive experiments demonstrate that OptiScene outperforms traditional prompt-driven and learning-based baselines. Moreover, OptiScene shows promising potential in interactive tasks such as scene editing and robot navigation, highlighting its applicability beyond static layout generation.""}",https://openreview.net{'value': '/pdf/006d74d8622bdd923a664d247091cceaf995db43.pdf'},{'title_filter': 'Data Synthesis'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=ZkGHzGIaMB,{'value': 'Generalization or Hallucination? Understanding Out-of-Context Reasoning in Transformers'},Yixiao Huang; Hanlin Zhu; Tianyu Guo; Jiantao Jiao; Somayeh Sojoudi; Michael I. Jordan; Stuart Russell; Song Mei,~Yixiao_Huang3; ~Hanlin_Zhu2; ~Tianyu_Guo4; ~Jiantao_Jiao1; ~Somayeh_Sojoudi1; ~Michael_I._Jordan2; ~Stuart_Russell1; ~Song_Mei1,"{'value': ['Factual implication', 'Transformer', 'Implicit bias']}","{'value': 'Large language models (LLMs) can acquire new knowledge through fine-tuning, but this process exhibits a puzzling duality: models can generalize remarkably from new facts, yet are also prone to hallucinating incorrect information. However, the reasons for this phenomenon remain poorly understood. In this work, we argue that both behaviors stem from a single mechanism known as out-of-context reasoning (OCR): the ability to deduce implications by associating concepts, even those without a causal link. Our experiments across five prominent LLMs confirm that OCR indeed drives both generalization and hallucination, depending on whether the associated concepts are causally related. To build a rigorous theoretical understanding of this phenomenon, we then formalize OCR as a synthetic factual recall task. We empirically show that a one-layer single-head attention-only transformer with factorized output and value matrices can learn to solve this task, while a model with combined weights cannot, highlighting the crucial role of matrix factorization. Our theoretical analysis shows that the OCR capability can be attributed to the implicit bias of gradient descent, which favors solutions that minimize the nuclear norm of the combined output-value matrix. This structure explains why the model learns to associate facts and implications with high sample efficiency, regardless of whether the correlation is causal or merely spurious. Ultimately, our work provides a theoretical foundation for understanding the OCR phenomenon, offering a new lens for analyzing and mitigating undesirable behaviors from knowledge injection.'}",https://openreview.net{'value': '/pdf/ba09a69b9f3ea21dc345fef9e047ff5eb6a933f0.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=Zj0L8xIZYP,{'value': 'Sequential Monte Carlo for Policy Optimization in Continuous POMDPs'},Hany Abdulsamad; Sahel Iqbal; Simo Särkkä,~Hany_Abdulsamad1; ~Sahel_Iqbal1; ~Simo_Särkkä1,"{'value': ['POMDP', 'Policy Optimization', 'Sequential Monte Carlo', 'Feynman--Kac', 'Control-as-Inference', 'Decision-Making under Uncertainty']}","{'value': 'Optimal decision-making under partial observability requires agents to balance reducing uncertainty (exploration) against pursuing immediate objectives (exploitation). In this paper, we introduce a novel policy optimization framework for continuous partially observable Markov decision processes (POMDPs) that explicitly addresses this challenge. Our method casts policy learning as probabilistic inference in a non-Markovian Feynman--Kac model that inherently captures the value of information gathering by anticipating future observations, without requiring suboptimal approximations or handcrafted heuristics. To optimize policies under this model, we develop a nested sequential Monte Carlo (SMC) algorithm that efficiently estimates a history-dependent policy gradient under samples from the optimal trajectory distribution induced by the POMDP. We demonstrate the effectiveness of our algorithm across standard continuous POMDP benchmarks, where existing methods struggle to act under uncertainty.'}",https://openreview.net{'value': '/pdf/9fe8055f380f6f73928ee97039186ebd8ea75d8e.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=Zf6Oj5x9sE,{'value': 'Causal Differentiating Concepts:  Interpreting LM Behavior via Causal Representation Learning'},Navita Goyal; Hal Daumé III; Alexandre Drouin; Dhanya Sridhar,~Navita_Goyal1; ~Hal_Daumé_III1; ~Alexandre_Drouin2; ~Dhanya_Sridhar2,"{'value': ['LM interpretability', 'causal representation learning', 'concept discovery']}","{'value': 'Language model activations entangle concepts that mediate their behavior, making it difficult to interpret these factors, which has implications for generalizability and robustness. We introduce an approach for disentangling these concepts without supervision. Existing methods for concept discovery often rely on external labels, contrastive prompts, or known causal structures, which limits their scalability and biases them toward predefined, easily annotatable features. In contrast, we propose a new unsupervised algorithm that identifies causal differentiating concepts—interpretable latent directions in LM activations that must be changed to elicit a different model behavior. These concepts are discovered using a constrained contrastive learning objective, guided by the insight that eliciting a target behavior requires only sparse changes to the underlying concepts. We formalize this notion and show that, under a particular assumption about the sparsity of these causal differentiating concepts, our method learns disentangled representations that align with human-interpretable factors influencing LM decisions. We empirically show the ability of our method to recover ground-truth causal factors in synthetic and semi-synthetic settings. Additionally, we illustrate the utility of our method through a case study on refusal behavior in language models. Our approach offers a scalable and interpretable lens into the internal workings of LMs, providing a principled foundation for interpreting language model behavior.'}",https://openreview.net{'value': '/pdf/f3cb8729c23c66e62a1b81e23f4f38cb11802aca.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=ZdmmOAN4h3,{'value': 'Breaking the Frozen Subspace: Importance Sampling for Low-Rank Optimization in LLM Pretraining'},Haochen Zhang; Junze Yin; Guanchu Wang; Zirui Liu; Lin Yang; Tianyi Zhang; Anshumali Shrivastava; Vladimir Braverman,~Haochen_Zhang9; ~Junze_Yin1; ~Guanchu_Wang1; ~Zirui_Liu1; ~Lin_Yang12; ~Tianyi_Zhang6; ~Anshumali_Shrivastava1; ~Vladimir_Braverman1,"{'value': ['low-rank optimization', 'large language models', 'Adam', 'memory efficiency']}","{'value': 'Low-rank optimization has emerged as a promising approach to enabling memory-efficient training of large language models (LLMs). Existing low-rank optimization methods typically project gradients onto a low-rank subspace, reducing the memory cost of storing optimizer states. A key challenge in these methods is selecting suitable subspaces to ensure an effective optimization trajectory. Most existing approaches select the dominant subspace to preserve gradient information, as this intuitively provides the best approximation. However, we find that in practice, the dominant subspace stops changing during pretraining, thereby constraining weight updates to similar subspaces. In this paper, we propose importance sampling for low-rank optimization in LLM pretraining with a provable convergence guarantee, which the dominant subspace approach does not have. Empirically, we demonstrate that our method significantly outperforms previous methods in LLM pretraining tasks.'}",https://openreview.net{'value': '/pdf/a5c087fda18ddf464374f4ba9f0eaf93e5414c84.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=ZBlHEeSvKd,{'value': 'PaTH Attention: Position Encoding via Accumulating Householder Transformations'},Songlin Yang; Yikang Shen; Kaiyue Wen; Shawn Tan; Mayank Mishra; Liliang Ren; Rameswar Panda; Yoon Kim,~Songlin_Yang1; ~Yikang_Shen1; ~Kaiyue_Wen1; ~Shawn_Tan1; ~Mayank_Mishra1; ~Liliang_Ren1; ~Rameswar_Panda1; ~Yoon_Kim1,"{'value': ['position encoding', 'state tracking', 'position embedding', 'contextualized position encoding', 'sequence modeling', 'softmax attention', 'attention mechanism', 'DeltaNet', 'delta rule']}","{'value': 'The attention mechanism is a core primitive in modern large language models (LLMs) and AI more broadly. Since attention by itself is permutation-invariant, position encoding is essential for modeling structured domains such as language. Rotary position encoding (RoPE) has emerged as the de facto standard approach for position encoding and is part of many modern LLMs. However, in RoPE the key/query transformation between two elements in a sequence is only a function of their relative position and otherwise independent of the actual input. This limits the expressivity of RoPE-based transformers.\n\n   This paper describes PaTH, a flexible data-dependent position encoding scheme based on accumulated products of  Householder(like) transformations, where each transformation is data-dependent, i.e., a function of the input. We derive an efficient parallel  algorithm for training through exploiting a compact representation of products of Householder matrices, and implement a FlashAttention-style blockwise  algorithm. Across both targeted synthetic benchmarks  and moderate-scale real-world language modeling experiments, we find that PaTH improves upon RoPE and other recent baselines. Finally, we show that we can convert pretrained RoPE transformers into PaTH with continued pretraining.'}",https://openreview.net{'value': '/pdf/ccd24f6146e807c67104d8bb617a102d9c7bb6d5.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=ZAKpELpclI,{'value': 'Optimal Neural Compressors for the Rate-Distortion-Perception Tradeoff'},Eric Lei; Hamed Hassani; Shirin Saeedi Bidokhti,~Eric_Lei2; ~Hamed_Hassani2; ~Shirin_Saeedi_Bidokhti1,"{'value': ['neural compression', 'rate-distortion-perception', 'lattice quantization', 'dithering']}","{'value': 'Recent efforts in neural compression have focused on the rate-distortion-perception (RDP) tradeoff, where the perception constraint ensures the source and reconstruction distributions are close in terms of a statistical divergence. Theoretical work on RDP describes properties of RDP-optimal compressors without providing constructive and low complexity solutions. While classical rate-distortion theory shows that optimal compressors should efficiently pack space, RDP theory additionally shows that infinite randomness shared between the encoder and decoder may be necessary for RDP optimality. In this paper, we propose neural compressors that are low complexity and benefit from high packing efficiency through lattice coding and shared randomness through shared dithering over the lattice cells. For two important settings, namely infinite shared and zero shared randomness, we analyze the RDP tradeoff achieved by our proposed neural compressors and show optimality in both cases. Experimentally, we investigate the roles that these two components of our design, lattice coding and randomness, play in the performance of neural compressors on synthetic and real-world data. We observe that performance improves with more shared randomness and better lattice packing.'}",https://openreview.net{'value': '/pdf/bbe3f37b801834125ced0fa0dbae569f66f22842.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=Z6b7xavA3Y,{'value': 'Generative Model Inversion Through the Lens of the Manifold Hypothesis'},Xiong Peng; Bo Han; Fengfei Yu; Tongliang Liu; Feng Liu; Mingyuan Zhou,~Xiong_Peng1; ~Bo_Han1; ~Fengfei_Yu1; ~Tongliang_Liu1; ~Feng_Liu2; ~Mingyuan_Zhou1,{'value': ['Generative Model Inversion Attacks']},"{'value': 'Model inversion attacks (MIAs) aim to reconstruct class-representative samples from trained models. Recent generative MIAs utilize generative adversarial networks to learn image priors that guide the inversion process, yielding reconstructions with high visual quality and strong fidelity to the private data. To explore the reason behind their effectiveness, we begin by examining the gradients of inversion loss w.r.t. synthetic inputs, and find that these gradients are surprisingly noisy. Further analysis shows that generative model inversion approaches implicitly denoise the gradients by projecting them onto the tangent space of the generator manifold—filtering out directions that deviate from the manifold structure while preserving informative components aligned with it. Our empirical measurements show that, in models trained with standard supervision, loss gradients exhibit large angular deviations from the data manifold, indicating poor alignment with class-relevant directions. This observation motivates our central hypothesis: models become more vulnerable to MIAs when their loss gradients align more closely with the generator manifold. We validate this hypothesis by designing a novel training objective that explicitly promotes such alignment. Building on this insight, we further introduce a training-free approach to enhance gradient–manifold alignment during inversion, leading to consistent improvements over state-of-the-art generative MIAs.'}",https://openreview.net{'value': '/pdf/15ac6e24d88ce327661d68bda991fb9ead682462.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=Z6DJJIN8IJ,{'value': 'Modeling Cell Dynamics and Interactions with Unbalanced Mean Field Schrödinger Bridge'},Zhenyi Zhang; Zihan Wang; Yuhao Sun; Tiejun Li; Peijie Zhou,~Zhenyi_Zhang1; ~Zihan_Wang37; ~Yuhao_Sun5; ~Tiejun_Li2; ~Peijie_Zhou1,"{'value': ['optimal transport', 'Schrödinger bridge', 'trajectory inference', 'single-cell']}","{'value': 'Modeling the dynamics from sparsely time-resolved snapshot data is crucial for understanding complex cellular processes and behavior. Existing methods leverage optimal transport, Schrödinger bridge theory, or their variants to simultaneously infer stochastic, unbalanced dynamics from snapshot data. However, these approaches remain limited in their ability to account for cell-cell interactions. This integration is essential in real-world scenarios since intercellular communications are fundamental life processes and can influence cell state-transition dynamics. To address this challenge, we formulate the Unbalanced Mean-Field Schrödinger Bridge (UMFSB) framework to model unbalanced stochastic interaction dynamics from snapshot data. Inspired by this framework, we further propose CytoBridge, a deep learning algorithm designed to approximate the UMFSB problem. By explicitly modeling cellular transitions, proliferation, and interactions through neural networks, CytoBridge offers the flexibility to learn these processes directly from data. The effectiveness of our method has been extensively validated using both synthetic gene regulatory data and real scRNA-seq datasets. Compared to existing methods, CytoBridge identifies growth, transition, and interaction patterns, eliminates false transitions, and reconstructs the developmental landscape with greater accuracy. Code is available at: https://github.com/zhenyiizhang/CytoBridge-NeurIPS.'}",https://openreview.net{'value': '/pdf/1a39307a0187d0af28eee4b922b672feaa070487.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=YxPI1c5e09,{'value': 'Causal Climate Emulation with Bayesian Filtering'},Sebastian Hickman; Ilija Trajković; Julia Kaltenborn; Francis Pelletier; Alexander T Archibald; Yaniv Gurwicz; Peer Nowack; David Rolnick; Julien Boussard,~Sebastian_Hickman1; ~Ilija_Trajković1; ~Julia_Kaltenborn1; ~Francis_Pelletier1; ~Alexander_T_Archibald1; ~Yaniv_Gurwicz1; ~Peer_Nowack1; ~David_Rolnick1; ~Julien_Boussard1,"{'value': ['Climate', 'causality', 'interpretability', 'physics', 'emulation']}","{'value': 'Traditional models of climate change use complex systems of coupled equations to simulate physical processes across the Earth system. These simulations are highly computationally expensive, limiting our predictions of climate change and analyses of its causes and effects. Machine learning has the potential to quickly emulate data from climate models, but current approaches are not able to incorporate physically-based causal relationships. Here, we develop an interpretable climate model emulator based on causal representation learning. We derive a novel approach including a Bayesian filter for stable long-term autoregressive emulation. We demonstrate that our emulator learns accurate climate dynamics, and we show the importance of each one of its components on a realistic synthetic dataset and data from two widely deployed climate models.'}",https://openreview.net{'value': '/pdf/88f64ad1cda59878ee4fdb42b092b785c51e1a86.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=YufSVJxDgt,{'value': 'Inpainting the Neural Picture: Inferring Unrecorded Brain Area Dynamics from  Multi-Animal Datasets'},Ji Xia; Yizi Zhang; Shuqi Wang; Genevera I. Allen; Liam Paninski; Cole Lincoln Hurwitz; Kenneth D. Miller,~Ji_Xia1; ~Yizi_Zhang1; ~Shuqi_Wang1; ~Genevera_I._Allen1; ~Liam_Paninski1; ~Cole_Lincoln_Hurwitz1; ~Kenneth_D._Miller2,"{'value': ['neuroscience', 'autoencoder', 'Neuropixels datasets', 'inpainting', 'brain area interactions', 'eletrophysiology.']}","{'value': 'Characterizing interactions between brain areas is a fundamental goal of systems neuroscience. While such analyses are possible when areas are recorded simultaneously, it is rare to observe all combinations of areas of interest within a single animal or recording session. How can we leverage multi-animal datasets to better understand multi-area interactions? Building on recent progress in large-scale, multi-animal models, we introduce NeuroPaint, a masked autoencoding approach for inferring the dynamics of unobserved brain areas. By training across animals with overlapping subsets of recorded areas, NeuroPaint learns to reconstruct activity in missing areas based on shared structure across individuals. We train and evaluate our approach on both synthetic data and two multi-animal, multi-area Neuropixels datasets. Our results demonstrate that models trained across animals with partial observations can successfully in-paint the dynamics of unrecorded areas, enabling multi-area analyses that transcend the limitations of any single experiment.'}",https://openreview.net{'value': '/pdf/33cd92a1d08392c560a081c7854fbea4c27b00b9.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=YtmfBtIOPQ,{'value': 'Dataset Distillation of 3D Point Clouds via Distribution Matching'},Jae-Young Yim; Dongwook Kim; Jae-Young Sim,~Jae-Young_Yim1; ~Dongwook_Kim3; ~Jae-Young_Sim2,"{'value': ['Dataset Distillation', 'Dataset Condensation']}","{'value': 'Large-scale datasets are usually required to train deep neural networks; however, they increase computational complexity, hindering practical applications. Recently, dataset distillation for images and texts has attracted considerable attention, as it reduces the original dataset to a small synthetic one to alleviate the computational burden of training while preserving essential task-relevant information. However, dataset distillation for 3D point clouds remains largely unexplored, as point clouds exhibit fundamentally different characteristics from those of images, making this task more challenging. In this paper, we propose a distribution-matching-based distillation framework for 3D point clouds that jointly optimizes the geometric structures and orientations of synthetic 3D objects. To address the semantic misalignment caused by the unordered nature of point clouds, we introduce a Semantically Aligned Distribution Matching (SADM) loss, which is computed on the sorted features within each channel. Moreover, to handle rotational variations, we jointly learn optimal rotation angles while updating the synthetic dataset to better align with the original feature distribution. Extensive experiments on widely used benchmark datasets demonstrate that the proposed method consistently outperforms existing dataset distillation approaches, achieving higher accuracy and strong cross-architecture generalization.'}",https://openreview.net{'value': '/pdf/4a5cb091892654637b764d6a15b6c563e427e044.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=YktFxpaEmR,{'value': 'Selftok-Zero: Reinforcement Learning for Visual Generation via Discrete and Autoregressive Visual Tokens'},Bohan Wang; Mingze Zhou; Zhongqi Yue; Wang Lin; Kaihang Pan; Liyu Jia; Wentao Hu; Wei Zhao; Hanwang Zhang,~Bohan_Wang5; ~Mingze_Zhou1; ~Zhongqi_Yue1; ~Wang_Lin2; ~Kaihang_Pan1; ~Liyu_Jia1; ~Wentao_Hu5; ~Wei_Zhao13; ~Hanwang_Zhang3,"{'value': ['Tokenizer', 'MLLM', 'Reinforcement Learning']}","{'value': 'Reinforcement learning (RL) has become an indispensable post-training step for unlocking the full potential of Large Language Models (LLMs). Its core motivation is to incentivize the model’s inference trajectory via a reward model, effectively balancing the exploration–exploitation trade-off in scenarios where collecting exhaustive input–output ground-truth pairs is infeasible. This motivation naturally extends to visual generation, where perfect alignment between an image and a textual prompt is inherently ambiguous and often unattainable. However, existing visual generative models are not yet ready for RL due to the following two fundamental drawbacks that undermine the foundations of RL: 1) For diffusion-based models, the actual generation trajectories of sampled images cannot be reliably rewarded, as diffusion inversion is notoriously difficult. 2) For autoregressive (AR) models, we show that the widely used spatial visual tokens do not satisfy the Bellman equation and thus violate the policy improvement theorem of RL. To this end, we propose to use Selftok (Self-consistency Tokenizer), which represents each image as a sequential 1D stream of discrete, autoregressive tokens. Together with language, we train a pure AR vision-language model (VLM) for visual generation. Impressively, without using any text-image training pairs, a simple policy gradient algorithm applied to Selftok tokens significantly boosts visual generation performance, surpassing existing models by a large margin. Implementation details are provided in the Appendix.'}",https://openreview.net{'value': '/pdf/75e9ddf2fa015039429cc0508904811592630c03.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=YX5DHa9OfX,{'value': 'Imitation Beyond Expectation Using Pluralistic Stochastic Dominance'},Ali Farajzadeh; Danyal Saeed; Syed M Abbas; Rushit N. Shah; Aadirupa Saha; Brian D Ziebart,~Ali_Farajzadeh1; ~Danyal_Saeed1; ~Syed_M_Abbas1; ~Rushit_N._Shah1; ~Aadirupa_Saha1; ~Brian_D_Ziebart1,{'value': ['imitation learning']},"{'value': ""Imitation learning seeks policies reflecting the values of demonstrated behaviors. Prevalent approaches learn to match or exceed the demonstrator's performance in expectation without knowing the demonstrator’s reward function. Unfortunately, this does not induce pluralistic imitators that learn to support qualitatively distinct demonstrations. We reformulate imitation learning using stochastic dominance over the demonstrations' reward distribution across a range of reward functions as our foundational aim. Our approach matches imitator policy samples (or support) with demonstrations using optimal transport theory to define an imitation learning objective over trajectory pairs. We demonstrate the benefits of pluralistic stochastic dominance (PSD) for imitation in both theory and practice.""}",https://openreview.net{'value': '/pdf/bd5857ac56eed9be2cc497a059283b245fcf4de0.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=YWE9na9Jai,{'value': 'SNEAKDOOR: Stealthy Backdoor Attacks against Distribution Matching-based Dataset Condensation'},He Yang; Dongyi Lv; Song Ma; Wei Xi; Jizhong Zhao,~He_Yang1; ~Dongyi_Lv1; ~Song_Ma1; ~Wei_Xi1; ~Jizhong_Zhao3,"{'value': ['Dataset Distillation', 'Backdoor Attacks']}","{'value': 'Dataset condensation aims to synthesize compact yet informative datasets that retain the training efficacy of full-scale data, offering substantial gains in efficiency. Recent studies reveal that the condensation process can be vulnerable to backdoor attacks, where malicious triggers are injected into the condensation dataset, manipulating model behavior during inference. While prior approaches have made progress in balancing attack success rate and clean test accuracy, they often fall short in preserving stealthiness, especially in concealing the visual artifacts of condensed data or the perturbations introduced during inference. To address this challenge, we introduce \\textsc{Sneakdoor}, which enhances stealthiness without compromising attack effectiveness. \\textsc{Sneakdoor} exploits the inherent vulnerability of class decision boundaries and incorporates a generative module that constructs input-aware triggers aligned with local feature geometry, thereby minimizing detectability. This joint design enables the attack to remain imperceptible to both human inspection and statistical detection. Extensive experiments across multiple datasets demonstrate that \\textsc{Sneakdoor} achieves a compelling balance among attack success rate, clean test accuracy, and stealthiness, substantially improving the invisibility of both the synthetic data and triggered samples while maintaining high attack efficacy. The code is available at \\url{https://github.com/XJTU-AI-Lab/SneakDoor}.'}",https://openreview.net{'value': '/pdf/696c61999e24b3ee8f66a702fd378acd31382636.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=YVZbaVikBp,{'value': 'Generalization Error Analysis for Selective State-Space Models Through the Lens of Attention'},Arya Honarpisheh; Mustafa Bozdag; Octavia Camps; Mario Sznaier,~Arya_Honarpisheh1; ~Mustafa_Bozdag1; ~Octavia_Camps1; ~Mario_Sznaier1,"{'value': ['Generalization Bounds', 'State-Space Models', 'Selective Scan', 'Stability', 'Transformers', 'Rademacher Complexity', 'Covering Numbers']}","{'value': 'State-space models (SSMs) have recently emerged as a compelling alternative to Transformers for sequence modeling tasks. This paper presents a theoretical generalization analysis of selective SSMs, the core architectural component behind the Mamba model. We derive a novel covering number-based generalization bound for selective SSMs, building upon recent theoretical advances in the analysis of Transformer models. Using this result, we analyze how the spectral abscissa of the continuous-time state matrix influences the model’s stability during training and its ability to generalize across sequence lengths. We empirically validate our findings on a synthetic majority task, the IMDb sentiment classification benchmark, and the ListOps task, demonstrating how our theoretical insights translate into practical model behavior.'}",https://openreview.net{'value': '/pdf/5c4b7076e7711c8642942198bf94cb670d9962ec.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=YLlpF71IZJ,{'value': 'Robust Distortion-Free Watermark for Autoregressive Audio Generation Models'},Yihan Wu; Georgios Milis; Ruibo Chen; Heng Huang,~Yihan_Wu1; ~Georgios_Milis1; ~Ruibo_Chen2; ~Heng_Huang1,{'value': ['Audio watermarking']},"{'value': ""The rapid advancement of next-token-prediction models has led to widespread adoption across modalities, enabling the creation of realistic synthetic media. In the audio domain, while autoregressive speech models have propelled conversational interactions forward, the potential for misuse, such as impersonation in phishing schemes or crafting misleading speech recordings, has also increased. Security measures such as watermarking have thus become essential to ensuring the authenticity of digital media. Traditional statistical watermarking methods used for autoregressive language models face challenges when applied to autoregressive audio models, due to the inevitable ``retokenization mismatch'' - the discrepancy between original and retokenized discrete audio token sequences. To address this, we introduce Aligned-IS, a novel, distortion-free watermark, specifically crafted for audio generation models. This technique utilizes a clustering approach that treats tokens within the same cluster equivalently, effectively countering the retokenization mismatch issue. Our comprehensive testing on prevalent audio generation platforms demonstrates that Aligned-IS not only preserves the quality of generated audio but also significantly improves the watermark detectability compared to the state-of-the-art distortion-free watermarking adaptations, establishing a new benchmark in secure audio technology applications.""}",https://openreview.net{'value': '/pdf/3914c1d5c6e47a67df45333bbf7829a1a27c3ca8.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=YJxGJP8feU,{'value': 'macOSWorld: A Multilingual Interactive Benchmark for GUI Agents'},Pei Yang; Hai Ci; Mike Zheng Shou,~Pei_Yang5; ~Hai_Ci1; ~Mike_Zheng_Shou1,"{'value': ['Benchmark', 'GUI agent', 'interactive', 'macOS', 'multilingual', 'safety']}","{'value': 'Graphical User Interface (GUI) agents show promising capabilities for automating computer-use tasks and facilitating accessibility, but existing interactive benchmarks are mostly English-only, covering web-use or Windows, Linux, and Android environments, but not macOS. macOS is a major OS with distinctive GUI patterns and exclusive applications. To bridge the gaps, we present macOSWorld, the first comprehensive benchmark for evaluating GUI agents on macOS. macOSWorld features 202 multilingual interactive tasks across 30 applications (28 macOS-exclusive), with task instructions and OS interfaces offered in 5 languages (English, Chinese, Arabic, Japanese, and Russian). As GUI agents are shown to be vulnerable to deception attacks, macOSWorld also includes a dedicated safety benchmarking subset. Our evaluation on six GUI agents reveals a dramatic gap: proprietary computer-use agents lead at above 30\\% success rate, while open-source lightweight research models lag at below 5\\%, highlighting the need for macOS domain adaptation. Multilingual benchmarks also expose common weaknesses, especially in Arabic, with a 28.8\\% average degradation compared to English. Results from safety benchmarking also highlight that deception attacks are more general and demand immediate attention. Project page: https://macos-world.github.io.'}",https://openreview.net{'value': '/pdf/459d1f14b2d8120bc56ab101c56303a40f69e1ef.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=YIGUv0BZCy,{'value': 'Mitigating the Privacy–Utility Trade-off in Decentralized Federated Learning via f-Differential Privacy'},Xiang Li; Chendi Wang; Buxin Su; Qi Long; Weijie J Su,~Xiang_Li15; ~Chendi_Wang2; ~Buxin_Su1; ~Qi_Long1; ~Weijie_J_Su1,"{'value': ['f-Differential Privacy', 'Decentralized FL', 'Privacy–Utility Trade-off', 'Random Walks', 'Correlated noises']}","{'value': 'Differentially private (DP) decentralized Federated Learning (FL) allows local users to collaborate without sharing their data with a central server. However, accurately quantifying the privacy budget of private FL algorithms is challenging due to the co-existence of complex algorithmic components such as decentralized communication and local updates. This paper addresses privacy accounting for two decentralized FL algorithms within the $f$-differential privacy ($f$-DP) framework. We develop two new $f$-DP–based accounting methods tailored to decentralized settings: Pairwise Network $f$-DP (PN-$f$-DP), which quantifies privacy leakage between user pairs under random-walk communication, and Secret-based $f$-Local DP (Sec-$f$-LDP), which supports structured noise injection via shared secrets. \nBy combining tools from $f$-DP theory and Markov chain concentration, our accounting framework captures privacy amplification arising from sparse communication, local iterations, and correlated noise. Experiments on synthetic and real datasets demonstrate that our methods yield consistently tighter $(\\epsilon, \\delta)$ bounds and improved utility compared to Rényi DP–based approaches, illustrating the benefits of $f$-DP in decentralized privacy accounting.'}",https://openreview.net{'value': '/pdf/7a538e55855bc6e3fff6befdb544d77a5d77c535.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=YGIbwfNWot,{'value': '3D-Agent: A Tri-Modal Multi-Agent Responsive Framework for Comprehensive 3D Object Annotation'},Jusheng Zhang; Yijia Fan; Zimo Wen; Jian Wang; Keze Wang,~Jusheng_Zhang3; ~Yijia_Fan1; ~Zimo_Wen1; ~Jian_Wang10; ~Keze_Wang1,{'value': ['3D object annotation ，Multi-agent systems，Cross-view consistency']},"{'value': 'Driven by the applications in autonomous driving, robotics, and augmented reality, 3D object annotation is a critical task compared to 2D annotation, such as spatial complexity, occlusion, and viewpoint inconsistency. The existing methods relying on single models often struggle with these issues. In this paper, we introduce Tri-MARF, a novel framework that integrates tri-modal inputs (i.e., 2D multi-view images, text descriptions, and 3D point clouds) with multi-agent collaboration to enhance the 3D annotation process. Our Tri-MARF consists of three specialized agents: a vision-language model agent that generates multi-view descriptions, an information aggregation agent that selects optimal descriptions, and a gating agent that aligns text descriptions with 3D geometries for more refined captioning. Extensive experiments on the Objaverse-LVIS, Objaverse-XL, and ABO datasets demonstrate the superiority of our Tri-MARF, which achieves a CLIPScore of 88.7 (compared to 78.6–82.4 for other SOTA methods), retrieval accuracy of 45.2/43.8 (ViLT R@5), and an impressive throughput of 12,000 objects per hour on a single NVIDIA A100 GPU.'}",https://openreview.net{'value': '/pdf/ea4b7426b0fbbc2d294919f12d89ede731f894ef.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=YDWRTYgR79,{'value': 'MAT-Agent: Adaptive Multi-Agent Training Optimization'},Jusheng Zhang; Kaitong Cai; Yijia Fan; Ningyuan Liu; Keze Wang,~Jusheng_Zhang3; ~Kaitong_Cai1; ~Yijia_Fan1; ~Ningyuan_Liu1; ~Keze_Wang1,"{'value': ['Multi-Agent，Multi-Label，Bandit', 'Training-Optimization']}","{'value': 'We propose a novel collaborative multi-agent optimization framework for adaptive training in multi-label image classification, fundamentally advancing beyond static decision rules and isolated automation. Our method deploys a set of distributed, task-specific agents, each responsible for dynamically orchestrating critical training components—including data augmentation, optimization methods, learning rate schedules, and loss functions—according to evolving visual-semantic relationships and training states. Each agent employs an advanced non-stationary multi-armed bandit algorithm, integrating both $\\epsilon$-greedy and upper confidence bound strategies, to judiciously balance exploration with exploitation throughout the training lifecycle. A hierarchical composite reward mechanism synergizes overall classification accuracy, rare class recognition, and training stability, fostering both independent optimization and implicit collaborative behavior among agents. The framework further leverages refined techniques such as dual-rate exponential moving average smoothing and structured mixed-precision training to enhance robustness and computational efficiency. Extensive experiments across benchmarks including Pascal VOC, COCO, Yeast, and Mediamill demonstrate that our approach achieves superior mean average precision and rare-class F1 scores compared to state-of-the-art methods, while also exhibiting rapid convergence and remarkable cross-domain generalization. Our results indicate that collaborative multi-agent adaptive optimization offers a scalable and principled solution for self-optimizing deep learning in complex multi-label scenarios.'}",https://openreview.net{'value': '/pdf/f812e65f877761cb57d994cd3c97d5b1b748442b.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=YAc0O13qMc,{'value': 'A Geometry-Aware Metric for Mode Collapse in Time Series Generative Models'},Yassine ABBAHADDOU; Amine M. Aboussalah,~Yassine_ABBAHADDOU1; ~Amine_M._Aboussalah1,"{'value': ['Time series', 'Generative models', 'Mode Collapse']}","{'value': 'Generative models such as Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and diffusion models often suffer from mode collapse, failing to reproduce the full diversity of their training data. While this problem has been extensively studied in image generation, it remains largely unaddressed for time series. We introduce a formal definition of mode collapse for time series and propose DMD-GEN, a geometry-aware metric that quantifies its severity. DMD-GEN leverages Dynamic Mode Decomposition (DMD) to extract coherent temporal structures and uses Optimal Transport between DMD eigenvectors to measure discrepancies in underlying dynamics. By representing the subspaces spanned by the DMD eigenvectors as point structures on a Grassmann manifold, and comparing them via Wasserstein distances computed from principal angles, DMD-GEN enables a principled geometric comparison between real and generated sequences. The metric is efficient, requiring no additional training, supports mini-batch evaluation, and is easily parallelizable. Beyond quantification, DMD-GEN offers interpretability by revealing which dynamical modes are distorted or missing in the generated data. Experiments on synthetic and real-world datasets using TimeGAN, TimeVAE, and DiffusionTS show that DMD-GEN aligns with existing metrics while providing the first principled framework for detecting and interpreting mode collapse in time series.'}",https://openreview.net{'value': '/pdf/3db66b31c25521e6e0e52787456dbe1efe73a799.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=Y1bt0YIS6Y,{'value': 'VeriThinker: Learning to Verify Makes Reasoning Model Efficient'},Zigeng Chen; Xinyin Ma; Gongfan Fang; Ruonan Yu; Xinchao Wang,~Zigeng_Chen1; ~Xinyin_Ma1; ~Gongfan_Fang2; ~Ruonan_Yu1; ~Xinchao_Wang1,"{'value': ['cot compression', 'efficient reasoning model']}","{'value': 'Large Reasoning Models (LRMs) have garnered considerable attention for their ability to tackle complex tasks through the Chain-of-Thought (CoT) approach. However, their tendency toward overthinking results in unnecessarily lengthy reasoning chains, dramatically increasing the inference costs. To mitigate this issue, we introduce VeriThinker, a novel approach for CoT compression. Unlike conventional methods that fine-tune LRMs directly on the original reasoning task using synthetic concise CoT data, we innovatively fine-tune the model solely through an auxiliary verification task. By training LRMs to accurately verify the correctness of CoT solutions, the LRMs inherently become more discerning about the necessity of subsequent self-reflection steps, thereby effectively suppressing overthinking. Extensive experiments validate that VeriThinker substantially reduces reasoning chain lengths while maintaining or even slightly improving accuracy. When applied to DeepSeek-R1-Distill-Qwen-7B, our approach reduces reasoning tokens on MATH500 from 3790 to 2125 while improving accuracy by 0.8% (94.0% to 94.8%), and on AIME25, tokens decrease from 14321 to 10287 with a 2.1% accuracy gain (38.7% to 40.8%). Additionally, our experiments demonstrate that VeriThinker can also be zero-shot generalized to speculative reasoning.'}",https://openreview.net{'value': '/pdf/21faeda3ee514a2282f383933827be95d5eab10c.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=XzXGqoUNUa,{'value': 'Oryx: a Scalable Sequence Model for Many-Agent Coordination in Offline MARL'},Juan Claude Formanek; Omayma Mahjoub; Louay Ben Nessir; Sasha Abramowitz; Ruan John de Kock; Wiem Khlifi; Daniel Rajaonarivonivelomanantsoa; Simon Verster Du Toit; Arnol Manuel Fokam; Siddarth Singh; Ulrich Armel Mbou Sob; Felix Chalumeau; Arnu Pretorius,~Juan_Claude_Formanek1; ~Omayma_Mahjoub1; ~Louay_Ben_Nessir3; ~Sasha_Abramowitz1; ~Ruan_John_de_Kock1; ~Wiem_Khlifi1; ~Daniel_Rajaonarivonivelomanantsoa1; ~Simon_Verster_Du_Toit1; ~Arnol_Manuel_Fokam1; ~Siddarth_Singh2; ~Ulrich_Armel_Mbou_Sob1; ~Felix_Chalumeau1; ~Arnu_Pretorius1,"{'value': ['reinforcement learning', 'offline reinforcement learning', 'multi-agent reinforcement learning', 'offline multi-agent reinforcement learning']}","{'value': ""A key challenge in offline multi-agent reinforcement learning (MARL) is achieving effective many-agent multi-step coordination in complex environments. In this work, we propose Oryx, a novel algorithm for offline cooperative MARL to directly address this challenge. Oryx adapts the recently proposed retention-based architecture Sable and combines it with a sequential form of implicit constraint Q-learning (ICQ), to develop a novel offline autoregressive policy update scheme. This allows Oryx to solve complex coordination challenges while maintaining temporal coherence over long trajectories. We evaluate Oryx across a diverse set of benchmarks from prior works—SMAC, RWARE, and Multi-Agent MuJoCo—covering tasks of both discrete and continuous control, varying in scale and difficulty. Oryx achieves state-of-the-art performance on more than 80% of the 65 tested datasets, outperforming prior offline MARL methods and demonstrating robust generalisation across domains with many agents and long horizons. Finally, we introduce new datasets to push the limits of many-agent coordination in offline MARL, and demonstrate Oryx's superior ability to scale effectively in such settings.""}",https://openreview.net{'value': '/pdf/760cfff7afea430a6744bb86e4d0525881a6f6fa.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=XwMDUND6iO,{'value': 'MACS: Multi-Agent Reinforcement Learning for Optimization of Crystal Structures'},Elena Zamaraeva; Christopher Collins; George R Darling; Matthew Stephen Dyer; Bei Peng; Rahul Savani; Dmytro Antypov; Vladimir Gusev; Judith Clymo; Paul G. Spirakis; Matthew Rosseinsky,~Elena_Zamaraeva1; ~Christopher_Collins3; ~George_R_Darling1; ~Matthew_Stephen_Dyer1; ~Bei_Peng2; ~Rahul_Savani1; ~Dmytro_Antypov1; ~Vladimir_Gusev1; ~Judith_Clymo1; ~Paul_G._Spirakis1; ~Matthew_Rosseinsky1,"{'value': ['multi-agent reinforcement learning', 'learning to optimize', 'geometry optimization', 'local optimization', 'atomic structure optimization', 'crystal structure']}","{'value': 'Geometry optimization of atomic structures is a common and crucial task in computational chemistry and materials design. Following the learning to optimize paradigm, we propose a new multi-agent reinforcement learning method called Multi-Agent Crystal Structure optimization (MACS) to address the problem of periodic crystal structure optimization. MACS treats geometry optimization as a partially observable Markov game in which atoms are agents that adjust their positions to collectively discover a stable configuration. We train MACS across various compositions of reported crystalline materials to obtain a policy that successfully optimizes structures from the training compositions as well as structures of larger sizes and unseen compositions, confirming its excellent scalability and zero-shot transferability. We benchmark our approach against a broad range of state-of-the-art optimization methods and demonstrate that MACS optimizes periodic crystal structures significantly faster, with fewer energy calculations, and the lowest failure rate.'}",https://openreview.net{'value': '/pdf/211e025089643c744c06921ade5974c4520d0b46.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=Xuvdo6oMkE,{'value': 'Rethinking the Role of Verbatim Memorization in LLM Privacy'},Tom Sander; Bargav Jayaraman; Mark Ibrahim; Kamalika Chaudhuri; Chuan Guo,~Tom_Sander1; ~Bargav_Jayaraman1; ~Mark_Ibrahim1; ~Kamalika_Chaudhuri1; ~Chuan_Guo1,{'value': ['LLM;memorization;privacy']},"{'value': 'Conventional wisdom in machine learning privacy research states that memorization \ndirectly implies a loss of privacy. In contrast, a well-generalized model only remembers distributional patterns and preserves privacy of its training data.  In this work, we show that this relationship is much more complex for LLMs trained for chat,\nand depends heavily on how knowledge is encoded and manipulated. To this end, we fine-tune language models on synthetically generated biographical information including PIIs, and try to extract them in different ways after instruction fine-tuning.  We find counter to conventional wisdom that better verbatim memorization does not necessarily increase data leakage via chat. We also find that it is easier to extract information via chat from an LLM that is better able to manipulate and process knowledge even if it is smaller, and that not all attributes are equally extractable. This suggests that the relationship between privacy, memorization and language understanding of LLMs is very intricate, and that examining memorization in isolation can lead to misleading conclusions.'}",https://openreview.net{'value': '/pdf/bedba0c6d4b699e2489c89ed123f6287565aed0f.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=XtNiw8OQsy,{'value': 'SynLogic: Synthesizing Verifiable Reasoning Data at Scale for Learning Logical Reasoning and Beyond'},Junteng Liu; Yuanxiang Fan; Jiang Zhuo; Han Ding; Yongyi Hu; Chi Zhang; Yiqi Shi; Shitong Weng; Aili Chen; Shiqi Chen; Mozhi Zhang; Pengyu Zhao; Junxian He,~Junteng_Liu2; ~Yuanxiang_Fan1; ~Jiang_Zhuo2; ~Han_Ding4; ~Yongyi_Hu4; ~Chi_Zhang33; ~Yiqi_Shi3; ~Shitong_Weng2; ~Aili_Chen1; ~Shiqi_Chen3; ~Mozhi_Zhang1; ~Pengyu_Zhao2; ~Junxian_He1,"{'value': ['LLM', 'reinforcement learning', 'reasoning', 'logical reasoning', 'data synthesis']}","{'value': 'Recent advances such as OpenAI-o1 and DeepSeek R1 have demonstrated the potential of Reinforcement Learning (RL) to enhance reasoning abilities in Large Language Models (LLMs). While open-source replication efforts have primarily focused on mathematical and coding domains, methods and resources for developing general reasoning capabilities remain underexplored. This gap is partly due to the challenge of collecting diverse and verifiable reasoning data suitable for RL.\nWe hypothesize that logical reasoning is critical for developing general reasoning capabilities, as logic forms a fundamental building block of reasoning. In this work, we present SynLogic, a data synthesis framework and dataset that generates diverse logical reasoning data at scale, encompassing 35 diverse logical reasoning tasks. The SynLogic approach enables controlled synthesis of data with adjustable difficulty and quantity. Importantly, all examples can be verified by simple rules, making them ideally suited for RL with verifiable rewards.\nIn our experiments, we validate the effectiveness of RL training on the SynLogic dataset based on 7B and 32B models. SynLogic leads to state-of-the-art logical reasoning performance among open-source datasets, surpassing DeepSeek-R1-Distill-Qwen-32B by 6 points on BBEH. Furthermore, mixing SynLogic data with mathematical and coding tasks improves the training efficiency of these domains and significantly enhances reasoning generalization. Notably, our mixed training model outperforms DeepSeek-R1-Zero-Qwen-32B across multiple benchmarks.\nThese findings position SynLogic as a valuable resource for advancing the broader reasoning capabilities of LLMs. We will open-source both the data synthesis pipeline and the SynLogic dataset.'}",https://openreview.net{'value': '/pdf/b5b93e7b533135e2ad1d72d22e3a481324c2a73d.pdf'},{'abstract_filter': 'Data Synthesis'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=XsNi2STaj0,{'value': 'Overcoming Long Context Limitations of State Space Models via Context Dependent Sparse Attention'},Zhihao Zhan; Jianan Zhao; Zhaocheng Zhu; Jian Tang,~Zhihao_Zhan1; ~Jianan_Zhao2; ~Zhaocheng_Zhu1; ~Jian_Tang1,"{'value': ['long-context modeling', 'state-space models', 'sparse attention', 'novel architectures design']}","{'value': 'Efficient long-context modeling remains a critical challenge for natural language processing (NLP), as the time complexity of the predominant Transformer architecture scales quadratically with the sequence length. While state-space models (SSMs) offer alternative sub-quadratic solutions, they struggle to capture long-range dependencies effectively. In this work, we focus on analyzing and improving the long-context modeling capabilities of SSMs. We show that the widely used synthetic task, associative recall, which requires a model to recall a value associated with a single key without context, insufficiently represents the complexities of real-world long-context modeling. To address this limitation, we extend the associative recall to a novel synthetic task, joint recall, which requires a model to recall the value associated with a key given in a specified context. Theoretically, we prove that SSMs do not have the expressiveness to solve multi-query joint recall in sub-quadratic time complexity. To resolve this issue, we propose a solution based on integrating SSMs with Context-Dependent Sparse Attention (CDSA), which has the expressiveness to solve multi-query joint recall with sub-quadratic computation. To bridge the gap between theoretical analysis and real-world applications, we propose locality-sensitive Hashing Attention with sparse Key Selection (HAX), which instantiates the theoretical solution and is further tailored to natural language domains. Extensive experiments on both synthetic and real-world long-context benchmarks show that HAX consistently outperforms SSM baselines and SSMs integrated with context-independent sparse attention (CISA). Our code is available at: https://github.com/DeepGraphLearning/HAX.'}",https://openreview.net{'value': '/pdf/513de78913093bd84e5f5969eab361e2ce29d0fe.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=Xr73jEYG29,{'value': 'LLM-PySC2: Starcraft II learning environment for Large Language Models'},Zongyuan Li; Yanan Ni; Runnan Qi; Chang Lu; Lumin Jiang; Xu Xiaojie; Xiangbei Liu; Pengfei Li; Yunzheng Guo; Zhe Ma; Huanyu Li; wu hui; Guo Xian; Kuihua Huang; Xuebo Zhang,~Zongyuan_Li1; ~Yanan_Ni1; ~Runnan_Qi1; ~Chang_Lu3; ~Lumin_Jiang1; ~Xu_Xiaojie1; ~Xiangbei_Liu1; ~Pengfei_Li14; ~Yunzheng_Guo1; ~Zhe_Ma5; ~Huanyu_Li3; ~wu_hui1; ~Guo_Xian1; ~Kuihua_Huang1; ~Xuebo_Zhang1,"{'value': ['Large Language Model', 'Decision-Making', 'Multi-Agent', 'StarCraft II Environment']}","{'value': ""The tremendous potential has been demonstrated by large language models (LLMs) in intelligent decision-making problems, with unprecedented capabilities shown across diverse applications ranging from gaming AI systems to complex strategic planning frameworks. However, the StarCraft II platform, which has been widely adopted for validating decision-making algorithms in the past decade, has not yet provided substantial support for this emerging domain. To address issues that LLMs cannot interface with the hundreds of actions of the pysc2 backend and the lack of native support for multi-agent (MA) collaboration, we propose the LLM-PySC2 environment. This is the first environment that offers LLMs the complete pysc2 action space with sufficient multi-modal information and game Wiki knowledge. With an asynchronous query architecture, the environment efficiently interacts with LLMs that maintain a constant latency regardless of the scale of the agents' population. In the experiments, we evaluated LLMs' decision-making performance in both the macro-decision and micro-operation scenarios, with traditional StarCraft II Multi-Agent Challenge (SMAC) tasks and a series of new proposed. Results indicate that LLMs possess the potential to achieve victories in complex scenarios but cannot constantly generate correct decisions, especially in the recovered pysc2 action space and MA settings. Without task-relevant instructions, the pre-trained models suffer from issues such as hallucinations and inefficient collaboration. \nOur findings suggest that StarCraft II still challenges in the era of large models, revealing that there is a lot to do to develop an advanced LLM decision-making system, and the proposed LLM-PySC2 environment will support future development of LLM-based decision-making solutions.""}",https://openreview.net{'value': '/pdf/ae23b5a1cbb9529359c184cdf3d394c6383add5a.pdf'},{'abstract_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=Xpi6YxNSiI,{'value': 'Beyond Modality Collapse: Representation Blending for Multimodal Dataset Distillation'},Xin Zhang; Ziruo Zhang; Jiawei Du; Zuozhu Liu; Joey Tianyi Zhou,~Xin_Zhang29; ~Ziruo_Zhang1; ~Jiawei_Du1; ~Zuozhu_Liu1; ~Joey_Tianyi_Zhou1,"{'value': ['multimodal dataset distillation', 'modality collapse', 'representations blending', 'symmetric projection trajectory matching']}","{'value': 'Multimodal Dataset Distillation (MDD) seeks to condense large-scale image-text datasets into compact surrogates while retaining their effectiveness for cross-modal learning. Despite recent progress, existing MDD approaches often suffer from ***Modality Collapse***, characterized by over-concentrated intra-modal representations and enlarged distributional gap across modalities. In this paper, at the first time, we identify this issue as stemming from a fundamental conflict between the over-compression behavior inherent in dataset distillation and the cross-modal supervision imposed by contrastive objectives. To alleviate modality collapse, we introduce **RepBlend**, a novel MDD framework that weakens overdominant cross-modal supervision via representation blending, thereby significantly enhancing intra-modal diversity. Additionally, we observe that current MDD methods impose asymmetric supervision across modalities, resulting in biased optimization. To address this, we propose symmetric projection trajectory matching, which synchronizes the optimization dynamics using modality-specific projection heads, thereby promoting balanced supervision and enhancing cross-modal alignment.\nExperiments on Flickr-30K and MS-COCO show that RepBlend consistently outperforms prior state-of-the-art MDD methods, achieving significant gains in retrieval performance (e.g., +9.4 IR@10, +6.3 TR@10 under the 100-pair setting) and offering up to 6.7$\\times$ distillation speedup.'}",https://openreview.net{'value': '/pdf/de1699487965b2fbfecaebd55a1b69d1580a88ea.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=Xm57IXqU0n,{'value': 'Contextual Integrity in LLMs via Reasoning and Reinforcement Learning'},Guangchen Lan; Huseyin A Inan; Sahar Abdelnabi; Janardhan Kulkarni; Lukas Wutschitz; Reza Shokri; Christopher Brinton; Robert Sim,~Guangchen_Lan1; ~Huseyin_A_Inan1; ~Sahar_Abdelnabi1; ~Janardhan_Kulkarni2; ~Lukas_Wutschitz1; ~Reza_Shokri1; ~Christopher_Brinton1; ~Robert_Sim1,"{'value': ['Reinforcement Learning', 'LLM Reasoning', 'Contextual Integrity']}","{'value': 'As the era of autonomous agents making decisions on behalf of users unfolds, ensuring contextual integrity (CI) -- what is the appropriate information to share while carrying out a certain task -- becomes a central question to the field. \nWe posit that CI demands a form of reasoning where the agent needs to reason about the context in which it is operating.\nTo test this, we first prompt LLMs to reason explicitly about CI when deciding what information to disclose. \nWe then extend this approach by developing a reinforcement learning (RL) framework that further instills in models the reasoning necessary to achieve CI.\nUsing a synthetic, automatically created, dataset of only $\\sim700$ examples but with diverse contexts and information disclosure norms, we show that our method substantially reduces inappropriate information disclosure while maintaining task performance across multiple model sizes and families. \nImportantly, improvements transfer from this synthetic dataset to established CI benchmarks such as PrivacyLens that has human annotations and evaluates privacy leakage of AI assistants in actions and tool calls.'}",https://openreview.net{'value': '/pdf/b39de1061902f7e2d23191a93a6d94f945bff28e.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=Xll01vw606,{'value': 'Ambient Proteins - Training Diffusion Models on Noisy Structures'},Giannis Daras; Jeffrey Ouyang-Zhang; Krithika Ravishankar; Constantinos Costis Daskalakis; Adam Klivans; Daniel Jesus Diaz,~Giannis_Daras1; ~Jeffrey_Ouyang-Zhang1; ~Krithika_Ravishankar1; ~Constantinos_Costis_Daskalakis1; ~Adam_Klivans1; ~Daniel_Jesus_Diaz1,"{'value': ['ambient', 'diffusion', 'protein', 'de novo protein design']}","{'value': 'We present Ambient Protein Diffusion, a framework for training protein diffusion models that generates structures with unprecedented diversity and quality. State-of-the-art generative models are trained on computationally derived structures from AlphaFold2 (AF), as experimentally determined structures are relatively scarce. The resulting models are therefore limited by the quality of synthetic datasets.  Since the accuracy of AF predictions degrades with increasing protein length and complexity, de novo generation of long, complex proteins remains challenging. Ambient Protein Diffusion overcomes this problem by treating low-confidence AF structures as corrupted data.  Rather than simply filtering out low-quality AF structures, our method adjusts the diffusion objective for each structure based on its corruption level, allowing the model to learn from both high and low quality structures. Empirically, ambient protein diffusion yields major improvements: on proteins with 700 residues, diversity increases from 45% to 85% from the previous state-of-the-art, and designability improves from 70% to 88%.'}",https://openreview.net{'value': '/pdf/22b564f0323f02f1220e3bfac5d7226e465bad2c.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=XkgkMFn4Ja,{'value': 'Track3R: Joint Point Map and Trajectory Prior for Spatiotemporal 3D Understanding'},Seong Hyeon Park; Jinwoo Shin,~Seong_Hyeon_Park2; ~Jinwoo_Shin1,{'value': ['computer vision']},"{'value': 'Understanding the 3D world from 2D monocular videos is a crucial ability for AI.\nRecently, to tackle this underdetermined task, end-to-end 3D geometry priors have been sought after, such as pre-trained point map models at scale.\nThese models enable robust 3D understanding from casually taken videos, providing accurate object shapes disentangled from uncertain camera parameters.\nHowever, they still struggle when affected by object deformation and dynamics, failing to establish consistent correspondence over the frames.\nFurthermore, their architectures are typically limited to pairwise frame processing, which is insufficient for capturing complex motion dynamics over extended sequences.\nTo address these limitations, we introduce Track3R, a novel framework that integrates a new architecture and task to jointly predict point map and motion trajectories across multiple frames from video input.\nSpecifically, our key idea is modeling two disentangled trajectories for each point: one representing object motion and the other camera poses.\nThis design not only can enable understanding of the 3D object dynamics, but also facilitates the learning of more robust priors for 3D shapes in dynamic scenes.\nIn our experiments, Track3R demonstrates significant improvements in a joint point mapping and 3D motion estimation task for dynamic scenes, such as 25.8% improvements in the motion estimation, and 15.7% in the point mapping accuracy.'}",https://openreview.net{'value': '/pdf/4fae0aa52db243eced9ba4db21dce1fc3fcb9a89.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=Xic1sPAmfC,{'value': 'Neural MJD: Neural Non-Stationary Merton Jump Diffusion for Time Series Prediction'},Yuanpei Gao; Qi Yan; Yan Leng; Renjie Liao,~Yuanpei_Gao2; ~Qi_Yan2; ~Yan_Leng1; ~Renjie_Liao1,"{'value': ['time series', 'sequantial models', 'neural merton jump diffusion']}","{'value': 'While deep learning methods have achieved strong performance in time series prediction, their black-box nature and inability to explicitly model underlying stochastic processes often limit their robustness handling non-stationary data, especially in the presence of abrupt changes. In this work, we introduce Neural MJD, a neural network based non-stationary Merton jump diffusion (MJD) model. Our model explicitly formulates forecasting as a stochastic differential equation (SDE) simulation problem, combining a time-inhomogeneous Itô diffusion to capture non-stationary stochastic dynamics with a time-inhomogeneous compound Poisson process to model abrupt jumps. To enable tractable learning, we introduce a likelihood truncation mechanism that caps the number of jumps within small time intervals and provide a theoretical error bound for this approximation. Additionally, we propose an Euler-Maruyama with restart solver, which achieves a provably lower error bound in estimating expected states and reduced variance compared to the standard solver. Experiments on both synthetic and real-world datasets demonstrate that Neural MJD consistently outperforms state-of-the-art deep learning and statistical learning methods. Our code is available at https://github.com/DSL-Lab/neural-MJD.'}",https://openreview.net{'value': '/pdf/ccede0e6ce6a41f531a8b0a103e94edcc58f819f.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=XVm8KOO3Ri,{'value': 'GUI Exploration Lab: Enhancing Screen Navigation in Agents via Multi-Turn Reinforcement Learning'},Haolong Yan; Yeqing Shen; Xin Huang; Jia Wang; Kaijun Tan; Zhixuan Liang; Hongxin Li; Zheng Ge; Osamu Yoshie; Si Li; Xiangyu Zhang; Daxin Jiang,~Haolong_Yan1; ~Yeqing_Shen2; ~Xin_Huang2; ~Jia_Wang15; ~Kaijun_Tan1; ~Zhixuan_Liang4; ~Hongxin_Li1; ~Zheng_Ge1; ~Osamu_Yoshie1; ~Si_Li5; ~Xiangyu_Zhang1; ~Daxin_Jiang2,"{'value': ['GUI Environment', 'Large Vision Language Model', 'Multi-Turn Reinforcement Learning', 'Agent']}","{'value': 'With the rapid development of Large Vision Language Models, the focus of Graphical User Interface (GUI) agent tasks shifts from single-screen tasks to complex screen navigation challenges. \nHowever, real-world GUI environments, such as PC software and mobile Apps, are often complex and proprietary, making it difficult to obtain the comprehensive environment information needed for agent training and evaluation. This limitation hinders systematic investigation and benchmarking of agent navigation capabilities.\nTo address this limitation, we introduce GUI Exploration Lab, a simulation environment engine for GUI agent navigation research that enables flexible definition and composition of screens, icons, and navigation graphs, while providing full access to environment information for comprehensive agent training and evaluation.\nThrough extensive experiments, we find that supervised fine-tuning enables effective memorization of fundamental knowledge, serving as a crucial foundation for subsequent training. Building on this, single-turn reinforcement learning further enhances generalization to unseen scenarios. Finally, multi-turn reinforcement learning encourages the development of exploration strategies through interactive trial and error, leading to further improvements in screen navigation performance.\nWe validate our methods on both static and interactive benchmarks, demonstrating that our findings generalize effectively to real-world scenarios.\nThese findings demonstrate the advantages of reinforcement learning approaches in GUI navigation and offer practical guidance for building more capable and generalizable GUI agents.'}",https://openreview.net{'value': '/pdf/ce35fb684e3b11b9c0f1fcc38598cfb3504c728e.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=XQrGTggLvT,{'value': 'LLM Strategic Reasoning: Agentic Study through Behavioral Game Theory'},Jingru Jia; Zehua Yuan; Junhao Pan; Paul E McNamara; Deming Chen,~Jingru_Jia1; ~Zehua_Yuan1; ~Junhao_Pan1; ~Paul_E_McNamara1; ~Deming_Chen1,"{'value': ['Large Language Model', 'Reasoning', 'Fairness', 'Interpretability', 'Multi-agent']}","{'value': 'What does it truly mean for a language model to “reason” strategically, and can scaling up alone guarantee intelligent, context-aware decisions? Strategic decision-making requires adaptive reasoning, where agents anticipate and respond to others’ actions under uncertainty. Yet, most evaluations of large language models (LLMs) for strategic decision-making often rely heavily on Nash Equilibrium (NE) benchmarks, overlook reasoning depth, and fail to reveal the mechanisms behind model behavior. To address this gap, we introduce a behavioral game-theoretic evaluation framework that disentangles intrinsic reasoning from contextual influence. Using this framework, we evaluate 22 state-of-the-art LLMs across diverse strategic scenarios. We find models like GPT-o3-mini, GPT-o1, and DeepSeek-R1 lead in reasoning depth. Through thinking chain analysis, we identify distinct reasoning styles—such as maximin or belief-based strategies—and show that longer reasoning chains do not consistently yield better decisions. Furthermore, embedding demographic personas reveals context-sensitive shifts: some models (e.g., GPT-4o, Claude-3-Opus) improve when assigned female identities, while others (e.g., Gemini 2.0) show diminished reasoning under minority sexuality personas. These findings underscore that technical sophistication alone is insufficient; alignment with ethical standards, human expectations, and situational nuance is essential for the responsible deployment of LLMs in interactive settings.'}",https://openreview.net{'value': '/pdf/b883ed6db89693acec5672378f105530d3b69bd2.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=XQ87Vo9GIz,{'value': 'TransferTraj: A Vehicle Trajectory Learning Model for Region and Task Transferability'},Tonglong Wei; Yan Lin; Zeyu Zhou; Haomin Wen; Jilin Hu; Shengnan Guo; Youfang Lin; Gao Cong; Huaiyu Wan,~Tonglong_Wei1; ~Yan_Lin1; ~Zeyu_Zhou3; ~Haomin_Wen2; ~Jilin_Hu1; ~Shengnan_Guo1; ~Youfang_Lin1; ~Gao_Cong1; ~Huaiyu_Wan1,"{'value': ['Spatio-temporal data mining', 'trajectory data mining', 'vehicle trajectory learning']}","{'value': 'Vehicle GPS trajectories provide valuable movement information that supports various downstream tasks and applications. A desirable trajectory learning model should be able to transfer across regions and tasks without retraining, avoiding the need to maintain multiple specialized models and subpar performance with limited training data. However, each region has its unique spatial features and contexts, which are reflected in vehicle movement patterns and are difficult to generalize. Additionally, transferring across different tasks faces technical challenges due to the varying input-output structures required for each task. Existing efforts towards transferability primarily involve learning embedding vectors for trajectories, which perform poorly in region transfer and require retraining of prediction modules for task transfer.\n\nTo address these challenges, we propose $\\textit{TransferTraj}$, a vehicle GPS trajectory learning model that excels in both region and task transferability. For region transferability, we introduce RTTE as the main learnable module within TransferTraj. It integrates spatial, temporal, POI, and road network modalities of trajectories to effectively manage variations in spatial context distribution across regions. It also introduces a TRIE module for incorporating relative information of spatial features and a spatial context MoE module for handling movement patterns in diverse contexts. For task transferability, we propose a task-transferable input-output scheme that unifies the input-output structure of different tasks into the masking and recovery of modalities and trajectory points. This approach allows TransferTraj to be pre-trained once and transferred to different tasks without retraining. We conduct extensive experiments on three real-world vehicle trajectory datasets under various transfer settings, including task transfer, zero-shot region transfer, and few-shot region transfer. Experimental results demonstrate that TransferTraj significantly outperforms state-of-the-art baselines in different scenarios, validating its effectiveness in region and task transfer. Code is available at https://github.com/wtl52656/TransferTraj.'}",https://openreview.net{'value': '/pdf/aba567925beae9b368b62a73954ca94cc1626abe.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=XPLf9H27aO,{'value': 'JarvisArt: Liberating Human Artistic Creativity via an Intelligent Photo Retouching Agent'},Yunlong Lin; ZiXu Lin; Kunjie Lin; Jinbin Bai; Panwang Pan; Chenxin Li; Haoyu Chen; Zhongdao Wang; Xinghao Ding; Wenbo Li; Shuicheng YAN,~Yunlong_Lin1; ~ZiXu_Lin1; ~Kunjie_Lin1; ~Jinbin_Bai1; ~Panwang_Pan1; ~Chenxin_Li1; ~Haoyu_Chen2; ~Zhongdao_Wang2; ~Xinghao_Ding1; ~Wenbo_Li6; ~Shuicheng_YAN3,{'value': ['AI agent; Photo retouching; Vision-foundation model']},"{'value': 'Photo retouching has become integral to contemporary visual storytelling, enabling users to capture aesthetics and express creativity. While professional tools such as Adobe Lightroom offer powerful capabilities, they demand substantial expertise and manual effort. In contrast, existing AI-based solutions provide automation but often suffer from limited adjustability and poor generalization, failing to meet diverse and personalized editing needs. To bridge this gap, we introduce JarvisArt, a multi-modal large language model (MLLM)-driven agent that understands user intent, mimics the reasoning process of professional artists, and intelligently coordinates over 200 retouching tools within Lightroom. JarvisArt undergoes a two-stage training process: an initial Chain-of-Thought supervised fine-tuning to establish basic reasoning and tool-use skills, followed by Group Relative Policy Optimization for Retouching (GRPO-R) to further enhance its decision-making and tool proficiency. We also propose the Agent-to-Lightroom Protocol to facilitate seamless integration with Lightroom. To evaluate performance, we develop MMArt-Bench, a novel benchmark constructed from real-world user edits. JarvisArt demonstrates user-friendly interaction, superior generalization, and fine-grained control over both global and local adjustments, paving a new avenue for intelligent photo retouching. Notably, it outperforms GPT-4o with a 60\\% improvement in average pixel-level metrics on MMArt-Bench for content fidelity, while maintaining comparable instruction-following capabilities.'}",https://openreview.net{'value': '/pdf/24cb8b7affa9be90e1900da83592fd3256640ece.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=XP3v1THxsq,{'value': 'Among Us: A Sandbox for Measuring and Detecting Agentic Deception'},Satvik Golechha; Adrià Garriga-Alonso,~Satvik_Golechha1; ~Adrià_Garriga-Alonso1,"{'value': ['Deception', 'Social Games', 'AI Safety', 'Linear Probes', 'SAEs']}","{'value': ""Prior studies on deception in language-based AI agents typically assess whether the agent produces a false statement about a topic, or makes a binary choice prompted by a goal, rather than allowing open-ended deceptive behavior to emerge in pursuit of a longer-term goal.\nTo fix this, we introduce $\\textit{Among Us}$, a sandbox social deception game where LLM-agents exhibit long-term, open-ended deception as a consequence of the game objectives. While most benchmarks saturate quickly, $\\textit{Among Us}$ can be expected to last much longer, because it is a multi-player game far from equilibrium.\nUsing the sandbox, we evaluate $18$ proprietary and open-weight LLMs and uncover a general trend:\nmodels trained with RL are comparatively much better at producing deception than detecting it.\nWe evaluate the effectiveness of methods to detect lying and deception: logistic regression on the activations and sparse autoencoders (SAEs). We find that probes trained on a dataset of ``pretend you're a dishonest model: $\\dots$'' generalize extremely well out-of-distribution, consistently obtaining AUROCs over 95% even when evaluated just on the deceptive statement, without the chain of thought. We also find two SAE features that work well at deception detection but are unable to steer the model to lie less.\nWe hope our open-sourced sandbox, game logs, and probes serve to anticipate and mitigate deceptive behavior and capabilities in language-based agents.""}",https://openreview.net{'value': '/pdf/0ff014da0c71915ceb0a84e3977c85eaf1e134dd.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=XOIKLlSiDq,{'value': 'Can DPO Learn Diverse Human Values? A Theoretical Scaling Law'},Shawn Im; Sharon Li,~Shawn_Im1; ~Sharon_Li1,"{'value': ['LLM', 'preference learning', 'generalization']}","{'value': 'Large language models (LLMs) have demonstrated remarkable capabilities but often struggle to align with human preferences, leading to harmful or undesirable outputs. Preference learning, which trains models to distinguish between preferred and non-preferred responses based on human feedback, has become a crucial component for ensuring that LLMs align with human values. An essential part of ensuring that LLMs are aligned for all people is accounting for a diverse set of values. This paper introduces a new theoretical framework to analyze how generalization scales with value diversity and sample quantity in models trained with direct preference optimization. Our framework rigorously assesses how well models generalize after a finite number of gradient steps, reflecting real-world LLM training practices. By analyzing the reward margin associated with each sample and its trajectory throughout training, we provide a bound on the generalization error that demonstrates the challenges of effectively learning a wide set of concepts or values. These insights are empirically validated on contemporary LLMs, underscoring the practical relevance of our theory.'}",https://openreview.net{'value': '/pdf/423a825732e0caf6fadb0f5b8b5e297d3d95696f.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=XKVhXWkPbp,"{'value': ""CPathAgent: An Agent-based Foundation Model for Interpretable High-Resolution Pathology Image Analysis Mimicking Pathologists' Diagnostic Logic""}",Yuxuan Sun; Yixuan Si; Chenglu Zhu; Kai Zhang; Zhongyi Shui; Bowen Ding; Tao Lin; Lin Yang,~Yuxuan_Sun3; ~Yixuan_Si1; ~Chenglu_Zhu1; ~Kai_Zhang10; ~Zhongyi_Shui1; ~Bowen_Ding1; ~Tao_Lin1; ~Lin_Yang13,"{'value': ['Agent', 'Computational pathology', 'Large multimodal model']}","{'value': ""Recent advances in computational pathology have led to the emergence of numerous foundation models. These models typically rely on general-purpose encoders with multi-instance learning for whole slide image (WSI) classification or apply multimodal approaches to generate reports directly from images. However, these models cannot emulate the diagnostic approach of pathologists, who systematically examine slides at low magnification to obtain an overview before progressively zooming in on suspicious regions to formulate comprehensive diagnoses. Instead, existing models directly output final diagnoses without revealing the underlying reasoning process.\nTo address this gap, we introduce CPathAgent, an innovative agent-based approach that mimics pathologists' diagnostic workflow by autonomously navigating across WSI through zoom-in/out and move operations based on observed visual features, thereby generating substantially more transparent and interpretable diagnostic summaries. To achieve this, we develop a multi-stage training strategy that unifies patch-level, region-level, and WSI-level capabilities within a single model, which is essential for replicating how pathologists understand and reason across diverse image scales.\nAdditionally, we construct PathMMU-HR², the first expert-validated benchmark for large region analysis. This represents a critical intermediate scale between patches and whole slides, reflecting a key clinical reality where pathologists typically examine several key large regions rather than entire slides at once. Extensive experiments demonstrate that CPathAgent consistently outperforms existing approaches across benchmarks at three different image scales, validating the effectiveness of our agent-based diagnostic approach and highlighting a promising direction for computational pathology.""}",https://openreview.net{'value': '/pdf/3fdd0c91240de60bf73e632a1ffb879579a03248.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=XF1OzY8mEI,{'value': 'Towards Principled Unsupervised Multi-Agent Reinforcement Learning'},Riccardo Zamboni; Mirco Mutti; Marcello Restelli,~Riccardo_Zamboni1; ~Mirco_Mutti1; ~Marcello_Restelli1,"{'value': ['unsupervised reinforcement learning', 'state entropy maximization', 'multi-agent reinforcement learning', 'convex reinforcement learning']}","{'value': ""In reinforcement learning, we typically refer to *unsupervised* pre-training when we aim to pre-train a policy without a priori access to the task specification, i.e., rewards, to be later employed for efficient learning of downstream tasks. In single-agent settings, the problem has been extensively studied and mostly understood. A popular approach casts the unsupervised objective as maximizing the *entropy* of the state distribution induced by the agent's policy, from which principles and methods follow. In contrast, little is known about state entropy maximization in multi-agent settings, which are ubiquitous in the real world. What are the pros and cons of alternative problem formulations in this setting? How hard is the problem in theory, how can we solve it in practice? In this paper, we address these questions by first characterizing those alternative formulations and highlighting how the problem, even when tractable in theory, is non-trivial in practice. Then, we present a scalable, decentralized, trust-region policy search algorithm to address the problem in practical settings. Finally, we provide numerical validations to both corroborate the theoretical findings and pave the way for unsupervised multi-agent reinforcement learning via state entropy maximization in challenging domains, showing that optimizing for a specific objective, namely *mixture entropy*, provides an excellent trade-off between tractability and performances.""}",https://openreview.net{'value': '/pdf/0b099e4ceadc5f85e5a60633a4e2c3b55b190bc7.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=XBMjXb6f4w,{'value': 'CTRL-ALT-DECEIT Sabotage Evaluations for Automated AI R&D'},Francis Rhys Ward; Teun van der Weij; Hanna Gábor; Sam Martin; Raja Mehta Moreno; Harel Lidar; Louis Makower; Thomas Jodrell; Lauren Robson,~Francis_Rhys_Ward1; ~Teun_van_der_Weij2; ~Hanna_Gábor1; ~Sam_Martin1; ~Raja_Mehta_Moreno1; ~Harel_Lidar1; ~Louis_Makower1; ~Thomas_Jodrell1; ~Lauren_Robson1,"{'value': ['Sabotage Evaluations', 'Sandbagging', 'AI Control', 'AI Safety', 'AI Alignment', 'Dangerous Capability Evals']}","{'value': 'AI systems are increasingly able to autonomously conduct realistic software engineering tasks, and may soon be deployed to automate machine learning (ML) R\\&D itself. Frontier AI systems may be deployed in safety-critical settings, including to help ensure the safety of future systems. Unfortunately, frontier and future systems may not be sufficiently trustworthy, and there is evidence that these systems may even be misaligned with their developers or users. Therefore, we investigate the capabilities of AI agents to act against the interests of their users when conducting ML engineering, by sabotaging ML models, sandbagging their performance, and subverting oversight mechanisms. First, we extend MLE-Bench, a benchmark for realistic ML tasks, with code-sabotage tasks such as implanting backdoors and purposefully causing generalisation failures. Frontier agents make meaningful progress on our sabotage tasks. In addition, we study agent capabilities to sandbag on MLE-Bench. Agents can calibrate their performance to specified target levels below their actual capability. To mitigate sabotage, we use LM monitors to detect suspicious agent behaviour, and we measure model capability to sabotage and sandbag without being detected by these monitors. Overall, monitors are capable at detecting code-sabotage attempts but our results suggest that detecting sandbagging is more difficult. Additionally, aggregating multiple monitor predictions works well, but monitoring may not be sufficiently reliable to mitigate sabotage in high-stakes domains. Our benchmark is implemented in the UK AISI’s Inspect framework and we make our code publicly available.'}",https://openreview.net{'value': '/pdf/5ba46eb607f50910cda80a0bfc28f6c4f5b9c656.pdf'},{'abstract_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=X8C20fJXtx,{'value': 'Hierarchical Koopman Diffusion: Fast Generation with Interpretable Diffusion Trajectory'},Hanru Bai; Weiyang Ding; Difan Zou,~Hanru_Bai2; ~Weiyang_Ding1; ~Difan_Zou1,"{'value': ['One-step Generation', 'Diffusion Models', 'Koopman Operators', 'Interpretable Image Synthesis']}","{'value': 'Diffusion models have achieved impressive success in high-fidelity image generation but suffer from slow sampling due to their inherently iterative denoising process. While recent one-step methods accelerate inference by learning direct noise-to-image mappings, they sacrifice the interpretability and fine-grained control intrinsic to diffusion dynamics, key advantages that enable applications like editable generation. To resolve this dichotomy, we introduce **Hierarchical Koopman Diffusion**, a novel framework that achieves both one-step sampling and interpretable generative trajectories.  Grounded in Koopman operator theory, our method lifts the nonlinear diffusion dynamics into a latent space where evolution is governed by globally linear operators, enabling closed-form trajectory solutions. This formulation not only eliminates iterative sampling but also provides full access to intermediate states, allowing manual intervention during generation. To model the multi-scale nature of images, we design a hierarchical architecture that disentangles generative dynamics across spatial resolutions via scale-specific Koopman subspaces, capturing coarse-to-fine details systematically. We empirically show that the Hierarchical Koopman Diffusion not only achieves competitive one-step generation performance but also provides a principled mechanism for interpreting and manipulating the generative process through spectral analysis. Our framework bridges the gap between fast sampling and interpretability in diffusion models, paving the way for explainable image synthesis in generative modeling.'}",https://openreview.net{'value': '/pdf/72a3f56cb6bb73a6bd931de3c45486ef7ca56070.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=X5Hk8aMs6w,{'value': 'Self-Verification Provably Prevents Model Collapse in Recursive Synthetic Training'},Shi Fu; Yingjie Wang; Yuzhu Chen; Li Shen; Dacheng Tao,~Shi_Fu1; ~Yingjie_Wang1; ~Yuzhu_Chen1; ~Li_Shen1; ~Dacheng_Tao1,"{'value': ['Model Collapse', 'Learning Theory', 'Synthetic Data', 'Self-Verification', 'LLMs']}","{'value': 'Large generative models are increasingly trained on synthetic data from earlier generations, raising concerns about *model collapse*, a progressive performance decline consistently observed in empirical studies. However, theoretical understanding of recursive training dynamics and their failure modes remains limited. In this work, we theoretically show that recursive training inherently leads to exponential error growth unless mitigated by sufficient real data.  Addressing the growing scarcity of real data, we introduce a self-verification mechanism enabling models to filter their outputs based on internal confidence scores without external validation. Through rigorous analysis, we derive finite-sample error bounds demonstrating that self-verification alone can prevent collapse, even in fully synthetic training regimes. Our theoretical framework extends to large language models (LLMs), characterizing the conditions under which recursive training can maintain stability without performance degradation.'}",https://openreview.net{'value': '/pdf/623a8abf038a3cdfb6f7204fbc0a67a690057306.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=X5B2yTT97A,{'value': 'SimpleStrat: Diversifying Language Model Generation with Stratification'},Justin Wong; Yury Orlovskiy; Alexander Shypula; Michael Luo; Sanjit A. Seshia; Joseph E. Gonzalez,~Justin_Wong1; ~Yury_Orlovskiy1; ~Alexander_Shypula1; ~Michael_Luo2; ~Sanjit_A._Seshia1; ~Joseph_E._Gonzalez1,"{'value': ['Coverage', 'Language Model Sampling', 'Stratified Sampling', 'Evaluation', 'Dataset']}","{'value': ""Generating diverse responses from large language models (LLMs) is crucial for applications such as adversarial testing, search, and synthetic data generation, where diversity provides distinct answers across generations. Previous approaches rely solely on increasing the temperature, sacrificing quality. Furthermore, the model's next-token probabilities may not be representative of the true answer distribution. To combat these challenges, we propose SimpleStrat, an alternative that uses the language model itself to partition the solution space into strata from which to sample. \nTo measure resampling diversity, we introduce CoverageQA, a dataset of underspecified questions with multiple equally plausible answers. We propose measuring resampling diversity as the KL Divergence between the output distribution and the uniform distribution over valid ground truth answers and use recall as an alternative when assessing proprietary models. On CoverageQA, SimpleStrat improves diversity across all temperatures, showing orthogonal benefits. Quantifiably, we achieve as much as 2X better recall when applied to GPT-4o, and an average reduction in KL divergence by 0.36 when applied to Llama 3. Furthermore, we show that SimpleStrat achieves more resampling diversity at temperature T=0 than scaling temperature to T=1 on creative writing, an open-ended domain. Implementation and dataset available at https://github.com/jwong8314/simplestrat.""}",https://openreview.net{'value': '/pdf/5956a078a6d902daf9e102fb69be664eea309abf.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=X51kYnijag,{'value': 'TRAP: Targeted Redirecting of Agentic Preferences'},Hangoo Kang; Jehyeok Yeon; Gagandeep Singh,~Hangoo_Kang1; ~Jehyeok_Yeon1; ~Gagandeep_Singh1,"{'value': ['Agentic AI', 'Trustworthy Machine Learning', 'Multimodal', 'Autonomous Decision Making', 'Large Language Model (LLM)', 'Vision Language Model (VLM))']}","{'value': 'Autonomous agentic AI systems powered by vision-language models (VLMs) are rapidly advancing toward real-world deployment, yet their cross-modal reasoning capabilities introduce new attack surfaces for adversarial manipulation that exploit semantic reasoning across modalities. Existing adversarial attacks typically rely on visible pixel perturbations or require privileged model or environment access, making them impractical for stealthy, real-world exploitation. We introduce TRAP, a novel generative adversarial framework that manipulates\nthe agent’s decision-making using diffusion-based semantic injections into the vision-language embedding space. Our method combines negative prompt–based degradation with positive semantic optimization, guided by a Siamese semantic network and layout-aware spatial masking. Without requiring access to model internals, TRAP produces visually natural images yet induces consistent selection\nbiases in agentic AI systems. We evaluate TRAP on the Microsoft Common Objects in Context (COCO) dataset, building multi-candidate decision scenarios. Across these scenarios, TRAP consistently induces decision-level preference redirection on leading models, including LLaVA-34B, Gemma3, GPT-4o, and Mistral-3.2, significantly outperforming existing baselines such as SPSA, Bandit, and standard diffusion approaches. These findings expose a critical, generalized vulnerability: autonomous agents can be consistently misled through visually subtle, semantically-guided cross-modal manipulations. Overall, our results show the need for defense strategies beyond pixel-level robustness to address semantic vulnerabilities in cross-modal decision-making. The code for TRAP is accessible on GitHub at https://github.com/uiuc-focal-lab/TRAP.'}",https://openreview.net{'value': '/pdf/8591b1dac1bf58780a964857d113f6ac8abbd3f2.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=X3zarVyJ5B,{'value': 'Learning Relative Gene Expression Trends from Pathology Images in Spatial Transcriptomics'},Kazuya Nishimura; Haruka Hirose; Ryoma Bise; Kaito Shiku; Yasuhiro Kojima,~Kazuya_Nishimura1; ~Haruka_Hirose1; ~Ryoma_Bise2; ~Kaito_Shiku1; ~Yasuhiro_Kojima1,"{'value': ['Spatial Transcriptomics', 'pathology image', 'learning to rank', 'gene expression']}","{'value': 'Gene expression estimation from pathology images has the potential to reduce the RNA sequencing cost.\nPoint-wise loss functions have been widely used to minimize the discrepancy between predicted and absolute gene expression values. \nHowever, due to the complexity of the sequencing techniques and intrinsic variability across cells, the observed gene expression contains stochastic noise and batch effects, and estimating the absolute expression values accurately remains a significant challenge.\nTo mitigate this, we propose a novel objective of learning relative expression patterns rather than absolute levels.\nWe assume that the relative expression levels of genes exhibit consistent patterns across independent experiments, even when absolute expression values are affected by batch effects and stochastic noise in tissue samples.\nBased on the assumption, we model the relation and propose a novel loss function called STRank that is robust to noise and batch effects.\nExperiments using synthetic datasets and real datasets demonstrate the effectiveness of the proposed method.\nThe code is available at https://github.com/naivete5656/STRank.'}",https://openreview.net{'value': '/pdf/9ff4681372159ffa6e4a9931903a4357423beeef.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=X3RVQNOIXZ,{'value': 'Increasing the Utility of Synthetic Images through Chamfer Guidance'},Nicola Dall'Asen; Xiaofeng Zhang; Reyhane Askari-Hemmat; Melissa Hall; Jakob Verbeek; Adriana Romero-Soriano; Michal Drozdzal,~Nicola_Dall'Asen1; ~Xiaofeng_Zhang2; ~Reyhane_Askari-Hemmat1; ~Melissa_Hall1; ~Jakob_Verbeek1; ~Adriana_Romero-Soriano1; ~Michal_Drozdzal1,"{'value': ['diffusion models', 'synthetic data diversity', 'guidance-based generation']}","{'value': 'Conditional image generative models hold considerable promise to produce infinite amounts of synthetic training data. \nYet, recent progress in generation quality has come at the expense of generation diversity, limiting the utility of these models as a source of synthetic training data.\nAlthough guidance-based approaches have been introduced to improve the utility of generated data by focusing on quality or diversity,\nthe (implicit or explicit) utility functions oftentimes disregard the potential distribution shift between synthetic and real data. In this work, we introduce Chamfer Guidance: a training-free guidance approach which leverages a handful of real exemplar  images to characterize the quality and diversity of synthetic data. We show that by leveraging the proposed Chamfer Guidance, we can boost the diversity of the generations w.r.t. a dataset of real images while maintaining or improving the generation quality on ImageNet-1k and standard geo-diversity benchmarks. Our approach achieves state-of-the-art few-shot performance with as little as 2 exemplar real images, obtaining 96.4% in terms of precision, and 86.4% in terms of distributional coverage, which increase to 97.5% and 92.7%, respectively, when using 32 real images. We showcase the benefits of the Chamfer Guidance generation by training downstream image classifiers on synthetic data, achieving accuracy boost of up to 15% for in-distribution over the baselines, and up to 16\\% in out-of-distribution.\nFurthermore, our approach does not require using the unconditional model, and thus obtains a 31\\% reduction in FLOPs w.r.t. classifier-free-guidance-based approaches at sampling time.'}",https://openreview.net{'value': '/pdf/f65243f266deee11b2bd41268987d57ee302f8ca.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=X2u8esISdb,{'value': 'DGS-LRM: Real-Time Deformable 3D Gaussian Reconstruction From Monocular Videos'},Chieh Hubert Lin; Zhaoyang Lv; Songyin Wu; Zhen Xu; Thu Nguyen-Phuoc; Hung-Yu Tseng; Julian Straub; Numair Khan; Lei Xiao; Ming-Hsuan Yang; Yuheng Ren; Richard Newcombe; Zhao Dong; Zhengqin Li,~Chieh_Hubert_Lin1; ~Zhaoyang_Lv1; ~Songyin_Wu1; ~Zhen_Xu5; ~Thu_Nguyen-Phuoc1; ~Hung-Yu_Tseng2; ~Julian_Straub1; ~Numair_Khan1; ~Lei_Xiao1; ~Ming-Hsuan_Yang1; ~Yuheng_Ren1; ~Richard_A._Newcombe1; ~Zhao_Dong2; ~Zhengqin_Li1,"{'value': ['Large reconstruction model', 'LRM', 'dynamic']}","{'value': 'We introduce the Deformable Gaussian Splats Large Reconstruction Model (DGS-LRM), the first feed-forward method predicting deformable 3D Gaussian splats from a monocular posed video of any dynamic scene. Feed-forward scene reconstruction has gained significant attention for its ability to rapidly create digital replicas of real-world environments. However, most existing models are limited to static scenes and fail to reconstruct the motion of moving objects. Developing a feed-forward model for dynamic scene reconstruction poses significant challenges, including the scarcity of training data and the need for appropriate 3D representations and training paradigms. To address these challenges, we introduce several key technical contributions: an enhanced large-scale synthetic dataset with ground-truth multi-view videos and dense 3D scene flow supervision; a per-pixel deformable 3D Gaussian representation that is easy to learn, supports high-quality dynamic view synthesis, and enables long-range 3D tracking; and a large transformer network that achieves real-time, generalizable dynamic scene reconstruction. Extensive qualitative and quantitative experiments demonstrate that DGS-LRM achieves dynamic scene reconstruction quality comparable to optimization-based methods, while significantly outperforming the state-of-the-art predictive dynamic reconstruction method on real-world examples. Its predicted physically grounded 3D deformation is accurate and can be readily adapted for long-range 3D tracking tasks, achieving performance on par with state-of-the-art monocular video 3D tracking methods.'}",https://openreview.net{'value': '/pdf/14d4fe9749b893a816da1e54be2fa3428a12cda1.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=X13jOIhnog,{'value': 'Partial Information Decomposition via Normalizing Flows in Latent Gaussian Distributions'},Wenyuan Zhao; Adithya Balachandran; Chao Tian; Paul Pu Liang,~Wenyuan_Zhao1; ~Adithya_Balachandran1; ~Chao_Tian2; ~Paul_Pu_Liang1,"{'value': ['Partial information decomposition', 'multimodal learning', 'information theory', 'Gaussian distributions']}","{'value': 'The study of multimodality has garnered significant interest in fields where analyzing interactions among multiple information sources can enhance predictive modeling, data fusion, and interpretability. Partial information decomposition (PID) has emerged as a useful information-theoretic framework to quantify the degree to which individual modalities independently, redundantly, or synergistically convey information about a target variable. However, existing PID methods depend on optimizing over a joint distribution constrained by estimated pairwise probability distributions, which are costly and inaccurate for continuous and high-dimensional modalities. Our first key insight is that the problem can be solved efficiently when the pairwise distributions are multivariate Gaussians, and we refer to this problem as Gaussian PID (GPID). We propose a new gradient-based algorithm that substantially enhances computational efficiency for GPID based on an alternative formulation of the underlying optimization problem. To generalize the applicability to non-Gaussian data, we learn information-preserving encoders to transform random variables of arbitrary input distributions into pairwise Gaussian random variables. Along the way, we resolved an open problem regarding the optimality of joint Gaussian solutions for GPID. Empirical validation on diverse synthetic examples demonstrates that our proposed method provides more accurate and efficient PID estimates than existing baselines. We further evaluate on a series of large-scale multimodal benchmarks to show its utility in real-world applications of quantifying PID in multimodal datasets and selecting high-performing models.'}",https://openreview.net{'value': '/pdf/9ddd778468bb3caf9340a8a944214485f2bc6fca.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=WydxWM2xNb,{'value': 'Partner Modelling Emerges in Recurrent Agents (But Only When It Matters)'},Ruaridh Mon-Williams; Max Taylor-Davies; Elizabeth Mieczkowski; Natalia Vélez; Neil R Bramley; Yanwei Wang; Thomas L. Griffiths; Christopher G. Lucas,~Ruaridh_Mon-Williams1; ~Max_Taylor-Davies1; ~Elizabeth_Mieczkowski1; ~Natalia_Vélez1; ~Neil_R_Bramley1; ~Yanwei_Wang1; ~Thomas_L._Griffiths1; ~Christopher_G._Lucas1,"{'value': ['multi-agent reinforcement learning', 'partner modelling', 'emergent representations', 'collaboration']}","{'value': ""Humans are remarkably adept at collaboration, able to infer the strengths and weaknesses of new partners in order to work successfully towards shared goals. To build AI systems with this capability, we must first understand its building blocks: does such flexibility require explicit, dedicated mechanisms for modelling others—or can it emerge spontaneously from the pressures of open-ended cooperative interaction? To investigate this question, we train simple model-free RNN agents to collaborate with a population of diverse partners. Using the 'Overcooked-AI' environment, we collect data from thousands of collaborative teams, and analyse agents' internal hidden states. Despite a lack of additional architectural features, inductive biases, or auxiliary objectives, the agents nevertheless develop structured internal representations of their partners' task abilities, enabling rapid adaptation and generalisation to novel collaborators. We investigated these internal models through probing techniques, and large-scale behavioural analysis. Notably, we find that structured partner modelling emerges when agents can influence partner behaviour by controlling task allocation. Our results show that partner modelling can arise spontaneously in model-free agents—but only under environmental conditions that impose the right kind of social pressure.""}",https://openreview.net{'value': '/pdf/ce9e0e5f6bb446a8103ef0fb8f4c67e47b7972d0.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=Wlx38NK0Om,{'value': 'Pairwise Optimal Transports for Training All-to-All Flow-Based Condition Transfer Model'},Kotaro Ikeda; Masanori Koyama; Jinzhe Zhang; Kohei Hayashi; Kenji Fukumizu,~Kotaro_Ikeda1; ~Masanori_Koyama1; ~Jinzhe_Zhang2; ~Kohei_Hayashi1; ~Kenji_Fukumizu1,"{'value': ['Flow Matching', 'Conditional Transfer']}","{'value': 'In this paper, we propose a flow-based method for learning all-to-all transfer maps among conditional distributions that approximates pairwise optimal transport. The proposed method addresses the challenge of handling the case of continuous conditions, which often involve a large set of conditions with sparse empirical observations per condition.  We introduce a novel cost function that enables simultaneous learning of optimal transports for all pairs of conditional distributions. Our method is supported by a theoretical guarantee that, in the limit, it converges to the pairwise optimal transports among infinite pairs of conditional distributions. The learned transport maps are subsequently used to couple data points in conditional flow matching. We demonstrate the effectiveness of this method on synthetic and benchmark datasets, as well as on chemical datasets in which continuous physical properties are defined as conditions.'}",https://openreview.net{'value': '/pdf/601217b4b5bf65e3228f7c4c2e865d154e06e4e4.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=WdL3O58gde,{'value': 'Self-Generated In-Context Examples Improve LLM Agents for Sequential Decision-Making Tasks'},Vishnu Sarukkai; Zhiqiang Xie; Kayvon Fatahalian,~Vishnu_Sarukkai1; ~Zhiqiang_Xie3; ~Kayvon_Fatahalian2,"{'value': ['language models', 'agents', 'self-improvement', 'in-context learning', 'sequential decision-making']}","{'value': 'Improving Large Language Model (LLM) agents for sequential decision-making tasks typically requires extensive task-specific knowledge engineering—custom prompts, curated examples, and specialized observation/action spaces. We investigate a different approach where agents automatically improve by learning from their own successful experiences without human intervention. Our method constructs and refines a database of self-generated trajectories that serve as in-context examples for future tasks. Even naive accumulation of successful trajectories yields substantial performance gains across three diverse benchmarks: ALFWorld (73\\% to 89\\%), Wordcraft (55\\% to 64\\%), and InterCode-SQL (75\\% to 79\\%). These improvements exceed those achieved by upgrading from gpt-4o-mini to gpt-4o and match the performance of allowing multiple attempts per task. We further enhance this approach with two innovations: database-level curation using population-based training to propagate high-performing example collections, and exemplar-level curation that selectively retains trajectories based on their empirical utility as in-context examples. With these enhancements, our method achieves 93\\% success on ALFWorld—surpassing approaches that use more powerful LLMs and hand-crafted components. Our trajectory bootstrapping technique demonstrates that agents can autonomously improve through experience, offering a scalable alternative to labor-intensive knowledge engineering.'}",https://openreview.net{'value': '/pdf/05d0804df1c396da814a29970ae7d37c40a1b84e.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=WYnvP3DePZ,{'value': 'Bridging Theory and Practice in Link Representation with Graph Neural Networks'},Veronica Lachi; Francesco Ferrini; Antonio Longa; Bruno Lepri; Andrea Passerini; Manfred Jaeger,~Veronica_Lachi1; ~Francesco_Ferrini2; ~Antonio_Longa1; ~Bruno_Lepri1; ~Andrea_Passerini2; ~Manfred_Jaeger1,"{'value': ['Graph Neural Networks', 'Link Representation', 'Expressiveness']}","{'value': 'Graph Neural Networks (GNNs) are widely used to compute representations of node pairs for downstream tasks such as link prediction. Yet, theoretical understanding of their expressive power has focused almost entirely on graph-level representations. In this work, we shift the focus to links and provide the first comprehensive study of GNN expressiveness in link representation. We introduce a unifying framework, the $k_\\phi$-$k_\\rho$-$m$ framework, that subsumes existing message-passing link models and enables formal expressiveness comparisons. Using this framework, we derive a hierarchy of state-of-the-art methods and offer theoretical tools to analyze future architectures. To complement our analysis, we propose a synthetic evaluation protocol comprising the first benchmark specifically designed to assess link-level expressiveness. Finally, we ask: does expressiveness matter in practice? We use a graph symmetry metric that quantifies the difficulty of distinguishing links and show that while expressive models may underperform on standard benchmarks, they significantly outperform simpler ones as symmetry increases, highlighting the need for dataset-aware model selection.'}",https://openreview.net{'value': '/pdf/124d69e8b54debfcfeb0e34773f9fb43350ff919.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=WQb0YrFl3H,{'value': 'Unmasking Puppeteers: Leveraging Biometric Leakage to Expose Impersonation in AI-Based Videoconferencing'},Danial Samadi Vahdati; Tai Duc Nguyen; Ekta Prashnani; Koki Nagano; david luebke; Orazio Gallo; Matthew Stamm,~Danial_Samadi_Vahdati1; ~Tai_Duc_Nguyen1; ~Ekta_Prashnani1; ~Koki_Nagano1; ~david_luebke1; ~Orazio_Gallo1; ~Matthew_Stamm1,"{'value': ['Multimedia Forensics', 'Talking Head Videos', 'Talking Head Videoconferencing', 'Puppeteering Attacks']}","{'value': ""AI-based talking-head videoconferencing systems reduce bandwidth by transmitting a latent representation of a speaker’s pose and expression, which is used to synthesize frames on the receiver's end. However, these systems are vulnerable to “puppeteering” attacks, where an adversary controls the identity of another person in real-time. Traditional deepfake detectors fail here, as all video content is synthetic. We propose a novel biometric defense that detects identity leakage in the transmitted latent representation. Our metric-learning approach disentangles identity cues from pose and expression, enabling detection of unauthorized swaps. Experiments across multiple talking-head models show that our method consistently outperforms prior defenses, operates in real time on consumer GPUs, and generalizes well to out-of-distribution data. By targeting the latent features shared during normal operation, our method offers a practical and robust safeguard against puppeteering.""}",https://openreview.net{'value': '/pdf/5abf6ea1e760d64cd265115b649275903e340a7b.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=WJnqeSPkQe,{'value': 'DiffE2E: Rethinking End-to-End Driving with a Hybrid Diffusion-Regression-Classification Policy'},Rui Zhao; Yuze Fan; Ziguo Chen; Fei Gao; Zhenhai Gao,~Rui_Zhao24; ~Yuze_Fan1; ~Ziguo_Chen1; ~Fei_Gao24; ~Zhenhai_Gao1,"{'value': ['Autonomous driving', 'diffusion model', 'end-to-end', 'transformer']}","{'value': 'End-to-end learning has emerged as a transformative paradigm for autonomous driving. However, the inherently multimodal nature of driving behaviors remains a fundamental challenge to robust deployment. We propose DiffE2E, a diffusion-based end-to-end autonomous driving framework. The architecture first performs multi-scale alignment of perception features from multiple sensors via a hierarchical bidirectional cross-attention mechanism. Subsequently, we design a hybrid diffusion-regression-classification decoder based on the Transformer architecture, adopting a collaborative training paradigm to seamlessly fuse the strengths of diffusion and explicit strategies. DiffE2E conducts structured modeling in the latent space: diffusion captures the multimodal distribution of future trajectories, while regression and classification act as explicit strategies to precisely model key control variables such as velocity, enhancing both the precision and controllability of the model. A global condition integration module further enables deep fusion of perception features with high-level goals, significantly improving the quality of trajectory generation. The subsequent cross-attention mechanism facilitates efficient interaction between integrated features and hybrid latent variables, promoting joint optimization of diffusion and explicit strategies for structured output generation and thereby yielding more robust control. Experimental results demonstrate that DiffE2E achieves state-of-the-art performance on both CARLA closed-loop benchmarks and NAVSIM evaluations. The proposed unified framework that integrates diffusion and explicit strategies provides a generalizable paradigm for hybrid action representation and shows substantial potential for extension to broader domains, including embodied intelligence.'}",https://openreview.net{'value': '/pdf/fa06cd5cd12b6bce86a62d71d9ae0ac8a94d814f.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=WCPAHpVAUp,{'value': 'Optimal Graph Clustering without Edge Density Signals'},Maximilien Dreveton; Elaine S. Liu; Matthias Grossglauser; Patrick Thiran,~Maximilien_Dreveton1; ~Elaine_S._Liu1; ~Matthias_Grossglauser1; ~Patrick_Thiran1,"{'value': ['community detection', 'unsupervised learning', 'stochastic block model', 'spectral clustering']}","{'value': 'This paper establishes the theoretical limits of graph clustering under the Popularity-Adjusted Block Model (PABM), addressing limitations of existing models. In contrast to the Stochastic Block Model (SBM), which assumes uniform vertex degrees, and to the Degree-Corrected Block Model (DCBM), which applies uniform degree corrections across clusters, PABM introduces separate popularity parameters for intra- and inter-cluster connections. Our main contribution is the characterization of the optimal error rate for clustering under PABM, which provides novel insights on clustering hardness: we demonstrate that unlike SBM and DCBM, cluster recovery remains possible in PABM even when traditional edge-density signals vanish, provided intra- and inter-cluster popularity coefficients differ. This highlights a dimension of degree heterogeneity captured by PABM but overlooked by DCBM: local differences in connectivity patterns can enhance cluster separability independently of global edge densities. Finally, because PABM exhibits a richer structure, its expected adjacency matrix has rank between $k$ and $k^2$, where $k$ is the number of clusters. As a result, spectral embeddings based on the top $k$ eigenvectors may fail to capture important structural information. Our numerical experiments on both synthetic and real datasets confirm that spectral clustering algorithms incorporating $k^2$ eigenvectors outperform traditional spectral approaches.'}",https://openreview.net{'value': '/pdf/16a7ddd1000907f1aa0517e02acd89eb5beff5a0.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=W0sqoTL7rL,{'value': 'Distilling LLM Prior to Flow Model for Generalizable Agent’s Imagination in Object Goal Navigation'},Badi Li; Ren-Jie Lu; Yu Zhou; Jingke Meng; Wei-Shi Zheng,~Badi_Li1; ~Ren-Jie_Lu1; ~Yu_Zhou21; ~Jingke_Meng2; ~Wei-Shi_Zheng3,{'value': ['Visual Navigation; Object Goal Navigation']},"{'value': 'The Object Goal Navigation (ObjectNav) task challenges agents to locate a specified object in an unseen environment by imagining unobserved regions of the scene. Prior approaches rely on deterministic and discriminative models to complete semantic maps, overlooking the inherent uncertainty in indoor layouts and limiting their ability to generalize to unseen environments. In this work, we propose GOAL, a generative flow-based framework that models the semantic distribution of indoor environments by bridging observed regions with LLM-enriched full-scene semantic maps. During training, spatial priors inferred from large language models (LLMs) are encoded as two-dimensional Gaussian fields and injected into target maps, distilling rich contextual knowledge into the flow model and enabling more generalizable completions. Extensive experiments demonstrate that GOAL achieves state-of-the-art performance on MP3D and Gibson, and shows strong generalization in transfer settings to HM3D.'}",https://openreview.net{'value': '/pdf/fd4b1ee5099804b40602b7867c724285c5791fe0.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=W0eTcFyx44,{'value': 'ChemOrch: Empowering LLMs with Chemical Intelligence via Groundbreaking Synthetic Instructions'},Yue Huang; Zhengzhe Jiang; Xiaonan Luo; Kehan Guo; Haomin Zhuang; Yujun Zhou; Zhengqing Yuan; Xiaoqi Sun; Jules Schleinitz; Yanbo Wang; Shuhao Zhang; Mihir Surve; Nitesh V Chawla; Olaf Wiest; Xiangliang Zhang,~Yue_Huang9; ~Zhengzhe_Jiang1; ~Xiaonan_Luo5; ~Kehan_Guo1; ~Haomin_Zhuang1; ~Yujun_Zhou1; ~Zhengqing_Yuan2; ~Xiaoqi_Sun2; ~Jules_Schleinitz1; ~Yanbo_Wang10; ~Shuhao_Zhang7; ~Mihir_Surve1; ~Nitesh_V_Chawla1; ~Olaf_Wiest1; ~Xiangliang_Zhang1,"{'value': ['Chemistry', 'Large Language Model', 'Synthetic Data']}","{'value': 'Empowering large language models (LLMs) with chemical intelligence remains a challenge due to the scarcity of high-quality, domain-specific instruction-response datasets and the misalignment of existing synthetic data generation pipelines with the inherently hierarchical and rule-governed structure of chemical information. To address this, we propose ChemOrch, a framework that synthesizes chemically grounded instruction–response pairs through a two-stage process: task-controlled instruction generation and tool-aware response construction. ChemOrch enables controllable diversity and levels of difficulty for the generated tasks and ensures response precision through tool planning \\& distillation, and tool-based self-repair mechanisms. The effectiveness of ChemOrch is evaluated based on: 1)  the \\textbf{high quality} of generated instruction data, demonstrating superior diversity and strong alignment with chemical constraints; 2)  the \\textbf{dynamic generation of evaluation tasks} that more effectively reveal LLM weaknesses in chemistry; and 3)  the significant \\textbf{improvement of LLM chemistry capabilities} when the generated instruction data are used for fine-tuning. Our work thus represents a critical step toward scalable and verifiable chemical intelligence in LLMs. The code is available at \\url{https://anonymous.4open.science/r/ChemOrch-854A}.'}",https://openreview.net{'value': '/pdf/23e4294ab38fe1690b33c8e77141dc83898cdfc4.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=Vzi96rTe4w,{'value': 'scPilot: Large Language Model Reasoning Toward Automated Single-Cell Analysis and Discovery'},Yiming Gao; Zhen Wang; Jefferson Chen; Mark Antkowiak; Mengzhou Hu; JungHo Kong; Dexter Pratt; Jieyuan Liu; Enze Ma; Zhiting Hu; Eric P. Xing,~Yiming_Gao5; ~Zhen_Wang6; ~Jefferson_Chen1; ~Mark_Antkowiak1; ~Mengzhou_Hu1; ~JungHo_Kong1; ~Dexter_Pratt1; ~Jieyuan_Liu1; ~Enze_Ma1; ~Zhiting_Hu3; ~Eric_Xing1,"{'value': ['Large Language Models', 'Scientific Reasoning', 'Automation of Science', 'Single-cell Transcriptomics', 'Cell Type Annotation', 'Trajectory Inference', 'Gene Regulatory Network Inference']}","{'value': 'We present scPilot, the first systematic framework to practice \\textit{omics-native reasoning}: a large language model (LLM) converses in natural language while directly inspecting single-cell RNA-seq data and on-demand bioinformatics tools. scPilot converts core single-cell analyses, i.e., cell-type annotation, developmental-trajectory reconstruction, and transcription-factor targeting, into step-by-step reasoning problems that the model must solve, justify, and, when needed, revise with new evidence. To measure progress, we release \\scbench, a suite of 9 expertly curated datasets and graders that faithfully evaluate the omics-native reasoning capability of scPilot w.r.t various LLMs. Experiments with o1 show that \\textit{iterative} omics-native reasoning lifts average accuracy by 11\\% for cell-type annotation and Gemini 2.5 Pro cuts trajectory graph-edit distance by 30\\% versus one-shot prompting, while generating transparent reasoning traces that explain marker gene ambiguity and regulatory logic. By grounding LLMs in raw omics data, scPilot enables auditable, interpretable, and diagnostically informative single-cell analyses.'}",https://openreview.net{'value': '/pdf/dfb3dccdd0ea2a09c317ede66642cf8f4834c9d7.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=VzWjHxE8PF,{'value': 'TAPIP3D: Tracking Any Point in Persistent 3D Geometry'},Bowei Zhang; Lei Ke; Adam W Harley; Katerina Fragkiadaki,~Bowei_Zhang2; ~Lei_Ke1; ~Adam_W_Harley1; ~Katerina_Fragkiadaki1,{'value': ['3d point tracking']},"{'value': 'We introduce TAPIP3D,  a novel approach for long-term 3D point tracking in monocular RGB and RGB-D videos. TAPIP3D represents videos as camera-stabilized spatio-temporal feature clouds, leveraging depth and camera motion information to lift 2D video features into a 3D world space where camera movement is effectively canceled out. Within this stabilized 3D representation, TAPIP3D iteratively refines multi-frame motion estimates, enabling robust point tracking over long time horizons. To handle the irregular structure of 3D point distributions, we propose a 3D Neighborhood-to-Neighborhood (N2N) attention mechanism—a 3D-aware contextualization strategy that builds informative, spatially coherent feature neighborhoods to support precise trajectory estimation. Our 3D-centric formulation significantly improves performance over existing 3D point tracking methods and even surpasses state-of-the-art 2D pixel trackers in accuracy when reliable depth is available. The model supports inference in both camera-centric (unstabilized) and world-centric (stabilized) coordinates, with experiments showing that compensating for camera motion leads to substantial gains in tracking robustness. By replacing the conventional 2D square correlation windows used in prior 2D and 3D trackers with a spatially grounded 3D attention mechanism, TAPIP3D achieves strong and consistent results across multiple 3D point tracking benchmarks. Our code and trained checkpoints will be public.'}",https://openreview.net{'value': '/pdf/ac17d5db59163a51e4e886fdcc55ff845c9e1eb1.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=VzSjSUE0BZ,{'value': 'CREA: A Collaborative Multi-Agent Framework for Creative Image Editing and Generation'},Kavana Venkatesh; Connor Dunlop; Pinar Yanardag,~Kavana_Venkatesh1; ~Connor_Dunlop2; ~Pinar_Yanardag1,"{'value': ['creativity', 't2i', 'diffusion', 'multi-agentic systems', 'llm']}","{'value': 'Creativity in AI imagery remains a fundamental challenge, requiring not only the generation of visually compelling content but also the capacity to add novel, expressive, and artistically rich transformations to images. Unlike conventional editing tasks that rely on direct prompt-based modifications, creative image editing demands an autonomous, iterative approach that balances originality, coherence, and artistic intent. To address this, we introduce CREA, a novel multi-agent collaborative framework that mimics the human creative process. Our framework leverages a team of specialized AI agents who dynamically collaborate to conceptualize, generate, critique, and enhance images.  Through extensive qualitative and quantitative evaluations, we demonstrate that CREA significantly outperforms state-of-the-art methods in diversity, semantic alignment, and creative transformation. To the best of our knowledge, this is the first work to introduce the task of creative editing.'}",https://openreview.net{'value': '/pdf/28e7d3d9e1c9989f49f1595e3f193be85c855561.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=VwPt1WDQNB,"{'value': 'Trajectory Balance with Asynchrony: Decoupling Exploration and Learning for Fast, Scalable LLM Post-Training'}",Brian R. Bartoldson; Siddarth Venkatraman; James Diffenderfer; Moksh Jain; Tal Ben-Nun; Seanie Lee; Minsu Kim; Johan Obando-Ceron; Yoshua Bengio; Bhavya Kailkhura,~Brian_R._Bartoldson1; ~Siddarth_Venkatraman1; ~James_Diffenderfer1; ~Moksh_Jain1; ~Tal_Ben-Nun1; ~Seanie_Lee1; ~Minsu_Kim2; ~Johan_Obando-Ceron1; ~Yoshua_Bengio1; ~Bhavya_Kailkhura1,"{'value': ['LLM', 'post-training', 'RL', 'async', 'off-policy', 'RLHF', 'reasoning']}","{'value': ""Reinforcement learning (RL) is a critical component of large language model (LLM) post-training. However, on-policy algorithms used for post-training are not naturally robust to a diversified content of experience replay buffers, which asynchronous off-policy actors can efficiently populate in parallel to training. We propose efficiently learning on such off-policy data via Trajectory Balance with Asynchrony (TBA), an approach to asynchronous RL for LLMs that leverages the principled off-policy TB objective. On math, preference-tuning, and automated red-teaming tasks, we post-train models ranging from Pythia 410M to Qwen 2.5 7B, finding TBA offers speed and performance boosts over strong baselines like Online DPO and Dr. GRPO. Beyond TBA's performance benefits (high accuracy even as asynchrony grows) and speedups ($4\\times$ or more), we show its reward- and recency-prioritizing sampling enable further gains as data generation is scaled. Our code is available at https://github.com/bbartoldson/TBA.""}",https://openreview.net{'value': '/pdf/13f871efbbbe385c376ef8105b8c5e2aaeddb542.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=Vusd1Hw2D9,{'value': 'Multi-Agent Debate for LLM Judges with Adaptive Stability Detection'},Tianyu Hu; Zhen Tan; Song Wang; Huaizhi Qu; Tianlong Chen,~Tianyu_Hu4; ~Zhen_Tan2; ~Song_Wang6; ~Huaizhi_Qu1; ~Tianlong_Chen1,"{'value': ['LLM-as-Judge', 'Multi-Agent Debate', 'Adaptive Stopping']}","{'value': ""With advancements in reasoning capabilities, \nLarge Language Models (LLMs) are increasingly employed for automated judgment tasks.\nWhile LLMs-as-Judges offer promise in automating evaluations, \ncurrent approaches often rely on simplistic aggregation methods (e.g., majority voting), \nwhich can fail even when individual agents provide correct answers.\nTo address this, we propose a multi-agent debate judge framework where agents collaboratively reason and iteratively refine their responses. \nWe formalize the debate process mathematically, analyzing agent interactions and proving that debate amplifies correctness compared to static ensembles.\nTo enhance efficiency, we introduce a stability detection mechanism that models judge consensus dynamics via a time-varying Beta-Binomial mixture, with adaptive stopping based on distributional similarity (Kolmogorov-Smirnov test).\nThis mechanism models the judges' collective correct rate dynamics using a time-varying mixture of Beta-Binomial distributions and employs an adaptive stopping criterion based on distributional similarity (Kolmogorov-Smirnov statistic). \nExperiments across multiple benchmarks and models demonstrate that our framework improves judgment accuracy over majority voting while maintaining computational efficiency.""}",https://openreview.net{'value': '/pdf/6f99dac2bdcda05f1538352395bc8461eea20d68.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=VkicTqszOn,{'value': 'Distilling LLM Agent into Small Models with Retrieval and Code Tools'},Minki Kang; Jongwon Jeong; Seanie Lee; Jaewoong Cho; Sung Ju Hwang,~Minki_Kang1; ~Jongwon_Jeong1; ~Seanie_Lee1; ~Jaewoong_Cho1; ~Sung_Ju_Hwang1,"{'value': ['langauge model', 'language agent', 'reasoning', 'distillation']}","{'value': 'Large language models (LLMs) excel at complex reasoning tasks but remain computationally expensive, limiting their practical deployment.\nTo address this, recent works have focused on distilling reasoning capabilities into smaller language models (sLMs) using chain-of-thought (CoT) traces from teacher LLMs.\nHowever, this approach struggles in scenarios requiring rare factual knowledge or precise computation, where sLMs often hallucinate due to limited capability.\nIn this work, we propose Agent Distillation, a framework for transferring not only reasoning capability but full task-solving behavior from LLM-based agents into sLMs with retrieval and code tools. \nWe improve agent distillation along two complementary axes: (1) we introduce a prompting method called first-thought prefix to enhance the quality of teacher-generated trajectories; \nand (2) we propose a self-consistent action generation for improving test-time robustness of small agents.\nWe evaluate our method on eight reasoning tasks across factual and mathematical domains, covering both in-domain and out-of-domain generalization.\nOur results show that sLMs as small as 0.5B, 1.5B, 3B parameters can achieve performance competitive with next-tier larger 1.5B, 3B, 7B models fine-tuned using CoT distillation, demonstrating the potential of agent distillation for building practical, tool-using small agents.'}",https://openreview.net{'value': '/pdf/c3ead64f6c3fd03156d79bf7aa5185204700b2a2.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=Vejx32FeWt,{'value': 'A Principle of Targeted Intervention for Multi-Agent Reinforcement Learning'},Anjie Liu; Jianhong Wang; Samuel Kaski; Jun Wang; Mengyue Yang,~Anjie_Liu1; ~Jianhong_Wang1; ~Samuel_Kaski1; ~Jun_Wang2; ~Mengyue_Yang1,"{'value': ['multi-agent reinforcement learning', 'targeted intervention', 'pre-strategy intervention', 'multi-agent influence diagrams', 'multi-agent systems', 'hanabi']}","{'value': 'Steering cooperative multi-agent reinforcement learning (MARL) towards desired outcomes is challenging, particularly when the global guidance from a human on the whole multi-agent system is impractical in a large-scale MARL. On the other hand, designing external mechanisms (e.g., intrinsic rewards and human feedback) to coordinate agents mostly relies on empirical studies, lacking a easy-to-use research tool. In this work, we employ multi-agent influence diagrams (MAIDs) as a graphical framework to address the above issues. First, we introduce the concept of MARL interaction paradigms (orthogonal to MARL learning paradigms), using MAIDs to analyze and visualize both unguided self-organization and global guidance mechanisms in MARL. Then, we design a new MARL interaction paradigm, referred to as the targeted intervention paradigm that is applied to only a single targeted agent, so the problem of global guidance can be mitigated. In implementation, we introduce a causal inference technique—referred to as Pre-Strategy Intervention (PSI)—to realize the targeted intervention paradigm. Since MAIDs can be regarded as a special class of causal diagrams, a composite desired outcome that integrates the primary task goal and an additional desired outcome can be achieved by maximizing the corresponding causal effect through the PSI. Moreover, the bundled relevance graph analysis of MAIDs provides a tool to identify whether an MARL learning paradigm is workable under the design of an MARL interaction paradigm. In experiments, we demonstrate the effectiveness of our proposed targeted intervention, and verify the result of relevance graph analysis.'}",https://openreview.net{'value': '/pdf/11cf216de1cfa39c988ea8c0cf6e714a2e3ad43c.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=VYY5sG4EMm,{'value': 'Policy Gradient Methods Converge Globally in Imperfect-Information Extensive-Form Games'},Fivos Kalogiannis; Gabriele Farina,~Fivos_Kalogiannis1; ~Gabriele_Farina1,"{'value': ['policy gradient methods', 'policy optimization', 'MARL', 'extensive-form games', 'zero-sum extensive-form games', 'imperfect-information', 'PL', 'Polyak- Łojasiewicz', 'natural policy gradient', 'softmax parametrization', 'REINFORCE', 'hidden convexity', 'hidden concave', 'hidden convex']}","{'value': 'Multi-agent reinforcement learning (MARL) has long been seen as inseparable from Markov games (Littman 1994). Yet, the most remarkable achievements of practical MARL have arguably been in extensive-form games (EFGs)---spanning games like Poker, Stratego, and Hanabi. At the same time, little is known about provable equilibrium convergence for MARL algorithms applied to EFGs as they stumble upon the inherent nonconvexity of the optimization landscape and the failure of the value-iteration subroutine in EFGs. To this goal, we utilize contemporary advances in nonconvex optimization theory to prove that regularized alternating policy gradient with (i) *direct policy parametrization*, (ii) *softmax policy parametrization*, and (iii) *softmax policy parametrization with natural policy gradient* updates converge to an approximate Nash equilibrium (NE) in the *last-iterate* in imperfect-information perfect-recall zero-sum EFGs. Namely, we observe that since the individual utilities are concave with respect to the sequence-form strategy, they satisfy gradient dominance w.r.t. the behavioral strategy---or, \\textit{policy}, in reinforcement learning terms. We exploit this structure to further prove that the regularized utility satisfies the much stronger proximal Polyak- Łojasiewicz condition. In turn, we show that the different flavors of alternating policy gradient methods converge to an $\\epsilon$-approximate NE with a number of iterations and trajectory samples that are  polynomial in $1/\\epsilon$ and the natural parameters of the game. Our work is a preliminary---yet principled---attempt in bridging the conceptual gap between the theory of Markov and imperfect-information EFGs while it aspires to stimulate a deeper dialogue between them.'}",https://openreview.net{'value': '/pdf/17954acd345b0c815841fa019cdc61241787627d.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=VIf1Ygh1Pv,{'value': 'CORAL: Disentangling Latent Representations in Long-Tailed Diffusion'},Esther Rodriguez; Monica Welfert; Samuel McDowell; Nathan Stromberg; Julian Antolin Camarena; Lalitha Sankar,~Esther_Rodriguez1; ~Monica_Welfert1; ~Samuel_McDowell1; ~Nathan_Stromberg1; ~Julian_Antolin_Camarena1; ~Lalitha_Sankar2,"{'value': ['Diffusion', 'Latent', 'Contrastive', 'Metric Learning', 'Long-Tailed', 'Imbalanced', 'Generative Models', 'Classifier-Free Guidance']}","{'value': 'Diffusion models have achieved impressive performance in generating high-quality and diverse synthetic data. However, their success typically assumes a class-balanced training distribution. In real-world settings, multi-class data often follow a long-tailed distribution, where standard diffusion models struggle—producing low-diversity and lower-quality samples for underrepresented (tail) classes. While this degradation is well-documented, its underlying cause remains poorly understood. In this work, we investigate the behavior of diffusion models trained on long-tailed datasets and identify a key issue: the latent representations (from the bottleneck layer of the U-Net) for tail class subspaces exhibit significant overlap with those of head classes, leading to feature borrowing and poor generation quality. Importantly, we show that this is not merely due to limited data per class, but that the relative class imbalance significantly contributes to this phenomenon. To address this, we propose **CO**ntrastive **R**egularization for **A**ligning **L**atents (CORAL), a contrastive latent alignment framework that leverages supervised contrastive losses to encourage well-separated latent class representations. Experiments demonstrate that CORAL significantly improves both the diversity and visual quality of samples generated for tail classes relative to state-of-the-art methods.'}",https://openreview.net{'value': '/pdf/e3416267c09392ef6e0188579d96c37e21818c96.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=VIP5mV8x0b,{'value': 'When Does Curriculum Learning Help? A Theoretical Perspective'},Raman Arora; Yunjuan Wang; Kaibo Zhang,~Raman_Arora1; ~Yunjuan_Wang1; ~Kaibo_Zhang3,{'value': ['curriculum learning; learning theory; generalization; biased regularization; convex learning problems']},"{'value': 'Curriculum learning has emerged as an effective strategy to enhance the training efficiency and generalization of machine learning models. However, its theoretical underpinnings remain relatively underexplored. In this work, we develop a theoretical framework for curriculum learning based on biased regularized empirical risk minimization (RERM), identifying conditions under which curriculum learning provably improves generalization. We introduce a sufficient condition that characterizes a ""good""   curriculum and analyze a multi-task curriculum framework, where solving a sequence of convex tasks can facilitate better generalization. We also demonstrate how these theoretical insights translate to practical benefits when using stochastic gradient descent (SGD) as an optimization method. Beyond convex settings, we explore the utility of curriculum learning for non-convex tasks. Empirical evaluations on synthetic datasets and MNIST validate our theoretical findings and highlight the practical efficacy of curriculum-based training.'}",https://openreview.net{'value': '/pdf/0ef164d4bf4883f485cf2963d2d6dc500951d7e8.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=VHWmDTYI2O,{'value': 'Non-Adaptive Adversarial Face Generation'},Sunpill Kim; Seunghun Paik; Chanwoo Hwang; Minsu Kim; Jae Hong Seo,~Sunpill_Kim1; ~Seunghun_Paik1; ~Chanwoo_Hwang1; ~Minsu_Kim5; ~Jae_Hong_Seo1,"{'value': ['adversarial attack', 'face recognition', 'non-adaptive attack']}","{'value': 'Adversarial attacks on face recognition systems (FRSs) pose serious security and privacy threats, especially when these systems are used for identity verification. In this paper, we propose a novel method for generating adversarial faces—synthetic facial images that are visually distinct yet recognized as a target identity by the FRS. Unlike iterative optimization-based approaches (e.g., gradient descent or other iterative solvers), our method leverages the structural characteristics of the FRS feature space. We figure out that individuals sharing the same attribute (e.g., gender or race) form an attributed subsphere. By utilizing such subspheres, our method achieves both non-adaptiveness and a remarkably small number of queries. This eliminates the need for relying on transferability and open-source surrogate models, which have been a typical strategy when repeated adaptive queries to commercial FRSs are impossible. Despite requiring only a single non-adaptive query consisting of 100 face images, our method achieves a high success rate of over 93% against AWS’s CompareFaces API at its default threshold. Furthermore, unlike many existing attacks that perturb a given image, our method can deliberately produce adversarial faces that impersonate the target identity while exhibiting high-level attributes chosen by the adversary.'}",https://openreview.net{'value': '/pdf/faf5d1e4cb9b5f92713228417573880ee8afdca6.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=VCTt5DXiBe,{'value': 'Generative Trajectory Stitching through Diffusion Composition'},Yunhao Luo; Utkarsh Aashu Mishra; Yilun Du; Danfei Xu,~Yunhao_Luo1; ~Utkarsh_Aashu_Mishra2; ~Yilun_Du1; ~Danfei_Xu1,"{'value': ['Trajectory Stitching', 'Diffusion Models', 'Compositionality', 'Planning']}","{'value': 'Effective trajectory stitching for long-horizon planning is a significant challenge in robotic decision-making. While diffusion models have shown promise in planning, they are limited to solving tasks similar to those seen in their training data. We propose CompDiffuser, a novel generative approach that can solve new tasks by learning to compositionally stitch together shorter trajectory chunks from previously seen tasks. Our key insight is modeling the trajectory distribution by subdividing it into overlapping chunks and learning their conditional relationships through a single bidirectional diffusion model. This allows information to propagate between segments during generation, ensuring physically consistent connections. We conduct experiments on benchmark tasks of various difficulties, covering different environment sizes, agent state dimension, trajectory types, training data quality, and show that CompDiffuser significantly outperforms existing methods.'}",https://openreview.net{'value': '/pdf/6b15dc923dc45c7e34e4a4d254a153f120ef2b1a.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=VA5P0rUZPx,{'value': 'LLM-Explorer: A Plug-in Reinforcement Learning Policy Exploration Enhancement Driven by Large Language Models'},Qianyue Hao; Yiwen Song; Qingmin Liao; Jian Yuan; Yong Li,~Qianyue_Hao1; ~Yiwen_Song2; ~Qingmin_Liao1; ~Jian_Yuan1; ~Yong_Li7,"{'value': ['Reinforcement learning', 'large language model', 'policy exploration']}","{'value': ""Policy exploration is critical in reinforcement learning (RL), where existing approaches include $\\epsilon$-greedy, Gaussian process, etc.\nHowever, these approaches utilize preset stochastic processes and are indiscriminately applied in all kinds of RL tasks without considering task-specific features that influence policy exploration. Moreover, during RL training, the evolution of such stochastic processes is rigid, which typically only incorporates a decay in the variance, failing to adjust flexibly according to the agent's real-time learning status.\nInspired by the analyzing and reasoning capability of large language models (LLMs), we design **LLM-Explorer** to adaptively generate task-specific exploration strategies with LLMs, enhancing the policy exploration in RL. In our design, we sample the learning trajectory of the agent during the RL training in a given task and prompt the LLM to analyze the agent's current policy learning status and then generate a probability distribution for future policy exploration. Updating the probability distribution periodically, we derive a stochastic process specialized for the particular task and dynamically adjusted to adapt to the learning process. Our design is a plug-in module compatible with various widely applied RL algorithms, including the DQN series, DDPG, TD3, and any possible variants developed based on them. Through extensive experiments on the Atari and MuJoCo benchmarks, we demonstrate LLM-Explorer's capability to enhance RL policy exploration, achieving an average performance improvement up to 37.27%. Our code is open-source at https://github.com/tsinghua-fib-lab/LLM-Explorer for reproducibility.""}",https://openreview.net{'value': '/pdf/64ba671c860d8032b21824e28d00916c3e613964.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=V8sDJ1oMEy,{'value': 'VT-FSL: Bridging Vision and Text with LLMs for Few-Shot Learning'},Wenhao Li; Qiangchang Wang; Xianjing Meng; Zhibin Wu; Yilong Yin,~Wenhao_Li19; ~Qiangchang_Wang1; ~Xianjing_Meng1; ~Zhibin_Wu1; ~Yilong_Yin1,"{'value': ['Few-Shot Learning', 'Multimodal Fusion', 'LLM']}","{'value': 'Few-shot learning (FSL) aims to recognize novel concepts from only a few labeled support samples. Recent studies enhance support features by incorporating additional semantic information  (e.g., class descriptions) or designing complex semantic fusion modules. However, these methods still suffer from hallucinating semantics that contradict the visual evidence due to the lack of grounding in actual instances, resulting in noisy guidance and costly corrections. To address these issues, we propose a novel framework, bridging Vision and Text with LLMs for Few-Shot Learning (VT-FSL), which constructs precise cross-modal prompts conditioned on Large Language Models (LLMs) and support images, seamlessly integrating them through a geometry-aware alignment mechanism. It mainly consists of Cross-modal Iterative Prompting (CIP) and Cross-modal Geometric Alignment (CGA). Specifically, the CIP conditions an LLM on both class names and support images to generate precise class descriptions iteratively in a single  structured reasoning pass. These descriptions not only enrich the semantic understanding of novel classes but also enable the zero-shot synthesis of semantically consistent images. The descriptions and synthetic images act respectively as complementary textual and visual prompts, providing high-level class semantics and low-level intra-class diversity to compensate for limited support data. Furthermore, the CGA jointly aligns the fused textual, support, and synthetic visual representations by minimizing the kernelized volume of the 3-dimensional parallelotope they span. It captures global and nonlinear relationships among all representations, enabling structured and consistent multimodal integration. The proposed VT-FSL method establishes new state-of-the-art performance across ten diverse benchmarks, including standard, cross-domain, and fine-grained few-shot learning scenarios. Code is available at https://github.com/peacelwh/VT-FSL.'}",https://openreview.net{'value': '/pdf/521c2d2f24d89aa54641a2bb0276e4fd1a5cebf4.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=V5efEA8nIr,{'value': 'Spike4DGS: Towards High-Speed Dynamic Scene Rendering with 4D Gaussian Splatting via a Spike Camera Array'},Qinghong Ye; Yiqian Chang; Jianing Li; Haoran Xu; Xuan Wang; Wei Zhang; Yonghong Tian; Peixi Peng,~Qinghong_Ye1; ~Yiqian_Chang1; ~Jianing_Li4; ~Haoran_Xu5; ~Xuan_Wang8; ~Wei_Zhang78; ~Yonghong_Tian1; ~Peixi_Peng2,{'value': ['High-speed scene; Novel view synthesis; Multiple views; Spike camera']},"{'value': 'Spike camera with high temporal resolution offers a new perspective on high-speed dynamic scene rendering. Most existing rendering methods rely on Neural Radiance Fields (NeRF) or 3D Gaussian Splatting (3DGS) for static scenes using a monocular spike camera. However, these methods struggle with dynamic motion, while a single camera suffers from limited spatial coverage, making it challenging to reconstruct fine details in high-speed scenes. To address these problems, we propose Spike4DGS, the first high-speed dynamic scene rendering framework with 4D Gaussian Splatting using spike camera arrays. Technically, we first build a multi-view spike camera array to validate our solution, then establish both synthetic and real-world multi-view spike-based reconstruction datasets. Then, we design a multi-view spike-based dense initialization module that obtains dense point clouds and camera poses from continuous spike streams. Finally, we propose a spike-pixel synergy constraint supervision to optimize Spike4DGS, incorporating both rendered image quality loss and dynamic spatiotemporal spike loss. The results show that our Spike4DGS outperforms state-of-the-art methods in terms of novel view rendering quality on both synthetic and real-world datasets. More details are available at https://github.com/Qinghongye/Spike4DGS.'}",https://openreview.net{'value': '/pdf/eafaace25bc14b856bfab3b03a0f505e5f676f25.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=V0lnRCH73U,{'value': 'Breaking the Gradient Barrier: Unveiling Large Language Models for Strategic Classification'},Xinpeng Lv; Yunxin Mao; Haoxuan Li; KE LIANG; Jinxuan Yang; Wanrong Huang; Haoang Chi; Huan Chen; Long Lan; Cyuanlong; Wenjing Yang; Haotian Wang,~Xinpeng_Lv1; ~Yunxin_Mao1; ~Haoxuan_Li6; ~KE_LIANG1; ~Jinxuan_Yang1; ~Wanrong_Huang1; ~Haoang_Chi1; ~Huan_Chen1; ~Long_Lan2; ~Cyuanlong1; ~Wenjing_Yang1; ~Haotian_Wang2,"{'value': ['strategic classification', 'machine learning', 'LLMs']}","{'value': 'Strategic classification (SC) explores how individuals or entities modify their features strategically to achieve favorable classification outcomes. However, existing SC methods, which are largely based on linear models or shallow neural networks, face significant limitations in terms of scalability and capacity when applied to real-world datasets with significantly increasing scale, especially in financial services and the internet sector. \nIn this paper, we investigate how to leverage large language models to design a more scalable and efficient SC framework, especially in the case of growing individuals engaged with decision-making processes. Specifically, we introduce GLIM, a gradient-free SC method grounded in in-context learning. \nDuring the feed-forward process of self-attention, GLIM implicitly simulates the typical bi-level optimization process of SC, including both the feature manipulation and decision rule optimization. \nWithout fine-tuning the LLMs, our proposed GLIM enjoys the advantage of cost-effective adaptation in dynamic strategic environments. Theoretically, we prove GLIM can support pre-trained LLMs to adapt to a broad range of strategic manipulations. We validate our approach through experiments with a collection of pre-trained LLMs on real-world and synthetic datasets in financial and internet domains, demonstrating that our GLIM exhibits both robustness and efficiency, and offering an effective solution for large-scale SC tasks.'}",https://openreview.net{'value': '/pdf/92e89c149499e54f937df5a1da5b3c934948757d.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=Uon41HfqR3,"{'value': 'Many Minds, One Goal: Time Series Forecasting via Sub-task Specialization and Inter-agent Cooperation'}",Qihe Huang; Zhengyang Zhou; Yangze Li; Kuo Yang; Binwu Wang; Yang Wang,~Qihe_Huang2; ~Zhengyang_Zhou1; ~Yangze_Li2; ~Kuo_Yang2; ~Binwu_Wang1; ~Yang_Wang32,{'value': ['time series forecasting']},"{'value': 'Time series forecasting is a critical and complex task, characterized by diverse temporal patterns, varying statistical properties, and different prediction horizons across datasets and domains. Conventional approaches typically rely on a single, unified model architecture to handle all forecasting scenarios. However, such monolithic models struggle to generalize across dynamically evolving time series with shifting patterns. In reality, different types of time series may require distinct modeling strategies. Some benefit from homogeneous multi-scale forecasting awareness, while others rely on more complex and heterogeneous signal perception. Relying on a single model to capture all temporal diversity and structural variations leads to limited  performance and poor interpretability. To address this challenge, we propose a Multi-Agent Forecasting System (MAFS) that abandons the one-size-fits-all paradigm. MAFS decomposes the forecasting task into multiple sub-tasks, each handled by a dedicated agent trained on specific temporal perspectives (e.g., different forecasting resolutions or signal characteristics).  Furthermore, to achieve holistic forecasting, agents share and refine information through different communication topology, enabling cooperative reasoning across different temporal views. A lightweight voting aggregator then integrates their outputs into consistent final predictions. Extensive experiments across 11 benchmarks demonstrate that MAFS significantly outperforms traditional single-model approaches, yielding more robust and adaptable forecasts.'}",https://openreview.net{'value': '/pdf/703b1261fdea6ed1048e2c011db26cfa5a8ecae0.pdf'},{'abstract_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=UXc87Orcri,{'value': 'MetaGS: A Meta-Learned Gaussian-Phong Model for Out-of-Distribution 3D Scene Relighting'},Yumeng He; Yunbo Wang,~Yumeng_He1; ~Yunbo_Wang2,"{'value': ['Neural rendering', '3D relighting', 'meta-learning']}","{'value': 'Out-of-distribution (OOD) 3D relighting requires novel view synthesis under unseen lighting conditions that differ significantly from the observed images. Existing relighting methods, which assume consistent light source distributions between training and testing, often degrade in OOD scenarios. We introduce **MetaGS** to tackle this challenge from two perspectives. First, we propose a meta-learning approach to train 3D Gaussian splatting, which explicitly promotes learning generalizable Gaussian geometries and appearance attributes across diverse lighting conditions, even with biased training data. Second, we embed fundamental physical priors from the *Blinn-Phong* reflection model into Gaussian splatting, which enhances the decoupling of shading components and leads to more accurate 3D scene reconstruction. Results on both synthetic and real-world datasets demonstrate the effectiveness of MetaGS in challenging OOD relighting tasks, supporting efficient point-light relighting and generalizing well to unseen environment lighting maps.'}",https://openreview.net{'value': '/pdf/675dbaee7a026ed452592654e399e8d651729a04.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=UTGjik64IK,{'value': 'Distillation Robustifies Unlearning'},Bruce W. Lee; Addie Foote; Alex Infanger; Leni Shor; Harish K Kamath; Jacob Goldman-Wetzler; Bryce Woodworth; Alex Cloud; Alexander Matt Turner,~Bruce_W._Lee1; ~Addie_Foote1; ~Alex_Infanger1; ~Leni_Shor1; ~Harish_K_Kamath1; ~Jacob_Goldman-Wetzler1; ~Bryce_Woodworth1; ~Alex_Cloud1; ~Alexander_Matt_Turner1,"{'value': ['machine unlearning', 'robust unlearning', 'relearning attacks', 'AI safety', 'alignment', 'distillation']}","{'value': 'Current LLM unlearning methods are not robust. A few steps of finetuning can revert their effects. We begin by showing that this is true even for an idealized form of unlearning: training to imitate a model that was never trained on unwanted information. This shows that training a model can drastically modify its input-output behavior while leaving its underlying capabilities intact. In light of this dynamic, we show our main result. Training a randomly initialized student on the outputs of an unlearned model transfers behaviors while leaving latent capabilities behind. In short, distillation robustifies unlearning. Based on this result, we propose Unlearn-Noise-Distill-on-Outputs (UNDO), a scalable method that distills an unlearned model into a noised copy of itself. UNDO introduces a tunable tradeoff between compute cost and robustness, establishing a new Pareto frontier on synthetic language and arithmetic tasks. At its strongest setting, UNDO matches the robustness of a model retrained from scratch with perfect data filtering while using only 60-80% of the compute and requiring only 0.01% of the pretraining data to be labeled. We also show that UNDO robustifies unlearning on the more realistic Weapons of Mass Destruction Proxy (WMDP) benchmark. Since distillation is widely used in practice, incorporating an unlearning step beforehand offers a convenient path to robust capability removal.'}",https://openreview.net{'value': '/pdf/0115d208300490bee5980b552b16a418fc04b102.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=UKt31LbRPI,{'value': 'When Are Concepts Erased From Diffusion Models?'},Kevin Lu; Nicky Kriplani; Rohit Gandikota; Minh Pham; David Bau; Chinmay Hegde; Niv Cohen,~Kevin_Lu5; ~Nicky_Kriplani1; ~Rohit_Gandikota1; ~Minh_Pham3; ~David_Bau1; ~Chinmay_Hegde1; ~Niv_Cohen1,{'value': ['Concept Erasure']},"{'value': ""In concept erasure, a model is modified to selectively prevent it from generating a target concept. Despite the rapid development of new methods, it remains unclear how thoroughly these approaches remove the target concept from the model. We begin by proposing two conceptual models for the erasure mechanism in diffusion models: (i) interfering with the model’s internal guidance processes, and (ii) reducing the unconditional likelihood of generating the target concept, potentially removing it entirely. To assess whether a concept has been truly erased from the model, we introduce a comprehensive suite of independent probing techniques: supplying visual context, modifying the diffusion trajectory, applying classifier guidance, and analyzing the model's alternative generations that emerge in place of the erased concept. Our results shed light on the value of exploring concept erasure robustness outside of adversarial text inputs, and emphasize the importance of comprehensive evaluations for erasure in diffusion models.""}",https://openreview.net{'value': '/pdf/c050e5998dbf1bf48a5bad71927470dc1362ec37.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=U88JlpY0vR,{'value': 'MesaTask: Towards Task-Driven Tabletop Scene Generation via 3D Spatial Reasoning'},Jinkun Hao; Naifu Liang; Zhen Luo; Xudong XU; Weipeng Zhong; Ran Yi; Yichen Jin; Zhaoyang Lyu; Feng Zheng; Lizhuang Ma; Jiangmiao Pang,~Jinkun_Hao1; ~Naifu_Liang1; ~Zhen_Luo2; ~Xudong_XU1; ~Weipeng_Zhong1; ~Ran_Yi1; ~Yichen_Jin1; ~Zhaoyang_Lyu1; ~Feng_Zheng1; ~Lizhuang_Ma1; ~Jiangmiao_Pang1,"{'value': ['3D scene generation', '3D', 'Tabletop Scene Generation', 'Tabletop Dataset']}","{'value': 'The ability of robots to interpret human instructions and execute manipulation tasks necessitates the availability of task-relevant tabletop scenes for training. However, traditional methods for creating these scenes rely on time-consuming manual layout design or purely randomized layouts, which are limited in terms of plausibility or alignment with the tasks. In this paper, we formulate a novel task, namely task-oriented tabletop scene generation, which poses significant challenges due to the substantial gap between high-level task instructions and the tabletop scenes. To support research on such a challenging task, we introduce \\textbf{MesaTask-10K}, a large-scale dataset comprising approximately 10,700 synthetic tabletop scenes with \\emph{manually crafted layouts} that ensure realistic layouts and intricate inter-object relations. To bridge the gap between tasks and scenes, we propose a \\textbf{Spatial Reasoning Chain} that decomposes the generation process into object inference, spatial interrelation reasoning, and scene graph construction for the final 3D layout. We present \\textbf{MesaTask}, an LLM-based framework that utilizes this reasoning chain and is further enhanced with DPO algorithms to generate physically plausible tabletop scenes that align well with given task descriptions. Exhaustive experiments demonstrate the superior performance of MesaTask compared to baselines in generating task-conforming tabletop scenes with realistic layouts.'}",https://openreview.net{'value': '/pdf/094b02e3ef77b10aa88b9a149588ac30f57b6cee.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=U7ab14f4YQ,{'value': 'Split Gibbs Discrete Diffusion Posterior Sampling'},Wenda Chu; Zihui Wu; Yifan Chen; Yang Song; Yisong Yue,~Wenda_Chu1; ~Zihui_Wu2; ~Yifan_Chen5; ~Yang_Song1; ~Yisong_Yue1,"{'value': ['discrete diffusion model', 'posterior sampling', 'inverse problem']}","{'value': 'We study the problem of posterior sampling in discrete-state spaces using discrete diffusion models. While posterior sampling methods for continuous diffusion models have achieved remarkable progress, analogous methods for discrete diffusion models remain challenging. In this work, we introduce a principled plug-and-play discrete diffusion posterior sampling algorithm based on split Gibbs sampling, which we call SGDD. Our algorithm enables reward-guided generation and solving inverse problems in discrete-state spaces. We demonstrate the convergence of SGDD to the target posterior distribution and verify this through controlled experiments on synthetic benchmarks. Our method enjoys state-of-the-art posterior sampling performance on a range of benchmarks for discrete data, including DNA sequence design, discrete image inverse problems, and music infilling, achieving more than 30% improved performance compared to existing baselines.'}",https://openreview.net{'value': '/pdf/fe5e4234d90a705091f6f04b22d72b90cc84e8bc.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=U5w9l0yQdo,{'value': 'Score-informed Neural Operator for Enhancing Ordering-based Causal Discovery'},Jiyeon Kang; Songseong Kim; Chanhui Lee; Doyeong Hwang; Joanie Hayoun Chung; Yunkyung Ko; Sumin Lee; Sungwoong Kim; Sungbin Lim,~Jiyeon_Kang3; ~Songseong_Kim1; ~Chanhui_Lee2; ~Doyeong_Hwang2; ~Joanie_Hayoun_Chung1; ~Yunkyung_Ko1; ~Sumin_Lee6; ~Sungwoong_Kim2; ~Sungbin_Lim1,"{'value': ['Causal Discovery', 'Score Matching', 'Diffusion Models', 'Neural Operator']}","{'value': ""Ordering-based approaches to causal discovery identify topological orders of causal graphs, providing scalable alternatives to combinatorial search methods. Under the Additive Noise Models (ANMs) assumption, recent causal ordering methods based on score matching require an accurate estimation of the Hessian diagonal of the log-densities. However, previous approaches mainly use Stein gradient estimators, which are computationally expensive and memory-intensive. Although DiffAN addresses these limitations by substituting kernel-based estimates with diffusion models, it remains numerically unstable due to the second-order derivatives of score models. To alleviate these problems, we propose Score-informed Neural Operator (SciNO), a probabilistic generative model in smooth function spaces designed to stably approximate the Hessian diagonal and to preserve structural information during the score modeling. \nEmpirical results show that SciNO reduces order divergence by 42.7% on synthetic graphs and by 31.5% in real-world datasets on average compared to DiffAN, while maintaining memory efficiency and scalability. Furthermore, we propose a probabilistic control algorithm for causal reasoning with autoregressive models that integrates SciNO's probability estimates with autoregressive model priors, enabling reliable data-driven causal ordering informed by semantic information. Consequently, the proposed method enhances causal reasoning abilities of LLMs without additional fine-tuning or prompt engineering.""}",https://openreview.net{'value': '/pdf/b84c8673c274ce40a61269ee1f5ff8e3069be7ce.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=TrNB08KuHK,{'value': 'Training-Free Constrained Generation With Stable Diffusion Models'},Stefano Zampini; Jacob K Christopher; Luca Oneto; Davide Anguita; Ferdinando Fioretto,~Stefano_Zampini1; ~Jacob_K_Christopher1; ~Luca_Oneto1; ~Davide_Anguita2; ~Ferdinando_Fioretto1,"{'value': ['Stable Diffusion', 'Constrained Generation', 'Differentiable Optimization']}","{'value': 'Stable diffusion models represent the state-of-the-art in data synthesis across diverse domains and hold transformative potential for applications in science and engineering, e.g., by facilitating the discovery of novel solutions and simulating systems that are computationally intractable to model explicitly. While there is increasing effort to incorporate physics-based constraints into generative models, existing techniques are either limited in their applicability to latent diffusion frameworks or lack the capability to strictly enforce domain-specific constraints. To address this limitation this paper proposes a novel integration of stable diffusion models with constrained optimization frameworks, enabling the generation of outputs satisfying stringent physical and functional requirements. The effectiveness of this approach is demonstrated through material design experiments requiring adherence to precise morphometric properties, challenging inverse design tasks involving the generation of materials inducing specific stress-strain responses, and copyright-constrained content generation tasks. All code has been released at https://github.com/RAISELab-atUVA/Constrained-Stable-Diffusion.'}",https://openreview.net{'value': '/pdf/fe2309484ca87adfc6434f42e5b2fb59b6eaf125.pdf'},{'abstract_filter': 'Data Synthesis'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=ToNRHqX6xq,{'value': 'MIP against Agent: Malicious Image Patches Hijacking Multimodal OS Agents'},Lukas Aichberger; Alasdair Paren; Guohao Li; Philip Torr; Yarin Gal; Adel Bibi,~Lukas_Aichberger1; ~Alasdair_Paren1; ~Guohao_Li1; ~Philip_Torr1; ~Yarin_Gal1; ~Adel_Bibi1,"{'value': ['OS', 'agents', 'LLM', 'VLM', 'api', 'tool use', 'adversarial attack', 'adversarial images', 'malicious image patches', 'MIP', 'robustness', 'safety', 'security', 'trustworthiness']}","{'value': 'Recent advances in operating system (OS) agents have enabled vision-language models (VLMs) to directly control a user’s computer. Unlike conventional VLMs that passively output text, OS agents autonomously perform computer-based tasks in response to a single user prompt. OS agents do so by capturing, parsing, and analysing screenshots and executing low-level actions via application programming interfaces (APIs), such as mouse clicks and keyboard inputs. This direct interaction with the OS significantly raises the stakes, as failures or manipulations can have immediate and tangible consequences. In this work, we uncover a novel attack vector against these OS agents: Malicious Image Patches (MIPs), adversarially perturbed screen regions that, when captured by an OS agent, induce it to perform harmful actions by exploiting specific APIs. For instance, a MIP can be embedded in a desktop wallpaper or shared on social media to cause an OS agent to exfiltrate sensitive user data. We show that MIPs generalise across user prompts and screen configurations, and that they can hijack multiple OS agents even during the execution of benign instructions. These findings expose critical security vulnerabilities in OS agents that have to be carefully addressed before their widespread deployment.'}",https://openreview.net{'value': '/pdf/9a3fb73f2583fb6ee0e586d6ef2376e5ccf66943.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=TecJ926Vgn,{'value': 'Differentially Private Federated Low Rank Adaptation Beyond Fixed-Matrix'},Ming Wen; Jiaqi Zhu; Yuedong Xu; Yipeng Zhou; DINGDING HAN,~Ming_Wen2; ~Jiaqi_Zhu12; ~Yuedong_Xu1; ~Yipeng_Zhou1; ~DINGDING_HAN1,"{'value': ['Federated Learning', 'Low-Rank Adaptation', 'Differential Privacy']}","{'value': ""Large language models (LLMs) typically require fine-tuning for domain-specific tasks, and LoRA offers a computationally efficient approach by training low-rank adaptors. LoRA is also communication-efficient for federated LLMs when multiple users collaboratively fine-tune a global LLM model without sharing their proprietary raw data. However, even the transmission of local adaptors between a server and clients risks serious privacy leakage. Applying differential privacy (DP) to federated LoRA encounters a dilemma: adding noise to both adaptors amplifies synthetic noise on the model, while fixing one adaptor impairs the learnability of fine-tuning. In this paper, we propose FedASK (Differentially Private Federated Low Rank Adaptation with Double SKetching) , a novel federated LoRA framework to enable effective updating of both low-rank adaptor matrices with robust differential privacy. Inspired by randomized SVD, our key idea is a two-stage sketching pipeline. This pipeline first aggregates carefully sketched, privacy-preserving local updates, and then reconstructs the global matrices on the server to facilitate effective updating of both adaptors. We theoretically prove FedASK's differential privacy guarantee and its exact aggregation property. Comprehensive experiments demonstrate that FedASK consistently outperforms baseline methods across a variety of privacy settings and data distributions.""}",https://openreview.net{'value': '/pdf/62884b1154dedb952f5521fa89f03730716eaf31.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=TdmzrkdLG0,{'value': 'LLM Interpretability with Identifiable Temporal-Instantaneous Representation'},Xiangchen Song; Jiaqi Sun; Zijian Li; Yujia Zheng; Kun Zhang,~Xiangchen_Song1; ~Jiaqi_Sun1; ~Zijian_Li1; ~Yujia_Zheng1; ~Kun_Zhang1,"{'value': ['identifiability', 'causal representation learning', 'large language models', 'interpretability']}","{'value': ""Despite Large Language Models' remarkable capabilities, understanding their internal representations remains challenging. Mechanistic interpretability tools such as sparse autoencoders (SAEs) were developed to extract interpretable features from LLMs but lack temporal dependency modeling, instantaneous relation representation, and more importantly theoretical guarantees—undermining both the theoretical foundations and the practical confidence necessary for subsequent analyses. While causal representation learning (CRL) offers theoretically-grounded approaches for uncovering latent concepts, existing methods cannot scale to LLMs' rich conceptual space due to inefficient computation. To bridge the gap, we introduce an identifiable temporal causal representation learning framework specifically designed for LLMs' high-dimensional concept space, capturing both time-delayed and instantaneous causal relations. Our approach provides theoretical guarantees and demonstrates efficacy on synthetic datasets scaled to match real-world complexity. By extending SAE techniques with our temporal causal framework, we successfully discover meaningful concept relationships in LLM activations. Our findings show that modeling both temporal and instantaneous conceptual relationships advances the interpretability of LLMs.""}",https://openreview.net{'value': '/pdf/5dca3120937517fede013fac024695372ebd078c.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=TRHT8ksdUQ,{'value': 'How Patterns Dictate Learnability in Sequential Data'},Mario Morawski; Anaïs Després; Remi Rehm,~Mario_Morawski1; ~Anaïs_Després1; ~Remi_Rehm1,"{'value': ['Time Series', 'Sequential Data', 'Autoregressive Models', 'Mutual Information', 'Generalization Error']}","{'value': 'Sequential data—ranging from financial time series to natural language—has driven the growing adoption of autoregressive models. However, these algorithms rely on the presence of underlying patterns in the data, and their identification often depends heavily on human expertise. Misinterpreting these patterns can lead to model misspecification, resulting in increased generalization error and degraded performance. The recently proposed $\\texttt{evolving pattern (EvoRate)}$ metric addresses this by using the mutual information between the next data point and its past to guide regression order estimation and feature selection. Building on this idea, we introduce a general framework based on predictive information—the mutual information between the past and the future, $\\mathbf{I}(X_{\\text{past}}; X_{\\text{future}})$. This quantity naturally defines an information-theoretic learning curve, which quantifies the amount of predictive information available as the observation window grows. Using this formalism, we show that the presence or absence of temporal patterns fundamentally constrains the learnability of sequential models: even an optimal predictor cannot outperform the intrinsic information limit imposed by the data. We validate our framework through experiments on synthetic data, demonstrating its ability to assess model adequacy, quantify the inherent complexity of a dataset, and reveal interpretable structure in sequential data.'}",https://openreview.net{'value': '/pdf/f597d83ff2b5f68ef4093952d1d32de5accdc7da.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=T3DF4yxcPz,{'value': 'Multiscale guidance of protein structure prediction with heterogeneous cryo-EM data'},Rishwanth Raghu; Axel Levy; Gordon Wetzstein; Ellen D Zhong,~Rishwanth_Raghu1; ~Axel_Levy1; ~Gordon_Wetzstein3; ~Ellen_D_Zhong1,"{'value': ['Computational Biology and Bioinformatics', 'Generative Models']}","{'value': 'Protein structure prediction models are now capable of generating accurate 3D structural hypotheses from sequence alone. However, they routinely fail to capture the conformational diversity of dynamic biomolecular complexes, often requiring heuristic MSA subsampling approaches for generating alternative states. In parallel, cryo-electron microscopy (cryo-EM) has emerged as a powerful tool for imaging near-native structural heterogeneity, but is challenged by arduous pipelines to transform raw experimental data into atomic models. Here, we bridge the gap between these modalities, combining cryo-EM density maps with the rich sequence and biophysical priors learned by protein structure prediction models. Our method, CryoBoltz, guides the sampling trajectory of a pretrained biomolecular structure prediction model using both global and local structural constraints derived from density maps, driving predictions towards conformational states consistent with the experimental data. We demonstrate that this flexible yet powerful inference-time approach allows us to build atomic models into heterogeneous cryo-EM maps across a variety of dynamic biomolecular systems including transporters and antibodies.'}",https://openreview.net{'value': '/pdf/83496421395dceae15d77a0a4ae4dd8ffdd45af4.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=SoqzNbcBjy,{'value': 'Spiral: Semantic-Aware Progressive LiDAR Scene Generation and Understanding'},Dekai Zhu; Yixuan Hu; Youquan Liu; Dongyue Lu; Lingdong Kong; Slobodan Ilic,~Dekai_Zhu1; ~Yixuan_Hu1; ~Youquan_Liu1; ~Dongyue_Lu1; ~Lingdong_Kong1; ~Slobodan_Ilic3,"{'value': ['LiDAR Diffusion', 'LiDAR Generation', 'LiDAR Semantic Segmentation']}","{'value': 'Leveraging diffusion models, 3D LiDAR scene generation has achieved great success in both range-view and voxel-based representations. While recent voxel-based approaches can generate both geometric structures and semantic labels, existing range-view methods are limited to producing unlabeled LiDAR scenes. Relying on pretrained segmentation models to predict the semantic maps often results in suboptimal cross-modal consistency. To address this limitation while preserving the advantages of range-view representations, such as computational efficiency and simplified network design, we propose Spiral, a novel range-view LiDAR diffusion model that simultaneously generates depth, reflectance images, and semantic maps. Furthermore, we introduce novel semantic-aware metrics to evaluate the quality of the generated labeled range-view data. Experiments on SemanticKITTI and nuScenes datasets demonstrate that Spiral achieves state-of-the-art performance with the smallest parameter size, outperforming two-step methods that combine the best available generative and segmentation models. Additionally, we validate that Spiral’s generated range images can be effectively used for synthetic data augmentation in the downstream segmentation training, significantly reducing the labeling effort on LiDAR data.'}",https://openreview.net{'value': '/pdf/b1b7493189ab7bb4d33ec2f618e7c920cfa17565.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=SoA8rMxDaF,{'value': 'Projecting Assumptions: The Duality Between Sparse Autoencoders and Concept Geometry'},Sai Sumedh R. Hindupur; Ekdeep Singh Lubana; Thomas Fel; Demba E. Ba,~Sai_Sumedh_R._Hindupur1; ~Ekdeep_Singh_Lubana1; ~Thomas_Fel2; ~Demba_E._Ba1,"{'value': ['sparse autoencoders', 'dictionary learning', 'interpretability']}","{'value': 'Sparse Autoencoders (SAEs) are widely used to interpret neural networks by identifying meaningful concepts from their representations. However, do SAEs truly uncover all concepts a model relies on, or are they inherently biased toward certain kinds of concepts? We introduce a unified framework that recasts SAEs as solutions to a bilevel optimization problem, revealing a fundamental challenge: each SAE imposes structural assumptions about how concepts are encoded in model representations, which in turn shapes what it can and cannot detect. This means different SAEs are not interchangeable -- switching architectures can expose entirely new concepts or obscure existing ones. To systematically probe this effect, we evaluate SAEs across a spectrum of settings: from controlled toy models that isolate key variables, to semi-synthetic experiments on real model activations and finally to large-scale, naturalistic datasets. Across this progression, we examine two fundamental properties that real-world concepts often exhibit: heterogeneity in intrinsic dimensionality (some concepts are inherently low-dimensional, others are not) and nonlinear separability. We show that SAEs fail to recover concepts when these properties are ignored, and we design a new SAE that explicitly incorporates both, enabling the discovery of previously hidden concepts and reinforcing our theoretical insights. Our findings challenge the idea of a universal SAE and underscores the need for architecture-specific choices in model interpretability. Overall, we argue an SAE does not just reveal concepts -- it determines what can be seen at all.'}",https://openreview.net{'value': '/pdf/b18fbba9aedb50215b3abd3d15b60ad4a615683c.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=Sf5nxMRiG7,{'value': 'Corporate Needs You to Find the Difference: Revisiting Submodular and Supermodular Ratio Optimization Problems'},Elfarouk Harb; Yousef Yassin; Chandra Chekuri,~Elfarouk_Harb1; ~Yousef_Yassin1; ~Chandra_Chekuri1,"{'value': ['densest subgraph', 'densest supermodular set', 'submodular function minimization.']}","{'value': ""We consider the following question: given a submodular or supermodular set function $f:2^V \\to \\mathbb{R}$, how should one minimize or maximize its average value $f(S)/|S|$ over non-empty subsets $S\\subseteq V$? This problem generalizes several well-known objectives including Densest Subgraph (DSG), Densest Supermodular Set (DSS), and Submodular Function Minimization (SFM). Motivated by recent applications [39, 31], we formalize two new broad problems: the Unrestricted Sparsest Submodular Set (USSS) and Unrestricted Densest Supermodular Set (UDSS) which allow negative and non-monotone functions.\n\nUsing classical results we observe that DSS, SFM, USSS, UDSS, and MNP are all equivalent under strongly polynomial-time reductions. This equivalence enables algorithmic cross-over: methods designed for one problem can be repurposed to solve others efficiently. In particular we use the perspective of the minimum norm point in the base polyhedron of a sub/supermodular function which, via Fujishige's results, yields the dense decomposition as a byproduct. Via this perspective we show that a recent converging heuristic for DSS, \\textsc{SuperGreedy++} [15, 29], and Wolfe’s minimum norm point algorithm are both universal solvers for all of these problems. \n\nOn the theoretical front, we explain the observation made in recent work [39, 31] that \\textsc{SuperGreedy++} appears to work well even in settings beyond DSS. Surprisingly, we also show that this simple algorithm can be used for Submodular Function Minimization, including for example that it can act as an effective minimum $st$ cut algorithm. \n\nOn the empirical front, we explore the utility of several different algorithms including Fujishige-Wolfe min-norm point algorithm for recent problems. We conduct over 400 experiments across seven problem types and large-scale synthetic and real-world datasets (up to $\\approx 100$ million edges). Our results reveal that methods historically considered inefficient, such as convex-programming methods, flow-based solvers, and Fujishige-Wolfe’s algorithm, outperform state-of-the-art task-specific baselines by orders of magnitude on concrete problems like HNSN [39]. These findings challenge prevailing assumptions and demonstrate that with the right framing, general optimization algorithms can be both scalable and state-of-the-art for supermodular and submodular ratio problems.""}",https://openreview.net{'value': '/pdf/70b6723ab06ba4aa254ae037c5c3cff5b455bf43.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=SbfdxWibDn,{'value': 'C-NAV: Towards Self-Evolving Continual Object Navigation in Open World'},MingMing Yu; Fei Zhu; wenzhuo liu; Yirong Yang; Qunbo Wang; wenjun wu; Jing Liu,~MingMing_Yu1; ~Fei_Zhu1; ~wenzhuo_liu1; ~Yirong_Yang2; ~Qunbo_Wang1; ~wenjun_wu3; ~Jing_Liu1,"{'value': ['Embodied AI', 'Continue Learning']}","{'value': 'Embodied agents are expected to perform object navigation in dynamic, open-world environments. However, existing approaches typically rely on static trajectories and a fixed set of object categories during training, overlooking the real-world requirement for continual adaptation to evolving scenarios. To facilitate related studies, we introduce the continual object navigation benchmark, which requires agents to acquire navigation skills for new object categories while avoiding catastrophic forgetting of previously learned knowledge. To tackle this challenge, we propose C-Nav, a continual visual navigation framework that integrates two key innovations: (1) A dual-path anti-forgetting mechanism, which comprises feature distillation that aligns multi-modal inputs into a consistent representation space to ensure representation consistency, and feature replay that retains temporal features within the action decoder to ensure policy consistency. (2) An adaptive sampling strategy that selects diverse and informative experiences, thereby reducing redundancy and minimizing memory overhead. Extensive experiments across multiple model architectures demonstrate that C-Nav consistently outperforms existing approaches, achieving superior performance even compared to baselines with full trajectory retention, while significantly lowering memory requirements. \nThe code will be publicly available at \\url{https://bigtree765.github.io/C-Nav-project}.'}",https://openreview.net{'value': '/pdf/4ac4cb06f6085be0e1f670ec7a2d405400da20e8.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=SbGtQpm2vP,{'value': 'Structural Information-based Hierarchical Diffusion for Offline Reinforcement Learning'},Xianghua Zeng; Hao Peng; Yicheng Pan; Angsheng Li; Guanlin Wu,~Xianghua_Zeng1; ~Hao_Peng7; ~Yicheng_Pan1; ~Angsheng_Li1; ~Guanlin_Wu1,"{'value': ['offline reinforcement learning', 'diffusion models', 'structural information principles']}","{'value': 'Diffusion-based generative methods have shown promising potential for modeling trajectories from offline reinforcement learning (RL) datasets, and hierarchical diffusion has been introduced to mitigate variance accumulation and computational challenges in long-horizon planning tasks. However, existing approaches typically assume a fixed two-layer diffusion hierarchy with a single predefined temporal scale, which limits adaptability to diverse downstream tasks and reduces flexibility in decision making. In this work, we propose SIHD, a novel Structural Information-based Hierarchical Diffusion framework for effective and stable offline policy learning in long-horizon environments with sparse rewards. Specifically, we analyze structural information embedded in offline trajectories to construct the diffusion hierarchy adaptively, enabling flexible trajectory modeling across multiple temporal scales. Rather than relying on reward predictions from localized sub-trajectories, we quantify the structural information gain of each state community and use it as a conditioning signal within the corresponding diffusion layer. To reduce overreliance on offline datasets, we introduce a structural entropy regularizer that encourages exploration of underrepresented states while avoiding extrapolation errors from distributional shifts. Extensive evaluations show that SIHD significantly outperforms state-of-the-art baselines in decision-making performance and demonstrates superior generalization across diverse scenarios.'}",https://openreview.net{'value': '/pdf/c098195a570ab9aa8aa8f091223f39fc9eb37728.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=SYKwGnik3w,{'value': 'DyMoDreamer: World Modeling with Dynamic Modulation'},Boxuan Zhang; Runqing Wang; Wei Xiao; Weipu Zhang; Jian Sun; Gao Huang; Jie Chen; Gang Wang,~Boxuan_Zhang3; ~Runqing_Wang1; ~Wei_Xiao6; ~Weipu_Zhang1; ~Jian_Sun7; ~Gao_Huang1; ~Jie_Chen24; ~Gang_Wang17,"{'value': ['Model-based reinforcement learning', 'world model', 'dynamic modulation', 'recurrent state space model']}","{'value': ""A critical bottleneck in deep reinforcement learning (DRL) is sample inefficiency, as training high-performance agents often demands extensive environmental interactions. Model-based reinforcement learning (MBRL) mitigates this by building world models that simulate environmental dynamics and generate synthetic experience, improving sample efficiency. However, conventional world models process observations holistically, failing to decouple dynamic objects and temporal features from static backgrounds. This approach is computationally inefficient, especially for visual tasks where dynamic objects significantly influence rewards and decision-making performance. To address this, we introduce DyMoDreamer, a novel MBRL algorithm that incorporates a dynamic modulation mechanism to improve the extraction of dynamic features and enrich the temporal information. DyMoDreamer employs differential observations derived from a novel inter-frame differencing mask, explicitly encoding object-level motion cues and temporal dynamics. Dynamic modulation is modeled as stochastic categorical distributions and integrated into a recurrent state-space model (RSSM), enhancing the model's focus on reward-relevant dynamics. Experiments demonstrate that DyMoDreamer sets a new state-of-the-art on the Atari $100$k benchmark with a $156.6$\\% mean human-normalized score, establishes a new record of $832$ on the DeepMind Visual Control Suite, and gains a $9.5$\\% performance improvement after $1$M steps on the Crafter benchmark.""}",https://openreview.net{'value': '/pdf/4faa5aa4dc13ce2e74a66d19a97181545d04985f.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=SYDmbsqHI0,{'value': 'MOSDT: Self-Distillation-Based Decision Transformer for Multi-Agent Offline Safe Reinforcement Learning'},Yuchen Xia; Yunjian Xu,~Yuchen_Xia4; ~Yunjian_Xu1,"{'value': ['multi-agent offline safe reinforcement learning', 'decision transformer', 'self-distillation']}","{'value': 'We introduce MOSDT, the first algorithm designed for multi-agent offline safe reinforcement learning (MOSRL), alongside MOSDB, the first dataset and benchmark for this domain. Different from most existing knowledge distillation-based multi-agent RL methods, we propose policy self-distillation (PSD) with a new global information reconstruction scheme by fusing the observation features of all agents, streamlining training and improving parameter efficiency. We adopt full parameter sharing across agents, significantly slashing parameter count and boosting returns up to 38.4-fold by stabilizing training. We propose a new plug-and-play cost binary embedding (CBE) module, which binarizes cumulative costs as safety signals and embeds the signals into return features for efficient information aggregation. On the strong MOSDB benchmark, MOSDT achieves state-of-the-art (SOTA) returns in 14 out of 18 tasks (across all base environments including MuJoCo, Safety Gym, and Isaac Gym) while ensuring complete safety, with only 65% of the execution parameter count of a SOTA single-agent offline safe RL method CDT. Code, dataset, and results are available at this website: https://github.com/Lucian1115/MOSDT.git'}",https://openreview.net{'value': '/pdf/ba9e5784427b11f66cb1caf1650cc37ca0217375.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=SXr3Dynctm,{'value': 'Learning to Insert for Constructive Neural Vehicle Routing Solver'},Fu Luo; Xi Lin; Mengyuan Zhong; Fei Liu; Zhenkun Wang; Jianyong Sun; Qingfu Zhang,~Fu_Luo1; ~Xi_Lin2; ~Mengyuan_Zhong1; ~Fei_Liu14; ~Zhenkun_Wang1; ~Jianyong_Sun2; ~Qingfu_Zhang1,"{'value': ['Neural Combinatorial Optimization', 'Vehicle Routing Problem', 'Insertion-based Construction']}","{'value': ""Neural Combinatorial Optimisation (NCO) is a promising learning-based approach for solving Vehicle Routing Problems (VRPs) without extensive manual design. While existing constructive NCO methods typically follow an appending-based paradigm that sequentially adds unvisited nodes to partial solutions, this rigid approach often leads to suboptimal results. To overcome this limitation, we explore the idea of the insertion-based paradigm and propose Learning to Construct with Insertion-based Paradigm (L2C-Insert), a novel learning-based method for constructive NCO. Unlike traditional approaches, L2C-Insert builds solutions by strategically inserting unvisited nodes at any valid position in the current partial solution, which can significantly enhance the flexibility and solution quality. The proposed framework introduces three key components: a novel model architecture for precise insertion position prediction, an efficient training scheme for model optimization, and an advanced inference technique that fully exploits the insertion paradigm's flexibility. Extensive experiments on both synthetic and real-world instances of the Travelling Salesman Problem (TSP) and Capacitated Vehicle Routing Problem (CVRP) demonstrate that L2C-Insert consistently achieves superior performance across various problem sizes. The code is available at [https://github.com/CIAM-Group/L2C\\_Insert](https://github.com/CIAM-Group/L2C\\_Insert).""}",https://openreview.net{'value': '/pdf/63d036d5c18772b8d7e0057bf03070b8fd0586c8.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=SXCjvhEQZO,{'value': 'On Optimal Steering to Achieve Exact Fairness'},mohit sharma; Amit Deshpande; Chiranjib Bhattacharyya; Rajiv Ratn Shah,~mohit_sharma5; ~Amit_Deshpande1; ~Chiranjib_Bhattacharyya2; ~Rajiv_Ratn_Shah1,"{'value': ['steering', 'fairness', 'representation', 'bayes optimal classifiers', 'data bias', 'ideal distributions']}","{'value': ""To fix the `bias in, bias out' problem in fair machine learning, it is important to steer feature distributions of data or internal representations of Large Language Models (LLMs) to \\emph{ideal} ones that guarantee group-fair outcomes. Previous work on fair generative models and representation steering could greatly benefit from provable fairness guarantees on the model output. We define a distribution as \\emph{ideal} if the minimizer of any cost-sensitive risk on it is guaranteed to have exact group-fair outcomes (e.g., demographic parity, equal opportunity)---in other words, it has no fairness-utility trade-off. We formulate an optimization program for optimal steering by finding the nearest \\emph{ideal} distribution in KL-divergence, and provide efficient algorithms for it when the underlying distributions come from well-known parametric families (e.g., normal, log-normal).\n\nEmpirically, our optimal steering techniques on both synthetic and real-world datasets improve fairness without diminishing utility (and sometimes even improve utility). We demonstrate affine steering of LLM representations to reduce bias in multi-class classification, e.g., occupation prediction from a short biography in Bios dataset (De-Arteaga et al.). Furthermore, we steer internal representations of LLMs towards desired outputs so that it works equally well across different groups.""}",https://openreview.net{'value': '/pdf/4728b468eb1ad668dced2d68c14bdda856a453fe.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=SJPq1xBPHX,{'value': 'PLMTrajRec: A Scalable and Generalizable Trajectory Recovery Method with Pre-trained Language Models'},Tonglong Wei; Yan Lin; Youfang Lin; Shengnan Guo; Jilin Hu; Haitao Yuan; Gao Cong; Huaiyu Wan,~Tonglong_Wei1; ~Yan_Lin1; ~Youfang_Lin1; ~Shengnan_Guo1; ~Jilin_Hu1; ~Haitao_Yuan2; ~Gao_Cong1; ~Huaiyu_Wan1,"{'value': ['Spatio-temporal data mining', 'trajectory data mining', 'vehicle trajectory recovery']}","{'value': 'Spatiotemporal trajectory data is crucial for various traffic-related applications. However, issues such as device malfunctions and network instability often result in sparse trajectories that lose detailed movement information compared to their dense counterparts. Recovering missing points in sparse trajectories is thus essential. Despite recent progress, three challenges remain. First, the lack of large-scale dense trajectory datasets hinders the training of a trajectory recovery model. Second, the varying spatiotemporal correlations in sparse trajectories make it hard to generalize across different sampling intervals. Third, extracting road conditions for missing points is non-trivial.\n\nTo address these challenges, we propose $\\textit{PLMTrajRec}$, a novel trajectory recovery model. It leverages the scalability of a pre-trained language model (PLM) and can effectively recover trajectories by fine-tuning with small-scale dense trajectory datasets. To handle different sampling intervals in sparse trajectories, we first convert sampling intervals and movement features into prompts for the PLM to understand. We then introduce a trajectory encoder to unify trajectories of varying intervals into a single interval. To extract road conditions for missing points, we propose an area flow-guided implicit trajectory prompt that represents traffic conditions in each region, and a road condition passing mechanism that infers the road conditions of missing points using the observed ones. Experiments on four public trajectory datasets with three sampling intervals demonstrate the effectiveness, scalability, and generalization ability of PLMTrajRec. Code is available at https://github.com/wtl52656/PLMTrajRec.'}",https://openreview.net{'value': '/pdf/53adb331daed30a3af87137d1afbda00617909f5.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=S8XcHutp7Z,{'value': 'X-Field: A Physically Informed Representation for 3D X-ray Reconstruction'},Feiran Wang; Jiachen Tao; Junyi Wu; Haoxuan Wang; Bin Duan; Kai Wang; Zongxin Yang; Yan Yan,~Feiran_Wang2; ~Jiachen_Tao1; ~Junyi_Wu1; ~Haoxuan_Wang1; ~Bin_Duan1; ~Kai_Wang8; ~Zongxin_Yang1; ~Yan_Yan6,{'value': ['3D Reconstruction; X-ray']},"{'value': 'X-ray imaging is indispensable in medical diagnostics, yet its use is tightly regulated due to radiation exposure. Recent research borrows representations from the 3D reconstruction area to complete two tasks with reduced radiation dose: X-ray Novel View Synthesis (NVS) and Computed Tomography (CT) reconstruction. \nHowever, these representations fail to fully capture the penetration and attenuation properties of X-ray imaging as they originate from visible light imaging.\nIn this paper, we introduce X-Field, a 3D representation informed in the physics of X-ray imaging. \nFirst, we employ homogeneous 3D ellipsoids with distinct attenuation coefficients to accurately model diverse materials within internal structures. Second, we introduce an efficient path-partitioning algorithm that resolves the intricate intersection of ellipsoids to compute cumulative attenuation along an X-ray path.\nWe further propose a hybrid progressive initialization to refine the geometric accuracy of X-Field and incorporate material-based optimization to enhance model fitting along material boundaries.\nExperiments show that X-Field achieves superior visual fidelity on both real-world human organ and synthetic object datasets, outperforming state-of-the-art methods in X-ray NVS and CT Reconstruction.'}",https://openreview.net{'value': '/pdf/bc7c4d2d1cb4f4214fe15f5397ec6f8cc597aa52.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=S1F2qhendd,{'value': 'Self-Refining Language Model Anonymizers via Adversarial Distillation'},Kyuyoung Kim; Hyunjun Jeon; Jinwoo Shin,~Kyuyoung_Kim1; ~Hyunjun_Jeon1; ~Jinwoo_Shin1,"{'value': ['privacy', 'anonymization', 'distillation', 'large language models', 'small language models']}","{'value': 'Large language models (LLMs) are increasingly used in sensitive domains, where their ability to infer personal data from seemingly benign text introduces emerging privacy risks. While recent LLM-based anonymization methods help mitigate such risks, they often rely on proprietary models (e.g., GPT-4), raising concerns about cost and the potential exposure of sensitive data to untrusted external systems. To address this, we introduce $\\textit{SElf-refining Anonymization with Language model}$ (SEAL), a novel distillation framework for training small language models (SLMs) to perform effective anonymization without relying on external models at inference time. SEAL leverages adversarial interactions between an LLM anonymizer and an inference model to collect trajectories of anonymized texts and inferred attributes, which are then used to distill anonymization and critique capabilities into SLMs through supervised fine-tuning and preference learning. The resulting models learn both to anonymize text and to evaluate their outputs, enabling iterative improvement of anonymization quality via self-refinement. Experiments on SynthPAI, a dataset of synthetic personal profiles and text comments, demonstrate that SLMs trained with SEAL achieve substantial improvements in anonymization capabilities. Notably, 8B models attain a privacy-utility trade-off comparable to that of the GPT-4 anonymizer and, with self-refinement, even surpass it in terms of privacy protection. These results highlight the effectiveness of our adversarial distillation framework for training SLMs as efficient anonymizers.'}",https://openreview.net{'value': '/pdf/3f8a6454ad03b1ebbd65fb27990a3c58e2aa7919.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=Rxdon7jWni,{'value': 'MALinZero: Efficient Low-Dimensional Search for Mastering Complex Multi-Agent Planning'},Sizhe Tang; Jiayu Chen; Tian Lan,~Sizhe_Tang1; ~Jiayu_Chen2; ~Tian_Lan4,"{'value': ['Monte Carlo Tree Search', 'Reinforcement Learning', 'Multi-Agent System']}","{'value': 'Monte Carlo Tree Search (MCTS), which leverages Upper Confidence Bound for Trees (UCTs) to balance exploration and exploitation through randomized sampling, is instrumental to solving complex planning problems. However, for multi-agent planning, MCTS is confronted with a large combinatorial action space that often grows exponentially with the number of agents. As a result, the branching factor of MCTS during tree expansion also increases exponentially, making it very difficult to efficiently explore and exploit during tree search. To this end, we propose MALinZero, a new approach to leverage low-dimensional representational structures on joint-action returns and enable efficient MCTS in complex multi-agent planning. Our solution can be viewed as projecting the joint-action returns into the low-dimensional space representable using a contextual linear bandit problem formulation. We solve the contextual linear bandit problem with convex and $\\mu$-smooth loss functions -- in order to place more importance on better joint actions and mitigate potential representational limitations -- and derive a linear Upper Confidence Bound applied to trees (LinUCT) to enable novel multi-agent exploration and exploitation in the low-dimensional space. We analyze the regret of MALinZero for low-dimensional reward functions and propose an $(1-\\tfrac1e)$-approximation algorithm for the joint action selection by maximizing a sub-modular objective. MALinZero demonstrates state-of-the-art performance on multi-agent benchmarks such as matrix games, SMAC, and SMACv2, outperforming both model-based and model-free multi-agent reinforcement learning baselines with faster learning speed and better performance.'}",https://openreview.net{'value': '/pdf/8e363493ff9d9b3fa837f8d6bb3198fa13ba65f4.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=RwfrdKSgCE,"{'value': 'AI Research Agents for Machine Learning: Search, Exploration, and Generalization in MLE-bench'}",Edan Toledo; Karen Hambardzumyan; Martin Josifoski; RISHI HAZRA; Nicolas Baldwin; Alexis Audran-Reiss; Michael Kuchnik; Despoina Magka; Minqi Jiang; Alisia Maria Lupidi; Andrei Lupu; Roberta Raileanu; Tatiana Shavrina; Kelvin Niu; Jean-Christophe Gagnon-Audet; Michael Shvartsman; Shagun Sodhani; Alexander H Miller; Abhishek Charnalia; Derek Dunfield; Carole-Jean Wu; Pontus Stenetorp; Nicola Cancedda; Jakob Nicolaus Foerster; Yoram Bachrach,~Edan_Toledo1; ~Karen_Hambardzumyan1; ~Martin_Josifoski1; ~RISHI_HAZRA1; ~Nicolas_Baldwin1; ~Alexis_Audran-Reiss1; ~Michael_Kuchnik1; ~Despoina_Magka2; ~Minqi_Jiang1; ~Alisia_Maria_Lupidi1; ~Andrei_Lupu1; ~Roberta_Raileanu2; ~Tatiana_Shavrina1; ~Kelvin_Niu1; ~Jean-Christophe_Gagnon-Audet1; ~Michael_Shvartsman1; ~Shagun_Sodhani1; ~Alexander_H_Miller1; ~Abhishek_Charnalia1; ~Derek_Dunfield1; ~Carole-Jean_Wu2; ~Pontus_Stenetorp1; ~Nicola_Cancedda1; ~Jakob_Nicolaus_Foerster1; ~Yoram_Bachrach2,{'value': ['LLM Agents; Code generation; AutoML; LLM-driven search; ML Engineering Agents; ML Research Agents; AI Research Agents']},"{'value': ""AI research agents are demonstrating great potential to accelerate scientific progress by automating the design, implementation, and training of machine learning models. We focus on methods for improving agents' performance on MLE-bench, a challenging benchmark where agents compete in Kaggle competitions to solve real-world machine learning problems. We formalize AI research agents as search policies that navigate a space of candidate solutions, iteratively modifying them using operators. By designing and systematically varying different operator sets and search policies (Greedy, MCTS, Evolutionary), we show that their interplay is critical for achieving high performance. Our best pairing of search strategy and operator set achieves a state-of-the-art result on MLE-bench lite, increasing the success rate of achieving a Kaggle medal from 39.6% to 47.7%. Our investigation underscores the importance of jointly considering the search strategy, operator design, and evaluation methodology in advancing automated machine learning.""}",https://openreview.net{'value': '/pdf/a22e34894b1de174131d79168e9a32bf5fefd3a5.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=RmqWt1btxQ,{'value': 'Transcending Cost-Quality Tradeoff in Agent Serving via Session-Awareness'},Yanyu Ren; Li Chen; Dan Li; Xizheng Wang; Zhiyuan Wu; Yukai Miao; Yu Bai,~Yanyu_Ren1; ~Li_Chen24; ~Dan_Li14; ~Xizheng_Wang1; ~Zhiyuan_Wu1; ~Yukai_Miao1; ~Yu_Bai5,"{'value': ['Agent Serving', 'LLM Serving', 'LLM infrastructure', 'Large language models', 'inference optimizations']}","{'value': 'Large Language Model (LLM) agents are capable of task execution across various domains by autonomously interacting with environments and refining LLM responses based on feedback.\nHowever, existing model serving systems are not optimized for the unique demands of serving agents. Compared to classic model serving, agent serving has different characteristics:\npredictable request pattern, increasing quality requirement, and unique prompt formatting. We identify a key problem for agent serving: LLM serving systems lack session-awareness. They neither perform effective KV cache management nor precisely select the cheapest yet competent model in each round.\nThis leads to a cost-quality tradeoff, and we identify an opportunity to surpass it in an agent serving system.\n\nTo this end, we introduce AgServe for AGile AGent SERVing.\nAgServe features a session-aware server that boosts KV cache reuse via Estimated-Time-of-Arrival-based eviction and in-place positional embedding calibration, a quality-aware client that performs session-aware model cascading through real-time quality assessment, and a dynamic resource scheduler that maximizes GPU utilization. \nWith AgServe, we allow agents to select and upgrade models during the session lifetime, and to achieve similar quality at much lower costs, effectively transcending the tradeoff. Extensive experiments on real testbeds demonstrate that AgServe (1) achieves comparable response quality to GPT-4o at a 16.5\\% cost. (2) delivers 1.8$\\times$ improvement in quality relative to the tradeoff curve.'}",https://openreview.net{'value': '/pdf/27eca12a3d907e412808e51efe4a0b94f9e7353a.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=RhRLbCt7MS,{'value': 'Functional Complexity-adaptive Temporal Tensor Decomposition'},Panqi Chen; Lei Cheng; Jianlong Li; Weichang Li; Weiqing Liu; Jiang Bian; Shikai Fang,~Panqi_Chen1; ~Lei_Cheng8; ~Jianlong_Li1; ~Weichang_Li1; ~Weiqing_Liu1; ~Jiang_Bian1; ~Shikai_Fang2,{'value': ['functional tensor decomposition，Bayesian Method']},"{'value': 'Tensor decomposition is a fundamental tool for analyzing multi-dimensional data by learning low-rank factors to represent high-order interactions. While recent works on temporal tensor decomposition have made significant progress by incorporating continuous timestamps in latent factors, they still struggle with general tensor data with continuous indexes not only in the temporal mode but also in other modes, such as spatial coordinates in climate data.  Moreover, the challenge of self-adapting model complexity is largely unexplored in functional temporal tensor models, with existing methods being inapplicable in this setting.  To address these limitations, we propose functional Complexity-Adaptive Temporal Tensor dEcomposition (Catte). \n Our approach encodes continuous spatial indexes as learnable Fourier features and employs neural ODEs in latent space to learn the temporal trajectories of factors. To enable automatic adaptation of model complexity, we introduce a sparsity-inducing prior over the factor trajectories. \n We develop an efficient variational inference scheme with an analytical evidence lower bound, enabling sampling-free optimization. Through extensive experiments on both synthetic and real-world datasets, we demonstrate that Catte not only reveals the underlying ranks of functional temporal tensors but also significantly outperforms existing methods in prediction performance and robustness against noise.'}",https://openreview.net{'value': '/pdf/09b0b696cafe98d88886d83a5fe5042778080ff8.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=RbkHARGCcH,{'value': 'Multi-Agent Imitation by Learning and Sampling from Factorized Soft Q-Function'},Yi-Chen Li; Zhongxiang Ling; Tao Jiang; Fuxiang Zhang; Pengyuan Wang; Lei Yuan; Zongzhang Zhang; Yang Yu,~Yi-Chen_Li1; ~Zhongxiang_Ling1; ~Tao_Jiang21; ~Fuxiang_Zhang1; ~Pengyuan_Wang3; ~Lei_Yuan2; ~Zongzhang_Zhang1; ~Yang_Yu5,"{'value': ['Multi-Agent Imitation Learning', 'Energy-Based Models', 'Inverse Reinforcement Learning']}","{'value': 'Learning from multi-agent expert demonstrations, known as Multi-Agent Imitation Learning (MAIL), provides a promising approach to sequential decision-making. However, existing MAIL methods including Behavior Cloning (BC) and Adversarial Imitation Learning (AIL) face significant challenges: BC suffers from the compounding error issue, while the very nature of adversarial optimization makes AIL prone to instability. In this work, we propose \\textbf{M}ulti-\\textbf{A}gent imitation by learning and sampling from \\textbf{F}actor\\textbf{I}zed \\textbf{S}oft Q-function (MAFIS), a novel method that addresses these limitations for both online and offline MAIL settings. Built upon the single-agent IQ-Learn framework, MAFIS introduces the value decomposition network to factorize the imitation objective at agent level, thus enabling scalable training for multi-agent systems. Moreover, we observe that the soft Q-function implicitly defines the optimal policy as an energy-based model, from which we can sample actions via stochastic gradient Langevin dynamics. This allows us to estimate the gradient of the factorized optimization objective for continuous control tasks, avoiding the adversarial optimization between the soft Q-function and the policy required by prior work. By doing so, we obtain a tractable and \\emph{non-adversarial} objective for both discrete and continuous multi-agent control. Experiments on common benchmarks including the discrete control tasks StarCraft Multi-Agent Challenge v2 (SMACv2), Gold Miner, and Multi Particle Environments (MPE), as well as the continuous control task Multi-Agent MuJoCo (MaMuJoCo), demonstrate that MAFIS achieves superior performance compared with baselines. Our code is available at https://github.com/LAMDA-RL/MAFIS.'}",https://openreview.net{'value': '/pdf/5074f7d62c8caac24de92731041aecebc5af1224.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=RTzbr0k56C,{'value': 'One-Step Offline Distillation of Diffusion-based Models  via Koopman Modeling'},Nimrod Berman; Ilan Naiman; Moshe Eliasof; Hedi Zisling; Omri Azencot,~Nimrod_Berman1; ~Ilan_Naiman1; ~Moshe_Eliasof1; ~Hedi_Zisling1; ~Omri_Azencot1,"{'value': ['Koopman theory', 'diffusion models', 'offline distillation', 'one-step generation', 'dynamical systems']}","{'value': 'Diffusion-based generative models have demonstrated exceptional performance, yet their iterative sampling procedures remain computationally expensive. A prominent strategy to mitigate this cost is *distillation*, with *offline distillation* offering particular advantages in terms of efficiency, modularity, and flexibility. In this work, we identify two key observations that motivate a principled distillation framework: (1) while diffusion models have been viewed through the lens of dynamical systems theory, powerful and underexplored tools can be further leveraged; and (2) diffusion models inherently impose structured, semantically coherent trajectories in latent space. Building on these observations, we introduce the *Koopman Distillation Model* (KDM), a novel offline distillation approach grounded in Koopman theory - a classical framework for representing nonlinear dynamics linearly in a transformed space. KDM encodes noisy inputs into an embedded space where a learned linear operator propagates them forward, followed by a decoder that reconstructs clean samples. This enables single-step generation while preserving semantic fidelity. We provide theoretical justification for our approach: (1) under mild assumptions, the learned diffusion dynamics admit a finite-dimensional Koopman representation; and (2) proximity in the Koopman latent space correlates with semantic similarity in the generated outputs, allowing for effective trajectory alignment. Empirically, KDM achieves state-of-the-art performance across standard *offline distillation* benchmarks - improving FID scores by up to 40% in a single generation step.'}",https://openreview.net{'value': '/pdf/b3e2ca13dbc5eb750d07eb17f92302dbea334f6d.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=RIkHzQbpeR,{'value': 'Conformal Prediction Beyond the Horizon: Distribution-Free Inference for Policy Evaluation'},Feichen Gan; Lu Youcun; Yingying Zhang; Yukun Liu,~Feichen_Gan1; ~Lu_Youcun1; ~Yingying_Zhang2; ~Yukun_Liu4,"{'value': ['Conformal Prediction', 'Reinforcement Learning', 'Policy Evaluation', 'Infinite-Horizon']}","{'value': 'Reliable uncertainty quantification is crucial for reinforcement learning (RL) in high-stakes settings. We propose a unified conformal prediction framework for infinite-horizon policy evaluation that constructs distribution-free prediction intervals for returns in both on-policy and off-policy settings. Our method integrates distributional RL with conformal calibration, addressing challenges such as unobserved returns, temporal dependencies, and distributional shifts. We propose a modular pseudo-return construction based on truncated rollouts and a time-aware calibration strategy using experience replay and weighted subsampling. These innovations mitigate model bias and restore approximate exchangeability, enabling uncertainty quantification even under policy shifts. Our theoretical analysis provides coverage guarantees that account for model misspecification and importance weight estimation. Empirical results, including experiments in synthetic and benchmark environments like Mountain Car, show that our method significantly improves coverage and reliability over standard distributional RL baselines.'}",https://openreview.net{'value': '/pdf/9802ff5500db8ec8b53f485acf83bf086f507863.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=RCXF0UEmuE,{'value': 'Sample-efficient Learning of Concepts with Theoretical Guarantees: from Data to Concepts without Interventions'},Hidde Fokkema; Tim van Erven; Sara Magliacane,~Hidde_Fokkema1; ~Tim_van_Erven1; ~Sara_Magliacane1,"{'value': ['Interpretability', 'Concepts', 'Causal Representation Learning']}","{'value': 'Machine learning is a vital part of many real-world systems, but several concerns\nremain about the lack of interpretability, explainability and robustness of black-box\nAI systems. Concept Bottleneck Models (CBM) address some of these challenges\nby learning interpretable concepts from high-dimensional data, e.g. images, which\nare used to predict labels. An important issue in CBMs are spurious correlation\nbetween concepts, which effectively lead to learning “wrong” concepts. Current\nmitigating strategies have strong assumptions, e.g., they assume that the concepts\nare statistically independent of each other, or require substantial interaction in\nterms of both interventions and labels provided by annotators. In this paper, we\ndescribe a framework that provides theoretical guarantees on the correctness of\nthe learned concepts and on the number of required labels, without requiring any\ninterventions. Our framework leverages causal representation learning (CRL)\nmethods to learn latent causal variables from high-dimensional observations in\na unsupervised way, and then learns to align these variables with interpretable\nconcepts with few concept labels. We propose a linear and a non-parametric\nestimator for this mapping, providing a finite-sample high probability result in the\nlinear case and an asymptotic consistency result for the non-parametric estimator.\nWe evaluate our framework in synthetic and image benchmarks, showing that the\nlearned concepts have less impurities and are often more accurate than other CBMs,\neven in settings with strong correlations between concepts.'}",https://openreview.net{'value': '/pdf/5fce45669f00d55192969c6bf4695d729cf4c32d.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=RBiyFxwGJm,{'value': 'Learning-Augmented Streaming Algorithms for Correlation Clustering'},Yinhao Dong; Shan Jiang; Shi Li; Pan Peng,~Yinhao_Dong1; ~Shan_Jiang10; ~Shi_Li1; ~Pan_Peng1,"{'value': ['Correlation Clustering', 'graph streaming algorithms', 'learning-augmented algorithms']}","{'value': ""We study streaming algorithms for Correlation Clustering. Given a graph as an arbitrary-order stream of edges, with each edge labeled as positive or negative, the goal is to partition the vertices into disjoint clusters, such that the number of disagreements is minimized. In this paper, we give the first learning-augmented streaming algorithms for the problem on both complete and general graphs, improving the best-known space-approximation tradeoffs. Based on the works of Cambus et al. (SODA'24) and Ahn et al. (ICML'15), our algorithms use the predictions of pairwise distances between vertices provided by a predictor. For complete graphs, our algorithm achieves a better-than-$3$ approximation under good prediction quality, while using $\\tilde{O}(n)$ total space. For general graphs, our algorithm achieves an $O(\\log |E^-|)$ approximation under good prediction quality using $\\tilde{O}(n)$ total space, improving the best-known non-learning algorithm in terms of space efficiency. Experimental results on synthetic and real-world datasets demonstrate the superiority of our proposed algorithms over their non-learning counterparts.""}",https://openreview.net{'value': '/pdf/39907044d626030d4885b0c0f58dc3e8b992de8b.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=R8n2h7hzqS,{'value': 'Flow Matching Neural Processes'},Hussen Abu Hamad; Dan Rosenbaum,~Hussen_Abu_Hamad1; ~Dan_Rosenbaum1,"{'value': ['flow matching', 'neural processes']}","{'value': 'Neural processes (NPs) are a class of models that learn stochastic processes directly from data and can be used for inference, sampling and conditional sampling.  We introduce a new NP model based on flow matching, a generative modeling paradigm that has demonstrated strong performance on various data modalities. Following the NP training framework, the model provides amortized predictions of conditional distributions over any arbitrary points in the data. Compared to previous NP models, our model is simple to implement and can be used to sample from conditional distributions using an ODE solver, without requiring auxiliary conditioning methods.In addition, the model provides a controllable tradeoff between accuracy and running time via the number of steps in the ODE solver. We show that our model outperforms previous state-of-the-art neural process methods on various benchmarks including synthetic 1D Gaussian processes data, 2D images, and real-world weather data.'}",https://openreview.net{'value': '/pdf/46c83b4a6bc9f743f4af456ccdd41b33bea0eae6.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=R1CximX3Cw,{'value': 'Practical Kernel Selection for Kernel-based Conditional Independence Test'},Wenjie Wang; Mingming Gong; Biwei Huang; James Bailey; Bo Han; Kun Zhang; Feng Liu,~Wenjie_Wang3; ~Mingming_Gong1; ~Biwei_Huang1; ~James_Bailey1; ~Bo_Han1; ~Kun_Zhang1; ~Feng_Liu2,"{'value': ['conditional independence testing', 'kernel method', 'causal discovery']}","{'value': 'Conditional independence (CI) testing is a fundamental yet challenging task in modern statistics and machine learning. \nOne pivotal class of methods for assessing conditional independence encompasses kernel-based approaches, known for assessing CI by detecting general conditional dependence without imposing strict assumptions on relationships or data distributions.\nAs with any method utilizing kernels, selecting appropriate kernels is crucial for precise identification. \nHowever, it remains underexplored in kernel-based CI methods, where the kernels are often determined manually or heuristically.\nIn this paper, we analyze and propose a kernel parameter selection approach for the kernel-based conditional independence test (KCI).\nThe kernel parameters are selected based on the ratio of the statistic to the asymptotic variance, which approximates the test power for the given parameters at large sample sizes. \nThe search procedure is grid-based, allowing for parallelization with manageable additional computation time.\nWe theoretically demonstrate the consistency of the proposed criterion and conduct extensive experiments on both synthetic and real data to show the effectiveness of our method.'}",https://openreview.net{'value': '/pdf/74fe6b736caea11107f8a9f7d4d7c1b59816550a.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=R0dC7Xzwbk,{'value': 'Prismatic Synthesis: Gradient-based Data Diversification Boosts Generalization in LLM Reasoning'},Jaehun Jung; Seungju Han; Ximing Lu; Skyler Hallinan; David Acuna; Shrimai Prabhumoye; Mostofa Patwary; Mohammad Shoeybi; Bryan Catanzaro; Yejin Choi,~Jaehun_Jung1; ~Seungju_Han2; ~Ximing_Lu1; ~Skyler_Hallinan1; ~David_Acuna1; ~Shrimai_Prabhumoye1; ~Mostofa_Patwary1; ~Mohammad_Shoeybi1; ~Bryan_Catanzaro1; ~Yejin_Choi1,"{'value': ['Large Language Models', 'Data Diversity', 'Data Quality', 'Synthetic Data', 'LLM Reasoning']}","{'value': ""Data diversity is crucial for training a strong language model. Yet metrics of diversity often diverge from this goal, measuring variations in heuristic features—like n-grams or embeddings—that are detached from how the model actually performs on a target task. This motivates us to ask: *Can we redefine data diversity—beyond measuring variations in heuristic features—in a way that better predicts model generalization?* Through large-scale empirical analyses spanning over 300 training runs, carefully controlled for data scale and quality, we show that data diversity can be a strong predictor of generalization in LLM reasoning—as measured by average model performance on unseen out-of-distribution benchmarks. We introduce **G-Vendi**, a metric that quantifies diversity via the entropy of model-induced loss gradients. G-Vendi scales to million-sample datasets and yet consistently outperforms heuristic alternatives, achieving strong correlation ($\\text{Spearman's } \\rho \\approx 0.9$) with out-of-distribution (OOD) performance across both natural language inference (NLI) and math reasoning tasks. Building on this insight, we present **Prismatic Synthesis**, a framework for generating diverse synthetic data by targeting underrepresented regions in gradient space. Experimental results show that Prismatic Synthesis consistently improves model performance as we scale synthetic data—not just on in-distribution test but across unseen, out-of-distribution benchmarks—significantly outperforming state-of-the-art models in both domains. For example, PrismMath-7B, our model distilled from a 32B LLM without human verification, outperforms R1-Distill-Qwen-7B—trained on proprietary data generated by 671B R1—on 6 out of 7 challenging math benchmarks.""}",https://openreview.net{'value': '/pdf/cf925214a554d0ec2b50bb7ea4d5c5fd8177ce2f.pdf'},{'title_filter': 'Data Synthesis'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=QvV8oF08HA,{'value': 'ShiQ: Bringing back Bellman to LLMs'},Pierre Clavier; Nathan Grinsztajn; Raphaël Avalos; Yannis Flet-Berliac; Irem Ergun; Omar Darwiche Domingues; Olivier Pietquin; Pierre Harvey Richemond; Florian Strub; Matthieu Geist,~Pierre_Clavier1; ~Nathan_Grinsztajn1; ~Raphaël_Avalos1; ~Yannis_Flet-Berliac1; ~Irem_Ergun1; ~Omar_Darwiche_Domingues1; ~Olivier_Pietquin1; ~Pierre_Harvey_Richemond1; ~Florian_Strub1; ~Matthieu_Geist1,"{'value': ['Reinforcement Learning with Human Feedbacks', 'Reinforcement Learning', 'Q-Learning']}","{'value': 'The fine-tuning of pre-trained large language models (LLMs) using reinforcement learning (RL) is generally formulated as direct policy optimization. This approach was naturally favored as it efficiently improves a pretrained LLM with simple gradient updates. Another RL paradigm, Q-learning methods, has received far less attention in the LLM community while demonstrating major success in various non-LLM RL tasks. In particular, Q-learning effectiveness stems from its sample efficiency and ability to learn offline, which is particularly valuable given the high computational cost of sampling with LLM. However, naively applying a Q-learning–style update to the model’s logits is ineffective due to the specificity of LLMs. Our contribution is to derive theoretically grounded loss functions from Bellman equations to adapt Q-learning methods to LLMs. To do so, we interpret LLM logits as Q-values and carefully adapt insights from the RL literature to account for LLM-specific characteristics. It thereby ensures that the logits become reliable Q-value estimates. We then use this loss to build a practical algorithm, ShiQ for Shifted-Q, that supports off-policy, token-wise learning while remaining simple to implement. Finally,  ShiQ is evaluated on both synthetic data and real-world benchmarks, e.g., UltraFeedback, BFCL-V3, demonstrating its effectiveness in both single-turn and multi-turn LLM settings.'}",https://openreview.net{'value': '/pdf/4e9542daf18fbf921c3dca3c23f2b110547a310d.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=QtnCPZMxYg,{'value': 'Trajectory Graph Learning: Aligning with Long Trajectories in Reinforcement Learning Without Reward Design'},Yunfan Li; Eric Liu; Lin Yang,~Yunfan_Li4; ~Eric_Liu3; ~Lin_Yang12,"{'value': ['Reinforcement Learning', 'Trajectory Alignment', 'Trajectory Graph Learning']}","{'value': 'Reinforcement learning (RL) often relies on manually designed reward functions, which are difficult to specify and can lead to issues such as reward hacking and suboptimal behavior. Alternatives like inverse RL and preference-based RL attempt to infer surrogate rewards from demonstrations or preferences but suffer from ambiguity and distribution mismatch. A more direct approach, inspired by imitation learning, avoids reward modeling by leveraging expert demonstrations. However, most existing methods align actions only at individual states, failing to capture the coherence of long-horizon trajectories.\n\nIn this work, we study the problem of directly aligning policies with expert-labeled trajectories to preserve long-horizon behavior without relying on reward signals. Specifically, we aim to learn a policy that maximizes the probability of generating the expert trajectories. Nevertheless, we prove that, in its general form, this trajectory alignment problem is NP-complete. \nTo address this, we propose Trajectory Graph Learning (TGL), a framework that leverages structural assumptions commonly satisfied in practice—such as bounded realizability of expert trajectories or a tree-structured MDP. These enable a graph-based policy planning algorithm that computes optimal policies in polynomial time under known dynamics. For settings with unknown dynamics, we develop a sample-efficient algorithm based on UCB-style exploration and establish sub-linear regret. Experiments on grid-world tasks demonstrate that TGL substantially outperforms standard imitation learning methods for long-trajectory planning.'}",https://openreview.net{'value': '/pdf/3b020428ee7c08d20b8d792f438007638960fa97.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=QsQGMijLhL,{'value': 'Generalizing Experience for Language Agents with Hierarchical MetaFlows'},Shengda Fan; Xin Cong; Zhong Zhang; Yuepeng Fu; Yesai Wu; Hao Wang; Xinyu Zhang; Enrui Hu; Yankai Lin,~Shengda_Fan1; ~Xin_Cong1; ~Zhong_Zhang5; ~Yuepeng_Fu1; ~Yesai_Wu1; ~Hao_Wang140; ~Xinyu_Zhang6; ~Enrui_Hu1; ~Yankai_Lin1,"{'value': ['agent', 'workflow', 'large language models']}","{'value': 'Recent efforts to employ large language models (LLMs) as agents have demonstrated promising results in a wide range of multi-step agent tasks. However, existing agents lack an effective experience reuse approach to leverage historical completed tasks. In this paper, we propose a novel experience reuse framework MetaFlowLLM, which constructs a hierarchical experience tree from historically completed tasks. Each node in this experience tree is presented as a MetaFlow which contains static execution workflow and subtask required by agents to complete dynamically. Then, we propose a Hierarchical MetaFlow Merging algorithm to construct the hierarchical experience tree. When accomplishing a new task, MetaFlowLLM can first retrieve the most relevant MetaFlow node from the experience tree and then execute it accordingly. To effectively generate valid MetaFlows from historical data, we further propose a reinforcement learning pipeline to train the MetaFlowGen. Extensive experimental results on AppWorld and WorkBench demonstrate that integrating with MetaFlowLLM, existing agents (e.g., ReAct, Reflexion) can gain substantial performance improvement with reducing execution costs. Notably, MetaFlowLLM achieves an average success rate improvement of 32.3% on AppWorld and 6.2% on WorkBench, respectively.'}",https://openreview.net{'value': '/pdf/e5e7cd3c074c77adae516f8d392136a8fe8657f5.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=QclFsekj9B,{'value': 'X-Scene: Large-Scale Driving Scene Generation with High Fidelity and Flexible Controllability'},Yu Yang; Alan Liang; Jianbiao Mei; Yukai Ma; Yong Liu; Gim Hee Lee,~Yu_Yang16; ~Alan_Liang1; ~Jianbiao_Mei1; ~Yukai_Ma1; ~Yong_Liu11; ~Gim_Hee_Lee1,"{'value': ['3D Scene Generation', 'Autonomous Driving']}","{'value': 'Diffusion models are advancing autonomous driving by enabling realistic data synthesis, predictive end-to-end planning, and closed-loop simulation, with a primary focus on temporally consistent generation. However, large-scale 3D scene generation requiring spatial coherence remains underexplored. In this paper, we present X-Scene, a novel framework for large-scale driving scene generation that achieves geometric intricacy, appearance fidelity, and flexible controllability. Specifically, X-Scene supports multi-granular control, including low-level layout conditioning driven by user input or text for detailed scene composition, and high-level semantic guidance informed by user intent and LLM-enriched prompts for efficient customization. To enhance geometric and visual fidelity, we introduce a unified pipeline that sequentially generates 3D semantic occupancy and corresponding multi-view images and videos, ensuring alignment and temporal consistency across modalities. We further extend local regions into large-scale scenes via consistency-aware outpainting, which extrapolates occupancy and images from previously generated areas to maintain spatial and visual coherence. The resulting scenes are lifted into high-quality 3DGS representations, supporting diverse applications such as simulation and scene exploration. Extensive experiments demonstrate that X-Scene substantially advances controllability and fidelity in large-scale scene generation, empowering data generation and simulation for autonomous driving.'}",https://openreview.net{'value': '/pdf/6cc5e90c6b7750a3714c1be0c2f224349f14dd35.pdf'},{'abstract_filter': 'Data Synthesis'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=QYJt0pX0zJ,"{'value': 'Virus Infection Attack on LLMs: Your Poisoning Can Spread ""VIA"" Synthetic Data'}",Zi Liang; Qingqing Ye; Xuan Liu; Yanyun Wang; Jianliang Xu; Haibo Hu,~Zi_Liang1; ~Qingqing_Ye1; ~Xuan_Liu8; ~Yanyun_Wang1; ~Jianliang_Xu1; ~Haibo_Hu2,"{'value': ['Data Poisoning', 'Synthetic Data', 'Large Language Models']}","{'value': 'Synthetic data refers to artificial samples generated by models. While it has been validated to significantly enhance the performance of large language models (LLMs) during training and has been widely adopted in LLM development, potential security risks it may introduce remain uninvestigated. This paper systematically evaluates the resilience of synthetic-data-integrated training paradigm for LLMs against mainstream poisoning and backdoor attacks. We reveal that such a paradigm exhibits strong resistance to existing attacks, primarily thanks to the different distribution patterns between poisoning data and queries used to generate synthetic samples. To enhance the effectiveness of these attacks and further investigate the security risks introduced by synthetic data, we introduce a novel and universal attack framework, namely, Virus Infection Attack (VIA), which enables the propagation of current attacks through synthetic data even under purely clean queries. Inspired by the principles of virus design in cybersecurity, VIA conceals the poisoning payload within a protective “shell” and strategically searches for optimal hijacking points in benign samples to maximize the likelihood of generating malicious content. Extensive experiments on both data poisoning and backdoor attacks show that VIA significantly increases the presence of poisoning content in synthetic data and correspondingly raises the attack success rate (ASR) on downstream models to levels comparable to those observed in the poisoned upstream models.'}",https://openreview.net{'value': '/pdf/4314d097789b9ce667a3dcd9e84db87e31c26f92.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=QXEhBMNrCW,{'value': 'Group-in-Group Policy Optimization for LLM Agent Training'},Lang Feng; Zhenghai Xue; Tingcong Liu; Bo An,~Lang_Feng1; ~Zhenghai_Xue1; ~Tingcong_Liu1; ~Bo_An2,"{'value': ['Large Language Model', 'Agent', 'Group-Based Reinforcement Learning']}","{'value': 'Recent advances in group-based reinforcement learning (RL) have driven frontier large language models (LLMs) in single-turn tasks like mathematical reasoning. However, their scalability to multi-turn LLM agent training remains limited. Unlike static tasks, agent-environment interactions unfold over many steps and often yield sparse or delayed rewards, making credit assignment across individual steps significantly more challenging. In this work, we propose Group-in-Group Policy Optimization (GiGPO), a novel RL algorithm that achieves fine-grained credit assignment for LLM agents while preserving the appealing properties of group-based RL: critic-free, low memory, and stable convergence. GiGPO introduces a two-level structure for estimating relative advantage: (i) At the episode-level, GiGPO computes macro relative advantages based on groups of complete trajectories; (ii) At the step-level, GiGPO introduces an anchor state grouping mechanism that retroactively constructs step-level groups by identifying repeated environment states across trajectories. Actions stemming from the same state are grouped together, enabling micro relative advantage estimation. This hierarchical structure effectively captures both global trajectory quality and local step effectiveness without relying on auxiliary models or additional rollouts. We evaluate GiGPO on challenging agent benchmarks, including ALFWorld and WebShop, as well as tool-integrated reasoning on search-augmented QA tasks, using Qwen2.5-1.5B/3B/7B-Instruct. Crucially, GiGPO delivers fine-grained per-step credit signals, achieves performance gains of > 12\\% on ALFWorld and > 9\\% on WebShop over GRPO, and obtains superior performance on QA tasks (42.1\\% on 3B and 47.2\\% on 7B): all while maintaining the same GPU memory overhead, identical LLM rollout, and incurring little to no additional time cost.'}",https://openreview.net{'value': '/pdf/c28e200ee92ae5eef9869fe35dbd6fc859cd04cf.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=QUN6uidabr,{'value': 'Provable Meta-Learning with Low-Rank Adaptations'},Jacob L. Block; Sundararajan Srinivasan; Liam Collins; Aryan Mokhtari; Sanjay Shakkottai,~Jacob_L._Block1; ~Sundararajan_Srinivasan2; ~Liam_Collins1; ~Aryan_Mokhtari3; ~Sanjay_Shakkottai1,"{'value': ['Meta-Learning', 'Low-Rank Adaptation', 'Parameter-Efficient Fine-Tuning', 'Non-convex Optimization']}","{'value': 'The power of foundation models (FMs) lies in their capacity to learn highly expressive representations that can be adapted to a broad spectrum of tasks. However, these pretrained models require additional training stages to become effective for downstream applications. In the multi-task setting, prior works have shown empirically that specific meta-learning approaches for preparing a model for future adaptation through parameter-efficient fine-tuning (PEFT) can outperform standard retraining methods, but the mechanism of the benefits of meta-learning has been largely unexplored. We introduce a framework for generic PEFT-based meta-learning to learn a model that can easily adapt to unseen tasks. For linear models using LoRA, we show that standard retraining is provably suboptimal for finding an adaptable set of parameters and provide strict performance guarantees for our proposed method. We verify these theoretical insights through experiments on synthetic data as well as real-data vision and language tasks. We observe significant performance benefits using a simple implementation of our proposed meta-learning scheme during retraining relative to the conventional approach.'}",https://openreview.net{'value': '/pdf/af0efb03ccacfddad17278e239a99ebbcd99f634.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=QRKg5GA9Zo,{'value': 'How Classifier Features Transfer to Downstream: An Asymptotic Analysis in a Two-Layer Model'},HEE BIN YOO; Sungyoon Lee; Cheongjae Jang; Dong-Sig Han; Jaein Kim; Seunghyeon Lim; Byoung-Tak Zhang,~HEE_BIN_YOO1; ~Sungyoon_Lee1; ~Cheongjae_Jang1; ~Dong-Sig_Han2; ~Jaein_Kim2; ~Seunghyeon_Lim1; ~Byoung-Tak_Zhang1,"{'value': ['open-set clustering', 'feature transfer', 'two-layer neural network', 'feature learning', 'metric learning', 'retrieval']}","{'value': 'Neural networks learn effective feature representations, which can be transferred to new tasks without additional training.\nWhile larger datasets are known to improve feature transfer, the theoretical conditions for the success of such transfer remain unclear.\nThis work investigates feature transfer in networks trained for classification to identify the conditions that enable effective clustering in unseen classes.\nWe first reveal that higher similarity between training and unseen distributions leads to improved Cohesion and Separability.\nWe then show that feature expressiveness is enhanced when inputs are similar to the training classes, while the features of irrelevant inputs remain indistinguishable.\nWe validate our analysis on synthetic and benchmark datasets, including CAR, CUB, SOP, ISC, and ImageNet.\nOur analysis highlights the importance of the similarity between training classes and the input distribution for successful feature transfer.'}",https://openreview.net{'value': '/pdf/3a343bb0f858db6599913fa310540577d4c2bf14.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=QQybz4enRc,{'value': 'Safely Learning Controlled Stochastic Dynamics'},Luc Brogat-Motte; Alessandro Rudi; Riccardo Bonalli,~Luc_Brogat-Motte1; ~Alessandro_Rudi1; ~Riccardo_Bonalli1,"{'value': ['Kernel Methods', 'Dynamical Systems', 'Exploration', 'Density Estimation', 'Learning Theory']}","{'value': ""We address the problem of safely learning controlled stochastic dynamics from discrete-time trajectory observations, ensuring system trajectories remain within predefined safe regions during both training and deployment. Safety-critical constraints of this kind are crucial in applications such as autonomous robotics, finance, and biomedicine. We introduce a method that ensures safe exploration and efficient estimation of system dynamics by iteratively expanding an initial known safe control set using kernel-based confidence bounds. After training, the learned model enables predictions of the system's dynamics and permits safety verification of any given control. Our approach requires only mild smoothness assumptions and access to an initial safe control set, enabling broad applicability to complex real-world systems. We provide theoretical guarantees for safety and derive adaptive learning rates that improve with increasing Sobolev regularity of the true dynamics. Experimental evaluations demonstrate the practical effectiveness of our method in terms of safety, estimation accuracy, and computational efficiency.""}",https://openreview.net{'value': '/pdf/94c0be1186cd59b283c02662a89c2bd32c721569.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=QQhQIqons0,{'value': 'SEC-bench: Automated Benchmarking of LLM Agents on Real-World Software Security Tasks'},Hwiwon Lee; Ziqi Zhang; Hanxiao Lu; LINGMING ZHANG,~Hwiwon_Lee1; ~Ziqi_Zhang6; ~Hanxiao_Lu1; ~LINGMING_ZHANG2,"{'value': ['Security Benchmarking', 'LLM Agents', 'Security Engineering', 'AI for Security', 'Automated Evaluation']}","{'value': ""Rigorous security-focused evaluation of large language model (LLM) agents is imperative for establishing trust in their safe deployment throughout the software development lifecycle. However, existing benchmarks largely rely on synthetic challenges or simplified vulnerability datasets that fail to capture the complexity and ambiguity encountered by security engineers in practice. We introduce SEC-bench, the first fully automated benchmarking framework for evaluating LLM agents on authentic security engineering tasks. SEC-bench employs a novel multi-agent scaffold that automatically constructs code repositories with harnesses, reproduces vulnerabilities in isolated environments, and generates gold patches for reliable evaluation. Our framework automatically creates high-quality software vulnerability datasets with reproducible artifacts at a cost of only $0.87 per instance. Using SEC-bench, we implement two critical software security tasks to rigorously evaluate LLM agents' capabilities: proof-of-concept (PoC) generation and vulnerability patching. A comprehensive evaluation of state-of-the-art LLM code agents reveals significant performance gaps, achieving at most 18.0% success in PoC generation and 34.0% in vulnerability patching on our complete dataset. These results highlight the crucial steps needed toward developing LLM agents that are more practical, intelligent, and autonomous for security engineering.""}",https://openreview.net{'value': '/pdf/66d2a1a241b7979f0f8776b51e62c6b1f1bc7db8.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=QQS7TudonJ,{'value': 'Training-Free Safe Denoisers for Safe Use of Diffusion Models'},Mingyu Kim; Dongjun Kim; Amman Yusuf; Stefano Ermon; Mijung Park,~Mingyu_Kim2; ~Dongjun_Kim1; ~Amman_Yusuf1; ~Stefano_Ermon1; ~Mijung_Park3,{'value': ['Safety of Generative AI; Diffusion Models']},"{'value': 'There is growing concern over the safety of powerful diffusion models, as they are often misused to produce inappropriate, not-safe-for-work content or generate copyrighted material or data of individuals who wish to be forgotten. Many existing methods tackle these issues by heavily relying on text-based negative prompts or retraining the model to eliminate certain features or samples. In this paper, we take a radically different approach, directly modifying the sampling trajectory by leveraging a negation set (e.g., unsafe images, copyrighted data, or private data) to avoid specific regions of data distribution, without needing to retrain or fine-tune the model. We formally derive the relationship between the expected denoised samples that are safe and those that are unsafe, leading to our *safe* denoiser, which ensures its final samples are away from the area to be negated. We achieve state-of-the-art safety performance in large-scale datasets such as the CoPro dataset while also enabling significantly more cost-effective sampling than existing methodologies.'}",https://openreview.net{'value': '/pdf/f142fccd122db61cfcc0a2ec9dc51db151a14a47.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=QNtJO0jTf3,{'value': 'Learning Equilibria from Data: Provably Efficient Multi-Agent Imitation Learning'},Till Freihaut; Luca Viano; Volkan Cevher; Matthieu Geist; Giorgia Ramponi,~Till_Freihaut1; ~Luca_Viano1; ~Volkan_Cevher1; ~Matthieu_Geist1; ~Giorgia_Ramponi1,"{'value': ['Reinforcement Learning', 'Multi-Agent Reinforcement Learning', 'Imitation Learning', 'Multi-Agent Imitation Learning']}","{'value': 'This paper provides the first expert sample complexity characterization for learning a Nash equilibrium from expert data in Markov Games.\nWe show that a new quantity named the *single policy deviation concentrability coefficient* is unavoidable in the non-interactive imitation learning setting, and we provide an upper bound for behavioral cloning (BC) featuring such coefficient. BC exhibits substantial regret in games with high concentrability coefficient, leading us to utilize expert queries to develop and introduce two novel solution algorithms: MAIL-BRO and MURMAIL. The former employs a best response oracle and learns an $\\varepsilon$-Nash equilibrium with $\\mathcal{O}(\\varepsilon^{-4})$ expert and oracle queries. The latter bypasses completely the best response oracle at the cost of a worse expert query complexity of order  $\\mathcal{O}(\\varepsilon^{-8})$. Finally, we provide numerical evidence, confirming our theoretical findings.'}",https://openreview.net{'value': '/pdf/fddf287f1d6ed42d23cebf1b3b16ed1d041a79a7.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=QL3J1fyAFv,{'value': 'Length Generalization via Auxiliary Tasks'},Pranjal Awasthi; Anupam Gupta; Ravi Kumar,~Pranjal_Awasthi3; ~Anupam_Gupta2; ~Ravi_Kumar1,"{'value': ['length generalization', 'theory']}","{'value': '_Length generalization_, the ability of sequence models to\n  generalize to sequences longer than those encountered during\n  training, remains a key challenge for transformers,\n  especially in tasks requiring algorithmic reasoning. Existing\n  theoretical understanding of length generalization is limited, often providing\n  only asymptotic results or focusing on specific problem classes or\n  architectural variants, while empirical approaches frequently rely on\n  ad hoc and often fragile techniques.\n\n  In this work we introduce a novel framework for analyzing and\n  proving length generalization bounds under specified, verifiable assumptions. A key\n  outcome of the theory is the identification of a natural set of\n  _auxiliary_ tasks, intricately related to the primary task structure,\n  such that strong performance on these auxiliary tasks, alongside the\n  primary task, provably guarantees length generalization within the framework.  This\n  motivates a multi-task training procedure that explicitly optimizes\n  performance on both the primary and the identified auxiliary tasks.\n\n  Empirical evaluations on a variety of synthetic benchmarks\n  known to be challenging for length generalization, including sequence\n  sorting, and reversal, demonstrate that our proposed method yields\n  significant improvements in generalization to substantially longer\n  sequences.'}",https://openreview.net{'value': '/pdf/a5e5e4faf09290faa591d33b29401917374054fa.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=QINnsnppv8,{'value': 'Memory Injection Attacks on LLM Agents via Query-Only Interaction'},Shen Dong; Shaochen Xu; Pengfei He; Yige Li; Jiliang Tang; Tianming Liu; Hui Liu; Zhen Xiang,~Shen_Dong4; ~Shaochen_Xu1; ~Pengfei_He2; ~Yige_Li1; ~Jiliang_Tang1; ~Tianming_Liu3; ~Hui_Liu8; ~Zhen_Xiang1,"{'value': ['LLM agent', 'LLM', 'Memory Injection', 'Trustworthy']}","{'value': ""Agents powered by large language models (LLMs) have demonstrated strong capabilities in a wide range of complex, real-world applications.\nHowever, LLM agents with a compromised memory bank may easily produce harmful outputs when the past records retrieved for demonstration are malicious.\nIn this paper, we propose a novel Memory INJection Attack, MINJA, without assuming that the attacker can directly modify the memory bank of the agent.\nThe attacker injects malicious records into the memory bank by only **interacting with the agent via queries and output observations**.\nThese malicious records are designed to elicit a sequence of malicious reasoning steps corresponding to a different target query during the agent's execution of the victim user's query.\nSpecifically, we introduce a sequence of *bridging steps* to link victim queries to the malicious reasoning steps.\nDuring the memory injection, we propose an *indication prompt* that guides the agent to autonomously generate similar bridging steps, with a *progressive shortening strategy* that gradually removes the indication prompt, such that the malicious record will be easily retrieved when processing later victim queries.\nOur extensive experiments across diverse agents demonstrate the effectiveness of MINJA in compromising agent memory.\nWith minimal requirements for execution, MINJA enables any user to influence agent memory, highlighting the risk.""}",https://openreview.net{'value': '/pdf/147a28fb3186337d99bf8c22ac92c2b15660c7fc.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=QFuuxfmqb5,{'value': 'ROOT: Rethinking Offline Optimization as Distributional Translation via Probabilistic Bridge'},Manh Cuong Dao; The Hung Tran; Phi Le Nguyen; Thao Nguyen Truong; Trong Nghia Hoang,~Manh_Cuong_Dao1; ~The_Hung_Tran1; ~Phi_Le_Nguyen2; ~Thao_Nguyen_Truong1; ~Trong_Nghia_Hoang1,"{'value': ['Offline Optimization', 'Diffusion Model', 'Probabilistic Method']}","{'value': 'This paper studies the black-box optimization task which aims to find the maxima of a black-box function using a static set of its observed input-output pairs. This is often achieved via learning and optimizing a surrogate function with that offline data. Alternatively, it can also be framed as an inverse modeling task that maps a desired performance to potential input candidates that achieve it. Both approaches are constrained by the limited amount of offline data. To mitigate this limitation, we introduce a new perspective that casts offline optimization as a distributional translation task. This is formulated as learning a probabilistic bridge transforming an implicit distribution of low-value inputs (i.e., offline data) into another distribution of high-value inputs (i.e., solution candidates). Such probabilistic bridge can be learned using low- and high-value inputs sampled from synthetic functions that resemble the target function. These synthetic functions are constructed as the mean posterior of multiple Gaussian processes fitted with different parameterizations on the offline data, alleviating the data bottleneck. The proposed approach is evaluated on an extensive benchmark comprising most recent methods, demonstrating significant improvement and establishing a new state-of-the-art performance. Our code is publicly available at https://github.com/cuong-dm/ROOT.'}",https://openreview.net{'value': '/pdf/cf8206509e6b29018c61097adfc12f609715c059.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=QD06Qv7O0P,{'value': 'Deep RL Needs Deep Behavior Analysis: Exploring Implicit Planning by Model-Free Agents in Open-Ended Environments'},Riley Simmons-Edler; Ryan Paul Badman; Felix Baastad Berg; Raymond Chua; John Vastola; Joshua Lunger; William Qian; Kanaka Rajan,~Riley_Simmons-Edler1; ~Ryan_Paul_Badman1; ~Felix_Baastad_Berg1; ~Raymond_Chua2; ~John_Vastola1; ~Joshua_Lunger1; ~William_Qian1; ~Kanaka_Rajan1,"{'value': ['Deep reinforcement learning', 'reinforcement learning', 'foraging', 'exploration', 'RNN analysis', 'open-ended learning', 'navigation', 'decision making', 'behavior analysis', 'cognitive science', 'neural dynamics', 'representations spatial memory', 'recurrent neural dynamics', 'joint neural-behavioral modeling']}","{'value': 'Understanding the behavior of deep reinforcement learning (DRL) agents—particularly as task and agent sophistication increase—requires more than simple comparison of reward curves, yet standard methods for behavioral analysis remain underdeveloped in DRL.\nWe apply tools from neuroscience and ethology to study DRL agents in a novel, complex, partially observable environment, ForageWorld, designed to capture key aspects of real-world animal foraging—including sparse, depleting resource patches, predator threats, and spatially extended arenas.\nWe use this environment as a platform for applying joint behavioral and neural analysis to agents, revealing detailed, quantitatively grounded insights into agent strategies, memory, and planning.\nContrary to common assumptions, we find that model-free RNN-based DRL agents can exhibit structured, planning-like behavior purely through emergent dynamics—without requiring explicit memory modules or world models.\nOur results show that studying DRL agents like animals—analyzing them with neuroethology-inspired tools that reveal structure in both behavior and neural dynamics—uncovers rich structure in their learning dynamics that would otherwise remain invisible.\nWe distill these tools into a general analysis framework linking core behavioral and representational features to diagnostic methods, which can be reused for a wide range of tasks and agents.\nAs agents grow more complex and autonomous, bridging neuroscience, cognitive science, and AI will be essential—not just for understanding their behavior, but for ensuring safe alignment and maximizing desirable behaviors that are hard to measure via reward.\nWe show how this can be done by drawing on lessons from how biological intelligence is studied.'}",https://openreview.net{'value': '/pdf/928d63d7fd5d5b2056d6aa39c03ffc3bf3207b50.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=Q8m0TkIpJZ,{'value': 'Blending Complementary Memory Systems in Hybrid Quadratic-Linear Transformers'},Kazuki Irie; Morris Yau; Samuel J. Gershman,~Kazuki_Irie1; ~Morris_Yau3; ~Samuel_J._Gershman1,"{'value': ['sequence processing', 'transformers', 'linear transformers', 'fast weight programmers', 'key-value memory', 'memory modeling', 'hybrid transformers']}","{'value': 'We develop hybrid memory architectures for general-purpose sequence processing neural networks, that combine key-value memory using softmax attention (KV-memory) with fast weight memory through dynamic synaptic modulation (FW-memory)---the core principles of quadratic and linear transformers, respectively. These two memory systems have complementary but individually limited properties: KV-memory offers precise retrieval but is constrained by quadratic complexity in sequence length, while FW-memory supports arbitrarily long sequences and enables more expressive computation but sacrifices precise recall. We propose and compare three methods to blend these two systems into a single memory system, differing in how and when input information is delivered to each system, to leverage the strengths of both. We conduct experiments on general language modeling and retrieval tasks by training 340M- and 1.3B-parameter models from scratch, as well as on synthetic algorithmic tasks designed to precisely illustrate the benefits of certain hybrid methods over others. We also evaluate our hybrid memory systems on reinforcement learning in partially observable environments. Overall, we demonstrate how a well-designed hybrid can overcome the limitations of its individual components, offering new insights into the design principle of neural memory systems.'}",https://openreview.net{'value': '/pdf/649284bceccab35070e92c0d8b08a7f73d769aa4.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=Q7YnqREWLq,{'value': 'Genesis: Multimodal Driving Scene Generation with Spatio-Temporal and Cross-Modal Consistency'},Xiangyu Guo; Zhanqian Wu; Kaixin Xiong; Ziyang Xu; Lijun Zhou; Gangwei Xu; Shaoqing Xu; Haiyang Sun; BING WANG; Guang Chen; Hangjun Ye; Wenyu Liu; Xinggang Wang,~Xiangyu_Guo5; ~Zhanqian_Wu1; ~Kaixin_Xiong1; ~Ziyang_Xu3; ~Lijun_Zhou1; ~Gangwei_Xu1; ~Shaoqing_Xu1; ~Haiyang_Sun2; ~BING_WANG23; ~Guang_Chen2; ~Hangjun_Ye1; ~Wenyu_Liu3; ~Xinggang_Wang1,{'value': ['autonomous driving; driving scenario generation']},"{'value': 'We present Genesis, a unified world model for joint generation of multi-view driving videos and LiDAR sequences with spatio-temporal and cross-modal consistency. Genesis employs a two-stage architecture that integrates a DiT-based video diffusion model with 3D-VAE encoding, and a BEV-represented LiDAR generator with NeRF-based rendering and adaptive sampling. Both modalities are directly coupled through a shared condition input, enabling coherent evolution across visual and geometric domains. To guide the generation with structured semantics, we introduce DataCrafter, a captioning module built on vision-language models that provides scene-level and instance-level captions. Extensive experiments on the nuScenes benchmark demonstrate that Genesis achieves state-of-the-art performance across video and LiDAR metrics (FVD 16.95, FID 4.24, Chamfer 0.611), and benefits downstream tasks including segmentation and 3D detection, validating the semantic fidelity and practical utility of the synthetic data.'}",https://openreview.net{'value': '/pdf/a4a4634e1dcaf8e3292d359f0dc7ac94f73516a5.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=PrYDDxphym,{'value': 'Neural Stochastic Flows: Solver-Free Modelling and Inference for SDE Solutions'},Naoki Kiyohara; Edward Johns; Yingzhen Li,~Naoki_Kiyohara1; ~Edward_Johns1; ~Yingzhen_Li1,"{'value': ['Neural stochastic flows', 'stochastic differential equations', 'normalising flows', 'continuous-time models', 'latent dynamics', 'time series modelling']}","{'value': 'Stochastic differential equations (SDEs) are well suited to modelling noisy and/or irregularly-sampled time series, which are omnipresent in finance, physics, and machine learning applications. Traditional approaches require costly simulation of numerical solvers when sampling between arbitrary time points. We introduce Neural Stochastic Flows (NSFs) and their latent dynamic versions, which learns (latent) SDE transition laws directly using conditional normalising flows, with architectural constraints that preserve properties inherited from stochastic flow. This enables sampling between arbitrary states in a single step, providing up to two orders of magnitude speedup for distant time points. Experiments on synthetic SDE simulations and real-world tracking and video data demonstrate that NSF maintains distributional accuracy comparable to numerical approaches while dramatically reducing computation for arbitrary time-point sampling, enabling applications where numerical solvers remain prohibitively expensive.'}",https://openreview.net{'value': '/pdf/1553e352e4f11e9a32e26182a59107087e8eb641.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=PhnquAa8eV,{'value': 'Inductive Domain Transfer In Misspecified Simulation-Based Inference'},Ortal Senouf; Antoine Wehenkel; Cédric Vincent-Cuaz; Emmanuel Abbe; Pascal Frossard,~Ortal_Senouf1; ~Antoine_Wehenkel1; ~Cédric_Vincent-Cuaz1; ~Emmanuel_Abbe1; ~Pascal_Frossard1,"{'value': ['AI4Science', 'SBI', 'Domain transfer', 'sim2real']}","{'value': 'Simulation-based inference (SBI) of latent parameters in physical systems is often hindered by model misspecification--the mismatch between simulated and real-world observations caused by inherent modeling simplifications. RoPE, a recent SBI approach, addresses this challenge through a two-stage domain transfer process that combines semi-supervised calibration with optimal transport (OT)-based distribution alignment. However, RoPE operates in a fully transductive setting, requiring access to a batch of test samples at inference time, which limits scalability and generalization.  We propose a fully inductive and amortized SBI framework that integrates calibration and distributional alignment into a single, end-to-end trainable model. Our method leverages mini-batch OT with a closed-form coupling to align real and simulated observations that correspond to the same latent parameters, using both paired calibration data and unpaired samples. A conditional normalizing flow is then trained to approximate the OT-induced posterior, enabling efficient inference without simulation access at test time. \nAcross a range of synthetic and real-world benchmarks--including complex medical biomarker estimation--our approach matches or exceeds the performance of RoPE, while offering improved scalability and applicability in challenging, misspecified environments.'}",https://openreview.net{'value': '/pdf/750c5d3ff705ece5809871281b1d88062cd0c1fc.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=PZqII8EoFG,{'value': 'Prioritizing Perception-Guided Self-Supervision: A New Paradigm for Causal Modeling in End-to-End Autonomous Driving'},Yi Huang; zhan qu; Lihui Jiang; Bingbing Liu; Hongbo Zhang,~Yi_Huang20; ~zhan_qu4; ~Lihui_Jiang1; ~Bingbing_Liu2; ~Hongbo_Zhang1,{'value': ['End to end autonomous driving']},"{'value': 'End-to-end autonomous driving systems, predominantly trained through imitation learning, have demonstrated considerable effectiveness in leveraging large-scale expert driving data. Despite their success in open-loop evaluations, these systems often exhibit significant performance degradation in closed-loop scenarios due to causal confusion. This confusion is fundamentally exacerbated by the overreliance of the imitation learning paradigm on expert trajectories, which often contain unattributable noise and interfere with the modeling of causal relationships between environmental contexts and appropriate driving actions.\n\nTo address this fundamental limitation, we propose Perception-Guided Self-Supervision (PGS)—a simple yet effective training paradigm that leverages perception outputs as the primary supervisory signals, explicitly modeling causal relationships in decision-making. The proposed framework aligns both the inputs and outputs of the decision-making module with perception results—such as lane centerlines and the predicted motions of surrounding agents—by introducing positive and negative self-supervision for the ego trajectory. This alignment is specifically designed to mitigate causal confusion arising from the inherent noise in expert trajectories.\n\nEquipped with perception-driven supervision, our method—built on a standard end-to-end architecture—achieves a Driving Score of 78.08 and a mean success rate of 48.64\\% on the challenging closed-loop Bench2Drive benchmark, significantly outperforming existing state-of-the-art methods, including those employing more complex network architectures and inference pipelines. These results underscore the effectiveness and robustness of the proposed PGS framework, and point to a promising direction for addressing causal confusion and enhancing real-world generalization in autonomous driving.'}",https://openreview.net{'value': '/pdf/ac51129b7a5068340b222bb3951ab25b514a5703.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=PSvsmbCrGs,{'value': 'Implicit Generative Property Enhancer'},Pedro O. Pinheiro; Pan Kessel; Aya Abdelsalam Ismail; Sai Pooja Mahajan; Kyunghyun Cho; Saeed Saremi; Natasa Tagasovska,~Pedro_O._Pinheiro1; ~Pan_Kessel1; ~Aya_Abdelsalam_Ismail1; ~Sai_Pooja_Mahajan1; ~Kyunghyun_Cho1; ~Saeed_Saremi1; ~Natasa_Tagasovska2,"{'value': ['generative modeling', 'drug discovery', 'design optimization']}","{'value': 'Generative modeling is increasingly important for data-driven computational design. Conventional approaches pair a generative model with a discriminative model to select or guide samples toward optimized designs. Yet discriminative models often struggle in data-scarce settings, common in scientific applications, and are unreliable in the tails of the distribution where optimal designs typically lie. We introduce generative property enhancer (GPE), an approach that implicitly guides generation by matching samples with lower property values to higher-value ones. Formulated as conditional density estimation, our framework defines a target distribution with improved properties, compelling the generative model to produce enhanced, diverse designs without auxiliary predictors. GPE is simple, scalable, end-to-end, modality-agnostic, and integrates seamlessly with diverse generative model architectures and losses. We demonstrate competitive empirical results on standard _in silico_ offline (non-sequential) protein fitness optimization benchmarks. Finally, we propose iterative training on a combination of limited real data and self-generated synthetic data, enabling extrapolation beyond the original property ranges.'}",https://openreview.net{'value': '/pdf/58adb3e4b625eda1a413afebe0f049f752446d86.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=PJOwQ77Mul,{'value': 'SAMPO: Scale-wise Autoregression with Motion Prompt for Generative World Models'},Sen Wang; Jingyi Tian; Le Wang; Zhimin Liao; lijiayi; Huaiyi Dong; Kun Xia; Sanping Zhou; Wei Tang; Gang Hua,~Sen_Wang19; ~Jingyi_Tian1; ~Le_Wang8; ~Zhimin_Liao1; ~lijiayi1; ~Huaiyi_Dong1; ~Kun_Xia1; ~Sanping_Zhou1; ~Wei_Tang5; ~Gang_Hua3,"{'value': ['World Model', 'Video Prediction', 'Robotic Control']}","{'value': ""World models allow agents to simulate the consequences of actions in imagined environments for planning, control, and long-horizon decision-making. However, existing autoregressive world models struggle with visually coherent predictions due to disrupted spatial structure, inefficient decoding, and inadequate motion modeling. In response, we propose Scale-wise Autoregression with Motion PrOmpt (SAMPO), a hybrid framework that combines visual autoregressive modeling for intra-frame generation with causal modeling for next-frame generation. Specifically, SAMPO integrates temporal causal decoding with bidirectional spatial attention, which preserves spatial locality and supports parallel decoding within each scale. This design significantly enhances both temporal consistency and rollout efficiency. To further improve dynamic scene understanding, we devise an asymmetric multi-scale tokenizer that preserves spatial details in observed frames and extracts compact dynamic representations for future frames, optimizing both memory usage and model performance. Additionally, we introduce a trajectory-aware motion prompt module that injects spatiotemporal cues about object and robot trajectories, focusing attention on dynamic regions and improving temporal consistency and physical realism. Extensive experiments show that SAMPO achieves competitive performance in action-conditioned video prediction and model-based control, improving generation quality with 4.4× faster inference. We also evaluate SAMPO's zero-shot generalization and scaling behavior, demonstrating its ability to generalize to unseen tasks and benefit from larger model sizes.""}",https://openreview.net{'value': '/pdf/829c7820e5b754498ac9f30bbe8588d4d77b2ddf.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=PAIVwOaAnq,{'value': 'Shape it Up! Restoring LLM Safety during Finetuning'},ShengYun Peng; Pin-Yu Chen; Jianfeng Chi; Seongmin Lee; Duen Horng Chau,~ShengYun_Peng1; ~Pin-Yu_Chen1; ~Jianfeng_Chi1; ~Seongmin_Lee2; ~Duen_Horng_Chau1,"{'value': ['LLM', 'LLM finetuning', 'LLM finetuning risks', 'harmful finetuning', 'guardrail', 'safe guard', 'safety shaping']}","{'value': 'Finetuning large language models (LLMs) enables user-specific customization but introduces critical safety risks: even a few harmful examples can compromise safety alignment. A common mitigation strategy is to update the model more strongly on examples deemed safe, while downweighting or excluding those flagged as unsafe. However, because safety context can shift within a single example, updating the model equally on both harmful and harmless parts of a response is suboptimal — an atomic treatment we term static safety shaping. In contrast, we propose dynamic safety shaping (DSS), a dynamic shaping framework that uses fine-grained safety signals to reinforce learning from safe segments of a response while suppressing unsafe content. To enable such fine-grained control during finetuning, we introduce a key insight: guardrail models, traditionally used for filtering, can be repurposed to evaluate partial responses, tracking how safety risk evolves throughout the response, segment by segment. This leads to the Safety Trajectory Assessment of Response (STAR), a token-level signal that enables shaping to operate dynamically over the training sequence. Building on this, we present ★DSS, a DSS method guided by STAR scores that robustly mitigates finetuning risks and delivers substantial safety improvements across diverse threats, datasets, and model families, all without compromising capability on intended tasks. We encourage future safety research to build on dynamic shaping principles for stronger mitigation against evolving finetuning risks. Our code is publicly available at https://github.com/poloclub/star-dss'}",https://openreview.net{'value': '/pdf/d1bd2173c57d6c40a221125d48a43b0c5b1b696b.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=P69X3V4WwH,{'value': 'StruDiCO: Structured Denoising Diffusion with Gradient-free Inference-stage Boosting for Memory and Time Efficient Combinatorial Optimization'},Yu Wang; Yang Li; Junchi Yan; Yi Chang,~Yu_Wang61; ~Yang_Li32; ~Junchi_Yan2; ~Yi_Chang4,"{'value': ['Neural Combinatorial Optimization', 'Generative Modeling']}","{'value': 'Diffusion models have recently emerged as powerful neural solvers for combinatorial optimization (CO). However, existing approaches fail to reveal how variables are progressively determined during inference, making the final solution opaque until the last step. To address this limitation, we propose a structured denoising diffusion model, StruDiCO, which incrementally constructs solutions through step-wise variable selection. This is achieved via a variable-absorption noising model, wherein the forward process simulates gradual variable deactivation, converging to an empty solution, while the reverse process incrementally selects variables to reconstruct the final solution. This design induces structural continuity across intermediate states, enabling interpretable and trajectory-consistent partial solutions throughout inference. To further improve the reliability of reverse inference, we introduce a constrained consistency sampling strategy, which suppresses low-confidence variable selection at each step to stabilize the reverse process. Leveraging the structure-preserving reverse process, we further propose a lightweight, gradient-free, objective-aware refinement framework, which iteratively improves solution quality by applying structure-aware perturbations to the current solution, performing reverse inference through the constraint consistency model, and decoding with an objective-guided scoring scheme. Extensive experiments on two canonical CO tasks, the Traveling Salesman Problem (TSP) and Maximal Independent Set (MIS), show that StruDiCO outperforms state-of-the-art diffusion-based solvers, achieving up to $3.5\\times$ faster inference, 70\\% lower GPU memory usage, and significantly improved solution quality, with up to 37.7\\% drop reduction on TSP and an average 38.1\\% improvement on MIS.\nThe codes are publicly available at https://github.com/yuuuuwang/StruDiCO.'}",https://openreview.net{'value': '/pdf/c20f6e7ed940c3da0e3fcbbbeda9d9aa0e16ea01.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=P4xaLYXBRe,{'value': 'SPACE: Noise Contrastive Estimation Stabilizes Self-Play Fine-Tuning for Large Language Models'},Yibo Wang; Guangda Huzhang; Qing-Guo Chen; Zhao Xu; Weihua Luo; Kaifu Zhang; Lijun Zhang,~Yibo_Wang2; ~Guangda_Huzhang2; ~Qing-Guo_Chen1; ~Zhao_Xu7; ~Weihua_Luo2; ~Kaifu_Zhang2; ~Lijun_Zhang1,"{'value': ['Language Models', 'Self-play Fine-tuning', 'Noise Contrastive Estimation']}","{'value': 'Self-play fine-tuning has demonstrated promising abilities in adapting large language models (LLMs) to downstream tasks with limited real-world data. The basic principle is to iteratively refine the model with real samples and synthetic ones generated from itself. However, the existing methods primarily focus on the relative gaps between the rewards for two types of data, neglecting their absolute values. Through theoretical analysis, we identify that the gap-based methods suffer from unstable evolution, due to the potentially degenerated objectives. To address this limitation, we introduce a novel self-play fine-tuning method, namely \\underline{S}elf-\\underline{P}l\\underline{A}y via Noise \\underline{C}ontrastive \\underline{E}stimation (SPACE), which leverages noise contrastive estimation to capture the real-world data distribution. Specifically, SPACE treats synthetic samples as auxiliary components, and discriminates them from the real ones in a binary classification manner. As a result, SPACE independently optimizes the absolute reward values for each type of data, ensuring a consistently meaningful objective and thereby avoiding the instability issue. Theoretically, we show that the optimal solution of the objective in SPACE aligns with the underlying distribution of real-world data, and SPACE guarantees a provably stable convergence to the optimal distribution. Empirically, we show that SPACE significantly improves the performance of LLMs over various tasks, and outperforms supervised fine-tuning that employs much more real-world samples. Compared to gap-based self-play fine-tuning methods, SPACE exhibits remarkable superiority and stable evolution.'}",https://openreview.net{'value': '/pdf/694976ed654aa651e22e67966e61c6b69f328d65.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=P382qaxvjc,{'value': 'HAODiff: Human-Aware One-Step Diffusion via Dual-Prompt Guidance'},Jue Gong; Tingyu Yang; Jingkai Wang; Zheng Chen; Xing Liu; Hong Gu; Yulun Zhang; Xiaokang Yang,~Jue_Gong1; ~Tingyu_Yang2; ~Jingkai_Wang2; ~Zheng_Chen11; ~Xing_Liu13; ~Hong_Gu1; ~Yulun_Zhang1; ~Xiaokang_Yang1,"{'value': ['Low-level Vision', 'Diffusion Model', 'Human Body Restoration']}","{'value': 'Human-centered images often suffer from severe generic degradation during transmission and are prone to human motion blur (HMB), making restoration challenging. Existing research lacks sufficient focus on these issues, as both problems often coexist in practice. To address this, we design a degradation pipeline that simulates the coexistence of HMB and generic noise, generating synthetic degraded data to train our proposed HAODiff, a human-aware one-step diffusion. Specifically, we propose a triple-branch dual-prompt guidance (DPG), which leverages high-quality images, residual noise (LQ minus HQ), and HMB segmentation masks as training targets. It produces a positive–negative prompt pair for classifier‑free guidance (CFG) in a single diffusion step. The resulting adaptive dual prompts let HAODiff exploit CFG more effectively, boosting robustness against diverse degradations. For fair evaluation, we introduce MPII‑Test, a benchmark rich in combined noise and HMB cases. Extensive experiments show that our HAODiff surpasses existing state-of-the-art (SOTA) methods in terms of both quantitative metrics and visual quality on synthetic and real-world datasets, including our introduced MPII-Test. Code is available at: https://github.com/gobunu/HAODiff.'}",https://openreview.net{'value': '/pdf/3b993460c5fcc36340dca7862581f3e0e027a8e4.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=Owu54YW8HR,{'value': 'Zero-Shot Trajectory Planning for Signal Temporal Logic Tasks'},Ruijia Liu; Ancheng Hou; Xiao Yu; Xiang Yin,~Ruijia_Liu1; ~Ancheng_Hou1; ~Xiao_Yu3; ~Xiang_Yin5,"{'value': ['signal temporal logic', 'diffusion model', 'trajectory planning']}","{'value': 'Signal Temporal Logic (STL) is a powerful specification language for describing complex temporal behaviors of continuous signals, making it well-suited for high-level robotic task descriptions. However, generating executable plans for STL tasks is challenging, as it requires consideration of the coupling between the task specification and the system dynamics. Existing approaches either follow a model-based setting that explicitly requires knowledge of the system dynamics or adopt a task-oriented data-driven approach to learn plans for specific tasks. In this work, we address the problem of generating executable STL plans for systems with unknown dynamics. We propose a  hierarchical planning framework that enables zero-shot generalization to new STL tasks by leveraging only task-agnostic trajectory data during offline training. The framework consists of three key components: (i) decomposing the STL specification into several progresses and time constraints, (ii) searching for timed waypoints that satisfy all progresses under time constraints, and (iii) generating trajectory segments using a pre-trained diffusion model and stitching them into complete trajectories. We formally prove that our method guarantees STL satisfaction, and simulation results demonstrate its effectiveness in generating dynamically feasible trajectories across diverse long-horizon STL tasks. Project Page: https://cps-sjtu.github.io/Zero-Shot-STL/'}",https://openreview.net{'value': '/pdf/d6e6ed98e40aaaff438ff0db55bd3466643319bd.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=Ou30gzTLJe,{'value': 'Towards Self-Refinement of Vision-Language Models with Triangular Consistency'},Yunlong Deng; Guangyi Chen; Tianpei Gu; Lingjing Kong; Yan Li; Zeyu Tang; Kun Zhang,~Yunlong_Deng1; ~Guangyi_Chen1; ~Tianpei_Gu1; ~Lingjing_Kong1; ~Yan_Li44; ~Zeyu_Tang1; ~Kun_Zhang1,"{'value': ['Vision-Language Models', 'Self-Refinement', 'Unsupervised Learning']}","{'value': 'Vision-Language Models (VLMs) integrate visual knowledge with the analytical capabilities of Large Language Models (LLMs) through supervised visual instruction tuning, using image-question-answer triplets. However, the potential of VLMs trained without supervised instruction remains largely unexplored. This study validates that VLMs possess inherent self-refinement capabilities, enabling them to generate high-quality supervised data without external inputs and thereby learn autonomously. Specifically, to stimulate the self-refinement ability of VLMs, we propose a self-refinement framework based on a Triangular Consistency principle: within the image-query-answer triangle, any masked elements should be consistently and accurately reconstructed. The framework involves three steps: (1) We enable the instruction generation ability of VLMs by adding multi-task instruction tuning like image$\\rightarrow$question-answer or image-answer$\\rightarrow$question. (2) We generate image-query-answer triplets from unlabeled images and use the Triangular Consistency principle for filtering. (3) The model is further updated using the filtered synthetic data. \nTo investigate the underlying mechanisms behind this self-refinement capability, we conduct a theoretical analysis from a causal perspective. \nUsing the widely recognized LLaVA-1.5 as our baseline, our experiments reveal that the model can autonomously achieve consistent, though deliberately modest, improvements across multiple benchmarks without any external supervision, such as human annotations or environmental feedback.\nWe expect that the insights of this study on the self-refinement ability of VLMs can inspire future research on the learning mechanism of VLMs. Code is available at https://github.com/dengyl20/SRF-LLaVA-1.5.'}",https://openreview.net{'value': '/pdf/3acba55c4efdef3ee37a854031bdd972e9e31008.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=OhUu5PlRkF,{'value': 'CAML: Collaborative Auxiliary Modality Learning for Multi-Agent Systems'},Rui Liu; Yu Shen; Peng Gao; Pratap Tokekar; Ming Lin,~Rui_Liu19; ~Yu_Shen1; ~Peng_Gao4; ~Pratap_Tokekar1; ~Ming_Lin2,"{'value': ['Multi-Modal Learning', 'Multi-Agent Systems', 'Collaborative Auxiliary Modality Learning']}","{'value': 'Multi-modal learning has emerged as a key technique for improving performance across domains such as autonomous driving, robotics, and reasoning. However, in certain scenarios, particularly in resource-constrained environments, some modalities available during training may be absent during inference. While existing frameworks effectively utilize multiple data sources during training and enable inference with reduced modalities, they are primarily designed for single-agent settings. This poses a critical limitation in dynamic environments such as connected autonomous vehicles (CAV), where incomplete data coverage can lead to decision-making blind spots. Conversely, some works explore multi-agent collaboration but without addressing missing modality at test time. To overcome these limitations, we propose Collaborative Auxiliary Modality Learning (CAML), a novel multi-modal multi-agent framework that enables agents to collaborate and share multi-modal data during training, while allowing inference with reduced modalities during testing. Experimental results in collaborative decision-making for CAV in accident-prone scenarios demonstrate that CAML achieves up to a 58.1% improvement in accident detection. Additionally, we validate CAML on real-world aerial-ground robot data for collaborative semantic segmentation, achieving up to a 10.6% improvement in mIoU.'}",https://openreview.net{'value': '/pdf/ecf80a1537bbfd15794b5058a00bf689f30f6583.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=Ogml5bxDH3,{'value': 'Value-Guided Decision Transformer: A Unified Reinforcement Learning Framework for Online and Offline Settings'},Hongling Zheng; Li Shen; Yong Luo; Deheng Ye; Shuhan Xu; Bo Du; Jialie Shen; Dacheng Tao,~Hongling_Zheng2; ~Li_Shen1; ~Yong_Luo2; ~Deheng_Ye1; ~Shuhan_Xu1; ~Bo_Du3; ~Jialie_Shen2; ~Dacheng_Tao1,"{'value': ['Offline RL', 'Conditional Sequence Modeling', 'Decision Transformer']}","{'value': ""The Conditional Sequence Modeling (CSM) paradigm, benefiting from the transformer's powerful distribution modeling capabilities, has demonstrated considerable promise in Reinforcement Learning (RL) tasks. However, much of the work has focused on applying CSM to single online or offline settings, with the general architecture rarely explored. Additionally, existing methods primarily focus on deterministic trajectory modeling, overlooking the randomness of state transitions and the diversity of future trajectory distributions. Fortunately, value-based methods offer a viable solution for CSM, further bridging the potential gap between offline and online RL. In this paper, we propose Value-Guided Decision Transformer (VDT), which leverages value functions to perform advantage-weighting and behavior regularization on the Decision Transformer (DT), guiding the policy toward upper-bound optimal decisions during the offline training phase. In the online tuning phase, VDT further integrates value-based policy improvement with behavior cloning under the CSM architecture through limited interaction and data collection, achieving performance improvement within minimal timesteps. The predictive capability of value functions for future returns is also incorporated into the sampling process. Our method achieves competitive performance on various standard RL benchmarks, providing a feasible solution for developing CSM architectures in general scenarios. Code is available at here.""}",https://openreview.net{'value': '/pdf/11c10f9f5570fac4a8e39ffe4ab377d323f6abf2.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=OfMCET0hqJ,{'value': 'Time Reversal Symmetry for Efficient Robotic Manipulations in Deep Reinforcement Learning'},Yunpeng Jiang; Jianshu Hu; Paul Weng; Yutong Ban,~Yunpeng_Jiang1; ~Jianshu_Hu1; ~Paul_Weng1; ~Yutong_Ban1,"{'value': ['Deep Reinforcement Learning', 'Robotics Control']}","{'value': 'Symmetry is pervasive in robotics and has been widely exploited to improve sample efficiency in deep reinforcement learning (DRL). However, existing approaches primarily focus on spatial symmetries—such as reflection, rotation, and translation—while largely neglecting temporal symmetries. To address this gap, we explore time reversal symmetry, a form of temporal symmetry commonly found in robotics tasks such as door opening and closing. We propose Time Reversal symmetry enhanced Deep Reinforcement Learning (TR-DRL), a framework that combines trajectory reversal augmentation and time reversal guided reward shaping to efficiently solve temporally symmetric tasks. Our method generates reversed transitions from fully reversible transitions, identified by a proposed dynamics-consistent filter, to augment the training data. For partially reversible transitions, we apply reward shaping to guide learning, according to successful trajectories from the reversed task. Extensive experiments on the Robosuite and MetaWorld benchmarks demonstrate that TR-DRL is effective in both single-task and multi-task settings, achieving higher sample efficiency and stronger final performance compared to baseline methods.'}",https://openreview.net{'value': '/pdf/2061e5ae8cf684bf3400e9234f6ebce715b530ac.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=OaNbl9b56B,{'value': 'Do-PFN: In-Context Learning for Causal Effect Estimation'},Jake Robertson; Arik Reuter; Siyuan Guo; Noah Hollmann; Frank Hutter; Bernhard Schölkopf,~Jake_Robertson1; ~Arik_Reuter1; ~Siyuan_Guo1; ~Noah_Hollmann1; ~Frank_Hutter1; ~Bernhard_Schölkopf1,"{'value': ['Prior-Data Fitted Networks', 'Causality', 'Causal Effect Estimation', 'CATE Estimation', 'Amortized Inference', 'In-Context Learning']}","{'value': 'Causal effect estimation is critical to a range of scientific disciplines. Existing methods for this task either require interventional data, knowledge about the ground-truth causal graph, or rely on assumptions such as unconfoundedness, restricting their applicability in real-world settings. In the domain of tabular machine learning, Prior-data fitted networks (PFNs) have achieved state-of-the-art predictive performance, having been pre-trained on synthetic causal data to solve tabular prediction problems via in-context learning. To assess whether this can be transferred to the problem of causal effect estimation, we pre-train PFNs on synthetic data drawn from a wide variety of causal structures, including interventions, to predict interventional outcomes given observational data. Through extensive experiments in synthetic and semi-synthetic settings, we show that our approach allows for the accurate estimation of causal effects without knowledge of the underlying causal graph.'}",https://openreview.net{'value': '/pdf/11b6cd978f8807f801432ebecd42222eb1d48b37.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=OZljvntsto,{'value': 'Grids Often Outperform Implicit Neural Representation at Compressing Dense Signals'},Namhoon Kim; Sara Fridovich-Keil,~Namhoon_Kim2; ~Sara_Fridovich-Keil1,"{'value': ['Implicit Neural Representations (INR)', 'Grid', 'Interpolation', 'Bandwidth', 'Inverse Problems']}","{'value': 'Implicit Neural Representations (INRs) have recently shown impressive results, but their fundamental capacity, implicit biases, and scaling behavior remain poorly understood. We investigate the performance of diverse INRs across a suite of 2D and 3D real and synthetic signals with varying effective bandwidth, as well as both overfitting and generalization tasks including tomography, super-resolution, and denoising. By stratifying performance according to model size as well as signal type and bandwidth, our results shed light on how different INR and grid representations allocate their capacity. We find that, for most tasks and signals, a simple regularized grid with interpolation trains faster and to higher quality than any INR with the same number of parameters. We also find limited settings–namely fitting binary signals such as shape contours–where INRs outperform grids, to guide future development and use of INRs towards the most advantageous applications.'}",https://openreview.net{'value': '/pdf/13c6cee0202b9ec3018c19cd19ac9a090696fe63.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=OKf5SSUhJF,{'value': 'Enhancing Diffusion-based Unrestricted Adversarial Attacks via Adversary Preferences Alignment'},Kaixun Jiang; Zhaoyu Chen; HaiJing Guo; Jinglun Li; Jiyuan Fu; Pinxue Guo; Hao Tang; Bo Li; Wenqiang Zhang,~Kaixun_Jiang1; ~Zhaoyu_Chen1; ~HaiJing_Guo1; ~Jinglun_Li1; ~Jiyuan_Fu1; ~Pinxue_Guo1; ~Hao_Tang6; ~Bo_Li20; ~Wenqiang_Zhang1,"{'value': ['unrestricted adversarial attack', 'preference alignment']}","{'value': 'Preference alignment in diffusion models has primarily focused on benign human preferences (e.g., aesthetic). In this paper, we propose a novel perspective: framing unrestricted adversarial example generation as a problem of aligning with adversary preferences. Unlike benign alignment, adversarial alignment involves two inherently conflicting preferences: visual consistency and attack effectiveness, which often lead to unstable optimization and reward hacking (e.g., reducing visual quality to improve attack success). To address this, we propose APA (Adversary Preferences Alignment), a two-stage framework that decouples conflicting preferences and optimizes each with differentiable rewards. In the first stage, APA fine-tunes LoRA to improve visual consistency using rule-based similarity reward. In the second stage, APA updates either the image latent or prompt embedding based on feedback from a substitute classifier, guided by trajectory-level and step-wise rewards. To enhance black-box transferability, we further incorporate a diffusion augmentation strategy. Experiments demonstrate that APA achieves significantly better attack transferability while maintaining high visual consistency, inspiring further research to approach adversarial attacks from an alignment perspective.'}",https://openreview.net{'value': '/pdf/3d2dc3627bd25e3cef5ba061fa69cab5ef2983bd.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=OEawM2coNT,{'value': 'Partition to Evolve: Niching-enhanced Evolution with LLMs for Automated Algorithm Discovery'},Qinglong Hu; Qingfu Zhang,~Qinglong_Hu1; ~Qingfu_Zhang1,"{'value': ['Automated algorithm discovery', 'Evolutionary computation', 'Large language model']}","{'value': 'Large language model-assisted Evolutionary Search (LES) has emerged as a promising approach for Automated Algorithm Discovery (AAD). While many evolutionary search strategies have been developed for classic optimization problems, LES operates in abstract language spaces, presenting unique challenges for applying these strategies effectively. To address this, we propose a general LES framework that incorporates feature-assisted niche construction within abstract search spaces, enabling the seamless integration of niche-based search strategies from evolutionary computation. Building on this framework, we introduce PartEvo, an LES method that combines niche collaborative search and advanced prompting strategies to improve algorithm discovery efficiency. Experiments on both synthetic and real-world optimization problems show that PartEvo outperforms human-designed baselines and surpasses prior LES methods, such as Eoh and Funsearch. In particular, on resource scheduling tasks, PartEvo generates meta-heuristics with low design costs, achieving up to 90.1\\% performance improvement over widely-used baseline algorithms, highlighting its potential for real-world applications.'}",https://openreview.net{'value': '/pdf/f15d31656faac2d98a5ae511927e6845a7efa54e.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=NwLOIEi9vX,{'value': 'Optimizing the Unknown: Black Box Bayesian Optimization with Energy-Based Model and Reinforcement Learning'},RUIYAO MIAO; Junren Xiao; Shiya Tsang; Hui Xiong; Ying Nian Wu,~RUIYAO_MIAO1; ~Junren_Xiao1; ~Shiya_Tsang2; ~Hui_Xiong1; ~Ying_Nian_Wu1,"{'value': ['Black Box Optimization', 'Bayesian Optimization', 'Energy-Based Model', 'Reinforcement Learning']}","{'value': 'Existing Bayesian Optimization (BO) methods typically balance exploration and exploitation to optimize costly objective functions. However, these methods often suffer from a significant one-step bias, which may lead to convergence towards local optima and poor performance in complex or high-dimensional tasks. Recently, Black-Box Optimization (BBO) has achieved success across various scientific and engineering domains, particularly when function evaluations are costly and gradients are unavailable. Motivated by this, we propose the Reinforced Energy-Based Model for Bayesian Optimization (REBMBO), which integrates Gaussian Processes (GP) for local guidance with an Energy-Based Model (EBM) to capture global structural information. Notably, we define each Bayesian Optimization iteration as a Markov Decision Process (MDP) and use Proximal Policy Optimization (PPO) for adaptive multi-step lookahead, dynamically adjusting the depth and direction of exploration to effectively overcome the limitations of traditional BO methods. We conduct extensive experiments on synthetic and real-world benchmarks, confirming the superior performance of REBMBO. Additional analyses across various GP configurations further highlight its adaptability and robustness. Our code is publicly available at: https://github.com/ruiyaoMiao0809/Black-Box-Bayesian-Optimization-with-Energy-Based-Model-and-Reinforcement-Learning'}",https://openreview.net{'value': '/pdf/ee40111392f9988f18a25eec8e1169454ec8bd7a.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=NpRbTTgRBG,{'value': 'RaySt3R: Predicting Novel Depth Maps for Zero-Shot Object Completion'},Bardienus Pieter Duisterhof; Jan Oberst; Bowen Wen; Stan Birchfield; Deva Ramanan; Jeffrey Ichnowski,~Bardienus_Pieter_Duisterhof1; ~Jan_Oberst1; ~Bowen_Wen1; ~Stan_Birchfield1; ~Deva_Ramanan1; ~Jeffrey_Ichnowski1,"{'value': ['3D Vision', '3D completion']}","{'value': '3D shape completion has broad applications in robotics, digital twin reconstruction, and extended reality (XR). Although recent advances in 3D object and scene completion have achieved impressive results, existing methods lack 3D consistency, are computationally expensive, and struggle to capture sharp object boundaries. \nOur work (RaySt3R) addresses these limitations by recasting 3D shape completion as a novel view synthesis problem. \nSpecifically, given a single RGB-D image, \nand a novel viewpoint (encoded as a collection of query rays),\nwe train a feedforward transformer to predict depth maps, object masks, and per-pixel confidence scores for those query rays. \nRaySt3R fuses these predictions across multiple query views \nto reconstruct complete 3D shapes. \nWe evaluate RaySt3R on synthetic and real-world datasets, and observe it achieves state-of-the-art performance,\noutperforming the baselines on all datasets by up to 44% in 3D chamfer distance.'}",https://openreview.net{'value': '/pdf/5ce1e90c1710406515590644e0b438d818e0a51d.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=NoC9HT7Kf7,{'value': 'VideoHallu: Evaluating and Mitigating Multi-modal Hallucinations on Synthetic Video Understanding'},Zongxia Li; Xiyang Wu; Guangyao Shi; Yubin Qin; Hongyang Du; Tianyi Zhou; Dinesh Manocha; Jordan Lee Boyd-Graber,~Zongxia_Li1; ~Xiyang_Wu1; ~Guangyao_Shi2; ~Yubin_Qin2; ~Hongyang_Du2; ~Tianyi_Zhou2; ~Dinesh_Manocha3; ~Jordan_Lee_Boyd-Graber1,"{'value': ['Vision-language Model', 'Video Understanding', 'Video Generation', 'Hallucination', 'Diffusion Models Monitoring']}","{'value': 'Vision Language models (VLMs) have achieved remarkable success in video understanding tasks. Yet, a key question remains: Do they comprehend visual information or merely learn superficial mappings between visual and textual patterns? \nUnderstanding visual cues, particularly those related to physics and common sense, is crucial for AI systems interacting with the physical world. However, existing VLM evaluations primarily rely on positive-control tests using real-world videos that resemble training distributions. While VLMs perform well on such benchmarks, it is unclear whether they grasp underlying visual and contextual signals or simply exploit visual-language correlations. To fill this gap, we propose incorporating negative-control tests, i.e., videos depicting physically impossible or logically inconsistent scenarios, and evaluating whether models can recognize these violations. True visual understanding should evince comparable performance across both positive and negative tests. Since such content is rare in the real world, we introduce VideoHallu, a synthetic video dataset featuring physics- and commonsense-violating scenes generated using state-of-the-art tools such as Veo2, Sora, and Kling. The dataset includes expert-annotated question-answer pairs spanning four categories of physical and commonsense violations, designed to be straightforward for human reasoning. We evaluate several leading VLMs, including Qwen-2.5-VL, Video-R1, and VideoChat-R1. Despite their strong performance on real-world benchmarks (e.g., MVBench, MMVU), these models hallucinate or fail to detect physical or logical violations, revealing fundamental weaknesses in visual understanding. Finally, we explore reinforcement learning-based post-training on our negative dataset: fine-tuning improves performance on VideoHallu without degrading results on standard benchmarks, indicating enhanced visual reasoning in VLMs. Our data is available at https://github.com/zli12321/VideoHallu.git.'}",https://openreview.net{'value': '/pdf/756648ea95e703a5d406ef365ed123793db01cae.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=NgLFQTBPRR,{'value': 'An Evidence-Based Post-Hoc Adjustment Framework for Anomaly Detection Under Data Contamination'},Sukanya Patra; Souhaib Ben Taieb,~Sukanya_Patra1; ~Souhaib_Ben_Taieb2,"{'value': ['anomaly detection', 'anomaly', 'contamination', 'test-time adaptation']}","{'value': 'Unsupervised anomaly detection (AD) methods typically assume clean training data, yet real-world datasets often contain undetected or mislabeled anomalies, leading to significant performance degradation. Existing solutions require access to the training pipelines, data or prior knowledge of the proportions of anomalies in the data, limiting their real-world applicability. To address this challenge, we propose EPHAD, a simple yet effective test-time adaptation framework that updates the outputs of AD models trained on contaminated datasets using evidence gathered at test time. Our approach integrates the prior knowledge captured by the AD model trained on contaminated datasets with evidence derived from multimodal foundation models like Contrastive Language-Image Pre-training (CLIP), classical AD methods like the Latent Outlier Factor or domain-specific knowledge. We illustrate the intuition behind EPHAD using a synthetic toy example and validate its effectiveness through comprehensive experiments across eight visual AD datasets, twenty-six tabular AD datasets, and a real-world industrial AD dataset. Additionally, we conduct an ablation study to analyse hyperparameter influence and robustness to varying contamination levels, demonstrating the versatility and robustness of EPHAD across diverse AD models and evidence pairs. To ensure reproducibility, our code is publicly available at https://github.com/sukanyapatra1997/EPHAD.'}",https://openreview.net{'value': '/pdf/25cad35493ea7cd6ca73fb415b52b7f54d237505.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=NYuvz5YUzy,{'value': 'Generative Perception of Shape and Material from Differential Motion'},Xinran Han; Ko Nishino; Todd Zickler,~Xinran_Han1; ~Ko_Nishino4; ~Todd_Zickler1,"{'value': ['generative perception', 'diffusion models', 'mid-level vision', 'perceptual ambiguity', 'shape reconstruction', 'material estimation']}","{'value': 'Perceiving the shape and material of an object from a single image is inherently ambiguous, especially when lighting is unknown and unconstrained. Despite this, humans can often disentangle shape and material, and when they are uncertain, they often move their head slightly or rotate the object to help resolve the ambiguities. Inspired by this behavior, we introduce a novel conditional denoising-diffusion model that generates samples of shape-and-material maps from a short video of an object undergoing differential motions. Our parameter-efficient architecture allows training directly in pixel-space, and it generates many disentangled attributes of an object simultaneously. Trained on a modest number of synthetic object-motion videos with supervision on shape and material, the model exhibits compelling emergent behavior: For static observations, it produces diverse, multimodal predictions of plausible shape-and-material maps that capture the inherent ambiguities; and when objects move, the distributions converge to more accurate explanations. The model also produces high-quality shape-and-material estimates for less ambiguous, real-world objects. \nBy moving beyond single-view to continuous motion observations, and by using generative perception to capture visual ambiguities, our work suggests ways to improve visual reasoning in physically-embodied systems.'}",https://openreview.net{'value': '/pdf/71ee2336c2f9c3274d08e92fd0ccd243cc1cea35.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=NNiwGUY50Y,{'value': 'ROVER: Recursive Reasoning Over Videos with Vision-Language Models for Embodied Tasks'},Philip Schroeder; Ondrej Biza; Thomas Weng; Hongyin Luo; James R. Glass,~Philip_Schroeder1; ~Ondrej_Biza1; ~Thomas_Weng1; ~Hongyin_Luo1; ~James_R._Glass1,"{'value': ['vision-language model', 'video reasoning', 'embodied intelligence', 'recursion']}","{'value': ""Vision-language models (VLMs) have exhibited impressive capabilities across diverse image understanding tasks, but still struggle in settings that require reasoning over extended sequences of camera frames from a video. This limits their utility in embodied settings, which require reasoning over long frame sequences from a continuous stream of visual input at each moment of a task attempt. To address this limitation, we propose ROVER (Reasoning Over VidEo Recursively), a framework that enables the model to recursively decompose long-horizon video trajectories into segments corresponding to shorter subtasks within the trajectory. In doing so, ROVER facilitates more focused and accurate reasoning over temporally localized frame sequences without losing global context. We evaluate ROVER, implemented using an in-context learning approach, on diverse OpenX Embodiment videos and on a new dataset derived from RoboCasa that consists of 543 videos showing both expert and perturbed non-expert trajectories across 27 manipulation tasks. ROVER outperforms strong baselines across three video reasoning tasks: task progress estimation, frame-level natural language reasoning, and video question answering. We observe that, by reducing the number of frames the model reasons over at each timestep, ROVER mitigates model hallucinations, especially during unexpected or non-optimal moments of a trajectory. In addition, by enabling the implementation of a subtask-specific sliding context window, ROVER's time complexity scales linearly with video length, an asymptotic improvement over baselines.""}",https://openreview.net{'value': '/pdf/194ef43930192ab08c960e21945eb03ce919797a.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=NNHgm6VJkC,{'value': 'GeneMAN: Generalizable Single-Image 3D Human Reconstruction from Multi-Source Human Data'},Wentao Wang; Hang Ye; Fangzhou Hong; Xue Yang; Jianfu Zhang; Yizhou Wang; Ziwei Liu; Liang Pan,~Wentao_Wang2; ~Hang_Ye1; ~Fangzhou_Hong1; ~Xue_Yang2; ~Jianfu_Zhang2; ~Yizhou_Wang1; ~Ziwei_Liu1; ~Liang_Pan2,{'value': ['3D Human Reconstruction;  Multi-source Human Dataset; Single Image-3D Reconstruction']},"{'value': 'Given a single in-the-wild human photo, it remains a challenging task to reconstruct a high-fidelity 3D human model. Existing methods face difficulties including a) the varying body proportions captured by in-the-wild human images; b) diverse personal belongings within the shot; and c) ambiguities in human postures and inconsistency in human textures. In addition, the scarcity of high-quality human data intensifies the challenge. To address these problems, we propose a Generalizable image-to-3D huMAN reconstruction framework, dubbed GeneMAN, building upon a comprehensive multi-source collection of high-quality human data, including 3D scans, multi-view videos, single photos, and our generated synthetic human data. GeneMAN encompasses three key modules. 1) Without relying on parametric human models (e.g., SMPL), GeneMAN first trains a human-specific text-to-image diffusion model and a view-conditioned diffusion model, serving as GeneMAN 2D human prior and 3D human prior for reconstruction, respectively. 2) With the help of the pretrained human prior models, the Geometry Initialization-&-Sculpting pipeline is leveraged to recover high-quality 3D human geometry given a single image. 3) To achieve high-fidelity 3D human textures, GeneMAN employs the Multi-Space Texture Refinement pipeline, consecutively refining textures in the latent and the pixel spaces. Extensive experimental results demonstrate that GeneMAN could generate high-quality 3D human models from a single image input, outperforming prior state-of-the-art methods. Notably, GeneMAN could reveal much better generalizability in dealing with in-the-wild images, often yielding high-quality 3D human models in natural poses with common items, regardless of the body proportions in the input images.'}",https://openreview.net{'value': '/pdf/6b7d857c87c324abe09b8327b3ea3f2f2b69d9c7.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=NLLLkiF3xa,{'value': 'Johnson-Lindenstrauss Lemma Beyond Euclidean Geometry'},Chengyuan Deng; Jie Gao; Kevin Lu; Feng Luo; Cheng Xin,~Chengyuan_Deng1; ~Jie_Gao6; ~Kevin_Lu4; ~Feng_Luo2; ~Cheng_Xin2,"{'value': ['Johnson-Lindenstrauss Lemma', 'Non-Euclidean Geometry']}","{'value': 'The Johnson-Lindenstrauss (JL) lemma is a cornerstone of dimensionality reduction in Euclidean space, but its applicability to non-Euclidean data has remained limited. This paper extends the JL lemma beyond Euclidean geometry to handle general dissimilarity matrices that are prevalent in real-world applications. We present two complementary approaches: First, we show how the JL transform can be applied to vectors in pseudo-Euclidean space with signature $(p,q)$, providing theoretical guarantees that depend on the ratio of the $(p, q)$ norm and Euclidean norm of two vectors, measuring the deviation from Euclidean geometry. Second, we prove that any symmetric hollow dissimilarity matrix can be represented as a matrix of generalized power distances, with an additional parameter representing the uncertainty level within the data. In this representation, applying the JL transform yields multiplicative approximation with a controlled additive error term proportional to the deviation from Euclidean geometry. Our theoretical results provide fine-grained performance analysis based on the degree to which the input data deviates from Euclidean geometry, making practical and meaningful reduction in dimensionality accessible to a wider class of data. We validate our approaches on both synthetic and real-world datasets, demonstrating the effectiveness of extending the JL lemma to non-Euclidean settings.'}",https://openreview.net{'value': '/pdf/ee58bd1ee4f47a814b4f1bd7c05d2212ff8e6084.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=NKcwN347H7,{'value': 'InfantAgent-Next: A Multimodal Generalist Agent for Automated Computer Interaction'},Bin Lei; Weitai Kang; Zijian Zhang; Winson Chen; Xi Xie; Shan Zuo; Mimi Xie; Ali Payani; Mingyi Hong; Yan Yan; Caiwen Ding,~Bin_Lei1; ~Weitai_Kang1; ~Zijian_Zhang13; ~Winson_Chen1; ~Xi_Xie1; ~Shan_Zuo1; ~Mimi_Xie1; ~Ali_Payani1; ~Mingyi_Hong1; ~Yan_Yan6; ~Caiwen_Ding1,"{'value': ['LLM based Agent', 'Multimodal Generalist Agent', 'Automated Computer Interaction', 'Infrastructure']}","{'value': 'This paper introduces \\textsc{InfantAgent-Next}, a generalist agent capable of interacting with computers in a multimodal manner, encompassing text, images, audio, and video.\nUnlike existing approaches that either build intricate workflows around a single large model or only provide workflow modularity, our agent integrates tool-based and pure vision agents within a highly modular architecture, enabling different models to collaboratively solve decoupled tasks in a step-by-step manner. \nOur generality is demonstrated by our ability to evaluate not only pure vision-based real-world benchmarks (i.e., OSWorld), but also more general or tool-intensive benchmarks (e.g., GAIA and SWE-Bench).\nSpecifically,\nwe\nachieve a $\\mathbf{7.27\\\\%}$ accuracy gain over Claude-Computer-Use on OSWorld.  \nCodes and evaluation scripts are included in the supplementary material and will be released as open-source.'}",https://openreview.net{'value': '/pdf/ae7bb751a0d72057590b5907d9d4fa86c412be50.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=NCslwlWjqB,{'value': 'FreeInv: Free Lunch for Improving DDIM Inversion'},Yuxiang Bao; Huijie Liu; xun gao; Huan Fu; Guoliang Kang,~Yuxiang_Bao1; ~Huijie_Liu2; ~xun_gao2; ~Huan_Fu1; ~Guoliang_Kang1,"{'value': ['DDIM inversion', 'diffusion model']}","{'value': 'Naive DDIM inversion process usually suffers from a trajectory deviation issue, i.e., the latent trajectory during reconstruction deviates from the one during inversion. To alleviate this issue, previous methods either learn to mitigate the deviation or design cumbersome compensation strategy to reduce the mismatch error, exhibiting substantial time and computation cost. In this work, we present a nearly free-lunch method (named FreeInv) to address the issue more effectively and efficiently. \nIn FreeInv, we randomly transform the latent representation and keep the transformation the same between the corresponding inversion and reconstruction time-step. \nIt is motivated from a statistical perspective that an ensemble of DDIM inversion processes for multiple trajectories yields a smaller trajectory mismatch error on expectation.\nMoreover, through theoretical analysis and empirical study, we show that FreeInv performs an efficient ensemble of multiple trajectories. FreeInv can be freely integrated into existing inversion-based image and video editing techniques. Especially for inverting video sequences, it brings more significant fidelity and efficiency improvements. Comprehensive quantitative and qualitative evaluation on PIE benchmark and DAVIS dataset shows that FreeInv remarkably outperforms conventional DDIM inversion, and is competitive among previous state-of-the-art inversion methods, with superior computation efficiency.'}",https://openreview.net{'value': '/pdf/8930a88d4b31f3939ab91035ec59b195791118f0.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=NBNwoHfMyf,{'value': 'Blockwise Flow Matching: Improving Flow Matching Models For Efficient High-Quality Generation'},Dogyun Park; Taehoon Lee; Minseok Joo; Hyunwoo J. Kim,~Dogyun_Park2; ~Taehoon_Lee3; ~Minseok_Joo1; ~Hyunwoo_J._Kim3,{'value': ['Diffusion; Flow matching; efficient generation']},"{'value': 'Recently, Flow Matching models have pushed the boundaries of high-fidelity data generation across a wide range of domains. It typically employs a single large network to learn the entire generative trajectory from noise to data. Despite their effectiveness, this design struggles to capture distinct signal characteristics across timesteps simultaneously and incurs substantial inference costs due to the iterative evaluation of the entire model. To address these limitations, we propose Blockwise Flow Matching (BFM), a novel framework that partitions the generative trajectory into multiple temporal segments, each modeled by smaller but specialized velocity blocks. This blockwise design enables each block to specialize effectively in its designated interval, improving inference efficiency and sample quality. To further enhance generation fidelity, we introduce a Semantic Feature Guidance module that explicitly conditions velocity blocks on semantically rich features aligned with pretrained representations.\nAdditionally, we propose a lightweight Feature Residual Approximation strategy that preserves semantic quality while significantly reducing inference cost.\nExtensive experiments on ImageNet 256x256 demonstrate that BFM establishes a substantially improved Pareto frontier over existing Flow Matching methods, achieving 2.1x to 4.9x accelerations in inference complexity at comparable generation performance.'}",https://openreview.net{'value': '/pdf/1b385f7dd441086164a71969e203ce2a272c8301.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=N9sJRKzVK7,{'value': 'Learning Individual Behavior in Agent-Based Models with Graph Diffusion Networks'},Francesco Cozzi; Marco Pangallo; Alan Perotti; André Panisson; Corrado Monti,~Francesco_Cozzi1; ~Marco_Pangallo1; ~Alan_Perotti2; ~André_Panisson1; ~Corrado_Monti1,"{'value': ['Agent-Based Models', 'Surrogate models', 'Diffusion Models', 'Graph Neural Networks', 'Probabilistic Machine Learning']}","{'value': ""Agent-Based Models (ABMs) are powerful tools for studying emergent properties in complex systems. In ABMs, agent behaviors are governed by local interactions and stochastic rules. However, these rules are ad hoc and, in general, non-differentiable, limiting the use of gradient-based methods for optimization, and thus integration with real-world data. We propose a novel framework to learn a differentiable surrogate of any ABM by observing its generated data. Our method combines diffusion models to capture behavioral stochasticity and graph neural networks to model agent interactions. Distinct from prior surrogate approaches, our method introduces a fundamental shift: rather than approximating system-level outputs, it models individual agent behavior directly, preserving the decentralized, bottom-up dynamics that define ABMs. We validate our approach on two ABMs (Schelling's segregation model and a Predator-Prey ecosystem) showing that it replicates individual-level patterns and accurately forecasts emergent dynamics beyond training. Our results demonstrate the potential of combining diffusion models and graph learning for data-driven ABM simulation.""}",https://openreview.net{'value': '/pdf/730e7372a852363418f6cd5d5cb8e74011f6ebcb.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=N9HLe9iPhj,{'value': 'Can Agent Fix Agent Issues?'},Alfin Wijaya Rahardja; Junwei Liu; Weitong Chen; Zhenpeng Chen; Yiling Lou,~Alfin_Wijaya_Rahardja1; ~Junwei_Liu9; ~Weitong_Chen3; ~Zhenpeng_Chen2; ~Yiling_Lou1,"{'value': ['LLM-based agents', 'SE agents', 'issue resolution']}","{'value': 'LLM-based agent systems are emerging as a new software paradigm and have been widely adopted across diverse domains such as medicine, robotics, and programming. However, maintaining these systems requires substantial effort, as they are inevitably prone to bugs and continually evolve to meet changing external requirements. Therefore, automatically resolving agent issues (i.e.,bug reports or feature requests) is a crucial and challenging task.  While recent software engineering (SE) agents (e.g., SWE-agent) have shown promise in addressing issues in traditional software systems, it remains unclear how effectively they can resolve real-world issues in agent systems, which differ significantly from traditional software. To fill this gap, we first manually analyze 201 real-world agent issues and identify common categories of agent issues. We then spend 500 person-hours constructing AgentIssue-bench, a reproducible benchmark comprising 50 agent issue resolution tasks (each with an executable environment and failure-triggering tests). We further evaluate state-of-the-art SE agents on AgentIssue-bench and reveal their limited effectiveness (\\.e., with only 0.67% - 4.67% resolution rates). These results underscore the unique challenges of maintaining agent systems compared to traditional software, highlighting the need for further research to develop advanced SE agents for resolving agent issues.'}",https://openreview.net{'value': '/pdf/ab4c234adba0d835dbb64828e87b465d8983cecd.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=MyCKtV9CpR,{'value': 'Centralized Reward Agent for Knowledge Sharing and Transfer in Multi-Task Reinforcement Learning'},Haozhe Ma; Zhengding Luo; Thanh Vinh Vo; Kuankuan Sima; Tze-Yun Leong,~Haozhe_Ma1; ~Zhengding_Luo1; ~Thanh_Vinh_Vo2; ~Kuankuan_Sima1; ~Tze-Yun_Leong2,"{'value': ['Reinforcement Learning', 'Reward Shaping', 'Knowledge Distillation and Distribution', 'Knowledge Transfer']}","{'value': 'Reward shaping is effective in addressing the sparse-reward challenge in reinforcement learning (RL) by providing immediate feedback through auxiliary, informative rewards. Based on the reward shaping strategy, we propose a novel multi-task reinforcement learning framework that integrates a centralized reward agent (CRA) and multiple distributed policy agents. The CRA functions as a knowledge pool, aimed at distilling knowledge from various tasks and distributing it to individual policy agents to improve learning efficiency. Specifically, the shaped rewards serve as a straightforward metric for encoding knowledge. This framework not only enhances knowledge sharing across established tasks but also adapts to new tasks by transferring meaningful reward signals. We validate the proposed method on both discrete and continuous domains, including the representative Meta-World benchmark, demonstrating its robustness in multi-task sparse-reward settings and its effective transferability to unseen tasks.'}",https://openreview.net{'value': '/pdf/38ee6499e41e6f21693d91c32df96a859b26ef67.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=MqGZIJxZ1z,{'value': 'Variational Uncertainty Decomposition for In-Context Learning'},I. Shavindra Jayasekera; Jacob Si; Filippo Valdettaro; Wenlong Chen; Aldo A. Faisal; Yingzhen Li,~I._Shavindra_Jayasekera1; ~Jacob_Si1; ~Filippo_Valdettaro1; ~Wenlong_Chen1; ~Aldo_A._Faisal1; ~Yingzhen_Li1,"{'value': ['Uncertainty Quantification', 'Uncertainty Decomposition', 'In-Context Learning', 'Variational Methods', 'Large Language Models']}","{'value': ""As large language models (LLMs) gain popularity in conducting prediction tasks in-context, understanding the sources of uncertainty in in-context learning becomes essential to ensuring reliability. The recent hypothesis of in-context learning performing predictive Bayesian inference opens the avenue for Bayesian uncertainty estimation, particularly for decomposing uncertainty into epistemic uncertainty due to lack of in-context data and aleatoric uncertainty inherent in the in-context prediction task. However, the decomposition idea remains under-explored due to the intractability of the latent parameter posterior from the underlying Bayesian model. In this work, we introduce a variational uncertainty decomposition framework for in-context learning without explicitly sampling from the latent parameter posterior, by optimising auxiliary inputs as probes to obtain an upper bound to the aleatoric uncertainty of an LLM's in-context learning procedure. Through experiments on synthetic and real-world tasks, we show quantitatively and qualitatively that the decomposed uncertainties obtained from our method exhibit desirable properties of epistemic and aleatoric uncertainty.""}",https://openreview.net{'value': '/pdf/e044da5609e35fc504bda2b43e5b9fc504a960ab.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=MVYz4GmcUH,{'value': 'Ambient Diffusion Omni: Training Good Models with Bad Data'},Giannis Daras; Adrian Rodriguez-Munoz; Adam Klivans; Antonio Torralba; Constantinos Costis Daskalakis,~Giannis_Daras1; ~Adrian_Rodriguez-Munoz1; ~Adam_Klivans1; ~Antonio_Torralba1; ~Constantinos_Costis_Daskalakis1,"{'value': ['ambient diffusion', 'diffusion models', 'corrupted data', 'generative AI']}","{'value': 'We show how to use low-quality, synthetic, and out-of-distribution images to improve the quality of a diffusion model. Typically, diffusion models are trained on curated datasets that emerge from highly filtered data pools from the Web and other sources. We show that there is immense value in the lower-quality images that are often discarded. We present Ambient Diffusion Omni, a simple, principled framework to train diffusion models that can extract signal from arbitrarily images during training. Our framework exploits two properties of natural images -- spectral power law decay and locality. We first validate our framework by successfully training diffusion models with images synthetically corrupted by Gaussian blur, JPEG compression, and motion blur. We use our framework to achieve state-of-the-art ImageNet FID and we show significant improvements in both image quality and diversity for text-to-image generative modeling. The core insight is that noise dampens the initial skew between the desired high-quality distribution and the mixed distribution we actually observe. We provide rigorous theoretical justification for our approach by analyzing the trade-off between learning from biased data versus limited unbiased data across diffusion times.'}",https://openreview.net{'value': '/pdf/9617415dd325d93577af94e8c4910f1e1f035da6.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=MQVyuWBfSH,{'value': 'Flow Matching-Based Autonomous Driving Planning with Advanced Interactive Behavior Modeling'},Tianyi Tan; Yinan Zheng; Ruiming Liang; Zexu Wang; Kexin ZHENG; Jinliang Zheng; Jianxiong Li; Xianyuan Zhan; Jingjing Liu,~Tianyi_Tan1; ~Yinan_Zheng1; ~Ruiming_Liang1; ~Zexu_Wang2; ~Kexin_ZHENG2; ~Jinliang_Zheng1; ~Jianxiong_Li1; ~Xianyuan_Zhan1; ~Jingjing_Liu2,"{'value': ['Autonomous Driving Planning', 'Flow Matching']}","{'value': 'Modeling interactive driving behaviors in complex scenarios remains a fundamental challenge for autonomous driving planning. Learning-based approaches attempt to address this challenge with advanced generative models, removing the dependency on over-engineered architectures for representation fusion. However, brute-force implementation by simply stacking transformer blocks lacks a dedicated mechanism for modeling interactive behaviors that is common in real driving scenarios. The scarcity of interactive driving data further exacerbates this problem, leaving conventional imitation learning methods ill-equipped to capture high-value interactive behaviors. We propose Flow Planner, which tackles these problems through coordinated innovations in data modeling, model architecture, and learning scheme. Specifically, we first introduce fine-grained trajectory tokenization, which decomposes the trajectory into overlapping segments to decrease the complexity of whole trajectory modeling. With a sophisticatedly designed architecture, we achieve efficient temporal and spatial fusion of planning and scene information, to better capture interactive behaviors. In addition, the framework incorporates flow matching with classifier-free guidance for multi-modal behavior generation, which dynamically reweights agent interactions during inference to maintain coherent response strategies, providing a critical boost for interactive scenario understanding. Experimental results on the large-scale nuPlan dataset demonstrate that Flow Planner achieves state-of-the-art performance among learning-based approaches while effectively modeling interactive behaviors in complex driving scenarios.'}",https://openreview.net{'value': '/pdf/dedea7f16d8c3b62dd2487dccdb437e2ddc99d50.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=MNqBFIGT8l,{'value': 'The Nuclear Route: Sharp Asymptotics of ERM in Overparameterized Quadratic Networks'},Vittorio Erba; Emanuele Troiani; Lenka Zdeborova; Florent Krzakala,~Vittorio_Erba1; ~Emanuele_Troiani2; ~Lenka_Zdeborova1; ~Florent_Krzakala1,"{'value': ['neural networks', 'quadratic activation', 'global minima', 'nuclear norm', 'regularisation']}","{'value': 'We study the high-dimensional asymptotics of empirical risk minimization (ERM) in over-parametrized two-layer neural networks with quadratic activations trained on synthetic data. We derive sharp asymptotics for both training and test errors by mapping the $\\ell_2$-regularized learning problem to a convex matrix sensing task with nuclear norm penalization.  This reveals that capacity control in such networks emerges from a low-rank structure in the learned feature maps. Our results characterize the global minima of the loss and yield precise generalization thresholds, showing how the width of the target function governs learnability. This analysis bridges and extends ideas from spin-glass methods, matrix factorization, and convex optimization and emphasizes the deep link between low-rank matrix sensing and learning in quadratic neural networks.'}",https://openreview.net{'value': '/pdf/95be6615c2d585896ae3ee6d349e6c5d9d4461a7.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=MBJ46gd1CT,{'value': 'OWL: Optimized Workforce Learning for General Multi-Agent Assistance in Real-World Task Automation'},Mengkang Hu; Yuhang Zhou; Wendong Fan; Yuzhou Nie; Ziyu Ye; Bowei Xia; Tao Sun; Zhaoxuan Jin; Yingru Li; Zeyu Zhang; Yifeng Wang; Qianshuo Ye; Bernard Ghanem; Ping Luo; Guohao Li,~Mengkang_Hu1; ~Yuhang_Zhou8; ~Wendong_Fan1; ~Yuzhou_Nie1; ~Ziyu_Ye1; ~Bowei_Xia2; ~Tao_Sun26; ~Zhaoxuan_Jin1; ~Yingru_Li1; ~Zeyu_Zhang14; ~Yifeng_Wang10; ~Qianshuo_Ye1; ~Bernard_Ghanem1; ~Ping_Luo2; ~Guohao_Li1,"{'value': ['Large Language Model', 'LLM-based Agent', 'Multi-Agent']}","{'value': ""Large Language Model (LLM)-based multi-agent systems show promise for automating real-world tasks but struggle to transfer across domains due to their domain-specific nature.\nCurrent approaches face two critical shortcomings: they require complete architectural redesign and full retraining of all components when applied to new domains.\nWe introduce **Workforce**, a hierarchical multi-agent framework that decouples strategic planning from specialized execution through a modular architecture comprising:\n*(i)* a *domain-agnostic* **Planner** for task decomposition,\n*(ii)* a **Coordinator** for subtask management, and\n*(iii)* specialized **Workers** with *domain-specific* tool-calling capabilities.\nThis decoupling enables cross-domain transferability during both inference and training phases:\nDuring inference, Workforce seamlessly adapts to new domains by adding or modifying worker agents;\nFor training, we introduce **Optimized Workforce Learning (OWL)**, which improves generalization across domains by optimizing a domain-agnostic planner with reinforcement learning from real-world feedback.\nTo validate our approach, we evaluate Workforce on the GAIA benchmark, covering various realistic, multi-domain agentic tasks.\nExperimental results demonstrate Workforce achieves open-source state-of-the-art performance (**69.70%**), outperforming commercial systems like OpenAI's Deep Research by **2.34%**.\nMore notably, our OWL-trained 32B model achieves **52.73%** accuracy (**+16.37%**) and demonstrates performance comparable to GPT-4o on challenging tasks.\nTo summarize, by enabling scalable generalization and modular domain transfer, our work establishes a foundation for the next generation of general-purpose AI assistants.\n\n*Our code is available at [Anonymous URL](https://anonymous.4open.science/r/annonymous-owl/), and our data is available at [Anonymous URL](https://huggingface.co/anonymous21016).*""}",https://openreview.net{'value': '/pdf/9ea2d3d5cf7f874c7669ab5c3f1270eb3bc794d1.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=M3zxsDL2Rk,{'value': 'Cycle-Sync: Robust Global Camera Pose Estimation through Enhanced Cycle-Consistent Synchronization'},Shaohan Li; Yunpeng Shi; Gilad Lerman,~Shaohan_Li1; ~Yunpeng_Shi1; ~Gilad_Lerman1,"{'value': ['Robust Synchronization', 'Camera Location Estimation', 'Structure from Motion', 'Computer Vision']}","{'value': 'We introduce Cycle-Sync, a robust and global framework for estimating camera poses (both rotations and locations). Our core innovation is a location solver that adapts message-passing least squares (MPLS) - originally developed for group synchronization - to the camera localization setting. We modify MPLS to emphasize cycle-consistent information, redefine cycle consistencies using estimated distances from previous iterations, and incorporate a Welsch-type robust loss. We establish the strongest known deterministic exact-recovery guarantee for camera location estimation, demonstrating that cycle consistency alone enables the lowest sample complexity to date. To further boost robustness, we introduce a plug-and-play outlier rejection module inspired by robust subspace recovery, and we fully integrate cycle consistency into MPLS for rotation averaging. Our global approach avoids the need for bundle adjustment. Experiments on synthetic and real datasets show that Cycle-Sync consistently outperforms leading pose estimators, including full structure-from-motion pipelines with bundle adjustment.'}",https://openreview.net{'value': '/pdf/84d7e8b21f0e94da735af8c70c00827ab90c6fdd.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=M1b7IuY6Co,{'value': 'Constrained Sampling for Language Models Should Be Easy: An MCMC Perspective'},Emmanuel Anaya Gonzalez; Sairam Vaidya; Kanghee Park; Ruyi Ji; Taylor Berg-Kirkpatrick; Loris D'Antoni,~Emmanuel_Anaya_Gonzalez1; ~Sairam_Vaidya1; ~Kanghee_Park1; ~Ruyi_Ji2; ~Taylor_Berg-Kirkpatrick1; ~Loris_D'Antoni1,"{'value': ['Language Models', 'Context-Free Grammars', 'Markov Chain Monte Carlo']}","{'value': 'Constrained decoding enables Language Models (LMs) to produce samples that provably satisfy hard constraints.\nHowever, existing constrained-decoding approaches often distort the underlying model distribution, a limitation that is especially problematic in applications like program fuzzing, where one wants to generate diverse and valid program inputs for testing purposes. \nWe propose a new constrained sampling framework based on Markov Chain Monte Carlo (MCMC) that simultaneously satisfies three core desiderata: constraint satisfying (every sample satisfies the constraint), monotonically converging (the sampling process converges to the true conditional distribution), and efficient (high-quality samples emerge in few steps). Our method constructs a proposal distribution over valid outputs and applies a Metropolis-Hastings acceptance criterion based on the LM’s likelihood, ensuring principled and efficient exploration of the constrained space. Empirically, our sampler outperforms existing methods on both synthetic benchmarks and real-world program fuzzing tasks.'}",https://openreview.net{'value': '/pdf/262545ead769a1b8e8f0fc6902f78488904b8153.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=M1DA33qucy,{'value': 'Adaptively Coordinating with Novel Partners via Learned Latent Strategies'},Benjamin Li; Shuyang Shi; Lucia Romero; Huao Li; Yaqi Xie; Woojun Kim; Stefanos Nikolaidis; Charles Michael Lewis; Katia P. Sycara; Simon Stepputtis,~Benjamin_Li2; ~Shuyang_Shi2; ~Lucia_Romero1; ~Huao_Li1; ~Yaqi_Xie1; ~Woojun_Kim1; ~Stefanos_Nikolaidis1; ~Charles_Michael_Lewis1; ~Katia_P._Sycara1; ~Simon_Stepputtis1,"{'value': ['multi-agent reinforcement learning', 'human-ai collaboration', 'multi-agent systems', 'zero-shot coordination']}","{'value': ""Adaptation is the cornerstone of effective collaboration among heterogeneous team members. In human-agent teams, artificial agents need to adapt to their human partners in real time, as individuals often have unique preferences and policies that may change dynamically throughout interactions. This becomes particularly challenging in tasks with time pressure and complex strategic spaces, where identifying partner behaviors and selecting suitable responses is difficult.\nIn this work, we introduce a strategy-conditioned cooperator framework that learns to represent, categorize, and adapt to a broad range of potential partner strategies in real-time. \nOur approach encodes strategies with a variational autoencoder to learn a latent strategy space from agent trajectory data, identifies distinct strategy types through clustering, and trains a cooperator agent conditioned on these clusters by generating partners of each strategy type.\nFor online adaptation to novel partners, we leverage a fixed-share regret minimization algorithm that dynamically infers and adjusts the partner's strategy estimation during interaction.\nWe evaluate our method in a modified version of the Overcooked domain, a complex collaborative cooking environment that requires effective coordination among two players with a diverse potential strategy space.\nThrough these experiments and an online user study, we demonstrate that our proposed agent achieves state of the art performance compared to existing baselines when paired with novel human, and agent teammates.""}",https://openreview.net{'value': '/pdf/69238b8875d33eff314d02a7b2788594acaa629d.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=LyH2ISbOV8,{'value': 'Automated Detection of Visual Attribute Reliance with a Self-Reflective Agent'},Christy Li; Josep Lopez Camuñas; Jake Thomas Touchet; Jacob Andreas; Agata Lapedriza; Antonio Torralba; Tamar Rott Shaham,~Christy_Li2; ~Josep_Lopez_Camuñas1; ~Jake_Thomas_Touchet1; ~Jacob_Andreas1; ~Agata_Lapedriza1; ~Antonio_Torralba1; ~Tamar_Rott_Shaham1,{'value': ['Model robustness; Interpretability; Interpretability Agent; Self-reflection; Interpretability benchmarks; Spurious correlation']},"{'value': ""When a vision model performs image recognition, which visual attributes drive its predictions? Detecting unintended reliance on specific visual features is critical for ensuring model robustness, preventing overfitting, and avoiding spurious correlations. We introduce an automated framework for detecting such dependencies in trained vision models. At the core of our method is a self-reflective agent that systematically generates and tests hypotheses about visual attributes that a model may rely on. This process is iterative: the agent refines its hypotheses based on experimental outcomes and uses a self-evaluation protocol to assess whether its findings accurately explain model behavior. When inconsistencies arise, the agent self-reflects over its findings and triggers a new cycle of experimentation. We evaluate our approach on a novel benchmark of 130 models designed to exhibit diverse visual attribute dependencies across 18 categories. Our results show that the agent's performance consistently improves with self-reflection, with a significant performance increase over non-reflective baselines. We further demonstrate that the agent identifies real-world visual attribute dependencies in state-of-the-art models, including CLIP's vision encoder and the YOLOv8 object detector.""}",https://openreview.net{'value': '/pdf/59662cad24df4f230c1ff208b2d360ed5e639be2.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=LuKlBH8DAT,{'value': 'AugGen: Synthetic Augmentation using Diffusion Models Can Improve Recognition'},Parsa Rahimi; Damien Teney; Sébastien Marcel,~Parsa_Rahimi1; ~Damien_Teney1; ~Sébastien_Marcel1,"{'value': ['Generative Models', 'Synthetic Data', 'Diffusion Models', 'Synthetic Augmentation', 'Face Recognition']}","{'value': 'The increasing reliance on large-scale datasets in machine learning poses significant privacy and ethical challenges, particularly in sensitive domains such as face recognition. Synthetic data generation offers a promising alternative; however, most existing methods depend heavily on external datasets or pre-trained models, increasing complexity and resource demands. In this paper, we introduce **AugGen**, a self-contained synthetic augmentation technique. AugGen strategically samples from a class-conditional generative model trained exclusively on the target FR dataset, eliminating the need for external resources. Evaluated across 8 FR benchmarks, including IJB-C and IJB-B, our method achieves **1–12% performance improvements**, outperforming models trained solely on real data and surpassing state-of-the-art synthetic data generation approaches, while using less real data. Notably, these gains often exceed those from architectural modifications, underscoring the value of synthetic augmentation in data-limited scenarios. Our findings demonstrate that carefully integrated synthetic data can both mitigate privacy constraints and substantially enhance discriminative performance in face recognition. Code and datasets will be made publicly available upon publication.'}",https://openreview.net{'value': '/pdf/54e02543209e7a4c27608214d41c5d7571a55a76.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=LtON4qr1if,{'value': 'On Efficiency-Effectiveness Trade-off of Diffusion-based Recommenders'},Wenyu Mao; Jiancan Wu; Guoqing Hu; Zhengyi Yang; Wei Ji; Xiang Wang,~Wenyu_Mao3; ~Jiancan_Wu1; ~Guoqing_Hu1; ~Zhengyi_Yang1; ~Wei_Ji1; ~Xiang_Wang6,"{'value': ['Diffusion Models', 'Recommender System', 'Preference Optimization']}","{'value': 'Diffusion models have emerged as a powerful paradigm for generative sequential recommendation, which typically generate next items to recommend guided by user interaction histories with a multi-step denoising process. However, the multi-step process relies on discrete approximations, introducing discretization error that creates a trade-off between computational efficiency and recommendation effectiveness.\nTo address this trade-off, we propose TA-Rec, a two-stage framework that achieves one-step generation by smoothing the denoising function during pretraining while alleviating trajectory deviation by aligning with user preferences during fine-tuning. Specifically, to improve the efficiency without sacrificing the recommendation performance, TA-Rec pretrains the denoising model with Temporal Consistency Regularization (TCR), enforcing the consistency between the denoising results across adjacent steps. Thus, we can smooth the denoising function to map the noise as oracle items in one step with bounded error. To further enhance effectiveness, TA-Rec introduces Adaptive Preference Alignment (APA) that aligns the denoising process with user preference adaptively based on preference pair similarity and timesteps. Extensive experiments prove that TA-Rec’s two-stage objective effectively mitigates the discretization errors-induced trade-off, enhancing both efficiency and effectiveness of diffusion-based recommenders. Our code is available at https://github.com/maowenyu-11/TA-Rec.'}",https://openreview.net{'value': '/pdf/28abafe6d0550c52fc2cef3c3ea532c12ca56eba.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=LtIk57nS8v,{'value': 'Controlling The Spread of Epidemics on Networks with Differential Privacy'},Dung Nguyen; Aravind Srinivasan; Renata Valieva; Anil Vullikanti; Jiayi Wu,~Dung_Nguyen2; ~Aravind_Srinivasan1; ~Renata_Valieva1; ~Anil_Vullikanti1; ~Jiayi_Wu8,"{'value': ['Differential privacy', 'network science', 'computational epidemiology', 'public health']}","{'value': 'Designing effective strategies for controlling epidemic spread by vaccination is an important question in epidemiology, especially in the early stages when vaccines are limited.\nThis is a challenging question when the contact network is very heterogeneous, and strategies based on controlling network properties, such as the degree and spectral radius, have been shown to be effective.\nImplementation of such strategies requires detailed information on the contact structure, which might be sensitive in many applications.\nOur focus here is on choosing effective vaccination strategies when the edges are sensitive and differential privacy guarantees are needed.\nOur main contributions are $(\\varepsilon,\\delta)$-differentially private algorithms for designing vaccination strategies by reducing the maximum degree and spectral radius.\nOur key technique is a private algorithm for the multi-set multi-cover problem, which we use for controlling network properties.\nWe evaluate privacy-utility tradeoffs of our algorithms on multiple synthetic and real-world networks, and show their effectiveness.'}",https://openreview.net{'value': '/pdf/cff4060ef424b91286d22193f3e1c294c3c7268a.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=LsmUgStXby,{'value': 'AI-Generated Video Detection via Perceptual Straightening'},Christian Internò; Robert Geirhos; Markus Olhofer; Sunny Liu; Barbara Hammer; David Klindt,~Christian_Internò1; ~Robert_Geirhos1; ~Markus_Olhofer1; ~Sunny_Liu1; ~Barbara_Hammer4; ~David_Klindt1,"{'value': ['Representation geometry', 'Perceptual straightening', 'AI-generated video detection', 'AI Safety']}","{'value': ""The rapid advancement of generative AI enables highly realistic synthetic video, posing significant challenges for content authentication and raising urgent concerns about misuse. Existing detection methods often struggle with generalization and capturing subtle temporal inconsistencies. We propose $ReStraV$ ($Re$presentation $Stra$ightening for $V$ideo), a novel approach to distinguish natural from AI-generated videos. Inspired by the ``perceptual straightening'' hypothesis—which suggests real-world video trajectories become more straight in neural representation domain—we analyze deviations from this expected geometric property. Using a pre-trained self-supervised vision transformer (DINOv2), we quantify the temporal curvature and stepwise distance in the model's representation domain. We aggregate statistical and signals descriptors of these measures for each video and train a classifier. Our analysis shows that AI-generated videos exhibit significantly different curvature and distance patterns compared to real videos. A lightweight classifier achieves state-of-the-art detection performance (e.g., $97.17$ % accuracy and $98.63$ % AUROC on the VidProM benchmark, substantially outperforming existing image- and video-based methods. ReStraV  is computationally efficient, it is offering a low-cost and effective detection solution. This work provides new insights into using neural representation geometry for AI-generated video detection.""}",https://openreview.net{'value': '/pdf/d8ac56ef445d1add6d0a001e627825040f6e452d.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=Lq4nneD2xX,{'value': '$\\texttt{G1}$: Teaching LLMs to Reason on Graphs with Reinforcement Learning'},Xiaojun Guo; Ang Li; Yifei Wang; Stefanie Jegelka; Yisen Wang,~Xiaojun_Guo1; ~Ang_Li35; ~Yifei_Wang1; ~Stefanie_Jegelka3; ~Yisen_Wang1,"{'value': ['Graph', 'Large Language Models', 'Reasoning', 'Reinforcement Learning']}","{'value': ""Although Large Language Models (LLMs) have demonstrated remarkable progress, their proficiency in graph-related tasks remains notably limited, hindering the development of truly general-purpose models. Previous attempts, including pretraining graph foundation models or employing supervised fine-tuning, often face challenges such as the scarcity of large-scale, universally represented graph data. We introduce $\\texttt{G1}$, a simple yet effective approach demonstrating that Reinforcement Learning (RL) on synthetic graph-theoretic tasks can significantly scale LLMs' graph reasoning abilities. To enable RL training, we curate \\erdos, the largest graph reasoning dataset to date comprising 50 diverse graph-theoretic tasks of varying difficulty levels, 100k training data and 5k test data, all drived from real-world graphs. With RL on \\erdos, $\\texttt{G1}$ obtains substantial improvements in graph reasoning, where our finetuned 3B model even outperforms Qwen2.5-72B-Instruct (24x size). RL-trained models also show strong zero-shot generalization to unseen tasks, domains, and graph encoding schemes, including other graph-theoretic benchmarks as well as real-world node classification and link prediction tasks, without compromising general reasoning abilities. Our findings offer an efficient, scalable path for building strong graph reasoners by finetuning LLMs with RL on graph-theoretic tasks, which combines the strengths of pretrained LLM capabilities with abundant, automatically generated synthetic data, suggesting that LLMs possess graph understanding abilities that RL can elicit successfully. Our implementation is open-sourced at https://github.com/PKU-ML/G1, with models and datasets hosted on Hugging Face collections https://huggingface.co/collections/PKU-ML/g1-683d659e992794fc99618cf2 for broader accessibility.""}",https://openreview.net{'value': '/pdf/eb95dfb11f1b0c705f2e368d650f0af1afbef02b.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=Lm4VIXVIuy,{'value': 'DEGauss: Defending Against Malicious 3D Editing for Gaussian Splatting'},Lingzhuang Meng; Mingwen Shao; Yuanjian Qiao; Xiang Lv,~Lingzhuang_Meng2; ~Mingwen_Shao1; ~Yuanjian_Qiao1; ~Xiang_Lv1,"{'value': ['3D Gaussian Splatting', 'Malicious editing defense', 'View-focal fusion', 'dual discrepancy optimization']}","{'value': '3D editing with Gaussian splatting is exciting in creating realistic content, but it also poses abuse risks for generating malicious 3D content. Existing 2D defense approaches mainly focus on adding perturbations to single image to resist malicious image editing. However, there remain two limitations when applied directly to 3D scenes: (1) These methods fail to reflect 3D spatial correlations, thus protecting ineffectively under multiple viewpoints. (2) Such pixel-level perturbation is easily eliminated during the iterations of 3D editing, leading to failure of protection. To address the above issues, we propose a novel Defense framework against malicious 3D Editing for Gaussian splatting (DEGauss) for robustly disrupting the trajectory of 3D editing in multi-views. Specifically, to enable the effectiveness of perturbation across various views, we devise a view-focal gradient fusion mechanism that dynamically emphasizes the contributions of the most challenging views to adaptively optimize 3D perturbations. Furthermore, we design a dual discrepancy optimization strategy that both maximize the semantic deviation and the edit direction deviation of the guidance conditions to stably disrupt the editing trajectory. Benefiting from the collaborative designs, our method achieves effective resistance to 3D editing from various views while preserving photorealistic rendering quality. Extensive experiments demonstrate that our DEGauss not only performs excellent defense in different scenes, but also exhibits strong generalization across various state-of-the-art 3D editing pipelines.'}",https://openreview.net{'value': '/pdf/2f52688e30f38f20b2395149c347bd5406639fa6.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=LlEJZ7x0R8,{'value': 'Learning non-equilibrium diffusions with Schrödinger bridges: from exactly solvable to simulation-free'},Stephen Y. Zhang; Michael Stumpf,~Stephen_Y._Zhang1; ~Michael_Stumpf1,"{'value': ['Schrodinger bridge', 'nonequilibrium dynamics', 'flow matching']}","{'value': 'We consider the Schrödinger bridge problem which, given ensemble measurements of the initial and final configurations of a stochastic dynamical system and some prior knowledge on the dynamics, aims to reconstruct the ""most likely"" evolution of the system compatible with the data. Most existing literature assume Brownian reference dynamics, and are implicitly limited to modelling systems driven by the gradient of a potential energy. We depart from this regime and consider reference processes described by a multivariate Ornstein-Uhlenbeck process with generic drift matrix $\\mathbf{A} \\in \\mathbb{R}^{d \\times d}$. When $\\mathbf{A}$ is asymmetric, this corresponds to a non-equilibrium system in which non-gradient forces are at play: this is important for applications to biological systems, which naturally exist out-of-equilibrium. In the case of Gaussian marginals, we derive explicit expressions that characterise exactly the solution of both the static and dynamic Schrödinger bridge. For general marginals, we propose mvOU-OTFM, a simulation-free algorithm based on flow and score matching for learning an approximation to the Schrödinger bridge. In application to a range of problems based on synthetic and real single cell data, we demonstrate that mvOU-OTFM achieves higher accuracy compared to competing methods, whilst being significantly faster to train.'}",https://openreview.net{'value': '/pdf/f30d449eb90e37c6a87b47c645c8a97e6dd1ced2.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=Ll5miDx8KB,{'value': 'From Flat to Hierarchical: Extracting Sparse Representations with Matching Pursuit'},Valérie Costa; Thomas Fel; Ekdeep Singh Lubana; Bahareh Tolooshams; Demba E. Ba,~Valérie_Costa1; ~Thomas_Fel2; ~Ekdeep_Singh_Lubana1; ~Bahareh_Tolooshams1; ~Demba_E._Ba1,"{'value': ['Interpretability', 'Explainability', 'Computer Vision', 'Representation Learning', 'Dictionary Learning', 'Sparse Autoencoders']}","{'value': 'Motivated by the hypothesis that neural network representations encode abstract, interpretable features as linearly accessible, approximately orthogonal directions, sparse autoencoders (SAEs) have become a popular tool in interpretability literature. However, recent work has demonstrated phenomenology of model representations that lies outside the scope of this hypothesis, showing signatures of hierarchical, nonlinear, and multi-dimensional features. This raises the question: do SAEs represent features that possess structure at odds with their motivating hypothesis? If not, does avoiding this mismatch help identify said features and gain further insights into neural network representations? To answer these questions, we take a construction-based approach and re-contextualize the popular matching pursuit (MP) algorithm from sparse coding to design MP-SAE—an SAE that unrolls its encoder into a sequence of residual-guided steps, allowing it to capture hierarchical and nonlinearly accessible features. Comparing this architecture with existing SAEs on a mixture of synthetic and natural data settings, we show: (i) hierarchical concepts induce conditionally orthogonal features, which existing SAEs are unable to faithfully capture, and (ii) the nonlinear encoding step of MP-SAE recovers highly meaningful features, helping us unravel shared structure in the seemingly dichotomous representation spaces of different modalities in a vision-language model, hence demonstrating the assumption that useful features are solely linearly accessible is insufficient. We also show that the sequential encoder principle of MP-SAE affords an additional benefit of adaptive sparsity at inference time, which may be of independent interest. Overall, we argue our results provide credence to the idea that interpretability should begin with the phenomenology of representations, with methods emerging from assumptions that fit it.'}",https://openreview.net{'value': '/pdf/fc090b8c4bcecec93025b98fc6194261875711ec.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=LkqK19tqgx,{'value': 'TPP-SD: Accelerating Transformer Point Process Sampling with Speculative Decoding'},Shukai Gong; YIYANG FU; Fengyuan Ran; Quyu Kong; Feng Zhou,~Shukai_Gong1; ~YIYANG_FU1; ~Fengyuan_Ran1; ~Quyu_Kong1; ~Feng_Zhou9,"{'value': ['Transformer point process', 'sampling', 'speculative decoding']}","{'value': 'We propose TPP-SD, a novel approach that accelerates Transformer temporal point process (TPP) sampling by adapting speculative decoding (SD) techniques from language models. By identifying the structural similarities between thinning algorithms for TPPs and speculative decoding for language models, we develop an efficient sampling framework that leverages a smaller draft model to generate multiple candidate events, which are then verified by the larger target model. TPP-SD maintains the same output distribution as autoregressive sampling while achieving significant acceleration. Experiments on both synthetic and real datasets demonstrate that our approach produces samples from identical distributions as standard methods, but with 2-6$\\times$ speedup. Our ablation studies analyze the impact of hyperparameters such as draft length and draft model size on sampling efficiency. TPP-SD bridges the gap between powerful Transformer TPP models and the practical need for rapid sequence generation.'}",https://openreview.net{'value': '/pdf/fe36aa837f3c952ae94cacfdc0a5d79ff0f60999.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=Ldni3xeyIa,{'value': 'Topology-Aware Conformal Prediction for Stream Networks'},Jifan Zhang; Fangxin Wang; Zihe Song; Philip S. Yu; Kaize Ding; Shixiang Zhu,~Jifan_Zhang2; ~Fangxin_Wang2; ~Zihe_Song2; ~Philip_S._Yu1; ~Kaize_Ding1; ~Shixiang_Zhu1,"{'value': ['conformal prediction', 'stream networks', 'spatiotemporal graph', 'uncertainty quantification']}","{'value': 'Stream networks, a unique class of spatiotemporal graphs, exhibit complex directional flow constraints and evolving dependencies, making uncertainty quantification a critical yet challenging task. Traditional conformal prediction methods struggle in this setting due to the need for joint predictions across multiple interdependent locations and the intricate spatio-temporal dependencies inherent in stream networks. Existing approaches either neglect dependencies, leading to overly conservative predictions, or rely solely on data-driven estimations, failing to capture the rich topological structure of the network. To address these challenges, we propose Spatio-Temporal Adaptive Conformal Inference (STACI), a novel framework that integrates network topology and temporal dynamics into the conformal prediction framework. STACI introduces a topology-aware nonconformity score that respects directional flow constraints and dynamically adjusts prediction sets to account for temporal distributional shifts. We provide theoretical guarantees on the validity of our approach and demonstrate its superior performance on both synthetic and real-world datasets. Our results show that STACI effectively balances prediction efficiency and coverage, outperforming existing conformal prediction methods for stream networks.'}",https://openreview.net{'value': '/pdf/f08362559f1d5f097762512013e8363175d22255.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=LPAqolHp9R,{'value': 'Reverse Diffusion Sequential Monte Carlo Samplers'},Luhuan Wu; Yi Han; Christian A. Naesseth; John Patrick Cunningham,~Luhuan_Wu1; ~Yi_Han15; ~Christian_A._Naesseth1; ~John_Patrick_Cunningham1,{'value': ['sampling; sequential monte carlo; diffusion models; probabilistic methods;']},"{'value': ""We propose a novel sequential Monte Carlo (SMC) method for sampling from unnormalized target distributions based on a reverse denoising diffusion process. While recent diffusion-based samplers simulate the reverse diffusion using approximate score functions, they can suffer from accumulating errors due to time discretization and imperfect score estimation. In this work, we introduce a principled SMC framework that formalizes diffusion-based samplers as proposals while systematically correcting for their biases. The core idea is to construct informative intermediate target distributions that progressively steer the sampling trajectory toward the final target distribution. \nAlthough ideal intermediate targets are intractable, we develop \\emph{exact approximations} using quantities from the score estimation-based proposal, without requiring additional model training or inference overhead. The resulting sampler, termed \\textit{\\ourmethodfull}, enables consistent sampling and unbiased estimation of the target's normalization constant under mild conditions. We demonstrate the effectiveness of our method on a range of synthetic targets and real-world Bayesian inference problems.""}",https://openreview.net{'value': '/pdf/9ef0ea5600e39dd030be4d785be28dedc5afaaa3.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=LKAp7Dknxf,{'value': 'LongVPO: From Anchored Cues to Self-Reasoning for Long-Form Video Preference Optimization'},Zhenpeng Huang; Jiaqi Li; Zihan Jia; Xinhao Li; Desen Meng; Lingxue Song; Xi Chen; Liang Li; Limin Wang,~Zhenpeng_Huang1; ~Jiaqi_Li3; ~Zihan_Jia2; ~Xinhao_Li1; ~Desen_Meng1; ~Lingxue_Song1; ~Xi_Chen51; ~Liang_Li11; ~Limin_Wang1,{'value': ['Video Large Language Models; Long Video Understanding; Preference Optimization']},"{'value': ""We present LongVPO, a novel two‑stage Direct Preference Optimization framework that enables short‑context vision‑language models to robustly understand ultra‑long videos without any long‑video annotations. In Stage 1, we synthesize preference triples by anchoring questions to individual short clips, interleaving them with distractors, and applying visual‑similarity and question‑specificity filtering to mitigate positional bias and ensure unambiguous supervision. We also approximate the reference model’s scoring over long contexts by evaluating only the anchor clip, reducing computational overhead. In Stage 2, we employ a recursive captioning pipeline on long videos to generate scene-level metadata, and then use a large language model to craft multi-segment reasoning queries and dispreferred responses, aligning the model's preferences through multi-segment reasoning tasks. With only 16K synthetic examples and no costly human labels, \\model{} outperforms the state‑of‑the‑art open‑source models on multiple long‑video benchmarks, while maintaining strong short‑video performance (e.g., on MVBench), offering a scalable paradigm for efficient long‑form video understanding.""}",https://openreview.net{'value': '/pdf/c4f3c2c527ec92cf737dd4b6bd2719fac774634b.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=LBo4e6Y7Zg,{'value': 'GaussianFusion: Gaussian-Based Multi-Sensor Fusion for End-to-End Autonomous Driving'},Shuai Liu; Quanmin Liang; Zefeng Li; Boyang Li; Kai Huang,~Shuai_Liu7; ~Quanmin_Liang1; ~Zefeng_Li3; ~Boyang_Li3; ~Kai_Huang2,"{'value': ['End-to-End Autonomous Driving', 'Multi-Sensor Fusion', 'Gaussian']}","{'value': 'Multi-sensor fusion is crucial for improving the performance and robustness of end-to-end autonomous driving systems. Existing methods predominantly adopt either attention-based flatten fusion or bird’s eye view fusion through geometric transformations. However, these approaches often suffer from limited interpretability or dense computational overhead. In this paper, we introduce GaussianFusion, a Gaussian-based multi-sensor fusion framework for end-to-end autonomous driving. Our method employs intuitive and compact Gaussian representations as intermediate carriers to aggregate information from diverse sensors. Specifically, we initialize a set of 2D Gaussians uniformly across the driving scene, where each Gaussian is parameterized by physical attributes and equipped with explicit and implicit features. These Gaussians are progressively refined by integrating multi-modal features. The explicit features capture rich semantic and spatial information about the traffic scene, while the implicit features provide complementary cues beneficial for trajectory planning. To fully exploit rich spatial and semantic information in Gaussians, we design a cascade planning head that iteratively refines trajectory predictions through interactions with Gaussians. Extensive experiments on the NAVSIM and Bench2Drive benchmarks demonstrate the effectiveness and robustness of the proposed GaussianFusion framework. The source code is included in the supplementary material and will be released publicly.'}",https://openreview.net{'value': '/pdf/c1cba5404d0c087f84e67002403584a7ea1c5be2.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=L2W4wQsNkY,{'value': 'MindJourney: Test-Time Scaling with World Models for Spatial Reasoning'},Yuncong Yang; Jiageng Liu; Zheyuan Zhang; Siyuan Zhou; Reuben Tan; Jianwei Yang; Yilun Du; Chuang Gan,~Yuncong_Yang1; ~Jiageng_Liu1; ~Zheyuan_Zhang4; ~Siyuan_Zhou2; ~Reuben_Tan1; ~Jianwei_Yang1; ~Yilun_Du1; ~Chuang_Gan1,"{'value': ['Spatial Reasoning', 'World Models', 'Test-time Scaling']}","{'value': 'Spatial reasoning in 3D space is central to human cognition and indispensable for embodied tasks such as navigation and manipulation. However, state-of-the-art vision–language models (VLMs) struggle frequently with tasks as simple as anticipating how a scene will look after an egocentric motion: they perceive 2D images but lack an internal model of 3D dynamics. We therefore propose SpatialNavigator, a test-time scaling framework that grants a VLM with this missing capability by coupling it to a controllable world model based on video diffusion. The VLM iteratively sketches a concise camera trajectory, while the world model synthesizes the corresponding view at each step. The VLM then reasons over this multi-view evidence gathered during the interactive exploration. Without any fine-tuning, our SpatialNavigator achieves an average 7.7\\% performance boost on the representative spatial reasoning benchmark SAT, showing that pairing VLMs with world models for test-time scaling offers a simple, plug-and-play route to robust 3D reasoning. Meanwhile, our method also improves upon the test-time inference VLMs trained through reinforcement learning, which demonstrates the potential of our method that utilizes world models for test-time scaling.'}",https://openreview.net{'value': '/pdf/5ed386610c8657ff319e5833b8272c6459dd85a4.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=L0xZPXT3le,{'value': 'Multi-Agent Collaboration via Evolving Orchestration'},Yufan Dang; Chen Qian; Xueheng Luo; Jingru Fan; Zihao Xie; Ruijie Shi; Weize Chen; Cheng Yang; Xiaoyin Che; Ye Tian; Xuantang Xiong; Lei Han; Zhiyuan Liu; Maosong Sun,~Yufan_Dang1; ~Chen_Qian8; ~Xueheng_Luo2; ~Jingru_Fan1; ~Zihao_Xie1; ~Ruijie_Shi1; ~Weize_Chen1; ~Cheng_Yang6; ~Xiaoyin_Che1; ~Ye_Tian1; ~Xuantang_Xiong1; ~Lei_Han4; ~Zhiyuan_Liu1; ~Maosong_Sun1,"{'value': ['Large Language Model', 'Autonomous Agent', 'Multi-Agent Collaboration', 'Evolving Orchestration']}","{'value': 'Large language models (LLMs) have achieved remarkable results across diverse downstream tasks, but their monolithic nature restricts scalability and efficiency in complex problem-solving. While recent research explores multi-agent collaboration among LLMs, most approaches rely on static organizational structures that struggle to adapt as task complexity and agent numbers grow, resulting in coordination overhead and inefficiencies. To this end, we propose a puppeteer-style paradigm for LLM-based multi-agent collaboration, where a centralized orchestrator (""puppeteer"") dynamically directs agents (""puppets"") in response to evolving task states. This orchestrator is trained via reinforcement learning to adaptively sequence and prioritize agents, enabling flexible and evolvable collective reasoning. Experiments on closed- and open-domain scenarios show that this method achieves superior performance with reduced computational costs. Analyses further reveal that the key improvements consistently stem from the emergence of more compact, cyclic reasoning structures under the orchestrator’s evolution. Our code is available at https://github.com/OpenBMB/ChatDev/tree/puppeteer.'}",https://openreview.net{'value': '/pdf/9727f658d788c52f49f12ae4b230baf4cf0d4007.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=KxcysQw6Ma,{'value': 'Continuous Domain Generalization'},Zekun Cai; Yiheng YAO; Guangji Bai; Renhe Jiang; Xuan Song; Ryosuke Shibasaki; Liang Zhao,~Zekun_Cai1; ~Yiheng_YAO1; ~Guangji_Bai1; ~Renhe_Jiang1; ~Xuan_Song5; ~Ryosuke_Shibasaki1; ~Liang_Zhao6,"{'value': ['Domain Generalization', 'Continuous Domain Generalization', 'Distribution Shift', 'Neural Operator', 'Lie Group']}","{'value': 'Real-world data distributions often shift continuously across multiple latent factors such as time, geography, and socioeconomic contexts. However, existing domain generalization approaches typically treat domains as discrete or as evolving along a single axis (e.g., time). This oversimplification fails to capture the complex, multidimensional nature of real-world variation. This paper introduces the task of Continuous Domain Generalization (CDG), which aims to generalize predictive models to unseen domains defined by arbitrary combinations of continuous variations. We present a principled framework grounded in geometric and algebraic theories, showing that optimal model parameters across domains lie on a low-dimensional manifold. To model this structure, we propose a Neural Lie Transport Operator (NeuralLio), which enables structure-preserving parameter transitions by enforcing geometric continuity and algebraic consistency. To handle noisy or incomplete domain variation descriptors, we introduce a gating mechanism to suppress irrelevant dimensions and a local chart-based strategy for robust generalization. Extensive experiments on synthetic and real-world datasets, including remote sensing, scientific documents, and traffic forecasting, demonstrate that our method significantly outperforms existing baselines in both generalization accuracy and robustness.'}",https://openreview.net{'value': '/pdf/572c51c19aec652602dfc49de0c962f80418047a.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=KsmlBRhLgs,{'value': 'Rainbow Delay Compensation: A Multi-Agent Reinforcement Learning Framework for Mitigating Observation Delays'},Songchen Fu; Siang Chen; Shaojing Zhao; Letian Bai; Hong Liang; Ta Li; Yonghong Yan,~Songchen_Fu1; ~Siang_Chen1; ~Shaojing_Zhao1; ~Letian_Bai1; ~Hong_Liang7; ~Ta_Li1; ~Yonghong_Yan4,"{'value': ['Deep Reinforcement Learning', 'Signal Delay', 'Multi-agent System']}","{'value': ""In real-world multi-agent systems (MASs), observation delays are ubiquitous, preventing agents from making decisions based on the environment's true state. An individual agent's local observation typically comprises multiple components from other agents or dynamic entities within the environment. These discrete observation components with varying delay characteristics pose significant challenges for multi-agent reinforcement learning (MARL). In this paper, we first formulate the decentralized stochastic individual delay partially observable Markov decision process (DSID-POMDP) by extending the standard Dec-POMDP. We then propose the Rainbow Delay Compensation (RDC), a MARL training framework for addressing stochastic individual delays, along with recommended implementations for its constituent modules. We implement the DSID-POMDP's observation generation pattern using standard MARL benchmarks, including MPE and SMAC. Experiments demonstrate that baseline MARL methods suffer severe performance degradation under fixed and unfixed delays. The RDC-enhanced approach mitigates this issue, remarkably achieving ideal delay-free performance in certain delay scenarios while maintaining generalizability. Our work provides a novel perspective on multi-agent delayed observation problems and offers an effective solution framework. The source code is available at https://github.com/linkjoker1006/RDC-pymarl.""}",https://openreview.net{'value': '/pdf/987910dbeae9a12971e2ab807f1001794e2402b0.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=KlZUwDP0pR,{'value': 'Tree of Preferences for Diversified Recommendation'},Hanyang Yuan; Ning Tang; Tongya Zheng; Jiarong Xu; Xintong Hu; Renhong Huang; Shunyu Liu; Jiacong Hu; Jiawei Chen; Mingli Song,~Hanyang_Yuan1; ~Ning_Tang3; ~Tongya_Zheng1; ~Jiarong_Xu2; ~Xintong_Hu1; ~Renhong_Huang1; ~Shunyu_Liu1; ~Jiacong_Hu1; ~Jiawei_Chen6; ~Mingli_Song1,"{'value': ['Large language model', 'recommendation diversity']}","{'value': ""Diversified recommendation has attracted increasing attention from both researchers and practitioners, which can effectively address the homogeneity of recommended items.\nExisting approaches predominantly aim to infer the diversity of user preferences from observed user feedback.\nNonetheless, due to inherent data biases, the observed data may not fully reflect user interests, where underexplored preferences can be overwhelmed or remain unmanifested. Failing to capture these preferences can lead to suboptimal diversity in recommendations. To fill this gap,  this work aims to study diversified recommendation from a data-bias perspective.\nInspired by the outstanding performance of large language models (LLMs) in zero-shot inference leveraging world knowledge, we propose a novel approach that utilizes LLMs' expertise to uncover underexplored user preferences from observed behavior, ultimately providing diverse and relevant recommendations.\nTo achieve this, we first introduce Tree of Preferences (ToP), an innovative structure constructed to model user preferences from coarse to fine. ToP enables LLMs to systematically reason over the user's rationale behind their behavior, thereby uncovering their underexplored preferences.\nTo guide diversified recommendations using uncovered preferences, we adopt a data-centric approach, identifying candidate items that match user preferences and generating synthetic interactions that reflect underexplored preferences.  These interactions are integrated to train a general recommender for diversification.\nMoreover, we scale up overall efficiency by dynamically selecting influential users during optimization.\nExtensive evaluations of both diversity and relevance show that our approach outperforms existing methods in most cases and achieves near-optimal performance in others, with reasonable inference latency.""}",https://openreview.net{'value': '/pdf/e026e2523a28ce8d1fb92eb33e565541d246a470.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=KWRKCXRwNg,{'value': 'Ground-Compose-Reinforce: Grounding Language in Agentic Behaviours using Limited Data'},Andrew C Li; Toryn Q. Klassen; Andrew Wang; Parand A. Alamdari; Sheila A. McIlraith,~Andrew_C_Li1; ~Toryn_Q._Klassen1; ~Andrew_Wang4; ~Parand_A._Alamdari1; ~Sheila_A._McIlraith1,"{'value': ['Reinforcement Learning', 'RL', 'Formal Language', 'Reward Machine', 'LTL', 'Language', 'Grounding', 'Compositional']}","{'value': 'Grounding language in perception and action is a key challenge when building situated agents that can interact with humans, or other agents, via language. In the past, addressing this challenge has required manually designing the language grounding or curating massive datasets that associate language with the environment. We propose Ground-Compose-Reinforce, an end-to-end, neurosymbolic framework for training RL agents directly from high-level task specifications—without manually designed reward functions or other domain-specific oracles, and without massive datasets. These task specifications take the form of Reward Machines, automata-based representations that capture high-level task structure and are in some cases autoformalizable from natural language. Critically, we show that Reward Machines can be grounded using limited data by exploiting compositionality. Experiments in a custom Meta-World domain with only 350 labelled pretraining trajectories show that our framework faithfully elicits complex behaviours from high-level specifications—including behaviours that never appear in pretraining—while non-compositional approaches fail.'}",https://openreview.net{'value': '/pdf/11307c66616c3c5251e9f263baa1529ef549037e.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=KR6tnkb6h4,{'value': 'MobileUse: A Hierarchical Reflection-Driven GUI Agent for Autonomous Mobile Operation'},Ning Li; Xiangmou Qu; Jiamu Zhou; Jun Wang; Muning Wen; Kounianhua Du; Xingyu Lou; Qiuying Peng; Jun Wang; Weinan Zhang,~Ning_Li8; ~Xiangmou_Qu1; ~Jiamu_Zhou1; ~Jun_Wang84; ~Muning_Wen2; ~Kounianhua_Du1; ~Xingyu_Lou3; ~Qiuying_Peng1; ~Jun_Wang38; ~Weinan_Zhang1,"{'value': ['Mobile GUI Agent', 'Multi-Agent Framework', 'Hierarchical Reflection', 'Proactive Exploration']}","{'value': 'Recent advances in Multimodal Large Language Models (MLLMs) have enabled the development of mobile agents that can understand visual inputs and follow user instructions, unlocking new possibilities for automating complex tasks on mobile devices. However, applying these models to real-world mobile scenarios remains a significant challenge due to the long-horizon task execution, difficulty in error recovery, and the cold-start problem in unfamiliar environments. To address these challenges, we propose MobileUse, a GUI agent designed for robust and adaptive mobile task execution. To improve resilience in long-horizon tasks and dynamic environments, we introduce a hierarchical reflection architecture that enables the agent to self-monitor, detect, and recover from errors across multiple temporal scales—ranging from individual actions to overall task completion—while maintaining efficiency through a Reflection-on-Demand strategy. To tackle cold-start issues, we further introduce a proactive exploration module, which enriches the agent’s understanding of the environment through self-planned exploration. Evaluations on the AndroidWorld and AndroidLab benchmarks demonstrate that MobileUse establishes new state-of-the-art performance, achieving success rates of 62.9% and 44.2%, respectively. To facilitate real-world applications, we release an out-of-the-box toolkit for automated task execution on physical mobile devices, which is available at https://github.com/MadeAgents/mobile-use.'}",https://openreview.net{'value': '/pdf/0dfcd45aa867bf09cef726711a929960f019ea27.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=KIximJjqjV,{'value': 'Quality-Driven Curation of Remote Sensing Vision-Language Data via Learned Scoring Models'},Dilxat Muhtar; Enzhuo Zhang; Zhenshi Li; Feng Gu; Yanglangxing He; Pengfeng Xiao; Xueliang Zhang,~Dilxat_Muhtar1; ~Enzhuo_Zhang1; ~Zhenshi_Li1; ~Feng_Gu6; ~Yanglangxing_He1; ~Pengfeng_Xiao1; ~Xueliang_Zhang1,"{'value': ['Remote Sensing Image', 'Vision Language Data', 'Vision Language Model']}","{'value': 'Vision-Language Models (VLMs) have demonstrated great potential in interpreting remote sensing (RS) images through language-guided semantic. However, the effectiveness of these VLMs critically depends on high-quality image-text training data that captures rich semantic relationships between visual content and language descriptions. Unlike natural images, RS lacks large-scale interleaved image-text pairs from web data, making data collection challenging. While current approaches rely primarily on rule-based methods or flagship VLMs for data synthesis, a systematic framework for automated quality assessment of such synthetically generated RS vision-language data is notably absent. To fill this gap, we propose a novel score model trained on large-scale RS vision-language preference data for automated quality assessment. Our empirical results demonstrate that fine-tuning CLIP or advanced VLMs (e.g., Qwen2-VL) with the top 30% of data ranked by our score model achieves superior accuracy compared to both full-data fine-tuning and CLIP-score-based ranking approaches. Furthermore, we demonstrate applications of our scoring model for reinforcement learning (RL) training and best-of-N (BoN) test-time scaling, enabling significant improvements in VLM performance for RS tasks. Our code, model, and dataset are publicly available.'}",https://openreview.net{'value': '/pdf/a8d9966faa0e0143bb9f670c36f097db77c00ad8.pdf'},{'abstract_filter': 'Data Synthesis'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=K7s0lIjhWx,{'value': 'Improving the Generation and Evaluation of Synthetic Data for Downstream Medical Causal Inference'},Harry Amad; Zhaozhi Qian; Dennis Frauen; Julianna Piskorz; Stefan Feuerriegel; Mihaela van der Schaar,~Harry_Amad1; ~Zhaozhi_Qian1; ~Dennis_Frauen1; ~Julianna_Piskorz1; ~Stefan_Feuerriegel1; ~Mihaela_van_der_Schaar2,"{'value': ['synthetic data', 'treatment effect estimation', 'medical data', 'generative models', 'evalution metrics']}","{'value': 'Causal inference is essential for developing and evaluating medical interventions, yet real-world medical datasets are often difficult to access due to regulatory barriers. This makes synthetic data a potentially valuable asset that enables these medical analyses, along with the development of new inference methods themselves. Generative models can produce synthetic data that closely approximate real data distributions, yet existing methods do not consider the unique challenges that downstream causal inference tasks, and specifically those focused on treatments, pose. We establish a set of desiderata that synthetic data containing treatments should satisfy to maximise downstream utility: preservation of (i) the covariate distribution, (ii) the treatment assignment mechanism, and (iii) the outcome generation mechanism. Based on these desiderata, we propose a set of evaluation metrics to assess such synthetic data. Finally, we present STEAM: a novel method for generating Synthetic data for Treatment Effect Analysis in Medicine that mimics the data-generating process of data containing treatments and optimises for our desiderata. We empirically demonstrate that STEAM achieves state-of-the-art performance across our metrics as compared to existing generative models, particularly as the complexity of the true data-generating process increases.'}",https://openreview.net{'value': '/pdf/b8844de75d6a526ebbaa13a9ead4fcc1af682cac.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=K6M7QmN1wQ,{'value': 'From Likelihood to Fitness: Improving Variant Effect Prediction in Protein and Genome Language Models'},Charles W. J. Pugh; Paulina G. Nuñez-Valencia; Mafalda Dias; Jonathan Frazer,~Charles_W._J._Pugh1; ~Paulina_G._Nuñez-Valencia1; ~Mafalda_Dias1; ~Jonathan_Frazer1,"{'value': ['Protein language model', 'Genomic language model', 'Fitness estimation']}","{'value': 'Generative models trained on natural sequences are increasingly used to predict the effects of genetic variation, enabling progress in therapeutic design, disease risk prediction, and synthetic biology. In the zero-shot setting, variant impact is estimated by comparing the likelihoods of sequences, under the assumption that likelihood serves as a proxy for fitness. However, this assumption often breaks down in practice: sequence likelihood reflects not only evolutionary fitness constraints, but also phylogenetic structure and sampling biases, especially as model capacity increases. We introduce Likelihood-Fitness Bridging (LFB), a simple and general strategy that improves variant effect prediction by averaging model scores across sequences subject to similar selective pressures. Assuming an Ornstein-Uhlenbeck model of evolution, LFB can be viewed as a way to marginalize the effects of genetic drift, although its benefits appear to extend more broadly. LFB applies to existing protein and genomic language models without requiring retraining, and incurs only modest computational overhead. Evaluated on large-scale deep mutational scans and clinical benchmarks, LFB consistently improves predictive performance across model families and sizes. Notably, it reverses the performance plateau observed in larger protein language models, making the largest models the most accurate when combined with LFB. These results suggest that accounting for phylogenetic and sampling biases is essential to realizing the full potential of large sequence models in variant effect prediction.'}",https://openreview.net{'value': '/pdf/a151f62ee40ad4dbb1a77edc99a894103d3ce137.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=JvHif4fyeP,{'value': 'Agents Robust to Distribution Shifts Learn Causal World Models Even Under Mediation'},Matteo Ceriscioli; Karthika Mohan,~Matteo_Ceriscioli1; ~Karthika_Mohan2,"{'value': ['Causality', 'POMDP', 'Multi-agent systems']}","{'value': ""In this work, we prove that agents capable of adapting to distribution shifts must have learned the causal model of their environment even in the presence of mediation. This term describes situations where an agent's actions affect its environment, a dynamic common to most real-world settings. For example, a robot in an industrial plant might interact with tools, move through space, and transform products to complete its task. We introduce an algorithm for eliciting causal knowledge from robust agents using optimal policy oracles, with the flexibility to incorporate prior causal knowledge. We further demonstrate its effectiveness in mediated single-agent scenarios and multi-agent environments. We identify conditions under which the presence of a single robust agent is sufficient to recover the full causal model and derive optimal policies for other agents in the same environment. Finally, we show how to apply these results to sequential decision-making tasks modeled as Partially Observable Markov Decision Processes (POMDPs).""}",https://openreview.net{'value': '/pdf/87ab0dc2d16adaecf9fc19c3d53702417f98bf63.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=Jom8tNYuQI,{'value': 'Diffusion Generative Modeling on Lie Group Representations'},Marco Bertolini; Tuan Le; Djork-Arné Clevert,~Marco_Bertolini1; ~Tuan_Le2; ~Djork-Arné_Clevert2,"{'value': ['generative modeling', 'diffusion models', 'lie groups', 'representation theory']}","{'value': 'We introduce a novel class of score-based diffusion processes that operate directly in the representation space of Lie groups.\nLeveraging the framework of Generalized Score Matching, we derive a class of Langevin dynamics that decomposes as a direct sum of Lie algebra representations,\nenabling the modeling of any target distribution on any (non-Abelian) Lie group.\nStandard score-matching emerges as a special case of our framework when the Lie group is the translation group. \nWe prove that our generalized generative processes arise as solutions to a new class of paired stochastic differential equations (SDEs), introduced here for the first time. \nWe validate our approach through experiments on diverse data types, demonstrating its effectiveness in real-world applications such as $\\text{SO}(3)$-guided molecular conformer generation and modeling ligand-specific global $\\text{SE}(3)$ transformations for molecular docking, showing improvement in comparison to Riemannian diffusion on the group itself.\nWe show that an appropriate choice of Lie group enhances learning efficiency by reducing the effective dimensionality of the trajectory space and enables the modeling of transitions between complex data distributions.'}",https://openreview.net{'value': '/pdf/5546a026b3fca100cee9766547c2179ef46b55ac.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=JkVQmaE5pK,{'value': 'SMARTraj$^2$: A Stable Multi-City Adaptive Method for Multi-View Spatio-Temporal Trajectory Representation Learning'},Tangwen Qian; Junhe Li; Yile Chen; Gao Cong; Zezhi Shao; Jun Zhang; Tao Sun; Fei Wang; Yongjun Xu,~Tangwen_Qian1; ~Junhe_Li1; ~Yile_Chen2; ~Gao_Cong1; ~Zezhi_Shao1; ~Jun_Zhang52; ~Tao_Sun19; ~Fei_Wang14; ~Yongjun_Xu1,"{'value': ['Trajectory Representation Learning', 'Spatio-Temporal Data Mining', 'Self-Supervised Learning']}","{'value': 'Spatio-temporal trajectory representation learning plays a crucial role in various urban applications such as transportation systems, urban planning, and environmental monitoring. Existing methods can be divided into single-view and multi-view approaches, with the latter offering richer representations by integrating multiple sources of spatio-temporal data. However, these methods often struggle to generalize across diverse urban scenes due to multi-city structural heterogeneity, which arises from the disparities in road networks, grid layouts, and traffic regulations across cities, and the amplified seesaw phenomenon, where optimizing for one city, view, or task can degrade performance in others. These challenges hinder the deployment of trajectory learning models across multiple cities, limiting their real-world applicability. In this work, we propose SMARTraj$^2$, a novel stable multi-city adaptive method for multi-view spatio-temporal trajectory representation learning. Specifically, we introduce a feature disentanglement module to separate domain-invariant and domain-specific features, and a personalized gating mechanism to dynamically stabilize the contributions of different views and tasks. Our approach achieves superior generalization across heterogeneous urban scenes while maintaining robust performance across multiple downstream tasks. Extensive experiments on benchmark datasets demonstrate the effectiveness of SMARTraj$^2$ in enhancing cross-city generalization and outperforming state-of-the-art methods. See our project website at \\url{https://github.com/GestaltCogTeam/SMARTraj}.'}",https://openreview.net{'value': '/pdf/f9006947e08855ad24613b7e76291046bd967bd1.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=JeXkIy0JyM,{'value': 'Ctrl-DNA: Controllable Cell-Type-Specific Regulatory DNA Design via Constrained RL'},Xingyu Chen; Shihao Ma; Runsheng Lin; Jiecong Lin; BO WANG,~Xingyu_Chen11; ~Shihao_Ma1; ~Runsheng_Lin1; ~Jiecong_Lin1; ~BO_WANG11,"{'value': ['Regulatory DNA sequence design', 'Reinforcement Learning', 'Constrained optimization', 'Genomic language model']}","{'value': 'Designing regulatory DNA sequences that achieve precise cell-type-specific gene expression is crucial for advancements in synthetic biology, gene therapy and precision medicine. Although transformer-based language models (LMs) can effectively capture patterns in regulatory DNA, their generative approaches often struggle to produce novel sequences with reliable cell-specific activity. Here, we introduce Ctrl-DNA, a novel constrained reinforcement learning (RL) framework tailored for designing regulatory DNA sequences with controllable cell-type specificity. By formulating regulatory sequence design as a biologically informed constrained optimization problem, we apply RL to autoregressive genomic LMs, enabling the models to iteratively refine sequences that maximize regulatory activity in targeted cell types while constraining off-target effects. Our evaluation on human promoters and enhancers demonstrates that Ctrl-DNA consistently outperforms existing generative and RL-based approaches, generating high-fitness regulatory sequences and achieving state-of-the-art cell-type specificity. Moreover, Ctrl-DNA-generated sequences capture key cell-type-specific transcription factor binding sites (TFBS), short DNA motifs recognized by regulatory proteins that control gene expression, demonstrating the biological plausibility of the generated sequences.'}",https://openreview.net{'value': '/pdf/56d32e6dccec0c78a8218c3c4cef541721609d05.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=Jd8UcXJDCz,{'value': 'Unsupervised Learning for Optimal Transport plan prediction between unbalanced graphs'},Sonia Mazelet; Rémi Flamary; Bertrand Thirion,~Sonia_Mazelet1; ~Rémi_Flamary1; ~Bertrand_Thirion1,"{'value': ['Non-Convex Optimization', 'Unsupervised Learning', 'optimal transport', 'gnn']}","{'value': 'Optimal transport between graphs, based on Gromov-Wasserstein and\n  other extensions, is a powerful tool for comparing and aligning\n  graph structures.  However, solving the associated non-convex\n  optimization problems is computationally expensive, which limits the\n  scalability of these methods to large graphs. In this work, we\n  present Unbalanced Learning of Optimal Transport (ULOT), a deep\n  learning method that predicts optimal transport plans between two\n  graphs. Our method is trained by minimizing the fused unbalanced\n  Gromov-Wasserstein (FUGW) loss. We propose a novel neural\n  architecture with cross-attention that is conditioned on the FUGW\n  tradeoff hyperparameters. We evaluate ULOT on synthetic stochastic\n  block model (SBM) graphs and on real cortical surface data obtained\n  from fMRI. ULOT predicts transport plans with competitive loss up to\n  two orders of magnitude faster than classical solvers.  Furthermore,\n  the predicted plan can be used as a warm start for classical solvers\n  to accelerate their convergence. Finally, the predicted transport\n  plan is fully differentiable with respect to the graph inputs and\n  FUGW hyperparameters, enabling the optimization of functionals of\n  the ULOT plan.'}",https://openreview.net{'value': '/pdf/f7e588cb1355fd38a15e72e1a5d4961e2bcb19c7.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=JZ1fVVS3uk,{'value': 'High-order Interactions Modeling for Interpretable Multi-Agent Q-Learning'},Qinyu Xu; Yuanyang Zhu; Xuefei Wu; Chunlin Chen,~Qinyu_Xu2; ~Yuanyang_Zhu1; ~Xuefei_Wu1; ~Chunlin_Chen1,"{'value': ['Continued fraction Q-learning', 'high-order interaction', 'interpretability', 'multi-agent reinforcement learning']}","{'value': 'The ability to model interactions among agents is crucial for effective coordination and understanding their cooperation mechanisms in multi-agent reinforcement learning (MARL). \nHowever, previous efforts to model high-order interactions have been primarily hindered by the combinatorial explosion or the opaque nature of their black-box network structures.\nIn this paper, we propose a novel value decomposition framework, called Continued Fraction Q-Learning (QCoFr), which can flexibly capture arbitrary-order agent interactions with only linear complexity $\\mathcal{O}\\left({n}\\right)$ in the number of agents, thus avoiding the combinatorial explosion when modeling rich cooperation. \nFurthermore, we introduce the variational information bottleneck to extract latent information for estimating credits.\nThis latent information helps agents filter out noisy interactions, thereby significantly enhancing both cooperation and interpretability.\nExtensive experiments demonstrate that QCoFr not only consistently achieves better performance but also provides interpretability that aligns with our theoretical analysis.'}",https://openreview.net{'value': '/pdf/285490f5da546e4b408c905507a4e808cb38d647.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=JYB6wFcbky,{'value': 'Graph-based Symbolic Regression with Invariance and Constraint Encoding'},Ziyu Xiang; Kenna Ashen; Xiaofeng Qian; Xiaoning Qian,~Ziyu_Xiang1; ~Kenna_Ashen1; ~Xiaofeng_Qian1; ~Xiaoning_Qian2,"{'value': ['Symbolic Regression', 'Expression Graph', 'Hybrid Neural-guided Monte Carlo Tree Search', 'Expression Equivalence', 'Permutation Invariance', 'Physics Constraints']}","{'value': ""Symbolic regression (SR) seeks interpretable analytical expressions that uncover the governing relationships within data, providing mechanistic insight beyond 'black-box' models. However, existing SR methods often suffer from two key limitations: (1) *redundant representations* that fail to capture mathematical equivalences and higher-order operand relations, breaking permutation invariance and hindering efficient learning; and (2) *sparse rewards* caused by incomplete incorporation of constraints that can only be evaluated on full expressions, such as constant fitting or physical-law verification. To address these challenges, we propose a unified framework, **Graph-based Symbolic Regression (GSR)**,  which compresses the search space through the permutation-invariant representations, expression graphs (EGs), that intrinsically encode expression equivalences via a term-rewriting system (TRS) and a directed acyclic graph (DAG) structure. GSR mitigates reward sparsity by employing a hybrid neural-guided Monte Carlo tree search (hnMCTS) on EGs, where constraint-informed neural guidance enables the direct incorporation of expression-level constraint priors, and an adaptive $\\epsilon$-UCB policy balances exploration and exploitation. Theoretical analyses establish the uniqueness of our proposed EG representation and the convergence of the hnMCTS algorithm. Experiments on synthetic and real-world scientific datasets demonstrate the efficiency and accuracy of GSR in discovering underlying expressions and adhering to physical laws, offering practical solutions for scientific discovery.""}",https://openreview.net{'value': '/pdf/95ee458f819eabcf3dd44fd6e588009c619490df.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=JWmfbzw8ur,{'value': 'Harnessing Feature Resonance under Arbitrary Target Alignment for Out-of-Distribution Node Detection'},Shenzhi Yang; Junbo Zhao; Sharon Li; Shouqing Yang; Dingyu Yang; Xiaofang Zhang; Haobo Wang,~Shenzhi_Yang1; ~Junbo_Zhao1; ~Sharon_Li1; ~Shouqing_Yang1; ~Dingyu_Yang1; ~Xiaofang_Zhang1; ~Haobo_Wang1,"{'value': ['Out-of-distribution detection', 'Node representation learning', 'Graph neural networks']}","{'value': 'Out-of-distribution (OOD) node detection in graphs is a critical yet challenging task. Most existing approaches rely heavily on fine-grained labeled data to obtain a pre-trained supervised classifier, inherently assuming the existence of a well-defined pretext classification task. However, when such a task is ill-defined or absent, their applicability becomes severely limited. To overcome this limitation, there is an urgent need to propose a more scalable OOD detection method that is independent of both pretext tasks and label supervision. We harness a new phenomenon called **Feature Resonance**, focusing on the feature space rather than the label space. We observe that, ideally, during the optimization of known ID samples, unknown ID samples undergo more significant representation changes than OOD samples, even when the model is trained to align arbitrary targets. The rationale behind it is that even without gold labels, the local manifold may still exhibit smooth resonance.  Based on this, we further develop a novel graph OOD framework, dubbed **R**esonance-based **S**eparation and **L**earning (**RSL**), which comprises two core modules:  (i)-a more practical micro-level proxy of feature resonance that measures the movement of feature vectors in one training step. (ii)-integrate with a synthetic OOD node strategy to train an effective OOD classifier. Theoretically, we derive an error bound showing the superior separability of OOD nodes during the resonance period. Extensive experiments on a total of thirteen real-world graph datasets empirically demonstrate that RSL achieves state-of-the-art performance.'}",https://openreview.net{'value': '/pdf/70ecba790a3d102db74e1939777f4d38e932ddbb.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=JScOknY0Su,{'value': 'FerretNet: Efficient Synthetic Image Detection via Local Pixel Dependencies'},Shuqiao Liang; Jian Liu; Chen Renzhang; Quanlong Guan,~Shuqiao_Liang2; ~Jian_Liu19; ~Chen_Renzhang1; ~Quanlong_Guan1,"{'value': ['Synthetic Image Detection', 'Local Pixel Dependencies', 'Markov Random Fields', 'Image Forensics']}","{'value': 'The increasing realism of synthetic images generated by advanced models such as VAEs, GANs, and LDMs poses significant challenges for synthetic image detection.\nTo address this issue, we explore two artifact types introduced during the generation process: (1) latent distribution deviations and (2) decoding-induced smoothing effects, which manifest as inconsistencies in local textures, edges, and color transitions.\nLeveraging local pixel dependencies (LPD) properties rooted in Markov Random Fields, we reconstruct synthetic images using neighboring pixel information to expose disruptions in texture continuity and edge coherence.\nBuilding upon LPD, we propose FerretNet, a lightweight neural network with only 1.1M parameters that delivers efficient and robust synthetic image detection.\nExtensive experiments demonstrate that FerretNet—trained exclusively on the 4-class ProGAN dataset—achieves an average accuracy of 97.1% on an open-world benchmark comprising 22 generative models. Our code and datasets are publicly available at https://github.com/xigua7105/FerretNet.'}",https://openreview.net{'value': '/pdf/9dbd59525224f8c9b26237c2dea448bad2ac9ee8.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=JRVZTACwb0,{'value': 'Fast Monte Carlo Tree Diffusion: 100× Speedup via Parallel and Sparse Planning'},Jaesik Yoon; Hyeonseo Cho; Yoshua Bengio; Sungjin Ahn,~Jaesik_Yoon1; ~Hyeonseo_Cho1; ~Yoshua_Bengio1; ~Sungjin_Ahn1,"{'value': ['Diffusion', 'MCTS', 'Long-term Planning', 'Offline RL', 'Goal-conditioned RL', 'Efficient Planning', 'Reasoning', 'Inference-Time Scaling']}","{'value': 'Diffusion models have recently emerged as a powerful approach for trajectory planning. However, their inherently non-sequential nature limits their effectiveness in long-horizon reasoning tasks at test time. The recently proposed Monte Carlo Tree Diffusion (MCTD) offers a promising solution by combining diffusion with tree-based search, achieving state-of-the-art performance on complex planning problems. Despite its strengths, our analysis shows that MCTD incurs substantial computational overhead due to the sequential nature of tree search and the cost of iterative denoising. To address this, we propose Fast-MCTD, a more efficient variant that preserves the strengths of MCTD while significantly improving its speed and scalability. Fast-MCTD integrates two techniques: Parallel MCTD, which enables parallel rollouts via delayed tree updates and redundancy-aware selection; and Sparse MCTD, which reduces rollout length through trajectory coarsening. Experiments show that Fast-MCTD achieves up to 100× speedup over standard MCTD while maintaining or improving planning performance. Remarkably, it even outperforms Diffuser in inference speed on some tasks, despite Diffuser requiring no search and yielding weaker solutions. These results position Fast-MCTD as a practical and scalable solution for diffusion-based inference-time reasoning.'}",https://openreview.net{'value': '/pdf/2fdea415929397a5ced9ee3ee515d155825c69b1.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=JPoQca8CSg,{'value': 'MoleBridge: Synthetic Space Projecting with Discrete Markov Bridges'},Rongchao Zhang; Yu Huang; Yongzhi Cao; Hanpin Wang,~Rongchao_Zhang2; ~Yu_Huang6; ~Yongzhi_Cao1; ~Hanpin_Wang1,"{'value': ['Markov Bridges', 'Diffusion Models', 'AIGC', 'Generation']}","{'value': 'Molecular synthetic space projecting is a critical technique in de novo molecular design, which aims to rectify molecules without synthesizability guarantee by converting them into synthetic postfix notations. However, the vast synthesizable chemical space and the discrete data modalities involved pose significant challenges to postfix notation conversion benchmarking. In this paper, we exploit conditional probability transitions in discrete state space and introduce MoleBridge, a deep generative model built on the Markov bridge approach for designing postfix notations of molecular synthesis pathways. MoleBridge consists of two iterative optimizations: i) Autoregressive extending of notation tokens from molecular graphs, and ii) generation of discrete reaction postfix notations through Markov bridge, where noisy token blocks are progressively denoised over multi-step iterations. For the challenging second iteration, which demands sensitivity to incorrect generative probability paths within intricate chemical spaces, we employ a thinking and denoising separation approach to denoise. Empirically, we find that MoleBridge is capable of accurately predicting synthesis pathways while exhibiting excellent performance in a variety of application scenarios.'}",https://openreview.net{'value': '/pdf/70167de8ddca83e28642e2a3c087bccd48a5f451.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=JPjMXgQQxk,{'value': 'Generative Modeling of Full-Atom Protein Conformations using Latent Diffusion on Graph Embeddings'},Aditya Sengar; Ali Hariri; Daniel Probst; PATRICK BARTH; Pierre Vandergheynst,~Aditya_Sengar1; ~Ali_Hariri1; ~Daniel_Probst3; ~PATRICK_BARTH1; ~Pierre_Vandergheynst1,"{'value': ['Latent Diffusion', 'Graph Neural Networks', 'Protein Structure Generation', 'All-atom modeling', 'Molecular Dynamics']}","{'value': 'Generating diverse, all‐atom conformational ensembles of dynamic proteins such as G‐protein‐coupled receptors (GPCRs) is critical for understanding their function, yet most generative models simplify atomic detail or ignore conformational diversity altogether. We present latent diffusion for full protein generation (LD-FPG), a framework that constructs complete all‐atom protein structures, including every side‐chain heavy atom, directly from molecular dynamics (MD) trajectories. LD-FPG employs a Chebyshev graph neural network (ChebNet) to obtain low‐dimensional latent embeddings of protein conformations, which are processed using three pooling strategies: blind, sequential and residue‐based. A diffusion model trained on these latent representations generates new samples that a decoder, optionally regularized by dihedral‐angle losses, maps back to Cartesian coordinates. Using D2R-MD, a $2\\mu\\text{s}$ MD trajectory (12 000 frames) of the human dopamine D$2$ receptor in a membrane environment, the sequential and residue-based pooling strategies reproduce the reference ensemble with high structural fidelity (all‐atom lDDT \\~ $0.7$; $C\\alpha$-lDDT \\~ $0.8$) and recovers backbone and side‐chain dihedral‐angle distributions with a Jensen–Shannon divergence $<0.03$ compared to the MD data. LD-FPG thereby offers a practical route to system‐specific, all‐atom ensemble generation for large proteins, providing a promising tool for structure‐based therapeutic design on complex, dynamic targets. The D2R-MD dataset and our implementation are freely available to facilitate further research.'}",https://openreview.net{'value': '/pdf/a98baeaa5867971c7e7ebb650d1d64686abf8c93.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=JH0DczMsAV,{'value': 'DCI: Dual-Conditional Inversion for Boosting Diffusion-Based Image Editing'},Zixiang Li; Haoyu Wang; Wei Wang; Chuangchuang Tan; Yunchao Wei; Yao Zhao,~Zixiang_Li2; ~Haoyu_Wang19; ~Wei_Wang43; ~Chuangchuang_Tan1; ~Yunchao_Wei1; ~Yao_Zhao1,{'value': ['Diffusion model; Image Editing']},"{'value': 'Diffusion models have achieved remarkable success in image generation and editing tasks. Inversion within these models aims to recover the latent noise representation for a real or generated image, enabling reconstruction, editing, and other downstream tasks. However, to date, most inversion approaches suffer from an intrinsic trade-off between reconstruction accuracy and editing flexibility. This limitation arises from the difficulty of maintaining both semantic alignment and structural consistency during the inversion process. In this work, we introduce **Dual-Conditional Inversion (DCI)**, a novel framework that jointly conditions on the source prompt and reference image to guide the inversion process. Specifically, DCI formulates the inversion process as a dual-condition fixed-point optimization problem, minimizing both the latent noise gap and the reconstruction error under the joint guidance. This design anchors the inversion trajectory in both semantic and visual space, leading to more accurate and editable latent representations. Our novel setup brings new understanding to the inversion process. Extensive experiments demonstrate that DCI achieves state-of-the-art performance across multiple editing tasks, significantly improving both reconstruction quality and editing precision. Furthermore, we also demonstrate that our method achieves strong results in reconstruction tasks, implying a degree of robustness and generalizability approaching the ultimate goal of the inversion process. Our codes are available at: [https://github.com/Lzxhh/Dual-Conditional-Inversion](https://github.com/Lzxhh/Dual-Conditional-Inversion)'}",https://openreview.net{'value': '/pdf/1f330898df7bfa95d49096393e316726b3eb7f18.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=IpYEKM0Bla,{'value': 'Quantifying Distributional Invariance in Causal Subgraph for IRM-Free Graph Generalization'},Yang Qiu; Yixiong Zou; Jun Wang; Wei Liu; Xiangyu Fu; Ruixuan Li,~Yang_Qiu2; ~Yixiong_Zou1; ~Jun_Wang1; ~Wei_Liu30; ~Xiangyu_Fu1; ~Ruixuan_Li1,{'value': ['graph neural networks; out-of-distribution']},"{'value': 'Out-of-distribution generalization under distributional shifts remains a critical challenge for graph neural networks. Existing methods generally adopt the Invariant Risk Minimization (IRM) framework, requiring costly environment annotations or heuristically generated synthetic splits. To circumvent these limitations, in this work, we aim to develop an IRM-free method for capturing causal subgraphs. We first identify that causal subgraphs exhibit substantially smaller distributional variations than non-causal components across diverse environments, which we formalize as the Invariant Distribution Criterion and theoretically prove in this paper. Building on this criterion, we systematically uncover the quantitative relationship between distributional shift and representation norm for identifying the causal subgraph, and investigate its underlying mechanisms in depth. Finally, we propose an IRM-free method by introducing a norm-guided invariant distribution objective for causal subgraph discovery and prediction. Extensive experiments on two widely used benchmarks demonstrate that our method consistently outperforms state-of-the-art methods in graph generalization. Code is available at https://github.com/anders1123/IDG.'}",https://openreview.net{'value': '/pdf/f3fc5d2d7904bac7b0aaa0d7cafec8b18b7e0297.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=IhOgbtClHL,"{'value': 'Anytime-valid, Bayes-assisted, Prediction-Powered Inference'}",Valentin Kilian; Stefano Cortinovis; Francois Caron,~Valentin_Kilian1; ~Stefano_Cortinovis1; ~Francois_Caron1,"{'value': ['Confidence sequences', ""Ville's inequality"", 'method of mixtures', 'mean estimation', 'statistical inference', 'semi-supervised inference.']}","{'value': ""Given a large pool of unlabelled data and a smaller amount of labels, prediction-powered inference (PPI) leverages machine learning predictions to increase the statistical efficiency of confidence interval procedures based solely on labelled data, while preserving fixed-time validity. In this paper, we extend the PPI framework to the sequential setting, where labelled and unlabelled datasets grow over time. Exploiting Ville's inequality and the method of mixtures, we propose prediction-powered confidence sequence procedures that are asymptotically valid uniformly over time and naturally accommodate prior knowledge on the quality of the predictions to further boost efficiency. We carefully illustrate the design choices behind our method and demonstrate its effectiveness in real and synthetic examples.""}",https://openreview.net{'value': '/pdf/e28b85b95922260957edcf5fa9611329ebaff4a5.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=IfD2MKTmWv,{'value': 'Memory Mosaics at scale'},Jianyu Zhang; Leon Bottou,~Jianyu_Zhang2; ~Leon_Bottou1,"{'value': ['In-context learning', 'memory mosaics']}","{'value': 'Memory Mosaics, networks of associative memories, have demonstrated appealing compositional and in-context learning capabilities on medium-scale networks (GPT-2 scale) and synthetic small datasets. This work shows that these favorable properties remain when we scale memory mosaics to large language model sizes (llama-8B scale) and real-world datasets. \n\nTo this end, we scale memory mosaics to 10B size, we train them on one trillion tokens, we introduce a couple architectural modifications (*memory mosaics v2*), we assess their capabilities across three evaluation dimensions: training-knowledge storage, new-knowledge storage, and in-context learning. \n\nThroughout the evaluation, memory mosaics v2 match transformers on the learning of training knowledge (first dimension) and significantly outperforms transformers on carrying out new tasks at inference time (second and third dimensions). These improvements cannot be easily replicated by simply increasing the training data for transformers. A memory mosaics v2 trained on one trillion tokens still perform better on these tasks than a transformer trained on eight trillion tokens.'}",https://openreview.net{'value': '/pdf/3c9cfbf81dbf50f6ca6d10c5c953d2370922037d.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=IeM6Io4Rsh,{'value': 'Global Minimizers of Sigmoid Contrastive Loss'},Kiril Bangachev; Guy Bresler; Iliyas Noman; Yury Polyanskiy,~Kiril_Bangachev1; ~Guy_Bresler1; ~Iliyas_Noman1; ~Yury_Polyanskiy1,"{'value': ['Representation Learning', 'Contrastive Learning', 'Multimodal Encoders', 'Sigmoid Loss', 'Modality Gap']}","{'value': 'The meta-task of obtaining and aligning representations through contrastive pretraining is steadily gaining importance since its introduction in CLIP and ALIGN. In this paper we theoretically explain the advantages of synchronizing with trainable inverse temperature and bias under the sigmoid loss, as implemented in the recent SigLIP and SigLIP2 models of Google DeepMind. Temperature and bias can drive the loss function to zero for a rich class of configurations that we call $(\\mathsf{m}, \\mathsf{br})$ -Constellations. \n$(\\mathsf{m}, \\mathsf{br})$ -Constellations are a novel combinatorial object related to spherical codes and are parametrized \nby a margin $\\mathsf{m}$ \nand relative bias $\\mathsf{br}$. \nWe use our characterization of constellations to theoretically justify the success of SigLIP on retrieval, to explain the modality gap present in SigLIP, and to identify the necessary dimension for producing high-quality representations. Finally, we propose a reparameterization of the sigmoid loss with explicit relative bias, which improves training dynamics in experiments with synthetic data.'}",https://openreview.net{'value': '/pdf/1fffd930490a3c7fff9bc39aa2c4d83c0e4370ce.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=IbzDaIDyt6,{'value': 'SE-GUI: Enhancing Visual Grounding for GUI Agents via Self-Evolutionary Reinforcement Learning'},Xinbin Yuan; Jian Zhang; Kaixin Li; Zhuoxuan Cai; Lujian Yao; Jie Chen; Enguang Wang; Qibin Hou; Jinwei Chen; Peng-Tao Jiang; Bo Li,~Xinbin_Yuan1; ~Jian_Zhang20; ~Kaixin_Li1; ~Zhuoxuan_Cai1; ~Lujian_Yao1; ~Jie_Chen44; ~Enguang_Wang1; ~Qibin_Hou1; ~Jinwei_Chen3; ~Peng-Tao_Jiang1; ~Bo_Li20,{'value': ['gui agent; reinforcement learning; visual grounding']},"{'value': 'Graphical User Interface (GUI) agents have made substantial strides in understanding and executing user instructions across diverse platforms. Yet, grounding these instructions to precise interface elements remains challenging—especially in complex, high-resolution, professional environments. Traditional supervised fine-tuning (SFT) methods often require large volumes of diverse data and exhibit weak generalization. To overcome these limitations, we introduce a reinforcement learning (RL)-based framework that incorporates three core strategies: (1) seed data curation to ensure high-quality training samples, (2) a dense policy gradient that provides continuous feedback based on prediction accuracy, and (3) a self-evolutionary reinforcement finetuning mechanism that iteratively refines the model using attention maps. With only 3k training samples, our 7B-parameter model achieves state-of-the-art results among similarly sized models on three grounding benchmarks. Notably, it attains 47.3\\% accuracy on the ScreenSpot-Pro dataset—outperforming much larger models, such as UI-TARS-72B, by a margin of 24.2\\%. These findings underscore the effectiveness of RL-based approaches in enhancing GUI agent performance, particularly in high-resolution, complex environments.'}",https://openreview.net{'value': '/pdf/13bc5a7cb4ce114ec3e9a478b5ce44334b495888.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=Ia1nRDN00L,{'value': 'Estimation of Treatment Effects in Extreme and Unobserved Data'},Jiyuan Tan; Vasilis Syrgkanis; Jose Blanchet,~Jiyuan_Tan1; ~Vasilis_Syrgkanis1; ~Jose_Blanchet1,"{'value': ['Causal Inference', 'Extreme Value Theory', 'Treatment Effect']}","{'value': 'Causal effect estimation seeks to determine the impact of an intervention from observational data. However, the existing causal inference literature primarily addresses treatment effects on frequently occurring events. But what if we are interested in estimating the effects of a policy intervention whose benefits, while potentially important, can only be observed and measured in rare yet impactful events, such as extreme climate events? The standard causal inference methodology is not designed for this type of inference since the events of interest may be scarce in the observed data and some degree of extrapolation is necessary. Extreme Value Theory (EVT) provides methodologies for analyzing statistical phenomena in such extreme regimes. We introduce a novel framework for assessing treatment effects in extreme data to capture the causal effect at the occurrence of rare events of interest. In particular, we employ the theory of multivariate regular variation to model extremities. We develop a consistent estimator for extreme treatment effects and present a rigorous non-asymptotic analysis of its performance. We illustrate the performance of our estimator using both synthetic and semi-synthetic data.'}",https://openreview.net{'value': '/pdf/132d76e5982670e7308503a61d6de8453b99b39d.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=IRtGJNgVYk,{'value': 'It’s Hard to Be Normal: The Impact of Noise on Structure-agnostic Estimation'},Jikai Jin; Lester Mackey; Vasilis Syrgkanis,~Jikai_Jin1; ~Lester_Mackey1; ~Vasilis_Syrgkanis1,"{'value': ['structure-agnostic causal inference', 'minimax', 'causal machine learning', 'semiparametric inference', 'Neyman orthogonality', 'double machine learning', 'higher-order robustness']}","{'value': 'Structure-agnostic causal inference studies how well one can estimate a treatment effect given black-box machine learning estimates of nuisance functions (like the impact of confounders on treatment and outcomes). Here, we find that the answer depends in a surprising way on the distribution of the treatment noise. Focusing on the partially linear model of Robinson (1988), we first show that the widely adopted double machine learning (DML) estimator is minimax rate-optimal for Gaussian treatment noise, resolving an open problem of Mackey et al. (2018). Meanwhile, for independent non-Gaussian treatment noise, we show that DML is always suboptimal by constructing new practical procedures with higher-order robustness to nuisance errors. These ACE procedures use structure-agnostic cumulant estimators to achieve r-th order insensitivity to nuisance errors whenever the (r+1)-st treatment cumulant is non-zero. We complement these core results with novel minimax guarantees for binary treatments in the partially linear model. Finally, using synthetic demand estimation experiments, we demonstrate the practical benefits of our higher-order robust estimators.'}",https://openreview.net{'value': '/pdf/1267e77f7a5d0a80da2e9f621eb0ddc20d03e9d8.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=IPxOoU8aqt,{'value': 'Doctor Approved: Generating Medically Accurate Skin Disease Images through AI-Expert Feedback'},Janet Wang; Yunbei Zhang; Zhengming Ding; Jihun Hamm,~Janet_Wang1; ~Yunbei_Zhang1; ~Zhengming_Ding5; ~Jihun_Hamm2,"{'value': ['Synthetic Clinical Data', 'Machine Learning for Healthcare', 'Skin Imaging Analysis']}","{'value': 'Paucity of medical data severely limits the generalizability of diagnostic ML models, as the full spectrum of disease variability can not be represented by a small clinical dataset. To address this, diffusion models (DMs) have been considered as a promising avenue for synthetic image generation and augmentation. However, they frequently produce _medically inaccurate_ images, deteriorating the model performance. Expert domain knowledge is critical for synthesizing images that correctly encode clinical information, especially when data is scarce and quality outweighs quantity. Existing approaches for incorporating human feedback, such as reinforcement learning (RL) and Direct Preference Optimization (DPO), rely on robust reward functions or demand labor-intensive expert evaluations. Recent progress in Multimodal Large Language Models (MLLMs) reveals their strong visual reasoning capabilities, making them adept candidates as evaluators. In this work, we propose a novel framework, coined MAGIC (**M**edically **A**ccurate **G**eneration of **I**mages through AI-Expert **C**ollaboration), that synthesizes clinically accurate skin disease images for data augmentation. Our method creatively translates expert-defined criteria into actionable feedback for image synthesis of DMs, significantly improving clinical accuracy while reducing the direct human workload. Experiments demonstrate that our method greatly improves the clinical quality of synthesized skin disease images, with outputs aligning with dermatologist assessments. Additionally, augmenting training data with these synthesized images improves diagnostic accuracy by +9.02% on a challenging 20-condition skin disease classification task, and by +13.89% in the few-shot setting. Beyond image synthesis, MAGIC illustrates a task-centric alignment paradigm: instead of adapting MLLMs to niche medical tasks, it adapts tasks to the evaluative strengths of general-purpose MLLMs by decomposing domain knowledge into attribute-level checklists. This design offers a scalable and reliable path for leveraging foundation models in specialized domains.'}",https://openreview.net{'value': '/pdf/bfda7ce299c470610390637d9e3b7107ccb0e9ba.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=INqBOmwIpG,{'value': 'Perception Encoder: The best visual embeddings are not at the output of the network'},Daniel Bolya; Po-Yao Huang; Peize Sun; Jang Hyun Cho; Andrea Madotto; Chen Wei; Tengyu Ma; Jiale Zhi; Jathushan Rajasegaran; Hanoona Abdul Rasheed; Junke Wang; Marco Monteiro; Hu Xu; Shiyu Dong; Nikhila Ravi; Shang-Wen Li; Piotr Dollar; Christoph Feichtenhofer,~Daniel_Bolya1; ~Po-Yao_Huang2; ~Peize_Sun1; ~Jang_Hyun_Cho1; ~Andrea_Madotto1; ~Chen_Wei2; ~Tengyu_Ma3; ~Jiale_Zhi1; ~Jathushan_Rajasegaran2; ~Hanoona_Abdul_Rasheed1; ~Junke_Wang1; ~Marco_Monteiro2; ~Hu_Xu1; ~Shiyu_Dong1; ~Nikhila_Ravi1; ~Shang-Wen_Li1; ~Piotr_Dollar1; ~Christoph_Feichtenhofer4,"{'value': ['vision encoder', 'vision-language', 'CLIP', 'pretraining', 'features', 'foundation model']}","{'value': 'We introduce Perception Encoder (PE), a family of state-of-the-art vision encoders for image and video understanding. Traditionally, vision encoders have relied on a variety of pretraining objectives, each excelling at different downstream tasks. Surprisingly, after scaling a carefully tuned image pretraining recipe and refining with a robust video data engine, we find that contrastive vision-language training alone can produce strong, general embeddings for all of these downstream tasks. There is only one caveat: these embeddings are hidden within the intermediate layers of the network. To draw them out, we introduce two alignment methods: language alignment for multimodal language modeling, and spatial alignment for dense prediction. Together, our PE family of models achieves state-of-the-art results on a wide variety of tasks, including zero-shot image and video classification and retrieval; document, image, and video Q&A; and spatial tasks such as detection, tracking, and depth estimation. We release our models, code, and novel dataset of synthetically and human-annotated videos: https://github.com/facebookresearch/perception_models'}",https://openreview.net{'value': '/pdf/13c5dcc0a71a6363ecf0568e449798970fe54388.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=IMmYPJSTPe,{'value': 'Towards Effective Federated Graph Foundation Model via Mitigating Knowledge Entanglement'},Yinlin Zhu; Xunkai Li; Jishuo Jia; Miao Hu; Di Wu; Meikang Qiu,~Yinlin_Zhu2; ~Xunkai_Li1; ~Jishuo_Jia1; ~Miao_Hu2; ~Di_Wu21; ~Meikang_Qiu2,"{'value': ['Graph Machine Learning', 'Federated Graph Learning', 'Graph Foundation Model']}","{'value': 'Recent advances in graph machine learning have shifted to data-centric paradigms, driven by two emerging research fields: \n    (1) Federated graph learning (FGL) facilitates multi-client collaboration but struggles with data and task heterogeneity, resulting in limited practicality;\n    (2) Graph foundation model (GFM) enables desirable domain generalization but is typically confined to single-machine training, neglecting the potential of cross-silo data and computational resources.\n    It is evident that these two paradigms are complementary, and their integration offers substantial advantages.\n    Motivated by this, we present a pioneering study about the federated graph foundation model (FedGFM), a novel decentralized GFM training paradigm. Despite the promising vision of FedGFM, knowledge entanglement has emerged as a critical challenge, where multi-domain knowledge is encoded into indistinguishable representations, thereby limiting downstream adaptation.\n\nTo this end, we propose FedGFM+, an effective FedGFM framework with two key modules to mitigate knowledge entanglement in a dual-pronged manner. \n(1) AncDAI: From a global perspective, we introduce a novel anchor-based domain-aware initialization strategy. Before pre-training, each client encodes its local graph into a domain-specific prototypes, which serve as semantic anchors in the representation space. Around each anchor, we construct synthetic embeddings to initialize the global model. We theoretically show that these prototypes are distinguishable across domains, and the initialization provides a strong inductive bias that facilitates disentanglement of domain-specific knowledge. \n(2) AdaDPP: From a local perspective, during pre-training, each client independently learns a lightweight graph prompt that captures domain semantic preferences. During fine-tuning, prompts from all clients are aggregated into an adaptive domain-sensitive prompt pool, from which the GFM selects relevant prompts to augment the target graph’s attributes, thereby improving the downstream adaptation. FedGFM+ is extensively evaluated on 8 diverse benchmarks spanning multiple domains and tasks, outperforming 20 baselines from isolated supervised learning, FGL, and federated variants of centralized GFM paradigms.'}",https://openreview.net{'value': '/pdf/3ab907a7b9d43e7cdf72710aa066c47129984186.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=IL1wvzOgqD,{'value': 'Towards A Translative Model of Sperm Whale Vocalization'},Orr Paradise; Liangyuan Chen; Pranav Muralikrishnan; Hugo Flores García; Bryan Pardo; Roee Diamant; David Gruber; Shane Gero; Shafi Goldwasser,~Orr_Paradise1; ~Liangyuan_Chen1; ~Pranav_Muralikrishnan1; ~Hugo_Flores_García1; ~Bryan_Pardo1; ~Roee_Diamant1; ~David_Gruber1; ~Shane_Gero1; ~Shafi_Goldwasser2,"{'value': ['Sperm Whale Communication', 'Bioacoustics', 'Masked Acoustic Token Modeling', 'Generative Audio Models', 'Representation Learning']}","{'value': ""Sperm whales communicate in short sequences of clicks known as codas. We present WhAM (Whale Acoustics Model), the first transformer-based model capable of generating synthetic sperm whale codas from any audio prompt. WhAM is built by finetuning VampNet, a masked acoustic token model pretrained on musical audio, using 10k coda recordings collected over the past two decades. Through iterative masked token prediction, WhAM generates high-fidelity synthetic codas that preserve key acoustic features of the source recordings. We evaluate WhAM's synthetic codas using Fréchet Audio Distance and through perceptual studies with expert marine biologists. On downstream tasks including rhythm, social unit, and vowel classification, WhAM's learned representations achieve strong performance, despite being trained for generation rather than classification. Our code is available at https://github.com/Project-CETI/wham""}",https://openreview.net{'value': '/pdf/900f003de489c017b71be92aecd5d797a78b6879.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=IKxKs3rF9V,{'value': '4KAgent: Agentic Any Image to 4K Super-Resolution'},Yushen Zuo; Qi Zheng; Mingyang Wu; Xinrui Jiang; Renjie Li; Jian Wang; Yide Zhang; Gengchen Mai; Lihong Wang; James Zou; Xiaoyu Wang; Ming-Hsuan Yang; Zhengzhong Tu,~Yushen_Zuo1; ~Qi_Zheng4; ~Mingyang_Wu1; ~Xinrui_Jiang4; ~Renjie_Li3; ~Jian_Wang10; ~Yide_Zhang1; ~Gengchen_Mai1; ~Lihong_Wang1; ~James_Zou1; ~Xiaoyu_Wang1; ~Ming-Hsuan_Yang1; ~Zhengzhong_Tu1,"{'value': ['Super-Resolution', 'Agent', 'Image Restoration', 'Low-level Vision']}","{'value': 'We present 4KAgent, a unified agentic super-resolution generalist system designed to universally upscale any image to 4K resolution (and even higher, if applied iteratively). Our system can transform images from extremely low resolutions with severe degradations, for example, highly distorted inputs at $256\\times 256$, into crystal-clear, photorealistic 4K outputs. 4KAgent comprises three core components: (1) Profiling, a module that customizes the 4KAgent pipeline based on bespoke use cases; (2) A Perception Agent, which leverages vision-language models alongside image quality assessment experts to analyze the input image and make a tailored restoration plan; and (3) A Restoration Agent, which executes the plan, following a recursive execution-reflection paradigm, guided by a quality-driven mixture-of-expert policy to select the optimal output for each step. Additionally, 4KAgent embeds a specialized face restoration pipeline, significantly enhancing facial details in portrait and selfie photos. We rigorously evaluate our 4KAgent across 11 distinct task categories encompassing a total of 26 diverse benchmarks, setting new state-of-the-art on a broad spectrum of imaging domains. Our evaluations cover natural images, portrait photos, AI-generated content, satellite imagery, fluorescence microscopy, and medical imaging like fundoscopy, ultrasound, and X-ray, demonstrating superior performance in terms of both perceptual (e.g., NIQE, MUSIQ) and fidelity (e.g., PSNR) metrics. By establishing a novel agentic paradigm for low-level vision tasks, we aim to catalyze broader interest and innovation within vision-centric autonomous agents across diverse research communities. We release all the code, models, and results at: https://4kagent.github.io.'}",https://openreview.net{'value': '/pdf/4cc594bf68d881fc9b2f742ba7629caba40b334f.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=IKVkpjSJzJ,{'value': 'EnCompass: Enhancing Agent Programming with Search Over Program Execution Paths'},Zhening Li; Armando Solar-Lezama; Yisong Yue; Stephan Zheng,~Zhening_Li1; ~Armando_Solar-Lezama1; ~Yisong_Yue1; ~Stephan_Zheng1,"{'value': ['AI agents', 'large language models', 'agent frameworks', 'angelic nondeterminism', 'inference-time strategies', 'test-time scaling']}","{'value': 'We introduce a new approach to *agent programming*, the development of LLM-based agents. Current approaches to agent programming often entangle two aspects of agent design: the core workflow logic and the inference-time strategy (e.g., tree search). We introduce *probabilistic angelic nondeterminism* (PAN), a programming model that disentangles these two concerns, allowing the programmer to describe the agent workflow and independently experiment with different inference-time strategies by simply changing a few inputs. We provide an implementation of PAN in Python as the EnCompass framework, which uses a Python decorator to compile agent workflow programs into a search space. We present three case studies that demonstrate how the framework lets the programmer quickly improve the reliability of an agent and easily switch between different inference-time strategies, all with little additional coding.'}",https://openreview.net{'value': '/pdf/fb71325ef32d558296d705abff2ddb01997fd4d1.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=IJmTOL4Raz,{'value': 'Stochastic Gradients under Nuisances'},Facheng Yu; Ronak Mehta; Alex Luedtke; Zaid Harchaoui,~Facheng_Yu2; ~Ronak_Mehta2; ~Alex_Luedtke1; ~Zaid_Harchaoui1,"{'value': ['Stochastic gradient', 'orthogonal statistical learning', 'nonparametric statistics']}","{'value': 'Stochastic gradient optimization is the dominant learning paradigm for a variety of scenarios, from classical supervised learning to modern self-supervised learning. We consider stochastic gradient algorithms for learning problems whose objectives rely on unknown nuisance parameters, and establish non-asymptotic convergence guarantees. Our results show that, while the presence of a nuisance can alter the optimum and upset the optimization trajectory, the classical stochastic gradient algorithm may still converge under appropriate conditions, such as Neyman orthogonality. Moreover, even when Neyman orthogonality is not satisfied, we also show that an algorithm variant with approximately orthogonalized updates (with an approximately orthogonalized gradient oracle) may achieve similar convergence rates. Examples from orthogonal statistical learning/double machine learning and causal inference are discussed.'}",https://openreview.net{'value': '/pdf/e79fa36e5ce4b35fe43205efd4d0a24002e43a4d.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=IGJHOcoQKp,{'value': 'UniTraj: Learning a Universal Trajectory Foundation Model from Billion-Scale Worldwide Traces'},Yuanshao Zhu; James Jianqiao Yu; Xiangyu Zhao; Xun Zhou; Liang Han; Xuetao Wei; Yuxuan Liang,~Yuanshao_Zhu1; ~James_Jianqiao_Yu1; ~Xiangyu_Zhao1; ~Xun_Zhou1; ~Liang_Han4; ~Xuetao_Wei2; ~Yuxuan_Liang1,"{'value': ['Spatio-Temporal Data Mining', 'Foundation Model', 'Urban Computing']}","{'value': 'Building a universal trajectory foundation model is a promising solution to address the limitations of existing trajectory modeling approaches, such as task specificity, regional dependency, and data sensitivity.\nDespite its potential, data preparation, pre-training strategy development, and architectural design present significant challenges in constructing this model.\nTherefore, we introduce **UniTraj**, a Universal Trajectory foundation model that aims to address these limitations through three key innovations.\nFirst, we construct **WorldTrace**, an unprecedented dataset of 2.45 million trajectories with billions of GPS points spanning 70 countries, providing the diverse geographic coverage essential for region-independent modeling. \nSecond, we develop novel pre-training strategies--Adaptive Trajectory Resampling and Self-supervised Trajectory Masking--that enable robust learning from heterogeneous trajectory data with varying sampling rates and quality. \nFinally, we tailor a flexible model architecture to accommodate a variety of trajectory tasks, effectively capturing complex movement patterns to support broad applicability.\nExtensive experiments across multiple tasks and real-world datasets demonstrate that UniTraj consistently outperforms existing methods, exhibiting superior scalability, adaptability, and generalization, with WorldTrace serving as an ideal yet non-exclusive training resource. \nThe implementation codes and full dataset are available at https://github.com/Yasoz/UniTraj.'}",https://openreview.net{'value': '/pdf/a1a6a045a43be34e5e45854f86a202ecc87cfc17.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=IByOCSsDU5,{'value': 'Bridging the gap to real-world language-grounded visual concept learning'},Whie Jung; Semin Kim; Junee Kim; Seunghoon Hong,~Whie_Jung1; ~Semin_Kim1; ~Junee_Kim1; ~Seunghoon_Hong2,"{'value': ['visual concept learning', 'vision-language model', 'image generation']}","{'value': 'Human intelligence effortlessly interprets visual scenes along a rich spectrum of semantic dimensions. \nHowever, existing approaches to language-grounded visual concept learning are limited to a few predefined primitive axes, such as color and shape, and are typically explored in synthetic datasets.\nIn this work, we propose a scalable framework that adaptively identifies image-related concept axes and grounds visual concepts along these axes in real-world scenes. \nLeveraging a pretrained vision-language model and our universal prompting strategy, our framework identifies a diverse image-related axes without any prior knowledge.\nOur universal concept encoder adaptively binds visual features to the discovered axes without introducing additional model parameters for each concept.\nTo ground visual concepts along the discovered axes, we optimize a compositional anchoring objective, which ensures that each axis can be independently manipulated without affecting others.\nWe demonstrate the effectiveness of our framework on subsets of ImageNet, CelebA-HQ, and AFHQ, showcasing superior editing capabilities across diverse real-world concepts that are too varied to be manually predefined. \nOur method also exhibits strong compositional generalization, outperforming existing visual concept learning and text-based editing methods. The code is available at https://github.com/whieya/Language-grounded-VCL.'}",https://openreview.net{'value': '/pdf/0bcb1846aed7fb3d788d751b0129765e4861a9ab.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=I1C0a01BZu,{'value': 'Tree-Guided Diffusion Planner'},Hyeonseong Jeon; Cheolhong Min; Jaesik Park,~Hyeonseong_Jeon2; ~Cheolhong_Min1; ~Jaesik_Park3,"{'value': ['diffusion-based planning', 'zero-shot planning', 'training-free guidance', 'decision making']}","{'value': 'Planning with pretrained diffusion models has emerged as a promising approach for solving test-time guided control problems. Standard gradient guidance typically performs optimally under convex, differentiable reward landscapes. However, it shows substantially reduced effectiveness in real-world scenarios with non-convex objectives, non-differentiable constraints, and multi-reward structures. Furthermore, recent supervised planning approaches require task-specific training or value estimators, which limits test-time flexibility and zero-shot generalization. We propose a Tree-guided Diffusion Planner (TDP), a zero-shot test-time planning framework that balances exploration and exploitation through structured trajectory generation. We frame test-time planning as a tree search problem using a bi-level sampling process: (1) diverse parent trajectories are produced via training-free particle guidance to encourage broad exploration, and (2) sub-trajectories are refined through fast conditional denoising guided by task objectives. TDP addresses the limitations of gradient guidance by exploring diverse trajectory regions and harnessing gradient information across this expanded solution space using only pretrained models and test-time reward signals. We evaluate TDP on three diverse tasks: maze gold-picking, robot arm block manipulation, and AntMaze multi-goal exploration. TDP consistently outperforms state-of-the-art approaches on all tasks. The project page can be found at: https://tree-diffusion-planner.github.io'}",https://openreview.net{'value': '/pdf/92c4a7eb993d51f256c62cf56923652c44ad10d3.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=Hxfjmc95rl,{'value': 'SONAR: Long-Range Graph Propagation Through Information Waves'},Alessandro Trenta; Alessio Gravina; Davide Bacciu,~Alessandro_Trenta2; ~Alessio_Gravina1; ~Davide_Bacciu1,"{'value': ['graph neural networks', 'long-range propagation']}","{'value': ""Capturing effective long-range information propagation remains a fundamental yet challenging problem in graph representation learning. Motivated by this, we introduce SONAR, a novel GNN architecture inspired by the dynamics of wave propagation in continuous media. SONAR models information flow on graphs as oscillations governed by the wave equation, allowing it to maintain effective propagation dynamics over long distances. By integrating adaptive edge resistances and state-dependent external forces, our method balances conservative and non-conservative behaviors, improving the ability to learn more complex dynamics. We provide a rigorous theoretical analysis of SONAR's energy conservation and information propagation properties, demonstrating its capacity to address the long-range propagation problem. Extensive experiments on synthetic and real-world benchmarks confirm that SONAR achieves state-of-the-art performance, particularly on tasks requiring long-range information exchange.""}",https://openreview.net{'value': '/pdf/a118821c47cb7cd91de3e44be2be5bbc2fd0ece8.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=HqsE29wxnS,{'value': 'FairDD: Fair Dataset Distillation'},Qihang Zhou; ShenHao Fang; Shibo He; Wenchao Meng; Jiming Chen,~Qihang_Zhou1; ~ShenHao_Fang1; ~Shibo_He1; ~Wenchao_Meng1; ~Jiming_Chen1,"{'value': ['Dataset Distillation', 'Dataset Condensation']}","{'value': 'Condensing large datasets into smaller synthetic counterparts has demonstrated its promise for image classification. However, previous research has overlooked a crucial concern in image recognition: ensuring that models trained on condensed datasets are unbiased towards protected attributes (PA), such as gender and race. Our investigation reveals that dataset distillation fails to alleviate the unfairness towards minority groups within original datasets. Moreover, this bias typically worsens in the condensed datasets due to their smaller size. To bridge the research gap, we propose a novel fair dataset distillation (FDD) framework, namely FairDD, which can be seamlessly applied to diverse matching-based DD approaches (DDs), requiring no modifications to their original architectures. The key innovation of FairDD lies in synchronously matching synthetic datasets to PA-wise groups of original datasets, rather than indiscriminate alignment to the whole distributions in vanilla DDs, dominated by majority groups. This synchronized matching allows synthetic datasets to avoid collapsing into majority groups and bootstrap their balanced generation to all PA groups. Consequently, FairDD could effectively regularize vanilla DDs to favor biased generation toward minority groups while maintaining the accuracy of target attributes. Theoretical analyses and extensive experimental evaluations demonstrate that FairDD significantly improves fairness compared to vanilla DDs, with a promising trade-off between fairness and accuracy. Its consistent superiority across diverse DDs, spanning Distribution and Gradient Matching, establishes it as a versatile FDD approach.'}",https://openreview.net{'value': '/pdf/ac66678fd9fbd2580655d5ec445d6700e903a617.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=HnJ1UkuJXS,{'value': 'Shapley-Coop: Credit Assignment for Emergent Cooperation in Self-Interested LLM Agents'},Yun Hua; Haosheng Chen; Shiqin Wang; Wenhao Li; Xiangfeng Wang; Jun Luo,~Yun_Hua1; ~Haosheng_Chen2; ~Shiqin_Wang3; ~Wenhao_Li2; ~Xiangfeng_Wang1; ~Jun_Luo20,"{'value': ['Large Language Model', 'Multi-Agent Systems', 'Mechanism Design']}","{'value': 'Large Language Models (LLMs) are increasingly deployed as autonomous agents in multi-agent systems, and promising coordination has been demonstrated in handling complex tasks under predefined roles and scripted workflows.\nHowever, significant challenges remain in open-ended environments, where agents are inherently self-interested and explicit coordination guidelines are absent. \nIn such scenarios, misaligned incentives frequently lead to social dilemmas and inefficient collective outcomes.\nInspired by how human societies tackle similar coordination challenges—through temporary collaborations like employment or subcontracting—a cooperative workflow \\textbf{Shapley-Coop} is proposed. \nThis workflow enables self-interested Large Language Model (LLM) agents to engage in emergent collaboration by using a fair credit allocation mechanism to ensure each agent’s contributions are appropriately recognized and rewarded.\nShapley-Coop introduces structured negotiation protocols and Shapley-inspired reasoning to estimate agents’ marginal contributions, thereby enabling effective task-time coordination and equitable post-task outcome redistribution. \nThis results in effective coordination that fosters collaboration while preserving agent autonomy, through a rational pricing mechanism that encourages cooperative behavior.\nEvaluated in two multi-agent games and a software engineering simulation, Shapley-Coop consistently enhances LLM agent collaboration and facilitates equitable outcome redistribution, accurately reflecting individual contributions during the task execution process.'}",https://openreview.net{'value': '/pdf/83eb93701943b70c240a3aadf6d0acb92a2b30f8.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=Hmd8CqMo3E,{'value': 'Semantic-guided Diverse Decoding for Large Language Model'},Weijie Shi; Yue Cui; Yaguang Wu; Jingzhi Fang; Shibo Zhang; Mengze Li; Sirui Han; Jia Zhu; Jiajie Xu; Xiaofang Zhou,~Weijie_Shi1; ~Yue_Cui2; ~Yaguang_Wu1; ~Jingzhi_Fang1; ~Shibo_Zhang5; ~Mengze_Li2; ~Sirui_Han1; ~Jia_Zhu2; ~Jiajie_Xu2; ~Xiaofang_Zhou3,"{'value': ['Diverse Decoding', 'Sampling Strategy', 'Large Language Model']}","{'value': 'Diverse decoding of large language models is crucial for applications requiring multiple semantically distinct responses, yet existing methods primarily achieve lexical rather than semantic diversity. This limitation significantly constrains Best-of-N strategies, group-based reinforcement learning, and data synthesis. While temperature sampling and diverse beam search modify token distributions or apply n-gram penalties, they fail to ensure meaningful semantic differentiation. We introduce Semantic-guided Diverse Decoding (SemDiD), operating directly in embedding space that balances quality with diversity through three complementary mechanisms: orthogonal directional guidance, dynamic inter-group repulsion, and position-debiased probability assessment. SemDiD harmonizes these competing objectives using adaptive gain functions and constraint optimization, ensuring both quality thresholds and maximal semantic differentiation. Experiments show SemDiD consistently outperforms existing methods, improving Best-of-N coverage by 1.4-5.2% across diverse tasks and accelerating RLHF training convergence by 15% while increasing accuracy by up to 2.1%.'}",https://openreview.net{'value': '/pdf/9a6bb6930d9a85846b541f44d9e74055dd67c548.pdf'},{'abstract_filter': 'Data Synthesis'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=HkumwkgqJo,{'value': 'SPMDM: Enhancing Masked Diffusion Models through Simplifing Sampling Path'},Yichen Zhu; Weiyu Chen; James Kwok; Zhou Zhao,~Yichen_Zhu2; ~Weiyu_Chen1; ~James_Kwok1; ~Zhou_Zhao3,"{'value': ['discrete diffusion', 'generative modeling']}","{'value': 'Autoregressive models (ARMs) show strong capabilities in many domains but face challenges with planning and complex reasoning due to their sequential generation. Masked diffusion models (MDMs) address these issues by enabling controllable, any-order, and parallel generation but encounter training difficulties as token prediction complexity varies with unmasked token positions. This work identifies two key characteristics of efficient MDM sampling paths: prioritizing tokens near unmasked ones and generating subsequence earlier in reasoning. We propose the Simple Path Masked Diffusion Model (SPMDM), which partitions sequences into fixed-length, non-overlapping subsequences and applies varying noise scales to learn token-level and cross-subsequence dependencies. Experiments on synthetic data and tasks like Countdown and Sudoku show SPMDM captures structural rules effectively, significantly outperforming existing MDMs and ARMs, with competitive results on broader reasoning benchmarks.'}",https://openreview.net{'value': '/pdf/1fa4919650958fa92c84e904610332a2b4e617df.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=Hk4cCTukeI,{'value': 'Triplets Better Than Pairs: Towards Stable and Effective Self-Play Fine-Tuning for LLMs'},Yibo Wang; Hai-Long Sun; Guangda Huzhang; Qing-Guo Chen; Zhao Xu; Weihua Luo; Kaifu Zhang; Lijun Zhang,~Yibo_Wang2; ~Hai-Long_Sun1; ~Guangda_Huzhang2; ~Qing-Guo_Chen1; ~Zhao_Xu7; ~Weihua_Luo2; ~Kaifu_Zhang2; ~Lijun_Zhang1,"{'value': ['Large Language Model', 'Self-play Optimization', 'Natural Language Processing']}","{'value': 'Recently, self-play fine-tuning (SPIN) has been proposed to adapt large language models to downstream applications with scarce expert-annotated data, by iteratively generating synthetic responses from the model itself. However, SPIN is designed to optimize the current reward advantages of annotated responses over synthetic responses at hand, which may gradually vanish during iterations, leading to \\textit{unstable optimization}. Moreover, the utilization of reference policy induces a \\textit{misalignment} issue between the reward formulation for training and the metric for generation. To address these limitations, we propose a novel \\textbf{T}riplet-based \\textbf{S}elf-\\textbf{P}lay f\\textbf{I}ne-tu\\textbf{N}ing (TSPIN) method that integrates two key designs. First, beyond current advantages, TSPIN additionally incorporates historical advantages between iteratively generated responses and proto-synthetic responses produced by the initial policy. Even if the current advantages diminish, historical advantages remain effective, stabilizing the overall optimization. Second, TSPIN introduces the entropy constraint into the self-play framework, which is theoretically justified to support reference-free fine-tuning, eliminating the training-generation discrepancy. Empirical results on various tasks demonstrate not only the superior performance of TSPIN over SPIN, but also its stable evolution during iterations. Remarkably, compared to supervised fine-tuning, TSPIN achieves comparable or even better performance with only $25\\\\%$ samples, highlighting its effectiveness when faced with scarce annotated data.'}",https://openreview.net{'value': '/pdf/e0596e6e39072aed73b22d2c2c86772c2aae52a0.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=HgLaVgCpCl,{'value': 'Conformal Prediction for Time-series Forecasting with Change Points'},Sophia Huiwen Sun; Rose Yu,~Sophia_Huiwen_Sun1; ~Rose_Yu1,"{'value': ['conformal prediction', 'time series', 'uncertainty quantification']}","{'value': ""Conformal prediction has been explored as a general and efficient way to provide uncertainty quantification for time series. However, current methods struggle to handle time series data with change points — sudden shifts in the underlying data-generating process. In this paper, we propose a novel Conformal Prediction for Time-series with Change points (CPTC) algorithm, addressing this gap by integrating a model to predict the underlying state with online conformal prediction to model uncertainties in non-stationary time series. We prove CPTC's validity and improved adaptivity in the time series setting under minimum assumptions, and demonstrate CPTC's practical effectiveness on 6 synthetic and real-world datasets, showing improved validity and adaptivity compared to state-of-the-art baselines.""}",https://openreview.net{'value': '/pdf/693af6b1ea916c95c110b1383d0c7df5c45182ba.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=HfdzglsZQH,{'value': 'Neurosymbolic Diffusion Models'},Emile van Krieken; Pasquale Minervini; Edoardo Ponti; Antonio Vergari,~Emile_van_Krieken1; ~Pasquale_Minervini4; ~Edoardo_Ponti1; ~Antonio_Vergari3,"{'value': ['neurosymbolic AI', 'discrete diffusion models', 'probabilistic reasoning', 'uncertainty', 'reasoning shortcuts']}","{'value': 'Neurosymbolic (NeSy) predictors combine neural perception with symbolic reasoning to solve tasks like visual reasoning. However, standard NeSy predictors assume conditional independence between the symbols they extract, thus limiting their ability to model interactions and uncertainty --- often leading to overconfident predictions and poor out-of-distribution generalisation. To overcome the limitations of the independence assumption, we introduce _neurosymbolic diffusion models_ (NeSyDMs), a new class of NeSy predictors that use discrete diffusion to model dependencies between symbols. Our approach reuses the independence assumption from NeSy predictors at each step of the diffusion process, enabling scalable learning while capturing symbol dependencies and uncertainty quantification. Across both synthetic and real-world benchmarks — including high-dimensional visual path planning and rule-based autonomous driving — NeSyDMs achieve state-of-the-art accuracy among NeSy predictors and demonstrate strong calibration.'}",https://openreview.net{'value': '/pdf/ca57dca820f3f3e82eef4fda8105645c327a7745.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=HenpVfO3Wp,"{'value': 'Language Model Behavioral Phases are Consistent Across Architecture, Training Data, and Scale'}",James A. Michaelov; Roger P. Levy; Ben Bergen,~James_A._Michaelov1; ~Roger_P._Levy1; ~Ben_Bergen1,"{'value': ['language models', 'training dynamics', 'n-grams', 'semantic similarity', 'heuristics', 'shortcuts']}","{'value': ""We show that across architecture (Transformer vs. Mamba vs. RWKV), training dataset (OpenWebText vs. The Pile), and scale (14 million parameters to 12 billion parameters), autoregressive language models exhibit highly consistent patterns of change in their behavior over the course of pretraining. Based on our analysis of over 1,400 language model checkpoints on over 110,000 tokens of English, we find that up to 98\\% of the variance in language model behavior at the word level can be explained by three simple heuristics: the unigram probability (frequency) of a given word, the $n$-gram probability of the word, and the semantic similarity between the word and its context. Furthermore, we see consistent behavioral phases in all language models, with their predicted probabilities for words overfitting to those words' $n$-gram probabilities for increasing $n$ over the course of training. Taken together, these results suggest that learning in neural language models may follow a similar trajectory irrespective of model details.""}",https://openreview.net{'value': '/pdf/4777d9381878e70e26c398b5799c4be27b50101d.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=HOa6LTIjyn,{'value': 'Prediction-Powered Causal Inferences'},Riccardo Cadei; Ilker Demirel; Piersilvio De Bartolomeis; Lukas Lindorfer; Sylvia Cremer; Cordelia Schmid; Francesco Locatello,~Riccardo_Cadei1; ~Ilker_Demirel1; ~Piersilvio_De_Bartolomeis1; ~Lukas_Lindorfer1; ~Sylvia_Cremer1; ~Cordelia_Schmid1; ~Francesco_Locatello1,"{'value': ['Causal Representation Learning', 'Causal Inference', 'Domain Generalization']}","{'value': 'In many scientific experiments, the data annotating cost constraints the pace for testing novel hypotheses. Yet, modern machine learning pipelines offer a promising solution—provided their predictions yield correct conclusions. We focus on Prediction-Powered Causal Inferences (PPCI), i.e., estimating the treatment effect in an unlabeled target experiment, relying on training data with the same outcome annotated but potentially different treatment or effect modifiers. We first show that conditional calibration guarantees valid PPCI at population level. Then, we introduce a sufficient representation constraint transferring validity across experiments,  which we propose to enforce in practice in Deconfounded Empirical Risk Minimization, our new model-agnostic training objective. We validate our method on synthetic and real-world scientific data, solving impossible problem instances for Empirical Risk Minimization even with standard invariance constraints. In particular, for the first time, we achieve valid causal inference on a scientific experiment with complex recording and no human annotations, fine-tuning a foundational model on our similar annotated experiment.'}",https://openreview.net{'value': '/pdf/9753bc6def7c53f1171a257d5ec4b78ca4d8d993.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=HL1j92hb6z,"{'value': 'First SFT, Second RL, Third UPT: Continual Improving Multi-Modal LLM Reasoning via Unsupervised Post-Training'}",Lai Wei; Yuting Li; Chen Wang; Yue Wang; Linghe Kong; Weiran Huang; Lichao Sun,~Lai_Wei7; ~Yuting_Li1; ~Chen_Wang56; ~Yue_Wang15; ~Linghe_Kong1; ~Weiran_Huang1; ~Lichao_Sun1,"{'value': ['Multi-modal Large Language Models', 'Multi-modal Reasoning', 'Self-Improvement', 'Unsupervised Post-Training']}","{'value': 'Improving Multi-modal Large Language Models (MLLMs) in the post-training stage typically relies on supervised fine-tuning (SFT) or reinforcement learning (RL), which require expensive and manually annotated multi-modal data--an ultimately unsustainable resource.\nThis limitation has motivated a growing interest in unsupervised paradigms as a third stage of post-training after SFT and RL.\nWhile recent efforts have explored this direction, their methods are complex and difficult to iterate.\nTo address this, we propose MM-UPT, a simple yet effective framework for unsupervised post-training of MLLMs, enabling continual self-improvement without any external supervision.\nThe training method of MM-UPT builds upon GRPO, replacing traditional reward signals with a self-rewarding mechanism based on majority voting over multiple sampled responses. \nOur experiments demonstrate that such training method effectively improves the reasoning ability of Qwen2.5-VL-7B (e.g., 66.3\\%$\\rightarrow$72.9\\% on MathVista, 62.9\\%$\\rightarrow$68.7\\% on We-Math), using standard dataset without ground truth labels.\nTo further explore scalability, we extend our framework to a data self-generation setting, designing two strategies that prompt the MLLM to synthesize new training samples on its own.\nAdditional experiments show that combining these synthetic data with the unsupervised training method can also boost performance, highlighting a promising approach for scalable self-improvement.\nOverall, MM-UPT offers a new paradigm for autonomous enhancement of MLLMs, serving as a critical third step after initial SFT and RL in the absence of external supervision.\nOur code is available at \\url{https://github.com/waltonfuture/MM-UPT}.'}",https://openreview.net{'value': '/pdf/b9ebd33d49d84affccdacf9ae1857c27f40e1ade.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=HDeIb67lJe,{'value': 'Informed Correctors for Discrete Diffusion Models'},Yixiu Zhao; Jiaxin Shi; Feng Chen; Shaul Druckmann; Lester Mackey; Scott Linderman,~Yixiu_Zhao2; ~Jiaxin_Shi1; ~Feng_Chen13; ~Shaul_Druckmann1; ~Lester_Mackey1; ~Scott_Linderman1,"{'value': ['Discrete diffusion', 'diffusion models', 'generative models', 'transformers', 'predictor corrector sampling', 'Gibbs sampling']}","{'value': 'Discrete diffusion has emerged as a powerful framework for generative modeling in discrete domains, yet efficiently sampling from these models remains challenging. Existing sampling strategies often struggle to balance computation and sample quality when the number of sampling steps is reduced, even when the model has learned the data distribution well. To address these limitations, we propose a predictor-corrector sampling scheme where the corrector is informed by the diffusion model to more reliably counter the accumulating approximation errors. To further enhance the effectiveness of our informed corrector, we introduce complementary architectural modifications based on hollow transformers and a simple tailored training objective that leverages more training signal. We use a synthetic example to illustrate the failure modes of existing samplers and show how informed correctors alleviate these problems. On the Text8 dataset, the informed corrector improves sample quality by generating text with significantly fewer errors than the baselines. On tokenized ImageNet 256x256, this approach consistently produces superior samples with fewer steps, achieving improved FID scores for discrete diffusion models. These results underscore the potential of informed correctors for fast and high-fidelity generation using discrete diffusion.'}",https://openreview.net{'value': '/pdf/33f835f8abacae18719b389f0a413d72b937fe5b.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=H1PLlbFvwW,{'value': 'V2V: Scaling Event-Based Vision through Efficient Video-to-Voxel Simulation'},Hanyue Lou; Jinxiu Liang; Minggui Teng; Yi Wang; Boxin Shi,~Hanyue_Lou1; ~Jinxiu_Liang1; ~Minggui_Teng1; ~Yi_Wang19; ~Boxin_Shi3,{'value': ['event-based vision']},"{'value': 'Event-based cameras offer unique advantages such as high temporal resolution, high dynamic range, and low power consumption. However, the massive storage requirements and I/O burdens of existing synthetic data generation pipelines and the scarcity of real data prevent event-based training datasets from scaling up, limiting the development and generalization capabilities of event vision models. To address this challenge, we introduce Video-to-Voxel (V2V), an approach that directly converts conventional video frames into event-based voxel grid representations, bypassing the storage-intensive event stream generation entirely. V2V enables a 150× reduction in storage requirements while supporting on-the-fly parameter randomization for enhanced model robustness. Leveraging this efficiency, we train several video reconstruction and optical flow estimation model architectures on 10,000 diverse videos totaling 52 hours—an order of magnitude larger than existing event datasets, yielding substantial improvements.'}",https://openreview.net{'value': '/pdf/0cbf4cc149cb2e2ef6497237d0e07dc97c42c1cd.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=Gz6dujD5j0,{'value': 'Toward Interpretable Evaluation Measures for Time Series Segmentation'},Félix Chavelli; Paul Boniol; Michaël Thomazo,~Félix_Chavelli1; ~Paul_Boniol1; ~Michaël_Thomazo2,"{'value': ['time series', 'state detection', 'change point detection', 'evaluation measure', 'interpretability']}","{'value': 'Time series segmentation is a fundamental task in analyzing temporal data across various domains, from human activity recognition to energy monitoring. While numerous state-of-the-art methods have been developed to tackle this problem, the evaluation of their performance remains critically limited. Existing measures predominantly focus on change point accuracy or rely on point-based metrics such as Adjusted Rand Index (ARI), which fail to capture the quality of the detected segments, ignore the nature of errors, and offer limited interpretability. In this paper, we address these shortcomings by introducing two novel evaluation measures: WARI (Weighted Adjusted Rand Index), a temporal extension of ARI that accounts for the position of segmentation errors, and SMS (State Matching Score), a fine-grained metric that identifies and scores four distinct and fundamental types of segmentation errors while allowing error-specific weighting. We empirically validate WARI and SMS on synthetic and real-world benchmarks, showing that they not only provide a more accurate assessment of segmentation quality but also uncover insights, such as error provenance and type, that are inaccessible with traditional measures.'}",https://openreview.net{'value': '/pdf/b55da58cdb0b746180ec94be5f8315103951960f.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=GxGrGswvND,{'value': 'Hybrid-Balance GFlowNet for Solving Vehicle Routing Problems'},Ni Zhang; Zhiguang Cao,~Ni_Zhang6; ~Zhiguang_Cao1,"{'value': ['GFlowNet', 'Vehicle Routing Problem']}","{'value': ""Existing GFlowNet-based methods for vehicle routing problems (VRPs) typically employ Trajectory Balance (TB) to achieve global optimization but often neglect important aspects of local optimization. While Detailed Balance (DB) addresses local optimization more effectively, it alone falls short in solving VRPs, which inherently require holistic trajectory optimization. To address these limitations, we introduce the Hybrid-Balance GFlowNet (HBG) framework, which uniquely integrates TB and DB in a principled and adaptive manner by aligning their intrinsically complementary strengths. Additionally, we propose a specialized inference strategy for depot-centric scenarios like the Capacitated Vehicle Routing Problem (CVRP), leveraging the depot node's greater flexibility in selecting successors. Despite this specialization, HBG maintains broad applicability, extending effectively to problems without explicit depots, such as the Traveling Salesman Problem (TSP). We evaluate HBG by integrating it into two established GFlowNet-based solvers, i.e., AGFN and GFACS, and demonstrate consistent and significant improvements across both CVRP and TSP, underscoring the enhanced solution quality and generalization afforded by our approach.""}",https://openreview.net{'value': '/pdf/9268d5ea694889e0f48122db6f1bfd3c2e9b22ff.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=Gvh6sU0uUt,{'value': 'Least squares variational inference'},Yvann Le Fay; Nicolas Chopin; Simon Barthelmé,~Yvann_Le_Fay1; ~Nicolas_Chopin1; ~Simon_Barthelmé1,"{'value': ['variational inference', 'computational statistics', 'gradient-free methods', 'kullback-leibler divergence', 'bayesian statistics', 'stochastic optimization']}","{'value': 'Variational inference seeks the best approximation of a target distribution within a chosen family, where ""best"" means minimizing Kullback-Leibler divergence. \nWhen the approximation family is exponential, the optimal approximation satisfies a fixed-point equation.\nWe introduce LSVI (Least Squares Variational Inference), a gradient-free, Monte Carlo-based scheme for the fixed-point recursion, where each iteration boils down to performing ordinary least squares regression on tempered log-target evaluations under the variational approximation.\nWe show that LSVI is equivalent to biased stochastic natural gradient descent and use this to derive convergence rates with respect to the numbers of samples and iterations.\nWhen the approximation family is Gaussian, LSVI involves inverting the Fisher information matrix, whose size grows quadratically with dimension $d$.\nWe exploit the regression formulation to eliminate the need for this inversion, yielding $O(d^3)$ complexity in the full-covariance case and $O(d)$ in the mean-field case.\nFinally, we numerically demonstrate LSVI’s performance on various tasks, including logistic regression, discrete variable selection, and Bayesian synthetic likelihood, showing competitive results with state-of-the-art methods, even when gradients are unavailable.'}",https://openreview.net{'value': '/pdf/f444285552e241faf5f867f0b6cd81adfa7017b1.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=Gsi42ohBoM,{'value': 'Personalized Safety in LLMs: A Benchmark and A Planning-Based Agent Approach'},Yuchen Wu; Edward Sun; Kaijie Zhu; Jianxun Lian; Jose Hernandez-Orallo; Aylin Caliskan; Jindong Wang,~Yuchen_Wu2; ~Edward_Sun1; ~Kaijie_Zhu1; ~Jianxun_Lian1; ~Jose_Hernandez-Orallo1; ~Aylin_Caliskan1; ~Jindong_Wang4,"{'value': ['LLM Safety', 'Evaluation', 'Personalized Safety', 'Structured User Context', 'Monte Carlo Tree Search (MCTS)']}","{'value': ""Large language models (LLMs) typically generate identical or similar responses for all users given the same prompt, posing serious safety risks in high-stakes applications where user vulnerabilities differ widely.\nExisting safety evaluations primarily rely on context-independent metrics—such as factuality, bias, or toxicity—overlooking the fact that the same response may carry divergent risks depending on the user's background or condition.\nWe introduce ``personalized safety'' to fill this gap and present PENGUIN—a benchmark comprising 14,000 scenarios across seven sensitive domains with both context-rich and context-free variants. Evaluating six leading LLMs, we demonstrate that personalized user information significantly improves safety scores by 43.2%, confirming the effectiveness of personalization in safety alignment. However, not all context attributes contribute equally to safety enhancement. To address this, we develop RAISE—a training-free, two-stage agent framework that strategically acquires user-specific background. RAISE improves safety scores by up to 31.6% over six vanilla LLMs, while maintaining a low interaction cost of just 2.7 user queries on average. Our findings highlight the importance of selective information gathering in safety-critical domains and offer a practical solution for personalizing LLM responses without model retraining. This work establishes a foundation for safety research that adapts to individual user contexts rather than assuming a universal harm standard.""}",https://openreview.net{'value': '/pdf/c98e7220e280f1d8bae43d92944840467237a1e7.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=GhVQnjVjlI,{'value': 'Optimal Online Change Detection via Random Fourier Features'},Florian Kalinke; Shakeel A O B Gavioli-Akilagun,~Florian_Kalinke1; ~Shakeel_A_O_B_Gavioli-Akilagun1,"{'value': ['change point detection', 'information-theoretic lower bounds', 'kernel mean embedding', 'non-parametric testing']}","{'value': ""This article studies the problem of online non-parametric change point detection in multivariate data streams. We approach the problem through the lens of kernel-based two-sample testing and introduce a sequential testing procedure based on random Fourier features, running with logarithmic time complexity per observation and with overall logarithmic space complexity. The algorithm has two advantages compared to the state of the art. First, our approach is genuinely online, and no access to training data known to be from the pre-change distribution is necessary. Second, the algorithm does not require the user to specify a window parameter over which local tests are to be calculated. We prove strong theoretical guarantees on the algorithm's performance, including information-theoretic bounds demonstrating that the detection delay is optimal in the minimax sense. Numerical studies on real and synthetic data show that our algorithm is competitive with respect to the state of the art.""}",https://openreview.net{'value': '/pdf/8f5dbae3c583ea28285e8f9e9361e70785b177e4.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=Gf4oPoluAV,{'value': 'TAI3: Testing Agent Integrity in Interpreting User Intent'},Shiwei Feng; Xiangzhe Xu; Xuan Chen; Kaiyuan Zhang; Syed Yusuf Ahmed; Zian Su; Mingwei Zheng; Xiangyu Zhang,~Shiwei_Feng1; ~Xiangzhe_Xu1; ~Xuan_Chen3; ~Kaiyuan_Zhang1; ~Syed_Yusuf_Ahmed1; ~Zian_Su1; ~Mingwei_Zheng1; ~Xiangyu_Zhang3,"{'value': ['LLM Agent', 'Agent Testing', 'Stress Testing', 'Software Engineering', 'API-Calling', 'Agent Safety']}","{'value': 'LLM agents are increasingly deployed to automate real-world tasks by invoking APIs through natural language instructions. While powerful, they often suffer from misinterpretation of user intent, leading to the agent’s actions that diverge from the user’s intended goal, especially as external toolkits evolve. Traditional software testing assumes structured inputs and thus falls short in handling the ambiguity of natural language. We introduce TAI3, an API-centric stress testing framework that systematically uncovers intent integrity violations in LLM agents. Unlike prior work focused on fixed benchmarks or adversarial inputs, TAI3 generates realistic tasks based on toolkits’ documentation and applies targeted mutations to expose subtle agent errors while preserving user intent. To guide testing, we propose semantic partitioning, which organizes natural language tasks into meaningful categories based on toolkit API parameters and their equivalence classes. Within each partition, seed tasks are mutated and ranked by a lightweight predictor that estimates the likelihood of triggering agent errors. To enhance efficiency, TAI3 maintains a datatype-aware strategy memory that retrieves and adapts effective mutation patterns from past cases. Experiments on 80 toolkit APIs demonstrate that TAI3 effectively uncovers intent integrity violations, significantly outperforming baselines in both error-exposing rate and query efficiency. Moreover, TAI3 generalizes well to stronger target models using smaller LLMs for test generation, and adapts to evolving APIs across domains.'}",https://openreview.net{'value': '/pdf/11f637b039ea8d411deed20635e2af4cc8c76b3a.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=GbRVlyVOqH,{'value': 'Dataset Distillation for Pre-Trained Self-Supervised Vision Models'},George Cazenavette; Antonio Torralba; Vincent Sitzmann,~George_Cazenavette1; ~Antonio_Torralba1; ~Vincent_Sitzmann1,"{'value': ['dataset distillation', 'self-supervised learning', 'few-shot learning']}","{'value': ""The task of dataset distillation aims to find a small set of synthetic images such that training a model on them reproduces the performance of the same model trained on a much larger dataset of real samples. Existing distillation methods focus on synthesizing datasets that enable training randomly initialized models. In contrast, state-of-the-art vision approaches are increasingly building on large, pre-trained self-supervised models rather than training from scratch. In this paper, we investigate the problem of distilling datasets that enable us to optimally train linear probes on top of such large, pre-trained vision models. We introduce a method of dataset distillation for this task called Linear Gradient Matching that optimizes the synthetic images such that, when passed through a pre-trained feature extractor, they induce gradients in the linear classifier similar to those produced by the real data. Our method yields synthetic data that out-perform all real-image baselines and, remarkably, generalize across pre-trained vision models, enabling us, for instance, to train a linear CLIP probe that performs competitively using a dataset distilled via a DINO backbone. Further, we show that distilled datasets provide a valuable tool for model interpretability, predicting, among other things, how similar two model's representations spaces are under the platonic representation hypothesis or whether a model is sensitive to spurious correlations in adversarial datasets.""}",https://openreview.net{'value': '/pdf/eba4a8c7ae859b5c86f681444ab21523f31574ca.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=GYLMYTYqZg,{'value': 'Low Precision Streaming PCA'},Sanjoy Dasgupta; Syamantak Kumar; Shourya Pandey; Purnamrita Sarkar,~Sanjoy_Dasgupta3; ~Syamantak_Kumar1; ~Shourya_Pandey1; ~Purnamrita_Sarkar1,"{'value': ['Streaming PCA', 'Low-Precision Quantization', 'Oja’s Algorithm', 'Stochastic Quantization', 'Finite-Sample Convergence', 'Spectral Gap Assumption', 'Minimax Lower Bounds']}","{'value': ""Low-precision Streaming PCA estimates the top principal component in a streaming setting under limited precision.  We establish an information‐theoretic lower bound on the quantization resolution required to achieve a target accuracy for the leading eigenvector. We study Oja's algorithm for streaming PCA under linear and nonlinear stochastic quantization. The quantized variants use unbiased stochastic quantization of the weight vector and the updates. Under mild moment and spectral-gap assumptions on the data distribution, we show that a batched version achieves the lower bound up to logarithmic factors under both schemes. This leads to a nearly _dimension-free_ quantization error in the nonlinear quantization setting. Empirical evaluations on synthetic streams validate our theoretical findings and demonstrate that our low-precision methods closely track the performance of standard Oja’s algorithm.""}",https://openreview.net{'value': '/pdf/370c858322d3928badec55b76296a088966914c5.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=GV82iAD70j,{'value': 'SCoT: Unifying Consistency Models and Rectified Flows via Straight-Consistent Trajectories'},zhangkai wu; Xuhui Fan; Hongyu Wu; Longbing Cao,~zhangkai_wu1; ~Xuhui_Fan1; ~Hongyu_Wu6; ~Longbing_Cao1,{'value': ['Generative Model']},"{'value': ""Pre-trained diffusion models are commonly used to generate clean data (e.g., images) from random noises, effectively forming pairs of noises and corresponding clean images. Distillation on these pre-trained models can be viewed as the process of constructing advanced trajectories within the pair to accelerate sampling. For instance, consistency model distillation develops consistent projection functions to regulate trajectories, although sampling efficiency remains a concern. Rectified flow method enforces straight trajectories to enable faster sampling, yet relies on numerical ODE solvers, which may introduce approximation errors. In this work, we bridge the gap between the consistency model and the rectified flow method by proposing a Straight-Consistent Trajectories~(SCoT) model. SCoT enjoys the benefits of both approaches for fast sampling, producing trajectories with consistent and straight properties simultaneously. These dual properties are strategically balanced by targeting two critical objectives: (1) regulating the gradient of SCoT's mapping function to a constant and (2) ensuring trajectory consistency. Extensive experimental results demonstrate the effectiveness and efficiency of SCoT.""}",https://openreview.net{'value': '/pdf/706a55fe820768bc0049aab7eeb62deb0a9005d8.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=GJbrk55Bt8,{'value': 'List-Level Distribution Coupling with Applications to Speculative Decoding and Lossy Compression'},Joseph Rowan; Buu Phan; Ashish J Khisti,~Joseph_Rowan1; ~Buu_Phan3; ~Ashish_J_Khisti1,"{'value': ['probability', 'sampling', 'compression', 'speculative decoding', 'multi-draft speculative sampling', 'large language models']}","{'value': 'We study a relaxation of the problem of coupling probability distributions — a list of samples is generated from one distribution and an *accept* is declared if any one of these samples is identical to the sample generated from the other distribution.\nWe propose a novel method for generating samples, which extends the Gumbel-max sampling suggested in Daliri et al. (2025) for coupling probability distributions. We also establish a corresponding lower bound on the acceptance probability, which we call the \\emph{list matching lemma}.\nWe next discuss two applications of our setup.\nFirst, we develop a new mechanism for multi-draft speculative sampling that is simple to implement and achieves performance competitive with baselines such as SpecTr and SpecInfer across a range of language tasks.\nOur method also guarantees a certain degree of *drafter invariance* with respect to the output tokens which is not supported by existing schemes.\nWe also provide a theoretical lower bound on the token level acceptance probability.\nAs our second application, we consider distributed lossy compression with side information in a setting where a source sample is compressed and available to multiple decoders, each with independent side information.\nWe propose a compression technique that is based on our generalization of Gumbel-max sampling and show that it provides significant gains in experiments involving synthetic Gaussian sources and the MNIST image dataset.'}",https://openreview.net{'value': '/pdf/74a2619228640bab3425872d8ea661d6b0a14289.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=GHAtg6RQ3b,{'value': 'Self-Supervised Discovery of Neural Circuits in Spatially Patterned Neural Responses with Graph Neural Networks'},Kijung Yoon,~Kijung_Yoon2,"{'value': ['Neuroscience', 'Memory', 'Neural connectivity inference', 'Continuous attractor networks', 'Neural circuit dynamics', 'Graph neural networks']}","{'value': 'Inferring synaptic connectivity from neural population activity is a fundamental challenge in computational neuroscience, complicated by partial observability and mismatches between inference models and true circuit dynamics. In this study, we propose a graph-based neural inference model that simultaneously predicts neural activity and infers latent connectivity by modeling neurons as interacting nodes in a graph. The architecture features two distinct modules: one for learning structural connectivity and another for predicting future spiking activity via a graph neural network (GNN). Our model accommodates unobserved neurons through auxiliary nodes, allowing for inference in partially observed circuits. We evaluate this approach using synthetic data generated from ring attractor network models and real spike recordings from head direction cells in mice. Across a wide range of conditions, including varying recurrent connectivity, external inputs, and incomplete observations, our model reliably resolves spurious correlations and recovers accurate weight profiles. When applied to real data, the inferred connectivity aligns with theoretical predictions of continuous attractor models. These results highlight the potential of GNN-based models to infer latent neural circuitry through self-supervised structure learning, while leveraging the spike prediction task to flexibly link connectivity and dynamics across both simulated and biological neural systems.'}",https://openreview.net{'value': '/pdf/c05bc41571da33f990f36d9d8a6e72a56dec68e6.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=GEzd5K5s5u,{'value': 'State-Covering Trajectory Stitching for Diffusion Planners'},Kyowoon Lee; Jaesik Choi,~Kyowoon_Lee1; ~Jaesik_Choi1,"{'value': ['Offline Reinforcement Learning', 'Trajectory Optimization', 'Diffusion Models', 'Trajectory Stitching']}","{'value': 'Diffusion-based generative models are emerging as powerful tools for long-horizon planning in reinforcement learning (RL), particularly with offline datasets. However, their performance is fundamentally limited by the quality and diversity of training data. This often restricts their generalization to tasks outside their training distribution or longer planning horizons. To overcome this challenge, we propose *State-Covering Trajectory Stitching* (SCoTS), a novel reward-free trajectory augmentation method that incrementally stitches together short trajectory segments, systematically generating diverse and extended trajectories. SCoTS first learns a temporal distance-preserving latent representation that captures the underlying temporal structure of the environment, then iteratively stitches trajectory segments guided by directional exploration and novelty to effectively cover and expand this latent space. We demonstrate that SCoTS significantly improves the performance and generalization capabilities of diffusion planners on offline goal-conditioned benchmarks requiring stitching and long-horizon reasoning. Furthermore, augmented trajectories generated by SCoTS significantly improve the performance of widely used offline goal-conditioned RL algorithms across diverse environments.'}",https://openreview.net{'value': '/pdf/fbd924159e56d01c2c1019884cd0c1b04052f6cb.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=G2kMroO9UV,{'value': 'Web-Shepherd: Advancing PRMs for Reinforcing Web Agents'},Hyungjoo Chae; Sunghwan Kim; Junhee Cho; Seungone Kim; Seungjun Moon; Gyeom Hwangbo; Dongha Lim; Minjin Kim; Yeonjun Hwang; Minju Gwak; Dongwook Choi; Minseok Kang; Gwanhoon Im; ByeongUng Cho; Hyojun Kim; Jun Hee Han; Taeyoon Kwon; Minju Kim; Beong-woo Kwak; Dongjin Kang; Jinyoung Yeo,~Hyungjoo_Chae1; ~Sunghwan_Kim3; ~Junhee_Cho4; ~Seungone_Kim1; ~Seungjun_Moon2; ~Gyeom_Hwangbo2; ~Dongha_Lim1; ~Minjin_Kim1; ~Yeonjun_Hwang1; ~Minju_Gwak1; ~Dongwook_Choi2; ~Minseok_Kang2; ~Gwanhoon_Im1; ~ByeongUng_Cho1; ~Hyojun_Kim3; ~Jun_Hee_Han1; ~Taeyoon_Kwon1; ~Minju_Kim1; ~Beong-woo_Kwak1; ~Dongjin_Kang1; ~Jinyoung_Yeo1,"{'value': ['Web Agent', 'Reward Model', 'LLM']}","{'value': 'Web navigation is a unique domain that can automate many repetitive real-life tasks and is challenging as it requires long-horizon sequential decision making beyond typical multimodal large language model (MLLM) tasks.\nYet, specialized reward models for web navigation that can be utilized during both training and test-time have been absent until now. Despite the importance of speed and cost-effectiveness, prior works have utilized MLLMs as reward models, which poses significant constraints for real-world deployment. To address this, in this work, we propose the first process reward model (PRM) called Web-Shepherd which could assess web navigation trajectories in a step-level. To achieve this, we first construct the WebPRM Collection, a large-scale dataset with 40K step-level preference pairs and annotated checklists spanning diverse domains and difficulty levels. Next, we also introduce the WebRewardBench, the first meta-evaluation benchmark for evaluating PRMs. In our experiments, we observe that our Web-Shepherd achieves about 30 points better accuracy compared to using GPT-4o on WebRewardBench. \nFurthermore, when testing on WebArena-lite by using GPT-4o-mini as the policy and Web-Shepherd as the verifier, we achieve 10.9 points better performance, in 10x less cost compared to using GPT-4o-mini as the verifier. \nOur model, dataset, and code are publicly available at https://github.com/kyle8581/Web-Shepherd.'}",https://openreview.net{'value': '/pdf/db46564195dad40b9b174514d7d03b0336d2a8eb.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=FxyG5xHjxb,{'value': 'Finite-Time Bounds for Average-Reward Fitted Q-Iteration'},Jongmin Lee; Ernest K. Ryu,~Jongmin_Lee3; ~Ernest_K._Ryu1,"{'value': ['reinforcement learning theory', 'average-reward MDP', 'fitted Q-iteration', 'value iteration', 'sample complexity', 'anchoring', 'single-trajectory data', 'IID data']}","{'value': 'Although there is an extensive body of work characterizing the sample complexity of discounted-return offline RL with function approximations, prior work on the average-reward setting has received significantly less attention, and existing approaches rely on restrictive assumptions, such as ergodicity or linearity of the MDP. In this work, we establish the first sample complexity results for average-reward offline RL with function approximation for weakly communicating MDPs, a much milder assumption. To this end, we introduce Anchored Fitted Q-Iteration, which combines the standard Fitted Q-Iteration with an anchor mechanism. We show that the anchor, which can be interpreted as a form of weight decay, is crucial for enabling finite-time analysis in the average-reward setting. We also extend our finite-time analysis to the setup where the dataset is generated from a single-trajectory rather than IID transitions, again leveraging the anchor mechanism.'}",https://openreview.net{'value': '/pdf/0d3ee4dc8e9505baa7a16118b3598b0349e1188c.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=FxCy8TvQHO,{'value': 'SimWorld: An Open-ended Simulator for Agents in Physical and Social Worlds'},Xiaokang Ye; Jiawei Ren; Yan Zhuang; Xuhong He; Yiming Liang; Yiqing Yang; Mrinaal Dogra; Xianrui Zhong; Eric Liu; Kevin Benavente; Rajiv Mandya Nagaraju; Dhruv Vivek Sharma; Ziqiao Ma; Tianmin Shu; Zhiting Hu; Lianhui Qin,~Xiaokang_Ye1; ~Jiawei_Ren4; ~Yan_Zhuang13; ~Xuhong_He1; ~Yiming_Liang3; ~Yiqing_Yang3; ~Mrinaal_Dogra1; ~Xianrui_Zhong1; ~Eric_Liu3; ~Kevin_Benavente1; ~Rajiv_Mandya_Nagaraju1; ~Dhruv_Vivek_Sharma1; ~Ziqiao_Ma1; ~Tianmin_Shu1; ~Zhiting_Hu3; ~Lianhui_Qin1,"{'value': ['Multi-Agent Simulator', 'Real World Agent', 'Social Simulation', 'Physical Simulation']}","{'value': 'While LLM/VLM-powered AI agents have advanced rapidly in math, coding, and computer use, their applications in complex physical and social environments remain challenging. Building agents that can survive and thrive in the real world (e.g., by autonomously earning income) requires massive-scale interaction, reasoning, training, and evaluation across diverse scenarios. However, existing world simulators for such development fall short: they often rely on limited hand-crafted environments, simulate simplified game-like physics and social rules, and lack native support for LLM/VLM agents. We introduce SimWorld, a new simulator built on Unreal Engine 5, designed for developing and evaluating LLM/VLM agents in rich, real-world-like settings. SimWorld offers three core capabilities: (1) realistic, open-ended world simulation, including accurate physical and social dynamics and language-driven procedural environment generation; (2) rich interface for LLM/VLM agents, with multi-modal world inputs/feedback and open-vocabulary action outputs at varying levels of abstraction; and (3) diverse physical and social reasoning scenarios that are easily customizable by users. We demonstrate SimWorld by deploying frontier LLM agents (e.g., Gemini-2.5-Flash, Claude-3.5, GPT-4o, and DeepSeek-Prover-V2) on both short-horizon navigation tasks requiring grounded re-planning, and long-horizon multi-agent food delivery tasks involving strategic cooperation and competition. The results reveal distinct reasoning patterns and limitations across models. We open-source SimWorld and hope it becomes a foundational platform for advancing real-world agent intelligence across disciplines. Please refer to the project website for the most up-to-date information: http://simworld.org/.'}",https://openreview.net{'value': '/pdf/a98dee23d8b37552151336bbac20c838fd5e9ee1.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=FvXI7DNQfz,{'value': 'OASIS: One-Shot Federated Graph Learning via Wasserstein Assisted Knowledge Integration'},Guancheng Wan; Jiaru Qian; Wenke Huang; Qilin Xu; Xianda Guo; Boheng Li; Guibin Zhang; Bo Du; Mang Ye,~Guancheng_Wan1; ~Jiaru_Qian1; ~Wenke_Huang1; ~Qilin_Xu1; ~Xianda_Guo2; ~Boheng_Li1; ~Guibin_Zhang1; ~Bo_Du3; ~Mang_Ye1,"{'value': ['Federated Learning', 'Graph Learning']}","{'value': 'Federated Graph Learning (FGL) offers a promising framework for collaboratively training Graph Neural Networks (GNNs) while preserving data privacy. In resource-constrained environments, One-shot Federated Learning (OFL) emerges as an effective solution by limiting communication to a single round. Current OFL approaches employing generative models have attracted considerable attention; however, they face unresolved challenges: these methods are primarily designed for traditional image data and fail to capture the fine-grained structural information of local graph data. Consequently, they struggle to integrate the intricate correlations necessary and transfer subtle structural insights from each client to the global model. To address these issues, we introduce **OASIS**, an innovative one-shot FGL framework. In OASIS, we propose a Synergy Graph Synthesizer designed to generate informative synthetic graphs and introduce a Topological Codebook to construct a structural latent space. Moreover, we propose the Wasserstein-Enhanced Semantic Affinity Distillation (WESAD) to incorporate rich inter-class relationships and the Wasserstein-Driven Structural Relation Distillation (WDSRD) to facilitate the effective transfer of structural knowledge from the Topological Codebook. Extensive experiments on real-world tasks demonstrate the superior performance and generalization capability of OASIS. The code is available for anonymous access at https://anonymous.4open.science/r/OASIS-NeurIPS25.'}",https://openreview.net{'value': '/pdf/4b55982840604fefb8c27e482652653aacc4ea2b.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=FrQd4NoQ16,{'value': 'CReFT-CAD: Boosting Orthographic Projection Reasoning for CAD via Reinforcement Fine-Tuning'},Ke Niu; zhuofan chen; Haiyang Yu; Yuwen Chen; Teng Fu; Mengyang Zhao; Bin Li; Xiangyang Xue,~Ke_Niu2; ~zhuofan_chen2; ~Haiyang_Yu5; ~Yuwen_Chen6; ~Teng_Fu1; ~Mengyang_Zhao1; ~Bin_Li4; ~Xiangyang_Xue1,"{'value': ['CAD Reasoning', 'Multi-Modal Dataset', 'Constraint-Driven Synthesis']}","{'value': 'Computer-Aided Design (CAD) is pivotal in industrial manufacturing, with orthographic projection reasoning foundational to its entire workflow—encompassing design, manufacturing, and simulation. However, prevailing deep-learning approaches employ standard 3D reconstruction pipelines as an alternative, which often introduce imprecise dimensions and limit the parametric editability required for CAD workflows. Recently, some researchers adopt vision–language models (VLMs), particularly supervised fine-tuning (SFT), to tackle CAD-related challenges. SFT shows promise but often devolves into pattern memorization, resulting in poor out-of-distribution (OOD) performance on complex reasoning tasks. To tackle these limitations, we introduce CReFT-CAD, a two-stage fine-tuning paradigm: first, a curriculum-driven reinforcement learning stage with difficulty-aware rewards to steadily build reasoning abilities; second, supervised post-tuning to refine instruction following and semantic extraction. Complementing this, we release TriView2CAD, the first large-scale, open-source benchmark for orthographic projection reasoning, comprising 200,000 synthetic and 3,000 real-world orthographic projections with precise dimensional annotations and six interoperable data modalities. Benchmarking leading VLMs on orthographic projection reasoning, we show that CReFT-CAD significantly improves reasoning accuracy and OOD generalizability in real-world scenarios, providing valuable insights to advance CAD reasoning research. The code and adopted datasets are available at \\url{https://github.com/KeNiu042/CReFT-CAD}.'}",https://openreview.net{'value': '/pdf/68e2680563b97bade61775e5324864d72194750f.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=Flntl1YwZg,{'value': 'A Gradient Guided Diffusion Framework for Chance Constrained Programming'},Boyang Zhang; Zhiguo Wang; Ya-Feng Liu,~Boyang_Zhang8; ~Zhiguo_Wang2; ~Ya-Feng_Liu1,"{'value': ['Chance Constrained Programming', 'Diffusion Model', 'Optimization via Sampling', 'Gradient Guidance', 'Waveform Design']}","{'value': 'Chance constrained programming (CCP) is a powerful framework for addressing optimization problems under uncertainty. In this paper, we introduce a novel Gradient-Guided Diffusion-based Optimization framework, termed GGDOpt, which tackles CCP through three key innovations. First, GGDOpt accommodates a broad class of CCP problems without requiring the knowledge of the exact distribution of uncertainty—relying solely on a set of samples. Second, to address the nonconvexity of the chance constraints, it reformulates the CCP as a sampling problem over the product of two distributions: an unknown data distribution supported on a nonconvex set and a Boltzmann distribution defined by the objective function, which fully leverages both first- and second-order gradient information. Third, GGDOpt has theoretical convergence guarantees and provides practical error bounds under mild assumptions. By progressively injecting noise during the forward diffusion process to convexify the nonconvex feasible region, GGDOpt enables guided reverse sampling to generate asymptotically optimal solutions. Experimental results on synthetic datasets and a waveform design task in wireless communications demonstrate that GGDOpt outperforms existing methods in both solution quality and stability with nearly 80\\% overhead reduction.'}",https://openreview.net{'value': '/pdf/b554367678f6f2a8375325f6a13cc15ca9154c37.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=FiM0M8gcct,{'value': 'A-Mem: Agentic Memory for LLM Agents'},Wujiang Xu; Zujie Liang; Kai Mei; Hang Gao; Juntao Tan; Yongfeng Zhang,~Wujiang_Xu1; ~Zujie_Liang1; ~Kai_Mei1; ~Hang_Gao10; ~Juntao_Tan1; ~Yongfeng_Zhang1,{'value': ['LLM Agents; Memory System']},"{'value': ""While large language model (LLM) agents can effectively use external tools for complex real-world tasks, they require memory systems to leverage historical experiences. Current memory systems enable basic storage and retrieval but lack sophisticated memory organization, despite recent attempts to incorporate graph databases. Moreover, these systems' fixed operations and structures limit their adaptability across diverse tasks. To address this limitation, this paper proposes a novel agentic memory system for LLM agents that can dynamically organize memories in an agentic way. Following the basic principles of the Zettelkasten method, we designed our memory system to create interconnected knowledge networks through dynamic indexing and linking. When a new memory is added, we generate a comprehensive note containing multiple structured attributes, including contextual descriptions, keywords, and tags. The system then analyzes historical memories to identify relevant connections, establishing links where meaningful similarities exist. Additionally, this process enables memory evolution -- as new memories are integrated, they can trigger updates to the contextual representations and attributes of existing historical memories, allowing the memory network to continuously refine its understanding. Our approach combines the structured organization principles of Zettelkasten with the flexibility of agent-driven decision making, allowing for more adaptive and context-aware memory management.\nEmpirical experiments on six foundation models show superior improvement against existing SOTA baselines. The code is available at \\url{https://anonymous.4open.science/r/AgenticMemory-76B4}.""}",https://openreview.net{'value': '/pdf/518e506d098a6c821c7e4ae97d1368f374fddac9.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=Fg5WE2vxgM,{'value': 'Adaptive Algorithms with Sharp Convergence Rates for Stochastic Hierarchical Optimization'},Xiaochuan Gong; Jie Hao; Mingrui Liu,~Xiaochuan_Gong1; ~Jie_Hao3; ~Mingrui_Liu2,"{'value': ['hierarchical optimization', 'adaptive algorithms', 'stochastic optimization']}","{'value': 'Hierarchical optimization refers to problems with interdependent decision variables and objectives, such as minimax and bilevel formulations. While various algorithms have been proposed, existing methods and analyses lack adaptivity in stochastic optimization settings: they cannot achieve optimal convergence rates across a wide spectrum of gradient noise levels without prior knowledge of the noise magnitude. In this paper, we propose novel adaptive algorithms for two important classes of stochastic hierarchical optimization problems: nonconvex-strongly-concave minimax optimization and nonconvex-strongly-convex bilevel optimization. Our algorithms achieve sharp convergence rates of $\\widetilde{O}(1/\\sqrt{T} + \\sqrt{\\bar{\\sigma}}/T^{1/4})$ in $T$ iterations for the gradient norm, where $\\bar{\\sigma}$ is an upper bound on the stochastic gradient noise. Notably, these rates are obtained without prior knowledge of the noise level, thereby enabling automatic adaptivity in both low and high-noise regimes. To our knowledge, this work provides the first adaptive and sharp convergence guarantees for stochastic hierarchical optimization. Our algorithm design combines the momentum normalization technique with novel adaptive parameter choices. Extensive experiments on synthetic and deep learning tasks demonstrate the effectiveness of our proposed algorithms.'}",https://openreview.net{'value': '/pdf/21bc15e4eb7d39cc082e039e32f75ff087a328c9.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=FYbe7r0mxu,{'value': 'Neural Mutual Information Estimation with Vector Copulas'},Yanzhi Chen; Zijing Ou; Adrian Weller; Michael U. Gutmann,~Yanzhi_Chen1; ~Zijing_Ou1; ~Adrian_Weller1; ~Michael_U._Gutmann1,"{'value': ['mutual information', 'flow-based models', 'copulas', 'vector ranks']}","{'value': 'Estimating mutual information (MI) is a fundamental task in data science and machine learning. Existing  estimators mainly rely on either highly flexible models (e.g., neural networks), which require large amounts of data, or overly simplified models (e.g., Gaussian copula), which fail to capture complex distributions. Drawing upon recent vector copula theory, we propose a principled interpolation between these two extremes to achieve a better trade-off between complexity and capacity. Experiments on state-of-the-art synthetic benchmarks and real-world data with diverse modalities demonstrate the advantages of the proposed method.'}",https://openreview.net{'value': '/pdf/64fd7737a9aeb1b343c72492951d6c92c9e9dfa9.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=FXTg2P8OQz,{'value': 'BoltzNCE: Learning likelihoods for Boltzmann Generation with Stochastic Interpolants and Noise Contrastive Estimation'},Rishal Aggarwal; Jacky Chen; Nicholas Matthew Boffi; David Koes,~Rishal_Aggarwal3; ~Jacky_Chen1; ~Nicholas_Matthew_Boffi1; ~David_Koes1,"{'value': ['Noise Contrastive Estimation', 'Flow Matching', 'Score Matching', 'Free Energy Estimation', 'Boltzmann Distribution', 'Boltzmann Generators']}","{'value': 'Efficient sampling from the Boltzmann distribution given its energy function is a key challenge for modeling complex physical systems such as molecules. Boltzmann Generators address this problem by leveraging continuous normalizing flows to transform a simple prior into a distribution that can be reweighted to match the target using sample likelihoods. Despite the elegance of this approach, obtaining these likelihoods requires computing costly Jacobians during integration, which is impractical for large molecular systems. To overcome this difficulty, we train an energy-based model (EBM) to approximate likelihoods using both noise contrastive estimation (NCE) and score matching, which we show outperforms the use of either objective in isolation. On 2D synthetic systems where failure can be easily visualized, NCE improves mode weighting relative to score matching alone. On alanine dipeptide, our method yields free energy profiles and energy distributions that closely match those obtained using exact likelihoods while achieving $100\\times$ faster inference. By training on multiple dipeptide systems, we show that our approach also exhibits effective transfer learning, generalizing to new systems at inference time and achieving at least a $6\\times$ speedup over standard MD with only a bit of fine-tuning. While many recent efforts in generative modeling have prioritized models with fast sampling, our work demonstrates the design of models with accelerated likelihoods, enabling the application of reweighting schemes that ensure unbiased Boltzmann statistics at scale. Our code is available at https://github.com/RishalAggarwal/BoltzNCE.'}",https://openreview.net{'value': '/pdf/5d4698ef7dc26d45983a4a1cf51d86e039d345c1.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=FUd016XD4d,{'value': 'Latent Policy Barrier: Learning Robust Visuomotor Policies by Staying In-Distribution'},Zhanyi Sun; Shuran Song,~Zhanyi_Sun1; ~Shuran_Song3,"{'value': ['Imitation Learning', 'Out-of-Distribution Generalization', 'Robotic Manipulation']}","{'value': 'Visuomotor policies trained via behavior cloning are vulnerable to covariate shift, where small deviations from expert trajectories can compound into failure. Common strategies to mitigate this issue involve expanding the training distribution through human-in-the-loop corrections or synthetic data augmentation. However, these approaches are often labor-intensive, rely on strong task assumptions, or compromise the quality of imitation. We introduce Latent Policy Barrier, a framework for robust visuomotor policy learning. Inspired by Control Barrier Functions, LPB treats the latent embeddings of expert demonstrations as an implicit barrier separating safe, in-distribution states from unsafe, out-of-distribution (OOD) ones. Our approach decouples the role of precise expert imitation and OOD recovery into two separate modules: a base diffusion policy solely on expert data, and a dynamics model trained on both expert and suboptimal policy rollout data.  At inference time, the dynamics model predicts future latent states and optimizes them to stay within the expert distribution. Both simulated and real-world experiments show that LPB improves both policy robustness and data efficiency, enabling reliable manipulation from limited expert data and without additional human correction or annotation. More details are on our anonymous project website https://latentpolicybarrier.github.io.'}",https://openreview.net{'value': '/pdf/55b30270447a357b440c091bcdeae59559fbccb4.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=FU62P5IXhK,{'value': 'Future-Aware End-to-End Driving: Bidirectional Modeling of Trajectory Planning and Scene Evolution'},Bozhou Zhang; Nan Song; jingyu li; Xiatian Zhu; Jiankang Deng; Li Zhang,~Bozhou_Zhang1; ~Nan_Song4; ~jingyu_li5; ~Xiatian_Zhu3; ~Jiankang_Deng1; ~Li_Zhang5,"{'value': ['autonomous driving', 'end-to-end', 'world model']}","{'value': 'End-to-end autonomous driving methods aim to directly map raw sensor inputs to future driving actions such as planned trajectories, bypassing traditional modular pipelines. While these approaches have shown promise, they often operate under a one-shot paradigm that relies heavily on the current scene context, potentially underestimating the importance of scene dynamics and their temporal evolution. This limitation restricts the model’s ability to make informed and adaptive decisions in complex driving scenarios. We propose a new perspective: the future trajectory of an autonomous vehicle is closely intertwined with the evolving dynamics of its environment, and conversely, the vehicle’s own future states can influence how the surrounding scene unfolds. Motivated by this bidirectional relationship, we introduce **SeerDrive**, a novel end-to-end framework that jointly models future scene evolution and trajectory planning in a closed-loop manner. Our method first predicts future bird’s-eye view (BEV) representations to anticipate the dynamics of the surrounding scene, then leverages this foresight to generate future-context-aware trajectories. Two key components enable this: (1) future-aware planning, which injects predicted BEV features into the trajectory planner, and (2) iterative scene modeling and vehicle planning, which refines both future scene prediction and trajectory generation through collaborative optimization. Extensive experiments on the NAVSIM and nuScenes benchmarks show that SeerDrive significantly outperforms existing state-of-the-art methods.'}",https://openreview.net{'value': '/pdf/31fb81f3ee7126625031a0926b0a2572bfd01b77.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=FAiIRMvIwy,{'value': 'DesignX: Human-Competitive Algorithm Designer for Black-Box Optimization'},Hongshu Guo; Zeyuan Ma; Yining Ma; Xinglin Zhang; Wei-Neng Chen; Yue-Jiao Gong,~Hongshu_Guo1; ~Zeyuan_Ma1; ~Yining_Ma1; ~Xinglin_Zhang1; ~Wei-Neng_Chen1; ~Yue-Jiao_Gong1,"{'value': ['Automated Algorithm Design', 'Black-Box-Optimization', 'Meta-Black-Box Optimization', 'Learning to Optimize', 'Deep Reinforcement Learning']}","{'value': ""Designing effective black‑box optimizers is hampered by limited problem-specific knowledge and manual control that spans months for almost every detail. In this paper, we present DesignX, the first automated algorithm design framework that generates an effective optimizer specific to a given black-box optimization problem within seconds. Rooted in the first principles, we identify two key sub-tasks: 1) algorithm structure generation and 2) hyperparameter control. To enable systematic construction, a comprehensive modular algorithmic space is first built, embracing hundreds of algorithm components collected from decades of research. We then introduce a dual-agent reinforcement learning system that collaborates on structural and parametric design through a novel cooperative training objective, enabling large-scale meta-training across 10k diverse instances. Remarkably, through days of autonomous learning, the DesignX-generated optimizers continuously surpass human-crafted optimizers by orders of magnitude, either on synthetic testbed or on realistic optimization scenarios such as Protein-docking, AutoML and UAV path planning. Further in-depth analysis reveals DesignX's capability to discover non-trivial algorithm patterns beyond expert intuition, which, conversely, provides valuable design insights for the optimization community. We provide DesignX's Python project at~\\url{https://github.com/MetaEvo/DesignX}.""}",https://openreview.net{'value': '/pdf/abf117580ed6ecdac082370b0104d85086274cb3.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=Ey0mro4vJ6,{'value': 'Continuous Soft Actor-Critic: An Off-Policy Learning Method Robust to Time Discretization'},Huimin Han; Shaolin Ji,~Huimin_Han3; ~Shaolin_Ji1,"{'value': ['Reinforcement learning', 'Continuous-time', 'Off-policy']}","{'value': ""Many \\textit{Deep Reinforcement Learning} (DRL) algorithms are sensitive to time discretization, which reduces their performance in real-world scenarios. We propose Continuous Soft Actor-Critic, an off-policy actor-critic DRL algorithm in continuous time and space. It is robust to environment time discretization. We also extend the framework to multi-agent scenarios. This \\textit{Multi-Agent Reinforcement Learning} (MARL) algorithm is suitable for both competitive and cooperative settings. Policy evaluation employs stochastic control theory, with loss functions derived from martingale orthogonality conditions. We establish scaling principles for hyperparameters of the algorithm as the environment time discretization $\\delta t$ changes ($\\delta t \\rightarrow 0$). We provide theoretical proofs for the relevant theorems. To validate the algorithm's effectiveness, we conduct comparative experiments between the proposed algorithm and other mainstream methods across multiple tasks in \\textit{Virtual Multi-Agent System} (VMAS). Experimental results demonstrate that the proposed algorithm achieves robust performance across various environments with different time discretization parameter settings, outperforming other methods.""}",https://openreview.net{'value': '/pdf/a23c3437ca227f32f586000c959a825f9fc94fbd.pdf'},{'abstract_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=ExVMnClnrM,{'value': 'Enhancing Consistency of Flow-Based Image Editing through Kalman Control'},Haozhe Chi; Zhicheng Sun; Yang Jin; Yi Ma; Jing Wang; Yadong MU,~Haozhe_Chi1; ~Zhicheng_Sun1; ~Yang_Jin1; ~Yi_Ma7; ~Jing_Wang18; ~Yadong_MU1,"{'value': ['Image Generation', 'Rectified Flows', 'Generative Modeling', 'Optimal Control', 'Image Editing']}","{'value': 'Flow-based generative models have gained popularity for image generation and editing. For instruction-based image editing, it is critical to ensure that modifications are confined to the targeted regions. Yet existing methods often fail to maintain consistency in non-targeted regions between the original / edited images. Our primary contribution is to identify the cause of this limitation as the error accumulation across individual editing steps and to address it by incorporating the historical editing trajectory. Specifically, we formulate image editing as a control problem and leverage the Kalman filter to integrate the historical editing trajectory. Our proposed algorithm, dubbed Kalman-Edit, reuses early-stage details from the historical trajectory to enhance the structural consistency of the editing results. To speed up editing, we introduce a shortcut technique based on approximate vector field velocity estimation. Extensive experiments on several datasets demonstrate its superior performance compared to previous state-of-the-art methods.'}",https://openreview.net{'value': '/pdf/f8ca2eae06cee1155bc274ca0b6b36af3368a06e.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=Eu2Tqcvxih,{'value': 'Efficient Multimodal Dataset Distillation via Generative Models'},Zhenghao Zhao; Haoxuan Wang; Junyi Wu; Yuzhang Shang; Gaowen Liu; Yan Yan,~Zhenghao_Zhao1; ~Haoxuan_Wang1; ~Junyi_Wu1; ~Yuzhang_Shang1; ~Gaowen_Liu4; ~Yan_Yan6,{'value': ['Dataset distillation']},"{'value': 'Dataset distillation aims to synthesize a small dataset from a large dataset, enabling the model trained on it to perform well on the original dataset. With the blooming of large language models and multimodal large language models, the importance of multimodal datasets, particularly image-text datasets, has grown significantly. However, existing multimodal dataset distillation methods are constrained by the Matching Training Trajectories algorithm, which significantly increases the computing resource requirement, and takes days to process the distillation. In this work, we introduce EDGE, a generative distillation method for efficient multimodal dataset distillation. Specifically, we identify two key challenges of distilling multimodal datasets with generative models: 1) The lack of correlation between generated images and captions. 2) The lack of diversity among generated samples.\nTo address the aforementioned issues, we propose a novel generative model training workflow with a bi-directional contrastive loss and a diversity loss. Furthermore, we propose a caption synthesis strategy to further improve text-to-image retrieval performance by introducing more text information.  Our method is evaluated on Flickr30K, COCO, and CC3M datasets, demonstrating superior performance and efficiency compared to existing approaches. Notably, our method achieves results 18$\\times$ faster than the state-of-the-art method. Our code will be made public at https://github.com/ichbill/EDGE.'}",https://openreview.net{'value': '/pdf/f0df1c77ffda619ce15867a3d44bc305db5577ee.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=EbjFkpXMke,{'value': 'SAO-Instruct: Free-form Audio Editing using Natural Language Instructions'},Michael Ungersböck; Florian Grötschla; Luca A Lanzendörfer; June Young Yi; Changho Choi; Roger Wattenhofer,~Michael_Ungersböck1; ~Florian_Grötschla1; ~Luca_A_Lanzendörfer1; ~June_Young_Yi1; ~Changho_Choi1; ~Roger_Wattenhofer1,"{'value': ['audio editing', 'text-to-audio generation', 'generative audio']}","{'value': 'Generative models have made significant progress in synthesizing high-fidelity audio from short textual descriptions. However, editing existing audio using natural language has remained largely underexplored. Current approaches either require the complete description of the edited audio or are constrained to predefined edit instructions that lack flexibility. In this work, we introduce SAO-Instruct, a model based on Stable Audio Open capable of editing audio clips using any free-form natural language instruction. To train our model, we create a dataset of audio editing triplets (input audio, edit instruction, output audio) using Prompt-to-Prompt, DDPM inversion, and a manual editing pipeline. Although partially trained on synthetic data, our model generalizes well to real in-the-wild audio clips and unseen edit instructions. We demonstrate that SAO-Instruct achieves competitive performance on objective metrics and outperforms other audio editing approaches in a subjective listening study. To encourage future research, we release our code and model weights.'}",https://openreview.net{'value': '/pdf/4e36a53f83242df472a043fc50c8481cfab464a9.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=EYxLmZRSK1,{'value': 'COME: Adding Scene-Centric Forecasting Control to Occupancy World Model'},Yining Shi; Kun Jiang; Qiang Meng; Ke Wang; Jiabao Wang; Wenchao Sun; Tuopu Wen; mengmeng yang; Diange Yang,~Yining_Shi1; ~Kun_Jiang3; ~Qiang_Meng1; ~Ke_Wang3; ~Jiabao_Wang5; ~Wenchao_Sun1; ~Tuopu_Wen1; ~mengmeng_yang2; ~Diange_Yang1,"{'value': ['Generative Models', 'Autonomous Driving', 'Occupancy Forecasting', 'Occupancy Generation', 'ControlNet']}","{'value': 'World models are critical for autonomous driving to simulate environmental dynamics and generate synthetic data.\nExisting methods struggle to disentangle ego-vehicle motion (perspective shifts) from scene evolvement (agent interactions), leading to suboptimal predictions. Instead, we propose to separate environmental changes from ego-motion by leveraging the scene-centric coordinate systems. In this paper, we introduce COME: a framework that integrates scene-centric forecasting Control into the Occupancy world ModEl. Specifically, COME first generates ego-irrelevant, spatially consistent future features through a scene-centric prediction branch, which are then converted into scene condition using a tailored ControlNet. These condition features are subsequently injected into the occupancy world model, enabling more accurate and controllable future occupancy predictions. Experimental results on the nuScenes-Occ3D dataset show that COME achieves consistent and significant improvements over state-of-the-art (SOTA) methods across diverse configurations, including different input sources (ground-truth, camera-based, fusion-based occupancy) and prediction horizons (3s and 8s). For example, under the same settings, COME achieves 26.3% better mIoU metric than DOME and 23.7% better mIoU metric than UniScene. These results highlight the efficacy of disentangled representation learning in enhancing spatio-temporal prediction fidelity for world models. Code is available at https://github.com/synsin0/COME.'}",https://openreview.net{'value': '/pdf/dd598a47e946c6f1d7636bde4518652893a0d07d.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=EY096v0Jmg,{'value': 'Active Test-time Vision-Language Navigation'},Heeju Ko; Sungjune Kim; Gyeongrok Oh; Jeongyoon Yoon; Honglak Lee; Sujin Jang; Seungryong Kim; Sangpil Kim,~Heeju_Ko1; ~Sungjune_Kim1; ~Gyeongrok_Oh1; ~Jeongyoon_Yoon1; ~Honglak_Lee2; ~Sujin_Jang2; ~Seungryong_Kim1; ~Sangpil_Kim4,"{'value': ['Vision-Language Navigation', 'Active Learning', 'Test-time Adaptation']}","{'value': ""Vision-Language Navigation (VLN) policies trained on offline datasets often exhibit degraded task performance when deployed in unfamiliar navigation environments at test time, where agents are typically evaluated without access to external interaction or feedback. Entropy minimization has emerged as a practical solution for reducing prediction uncertainty at test time; however, it can suffer from accumulated errors, as agents may become overconfident in incorrect actions without sufficient contextual grounding. To tackle these challenges, we introduce ATENA (Active TEst-time Navigation Agent), a test-time active learning framework that enables a practical human-robot interaction via episodic feedback on uncertain navigation outcomes. In particular, ATENA learns to increase certainty in successful episodes and decrease it in failed ones, improving uncertainty calibration. Here, we propose mixture entropy optimization, where entropy is obtained from a combination of the action and pseudo-expert distributions—a hypothetical action distribution assuming the agent's selected action to be optimal—controlling both prediction confidence and action preference. In addition, we propose a self-active learning strategy that enables an agent to evaluate its navigation outcomes based on confident predictions. As a result, the agent stays actively engaged throughout all iterations, leading to well-grounded and adaptive decision-making. Extensive evaluations on challenging VLN benchmarks—REVERIE, R2R, and R2R-CE—demonstrate that ATENA successfully overcomes distributional shifts at test time, outperforming the compared baseline methods across various settings.""}",https://openreview.net{'value': '/pdf/2b3182dfc9de3a07c9ea2a44ef0058ca99d61444.pdf'},{'abstract_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=ERQRSnqLRb,{'value': 'Generative Distribution Embeddings'},Nic Fishman; Gokul Gowri; Peng Yin; Jonathan S. Gootenberg; Omar Abudayyeh,~Nic_Fishman1; ~Gokul_Gowri1; ~Peng_Yin2; ~Jonathan_S._Gootenberg1; ~Omar_Abudayyeh1,"{'value': ['generative modeling', 'multiscale', 'distribution embeddings', 'representation learning', 'diffusion models', 'large language models', 'variational autoencoders', 'optimal transport', 'biology', 'genomics']}","{'value': 'Many real-world problems require reasoning across multiple scales, demanding models which operate not on single data points, but on entire distributions. We introduce generative distribution embeddings (GDE), a framework that lifts autoencoders to the space of distributions. In GDEs, an encoder acts on sets of samples, and the decoder is replaced by a generator which aims to match the input distribution. This framework enables learning representations of distributions by coupling conditional generative models with encoder networks which satisfy a criterion we call distributional invariance. We show that GDEs learn predictive sufficient statistics embedded in the Wasserstein space, such that latent GDE distances approximately recover the $W_2$ distance, and latent interpolation approximately recovers optimal transport trajectories for Gaussian and Gaussian mixture distributions. We systematically benchmark GDEs against existing approaches on synthetic datasets, demonstrating consistently stronger performance. We then apply GDEs to six key problems in computational biology: learning donor-level representations from single-nuclei RNA sequencing data (6M cells), capturing clonal dynamics in lineage-traced RNA sequencing data (150K cells), predicting perturbation effects on transcriptomes (1M cells), predicting perturbation effects on cellular phenotypes (20M single-cell images), designing synthetic yeast promoters (34M sequences), and spatiotemporal modeling of viral protein sequences (1M sequences).'}",https://openreview.net{'value': '/pdf/aad68cac884a075589189fe863288867a3e2b890.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=EOgaGafwv5,{'value': 'GST-UNet: A Neural Framework for Spatiotemporal Causal Inference with Time-Varying Confounding'},Miruna Oprescu; David Keetae Park; Xihaier Luo; Shinjae Yoo; Nathan Kallus,~Miruna_Oprescu1; ~David_Keetae_Park2; ~Xihaier_Luo1; ~Shinjae_Yoo1; ~Nathan_Kallus1,"{'value': ['spatiotemporal causal inference', 'time-varying confounding', 'G-computation', 'observational studies', 'neural networks', 'treatment effects', 'observational data']}","{'value': 'Estimating causal effects from spatiotemporal observational data is essential in public health, environmental science, and policy evaluation, where randomized experiments are often infeasible. Existing approaches, however, either rely on strong structural assumptions or fail to handle key challenges such as interference, spatial confounding, temporal carryover, and *time-varying confounding*—where covariates are influenced by past treatments and, in turn, affect future ones. We introduce the **GST-UNet** (**G**-computation **S**patio-**T**emporal **UNet**), a theoretically grounded neural framework that combines a U-Net-based spatiotemporal encoder with regression-based iterative G-computation to estimate location-specific potential outcomes under complex intervention sequences. GST-UNet explicitly adjusts for time-varying confounders and captures non-linear spatial and temporal dependencies, enabling valid causal inference from a *single* observed trajectory in data-scarce settings. We validate its effectiveness in synthetic experiments and in a real-world analysis of wildfire smoke exposure and respiratory hospitalizations during the 2018 California Camp Fire. Together, these results position GST-UNet as a **principled and ready-to-use framework** for spatiotemporal causal inference, advancing reliable estimation in policy-relevant and scientific domains.'}",https://openreview.net{'value': '/pdf/559f89bcc30537678b6e7eeb85d7dfe10a1f9f73.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=EKJhU5ioSo,{'value': 'GAM-Agent: Game-Theoretic and Uncertainty-Aware Collaboration for Complex Visual Reasoning'},Jusheng Zhang; Yijia Fan; Wenjun Lin; Ruiqi Chen; Haoyi Jiang; Wenhao Chai; Jian Wang; Keze Wang,~Jusheng_Zhang3; ~Yijia_Fan1; ~Wenjun_Lin2; ~Ruiqi_Chen3; ~Haoyi_Jiang2; ~Wenhao_Chai1; ~Jian_Wang10; ~Keze_Wang1,{'value': ['Multi-Agent; Uncertainty; Visual Language Model']},"{'value': 'We propose **GAM-Agent**, a game-theoretic multi-agent framework for enhancing vision-language reasoning. Unlike prior single-agent or monolithic models, GAM-Agent formulates the reasoning process as a non-zero-sum game between base agents—each specializing in visual perception subtasks—and a critical agent that verifies logic consistency and factual correctness. Agents communicate via structured claims, evidence, and uncertainty estimates. The framework introduces an uncertainty-aware controller to dynamically adjust agent collaboration, triggering multi-round debates when disagreement or ambiguity is detected. This process yields more robust and interpretable predictions. Experiments on four challenging benchmarks—MMMU, MMBench, MVBench, and V*Bench—demonstrate that GAM-Agent significantly improves performance across various VLM backbones. Notably, GAM-Agent boosts the accuracy of small-to-mid scale models (e.g., Qwen2.5-VL-7B, InternVL3-14B) by 5–6\\%, and still enhances strong models like GPT-4o by up to 2–3\\%. Our approach is modular, scalable, and generalizable, offering a path toward reliable and explainable multi-agent multimodal reasoning.'}",https://openreview.net{'value': '/pdf/55c4606303cc86c81ca99b5d5743cfe40d7fb140.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=EGYwfs4XhI,{'value': 'Improving Diffusion-based Inverse Algorithms under Few-Step Constraint via Linear Extrapolation'},Jiawei Zhang; Ziyuan Liu; Leon Yan; Gen Li; Yuantao Gu,~Jiawei_Zhang16; ~Ziyuan_Liu5; ~Leon_Yan1; ~Gen_Li2; ~Yuantao_Gu1,"{'value': ['Inverse problem', 'diffusion model', 'few-step', 'high order solver']}","{'value': 'Diffusion-based inverse algorithms have shown remarkable performance across various inverse problems, yet their reliance on numerous denoising steps incurs high computational costs.  While recent developments of fast diffusion ODE solvers offer effective acceleration for diffusion sampling without observations, their application in inverse problems remains limited due to the heterogeneous formulations of inverse algorithms and their prevalent use of approximations and heuristics, which often introduce significant errors that undermine the reliability of analytical solvers. \nIn this work, we begin with an analysis of ODE solvers for inverse problems that reveals a linear combination structure of approximations for the inverse trajectory. Building on this insight, we propose a canonical form that unifies a broad class of diffusion-based inverse algorithms and facilitates the design of more generalizable solvers.\nInspired by the linear subspace search strategy, we propose Learnable Linear Extrapolation (LLE), a lightweight approach that universally enhances the performance of any diffusion-based inverse algorithm conforming to our canonical form. LLE optimizes the combination coefficients to refine current predictions using previous estimates, alleviating the sensitivity of analytical solvers for inverse algorithms.\nExtensive experiments demonstrate consistent improvements of the proposed LLE method across multiple algorithms and tasks, indicating its potential for more efficient solutions and boosted performance of diffusion-based inverse algorithms with limited steps. Codes for reproducing our experiments are available at https://github.com/weigerzan/LLE_inverse_problem.'}",https://openreview.net{'value': '/pdf/b511a4efc83d5d90d27de753515873b9a2db5a1c.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=EAtSPyQ09Z,{'value': 'ShapeX: Shapelet-Driven Post Hoc Explanations for Time Series Classification Models'},Bosong Huang; Ming Jin; Yuxuan Liang; Johan Barthelemy; Debo Cheng; Qingsong Wen; Chenghao Liu; Shirui Pan,~Bosong_Huang1; ~Ming_Jin3; ~Yuxuan_Liang1; ~Johan_Barthelemy1; ~Debo_Cheng1; ~Qingsong_Wen2; ~Chenghao_Liu1; ~Shirui_Pan1,"{'value': ['Explainability', 'Time Series Classification', 'Shapelet']}","{'value': 'Explaining time series classification models is crucial, particularly in high-stakes applications such as healthcare and finance, where transparency and trust play a critical role. Although numerous time series classification methods have identified key subsequences, known as shapelets, as core features for achieving state-of-the-art performance and validating their pivotal role in classification outcomes, existing post-hoc time series explanation (PHTSE) methods primarily focus on timestep-level feature attribution. These explanation methods overlook the fundamental prior that classification outcomes are predominantly driven by key shapelets. To bridge this gap, we present ShapeX, an innovative framework that segments time series into meaningful shapelet-driven segments and employs Shapley values to assess their saliency. At the core of ShapeX lies the Shapelet Describe-and-Detect (SDD) framework, which effectively learns a diverse set of shapelets essential for classification. We further demonstrate that ShapeX produces explanations which reveal causal relationships instead of just correlations, owing to the atomicity properties of shapelets. Experimental results on both synthetic and real-world datasets demonstrate that ShapeX outperforms existing methods in identifying the most relevant subsequences, enhancing both the precision and causal fidelity of time series explanations.'}",https://openreview.net{'value': '/pdf/651f51b5d9fd2fa80aa59a3652e5c3b31a318c46.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=EATkC9iHE3,{'value': 'RLGF: Reinforcement Learning with Geometric Feedback for Autonomous Driving Video Generation'},Tianyi Yan; Wencheng Han; xia zhou; Xueyang Zhang; Kun Zhan; Cheng-zhong Xu; Jianbing Shen,~Tianyi_Yan2; ~Wencheng_Han1; ~xia_zhou3; ~Xueyang_Zhang1; ~Kun_Zhan3; ~Cheng-zhong_Xu1; ~Jianbing_Shen1,"{'value': ['video generation', 'diffusion model', 'autonomous driving']}","{'value': 'Synthetic data is crucial for advancing autonomous driving (AD) systems, yet current state-of-the-art video generation models, despite their visual realism, suffer from subtle geometric distortions that limit their utility for downstream perception tasks. \nWe identify and quantify this critical issue, demonstrating a significant performance gap in 3D object detection when using synthetic versus real data.\nTo address this, we introduce Reinforcement Learning with Geometric Feedback (RLGF), RLGF uniquely refines video diffusion models by incorporating rewards from specialized latent-space AD perception models. \nIts core components include an efficient Latent-Space Windowing Optimization technique for targeted feedback during diffusion, and a Hierarchical Geometric Reward (HGR) system providing multi-level rewards for point-line-plane alignment, and scene occupancy coherence. \nTo quantify these distortions, we propose GeoScores. Applied to models like DiVE on nuScenes, RLGF substantially reduces geometric errors (e.g., VP error by 21\\%, Depth error by 57\\%) and dramatically improves 3D object detection mAP by 12.7\\%, narrowing the gap to real-data performance. RLGF offers a plug-and-play solution for generating geometrically sound and reliable synthetic videos for AD development.'}",https://openreview.net{'value': '/pdf/8b4d444543586225a5063e12afc6cf6ddd469eb5.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=E3oNDQ8e9r,{'value': 'GSRF: Complex-Valued 3D Gaussian Splatting for Efficient Radio-Frequency Data Synthesis'},Kang Yang; Gaofeng Dong; Sijie JI; Wan Du; Mani Srivastava,~Kang_Yang8; ~Gaofeng_Dong1; ~Sijie_JI1; ~Wan_Du1; ~Mani_Srivastava1,"{'value': ['3D Gaussian Splatting', 'Complex-Valued Modeling', 'RF Data Synthesis']}","{'value': 'Synthesizing radio-frequency (RF) data given the transmitter and receiver positions, e.g., received signal strength indicator (RSSI), is critical for wireless networking and sensing applications, such as indoor localization. However, it remains challenging due to complex propagation interactions, including reflection, diffraction, and scattering. State-of-the-art neural radiance field (NeRF)-based methods achieve high-fidelity RF data synthesis but are limited by long training times and high inference latency. We introduce GSRF, a framework that extends 3D Gaussian Splatting (3DGS) from the optical domain to the RF domain, enabling efficient RF data synthesis. GSRF realizes this adaptation through three key innovations: First, it introduces complex-valued 3D Gaussians with a hybrid Fourier–Legendre basis to model directional and phase-dependent radiance. Second, it employs orthographic splatting for efficient ray–Gaussian intersection identification. Third, it incorporates a complex-valued ray tracing algorithm, executed on RF-customized CUDA kernels and grounded in wavefront propagation principles, to synthesize RF data in real time. Evaluated across various RF technologies, GSRF preserves high-fidelity RF data synthesis while achieving significant improvements in training efficiency, shorter training time, and reduced inference latency.'}",https://openreview.net{'value': '/pdf/d8a4d456cd63b860846b6c4472af50f2b3667ca9.pdf'},{'title_filter': 'Data Synthesis'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=E16vULI6AF,{'value': 'Deciphering the Extremes: A Novel Approach for Pathological Long-tailed Recognition in Scientific Discovery'},Zhe Zhao; HaiBin Wen; Xianfu Liu; Rui Mao; Pengkun Wang; Liheng Yu; Linjiang Chen; Bo An; Qingfu Zhang; Yang Wang,~Zhe_Zhao5; ~HaiBin_Wen1; ~Xianfu_Liu1; ~Rui_Mao4; ~Pengkun_Wang1; ~Liheng_Yu1; ~Linjiang_Chen1; ~Bo_An2; ~Qingfu_Zhang1; ~Yang_Wang32,"{'value': ['Long-tailed learning', 'Imbalanced datasets']}","{'value': ""Scientific discovery across diverse fields increasingly grapples with datasets exhibiting pathological long-tailed distributions: a few common phenomena overshadow a multitude of rare yet scientifically critical instances. Unlike standard benchmarks, these scientific datasets often feature extreme imbalance coupled with a modest number of classes and limited overall sample volume, rendering existing long-tailed recognition (LTR) techniques ineffective. Such methods, biased by majority classes or prone to overfitting on scarce tail data, frequently fail to identify the very instances—novel materials, rare disease biomarkers, faint astronomical signals—that drive scientific breakthroughs. This paper introduces a novel, end-to-end framework explicitly designed to address pathological long-tailed recognition in scientific contexts. Our approach synergizes a Balanced Supervised Contrastive Learning (B-SCL) mechanism, which enhances the representation of tail classes by dynamically re-weighting their contributions, with a Smooth Objective Regularization (SOR) strategy that manages the inherent tension between tail-class focus and overall classification performance. We introduce and analyze the real-world ZincFluor chemical dataset ($\\mathcal{T}=137.54$) and synthetic benchmarks with controllable extreme imbalances (CIFAR-LT variants). Extensive evaluations demonstrate our method's superior ability to decipher these extremes. Notably, on ZincFluor, our approach achieves a Tail Top-2 accuracy of $66.84\\%$, significantly outperforming existing techniques. On CIFAR-10-LT with an imbalance ratio of $1000$ ($\\mathcal{T}=100$), our method achieves a tail-class accuracy of $38.99\\%$, substantially leading the next best. These results underscore our framework's potential to unlock novel insights from complex, imbalanced scientific datasets, thereby accelerating discovery.""}",https://openreview.net{'value': '/pdf/ec247f17bcabd9d6394f36e03ca23ba56439f017.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=E0cjqfM55C,{'value': 'Learning Interactive World Model for Object-Centric Reinforcement Learning'},Fan Feng; Phillip Lippe; Sara Magliacane,~Fan_Feng2; ~Phillip_Lippe1; ~Sara_Magliacane1,"{'value': ['World Model', 'Object-Centric RL']}","{'value': 'Agents that understand objects and their interactions can learn policies that are more robust and transferable. However, most object-centric RL methods factor state by individual objects while leaving interactions implicit. We introduce the Factored Interactive Object-Centric World Model (FIOC-WM), a unified framework that learns structured representations of both objects and their interactions within a world model. FIOC-WM captures environment dynamics with disentangled and modular representations of object interactions, improving sample efficiency and generalization for policy learning. Concretely, FIOC-WM first learns object-centric latents and an interaction structure directly from pixels, leveraging pre-trained vision encoders. The learned world model then decomposes tasks into composable interaction primitives, and a hierarchical policy is trained on top: a high level selects the type and order of interactions, while a low level executes them. On simulated robotic and embodied-AI benchmarks, FIOC-WM improves policy-learning sample efficiency and generalization over world-model baselines, indicating that explicit, modular interaction learning is crucial for robust control.'}",https://openreview.net{'value': '/pdf/66f1b36008267ba8f2a4d5c9c244c1481dd27825.pdf'},{'abstract_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=DrBwhFUqCY,{'value': 'When Models Don’t Collapse: On the Consistency of Iterative MLE'},Daniel Barzilai; Ohad Shamir,~Daniel_Barzilai1; ~Ohad_Shamir1,"{'value': ['Model Collapse', 'Generative Models', 'Maximum Likelihood', 'Generalization']}","{'value': 'The widespread use of generative models has created a feedback loop in which each generation of models is trained on data partially produced by its predecessors. This process has raised concerns about model collapse: A critical degradation in performance caused by repeated training on synthetic data. However, different analyses in the literature have reached different conclusions as to the severity of model collapse. As such, it remains unclear how concerning this phenomenon is, and under which assumptions it can be avoided. To address this, we theoretically study model collapse for maximum likelihood estimation (MLE), in a natural setting where synthetic data is gradually added to the original training set. Under standard assumptions (similar to those long used for proving asymptotic consistency and normality of MLE), we establish non-asymptotic bounds showing that collapse can be avoided even as the fraction of real data vanishes. On the other hand, we prove that some assumptions (beyond MLE consistency) are indeed necessary: Without them, model collapse can occur arbitrarily quickly, even when the original data is still present in the training set. To the best of our knowledge, these are the first rigorous examples of iterative generative modeling with accumulating data that rapidly leads to model collapse.'}",https://openreview.net{'value': '/pdf/9eef350486524f4f69f724c9fad3d4269caf357e.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=DorAT49sxj,{'value': 'WALL-E: World Alignment by NeuroSymbolic Learning improves World Model-based LLM Agents'},Siyu Zhou; Tianyi Zhou; Yijun Yang; Guodong Long; Deheng Ye; Jing Jiang; Chengqi Zhang,~Siyu_Zhou2; ~Tianyi_Zhou2; ~Yijun_Yang3; ~Guodong_Long1; ~Deheng_Ye1; ~Jing_Jiang6; ~Chengqi_Zhang1,"{'value': ['world model', 'embodied agent', 'large language model', 'neurosymbolic learning']}","{'value': 'Can we build accurate world models out of large language models (LLMs)? How can world models benefit LLM agents? The gap between the prior knowledge of LLMs and the specified environment\'s dynamics usually bottlenecks LLMs\' performance as world models. To bridge the gap, we propose a training-free ""world alignment"" that learns an environment\'s symbolic knowledge complementary to LLMs. The symbolic knowledge covers action rules, knowledge graphs, and scene graphs, which are extracted by LLMs from exploration trajectories and encoded into executable codes to regulate LLM agents\' policies. We further propose an RL-free, model-based agent ""WALL-E"" through the model-predictive control (MPC) framework. Unlike classical MPC requiring costly optimization on the fly, we adopt an LLM agent as an efficient look-ahead optimizer of future steps\' actions by interacting with the neurosymbolic world model. While the LLM agent\'s strong heuristics make it an efficient planner in MPC, the quality of its planned actions is also secured by the accurate predictions of the aligned world model. They together considerably improve learning efficiency in a new environment. On open-world challenges in Mars (Minecraft like) and ALFWorld (embodied indoor environments), WALL-E significantly outperforms existing methods, e.g., surpassing baselines in Mars by 16.1%–51.6% of success rate and by at least 61.7% in score. In ALFWorld, it achieves a new record 98% success rate after only 4 iterations.'}",https://openreview.net{'value': '/pdf/4a70c0605cac16a41fee061564452113f886243a.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=DghZGQDTaD,{'value': 'Encouraging metric-aware diversity in contrastive representation space'},Tianxu Li; Kun Zhu,~Tianxu_Li1; ~Kun_Zhu1,"{'value': ['Multi-agent reinforcement learning', 'Exploration', 'Multi-agent diversity', 'Wasserstein distance']}","{'value': 'In cooperative Multi-Agent Reinforcement Learning (MARL), agents that share policy network parameters often learn similar behaviors, which hinders effective exploration and can lead to suboptimal cooperative policies. Recent advances have attempted to promote multi-agent diversity by leveraging the Wasserstein distance to increase policy differences. However, these methods cannot effectively encourage diverse policies due to ineffective Wasserstein distance caused by the policy similarity. To address this limitation, we propose Wasserstein Contrastive Diversity (WCD) exploration, a novel approach that promotes multi-agent diversity by maximizing the Wasserstein distance between the trajectory distributions of different agents in a latent representation space. To make the Wasserstein distance meaningful, we propose a novel next-step prediction method based on Contrastive Predictive Coding (CPC) to learn distinguishable trajectory representations. Additionally, we introduce an optimized kernel-based method to compute the Wasserstein distance more efficiently. Since the Wasserstein distance is inherently defined for two distributions, we extend it to support multiple agents, enabling diverse policy learning. Empirical evaluations across a variety of challenging multi-agent tasks demonstrate that WCD outperforms existing state-of-the-art methods, delivering superior performance and enhanced exploration.'}",https://openreview.net{'value': '/pdf/d588efe6fd066bcfdda24005cb0ab0f80fdce804.pdf'},{'abstract_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=DZnBoIAy4V,{'value': 'Assignments for Congestion-Averse Agents: Seeking Competitive and Envy-Free Solutions'},Jiehua Chen; Jiong Guo; Yinghui Wen,~Jiehua_Chen1; ~Jiong_Guo2; ~Yinghui_Wen1,"{'value': ['Fair resource allocation', 'preferences with congestion aversion', 'congestion games', 'polynomial-time algorithms', 'complexity analysis']}","{'value': 'We investigate congested assignment problems where agents have preferences over both resources and their associated congestion levels. These agents are \\emph{averse} towards congestion, i.e., consistently preferring lower congestion for identical resources. Such scenarios are ubiquitous across domains including traffic management and school choice, where fair resource allocation is essential. We focus on the concept of \\emph{competitiveness}, recently introduced by Bogomolnaia and Moulin [6], and contribute a polynomial-time algorithm that determines competitiveness, resolving their open question. Additionally, we explore two optimization variants of congested assignments by examining the problem of finding envy-free or maximally competitive assignments that guarantee a certain amount of social welfare for every agent, termed \\emph{top-guarantees} [6]. While we prove that both problems are NP-hard, we develop parameterized algorithms with respect to the number of agents or resources.'}",https://openreview.net{'value': '/pdf/9f652d768a7afde3c141ee1c05e8d8bfacb86fa7.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=DYuPwwDy9n,{'value': 'Reinforcement Learning with Imperfect Transition Predictions: A Bellman-Jensen Approach'},Chenbei Lu; Zaiwei Chen; Tongxin Li; Chenye Wu; Adam Wierman,~Chenbei_Lu1; ~Zaiwei_Chen1; ~Tongxin_Li1; ~Chenye_Wu1; ~Adam_Wierman1,"{'value': ['Reinforcement Learning', 'Markov Decision Processes', 'Transition Prediction', 'Bellman-Jensen Gap', 'Sample Complexity']}","{'value': 'Traditional reinforcement learning (RL) assumes the agents make decisions based on Markov decision processes (MDPs) with one-step transition models. In many real-world applications, such as energy management and stock investment, agents can access multi-step predictions of future states, which provide additional advantages for decision making. However, multi-step predictions are inherently high-dimensional: naively embedding these predictions into an MDP leads to an exponential blow-up in state space and the curse of dimensionality. Moreover, existing RL theory provides few tools to analyze prediction-augmented MDPs, as it typically works on one-step transition kernels and cannot accommodate multi-step predictions with errors or partial action-coverage. We address these challenges with three key innovations: First, we propose the \\emph{Bayesian value function} to characterize the optimal prediction-aware policy tractably. Second, we develop a novel \\emph{Bellman–Jensen Gap} analysis on the Bayesian value function, which enables characterizing the value of imperfect predictions. Third, we introduce BOLA (Bayesian Offline Learning with Online Adaptation), a two-stage model-based RL algorithm that separates offline Bayesian value learning from lightweight online adaptation to real-time predictions. We prove that BOLA remains sample-efficient even under imperfect predictions. We validate our theory and algorithm on synthetic MDPs and a real-world wind energy storage control problem.'}",https://openreview.net{'value': '/pdf/772e77c64f558f9df89b7c750c36b0926c4de579.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=D88yhLFzDR,{'value': 'The Lighthouse of Language: Enhancing LLM Agents via Critique-Guided Improvement'},Ruihan Yang; Fanghua Ye; Jian Li; Siyu Yuan; Yikai Zhang; Zhaopeng Tu; Xiaolong Li; Deqing Yang,~Ruihan_Yang3; ~Fanghua_Ye1; ~Jian_Li17; ~Siyu_Yuan2; ~Yikai_Zhang6; ~Zhaopeng_Tu1; ~Xiaolong_Li4; ~Deqing_Yang1,"{'value': ['Large language model', 'Language agent', 'Agent learning']}","{'value': 'Large language models (LLMs) have recently transformed from text-based assistants to autonomous agents capable of planning, reasoning, and iteratively improving their actions. While numerical reward signals and verifiers can effectively rank candidate actions, they often provide limited contextual guidance. In contrast, natural language feedback better aligns with the generative capabilities of LLMs, providing richer and more actionable suggestions. However, parsing and implementing this feedback effectively can be challenging for LLM-based agents. In this work, we introduce Critique-Guided Improvement (CGI), a novel two-player framework, comprising an actor model that explores an environment and a critic model that generates detailed nature language feedback. By training the critic to produce fine-grained assessments and actionable revisions, and the actor to utilize these critiques, our approach promotes more robust exploration of alternative strategies while avoiding local optima. Experiments in three interactive environments show that CGI outperforms existing baselines by a substantial margin. Notably, even a small critic model surpasses GPT-4 in feedback quality. The resulting actor achieves state-of-the-art performance, demonstrating the power of explicit iterative guidance to enhance decision-making in LLM-based agents.'}",https://openreview.net{'value': '/pdf/ae3bf83043c88b4e28668b095624b19cc07ed197.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=D1Iw4Unvfc,{'value': 'ReAgent-V: A Reward-Driven Multi-Agent Framework for Video Understanding'},Yiyang Zhou; Yangfan He; Yaofeng Su; Siwei Han; Joel Jang; Gedas Bertasius; Mohit Bansal; Huaxiu Yao,~Yiyang_Zhou1; ~Yangfan_He1; ~Yaofeng_Su1; ~Siwei_Han1; ~Joel_Jang1; ~Gedas_Bertasius1; ~Mohit_Bansal2; ~Huaxiu_Yao1,{'value': ['Video understanding; Multi-agent framework; Reflective reasoning; VLA alignment; Video reasoning']},"{'value': 'Video understanding is fundamental to tasks such as action recognition, video reasoning, and robotic control. Early video understanding methods based on large vision-language models (LVLMs) typically adopt a single-pass reasoning paradigm without dynamic feedback, limiting the model’s capacity to self-correct and adapt in complex scenarios. Recent efforts have attempted to address this limitation by incorporating reward models and reinforcement learning to enhance reasoning, or by employing tool-agent frameworks. However, these approaches face several challenges, including high annotation costs, reward signals that fail to capture real-time reasoning states, and low inference efficiency. To overcome these issues, we propose ReAgent-V, a novel agentic video understanding framework that integrates efficient frame selection with real-time reward generation during inference. These reward signals not only guide iterative answer refinement through a multi-perspective reflection mechanism—adjusting predictions from conservative, neutral, and aggressive viewpoints—but also enable automatic filtering of high-quality data for supervised fine-tuning (SFT), direct preference optimization (DPO), and group relative policy optimization (GRPO). ReAgent-V is lightweight, modular, and extensible, supporting flexible tool integration tailored to diverse tasks. Extensive experiments on 12 datasets across three core applications—video understanding, video reasoning enhancement, and vision-language-action model alignment—demonstrate significant gains in generalization and reasoning, with improvements of up to 6.9%, 2.1%, and 9.8%, respectively, highlighting the effectiveness and versatility of the proposed framework.'}",https://openreview.net{'value': '/pdf/6d161d5f3d882ca658ad735bc6b9ad5b35e62169.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=CrwzbjO3aU,{'value': 'Multi-Agent Learning under Uncertainty: Recurrence vs. Concentration'},Kyriakos Lotidis; Panayotis Mertikopoulos; Nicholas Bambos; Jose Blanchet,~Kyriakos_Lotidis1; ~Panayotis_Mertikopoulos1; ~Nicholas_Bambos1; ~Jose_Blanchet1,"{'value': ['game theory', 'Nash equilibrium', 'uncertainty', 'regularized learning']}","{'value': 'In this paper, we examine the convergence landscape of multi-agent learning under uncertainty. Specifically, we analyze two stochastic models of regularized learning in continuous games—one in continuous and one in discrete time—with the aim of characterizing the long run behavior of the induced sequence of play. In stark contrast to deterministic, full-information models of learning (or models with a vanishing learning rate), we show that the resulting dynamics do not converge in general. In lieu of this, we ask instead which actions are played more often in the long run, and by how much. We show that, in strongly monotone games, the dynamics of regularized learning may wander away from equilibrium infinitely often, but they always return to its vicinity in finite time (which we estimate), and their long-run distribution is sharply concentrated around a neighborhood thereof. We quantify the degree of this concentration, and we show that these favorable properties may all break down if the underlying game is not strongly monotone—underscoring in this way the limits of regularized learning in the presence of persistent randomness and uncertainty'}",https://openreview.net{'value': '/pdf/ec6f2f6767f6101591ddc5ab8f2c7738be21f501.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=CmY6DzEG7Z,{'value': 'NOBLE - Neural Operator with Biologically-informed Latent Embeddings to Capture Experimental Variability in Biological Neuron Models'},Luca Ghafourpour; Valentin Duruisseaux; Bahareh Tolooshams; Philip H. Wong; Costas A. Anastassiou; Anima Anandkumar,~Luca_Ghafourpour1; ~Valentin_Duruisseaux1; ~Bahareh_Tolooshams1; ~Philip_H._Wong1; ~Costas_A._Anastassiou1; ~Anima_Anandkumar1,"{'value': ['Computational Neuroscience', 'Neural Dynamics', 'Neural Operators', 'Ensemble Surrogate Modeling', 'Interpretable Latent Embeddings']}","{'value': 'Characterizing the cellular properties of  neurons is fundamental to understanding their function in the brain. In this quest, the generation of bio-realistic models is central towards integrating multimodal cellular data sets and establishing causal relationships. However, current modeling approaches remain constrained by the limited availability and intrinsic variability of experimental neuronal data. The deterministic formalism of bio-realistic models currently precludes accounting for the natural variability observed experimentally. While deep learning is becoming increasingly relevant in this space, it fails to capture the full biophysical complexity of neurons, their nonlinear voltage dynamics, and variability. To address these shortcomings, we introduce $\\texttt{NOBLE}$, a neural operator framework that learns a mapping from a continuous frequency-modulated embedding of interpretable neuron features to the somatic voltage response induced by current injection. Trained on synthetic data generated from bio-realistic neuron models, $\\texttt{NOBLE}$ predicts distributions of neural dynamics accounting for the intrinsic experimental variability. Unlike conventional bio-realistic neuron models, interpolating within the embedding space offers models whose dynamics are consistent with experimentally observed responses. $\\texttt{NOBLE}$ enables the efficient generation of synthetic neurons that closely resemble experimental data and exhibit trial-to-trial variability, offering a $4200$× speedup over the numerical solver. $\\texttt{NOBLE}$ is the first scaled-up deep learning framework that validates its generalization with real experimental data. To this end, $\\texttt{NOBLE}$ captures fundamental neural properties in a unique and emergent manner that opens the door to a better understanding of cellular composition and computations, neuromorphic architectures, large-scale brain circuits, and general neuroAI applications.'}",https://openreview.net{'value': '/pdf/9897d6695150332b6fb368280bfbfe999b86b979.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=Cl45XdnCoK,{'value': 'SpecMAS: A Multi-Agent System for Self-Verifying System Generation via Formal Model Checking'},Rishabh Agrawal; Kaushik Tushar Ranade; Aja Khanal; Kalyan Shankar Basu; Apurva Narayan,~Rishabh_Agrawal3; ~Kaushik_Tushar_Ranade1; ~Aja_Khanal1; ~Kalyan_Shankar_Basu1; ~Apurva_Narayan1,"{'value': ['Multi-agent systems', 'formal verification', 'temporal logic', 'specification generation', 'model-checking', 'Large Language Models']}","{'value': 'We present SpecMAS, a novel multi-agent system that autonomously constructs and formally verifies executable system models from natural language specifications. Given a Standard Operating Procedure (SOP) describing a target system, SpecMAS parses the specification, identifies relevant operational modes, variables, transitions, and properties, and generates a formal model in NuSMV code syntax, an industry-standard symbolic model checker. A dedicated reasoning agent extracts both explicit and implicit properties from the SOP, and verification is performed via temporal logic model checking. If any properties fail to verify, an autonomous debugging agent analyzes counterexamples and iteratively corrects the model until all properties are satisfied. This closed-loop system design guarantees provable correctness by construction and advances the state of the art in automated, interpretable, and deployable verification pipelines. We demonstrate the generality, correctness, and practical feasibility of SpecMAS across a set of representative case studies and propose a new benchmark dataset for the evaluation and comparison of model checking performance.'}",https://openreview.net{'value': '/pdf/d2baf726e03709dc05beda305bd6ede14d1a9b1b.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=CYh2VrTM8N,{'value': 'Median Selection with  Noisy  and Structural Information'},Chenglin Fan; Mingyu Kang,~Chenglin_Fan1; ~Mingyu_Kang3,"{'value': ['median selection', 'unreliable oracles', 'persistent comparison model', 'lazy select algorithm', 'partially ordered data']}","{'value': ""We study the problem of computing the exact median by leveraging side information to minimize costly, exact comparisons. \nWe analyze this problem in two key settings: \n(1) using predictions from unreliable 'weak' oracles, and \n(2) exploiting known structural information in the form of a partial order. In the classical setting, we introduce a modified LazySelect algorithm that combines weak comparisons with occasional strong comparisons through majority voting. We show that this hybrid strategy has near-linear running time and can achieve high-probability correctness using only sublinear strong comparisons, even when the weak oracle is only slightly better than random guessing.  Our theoretical results hold under the persistent comparison model, where resampling will not amplify the probability of correctness. In the partially ordered setting, we generalize the notion of median to directed acyclic graphs (DAGs) and show that the complexity of median selection depends heavily on the DAG's width. We complement our analysis with extensive experiments on synthetic data.""}",https://openreview.net{'value': '/pdf/7cdf585218214d3278dc2c0da741ed12d73cca71.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=CVp0WCw4a1,{'value': 'Over-squashing in Spatiotemporal Graph Neural Networks'},Ivan Marisca; Jacob Bamberger; Cesare Alippi; Michael M. Bronstein,~Ivan_Marisca1; ~Jacob_Bamberger1; ~Cesare_Alippi1; ~Michael_M._Bronstein1,"{'value': ['Graph Neural Networks', 'Spatiotemporal Graph Neural Networks', 'Over-squashing', 'Time Series Processing', 'Time Series Forecasting']}","{'value': 'Graph Neural Networks (GNNs) have achieved remarkable success across various domains. However, recent theoretical advances have identified fundamental limitations in their information propagation capabilities, such as over-squashing, where distant nodes fail to effectively exchange information. While extensively studied in static contexts, this issue remains unexplored in Spatiotemporal GNNs (STGNNs), which process sequences associated with graph nodes. Nonetheless, the temporal dimension amplifies this challenge by increasing the information that must be propagated. In this work, we formalize the spatiotemporal over-squashing problem and demonstrate its distinct characteristics compared to the static case. Our analysis reveals that, counterintuitively, convolutional STGNNs favor information propagation from points temporally distant rather than close in time. Moreover, we prove that architectures that follow either time-and-space or time-then-space processing paradigms are equally affected by this phenomenon, providing theoretical justification for computationally efficient implementations. We validate our findings on synthetic and real-world datasets, providing deeper insights into their operational dynamics and principled guidance for more effective designs.'}",https://openreview.net{'value': '/pdf/13f511ca0082740974ac4289f97b40b59876ea9c.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=CTsdZ3j6dR,{'value': 'Mean-Field Sampling for Cooperative Multi-Agent Reinforcement Learning'},Emile Timothy Anand; Ishani Karmarkar; Guannan Qu,~Emile_Timothy_Anand1; ~Ishani_Karmarkar1; ~Guannan_Qu1,"{'value': ['multi-agent reinforcement learning', 'mean-field RL', 'online decision making', 'sampling theory', 'large-scale systems']}","{'value': 'Designing efficient algorithms for multi-agent reinforcement learning (MARL) is fundamentally challenging because the size of the joint state and action spaces grows exponentially in the number of agents. These difficulties are exacerbated when balancing sequential global decision-making with local agent interactions. In this work, we propose a new algorithm $\\texttt{SUBSAMPLE-MFQ}$ ($\\textbf{Subsample}$-$\\textbf{M}$ean-$\\textbf{F}$ield-$\\textbf{Q}$-learning) and a decentralized randomized policy for a system with $n$ agents. For any $k\\leq n$, our algorithm learns a policy for the system in time polynomial in $k$. We prove that this learned policy converges to the optimal policy on the order of $\\tilde{O}(1/\\sqrt{k})$ as the number of subsampled agents $k$ increases. In particular, this bound is independent of the number of agents $n$.'}",https://openreview.net{'value': '/pdf/8068654df0bddeccc848d58d7a46cdd76f4ba670.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=CH76rSKWZr,{'value': 'Test-Time Adaptation of Vision-Language Models for Open-Vocabulary Semantic Segmentation'},Mehrdad Noori; David OSOWIECHI; Gustavo Adolfo Vargas Hakim; Ali Bahri; Moslem Yazdanpanah; Sahar Dastani; Farzad Beizaee; Ismail Ben Ayed; Christian Desrosiers,~Mehrdad_Noori1; ~David_OSOWIECHI1; ~Gustavo_Adolfo_Vargas_Hakim1; ~Ali_Bahri1; ~Moslem_Yazdanpanah1; ~Sahar_Dastani1; ~Farzad_Beizaee1; ~Ismail_Ben_Ayed1; ~Christian_Desrosiers1,"{'value': ['Computer Vision', 'Segmentation', 'Test Time Adaptation', 'Vision Language Models']}","{'value': 'Recently, test-time adaptation has attracted wide interest in the context of vision-language models for image classification. However, to the best of our knowledge, the problem is completely overlooked in dense prediction tasks such as Open-Vocabulary Semantic Segmentation (OVSS). In response, we propose a novel TTA method tailored to adapting VLMs for segmentation during test time. Unlike TTA methods for image classification, our Multi-Level and Multi-Prompt (MLMP) entropy minimization integrates features from intermediate vision-encoder layers and is performed with different text-prompt templates at both the global CLS token and local pixel-wise levels. \nOur approach could be used as plug-and-play for any segmentation network, does not require additional training data or labels, and remains effective even with a single test sample. Furthermore, we introduce a comprehensive OVSS TTA benchmark suite, which integrates a rigorous evaluation protocol, nine segmentation datasets, 15 common synthetic corruptions, and additional real and rendered domain shifts, with a total of 87 distinct test scenarios, establishing a standardized and comprehensive testbed for future TTA research in open-vocabulary segmentation. Our experiments on this suite demonstrate that our segmentation-tailored method consistently delivers significant gains over direct adoption of TTA classification baselines. Code and data are available at https://github.com/dosowiechi/MLMP.'}",https://openreview.net{'value': '/pdf/a296b5c8daed4ee61f44a993f0f069dd41c72dc7.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=CF6qEI6rH0,{'value': 'Latent Refinement via Flow Matching for Training-free Linear Inverse Problem Solving'},Hossein Askari; Yadan Luo; Hongfu Sun; Fred Roosta,~Hossein_Askari1; ~Yadan_Luo1; ~Hongfu_Sun1; ~Fred_Roosta1,"{'value': ['Inverse Problems', 'Flow Matching', 'Posterior Sampling', 'ODE-based Inference', 'Training-Free Methods']}","{'value': 'Recent advances in *inverse problem* solving have increasingly adopted flow *priors* over diffusion models due to their ability to construct straight probability paths from noise to data, thereby enhancing efficiency in both training and inference. However, current flow-based inverse solvers face two primary limitations: (i) they operate directly in pixel space, which demands heavy computational resources for training and restricts scalability to high-resolution images, and (ii) they employ guidance strategies with *prior*-agnostic posterior covariances, which can weaken alignment with the generative trajectory and degrade posterior coverage. In this paper, we propose **LFlow** (**L**atent Refinement via **Flow**s), a *training-free* framework for solving linear inverse problems via pretrained latent flow priors. LFlow leverages the efficiency of flow matching to perform ODE sampling in latent space along an optimal path. This latent formulation further allows us to introduce a theoretically grounded posterior covariance, derived from the optimal vector field, enabling effective flow guidance. Experimental results demonstrate that our proposed method outperforms state-of-the-art latent diffusion solvers in reconstruction quality across most tasks.'}",https://openreview.net{'value': '/pdf/0a4da110e57ec8596b86c6639407566df8ac782e.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=C39ShJwtD5,{'value': 'Dual Data Alignment Makes AI-Generated Image Detector Easier Generalizable'},Ruoxin Chen; Junwei Xi; Zhiyuan Yan; Ke-Yue Zhang; Shuang Wu; Jingyi Xie; Xu Chen; Lei Xu; Isabel Guan; Taiping Yao; Shouhong Ding,~Ruoxin_Chen1; ~Junwei_Xi1; ~Zhiyuan_Yan3; ~Ke-Yue_Zhang1; ~Shuang_Wu7; ~Jingyi_Xie3; ~Xu_Chen42; ~Lei_Xu21; ~Isabel_Guan1; ~Taiping_Yao2; ~Shouhong_Ding3,{'value': ['AIGC Detection']},"{'value': ""The rapid increase in AI-generated images (AIGIs) underscores the need for detection methods. \nExisting detectors are often trained on biased datasets, leading to overfitting on spurious correlations between non-causal image attributes and real/synthetic labels.\nWhile these biased features enhance performance on the training data, they result in substantial performance degradation when tested on unbiased datasets.\nA common solution is to perform data alignment through generative reconstruction, matching the content between real and synthetic images. \nHowever, we find that pixel-level alignment alone is inadequate, as the reconstructed images still suffer from frequency-level misalignment, perpetuating spurious correlations.\nTo illustrate, we observe that reconstruction models restore the high-frequency details lost in real images, inadvertently creating a frequency-level misalignment, where synthetic images appear to have richer high-frequency content than real ones. This misalignment leads to models associating high-frequency features with synthetic labels, further reinforcing biased cues.\nTo resolve this, we propose Dual Data Alignment (DDA), which aligns both the pixel and frequency domains. \nDDA generates synthetic images that closely resemble real ones by fusing real and synthetic image pairs in both domains, enhancing the detector's ability to identify forgeries without relying on biased features.\nMoreover, we introduce two new test sets: DDA-COCO, containing DDA-aligned synthetic images, and EvalGEN, featuring the latest generative models. Our extensive evaluations demonstrate that a detector trained exclusively on DDA-aligned MSCOCO improves across diverse benchmarks. \nCode is available at https://github.com/roy-ch/Dual-Data-Alignment.""}",https://openreview.net{'value': '/pdf/5d2bec1a1b8624fa782255d71996498a72a45f85.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=BuYtcTUMyA,{'value': 'AgentTTS: Large Language Model Agent for Test-time Compute-optimal Scaling Strategy in Complex Tasks'},Fali Wang; Hui Liu; Zhenwei DAI; Jingying Zeng; Zhiwei Zhang; Zongyu Wu; Chen Luo; Zhen Li; Xianfeng Tang; Qi He; Suhang Wang,~Fali_Wang1; ~Hui_Liu3; ~Zhenwei_DAI1; ~Jingying_Zeng1; ~Zhiwei_Zhang10; ~Zongyu_Wu1; ~Chen_Luo3; ~Zhen_Li16; ~Xianfeng_Tang1; ~Qi_He5; ~Suhang_Wang1,"{'value': ['language models', 'scaling', 'test-time compute', 'compute-optimal inference']}","{'value': 'Test-time scaling (TTS) enhances the performance of large language models (LLMs) by allocating additional compute resources during inference. However, existing research primarily investigates TTS in single-stage tasks; while many real-world problems are multi-stage complex tasks, composed of a sequence of heterogeneous subtasks with each subtask requires LLM of specific capability. Therefore, we study a novel problem: the test-time compute-optimal scaling in multi-stage complex tasks, aiming to select suitable models and allocate budgets per subtask to maximize overall performance. TTS in multi-stage tasks introduces two fundamental challenges: (i) The combinatorial search space of model and budget allocations, combined with the high cost of inference, makes brute-force search impractical. (ii) The optimal model and budget allocations across subtasks are interdependent, increasing the complexity of the compute-optimal search. To address this gap, we conduct extensive pilot experiments on four tasks across six datasets, deriving three empirical insights characterizing the behavior of LLMs in multi-stage complex tasks. Informed by these insights, we propose AgentTTS, an LLM-agent-based framework that autonomously searches for compute-optimal allocations through iterative feedback-driven interactions with the execution environment. Experimental results demonstrate that AgentTTS significantly outperforms traditional and other LLM-based baselines in search efficiency, and shows improved robustness to varying training set sizes and enhanced interpretability.'}",https://openreview.net{'value': '/pdf/13ea5abf7135c2269571122e956e24009565de1f.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=Bkyl98YQRa,{'value': 'A Data-Driven Prism: Multi-View Source Separation with Diffusion Model Priors'},Sebastian Wagner-Carena; Aizhan Akhmetzhanova; Sydney Erickson,~Sebastian_Wagner-Carena1; ~Aizhan_Akhmetzhanova1; ~Sydney_Erickson1,"{'value': ['Diffusion', 'Source Separation', 'Score-Based', 'Linear Mixing Models', 'Expectation-Maximization', 'Unsupervised Methods']}","{'value': 'In the natural sciences, a common challenge is to disentangle distinct, unknown sources from observations. Examples of this source separation task include deblending galaxies in a crowded field, distinguishing the activity of individual neurons from overlapping signals, and separating seismic events from the ambient background. Traditional analyses often rely on simplified source models that fail to accurately reproduce the data. Recent advances have shown that diffusion models can directly learn complex prior distributions from noisy, incomplete data. In this work, we show that diffusion models can solve the source separation problem without explicit assumptions about the source. Our method relies only on multiple views, or the property that different sets of observations contain different linear transformations of the unknown sources. We show that our method succeeds even when no source is individually observed and the observations are noisy, incomplete, and vary in resolution. The learned diffusion models enable us to sample from the source priors, evaluate the probability of candidate sources, and draw from the joint posterior of our sources given an observation. We demonstrate the effectiveness of our method on a range of synthetic problems as well as real-world galaxy observations.'}",https://openreview.net{'value': '/pdf/c8828a6aaedf9300a585894fa0284d94e3edd793.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=BgwtOwFSvY,{'value': 'Flow based approach for Dynamic Temporal Causal models with non-Gaussian or Heteroscedastic Noises'},Abdellah Rahmani; Pascal Frossard,~Abdellah_Rahmani1; ~Pascal_Frossard1,"{'value': ['Bayesian structure learning', 'Bayesian expectation maximisation', 'non stationarity', 'time series', 'heteroscedasticity']}","{'value': ""Understanding causal relationships in multivariate time series is crucial in many scenarios, such as those dealing with financial or neurological data. Many such time series exhibit multiple regimes, i.e., consecutive temporal segments with a priori unknown boundaries, with each regime having its own causal structure. Inferring causal dependencies and regime shifts is critical for analyzing the underlying processes. However, causal structure learning in this setting is challenging due to (1) non-stationarity, i.e., each regime can have its own causal graph and mixing function, and (2) complex noise distributions, which may be non-Gaussian or heteroscedastic. Existing causal discovery approaches cannot address these challenges, since generally assume stationarity or Gaussian noise with constant variance. Hence, we introduce FANTOM, a unified framework for causal discovery that handles non-stationary processes along with non-Gaussian and heteroscedastic noises. FANTOM simultaneously infers the number of regimes and their corresponding indices and learns each regime’s Directed Acyclic Graph. It uses a Bayesian Expectation Maximization algorithm that maximizes the evidence lower bound of the data log-likelihood. On the theoretical side, we prove, under mild assumptions, that temporal heteroscedastic causal models, introduced in FANTOM's formulation, are identifiable in both stationary and non-stationary settings. In addition, extensive experiments on synthetic and real data show that FANTOM outperforms existing methods.""}",https://openreview.net{'value': '/pdf/8e6d0dc2f9e12de3d9936119be0a8e9838c54036.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=BeSFxKX3Po,{'value': 'Identifying interactions across brain areas while accounting for individual-neuron dynamics with a Transformer-based variational autoencoder'},Qi Xin; Robert Kass,~Qi_Xin6; ~Robert_Kass1,"{'value': ['functional connectivity', 'neural spike train modeling', 'trial-to-trial variation', 'point process', 'generalized linear models', 'deep latent variable models']}","{'value': 'Advances in large-scale recording technologies now enable simultaneous measurements from multiple brain areas, offering new opportunities to study signal transmission across interacting components of neural circuits. However, neural responses exhibit substantial trial-to-trial variability, often driven by unobserved factors such as subtle changes in animal behavior or internal states. To prevent evolving background dynamics from contaminating identification of functional coupling, we developed a hybrid neural spike train model, GLM-Transformer, that incorporates flexible, deep latent variable models into a point process generalized linear model (GLM) having an interpretable component for cross-population interactions. A Transformer-based variational autoencoder captures nonstationary individual-neuron dynamics that vary across trials, while standard nonparametric regression GLM coupling terms provide estimates of directed interactions between neural populations. We incorporate a low-rank structure on population-to-population coupling effects to improve scalability. Across synthetic datasets and mechanistic simulations, GLM-Transformer recovers known coupling structure and remains robust to shared background fluctuations. When applied to the Allen Institute Visual Coding dataset, it identifies feedforward pathways consistent with established visual hierarchies. This work offers a step toward improved identification of neural population interactions, and contributes to ongoing efforts aimed at achieving interpretable results while harvesting the benefits of deep learning.'}",https://openreview.net{'value': '/pdf/098b8bf836732919dffd481023be0e249c5124db.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=BSZqpqgqM0,{'value': 'Why Diffusion Models Don’t Memorize:  The Role of Implicit Dynamical Regularization in Training'},Tony Bonnaire; Raphaël Urfin; Giulio Biroli; Marc Mezard,~Tony_Bonnaire1; ~Raphaël_Urfin1; ~Giulio_Biroli1; ~Marc_Mezard1,"{'value': ['Diffusion Models', 'Deep Learning', 'Probabilistic Methods']}","{'value': 'Diffusion models have achieved remarkable success across a wide range of generative tasks. A key challenge is understanding the mechanisms that prevent their memorization of training data and allow generalization. In this work, we investigate the role of the training dynamics in the transition from generalization to memorization. Through extensive experiments and theoretical analysis, we identify two distinct timescales: an early time $\\tau_\\mathrm{gen}$ at which models begin to generate high-quality samples, and a later time $\\tau_\\mathrm{mem}$ beyond which memorization emerges. Crucially, we find that $\\tau_\\mathrm{mem}$ increases linearly with the training set size $n$, while $\\tau_\\mathrm{gen}$ remains constant. This creates a growing window of training times with $n$ where models generalize effectively, despite showing strong memorization if training continues beyond it. It is only when $n$ becomes larger than a model-dependent threshold that overfitting disappears at infinite training times.\nThese findings reveal a form of implicit dynamical regularization in the training dynamics, which allow to avoid memorization even in highly overparameterized settings. Our results are supported by numerical experiments with standard U-Net architectures on realistic and synthetic  datasets, and by a theoretical analysis using a tractable random features model studied in the high-dimensional limit.'}",https://openreview.net{'value': '/pdf/5e614f505850b9817f74307cdc7119e86647f339.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=BOiQ7Kd5Lx,"{'value': 'Follow the Energy, Find the Path: Riemannian Metrics from Energy-Based Models'}",Louis Béthune; David Vigouroux; Yilun Du; Rufin VanRullen; Thomas Serre; Victor Boutin,~Louis_Béthune1; ~David_Vigouroux1; ~Yilun_Du1; ~Rufin_VanRullen1; ~Thomas_Serre1; ~Victor_Boutin2,"{'value': ['Riemannian metric', 'geodesics', 'energy-based model', 'data-driven metric', 'energy landscape', 'shortest-path']}","{'value': ""What is the shortest path between two data points lying in a high-dimensional space? While the answer is trivial in Euclidean geometry, it becomes significantly more complex when the data lies on a curved manifold—requiring a Riemannian metric to describe the space's local curvature. Estimating such a metric, however, remains a major challenge in high dimensions.\n\nIn this work, we propose a method for deriving Riemannian metrics directly from pretrained Energy-Based Models (EBMs)—a class of generative models that assign low energy to high-density regions.\nThese metrics define spatially varying distances, enabling the computation of geodesics—shortest paths that follow the data manifold’s intrinsic geometry. We introduce two novel metrics derived from EBMs and show that they produce geodesics that remain closer to the data manifold and exhibit lower curvature distortion, as measured by alignment with ground-truth trajectories.\nWe evaluate our approach on increasingly complex datasets: synthetic datasets with known data density, rotated character images with interpretable geometry, and high-resolution natural images embedded in a pretrained VAE latent space.\nOur results show that EBM-derived metrics consistently outperform established baselines, especially in high-dimensional settings. \n\nOur work is the first to derive Riemannian metrics from EBMs, enabling data-aware geodesics and unlocking scalable, geometry-driven learning for generative modeling and simulation.""}",https://openreview.net{'value': '/pdf/a1d72a0b4bf65b6f41eed7ee1b2202aadfe0b995.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=BJ3z1hYuKx,{'value': 'MetaKoopman: Bayesian Meta-Learning of Koopman Operators for Modeling Structured Dynamics under Distribution Shifts'},Mahmoud Selim; Sriharsha Bhat; Karl Henrik Johansson,~Mahmoud_Selim2; ~Sriharsha_Bhat1; ~Karl_Henrik_Johansson1,"{'value': ['Meta Learning', 'Koopman Theory', 'Motion Planning']}","{'value': 'Modeling and forecasting nonlinear dynamics under distribution shifts is essential for robust decision-making in real-world systems. In this work, we propose **MetaKoopman**, a Bayesian meta-learning framework for modeling nonlinear dynamics through linear latent representations. MetaKoopman learns a Matrix Normal-Inverse Wishart (*MNIW*) prior over the Koopman operator, enabling closed-form Bayesian updates conditioned on recent trajectory segments. Moreover, it provides a closed-form posterior predictive distribution over future state trajectories, capturing both epistemic and aleatoric uncertainty in the learned dynamics. We evaluate MetaKoopman on a full-scale autonomous truck and trailer system across a wide range of adverse winter scenarios—including snow, ice, and mixed-friction conditions—as well as in simulated control tasks with diverse distribution shifts. MetaKoopman consistently outperforms prior approaches in multi-step prediction accuracy, uncertainty calibration and robustness to distributional shifts. Field experiments further demonstrate its effectiveness in dynamically feasible motion planning, particularly during evasive maneuvers and operation at the limits of traction. Project website: [https://mahmoud-selim.github.io/MetaKoopman/](https://mahmoud-selim.github.io/MetaKoopman/)'}",https://openreview.net{'value': '/pdf/99a35cc652a2eb21468db9141b983e47dd5c4fee.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=B5UvFCiisp,{'value': 'GenIR: Generative Visual Feedback for Mental Image Retrieval'},Diji Yang; Minghao Liu; Chung-Hsiang Lo; Yi Zhang; James Davis,~Diji_Yang1; ~Minghao_Liu2; ~Chung-Hsiang_Lo1; ~Yi_Zhang91; ~James_Davis1,"{'value': ['Multi-Round Image Retrieval', 'Vision-Language Models', 'Generative Retrieval']}","{'value': ""Vision-language models (VLMs) have shown strong performance on text-to-image retrieval benchmarks. However, bridging this success to real-world applications remains a challenge. In practice, human search behavior is rarely a one-shot action. Instead, it is often a multi-round process guided by clues in mind. That is, a mental image ranging from vague recollections to vivid mental representations of the target image. Motivated by this gap, we study the task of Mental Image Retrieval (MIR), which targets the realistic yet underexplored setting where users refine their search for a mentally envisioned image through multi-round interactions with an image search engine. Central to successful interactive retrieval is the capability of machines to provide users with clear, actionable feedback; however, existing methods rely on indirect or abstract verbal feedback, which can be ambiguous, misleading, or ineffective for users to refine the query. To overcome this, we propose GenIR, a generative multi-round retrieval paradigm leveraging diffusion-based image generation to explicitly reify the AI system's understanding at each round. These synthetic visual representations provide clear, interpretable feedback, enabling users to refine their queries intuitively and effectively. We further introduce a fully automated pipeline to generate a high-quality multi-round MIR dataset. Experimental results demonstrate that GenIR significantly outperforms existing interactive methods in the MIR scenario. This work establishes a new task with a dataset and an effective generative retrieval method, providing a foundation for future research in this direction""}",https://openreview.net{'value': '/pdf/44b341a4aa67e23bd2e6376e73eaccdabf8fbb2a.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=B2iPEX5A9c,{'value': 'Information-Theoretic Discrete Diffusion'},Moongyu Jeon; Sangwoo Shin; Dongjae Jeon; Albert No,~Moongyu_Jeon1; ~Sangwoo_Shin3; ~Dongjae_Jeon1; ~Albert_No1,"{'value': ['Discrete Diffusion Models', 'Information Theory', 'Score Matching', 'Denoising Score Entropy (DSE)', 'Denoising Cross-Entropy (DCE)']}","{'value': 'We present an information-theoretic framework for discrete diffusion models \nthat yields principled estimators of log-likelihood using score-matching losses.\nInspired by the I-MMSE identity for the Gaussian setup, we derive analogous results for the discrete setting.\nSpecifically, we introduce the Information–Minimum Denoising Score Entropy (I-MDSE) relation,\nwhich links mutual information between data and its diffused version to the minimum denoising score entropy (DSE) loss.\nWe extend this theory to masked diffusion and establish the Information–Minimum Denoising Cross-Entropy (I-MDCE) relation,\nconnecting cross-entropy losses to mutual information in discrete masked processes.\nThese results provide a time-integral decomposition of the log-likelihood of the data in terms of optimal score-based losses,\nshowing that commonly used losses such as DSE and DCE are not merely variational bounds \nbut tight and principled estimators of log-likelihood.\nThe I-MDCE decomposition further enables practical extensions, including time-free formula,\nconditional likelihood estimation in prompt–response tasks, and coupled Monte Carlo estimation of likelihood ratios.\nExperiments on synthetic and real-world data confirm the accuracy, variance stability, and utility of our estimators.\nThe code is publicly available at https://github.com/Dongjae0324/infodis.'}",https://openreview.net{'value': '/pdf/9b4e154703fd904ac9ee0a421f77a7013e3b4e1a.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=B0Gfxhr8V5,{'value': 'BTL-UI: Blink-Think-Link Reasoning Model for GUI Agent'},Shaojie Zhang; Ruoceng Zhang; Pei Fu; Shaokang Wang; Jiahui Yang; Xin Du; ShiqiCui; Bin Qin; Ying Huang; Zhenbo Luo; Jian Luan,~Shaojie_Zhang5; ~Ruoceng_Zhang1; ~Pei_Fu1; ~Shaokang_Wang2; ~Jiahui_Yang5; ~Xin_Du14; ~ShiqiCui1; ~Bin_Qin2; ~Ying_Huang10; ~Zhenbo_Luo2; ~Jian_Luan1,"{'value': ['Large Vision-Language Model', 'GUI Agent', 'Reinforcement Fine-Tuning']}","{'value': ""In the field of AI-driven human-GUI interaction automation, while rapid advances in multimodal large language models and reinforcement fine-tuning techniques have yielded remarkable progress, a fundamental challenge persists: their interaction logic significantly deviates from natural human-GUI communication patterns. To address this gap, we propose Blink–Think–Link (BTL), a brain-inspired framework for human-GUI interaction that mimics the human cognitive process between users and graphical interfaces. The system decomposes interactions into three biologically plausible phases: (1) \\textbf{Blink} - rapid detection and attention to relevant screen areas, analogous to saccadic eye movements; (2) \\textbf{Think} - higher-level reasoning and decision-making, mirroring cognitive planning; and (3) \\textbf{Link} - generation of executable commands for precise motor control, emulating human action selection mechanisms. Additionally, we introduce two key technical innovations for BTL framework:\n(1) Blink Data Generation - an automated annotation pipeline specifically optimized for blink data, and\n(2) {BTL Reward – the first rule-based reward mechanism that enables reinforcement learning driven by both process and outcome.}\nBuilding upon this framework, we develop a GUI agent model named BTL-UI, which demonstrates competitive performance across both static GUI understanding and dynamic interaction tasks in comprehensive benchmarks. These results provide conclusive empirical validation of the framework's efficacy in developing advanced GUI agents.""}",https://openreview.net{'value': '/pdf/ba5902ee29175bd53969957abcfa4c2349bdef9d.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=Auy2DmlJBO,{'value': 'MIRA: Medical Time Series Foundation Model for Real-World Health Data'},Hao Li; Bowen Deng; Chang Xu; ZhiYuan Feng; Viktor Schlegel; Yu-Hao Huang; Yizheng Sun; Jingyuan Sun; Kailai Yang; Yiyao Yu; Jiang Bian,~Hao_Li25; ~Bowen_Deng7; ~Chang_Xu10; ~ZhiYuan_Feng1; ~Viktor_Schlegel1; ~Yu-Hao_Huang2; ~Yizheng_Sun1; ~Jingyuan_Sun3; ~Kailai_Yang1; ~Yiyao_Yu1; ~Jiang_Bian1,"{'value': ['Time Series', 'Foundation Model', 'Healthcare']}","{'value': 'A unified foundation model for medical time series—pretrained on open access and ethically reviewed medical corpora—offers the potential to reduce annotation burdens, minimize model customization, and enable robust transfer across clinical institutions, modalities, and tasks, particularly in data-scarce or privacy-constrained environments.  However, existing time series foundation models struggle to handle medical time series data due to its inherent challenges, including irregular intervals, heterogeneous sampling rates, and frequent missingness. To address these challenges, we introduce MIRA, a unified foundation model specifically designed for medical time series forecasting. MIRA incorporates a Continuous-Time Rotary Positional Encoding that enables fine-grained modeling of variable time intervals, a frequency-specific mixture-of-experts layer that routes computation across latent frequency regimes to further promote temporal specialization, and a Continuous Dynamics Extrapolation Block based on Neural ODE that models the continuous trajectory of latent states, enabling accurate forecasting at arbitrary target timestamps. Pretrained on a large-scale and diverse medical corpus comprising over 454 billion time points collect from publicly available datasets, MIRA achieving reductions in forecasting errors by an average of 8% and 6% in out-of-distribution and in-distribution scenarios, respectively. We also introduce a comprehensive benchmark spanning multiple downstream clinical tasks, establishing a foundation for future research in medical time series modeling.'}",https://openreview.net{'value': '/pdf/d5cd77d31c930923058a643d0411a30d15807342.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=AghtKxDf7f,{'value': 'STITCH-OPE: Trajectory Stitching with Guided Diffusion for Off-Policy Evaluation'},Hossein Goli; Michael Gimelfarb; Nathan Samuel de Lara; Haruki Nishimura; Masha Itkina; Florian Shkurti,~Hossein_Goli2; ~Michael_Gimelfarb1; ~Nathan_Samuel_de_Lara1; ~Haruki_Nishimura2; ~Masha_Itkina1; ~Florian_Shkurti1,"{'value': ['Off Policy Evaluation', 'Reinforcement Learning', 'Generative Models']}","{'value': 'Off-policy evaluation (OPE) estimates the performance of a target policy using offline data collected from a behavior policy, and is crucial in domains such as robotics or healthcare where direct interaction with the environment is costly or unsafe. Existing OPE methods are ineffective for high-dimensional, long-horizon problems, due to exponential blow-ups in variance from importance weighting or compounding errors from learned dynamics models. To address these challenges, we propose STITCH-OPE, a model-based generative framework that leverages denoising diffusion for long-horizon OPE in high-dimensional state and action spaces. Starting with a diffusion model pre-trained on the behavior data, STITCH-OPE generates synthetic trajectories from the target policy by guiding the denoising process using the score function of the target policy. STITCH-OPE proposes two technical innovations that make it advantageous for OPE: (1) prevents over-regularization by subtracting the score of the behavior policy during guidance, and (2) generates long-horizon trajectories by stitching partial trajectories together end-to-end. We provide a theoretical guarantee that under mild assumptions, these modifications result in an exponential reduction in variance versus long-horizon trajectory diffusion. Experiments on the D4RL and OpenAI Gym benchmarks show substantial improvement in mean squared error, correlation, and regret metrics compared to state-of-the-art OPE methods.'}",https://openreview.net{'value': '/pdf/1134baef6d25ffbb5e008870b98e41f5c9a1525c.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=AYqtMLRwzj,{'value': 'Belief-Calibrated Multi-Agent Consensus Seeking for Complex NLP Tasks'},Wentao Deng; Jiahuan Pei; Zhiwei Xu; Zhaochun Ren; Zhumin Chen; Pengjie Ren,~Wentao_Deng1; ~Jiahuan_Pei1; ~Zhiwei_Xu3; ~Zhaochun_Ren1; ~Zhumin_Chen1; ~Pengjie_Ren1,"{'value': ['Natural Language Processing', 'Multi-Agent', 'Large Language Model', 'Consensus Seeking']}","{'value': 'A multi-agent system (MAS) enhances its capacity to solve complex natural language processing (NLP) tasks through collaboration among multiple agents, where consensus-seeking serves as a fundamental mechanism.\nHowever, existing consensus-seeking approaches typically rely on voting mechanisms to judge consensus, overlooking contradictions in system-internal beliefs that destabilize the consensus.\nMoreover, these methods often involve agents updating their results through indiscriminate collaboration with every other agent.\nSuch uniform interaction fails to identify the optimal collaborators for each agent, hindering the emergence of a stable consensus.\nTo address these challenges, we provide a theoretical framework for selecting optimal collaborators that maximize consensus stability.\nBased on the theorems, we propose the Belief-Calibrated Consensus Seeking (BCCS) framework to facilitate stable consensus via selecting optimal collaborators and calibrating the consensus judgment by system-internal beliefs.\nExperimental results on the MATH and MMLU benchmark datasets demonstrate that the proposed BCCS framework outperforms the best existing results by 2.23\\% and 3.95\\% of accuracy on challenging tasks, respectively.\nOur code and data are available at https://github.com/dengwentao99/BCCS.'}",https://openreview.net{'value': '/pdf/39b359519c1bf6d78ee6a18e9e8d68df5457c0bd.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=AXlquRUO0S,{'value': 'Sum Estimation under Personalized Local Differential Privacy'},Dajun Sun; Wei Dong; Yuan Qiu; Ke Yi; Graham Cormode,~Dajun_Sun1; ~Wei_Dong5; ~Yuan_Qiu1; ~Ke_Yi1; ~Graham_Cormode1,"{'value': ['Differential Privacy', 'Sum Estimation']}","{'value': 'People have diverse privacy requirements. This is best modeled using a personalized local differential privacy model where each user privatizes their data using a possibly different privacy parameter.  While the model of personalized local differential privacy is a natural and important one, prior work has failed to give meaningful error bounds. In this paper, we study the foundational sum/mean estimation problem under this model. We present two novel protocols that achieve strong error guarantees. The first gives a guarantee based on the radius of the data, suiting inputs that are centered around zero. The second extends the guarantee to the diameter of the data, capturing the case when the points are situated arbitrarily. Experimental results on both synthetic and real data show that our protocols significantly outperform existing methods in terms of accuracy while providing a strong level of privacy.'}",https://openreview.net{'value': '/pdf/24e769481cb63b600da3f3b223ab546dc74aebc5.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=AWU93F6Bup,{'value': 'MoodAngels: A Retrieval-augmented Multi-agent Framework for Psychiatry Diagnosis'},Mengxi Xiao; Ben Liu; He Li; Jimin Huang; Qianqian Xie; Xiaofen Zong; Mang Ye; Min Peng,~Mengxi_Xiao1; ~Ben_Liu2; ~He_Li4; ~Jimin_Huang1; ~Qianqian_Xie1; ~Xiaofen_Zong1; ~Mang_Ye1; ~Min_Peng2,"{'value': ['psychiatry diagnosis', 'multi-agent framework', 'mental health']}","{'value': 'The application of AI in psychiatric diagnosis faces significant challenges, including the subjective nature of mental health assessments, symptom overlap across disorders, and privacy constraints limiting data availability. To address these issues, we present MoodAngels, the first specialized multi-agent framework for mood disorder diagnosis. Our approach combines granular-scale analysis of clinical assessments with a structured verification process, enabling more accurate interpretation of complex psychiatric data. Complementing this framework, we introduce MoodSyn, an open-source dataset of 1,173 synthetic psychiatric cases that preserves clinical validity while ensuring patient privacy. Experimental results demonstrate that MoodAngels outperforms conventional methods, with our baseline agent achieving 12.3\\% higher accuracy than GPT-4o on real-world cases, and our full multi-agent system delivering further improvements. Together, these contributions provide both an advanced diagnostic tool and a critical research resource for computational psychiatry, bridging important gaps in AI-assisted mental health assessment.'}",https://openreview.net{'value': '/pdf/df7fcff1d36dbd01901985729311dd34fae572a1.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=ATewcZPbDj,{'value': 'Accelerating 3D Molecule Generative Models with Trajectory Diagnosis'},Zhilong Zhang; Yuxuan Song; Yichun Wang; Jingjing Gong; Hanlin Wu; Dongzhan Zhou; Hao Zhou; Wei-Ying Ma,~Zhilong_Zhang1; ~Yuxuan_Song2; ~Yichun_Wang1; ~Jingjing_Gong3; ~Hanlin_Wu1; ~Dongzhan_Zhou1; ~Hao_Zhou5; ~Wei-Ying_Ma2,"{'value': ['3D Molecule Generation', 'Fast Generation', 'Drug Design']}","{'value': 'Geometric molecule generative models have found expanding applications across various scientific domains, but their generation inefficiency has become a critical bottleneck. Through a systematic investigation of the generative trajectory, we discover a unique challenge for molecule geometric graph generation: generative models require determining the permutation order of atoms in the molecule before refining its atomic feature values. Based on this insight, we decompose the generation process into permutation phase and adjustment phase, and propose a geometric-informed prior and consistency parameter objective to accelerate each phase. Extensive experiments demonstrate that our approach achieves competitive performance with approximately 10 sampling steps, 7.5 × faster than previous state-of-the-art models and approximately 100 × faster than diffusion-based models, offering a significant step towards scalable molecular generation.'}",https://openreview.net{'value': '/pdf/9b6d2adfb4ba64950f7ce5bdfa7c078e3013c8a7.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=AHEKhff4Oa,{'value': 'PhysCtrl: Generative Physics for Controllable and Physics-Grounded Video Generation'},Chen Wang; Chuhao Chen; Yiming Huang; Zhiyang Dou; Yuan Liu; Jiatao Gu; Lingjie Liu,~Chen_Wang13; ~Chuhao_Chen1; ~Yiming_Huang5; ~Zhiyang_Dou1; ~Yuan_Liu3; ~Jiatao_Gu1; ~Lingjie_Liu1,"{'value': ['Physics simulation', 'video generation', 'diffusion models']}","{'value': 'Existing video generation models excel at producing photo-realistic videos from text or images, but often lack physical plausibility and 3D controllability. To overcome these limitations, we introduce PhysCtrl, a novel framework for physics-grounded image-to-video generation with physical parameters and force control. At its core is a generative physics network that learns the distribution of physical dynamics across four materials (elastic, sand, plasticine, and rigid) via a diffusion model conditioned on physics parameters and applied forces. We represent physical dynamics as 3D point trajectories and train on a large-scale synthetic dataset of 550K animations generated by physics simulators. We enhance the diffusion model with a novel spatiotemporal attention block that emulates particle interactions and incorporates physics-based constraints during training to enforce physical plausibility. Experiments show that PhysCtrl generates realistic, physics-grounded motion trajectories which, when used to drive image-to-video models, yield high-fidelity, controllable videos that outperform existing methods in both visual quality and physical plausibility. Our code, model and data will be made publicly available upon publication.'}",https://openreview.net{'value': '/pdf/f004af8c5e76c1b850e491839d37683ebf36cfac.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=ACSOnSHiWe,{'value': 'CAM: A Constructivist View of Agentic Memory for LLM-Based Reading Comprehension'},Rui Li; Zeyu Zhang; Xiaohe Bo; Zihang Tian; Xu Chen; Quanyu Dai; Zhenhua Dong; Ruiming Tang,~Rui_Li16; ~Zeyu_Zhang6; ~Xiaohe_Bo1; ~Zihang_Tian1; ~Xu_Chen13; ~Quanyu_Dai1; ~Zhenhua_Dong1; ~Ruiming_Tang2,"{'value': ['LLM-Based Reading Agent', 'Long-Text Reading Comprehension', 'LLM Memory']}","{'value': ""Current Large Language Models (LLMs) are confronted with overwhelming information volume when comprehending long-form documents. This challenge raises the imperative of a cohesive memory module, which can elevate vanilla LLMs into autonomous reading agents. Despite the emergence of some heuristic approaches, a systematic design principle remains absent. To fill this void, we draw inspiration from Jean Piaget's Constructivist Theory, illuminating three traits of the agentic memory---structured schemata, flexible assimilation, and dynamic accommodation. This blueprint forges a clear path toward a more robust and efficient memory system for LLM-based reading comprehension. To this end, we develop CAM, a prototype implementation of Constructivist Agentic Memory that simultaneously embodies the structurality, flexibility, and dynamicity. At its core, CAM is endowed with an incremental overlapping clustering algorithm for structured memory development, supporting both coherent hierarchical summarization and online batch integration. During inference, CAM adaptively explores the memory structure to activate query-relevant information for contextual response, akin to the human associative process. Compared to existing approaches, our design demonstrates dual advantages in both performance and efficiency across diverse long-text reading comprehension tasks, including question answering, query-based summarization, and claim verification.""}",https://openreview.net{'value': '/pdf/33d48884d041c742c7dca881251da63dbbc58a0f.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=A4JiifkTzq,{'value': 'SPRO: Improving Image Generation via Self-Play'},Ritika Jha; Aanisha Bhattacharyya; Yaman Kumar Singla; Rajiv Ratn Shah; Changyou Chen; Balaji Krishnamurthy,~Ritika_Jha1; ~Aanisha_Bhattacharyya2; ~Yaman_Kumar_Singla1; ~Rajiv_Ratn_Shah1; ~Changyou_Chen1; ~Balaji_Krishnamurthy1,"{'value': ['diffusion model', 'self play', 'llm', 'large language models', 'prompt improvement']}","{'value': 'Recent advances in diffusion models have dramatically improved image fidelity and diversity. However, aligning these models with nuanced human preferences -such as aesthetics, engagement, and subjective appeal remains a key challenge due to the scarcity of large-scale human annotations. Collecting such data is both expensive and limited in diversity. To address this, we leverage the reasoning capabilities of vision-language models (VLMs) and propose Self-Play Reward Optimization (SPRO), a scalable, annotation-free training framework based on multimodal self-play. SPRO learns to jointly align prompt and image generation with human preferences by iteratively generating, evaluating, and learning to refine outputs using synthetic reward signals such as aesthetics and human engagement. This self-improving feedback loop eliminates the need for external supervision. SPRO comprises three stages: (1) SPRO-Prompt, which trains a Guider-VLM via self-play to generate diverse, high-reward prompts targeting objectives such as PickScore (user preference), LAION-Aesthetics, and EngageNet (engagement); (2) SPRO-Image, which fine-tunes the diffusion model on high-reward images derived from these prompts; and (3) SPRO-Multimodal (SPRO-MM), which integrates both components for full end-to-end alignment. Without relying on human-labeled data, SPRO achieves an average 30\\% improvement across preference objectives. Moreover, its generated prompts generalize across both open- and closed-source diffusion models. Through iterative self-play, SPRO discovers prompting strategies rarely authored by humans such as emphasizing visual harmony for aesthetics or leveraging shadow-based cues for engagement. SPRO offers a scalable path toward aligning generative models with complex subjective human values.'}",https://openreview.net{'value': '/pdf/020238e55fd35519748e0cf78e2d8bcf409bce38.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=A2pmvkqOgp,{'value': 'Forging Time Series with Language: A Large Language Model Approach to Synthetic Data Generation'},Cécile Rousseau; Tobia Boschi; Giandomenico Cornacchia; Dhaval Salwala; Alessandra Pascale; Juan Bernabe Moreno,~Cécile_Rousseau4; ~Tobia_Boschi1; ~Giandomenico_Cornacchia1; ~Dhaval_Salwala1; ~Alessandra_Pascale1; ~Juan_Bernabe_Moreno1,"{'value': ['Time Series', 'Synthetic Data Generation', 'LLMs']}","{'value': ""SDForger is a flexible and efficient framework for generating high-quality multivariate time series using LLMs.\nLeveraging a compact data representation, SDForger provides synthetic time series generation from a few samples and low-computation fine-tuning of any autoregressive LLM. Specifically, the framework transforms univariate and multivariate signals into tabular embeddings, which are then encoded into text and used to fine-tune the LLM.\nAt inference, new textual embeddings are sampled and decoded into synthetic time series that retain the original data's statistical properties and temporal dynamics. Across a diverse range of datasets, SDForger outperforms existing generative models in many scenarios, both in similarity-based evaluations and downstream forecasting tasks. By enabling textual conditioning in the generation process, SDForger paves the way for multimodal modeling and the streamlined integration of time series with textual information. The model is open-sourced at https://github.com/IBM/fms-dgt/tree/main/fms_dgt/public/databuilders/time_series.""}",https://openreview.net{'value': '/pdf/2e07288e13fe84c7676bb493f7db6d8eaaf41eb0.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=9yusqX9DpR,{'value': 'Self-Challenging Language Model Agents'},Yifei Zhou; Sergey Levine; Jason E Weston; Xian Li; Sainbayar Sukhbaatar,~Yifei_Zhou1; ~Sergey_Levine1; ~Jason_E_Weston1; ~Xian_Li1; ~Sainbayar_Sukhbaatar1,"{'value': ['LLM Agent', 'self-improvement', 'multi-turn tool-use']}","{'value': 'Large language models  are quickly becoming the foundation for intelligent agents that are capable of using tools. However, training such agents is challenging because it requires human creation and annotation of a diverse set of tasks, tools, and evaluation criteria. In this paper, we propose  the Self-Challenging Agent framework for training an agent on high-quality tasks that are generated by itself. The agent first plays the role of challenger and generates a task after interacting with the given tools. The tasks take the form of a novel general class of problems termed Code-as-Task, which are defined by an instruction, a verification function and solution and failure cases which serve as tests, allowing to filter only for high-quality tasks.  \nThe agent then takes an executor role and trains on those tasks with reinforcement learning using the evaluation feedback as a reward.  We show our method improves the performance of Llama-3.1-8B-Instruct on two existing multi-turn tool-use agent benchmarks, M$^3$ToolEval and TauBench, with a two-fold average success rate increase, despite using only self-generated training data.'}",https://openreview.net{'value': '/pdf/d7856a8a4e991dab71814a3f39f28fe17b6b93bd.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=9vDpL9lgKS,{'value': 'Inverse Optimization Latent Variable Models for Learning Costs Applied to Route Problems'},Alan Lahoud; Erik Schaffernicht; Johannes A. Stork,~Alan_Lahoud1; ~Erik_Schaffernicht1; ~Johannes_A._Stork1,"{'value': ['inverse optimization', 'latent space']}","{'value': 'Learning representations for solutions of constrained optimization problems (COPs) with unknown cost functions is challenging, as models like (Variational) Autoencoders struggle to enforce constraints when decoding structured outputs. We propose an Inverse Optimization Latent Variable Model (IO-LVM) that learns a latent space of COP cost functions from observed solutions and reconstructs feasible outputs by solving a COP with a solver in the loop. Our approach leverages estimated gradients of a Fenchel-Young loss through a non-differentiable deterministic solver to shape the latent space. Unlike standard Inverse Optimization or Inverse Reinforcement Learning methods, which typically recover a single or context-specific cost function, IO-LVM captures a distribution over cost functions, enabling the identification of diverse solution behaviors arising from different agents or conditions not available during the training process. We validate our method on real-world datasets of ship and taxi routes, as well as paths in synthetic graphs, demonstrating its ability to reconstruct paths and cycles, predict their distributions, and yield interpretable latent representations.'}",https://openreview.net{'value': '/pdf/676d6a42a7d56fee93de3d481e6371d19e025442.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=9twwDW60Bw,{'value': 'Self-Guided Hierarchical Exploration for Generalist Foundation Model Web Agents'},Qianlan Yang; Xiangjun Wang; Danielle Perszyk; Yu-Xiong Wang,~Qianlan_Yang1; ~Xiangjun_Wang1; ~Danielle_Perszyk1; ~Yu-Xiong_Wang1,"{'value': ['Web Agent', 'Foundation Models', 'VLM', 'Reinforcement Learning']}","{'value': 'Foundation models have recently shown strong potential as web agents, capable of interpreting high-level instructions and interacting with complex web interfaces. However, existing training paradigms for these agents often rely on predefined task datasets and curated demonstrations, limiting their scalability, adaptability, and capacity for self-improvement. In this work, we introduce *Self-guided hierArchical exploration for Generalist wEb agents* (SAGE), a new training framework designed to support autonomous skill acquisition through self-guided hierarchical exploration. Our method introduces a three-tier exploration strategy: a pre-exploration phase to build structural understanding of web environments, a top-level exploration strategy to generate a self-evolving curriculum of tasks from easy to hard, and a low-level exploration mechanism that combines planning-based rollouts with step-wise learning to improve policy efficiency. Together, these components form a scalable, supervision-free framework for web agent training. Experimental results on WebVoyager and WebArena demonstrate that our method significantly outperforms prior approaches, enabling foundation model agents to learn complex web tasks with greater generalization and robustness.'}",https://openreview.net{'value': '/pdf/23935fe967684b7bdc286739474d07c94da9cc76.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=9t7gfYUp0U,{'value': 'MLZero: A Multi-Agent System for End-to-end Machine Learning Automation'},Haoyang Fang; Boran Han; Nick Erickson; Xiyuan Zhang; Su Zhou; Anirudh Dagar; Jiani Zhang; Ali Caner Turkmen; Cuixiong Hu; Huzefa Rangwala; Ying Nian Wu; Bernie Wang; George Karypis,~Haoyang_Fang1; ~Boran_Han1; ~Nick_Erickson1; ~Xiyuan_Zhang2; ~Su_Zhou2; ~Anirudh_Dagar1; ~Jiani_Zhang2; ~Ali_Caner_Turkmen1; ~Cuixiong_Hu1; ~Huzefa_Rangwala2; ~Ying_Nian_Wu1; ~Bernie_Wang1; ~George_Karypis1,"{'value': ['AutoML', 'Large Language Models', 'Multi-Agent Systems', 'End-to-End Machine Learning', 'Multimodal Learning', 'Code Generation']}","{'value': 'Existing AutoML systems have advanced the automation of machine learning (ML); however, they still require substantial manual configuration and expert input, particularly when handling multimodal data. We introduce MLZero, a novel multi-agent framework powered by Large Language Models (LLMs) that enables end-to-end ML automation across diverse data modalities with minimal human intervention. A cognitive perception module is first employed, transforming raw multimodal inputs into perceptual context that effectively guides the subsequent workflow. To address key limitations of LLMs, such as hallucinated code generation and outdated API knowledge, we enhance the iterative code generation process with semantic and episodic memory. MLZero demonstrates superior performance on MLE-Bench Lite, outperforming all competitors in both success rate and solution quality, securing six gold medals. Furthermore, when evaluated on our Multimodal AutoML Agent Benchmark, which includes 25 more challenging tasks spanning diverse data modalities, MLZero outperforms the competing methods by a large margin with a success rate of 0.92 (+263.6\\%) and an average rank of 2.28. Our approach maintains its robust effectiveness even with a compact 8B LLM, outperforming full-size systems from existing solutions.'}",https://openreview.net{'value': '/pdf/55f28109c8ee532fe1c950142c23f6efd636a79e.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=9qCejdqPXa,{'value': 'Text-to-Decision Agent: Offline Meta-Reinforcement Learning from Natural Language Supervision'},Shilin Zhang; Zican Hu; Wenhao Wu; Xinyi Xie; Jianxiang Tang; Chunlin Chen; Daoyi Dong; Yu Cheng; Zhenhong Sun; Zhi Wang,~Shilin_Zhang3; ~Zican_Hu1; ~Wenhao_Wu13; ~Xinyi_Xie2; ~Jianxiang_Tang2; ~Chunlin_Chen1; ~Daoyi_Dong1; ~Yu_Cheng1; ~Zhenhong_Sun1; ~Zhi_Wang7,"{'value': ['Offline meta-reinforcement learning', 'reinforcement learning', 'world model']}","{'value': 'Offline meta-RL usually tackles generalization by inferring task beliefs from high-quality samples or warmup explorations. The restricted form limits their generality and usability since these supervision signals are expensive and even infeasible to acquire in advance for unseen tasks. Learning directly from the raw text about decision tasks is a promising alternative to leverage a much broader source of supervision. In the paper, we propose **T**ext-to-**D**ecision **A**gent (**T2DA**), a simple and scalable framework that supervises offline meta-RL with natural language. We first introduce a generalized world model to encode multi-task decision data into a dynamics-aware embedding space. Then, inspired by CLIP, we predict which textual description goes with which decision embedding, effectively bridging their semantic gap via contrastive language-decision pre-training and aligning the text embeddings to comprehend the environment dynamics. After training the text-conditioned generalist policy, the agent can directly realize zero-shot text-to-decision generation in response to language instructions. Comprehensive experiments on MuJoCo and Meta-World benchmarks show that T2DA facilitates high-capacity zero-shot generalization and outperforms various types of baselines. Our code is available at [https://github.com/NJU-RL/T2DA](https://github.com/NJU-RL/T2DA).'}",https://openreview.net{'value': '/pdf/c33fdc82e3fa9e31b19dd8f58667e752537f7439.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=9osvTOYbT4,{'value': 'Segment Policy Optimization: Effective Segment-Level Credit Assignment in RL for Large Language Models'},Yiran Guo; Lijie Xu; Jie Liu; Ye Dan; Shuang Qiu,~Yiran_Guo2; ~Lijie_Xu1; ~Jie_Liu23; ~Ye_Dan1; ~Shuang_Qiu2,"{'value': ['LLM', 'Deep Learning', 'Reinforcement Learning']}","{'value': 'Enhancing the reasoning capabilities of large language models effectively using reinforcement learning (RL) remains a crucial challenge. Existing approaches primarily adopt two contrasting advantage estimation granularities: token-level methods (e.g., PPO) aim to provide fine-grained advantage signals but suffer from inaccurate estimation due to difficulties in training an accurate critic model. On the other extreme, trajectory-level methods (e.g., GRPO) solely rely on a coarse-grained advantage signal from the final reward, leading to imprecise credit assignment. To address these limitations, we propose Segment Policy Optimization (SPO), a novel RL framework that leverages segment-level advantage estimation at an intermediate granularity, achieving a better balance by offering more precise credit assignment than trajectory-level methods and requiring fewer estimation points than token-level methods, enabling accurate advantage estimation based on Monte Carlo (MC) without a critic model. SPO features three components with novel strategies: (1) flexible segment partition; (2) accurate segment advantage estimation; and (3) policy optimization using segment advantages, including a novel probability-mask strategy. We further instantiate SPO for two specific scenarios: (1) SPO-chain for short chain-of-thought (CoT), featuring novel cutpoint-based partition and chain-based advantage estimation, achieving $6$-$12$ percentage point improvements in accuracy over PPO and GRPO on GSM8K. (2) SPO-tree for long CoT, featuring novel tree-based advantage estimation, which significantly reduces the cost of MC estimation, achieving $7$-$11$ percentage point improvements over GRPO on MATH500 under 2K and 4K context evaluation. We make our code publicly available at https://github.com/AIFrameResearch/SPO.'}",https://openreview.net{'value': '/pdf/0014e043c5bdbee58956fee9fb2bb09545ac0aa2.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=9jONuWKoLj,{'value': 'CAMO: Convergence-Aware Multi-Fidelity Bayesian Optimization'},WEI W. XING; Lu Zhenjie; Akeel Shah,~WEI_W._XING1; ~Lu_Zhenjie1; ~Akeel_Shah1,{'value': ['Multi fidelity Bayesian Optimisation; Fidelity Differential Equations; Convergence aware; Acquisition function; Analysis; Regret bounds']},"{'value': 'Existing Multi-fidelity Bayesian Optimization (MFBO) methods ignore the convergence behavior of the multi-fidelity surrogate as the fidelity increases, leading to inefficient exploration and suboptimal performance. We introduce CAMO (Convergence-Aware Multi-fidelity Optimization), a principled framework based on Linear Fidelity Differential Equations (LFiDEs) that explicitly encodes  convergence of fidelity-indexed outputs and employs a closed-form nonstationary kernel. We rigorously prove the existence and pointwise/uniform convergence to the high fidelity surrogate under mild restrictions and provide new convergence results for general FiDEs using smooth, non-smooth and even non-convex Lyapunov functions, establishing a bridge between MFBO and the theory of subgradient flows  in non-smooth optimisation theory.  Combined with a fidelity-aware acquisition function,  CAMO outperforms state-of-the-art MFBO methods on a majority  of synthetic and real-world benchmarks, with up to a four-fold improvement in optimisation performance and a dramatic speed-up in convergence. CAMO offers a tractable and theoretically grounded approach to convergence-aware MFBO.'}",https://openreview.net{'value': '/pdf/66ad6e724b2a04c7e76c2aece18bc13fc451192a.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=9eIntNc69t,{'value': 'Memo: Training Memory-Efficient Embodied Agents with Reinforcement Learning'},Gunshi Gupta; Karmesh Yadav; Zsolt Kira; Yarin Gal; Rahaf Aljundi,~Gunshi_Gupta1; ~Karmesh_Yadav1; ~Zsolt_Kira1; ~Yarin_Gal1; ~Rahaf_Aljundi1,"{'value': ['Reinforcement learning', 'transformers', 'memory', 'compression']}","{'value': 'To enable embodied agents to operate effectively over extended timeframes, it is crucial to develop models that form and access memories to stay contextualized in their environment. In the current paradigm of training transformer-based policies for embodied sequential decision-making tasks, visual inputs often overwhelm the context limits of transformers, while humans can maintain and utilize a lifetime of experience compressed as memories. Significant compression is possible in principle, as much of the input is irrelevant and can be abstracted. However, existing approaches predominantly focus on either recurrent models with fixed-size memory or transformers with full-context reliance. In this work, we propose Memo, a transformer-based architecture and training recipe for reinforcement learning (RL) on memory-intensive, long-horizon tasks. Memo incorporates the creation and retrieval of memory by interleaving periodic summarization tokens with the inputs of a model during training. We demonstrate Memo’s effectiveness on a grid-world meta-RL benchmark and a multi-object navigation task in photo-realistic indoor settings. Memo outperforms naive long-context transformer baselines while being more compute and storage efficient. Additionally, Memo generalizes better to longer contexts at inference time and remains robust in streaming settings, where historical context must be truncated to fit inference constraints.'}",https://openreview.net{'value': '/pdf/4877c8c9446b72d733a5677610304c04fd55f44d.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=9RelLjiaHw,{'value': 'Distributionally Robust Feature Selection'},Maitreyi Swaroop; Tamar Krishnamurti; Bryan Wilder,~Maitreyi_Swaroop1; ~Tamar_Krishnamurti1; ~Bryan_Wilder2,"{'value': ['DRO', 'feature-selection']}","{'value': 'We study the problem of selecting limited features to observe such that models trained on them can perform well simultaneously across multiple subpopulations. This problem has applications in settings where collecting each feature is costly, e.g. requiring adding survey questions or physical sensors, and we must be able to use the selected features to create high-quality downstream models for different populations. Our method frames the problem as a continuous relaxation of traditional variable selection using a noising mechanism, without requiring backpropagation through model training processes. By optimizing over the variance of a Bayes-optimal predictor, we develop a model-agnostic framework that balances overall performance of downstream prediction across populations. We validate our approach through experiments on both synthetic datasets and real-world data.'}",https://openreview.net{'value': '/pdf/b7ba966bd5e16c8e7bcecbea172f7c07f1dfff0a.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=9Ook5bXnPr,{'value': 'TrajAgent: An LLM-Agent Framework for Trajectory Modeling via Large-and-Small Model Collaboration'},Yuwei Du; Jie Feng; Jie Zhao; Yong Li,~Yuwei_Du2; ~Jie_Feng8; ~Jie_Zhao7; ~Yong_Li7,"{'value': ['LLM-based Agent', 'Trajectory Data Mining', 'Collaboration Learning']}","{'value': 'Trajectory modeling, which includes research on trajectory data pattern mining and future prediction, has widespread applications in areas such as life services, urban transportation, and public administration. Numerous methods have been proposed to address specific problems within trajectory modeling. However, the heterogeneity of data and the diversity of trajectory tasks make effective and reliable trajectory modeling an important yet highly challenging endeavor, even for domain experts. In this paper, we propose TrajAgent, a agent framework powered by large language models (LLMs), designed to facilitate robust and efficient trajectory modeling through automation modeling. This framework leverages and optimizes diverse specialized models to address various trajectory modeling tasks across different datasets effectively. In TrajAgent, we first develop UniEnv, an execution environment with a unified data and model interface, to support the execution and training of various models. Building on UniEnv, we introduce an agentic workflow designed for automatic trajectory modeling across various trajectory tasks and data. Furthermore, we introduce collaborative learning schema between LLM-based agents and small speciallized models, to enhance the performance of the whole framework effectively. Extensive experiments on four tasks using four real-world datasets demonstrate the effectiveness of TrajAgent in automated trajectory modeling, achieving a performance improvement of 2.38%-69.91% over baseline methods. The codes and data can be accessed via https://github.com/tsinghua-fib-lab/TrajAgent.'}",https://openreview.net{'value': '/pdf/907c1941fbc6aba93b6f6858e39bc94e8fc84301.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=9KIvyH3L7c,{'value': 'Improving Reward Models with Proximal Policy Exploration for Preference-Based Reinforcement Learning'},Yiwen Zhu; Jinyi Liu; Pengjie Gu; Yifu Yuan; Zhenxing Ge; Wenya Wei; Zhou Fang; Yujing Hu; Bo An,~Yiwen_Zhu2; ~Jinyi_Liu1; ~Pengjie_Gu1; ~Yifu_Yuan1; ~Zhenxing_Ge1; ~Wenya_Wei1; ~Zhou_Fang2; ~Yujing_Hu2; ~Bo_An2,{'value': ['Reinforcement Learning; Preference-based Reinforcement Learning;']},"{'value': ""Reinforcement learning (RL) heavily depends on well-designed reward functions, which are often biased and difficult to design for complex behaviors. \nPreference-based RL (PbRL) addresses this by learning reward models from human feedback, but its practicality is constrained by a critical dilemma: while existing methods reduce human effort through query optimization, they neglect the preference buffer's restricted coverage  —\na factor that fundamentally determines the reliability of reward model. \nWe systematically demonstrate this limitation creates distributional mismatch: reward models trained on static buffers reliably assess in-distribution trajectories but falter with out-of-distribution (OOD) trajectories from policy exploration. \nCrucially, such failures in policy-proximal regions directly misguide iterative policy updates.\nTo address this, we propose **Proximal Policy Exploration (PPE)** with two key components:\n(1) a *proximal-policy extension* method that expands exploration in undersampled policy-proximal regions, and\n(2) a *mixture distribution query*  method that balances in-distribution and OOD trajectory sampling.\nBy enhancing buffer coverage while preserving evaluation accuracy in policy-proximal regions, PPE enables more reliable policy updates.\nExperiments across continuous control tasks demonstrate that PPE enhances preference feedback utilization efficiency  and RL sample efficiency over baselines, highlighting preference buffer coverage management's vital role in  PbRL.""}",https://openreview.net{'value': '/pdf/c2a5c801ae5655e39e6963d6e1c798db86d958c0.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=9Ia0KiVAut,{'value': 'Improving Retrieval-Augmented Generation through Multi-Agent Reinforcement Learning'},Yiqun Chen; Lingyong Yan; Weiwei Sun; Xinyu Ma; Yi Zhang; Shuaiqiang Wang; Dawei Yin; Yiming Yang; Jiaxin Mao,~Yiqun_Chen3; ~Lingyong_Yan1; ~Weiwei_Sun9; ~Xinyu_Ma4; ~Yi_Zhang56; ~Shuaiqiang_Wang2; ~Dawei_Yin1; ~Yiming_Yang1; ~Jiaxin_Mao1,"{'value': ['Retrieval-Augmented Generation', 'Multi-Agent Cooperation', 'Multi-Agent Reinforcement Learning', 'Multi-Module Joint Learning']}","{'value': ""Retrieval-augmented generation (RAG) is widely utilized to incorporate external knowledge into large language models, thereby enhancing factuality and reducing hallucinations in question-answering (QA) tasks. A standard RAG pipeline consists of several components, such as query rewriting, document retrieval, document filtering, and answer generation. However, these components are typically optimized separately through supervised fine-tuning, which can lead to misalignments between the objectives of individual components and the overarching aim of generating accurate answers. Although recent efforts have explored using reinforcement learning (RL) to optimize specific RAG components, these approaches often focus on simple pipelines with only two components or do not adequately address the complex interdependencies and collaborative interactions among the modules. To overcome these limitations, we propose treating the complex RAG pipeline with multiple components as a multi-agent cooperative task, in which each component can be regarded as an RL agent. Specifically, we present MMOA-RAG\\footnote{The code of MMOA-RAG is on \\url{https://github.com/chenyiqun/MMOA-RAG}.}, \\textbf{M}ulti-\\textbf{M}odule joint \\textbf{O}ptimization \\textbf{A}lgorithm for \\textbf{RAG}, which employs multi-agent reinforcement learning to harmonize all agents' goals toward a unified reward, such as the F1 score of the final answer. Experiments conducted on various QA benchmarks demonstrate that MMOA-RAG effectively boost the overall performance of the pipeline and outperforms existing baselines. Furthermore, comprehensive ablation studies validate the contributions of individual components and demonstrate MMOA-RAG can be adapted to different RAG pipelines and benchmarks.""}",https://openreview.net{'value': '/pdf/0bc82f5b29d7122b8b021ba8fad9f4e5ce031dd8.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=9F2Cmgo17M,{'value': 'PARCO: Parallel AutoRegressive Models for Multi-Agent Combinatorial Optimization'},Federico Berto; Chuanbo Hua; Laurin Luttmann; Jiwoo Son; Junyoung Park; Kyuree Ahn; Changhyun Kwon; Lin Xie; Jinkyoo Park,~Federico_Berto1; ~Chuanbo_Hua1; ~Laurin_Luttmann1; ~Jiwoo_Son2; ~Junyoung_Park1; ~Kyuree_Ahn1; ~Changhyun_Kwon1; ~Lin_Xie1; ~Jinkyoo_Park1,{'value': ['Multi-agent Combinatorial Optimization; Multi-agent Reinforcement Learning; Neural Combinatorial Optimization']},"{'value': 'Combinatorial optimization problems involving multiple agents are notoriously challenging due to their NP-hard nature and the necessity for effective agent coordination. Despite advancements in learning-based methods, existing approaches often face critical limitations, including suboptimal agent coordination, poor generalization, and high computational latency. To address these issues, we propose PARCO (Parallel AutoRegressive Combinatorial Optimization), a general reinforcement learning framework designed to construct high-quality solutions for multi-agent combinatorial tasks efficiently. To this end, PARCO integrates three key novel components: (1) transformer-based communication layers to enable effective agent collaboration during parallel solution construction, (2) a multiple pointer mechanism for low-latency, parallel agent decision-making, and (3) priority-based conflict handlers to resolve decision conflicts via learned priorities. We evaluate PARCO in multi-agent vehicle routing and scheduling problems, where our approach outperforms state-of-the-art learning methods, demonstrating strong generalization ability and remarkable computational efficiency. We make our source code publicly available to foster future research: https://github.com/ai4co/parco.'}",https://openreview.net{'value': '/pdf/672bb4ede45dba28f133a8ebb2cfe40fb1f395c8.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=95z3psF9zJ,{'value': 'Differentiable Cyclic Causal Discovery Under Unmeasured Confounders'},Muralikrishnna Guruswamy Sethuraman; Faramarz Fekri,~Muralikrishnna_Guruswamy_Sethuraman1; ~Faramarz_Fekri1,"{'value': ['causal discovery', 'confounders', 'feedback loops', 'generative modeling']}","{'value': 'Understanding causal relationships between variables is fundamental across scientific disciplines. Most causal discovery algorithms rely on two key assumptions: (i) all variables are observed, and (ii) the underlying causal graph is acyclic. While these assumptions simplify theoretical analysis, they are often violated in real-world systems, such as biological networks. Existing methods that account for confounders either assume linearity or struggle with scalability. To address these limitations, we propose DCCD-CONF, a novel framework for differentiable learning of nonlinear cyclic causal graphs in the presence of unmeasured confounders using interventional data. Our approach alternates between optimizing the graph structure and estimating the confounder distribution by maximizing the log-likelihood of the data. Through experiments on synthetic data and real-world gene perturbation datasets, we show that DCCD-CONF outperforms state-of-the-art methods in both causal graph recovery and confounder identification. Additionally, we provide consistency guarantees for our framework, reinforcing its theoretical soundness.'}",https://openreview.net{'value': '/pdf/afe5c3c1e5371e5f015154e6d2bcb8a162237f47.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=91H9CSvdwl,{'value': 'Safety Pretraining: Toward the Next Generation of Safe AI'},Pratyush Maini; Sachin Goyal; Dylan Sam; Alexander Robey; Yash Savani; Yiding Jiang; Andy Zou; Matt Fredrikson; Zachary Chase Lipton; J Zico Kolter,~Pratyush_Maini1; ~Sachin_Goyal1; ~Dylan_Sam1; ~Alexander_Robey1; ~Yash_Savani1; ~Yiding_Jiang2; ~Andy_Zou1; ~Matt_Fredrikson1; ~Zachary_Chase_Lipton1; ~J_Zico_Kolter1,"{'value': ['Safe LLMs', 'Pretraining', 'Data Centric ML']}","{'value': 'As large language models (LLMs) are increasingly deployed in high-stakes settings, the risk of generating harmful or toxic content remains a central challenge. Post-hoc alignment methods are brittle: once unsafe patterns are learned during pretraining, they are hard to remove.\nIn this work, we present a data-centric pretraining framework that builds safety into the model from the start. Our framework consists of four key steps:\n(i) Safety Filtering: building a safety classifier to classify webdata into safe and unsafe categories;\n(ii) Safety Rephrasing: we recontextualize unsafe webdata into safer narratives;\n(iii) Native Refusal: we synthetically generate pretraining datasets that actively teach models to refuse on unsafe content and the moral reasoning behind it, and\n(iv) Harmfulness-Tag annotated pretraining: we flag unsafe content during pretraining using a special token, and use it to steer models away from unsafe generations at inference-time.\nOur safety-pretrained models reduce attack success rates from 38.8% to 8.4% on standard LLM safety benchmarks with no performance degradation on general tasks.'}",https://openreview.net{'value': '/pdf/60d7860b3e2747b4def0be07de449da240c31b99.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=8y18QBU2s6,{'value': 'Retrv-R1: A Reasoning-Driven MLLM Framework for Universal and Efficient Multimodal Retrieval'},Lanyun Zhu; Deyi Ji; Tianrun Chen; Haiyang Wu; Shiqi Wang,~Lanyun_Zhu1; ~Deyi_Ji2; ~Tianrun_Chen1; ~Haiyang_Wu2; ~Shiqi_Wang1,{'value': ['Multimodal retrieval']},"{'value': ""The success of DeepSeek-R1 demonstrates the immense potential of using reinforcement learning (RL) to enhance LLMs' reasoning capabilities. This paper introduces Retrv-R1, the first R1-style MLLM specifically designed for multimodal universal retrieval, achieving higher performance by employing step-by-step reasoning to produce more accurate retrieval results. We find that directly applying the methods of DeepSeek-R1 to retrieval tasks is not feasible, mainly due to (1) the high computational cost caused by the large token consumption required for multiple candidates with reasoning processes, and (2) the instability and suboptimal results when directly applying RL to train for retrieval tasks. To address these issues, Retrv-R1 introduces an information compression module with a details inspection mechanism, which enhances computational efficiency by reducing the number of tokens while ensuring that critical information for challenging candidates is preserved. Additionally, a new training paradigm is proposed, including an activation stage using a retrieval-tailored synthetic CoT dataset for more effective optimization, followed by RL with a novel curriculum reward to improve both performance and efficiency. Incorporating these novel designs, Retrv-R1 achieves SOTA performance, high efficiency, and strong generalization ability, as demonstrated by extensive experiments across multiple benchmarks and tasks.""}",https://openreview.net{'value': '/pdf/7cb940939c9f96e79b0c9c85d4e93db10956f054.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=8t89BYV781,{'value': 'RoPECraft: Training-Free Motion Transfer with Trajectory-Guided RoPE Optimization on Diffusion Transformers'},Ahmet Berke Gökmen; Yiğit Ekin; Bahri Batuhan Bilecen; Aysegul Dundar,~Ahmet_Berke_Gökmen1; ~Yiğit_Ekin1; ~Bahri_Batuhan_Bilecen1; ~Aysegul_Dundar1,"{'value': ['video motion transfer', 'diffusion transformers', 'positional embeddings', 'motion', 'training-free', 'video', 'diffusion']}","{'value': 'We propose RoPECraft, a training-free video motion transfer method for diffusion transformers that operates solely by modifying their rotary positional embeddings (RoPE). We first extract dense optical flow from a reference video, and utilize the resulting motion offsets to warp the complex-exponential tensors of RoPE, effectively encoding motion into the generation process. These embeddings are then further optimized during denoising time steps via trajectory alignment between the predicted and target velocities using a flow-matching objective. To keep the output faithful to the text prompt and prevent duplicate generations, we incorporate a regularization term based on the phase components of the reference video’s Fourier transform, projecting the phase angles onto a smooth manifold to suppress high-frequency artifacts. Experiments on benchmarks reveal that RoPECraft outperforms all recently published methods, both qualitatively and quantitatively.'}",https://openreview.net{'value': '/pdf/b17350d79dd07914765a98c2d8395fb693915e2c.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=8hahZ1h9CG,{'value': 'PIVNO: Particle Image Velocimetry Neural Operator'},Jie Xu; Xuesong Zhang; Jing Jiang; Qinghua Cui,~Jie_Xu29; ~Xuesong_Zhang2; ~Jing_Jiang13; ~Qinghua_Cui1,"{'value': ['PIV', 'Motion Field', 'Neural Operator', 'Self-supervised']}","{'value': 'Particle Image Velocimetry (PIV) aims to infer underlying velocity fields from time-separated particle images, forming a PDE-constrained inverse problem governed by advection dynamics. Traditional cross-correlation methods and deep learning-based feature matching approaches often struggle with ambiguity, limited resolution, and generalization to real-world conditions. To address these challenges, we propose a PIV Neural Operator (PIVNO) framework that directly approximates the inverse mapping from paired particle images to flow fields within a function space. Leveraging a position informed Galerkin-style attention operator, PIVNO captures global flow structures while supporting resolution-adaptive inference across arbitrary subdomains. Moreover, to enhance real-world adaptability, we introduce a self-supervised fine-tuning scheme based on physical divergence constraints, enabling the model to generalize from synthetic to real experiments without requiring labeled data. Extensive evaluations demonstrate the accuracy, flexibility, and robustness of our approach across both simulated and experimental PIV datasets. Our code is at https://github.com/ZXS-Labs/PIVNO.'}",https://openreview.net{'value': '/pdf/3c4d47122bfb729bad018c92d5a6295597160577.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=8YniJnJQ0P,{'value': 'Detecting High-Stakes Interactions with Activation Probes'},Alex McKenzie; Urja Pawar; Phil Blandfort; William Bankes; David Krueger; Ekdeep Singh Lubana; Dmitrii Krasheninnikov,~Alex_McKenzie1; ~Urja_Pawar1; ~Phil_Blandfort1; ~William_Bankes1; ~David_Krueger1; ~Ekdeep_Singh_Lubana1; ~Dmitrii_Krasheninnikov1,"{'value': ['linear probes', 'monitoring', 'mechanistic interpretability', 'large language models']}","{'value': ""Monitoring is an important aspect of safely deploying Large Language Models (LLMs).\nThis paper examines activation probes for detecting ``high-stakes'' interactions---where the text indicates that the interaction might lead to significant harm---as a critical, yet underexplored, target for such monitoring.\nWe evaluate several probe architectures trained on synthetic data, and find them to exhibit robust generalization to diverse, out-of-distribution, real-world data.\nProbes' performance is comparable to that of prompted or finetuned medium-sized LLM monitors, while offering computational savings of six orders-of-magnitude.\nThese savings are enabled by reusing activations of the model that is being monitored.\nOur experiments also highlight the potential of building resource-aware hierarchical monitoring systems, where probes serve as an efficient initial filter and flag cases for more expensive downstream analysis.\nWe release our novel synthetic dataset and the codebase at\n\\url{https://github.com/arrrlex/models-under-pressure}.""}",https://openreview.net{'value': '/pdf/6291cf20df7b3579af7a0739c773db78424d18cd.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=8P5MUySaqi,{'value': 'Continual Optimization with Symmetry Teleportation for Multi-Task Learning'},Zhipeng Zhou; Ziqiao Meng; Pengcheng Wu; Peilin Zhao; Chunyan Miao,~Zhipeng_Zhou2; ~Ziqiao_Meng1; ~Pengcheng_Wu1; ~Peilin_Zhao2; ~Chunyan_Miao1,"{'value': ['Multi-Task Learning', 'Symmetry Teleportation']}","{'value': 'Multi-task learning (MTL) is a widely explored paradigm that enables the simultaneous learning of multiple tasks using a single model. Despite numerous solutions, the key issues of optimization conflict and task imbalance remain under-addressed, limiting performance. Unlike existing optimization-based approaches that typically reweight task losses or gradients to mitigate conflicts or promote progress, we propose a novel approach based on Continual Optimization with Symmetry Teleportation (COST). During MTL optimization, when an optimization conflict arises, we seek an alternative loss-equivalent point on the loss landscape to reduce conflict. Specifically, we utilize a low-rank adapter (LoRA) to facilitate this practical teleportation by designing convergent, loss-invariant objectives. Additionally, we introduce a historical trajectory reuse strategy to continually leverage the benefits of advanced optimizers. Extensive experiments on multiple mainstream datasets demonstrate the effectiveness of our approach. COST is a plug-and-play solution that enhances a wide range of existing MTL methods. When integrated with state-of-the-art methods, COST achieves superior performance.'}",https://openreview.net{'value': '/pdf/b4e6b025879c22afb9d0aa3904b049f59a71d4a0.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=8MHTtHZRFL,{'value': 'Masked Diffusion Models as Energy Minimization'},Sitong Chen; Shen Nie; Jiacheng Sun; Zijin Feng; Zhenguo Li; Ji-Rong Wen; Chongxuan Li,~Sitong_Chen1; ~Shen_Nie2; ~Jiacheng_Sun1; ~Zijin_Feng1; ~Zhenguo_Li1; ~Ji-Rong_Wen1; ~Chongxuan_Li1,"{'value': ['Masked Diffusion Models', 'Optimal Transport', 'Energy Minimization', 'Kinetic Energy', 'Few-Step Sampling']}","{'value': 'We present a systematic theoretical framework that interprets masked diffusion models (MDMs) as solutions to energy minimization problems in discrete optimal transport. Specifically, we prove that three distinct energy formulations—kinetic, conditional kinetic, and geodesic energy—are mathematically equivalent under the structure of MDMs, and that MDMs minimize all three when the mask schedule satisfies a closed-form optimality condition. This unification not only clarifies the theoretical foundations of MDMs, but also motivates practical improvements in sampling. By parameterizing interpolation schedules via Beta distributions, we reduce the schedule design space to a tractable 2D search, enabling efficient post-training tuning without model modification. Experiments on synthetic and real-world benchmarks demonstrate that our energy-inspired schedules outperform hand-crafted baselines, particularly in low-step sampling settings.'}",https://openreview.net{'value': '/pdf/ef39a95ba77715b13428ae00292067d4179c800f.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=894Yo61h1P,{'value': 'Reasoning Path Compression: Compressing Generation Trajectories for Efficient LLM Reasoning'},Jiwon Song; Dongwon Jo; Yulhwa Kim; Jae-Joon Kim,~Jiwon_Song1; ~Dongwon_Jo1; ~Yulhwa_Kim1; ~Jae-Joon_Kim2,"{'value': ['large language model', 'reasoning', 'test-time compute scaling', 'KV cache']}","{'value': 'Recent reasoning-focused language models achieve high accuracy by generating lengthy intermediate reasoning paths before producing final answers.\nWhile this approach is effective in solving problems that require logical thinking, long reasoning paths significantly increase memory usage and reduce throughput of token generation, limiting the practical deployment of such models.\nWe propose Reasoning Path Compression (RPC), a training-free method that accelerates inference by leveraging the semantic sparsity of reasoning paths.\nRPC periodically compresses the KV cache by retaining cache entries that receive high importance score, which are computed using a selector window composed of recently generated queries.\nExperiments show that RPC improves generation throughput of QwQ-32B by up to 1.60$\\times$ compared to the inference with full KV cache, with an accuracy drop of 1.2\\% on the AIME 2024 benchmark.\nOur findings demonstrate that semantic sparsity in reasoning traces can be effectively exploited for compression, offering a practical path toward efficient deployment of reasoning LLMs. Our code is available at https://github.com/jiwonsong-dev/ReasoningPathCompression.'}",https://openreview.net{'value': '/pdf/8e675a892e87d2f3f98f3a4c08cb1e44bbf0f712.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=87c2JwNJa0,{'value': 'LoMix: Learnable Weighted Multi-Scale Logits Mixing for Medical Image Segmentation'},Md Mostafijur Rahman; Radu Marculescu,~Md_Mostafijur_Rahman1; ~Radu_Marculescu2,"{'value': ['LoMix Supervision', 'Medical Image Segmentation', 'U-shaped Network', 'Combinatorial Multi-scale Fusion', 'Logits Mixing']}","{'value': 'U‑shaped networks output logits at multiple spatial scales, each capturing a different blend of coarse context and fine detail. Yet, training still treats these logits in isolation—either supervising only the final, highest‑resolution logits or applying deep supervision with identical loss weights at every scale—without exploring *mixed‑scale* combinations. Consequently, the decoder output misses the complementary cues that arise only when coarse and fine predictions are fused. To address this issue, we introduce LoMix ($\\underline{Lo}$gits $\\underline{Mix}$ing), a Neural Architecture Search (NAS)‑inspired, differentiable plug-and-play module that **generates** new mixed‑scale outputs and **learns** how exactly each of them should guide the training process. More precisely, LoMix mixes the multi-scale decoder logits with four lightweight fusion operators: addition, multiplication, concatenation, and attention-based weighted fusion, yielding a rich set of synthetic “mutant’’ maps. Every original or mutant map is given a softplus loss weight that is co‑optimized with network parameters, mimicking a one‑step architecture search that automatically discovers the most useful scales, mixtures, and operators. Plugging LoMix into recent U-shaped architectures (i.e., PVT‑V2‑B2 backbone with EMCAD decoder) on Synapse 8‑organ dataset improves DICE by +4.2\\% over single‑output supervision, +2.2\\% over deep supervision, and +1.5\\% over equally weighted additive fusion, all with **zero** inference overhead. When training data are scarce (e.g., one or two labeled scans, 5\\% of the trainset), the advantage grows to +9.23\\%, underscoring LoMix’s data efficiency. Across four benchmarks and diverse U-shaped networks, LoMiX improves DICE by up to +13.5\\% over single-output supervision, confirming that learnable weighted mixed‑scale fusion generalizes broadly while remaining data efficient, fully interpretable, and overhead-free at inference. Our implementation is available at https://github.com/SLDGroup/LoMix.'}",https://openreview.net{'value': '/pdf/0756b3c531c7788a76667829a758f005f2454484.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=7yOl9qiLWd,{'value': 'BrainODE: Neural Shape Dynamics for Age- and Disease-aware Brain Trajectories'},Wonjung Park; Suhyun Ahn; Maria C. Valdes Hernandez; Susana Muñoz Maniega; Jinah Park,~Wonjung_Park1; ~Suhyun_Ahn1; ~Maria_C._Valdes_Hernandez1; ~Susana_Muñoz_Maniega1; ~Jinah_Park1,"{'value': ['Shape analysis', 'Medical application', 'Prediagnosis']}","{'value': 'We present BrainODE, a neural ordinary differential equation (ODE)-based framework for modeling continuous longitudinal deformations of brain shapes. BrainODE learns a deformation space over anatomically meaningful brain regions to facilitate early prediction of neurodegenerative disease progression. Addressing inherent challenges of longitudinal neuroimaging data-such as limited sample sizes, irregular temporal sampling, and substantial inter-subject variability-we propose a conditional neural ODE architecture that models shape dynamics with subject-specific age and cognitive status. To enable autoregressive forecasting of brain morphology from a single observation, we propose a pseudo-cognitive status embedding that allows progressive shape prediction across intermediate time points with predicted cognitive decline. Experiments show that BrainODE outperforms time-aware baselines in predicting future brain shapes, demonstrating strong generalization across longitudinal datasets with both regular and irregular time intervals.'}",https://openreview.net{'value': '/pdf/880ef14ea12d26d9ce56b714466baf6faf211f69.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=7k7cubl1iL,{'value': 'CIDD: Collaborative Intelligence for Structure-Based Drug Design Empowered by LLMs'},Bowen Gao; Yanwen Huang; Yiqiao Liu; Wenxuan Xie; Bowei He; Haichuan Tan; Wei-Ying Ma; Ya-Qin Zhang; Yanyan Lan,~Bowen_Gao1; ~Yanwen_Huang2; ~Yiqiao_Liu2; ~Wenxuan_Xie3; ~Bowei_He1; ~Haichuan_Tan1; ~Wei-Ying_Ma2; ~Ya-Qin_Zhang1; ~Yanyan_Lan2,"{'value': ['Large Language Model', 'Drug Design']}","{'value': 'Structure-guided molecular generation is pivotal in early-stage drug discovery, enabling the design of compounds tailored to specific protein targets. However, despite recent advances in 3D generative modeling, particularly in improving docking scores, these methods often produce rare and intrinsically irrational molecular structures that deviate from drug-like chemical space. To quantify this issue, we propose a novel metric, the Molecule Reasonable Ratio (MRR), which measures structural rationality and reveals a critical gap between existing models and real-world approved drugs. To address this, we introduce the Collaborative Intelligence Drug Design (CIDD) framework, the first approach to unify the 3D interaction modeling capabilities of generative models with the general knowledge and reasoning power of large language models (LLMs). By leveraging LLM-based Chain-of-Thought reasoning, CIDD generates molecules that not only bind effectively to protein pockets but also exhibit strong structural drug-likeness, rationality, and synthetic accessibility. On the CrossDocked2020 benchmark, CIDD consistently improves drug-likeness metrics, including QED, SA, and MRR, across different base generative models, while maintaining competitive binding affinity. Notably, it raises the combined success rate (balancing drug-likeness and binding) from 15.72% to 34.59%, more than doubling previous results. These findings demonstrate the value of integrating knowledge reasoning with geometric generation to advance AI-driven drug design.'}",https://openreview.net{'value': '/pdf/77cb4fc7534bc0e0660ba9931aad895880b93492.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=7ieS4EYKnB,{'value': 'Flick: Empowering Federated Learning with Commonsense Knowledge'},Ran Zhu; Mingkun Yang; Shiqiang Wang; Jie Yang; Qing Wang,~Ran_Zhu2; ~Mingkun_Yang2; ~Shiqiang_Wang1; ~Jie_Yang1; ~Qing_Wang22,"{'value': ['Federated Learning', 'Data Heterogeneity']}","{'value': 'Federated Learning (FL) has emerged as a privacy-preserving framework for training models on data generated at the edge. However, the heterogeneity of data silos (e.g., label skew and domain shift) often leads to inconsistent learning objectives and suboptimal model performance. Inspired by the data-driven approach, we propose Flick, a novel data generation framework for heterogeneous **F**ederated **L**earning w**i**th **C**ommonsense **K**nowledge from Large Language Models (LLMs). In Flick, the client performs the local data summary to capture client-specific knowledge in textual form. The central server then distills task-relevant, high-quality knowledge from the out-of-the-box LLM -- guided by cross-client-specific insights -- to generate informative text prompts. These prompts direct a generative model in producing synthetic data, enabling global model fine-tuning and local data compensation. This process gradually aligns the label and feature distributions across clients. Extensive results on three datasets demonstrate that Flick improves the global model accuracy by up to 11.43\\%, and accelerates convergence by up to 12.9$\\times$, validating its effectiveness in addressing data heterogeneity.'}",https://openreview.net{'value': '/pdf/f09ed72312ebc714ef40dd7c5f046681e9f30b87.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=7cqKVDgFZQ,{'value': 'Curly Flow Matching for Learning Non-gradient Field Dynamics'},Katarina Petrović; Lazar Atanackovic; Viggo Moro; Kacper Kapuśniak; Ismail Ilkan Ceylan; Michael M. Bronstein; Joey Bose; Alexander Tong,~Katarina_Petrović1; ~Lazar_Atanackovic1; ~Viggo_Moro1; ~Kacper_Kapuśniak1; ~Ismail_Ilkan_Ceylan2; ~Michael_M._Bronstein1; ~Joey_Bose1; ~Alexander_Tong1,"{'value': ['Single-cell', 'Trajectory Inference', 'Schrödinger Bridge', 'Optimal Transport', 'Flow Matching']}","{'value': 'Modeling the transport dynamics of natural processes from population-level observations is a ubiquitous problem in the natural sciences. Such models rely on key assumptions about the underlying process in order to enable faithful learning of governing dynamics that mimic the actual system behavior. The de facto assumption in current approaches relies on the principle of least action that results in gradient field dynamics and leads to trajectories minimizing an energy functional between two probability measures. However, many real-world systems, such as cell cycles in single-cell RNA, are known to exhibit non-gradient, periodic behavior, which fundamentally cannot be captured by current state-of-the-art methods such as flow and bridge matching. In this paper, we introduce Curly Flow Matching (Curly-FM), a novel approach that is capable of learning non-gradient field dynamics by designing and solving a Schrödinger bridge problem with a non-zero drift reference process---in stark contrast to typical zero-drift reference processes---which is constructed using inferred velocities in addition to population snapshot data. We showcase Curly-FM by solving the trajectory inference problems for single cells, computational fluid dynamics, and ocean currents with approximate velocities. We demonstrate that Curly-FM can learn trajectories that better match both the reference process and population marginals. Curly-FM expands flow matching models beyond the modeling of populations and towards the modeling of known periodic behavior in physical systems. Our code repository is accessible\nat: https://github.com/kpetrovicc/curly-flow-matching.git'}",https://openreview.net{'value': '/pdf/c12b1bcb3344c4a2dd800499987efcf6aee1930b.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=7bEPq5MAQi,{'value': 'Learning Counterfactual Outcomes Under Rank Preservation'},Peng Wu; Haoxuan Li; Chunyuan Zheng; Yan Zeng; Jiawei Chen; Yang Liu; Ruocheng Guo; Kun Zhang,~Peng_Wu5; ~Haoxuan_Li6; ~Chunyuan_Zheng1; ~Yan_Zeng2; ~Jiawei_Chen6; ~Yang_Liu3; ~Ruocheng_Guo1; ~Kun_Zhang1,"{'value': ['Causal Inference', 'Nonparametric Identifiability', 'Individualized Treatment Effects']}","{'value': 'Counterfactual inference aims to estimate the counterfactual outcome at the individual level given knowledge of an observed treatment and the factual outcome, with broad applications in fields such as epidemiology, econometrics, and management science. Previous methods rely on a known structural causal model (SCM) or assume the homogeneity of the exogenous variable and strict monotonicity between the outcome and exogenous variable. In this paper, we propose a principled approach for identifying and estimating the counterfactual outcome. We first introduce a simple and intuitive rank preservation assumption to identify the counterfactual outcome without relying on a known structural causal model. Building on this, we propose a novel ideal loss for theoretically unbiased learning of the counterfactual outcome and further develop a kernel-based estimator for its empirical estimation. Our theoretical analysis shows that the rank preservation assumption is not stronger than the homogeneity and strict monotonicity assumptions, and shows that the proposed ideal loss is convex, and the proposed estimator is unbiased. Extensive semi-synthetic and real-world experiments are conducted to demonstrate the effectiveness of the proposed method.'}",https://openreview.net{'value': '/pdf/63a9fc5077d720cd4b1cd25178d737c3132dff34.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=7aYBgYDFhh,{'value': 'Real-World Adverse Weather Image Restoration via Dual-Level Reinforcement Learning with High-Quality Cold Start'},Fuyang Liu; Jiaqi Xu; Xiaowei Hu,~Fuyang_Liu1; ~Jiaqi_Xu1; ~Xiaowei_Hu3,"{'value': ['Image restoration', 'adverse weather', 'deraining', 'dehazing', 'desnowing', 'and reinforcement learning']}","{'value': 'Adverse weather severely impairs real-world visual perception, while existing vision models trained on synthetic data with fixed parameters struggle to generalize to complex degradations. To address this, we first construct HFLS-Weather, a physics-driven, high-fidelity dataset that simulates diverse weather phenomena, and then design a dual-level reinforcement learning framework initialized with HFLS-Weather for cold-start training. Within this framework, at the local level, weather-specific restoration models are refined through perturbation-driven image quality optimization, enabling reward-based learning without paired supervision; at the global level, a meta-controller dynamically orchestrates model selection and execution order according to scene degradation. This framework enables continuous adaptation to real-world conditions and achieves state-of-the-art performance across a wide range of adverse weather scenarios. Code is available at https://github.com/xxclfy/AgentRL-Real-Weather'}",https://openreview.net{'value': '/pdf/15e09eda7bc8119a966dab3b28e61ca06b1fe637.pdf'},{'abstract_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=7WgYEIOLdv,{'value': 'HIDISC: A Hyperbolic Framework for Domain Generalization with Generalized Category Discovery'},Vaibhav Rathore; Divyam Gupta; Biplab Banerjee,~Vaibhav_Rathore1; ~Divyam_Gupta2; ~Biplab_Banerjee1,"{'value': ['Domain Generalization', 'Category Discovery', 'Hyperbolic Spaces']}","{'value': 'Generalized Category Discovery (GCD) aims to classify test-time samples into either seen categories—available during training—or novel ones, without relying on label supervision. Most existing GCD methods assume simultaneous access to labeled and unlabeled data during training and arising from the same domain, limiting applicability in open-world scenarios involving distribution shifts. Domain Generalization with GCD (DG-GCD) lifts this constraint by requiring models to generalize to unseen domains containing novel categories, without accessing target-domain data during training.\nThe only prior DG-GCD method, DG$^2$CD-Net~\\cite{dg2net}, relies on episodic training with multiple synthetic domains and task vector aggregation, incurring high computational cost and error accumulation. We propose \\textsc{HiDISC}, a hyperbolic representation learning framework that achieves domain and category-level generalization without episodic simulation. To expose the model to minimal but diverse domain variations, we augment the source domain using GPT-guided diffusion, avoiding overfitting while maintaining efficiency.\nTo structure the representation space, we introduce \\emph{Tangent CutMix}, a curvature-aware interpolation that synthesizes pseudo-novel samples in tangent space, preserving manifold consistency. A unified loss—combining penalized Busemann alignment, hybrid hyperbolic contrastive regularization, and adaptive outlier repulsion—facilitates compact, semantically structured embeddings. A learnable curvature parameter further adapts the geometry to dataset complexity.\n\\textsc{HiDISC} achieves state-of-the-art results on PACS~\\cite{pacs}, Office-Home~\\cite{officehome}, and DomainNet~\\cite{domainnet}, consistently outperforming the existing Euclidean and hyperbolic (DG)-GCD baselines.'}",https://openreview.net{'value': '/pdf/98db185a9cbc023aaf46b25024606a05d21cae5c.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=7FLKzOqsKd,{'value': 'FrameShield: Adversarially Robust Video Anomaly Detection'},Mojtaba Nafez; Mobina Poulaei; Nikan Vasei; Bardia soltani moakhar; Mohammad Sabokrou; Mohammad Hossein Rohban,~Mojtaba_Nafez1; ~Mobina_Poulaei2; ~Nikan_Vasei1; ~Bardia_soltani_moakhar1; ~Mohammad_Sabokrou1; ~Mohammad_Hossein_Rohban1,"{'value': ['Video Anomaly Detection', 'Adversarial Robustness', 'Multiple Instance Learning']}","{'value': 'Weakly Supervised Video Anomaly Detection (WSVAD) has achieved notable advancements, yet existing models remain vulnerable to adversarial attacks, limiting their reliability. Due to the inherent constraints of weak supervision—where only video-level labels are provided despite the need for frame-level predictions—traditional adversarial defense mechanisms, such as adversarial training, are not effective since video-level adversarial perturbations are typically weak and inadequate. To address this limitation, pseudo-labels generated directly from the model can enable frame-level adversarial training; however, these pseudo-labels are inherently noisy, significantly degrading performance. We therefore introduce a novel Pseudo-Anomaly Generation method called Spatiotemporal Region Distortion (SRD), which creates synthetic anomalies by applying severe augmentations to localized regions in normal videos while preserving temporal consistency. Integrating these precisely annotated synthetic anomalies with the noisy pseudo-labels substantially reduces label noise, enabling effective adversarial training. Extensive experiments demonstrate that our method significantly enhances the robustness of WSVAD models against adversarial attacks, outperforming state-of-the-art methods by an average of 71.0\\% in overall AUROC performance across multiple benchmarks. The implementation and code are publicly available at [FrameShield (GitHub)](https://github.com/rohban-lab/FrameShield).'}",https://openreview.net{'value': '/pdf/f538a1b7575343f5c2540e46b4d180f40adcaa51.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=7EjdHkOwc4,{'value': 'PANGEA: Projection-Based Augmentation with Non-Relevant General Data for Enhanced Domain Adaptation in LLMs'},Seungyoo Lee; Giung Nam; Moonseok Choi; Hyungi Lee; Juho Lee,~Seungyoo_Lee3; ~Giung_Nam1; ~Moonseok_Choi1; ~Hyungi_Lee1; ~Juho_Lee2,"{'value': ['synthetic data generation', 'large language models', 'domain adaptation']}","{'value': 'Modern large language models (LLMs) achieve competitive performance across a wide range of natural language processing tasks through zero-shot or few-shot prompting. However, domain-specific tasks often still require fine-tuning, which is frequently hindered by data scarcity, i.e., collecting sufficient domain-specific data remains a practical challenge. A widely adopted solution is to generate synthetic data using LLMs by augmenting a small set of available domain-specific examples. In this work, we first identify fundamental limitations of such approach in terms of both data diversity and quality, particularly when relying on only a handful of domain-specific examples. We then propose our method, PANGEA, which leverages large-scale, publicly available general-purpose data---entirely unrelated to the target domain---to generate more diverse and higher-quality synthetic data. Our extensive experiments on domain-specific benchmarks, including GSM8K, MedQA, and FinQA, as well as a custom domain-specific language task, validate the effectiveness of our approach.'}",https://openreview.net{'value': '/pdf/3d612799b2d554a0e751a107b3bb08f11c70a030.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=7Eh2SK6Mo7,{'value': 'Trajectory Bellman Residual Minimization: A Simple Value-Based Method for LLM Reasoning'},Yurun Yuan; Fan Chen; Zeyu Jia; Alexander Rakhlin; Tengyang Xie,~Yurun_Yuan1; ~Fan_Chen4; ~Zeyu_Jia1; ~Alexander_Rakhlin1; ~Tengyang_Xie1,"{'value': ['large language models', 'value-based reinforcement learning', 'LLM post-training']}","{'value': ""Policy-based methods currently dominate reinforcement learning (RL) pipelines for large language model (LLM) reasoning, leaving value-based approaches largely unexplored. We revisit the classical paradigm of Bellman Residual Minimization and introduce Trajectory Bellman Residual Minimization (TBRM), an algorithm that naturally adapts this idea to LLMs, yielding a simple yet effective off-policy algorithm that optimizes a single trajectory-level Bellman objective using the model's own logits as $Q$-values. TBRM removes the need for critics, importance-sampling ratios, or clipping, and can operate with only one rollout per prompt. We prove convergence to the near-optimal KL-regularized policy from arbitrary off-policy data via an improved change-of-trajectory-measure analysis. Experiments on standard mathematical-reasoning benchmarks show that TBRM matches or surpasses policy-based baselines, like PPO and GRPO, with comparable or lower computational and memory overhead. Our results indicate that value-based RL might be a principled and efficient alternative for enhancing reasoning capabilities in LLMs. The codebase for TBRM is publicly available at [https://github.com/rlx-lab/TBRM](https://github.com/rlx-lab/TBRM).""}",https://openreview.net{'value': '/pdf/6aefcbc212ab28ccf45c24b827cd790bb04db214.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=7AGXSlXcK6,{'value': 'Predictability Enables Parallelization of Nonlinear State Space Models'},Xavier Gonzalez; Leo Kozachkov; David M. Zoltowski; Kenneth L. Clarkson; Scott Linderman,~Xavier_Gonzalez1; ~Leo_Kozachkov1; ~David_M._Zoltowski1; ~Kenneth_L._Clarkson1; ~Scott_Linderman1,"{'value': ['dynamical systems', 'optimization', 'largest Lyapunov exponent', 'contraction analysis', 'RNNs', ""Newton's method"", 'Parallel algorithms', 'Scalability', 'Numerical Stability', 'state-space models', 'DEER']}","{'value': 'The rise of parallel computing hardware has made it increasingly important to understand which nonlinear state space models can be efficiently parallelized. Recent advances have shown that evaluating a state space model can be recast as solving a parallelizable optimization problem, and sometimes this approach yields dramatic speed-ups in evaluation time. However, the factors that govern the difficulty of these optimization problems remain unclear, limiting the larger adoption of the technique. In this work, we establish a precise relationship between the dynamics of a nonlinear system and the conditioning of its corresponding optimization formulation. We show that the predictability of a system, defined as the degree to which small perturbations in state influence future behavior, directly governs the number of optimization steps required for evaluation. In predictable systems, the state trajectory can be computed in $\\mathcal{O}((\\log T)^2)$ time, where $T$ is the sequence length, a major improvement over the conventional sequential approach. In contrast, chaotic or unpredictable systems exhibit poor conditioning, with the consequence that parallel evaluation converges too slowly to be useful. Importantly, our theoretical analysis demonstrates that for predictable systems, the optimization problem is always well-conditioned, whereas for unpredictable systems, the conditioning degrades exponentially as a function of the sequence length. We validate our claims through extensive experiments, providing practical guidance on when nonlinear dynamical systems can be efficiently parallelized, and highlighting predictability as a key design principle for parallelizable models.'}",https://openreview.net{'value': '/pdf/ce3962ea4a5fbcc9516e7750a99733855fb35d9d.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=72UR53jN7T,{'value': 'ThinkAct: Vision-Language-Action Reasoning via Reinforced Visual Latent Planning'},Chi-Pin Huang; Yueh-Hua Wu; Min-Hung Chen; Yu-Chiang Frank Wang; Fu-En Yang,~Chi-Pin_Huang2; ~Yueh-Hua_Wu1; ~Min-Hung_Chen2; ~Yu-Chiang_Frank_Wang2; ~Fu-En_Yang1,"{'value': ['Vision-Language-Action Models', 'Reasoning']}","{'value': 'Vision-language-action (VLA) reasoning tasks require agents to interpret multimodal instructions, perform long-horizon planning, and act adaptively in dynamic environments. Existing approaches typically train VLA models in an end-to-end fashion, directly mapping inputs to actions without explicit reasoning, which hinders their ability to plan over multiple steps or adapt to complex task variations. In this paper, we propose ThinkAct, a dual-system framework that bridges high-level reasoning with low-level action execution via reinforced visual latent planning. ThinkAct trains a multimodal LLM to generate embodied reasoning plans guided by reinforcing action-aligned visual rewards based on goal completion and trajectory consistency. These reasoning plans are compressed into a visual plan latent that conditions a downstream action model for robust action execution on target environments. Extensive experiments on embodied reasoning and robot manipulation benchmarks demonstrate that ThinkAct enables few-shot adaptation, long-horizon planning, and self-correction behaviors in complex embodied AI tasks.'}",https://openreview.net{'value': '/pdf/b35b0fc70612e191baced400f754db8ff1fae711.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=6zfILEmD3u,{'value': 'CoP: Agentic Red-teaming for Large Language Models using Composition of Principles'},Chen Xiong; Pin-Yu Chen; Tsung-Yi Ho,~Chen_Xiong2; ~Pin-Yu_Chen1; ~Tsung-Yi_Ho2,"{'value': ['Large Language Model', 'Jailbreak Attack', 'LLM Agent']}","{'value': 'Recent advances in Large Language Models (LLMs) have spurred transformative applications in various domains, ranging from open-source to proprietary LLMs. However, jailbreak attacks, which aim to break safety alignment and user compliance by tricking the target LLMs into answering harmful and risky responses, are becoming an urgent concern. The practice of red-teaming for LLMs is to proactively explore potential risks and error-prone instances before the release of frontier AI technology. This paper proposes an agentic workflow to automate and scale the red-teaming process of LLMs through the Composition-of-Principles (CoP) framework, where human users provide a set of red-teaming principles as instructions to an AI agent to automatically orchestrate effective red-teaming strategies and generate jailbreak prompts. Distinct from existing red-teaming methods, our CoP framework provides a unified and extensible framework to encompass and orchestrate human-provided red-teaming principles to enable the automated discovery of new red-teaming strategies. When tested against leading LLMs, CoP reveals unprecedented safety risks by finding novel jailbreak prompts and improving the best-known single-turn attack success rate by up to 13.8 times.'}",https://openreview.net{'value': '/pdf/cb30447780175b5ce7f25d0e0277ddcc32156544.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=6xCcjYa97j,{'value': 'A Closer Look at Model Collapse: From a Generalization-to-Memorization Perspective'},Lianghe Shi; Meng Wu; Huijie Zhang; Zekai Zhang; Molei Tao; Qing Qu,~Lianghe_Shi1; ~Meng_Wu3; ~Huijie_Zhang2; ~Zekai_Zhang5; ~Molei_Tao1; ~Qing_Qu2,"{'value': ['Diffusion model', 'memorization', 'generative model']}","{'value': 'The widespread use of diffusion models has led to an abundance of AI-generated data, raising concerns about model collapse---a phenomenon in which recursive iterations of training on synthetic data lead to performance degradation. Prior work primarily characterizes this collapse via variance shrinkage or distribution shift, but these perspectives miss practical manifestations of model collapse. This paper identifies a transition from generalization to memorization during model collapse in diffusion models, where models increasingly replicate training data instead of generating novel content during iterative training on synthetic samples. This transition is directly driven by the declining entropy of the synthetic training data produced in each training cycle, which serves as a clear indicator of model degradation. Motivated by this insight, we propose an entropy-based data selection strategy to mitigate the transition from generalization to memorization and alleviate model collapse. Empirical results show that our approach significantly enhances visual quality and diversity in recursive generation, effectively preventing collapse.'}",https://openreview.net{'value': '/pdf/f1a865840486de8b3b89d47b694e90329bfa8a91.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=6uwV6ytamU,{'value': 'DualCnst: Enhancing Zero-Shot Out-of-Distribution Detection via Text-Image Consistency in Vision-Language Models'},Fayi Le; Wenwu He; Chentao Cao; Dong Liang; Zhuo-Xu Cui,~Fayi_Le1; ~Wenwu_He1; ~Chentao_Cao1; ~Dong_Liang1; ~Zhuo-Xu_Cui1,{'value': ['Out-of-distribution Detection']},"{'value': 'Pretrained vision-language models (VLMs), such as CLIP, have shown promising zero-shot out-of-distribution (OOD) detection capabilities by leveraging semantic similarities between input images and textual labels. However, most existing approaches focus solely on expanding the label space in the text domain, ignoring complementary visual cues that can further enhance discriminative power. In this paper, we introduce DualCnst, a novel framework that integrates text-image dual consistency for improved zero-shot OOD detection. Specifically, we generate synthetic images from both ID and mined OOD textual labels using a text-to-image generative model, and jointly evaluate each test image based on (i) its semantic similarity to class labels and (ii) its visual similarity to the synthesized images. The resulting unified score function effectively combines multimodal information without requiring access to in-distribution images or additional training.\nWe further provide theoretical analysis showing that incorporating multimodal negative labels reduces score variance and improves OOD separability. Extensive experiments across diverse OOD benchmarks demonstrate that DualCnst achieves state-of-the-art performance while remaining scalable, data-agnostic, and fully compatible with prior text-only VLM-based methods.'}",https://openreview.net{'value': '/pdf/76ec8720e26ef14ba02c4eee1e192dc5c75c2ed3.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=6jKed3sx4f,{'value': 'Bi-Level Knowledge Transfer for Multi-Task Multi-Agent Reinforcement Learning'},Junkai Zhang; Jinmin He; Yifan Zhang; Yifan Zang; Ning Xu; Jian Cheng,~Junkai_Zhang3; ~Jinmin_He1; ~Yifan_Zhang2; ~Yifan_Zang1; ~Ning_Xu8; ~Jian_Cheng7,{'value': ['MARL; multi-task; policy generalization for zero-shot']},"{'value': 'Multi-Agent Reinforcement Learning (MARL) has achieved remarkable success in various real-world scenarios, but its high cost of online training makes it impractical to learn each task from scratch. \nTo enable effective policy reuse, we consider the problem of zero-shot generalization from offline data across multiple tasks. \nWhile prior work focuses on transferring individual skills of agents, we argue that the effective policy transfer across tasks should also capture the team-level coordination knowledge.\nIn this paper, we propose Bi-Level Knowledge Transfer (BiKT) for Multi-Task MARL, which performs knowledge transfer at both the individual and team levels. \nAt the individual level, we extract transferable individual skill embeddings from offline MARL trajectories.\nAt the team level, we define tactics as coordinated patterns of skill combinations and capture them by leveraging the learned skill embeddings. \nWe map skill combinations into compact tactic embeddings and then construct a tactic codebook.\nTo incorporate both skills and tactics into decision-making, we design a bi-level decision transformer that infers them in sequence.\nOur BiKT leverages both the generalizability of individual skills and the diversity of tactics, enabling the learned policy to perform effectively across multiple tasks.\nExtensive experiments on SMAC and MPE benchmarks demonstrate that BiKT achieves strong generalization to previously unseen tasks.'}",https://openreview.net{'value': '/pdf/2b86cc9f576d8abadc37889762dbb565bf235fe1.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=6j9xJ9pBjm,{'value': 'GUARDIAN: Safeguarding LLM Multi-Agent Collaborations with Temporal Graph Modeling'},Jialong Zhou; Lichao Wang; Xiao Yang,~Jialong_Zhou1; ~Lichao_Wang2; ~Xiao_Yang4,"{'value': ['LLM-based agent', 'defense', 'safety']}","{'value': ""The emergence of large language models (LLMs) enables the development of intelligent agents capable of engaging in complex and multi-turn dialogues. However, multi-agent collaboration faces critical safety challenges, such as hallucination amplification and error injection and propagation. This paper presents GUARDIAN, a unified method for detecting and mitigating multiple safety concerns in GUARDing Intelligent Agent collaboratioNs. By modeling the multi-agent collaboration process as a discrete-time temporal attributed graph, GUARDIAN explicitly captures the propagation dynamics of hallucinations and errors. The unsupervised encoder-decoder architecture incorporating an incremental training paradigm learns to reconstruct node attributes and graph structures from latent embeddings, enabling the identification of anomalous nodes and edges with unparalleled precision. Moreover, we introduce a graph abstraction mechanism based on the Information Bottleneck Theory, which compresses temporal interaction graphs while preserving essential patterns. Extensive experiments demonstrate GUARDIAN's effectiveness in safeguarding LLM multi-agent collaborations against diverse safety vulnerabilities, achieving state-of-the-art accuracy with efficient resource utilization. The code is available at https://github.com/JialongZhou666/GUARDIAN.""}",https://openreview.net{'value': '/pdf/12984819e947af4200e71748ef8d3b07f7b029cd.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=6iRZvJiC9Q,{'value': 'OpenCUA: Open Foundations for Computer-Use Agents'},Xinyuan Wang; Bowen Wang; Dunjie Lu; Junlin Yang; Tianbao Xie; Junli Wang; Jiaqi Deng; Xiaole Guo; Yiheng Xu; Chen Henry Wu; Zhennan Shen; Zhuokai Li; Ryan Li; Xiaochuan Li; Junda Chen; Zheng Boyuan; LI PEIHANG; Fangyu Lei; Ruisheng Cao; Yeqiao Fu; Dongchan Shin; Martin Shin; Hu Jiarui; Yuyan Wang; Jixuan Chen; Yuxiao Ye; Danyang Zhang; Yipu Wang; Heng Wang; Diyi Yang; Victor Zhong; Y.Charles; Zhilin Yang; Tao Yu,~Xinyuan_Wang3; ~Bowen_Wang8; ~Dunjie_Lu1; ~Junlin_Yang2; ~Tianbao_Xie1; ~Junli_Wang3; ~Jiaqi_Deng3; ~Xiaole_Guo1; ~Yiheng_Xu1; ~Chen_Henry_Wu1; ~Zhennan_Shen1; ~Zhuokai_Li1; ~Ryan_Li3; ~Xiaochuan_Li3; ~Junda_Chen2; ~Zheng_Boyuan1; ~LI_PEIHANG1; ~Fangyu_Lei1; ~Ruisheng_Cao1; ~Yeqiao_Fu1; ~Dongchan_Shin1; ~Martin_Shin1; ~Hu_Jiarui1; ~Yuyan_Wang8; ~Jixuan_Chen1; ~Yuxiao_Ye3; ~Danyang_Zhang2; ~Yipu_Wang1; ~Heng_Wang10; ~Diyi_Yang2; ~Victor_Zhong1; ~Y.Charles2; ~Zhilin_Yang2; ~Tao_Yu5,"{'value': ['Computer-Use Agent', 'Visual Language Model', 'Planning', 'Reasoning', 'Scaling', 'Dataset', 'Evaluation']}","{'value': 'Vision-language models have demonstrated impressive capabilities as computer-use agents (CUAs) capable of automating diverse computer tasks. As their commercial potential grows, critical details of the most capable CUA systems remain closed. As these agents will increasingly mediate digital interactions and execute consequential decisions on our behalf, the research community needs access to open CUA frameworks to study their capabilities, limitations, and risks. To bridge this gap, we propose OpenCUA, a comprehensive open-source framework for scaling CUA data and foundation models. Our framework consists of: (1) an annotation infrastructure that seamlessly captures human computer-use demonstrations; (2) AgentNet, the first large-scale computer-use task dataset spanning 3 operating systems and 200+ applications and websites; (3) a scalable pipeline that transforms demonstrations into state–action pairs with reflective long Chain-of-Thought reasoning that sustain robust performance gains as data scales. Our end-to-end agent models demonstrate strong performance across CUA benchmarks. In particular, OpenCUA-72B achieves an average success rate of 45.0% on OSWorld‑Verified, establishing a new state-of-the-art (SOTA) among open-source models. Further analysis confirms that our approach generalizes well across domains and benefits significantly from increased test-time computation. We release our annotation tool, datasets, code, and models to build open foundations for further CUA research.'}",https://openreview.net{'value': '/pdf/eb1bd0238abbc386303352dba1049a4d5d1fec83.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=6hidr8PJ8F,{'value': 'Spectral Convolutional Conditional Neural Processes'},Peiman Mohseni; Nick Duffield,~Peiman_Mohseni1; ~Nick_Duffield1,"{'value': ['neural process', 'stochastic process', 'meta learning', 'fourier neural operator']}","{'value': 'Neural processes (NPs) are probabilistic meta-learning models that map sets of observations to posterior predictive distributions, enabling inference at arbitrary domain points. Their capacity to handle variable-sized collections of unstructured observations, combined with simple maximum-likelihood training and uncertainty-aware predictions, makes them well-suited for modeling data over continuous domains. \nSince their introduction, several variants have been proposed. Early approaches typically represented observed data using finite-dimensional summary embeddings obtained through aggregation schemes such as mean pooling. However, this strategy fundamentally mismatches the infinite-dimensional nature of the generative processes that NPs aim to capture. \nConvolutional conditional neural processes (ConvCNPs) address this limitation by constructing infinite-dimensional functional embeddings processed through convolutional neural networks (CNNs) to enforce translation equivariance. Yet CNNs with local spatial kernels struggle to capture long-range dependencies without resorting to large kernels, which impose significant computational costs. To overcome this limitation, we propose the Spectral ConvCNP (SConvCNP), which performs global convolution in the frequency domain. Inspired by Fourier neural operators (FNOs) for learning solution operators of partial differential equations (PDEs), our approach directly parameterizes convolution kernels in the frequency domain, leveraging the relatively compact yet global Fourier representation of many natural signals. We validate the effectiveness of SConvCNP on both synthetic and real-world datasets, demonstrating how ideas from operator learning can advance the capabilities of NPs.'}",https://openreview.net{'value': '/pdf/f9dccc06361b4408a2e5c0c6d84581f3d8532069.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=6ZkcC9NmGU,{'value': 'ItDPDM: Information-Theoretic Discrete Poisson Diffusion Model'},Sagnik Bhattacharya; Abhiram Rao Gorle; Ahsan Bilal; Connor Ding; Amit Kumar Singh Yadav; Tsachy Weissman,~Sagnik_Bhattacharya1; ~Abhiram_Rao_Gorle1; ~Ahsan_Bilal1; ~Connor_Ding1; ~Amit_Kumar_Singh_Yadav1; ~Tsachy_Weissman1,"{'value': ['poisson diffusion', 'information-theoretic framework', 'discrete modeling', 'negative log likelihood']}","{'value': 'Generative modeling of non-negative, discrete data, such as symbolic music, remains challenging due to two persistent limitations in existing methods. Firstly, many approaches rely on modeling continuous embeddings, which is suboptimal for inherently discrete data distributions. Secondly, most models optimize variational bounds rather than exact data likelihood, resulting in inaccurate likelihood estimates and degraded sampling quality. While recent diffusion-based models have addressed these issues separately, we tackle them jointly. In this work, we introduce the Information-Theoretic Discrete Poisson Diffusion Model (ItDPDM), inspired by photon arrival process, which combines exact likelihood estimation with fully discrete-state modeling. Central to our approach is an information-theoretic Poisson Reconstruction Loss (PRL) that has a provable exact relationship with the true data likelihood. ItDPDM achieves improved likelihood and sampling performance over prior discrete and continuous diffusion models on a variety of synthetic discrete datasets. Furthermore, on real-world datasets such as symbolic music and images, ItDPDM attains superior likelihood estimates and competitive generation quality—demonstrating a proof of concept for distribution-robust discrete generative modeling.'}",https://openreview.net{'value': '/pdf/8aa1c78207fec137bf42b101a93f3f8141b024ae.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=6UAeCPQPwP,{'value': 'Inference of Whole Brain Electrophysiological Networks Through Multimodal Integration of Simultaneous Scalp and Intracranial EEG'},Shihao Yang; Feng Liu,~Shihao_Yang5; ~Feng_Liu1,"{'value': ['Electrophysiological Brain Networks', 'State-Space Models', 'Multimodal Neuroimaging', 'Brain Connectome', 'Working Memory']}","{'value': 'Brain imaging research has transitioned over the past decades from identifying isolated regions of task-evoked activation to characterizing the spatiotemporal dynamics of large-scale brain networks. Electrophysiological signals are the direct manifestation of brain activity; thus, characterizing whole-brain electrophysiological networks (WBEN) can serve as a fundamental tool for neuroscience studies and clinical applications. In this work, we introduce a framework for integrating scalp EEG and intracranial EEG (iEEG) for WBEN estimation through a principled state-space modeling approach, where an Expectation-Maximization (EM) algorithm is designed to infer the state variables and brain connectivity simultaneously. We validated the proposed method on synthetic data, and the results revealed improved performance compared to traditional two-step methods using scalp EEG only, demonstrating the importance of including iEEG signals for WBEN estimation. For real data with simultaneous EEG and iEEG, we applied the developed framework to understand the information flows during encoding and maintenance phases of a working memory task. The information flows between subcortical and cortical regions are delineated, highlighting more significant information flows from cortical to subcortical regions during encoding than during maintenance. The results are consistent with previous research findings, but from a whole-brain perspective, which underscores the unique utility of the proposed framework.'}",https://openreview.net{'value': '/pdf/557fb198e7b0d205ae33e3b616d37933a0fc878d.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=6LIbPoVFWS,{'value': 'OmniZoom: A Universal Plug-and-Play Paradigm for Cross-Device Smooth Zoom Interpolation'},Xiaoan Zhu; Yue Zhao; Tianyang Hu; Jiaming Guo; Yulan Zeng; Renjing Pei; Fenglong Song; Huajun Feng,~Xiaoan_Zhu2; ~Yue_Zhao38; ~Tianyang_Hu3; ~Jiaming_Guo3; ~Yulan_Zeng1; ~Renjing_Pei1; ~Fenglong_Song1; ~Huajun_Feng1,"{'value': ['Smooth Zoom', 'Frame Interpolation', '3D Gaussian Splatting', 'Velocity Disambiguity', 'Cross-Device Dataset']}","{'value': 'Dual-camera smartphones suffer from geometric and photometric inconsistencies during zoom transitions, primarily due to disparities in intrinsic/extrinsic parameters and divergent image processing pipelines between the two cameras. Existing interpolation methods struggle to effectively address this issue, constrained by the lack of ground-truth datasets and motion ambiguity in dynamic scenarios.\nTo overcome these challenges, we propose OmniZoom, a universal plug-and-play paradigm for cross-device smooth zoom interpolation. \nSpecifically, we present a novel cross-device virtual data generation method utilizing 3D Gaussian Splatting. This method tackles data scarcity by decoupling geometric features via spatial transition modeling and correcting photometric variations with dynamic color adaptation. It is further enhanced by cross-domain consistency learning for device-agnostic semantic alignment. Additionally, we introduce a plug-and-play 3D-TPR (3D Trajectory Progress Ratio Mapping) framework that surmounts 2D spatial limitations. As components of our framework, a texture-focus strategy is introduced for high-frequency detail preservation, incorporating mask penalty constraints to suppress interpolation artifacts. Our pipeline exhibits broad compatibility with diverse interpolation methods and achieves good performance across multiple public benchmarks. Real-world evaluations on various smartphone platforms also reveal significant quality improvements after fine-tuning on our synthetic data, which underscores the robustness and practical effectiveness of our approach for cross-device zoom applications.'}",https://openreview.net{'value': '/pdf/6a82cec5d2ef6b55533540b2409b843b243d77ad.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=6LGyChG6Ep,{'value': 'REArtGS: Reconstructing and Generating Articulated Objects via 3D Gaussian Splatting with Geometric and Motion Constraints'},Di Wu; Liu Liu; Zhou Linli; Anran Huang; Liangtu Song; Qiaojun Yu; Qi Wu; Cewu Lu,~Di_Wu40; ~Liu_Liu13; ~Zhou_Linli1; ~Anran_Huang1; ~Liangtu_Song1; ~Qiaojun_Yu1; ~Qi_Wu11; ~Cewu_Lu3,"{'value': ['Surface Reconstruction', '3DGS', 'Embodied Intelligence']}","{'value': 'Articulated objects, as prevalent entities in human life, their 3D representations play crucial roles across various applications. However, achieving both high-fidelity textured surface reconstruction and dynamic generation for articulated objects remains challenging for existing methods. In this paper, we present REArtGS, a novel framework that introduces additional geometric and motion constraints to 3D Gaussian primitives, enabling realistic surface reconstruction and generation for articulated objects. Specifically, given multi-view RGB images of arbitrary two states of articulated objects,  we first introduce an unbiased Signed Distance Field (SDF) guidance to regularize Gaussian opacity fields, enhancing geometry constraints and improving surface reconstruction quality. Then we establish deformable fields for 3D Gaussians constrained by the kinematic structures of articulated objects, achieving unsupervised generation of surface meshes in unseen states. Extensive experiments on both synthetic and real datasets demonstrate our approach achieves high-quality textured surface reconstruction for given states, and enables high-fidelity surface generation for unseen states. Project site: https://sites.google.com/view/reartgs/home.'}",https://openreview.net{'value': '/pdf/76e9245ea8fb744e2aa61b7842a891cf95a22d75.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=6Bu7naotbL,{'value': 'Train on Pins and Test on Obstacles for Rectilinear Steiner Minimum Tree'},Xingbo Du; Ruizhe Zhong; Junchi Yan,~Xingbo_Du1; ~Ruizhe_Zhong1; ~Junchi_Yan2,"{'value': ['rectilinear Steiner minimum tree', 'Obstacle-avoiding rectilinear Steiner minimum tree', 'reinforcement learning', 'end-to-end']}","{'value': 'Rectilinear Steiner Minimum Tree (RSMT) is widely used in Very Large Scale Integration (VLSI) and aims at connecting a set of pins using rectilinear edges while minimizing wirelength. Recently, learning-based methods have been explored to tackle this problem effectively. However, existing methods either suffer from excessive exploration of the search space or rely on heuristic combinations that compromise effectiveness and efficiency, and this limitation becomes notably exacerbated when extended to the obstacle-avoiding RSMT (OARSMT). To address this, we propose OAREST, a reinforcement learning-based framework for constructing an Obstacle-Avoiding Rectilinear Edge Sequence (RES) Tree. We theoretically establish the optimality of RES in obstacle-avoiding scenarios, which forms the foundation of our approach. Leveraging this theoretical insight, we introduce a dynamic masking strategy that supports parallel training across varying numbers of pins and extends to obstacles during inference. Empirical evaluations on both synthetic and real-world benchmarks show superior effectiveness and efficiency for RSMT and OARSMT problems, particularly in handling obstacles without training on them. Code available: https://github.com/Thinklab-SJTU/EDA-AI/.'}",https://openreview.net{'value': '/pdf/fda8c041365dcf4ecfd9bf4089fb8fc38687daf9.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=67xkPEM3bZ,{'value': 'How to Train Your LLM Web Agent: A Statistical Diagnosis'},Dheeraj Vattikonda; Santhoshi Ravichandran; Emiliano Penaloza; Hadi Nekoei; Thibault Le Sellier de Chezelles; Megh Thakkar; Nicolas Gontier; Miguel Muñoz-Mármol; Sahar Omidi Shayegan; Stefania Raimondo; Xue Liu; Alexandre Drouin; Alexandre Piché; Alexandre Lacoste; Massimo Caccia,~Dheeraj_Vattikonda1; ~Santhoshi_Ravichandran1; ~Emiliano_Penaloza1; ~Hadi_Nekoei1; ~Thibault_Le_Sellier_de_Chezelles1; ~Megh_Thakkar1; ~Nicolas_Gontier1; ~Miguel_Muñoz-Mármol1; ~Sahar_Omidi_Shayegan1; ~Stefania_Raimondo1; ~Xue_Liu1; ~Alexandre_Drouin2; ~Alexandre_Piché1; ~Alexandre_Lacoste1; ~Massimo_Caccia1,"{'value': ['LLM agents', 'interactive tasks', 'MDP', 'reinforcement learning', 'reproducibility', 'compute allocation', 'generalization', 'statistical analysis', 'hyperparameters', 'curriculum learning.']}","{'value': 'Large language model (LLM) agents for web interfaces have advanced rapidly, yet open-source systems still lag behind proprietary agents. Bridging this gap is key to enabling customizable, efficient, and privacy-preserving agents. Two challenges hinder progress: the reproducibility issues in RL and LLM agent training, where results often depend on sensitive factors like seeds and decoding parameters, and the focus of prior work on single-step tasks, overlooking the complexities of web-based, multi-step decision-making.\n\nWe address these gaps by providing a statistically driven study of training LLM agents for web tasks. Our two-stage pipeline combines imitation learning from a Llama 3.3 70B teacher with on-policy fine-tuning via Group Relative Policy Optimization (GRPO) on a Llama 3.1 8B student. Through 240 configuration sweeps and rigorous bootstrapping, we chart the first compute allocation curve for open-source LLM web agents. Our findings show that dedicating one-third of compute to teacher traces and the rest to RL improves MiniWoB++ success by 6 points and closes 60\\% of the gap to GPT-4o on WorkArena, while cutting GPU costs by 45\\%. We introduce a principled hyperparameter sensitivity analysis, offering actionable guidelines for robust and cost-effective agent training.'}",https://openreview.net{'value': '/pdf/0252f1f5697c0153740a7438e473e45964e85102.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=66Z5tS8E45,{'value': 'Diffusing DeBias: Synthetic Bias Amplification for Model Debiasing'},Massimiliano Ciranni; Vito Paolo Pastore; Roberto Di Via; Enzo Tartaglione; Francesca Odone; Vittorio Murino,~Massimiliano_Ciranni1; ~Vito_Paolo_Pastore1; ~Roberto_Di_Via1; ~Enzo_Tartaglione1; ~Francesca_Odone1; ~Vittorio_Murino1,"{'value': ['Model debiasing', 'bias amplification', 'diffusion models', 'image classification']}","{'value': 'The effectiveness of deep learning models in classification tasks is often challenged by the quality and quantity of training data whenever they are affected by strong spurious correlations between specific attributes and target labels. This results in a form of bias affecting training data, which typically leads to unrecoverable weak generalization in prediction. This paper addresses this problem by leveraging bias amplification with generated synthetic data only: we introduce Diffusing DeBias (DDB), a novel approach acting as a plug-in for common methods of unsupervised model debiasing, exploiting the inherent bias-learning tendency of diffusion models in data generation. Specifically, our approach adopts conditional diffusion models to generate synthetic bias-aligned images, which fully replace the original training set for learning an effective bias amplifier model to be subsequently incorporated into an end-to-end and a two-step unsupervised debiasing approach. By tackling the fundamental issue of bias-conflicting training samples’ memorization in learning auxiliary models, typical of this type of technique, our proposed method outperforms the current state-of-the-art in multiple benchmark datasets, demonstrating its potential as a versatile and effective tool for tackling bias in deep learning models. Code is available at https://github.com/Malga-Vision/DiffusingDeBias'}",https://openreview.net{'value': '/pdf/28c96aa6ccd780bc52d0e4dfe4a4e6544b857406.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=5puCVHYtDB,{'value': 'IPSI: Enhancing Structural Inference with Automatically Learned Structural Priors'},Zhongben Gong; Xiaoqun Wu; Mingyang Zhou,~Zhongben_Gong1; ~Xiaoqun_Wu1; ~Mingyang_Zhou2,"{'value': ['Structural Inference', 'AI for Science', 'Graph Neural Networks']}","{'value': 'We propose IPSI, a general iterative framework for structural inference in interacting dynamical systems. It integrates a pretrained structural estimator and a joint inference module based on the Variational Autoencoder (VAE); these components\nare alternately updated to progressively refine the inferred structures. Initially, the\nstructural estimator is trained on labels from either a meta-dataset or a baseline\nmodel to extract features and generate structural priors, which provide multi-level\nguidance for training the joint inference module. In subsequent iterations, pseudolabels from the joint module replace the initial labels. IPSI is compatible with\nvarious VAE-based models. Experiments on synthetic datasets of physical systems\ndemonstrate that IPSI significantly enhances the performance of structural inference models such as Neural Relational Inference (NRI). Ablation studies reveal\nthat feature and structural prior inputs to the joint module offer complementary\nimprovements from representational and generative perspectives.'}",https://openreview.net{'value': '/pdf/d17ca41a45552fde0f5c14ab9a6d6649f067d529.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=5ofJyjgrth,{'value': 'Modeling Microenvironment Trajectories on Spatial Transcriptomics with NicheFlow'},Kristiyan Sakalyan; Alessandro Palma; Filippo Guerranti; Fabian J Theis; Stephan Günnemann,~Kristiyan_Sakalyan1; ~Alessandro_Palma1; ~Filippo_Guerranti1; ~Fabian_J_Theis1; ~Stephan_Günnemann1,"{'value': ['flow matching', 'spatial transcriptomics', 'microenvironments', 'trajectory inference', 'generative modeling', 'point cloud']}","{'value': 'Understanding the evolution of cellular microenvironments in spatiotemporal data is essential for deciphering tissue development and disease progression. While experimental techniques like spatial transcriptomics now enable high-resolution mapping of tissue organization across space and time, current methods that model cellular evolution operate at the single-cell level, overlooking the coordinated development of cellular states in a tissue. We introduce NicheFlow, a flow-based generative model that infers the temporal trajectory of cellular microenvironments across sequential spatial slides. By representing local cell neighborhoods as point clouds, NicheFlow jointly models the evolution of cell states and spatial coordinates using optimal transport and Variational Flow Matching. Our approach successfully recovers both global spatial architecture and local microenvironment composition across diverse spatiotemporal datasets, from embryonic to brain development.'}",https://openreview.net{'value': '/pdf/21303fd21fdbb68fc5c1979df0e9ba6bb6828568.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=5fSkinHw7w,{'value': 'GUI-Actor: Coordinate-Free Visual Grounding for GUI Agents'},Qianhui Wu; Kanzhi Cheng; Rui Yang; Chaoyun Zhang; Jianwei Yang; Huiqiang Jiang; Jian Mu; Baolin Peng; Bo Qiao; Reuben Tan; Si Qin; Lars Liden; Qingwei Lin; Huan Zhang; Tong Zhang; Jianbing Zhang; Dongmei Zhang; Jianfeng Gao,~Qianhui_Wu1; ~Kanzhi_Cheng1; ~Rui_Yang8; ~Chaoyun_Zhang1; ~Jianwei_Yang1; ~Huiqiang_Jiang2; ~Jian_Mu2; ~Baolin_Peng2; ~Bo_Qiao1; ~Reuben_Tan1; ~Si_Qin2; ~Lars_Liden1; ~Qingwei_Lin1; ~Huan_Zhang1; ~Tong_Zhang2; ~Jianbing_Zhang1; ~Dongmei_Zhang2; ~Jianfeng_Gao1,"{'value': ['GUI Agents', 'cooridinate-free visual grounding', 'VLM', 'VLA']}","{'value': 'One of the principal challenges in building VLM-powered GUI agents is visual grounding—localizing the appropriate screen region for action execution based on both the visual content and the textual plans. Most existing work formulates this as a text-based coordinate generation task. However, these approaches suffer from several limitations: weak spatial-semantic alignment due to lack of explicit spatial supervision; inability to handle ambiguous supervision targets, as single-point predictions penalize valid variations; and a mismatch between the dense nature of screen coordinates and the coarse, patch-level granularity of visual features extracted by models like Vision Transformers. In this paper, we propose **GUI-Actor**, a VLM-based method for coordinate-free GUI grounding. At its core, **GUI-Actor** introduces an attention-based action head that learns to align a dedicated `<ACTOR>` token with all relevant visual patch tokens, enabling the model to propose one or more action regions in a single forward pass. In line with this, we further design a grounding verifier to evaluate and select the most plausible action region from the candidates proposed for action execution. Extensive experiments show that **GUI-Actor** outperforms prior state-of-the-art methods on multiple GUI action grounding benchmarks, with improved generalization to unseen screen resolutions and layouts. Notably, **GUI-Actor-7B** achieves scores of **40.7** with Qwen2-VL and **44.6** with Qwen2.5-VL as backbones, outperforming **UI-TARS-72B (38.1)** on ScreenSpot-Pro, with significantly fewer parameters and training data. Furthermore, by incorporating the verifier, we find that fine-tuning only the newly introduced action head (~100M parameters for 7B model) while keeping the VLM backbone frozen is sufficient to achieve performance comparable to previous state-of-the-art models, highlighting that **GUI-Actor** can endow the underlying VLM with effective grounding capabilities without compromising its general-purpose strengths. Project page: [https://aka.ms/GUI-Actor](https://aka.ms/GUI-Actor)'}",https://openreview.net{'value': '/pdf/b077c66cdcba53dd1796d274aeb36050df714f8a.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=5b5wZg6Zeo,{'value': 'A solvable model of learning generative diffusion: theory and insights'},Hugo Cui; Cengiz Pehlevan; Yue M. Lu,~Hugo_Cui1; ~Cengiz_Pehlevan2; ~Yue_M._Lu1,"{'value': ['high-dimensional asymptotics', 'statistical physics', 'diffusion model']}","{'value': 'In this manuscript, we analyze a solvable model of flow or diffusion-based generative model. We consider the problem of learning a model parametrized by a two-layer auto-encoder, trained with online stochastic gradient descent, on a high-dimensional target density with an underlying low-dimensional manifold structure. We derive a tight asymptotic characterization of low-dimensional projections of the distribution of samples generated by the learned model, ascertaining in particular its dependence on the number of training samples. Building on this analysis, we discuss how mode collapse can arise, and lead to model collapse when the generative model is re-trained on generated synthetic data.'}",https://openreview.net{'value': '/pdf/5dabf9acd5e97798f87462edf922907db6f8ec7f.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=5NkfjxMpWe,{'value': 'PerceptionLM: Open-Access Data and Models for Detailed Visual Understanding'},Jang Hyun Cho; Andrea Madotto; Effrosyni Mavroudi; Triantafyllos Afouras; Tushar Nagarajan; Muhammad Maaz; Yale Song; Tengyu Ma; Shuming Hu; Suyog Jain; Miguel Martin; Huiyu Wang; Hanoona Abdul Rasheed; Peize Sun; Po-Yao Huang; Daniel Bolya; Nikhila Ravi; Shashank Jain; Tammy Stark; Seungwhan Moon; Babak Damavandi; Vivian Lee; Andrew Westbury; Salman Khan; Philipp Kraehenbuehl; Piotr Dollar; Lorenzo Torresani; Kristen Grauman; Christoph Feichtenhofer,~Jang_Hyun_Cho1; ~Andrea_Madotto1; ~Effrosyni_Mavroudi1; ~Triantafyllos_Afouras1; ~Tushar_Nagarajan1; ~Muhammad_Maaz1; ~Yale_Song1; ~Tengyu_Ma3; ~Shuming_Hu3; ~Suyog_Jain1; ~Miguel_Martin1; ~Huiyu_Wang1; ~Hanoona_Abdul_Rasheed1; ~Peize_Sun1; ~Po-Yao_Huang2; ~Daniel_Bolya1; ~Nikhila_Ravi1; ~Shashank_Jain1; ~Tammy_Stark1; ~Seungwhan_Moon1; ~Babak_Damavandi1; ~Vivian_Lee1; ~Andrew_Westbury1; ~Salman_Khan4; ~Philipp_Kraehenbuehl1; ~Piotr_Dollar1; ~Lorenzo_Torresani1; ~Kristen_Grauman1; ~Christoph_Feichtenhofer4,"{'value': ['llm', 'mllm', 'vlm', 'vision and language', 'perception']}","{'value': ""Vision-language models are integral to computer vision research, yet many high-performing models remain closed-source, obscuring their data, design and training recipe. The research community has responded by using distillation from black-box models to label training data, achieving strong benchmark results, at the cost of measurable scientific progress. However, without knowing the details of the teacher model and its data sources, scientific progress remains difficult to measure. In this paper, we study building a Perception Language Model (PLM) in a fully open and reproducible framework for transparent research in image and video understanding.  We analyze standard training pipelines without distillation from proprietary models and explore large-scale synthetic data to identify critical data gaps, particularly in detailed video understanding. To bridge these gaps, we release 2.8M human-labeled instances of fine-grained video question-answer pairs and spatio-temporally grounded video captions. Additionally, we introduce PLM–VideoBench, a suite for evaluating challenging video understanding tasks focusing on the ability to reason about ''what'', ''where'', ''when'', and ''how'' of a video. We make our work fully reproducible by providing data, training recipes, code & models.""}",https://openreview.net{'value': '/pdf/4bf7839de7763e96318a3ecc89aea5822812624b.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=5J4IpiMKkq,{'value': 'In-Context Fully Decentralized Cooperative Multi-Agent Reinforcement Learning'},Chao Li; Bingkun BAO; Yang Gao,~Chao_Li20; ~Bingkun_BAO1; ~Yang_Gao3,"{'value': ['Cooperative multi-agent reinforcement learning', 'Fully decentralized setting', 'Context modeling']}","{'value': ""In this paper, we consider fully decentralized cooperative multi-agent reinforcement learning, where each agent has access only to the states, its local actions, and the shared rewards. The absence of information about other agents' actions typically leads to the non-stationarity problem during per-agent value function updates, and the relative overgeneralization issue during value function estimation. However, existing works fail to address both issues simultaneously, as they lack the capability to model the agents' joint policy in a fully decentralized setting. To overcome this limitation, we propose a simple yet effective method named Return-Aware Context (RAC). RAC formalizes the dynamically changing task, as locally perceived by each agent, as a contextual Markov Decision Process (MDP), and addresses both non-stationarity and relative overgeneralization through return-aware context modeling. Specifically, the contextual MDP attributes the non-stationary local dynamics of each agent to switches between contexts, each corresponding to a distinct joint policy. Then, based on the assumption that the joint policy changes only between episodes, RAC distinguishes different joint policies by the training episodic return and constructs contexts using discretized episodic return values. Accordingly, RAC learns a context-based value function for each agent to address the non-stationarity issue during value function updates. For value function estimation, an individual optimistic marginal value is constructed to encourage the selection of optimal joint actions, thereby mitigating the relative overgeneralization problem. Experimentally, we evaluate RAC on various cooperative tasks (including matrix game, predator and prey, and SMAC), and its significant performance validates its effectiveness.""}",https://openreview.net{'value': '/pdf/c8e43e29371115e9c66bce1f2bd25f74ce725ade.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=5Iw1nDtYmT,{'value': 'KVFlow: Efficient Prefix Caching for Accelerating LLM-Based Multi-Agent Workflows'},Zaifeng Pan; AJJKUMAR PATEL; Yipeng Shen; Zhengding Hu; Yue Guan; Wan-Lu Li; Lianhui Qin; Yida Wang; Yufei Ding,~Zaifeng_Pan1; ~AJJKUMAR_PATEL1; ~Yipeng_Shen2; ~Zhengding_Hu3; ~Yue_Guan2; ~Wan-Lu_Li1; ~Lianhui_Qin1; ~Yida_Wang1; ~Yufei_Ding1,"{'value': ['LLM serving systems', 'multi-agent workflow', 'prefix caching']}","{'value': ""Large language model (LLM) based agentic workflows have become a popular paradigm for coordinating multiple specialized agents to solve complex tasks. To improve serving efficiency, existing LLM systems employ prefix caching to reuse key-value (KV) tensors corresponding to agents' fixed prompts, thereby avoiding redundant computation across repeated invocations. However, current systems typically evict KV caches using a Least Recently Used (LRU) policy, which fails to anticipate future agent usage and often discards KV caches shortly before their reuse. This leads to frequent cache misses and substantial recomputation or swap- ping overhead. We present KVFlow, a workflow-aware KV cache management framework tailored for agentic workloads. KVFlow abstracts the agent execution schedule as an Agent Step Graph and assigns each agent a steps-to-execution value that estimates its temporal proximity to future activation. These values guide a fine-grained eviction policy at the KV node level, allowing KVFlow to preserve entries likely to be reused and efficiently manage shared prefixes in tree-structured caches. Moreover, KVFlow introduces a fully overlapped KV prefetching mecha- nism, which proactively loads required tensors from CPU to GPU in background threads for agents scheduled in the next step, thereby avoiding cache miss stalls during generation. Compared to SGLang with hierarchical radix cache, KVFlow achieves up to 1.83× speedup for single workflows with large prompts, and up to 2.19× speedup for scenarios with many concurrent workflows.""}",https://openreview.net{'value': '/pdf/2c47adb29432f99879fceb1371b72f6e97e1f3ac.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=5GoxWETVvV,{'value': 'Sampling by averaging: A multiscale approach to score estimation'},Paula Cordero Encinar; Andrew B. Duncan; Sebastian Reich; O. Deniz Akyildiz,~Paula_Cordero_Encinar1; ~Andrew_B._Duncan1; ~Sebastian_Reich1; ~O._Deniz_Akyildiz1,"{'value': ['sampling from multi-modal densities', 'diffusion process', 'multiscale SDEs']}","{'value': 'We introduce a novel framework for efficient sampling from complex, unnormalised target distributions by exploiting multiscale dynamics. Traditional score-based sampling methods either rely on learned approximations of the score function or involve computationally expensive nested Markov chain Monte Carlo (MCMC) loops. In contrast, the proposed approach leverages stochastic averaging within a slow-fast system of stochastic differential equations (SDEs) to estimate intermediate scores along a diffusion path without training or inner-loop MCMC. Two algorithms are developed under this framework: *MultALMC*, which uses multiscale annealed Langevin dynamics, and *MultCDiff*, based on multiscale controlled diffusions for the reverse-time Ornstein-Uhlenbeck process. Both overdamped and underdamped variants are considered, with theoretical guarantees of convergence to the desired diffusion path. The framework is extended to handle heavy-tailed target distributions using Student’s t-based noise models and tailored fast-process dynamics. Empirical results across synthetic and real-world benchmarks, including multimodal and high-dimensional distributions, demonstrate that the proposed methods are competitive with existing samplers in terms of accuracy and efficiency, without the need for learned models.'}",https://openreview.net{'value': '/pdf/753efd7f1b58d6436dd6b4c7def481c835ae169d.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=5GaDcRVgBw,{'value': 'MASTER: Enhancing Large Language Model via Multi-Agent Simulated Teaching'},Liang Yue; Yihong Tang; Kehai Chen; Jie Liu; Min Zhang,~Liang_Yue2; ~Yihong_Tang2; ~Kehai_Chen2; ~Jie_Liu15; ~Min_Zhang9,{'value': ['Instruction Fine-Tuning；Data Augmentation；Multi-Agent Systems；Natural Language Processing']},"{'value': ""Instruction fine-tuning is crucial in NLP tasks, enhancing pretrained models' instruction-following capabilities and task-specific performance. However, obtaining high-quality fine-tuning data for large models is challenging due to data collection difficulties and high production costs. To address this, we propose MASTER, a novel data augmentation method that enriches original data through interactions among multiple agents with varying cognitive levels. We simulate three pedagogically grounded teaching scenarios, leveraging multi-agent conversations to generate high-quality teacher-student interaction data. Utilizing MASTER, we construct BOOST-QA, a fine-tuning dataset augmented from existing datasets like Orca-Math-200k, ProcQA, and OpenHermes2.5. Experiments show that models fine-tuned with BOOST-QA perform excellently across multiple benchmarks, demonstrating strong multitask generalization. Notably, MASTER significantly improves models' reasoning abilities in complex tasks, providing valuable insights for future research.""}",https://openreview.net{'value': '/pdf/bb6088909057b451870503a70bd0449f916e66ff.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=5BfO9i4kj1,{'value': 'TreeSplat: Mergeable Tree for Deformable Gaussian Splatting'},Qiuhong Shen; Xingyi Yang; Xinchao Wang,~Qiuhong_Shen1; ~Xingyi_Yang1; ~Xinchao_Wang1,"{'value': ['Dynamic 3D Scenes', '3D Gaussian Splatting']}","{'value': ""Dynamic 3D scene reconstruction from multi-view videos demands representation to model complex deformations at scale. Current Gaussian Splatting based methods often either suffer from significant computation cost due to dense MLP-based modeling or explicit modeling deformation of each Gaussian independently. However, the dynamics of objects within a scene are typically hierarchical and exhibit structural correlations. To leverage these structural priors into the representation, we introduce **TreeSplat**, a **Tree** data structure for deformable Gaussian **Splat**ting. In TreeSplat, as the name suggests, motions of Gaussian are represented hierarchically within a tree. Each node learns coefficients for time-varying basis functions, defining a part of the motion. The full motion for any given Gaussian is then determined by accumulating these transformations along the tree path from its leaf node to the root node. This tree isn't predefined; instead, it is constructed adaptively alongside Gaussian densification, where cloning or splitting a Gaussian correspondingly creates new leaf nodes. One central property of TreeSplat is its mergeability; after optimization during training, the hierarchical motion parameters for each Gaussian can be efficiently consolidated. By performing this merging step before test time, we eliminate the need to traverse the tree explicitly for each Gaussian during rendering. This results in dramatically faster rendering over 200 FPS and compact storage, while maintaining state-of-the-art rendering quality. Experiments on diverse synthetic and real-world datasets validate these advantages.""}",https://openreview.net{'value': '/pdf/2dfbd16739849f3c3fa068b87e5b2386b47941a5.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=56CgYnf9Dr,{'value': 'HyperMARL: Adaptive Hypernetworks for Multi-Agent RL'},Kale-ab Tessera; Arrasy Rahman; Amos Storkey; Stefano V. Albrecht,~Kale-ab_Tessera1; ~Arrasy_Rahman1; ~Amos_Storkey1; ~Stefano_V._Albrecht1,"{'value': ['Multi-Agent Reinforcement Learning', 'Parameter Sharing', 'Specialisation', 'Behavioural Diversity']}","{'value': 'Adaptive cooperation in multi-agent reinforcement learning (MARL) requires policies to express homogeneous, specialised, or mixed behaviours, yet achieving this adaptivity remains a critical challenge. While parameter sharing (PS) is standard for efficient learning, it notoriously suppresses the behavioural diversity required for specialisation. This failure is largely due to cross-agent gradient interference, a problem we find is surprisingly exacerbated by the common practice of *coupling agent IDs with observations*. Existing remedies typically add complexity through altered objectives, manual preset diversity levels, or sequential updates -- raising a fundamental question: *can shared policies adapt without these intricacies?* We propose a solution built on a key insight: an agent-conditioned hypernetwork can generate agent-specific parameters and *decouple* observation- and agent-conditioned gradients, directly countering the interference from coupling agent IDs with observations. Our resulting method, **HyperMARL**, avoids the complexities of prior work and empirically reduces policy gradient variance. Across diverse MARL benchmarks (22 scenarios, up to 30 agents), HyperMARL achieves performance competitive with six key baselines while preserving behavioural diversity comparable to non-parameter sharing methods, establishing it as a versatile and principled approach for adaptive MARL. The code is publicly available at https://github.com/KaleabTessera/HyperMARL.'}",https://openreview.net{'value': '/pdf/419bb79fe6098ef6311e7f20a067e51d6dc2efcb.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=4xvE6Iy77Y,{'value': 'PRIMT: Preference-based Reinforcement Learning with Multimodal Feedback and Trajectory Synthesis from Foundation Models'},Ruiqi Wang; Dezhong Zhao; Ziqin Yuan; Tianyu Shao; Guohua Chen; Dominic Kao; Sungeun Hong; Byung-Cheol Min,~Ruiqi_Wang14; ~Dezhong_Zhao1; ~Ziqin_Yuan1; ~Tianyu_Shao1; ~Guohua_Chen1; ~Dominic_Kao1; ~Sungeun_Hong2; ~Byung-Cheol_Min1,"{'value': ['Preference-based Reinforcement Learning', 'Foundation Models for Robotics', 'Neuro-Symbolic Fusion', 'Multimodal Feedback', 'Causal Inference', 'Trajectory Synthesis', 'Robot Manipulation']}","{'value': 'Preference-based reinforcement learning (PbRL) has emerged as a promising paradigm for teaching robots complex behaviors without reward engineering. However, its effectiveness is often limited by two critical challenges: the reliance on extensive human input and the inherent difficulties in resolving query ambiguity and credit assignment during reward learning. In this paper, we introduce PRIMT, a PbRL framework designed to overcome these challenges by leveraging foundation models (FMs) for multimodal synthetic feedback and trajectory synthesis. Unlike prior approaches that rely on single-modality FM evaluations, PRIMT employs a hierarchical neuro-symbolic fusion strategy, integrating the complementary strengths of vision-language models (VLMs) and large language models (LLMs) in evaluating robot behaviors for more reliable and comprehensive feedback. PRIMT also incorporates foresight trajectory generation to warm-start the trajectory buffer with bootstrapped samples, reducing early-stage query ambiguity, and hindsight trajectory augmentation for counterfactual reasoning with a causal auxiliary loss to improve credit assignment. We evaluate PRIMT on 2 locomotion and 6 manipulation tasks on various benchmarks, demonstrating superior performance over FM-based and scripted baselines. Website at https://primt25.github.io/.'}",https://openreview.net{'value': '/pdf/cdfd3bdfaabcaadcbca0caae2c468c1730a2cc88.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=4xl00JWQ1z,{'value': 'PointMAC: Meta-Learned Adaptation for Robust Test-Time Point Cloud Completion'},Linlian Jiang; Rui Ma; Li Gu; Ziqiang Wang; Xinxin Zuo; Yang Wang,~Linlian_Jiang1; ~Rui_Ma4; ~Li_Gu1; ~Ziqiang_Wang3; ~Xinxin_Zuo1; ~Yang_Wang1,{'value': ['point cloud completion']},"{'value': 'Point cloud completion is essential for robust 3D perception in safety-critical applications such as robotics and augmented reality. However, existing models perform static inference and rely heavily on inductive biases learned during training, limiting their ability to adapt to novel structural patterns and sensor-induced distortions at test time.\nTo address this limitation, we propose PointMAC, a meta-learned framework for robust test-time adaptation in point cloud completion. It enables sample-specific refinement without requiring additional supervision.\nOur method optimizes the completion model under two self-supervised auxiliary objectives that simulate structural and sensor-level incompleteness.\nA meta-auxiliary learning strategy based on Model-Agnostic Meta-Learning (MAML) ensures that adaptation driven by auxiliary objectives is consistently aligned with the primary completion task.\nDuring inference, we adapt the shared encoder on-the-fly by optimizing auxiliary losses, with the decoder kept fixed. To further stabilize adaptation, we introduce Adaptive $\\lambda$-Calibration, a meta-learned mechanism for balancing gradients between primary and auxiliary objectives. \nExtensive experiments on synthetic, simulated, and real-world datasets demonstrate that PointMAC achieves state-of-the-art results by refining each sample individually to produce high-quality completions. To the best of our knowledge, this is the first work to apply meta-auxiliary test-time adaptation to point cloud completion.'}",https://openreview.net{'value': '/pdf/c3827091222881e6b0c5ced8b4cf2107ef0d49fe.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=4xGJZkdjCU,{'value': 'On Fairness of Unified Multimodal Large Language Model for Image Generation'},Ming Liu; Hao Chen; Jindong Wang; Liwen Wang; Bhiksha Raj; Wensheng Zhang,~Ming_Liu21; ~Hao_Chen15; ~Jindong_Wang4; ~Liwen_Wang3; ~Bhiksha_Raj1; ~Wensheng_Zhang2,"{'value': ['Fairness', 'Unified Multimodal Large Language Model', 'Bias']}","{'value': ""Unified multimodal large language models (U-MLLMs) have demonstrated impressive performance in end-to-end visual understanding and generation tasks. However, compared to generation-only systems (e.g., Stable Diffusion), the unified architecture of U-MLLMs introduces new risks of propagating demographic stereotypes. In this paper, we benchmark several state-of-the-art U-MLLMs and show that they exhibit significant gender and race biases in the generated outputs. To diagnose the source of these biases, we propose a locate-then-fix framework: we first audit the vision and language components — using techniques such as linear probing and controlled generation — and find that the language model appears to be a primary origin of the observed generative bias. Moreover, we observe a ``partial alignment'' phenomenon, where the U-MLLMs exhibit less bias in understanding tasks yet produce substantially biased images. To address this, we introduce a novel \\emph{balanced preference loss} that enforces uniform generation probabilities across demographics by leveraging a synthetically balanced dataset. Extensive experiments show that our approach significantly reduces demographic bias while preserving semantic fidelity and image quality. Our findings underscore the need for targeted debiasing strategies in unified multimodal systems and introduce a practical approach to mitigate biases.""}",https://openreview.net{'value': '/pdf/5bae5b706da43f8b16d60529d0e26ac21ad24661.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=4p28lkk44b,"{'value': ""Achilles' Heel of Mamba: Essential difficulties of the Mamba architecture demonstrated by synthetic data""}",Tianyi Chen; Pengxiao Lin; Zhiwei Wang; Zhi-Qin John Xu,~Tianyi_Chen13; ~Pengxiao_Lin1; ~Zhiwei_Wang3; ~Zhi-Qin_John_Xu1,"{'value': ['Mamba', 'Transformer', 'Deep learning']}","{'value': ""State Space Models (SSMs) have emerged as promising alternatives to attention mechanisms, with the Mamba architecture demonstrating impressive performance and linear complexity for processing long sequences. However, the fundamental differences between Mamba and Transformer architectures remain incompletely understood. In this work, we use carefully designed synthetic tasks to reveal Mamba's inherent limitations. Through experiments, we identify that Mamba's nonlinear convolution introduces an asymmetry bias that significantly impairs its ability to recognize symmetrical patterns and relationships. Using composite function and inverse sequence matching tasks, we demonstrate that Mamba strongly favors compositional solutions over symmetrical ones and struggles with tasks requiring the matching of reversed sequences. We show these limitations stem not from the SSM module itself but from the nonlinear convolution preceding it, which fuses token information asymmetrically. These insights provide a new understanding of Mamba's constraints and suggest concrete architectural improvements for future sequence models.""}",https://openreview.net{'value': '/pdf/af6c999c81f75ffe220dcab582908d8821390f64.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=4f6mEr1DQs,{'value': 'Complete Structure Guided Point Cloud Completion via Cluster- and Instance-Level Contrastive Learning'},Yang Chen; Yirun Zhou; WEIZHONG ZHANG; Cheng Jin,~Yang_Chen14; ~Yirun_Zhou1; ~WEIZHONG_ZHANG2; ~Cheng_Jin2,"{'value': ['3D computer Vision', 'Point cloud', 'self-supervised point cloud completion', 'contrastive Learning']}","{'value': 'Point cloud completion, aiming to reconstruct missing part from incomplete point clouds, is a pivotal task in 3D computer vision. Traditional supervised approaches often necessitate complete point clouds for training supervision, which are not readily accessible in real-world applications. Recent studies have attempted to mitigate this dependency by employing self-supervise mechanisms. However, these approaches frequently yield suboptimal results due to the absence of complete structure in the point cloud data during training. To address these issues, in this paper, we propose an effective framework to complete the point cloud under the guidance of self learned complete structure. A key contribution of our work is the development of a novel self-supervised complete structure reconstruction module, which can learn the complete structure explicitly from incomplete point clouds and thus eliminate the reliance on training data from complete point clouds. Additionally, we introduce a contrastive learning approach at both the cluster- and instance-level to extract shape features guided by the complete structure and to capture style features, respectively. This dual-level learning design ensures that the generated point clouds are both shape-completed and detail-preserving. Extensive experiments on both synthetic and real-world datasets demonstrate that our approach significantly outperforms state-of-the-art self-supervised methods.'}",https://openreview.net{'value': '/pdf/898e52d701ce00afeb8ad0fde70d19f25cc91569.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=4ULtNYHc5T,{'value': 'Exploring Tradeoffs through Mode Connectivity for Multi-Task Learning'},Zhipeng Zhou; Ziqiao Meng; Pengcheng Wu; Peilin Zhao; Chunyan Miao,~Zhipeng_Zhou2; ~Ziqiao_Meng1; ~Pengcheng_Wu1; ~Peilin_Zhao2; ~Chunyan_Miao1,"{'value': ['Multi-Task Learning', 'Mode Connectivity']}","{'value': 'Nowadays deep models are required to be versatile due to the increasing realistic needs. Multi-task learning (MTL) offers an efficient way for this purpose to learn multiple tasks simultaneously with a single model. However, prior MTL solutions often focus on resolving conflicts and imbalances during optimization, which may not outperform simple linear scalarization strategies~\\citep{xin2022current}. Instead of altering the optimization trajectory, this paper leverages mode connectivity to efficiently approach the Pareto front and identify the desired trade-off point. Unlike Pareto Front Learning (PFL), which aims to align with the entire Pareto front, we focus on effectively and efficiently exploring optimal trade-offs. However, three challenges persist: (1) the low-loss path can neither fully traverse trade-offs nor align with user preference due to its randomness, (2) commonly adopted Bézier curves in mode connectivity are ill-suited to navigating the complex loss landscapes of deep models, and (3) poor scalability to large-scale task scenarios. To address these challenges, we adopt non-uniform rational B-Splines (NURBS) to model mode connectivity, allowing for more flexible and precise curve optimization. Additionally, we introduce an order-aware objective to explore task loss trade-offs and employ a task grouping strategy to enhance scalability under massive task scenarios. Extensive experiments on key MTL datasets demonstrate that our proposed method, *EXTRA* (EXplore TRAde-offs), effectively identifies the desired point on the Pareto front and achieves state-of-the-art performance. *EXTRA* is also validated as a plug-and-play solution for mainstream MTL approaches.'}",https://openreview.net{'value': '/pdf/7270729acb82c91739635deec06645f8f9d79115.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=4OLbpaTKJe,{'value': 'Model-Based Policy Adaptation for Closed-Loop End-to-end Autonomous Driving'},Haohong Lin; Yunzhi Zhang; Wenhao Ding; Jiajun Wu; Ding Zhao,~Haohong_Lin1; ~Yunzhi_Zhang1; ~Wenhao_Ding1; ~Jiajun_Wu1; ~Ding_Zhao1,"{'value': ['Autonomous Driving', 'World Model', 'Policy Adaptation']}","{'value': 'End-to-end (E2E) autonomous driving models have demonstrated strong performance in open-loop evaluations but often suffer from cascading errors and poor generalization in closed-loop settings. To address this gap, we propose Model-based Policy Adaptation (MPA), a general framework that enhances the robustness and safety of pretrained E2E driving agents during deployment. MPA first generates diverse counterfactual trajectories using a geometry-consistent simulation engine, exposing the agent to scenarios beyond the original dataset. Based on this generated data, MPA trains a diffusion-based policy adapter to refine the base policy’s predictions and a multi-step Q value model to evaluate long-term outcomes. At inference time, the adapter proposes multiple trajectory candidates, and the Q value model selects the one with the highest expected utility. Experiments on the nuScenes benchmark using a photorealistic closed-loop simulator demonstrate that MPA significantly improves performance across in-domain, out-of-domain, and safety-critical scenarios. We further investigate how the scale of counterfactual data and inference-time guidance strategies affect overall effectiveness.'}",https://openreview.net{'value': '/pdf/0e2581347e5d31a0ea0495f5e82c4e6cd4d03aa2.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=4NaW9mbTqq,{'value': 'Seeing the Wind from a Falling Leaf'},Zhiyuan Gao; Jiageng Mao; Hong-Xing Yu; Haozhe Lou; Emily Yue-ting Jia; Jernej Barbic; Jiajun Wu; Yue Wang,~Zhiyuan_Gao1; ~Jiageng_Mao1; ~Hong-Xing_Yu1; ~Haozhe_Lou2; ~Emily_Yue-ting_Jia1; ~Jernej_Barbic1; ~Jiajun_Wu1; ~Yue_Wang2,{'value': ['Physics-based Vision']},"{'value': 'A longstanding goal in computer vision is to model motions from videos, while the representations behind motions, i.e. the invisible physical interactions that cause objects to deform and move, remain largely unexplored. In this paper, we study how to recover the invisible forces from visual observations, e.g., estimating the wind field by observing a leaf falling to the ground. Our key innovation is an end-to-end differentiable inverse graphics framework, which jointly models object geometry, physical properties, and interactions directly from videos. Through backpropagation, our approach enables the recovery of force representations from object motions. We validate our method on both synthetic and real-world scenarios, and the results demonstrate its ability to infer plausible force fields from videos. Furthermore, we show the potential applications of our approach, including physics-based video generation and editing. We hope our approach sheds light on understanding and modeling the physical process behind pixels, bridging the gap between vision and physics. Please check more video results in our project page https://chaoren2357.github.io/seeingthewind/ .'}",https://openreview.net{'value': '/pdf/8cd7b23dd1782bb42e3cd67a239fd7d59e3a0b5d.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=4KengZ1RNX,{'value': 'Adjusting Initial Noise to Mitigate Memorization in Text-to-Image Diffusion Models'},Hyeonggeun Han; Sehwan Kim; Hyungjun Joo; Sangwoo Hong; Jungwoo Lee,~Hyeonggeun_Han1; ~Sehwan_Kim2; ~Hyungjun_Joo1; ~Sangwoo_Hong1; ~Jungwoo_Lee1,"{'value': ['Diffusion models', 'Memorization']}","{'value': 'Despite their impressive generative capabilities, text-to-image diffusion models often memorize and replicate training data, prompting serious concerns over privacy and copyright. Recent work has attributed this memorization to an attraction basin—a region where applying classifier-free guidance (CFG) steers the denoising trajectory toward memorized outputs—and has proposed deferring CFG application until the denoising trajectory escapes this basin. However, such delays often result in non-memorized images that are poorly aligned with the input prompts, highlighting the need to promote earlier escape so that CFG can be applied sooner in the denoising process. In this work, we show that the initial noise sample plays a crucial role in determining when this escape occurs. We empirically observe that different initial samples lead to varying escape times. Building on this insight, we propose two mitigation strategies that adjust the initial noise—either collectively or individually—to find and utilize initial samples that encourage earlier basin escape. These approaches significantly reduce memorization while preserving image-text alignment.'}",https://openreview.net{'value': '/pdf/70265c320cd814d9cdd410644c47a4c1c6df1f87.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=4KRERpdVDC,{'value': 'Finding separatrices of dynamical flows with Deep Koopman Eigenfunctions'},Kabir Vinay Dabholkar; Omri Barak,~Kabir_Vinay_Dabholkar1; ~Omri_Barak1,"{'value': ['Reverse-engineering', 'Recurrent Neural Networks', 'Dynamical Systems', 'Koopman Operator']}","{'value': 'Many natural systems, including neural circuits involved in decision making, are modeled as high-dimensional dynamical systems with multiple stable states. While existing analytical tools primarily describe behavior near stable equilibria, characterizing separatrices -- the manifolds that delineate boundaries between different basins of attraction -- remains challenging, particularly in high-dimensional settings. Here, we introduce a numerical framework leveraging Koopman Theory combined with Deep Neural Networks to effectively characterize separatrices. Specifically, we approximate Koopman Eigenfunctions (KEFs) associated with real positive eigenvalues, which vanish precisely at the separatrices. Utilizing these scalar KEFs, optimization methods efficiently locate separatrices even in complex systems. We demonstrate our approach on synthetic benchmarks, ecological network models, and high-dimensional recurrent neural networks trained on either neuroscience-inspired tasks or fit to real neural data. Moreover, we illustrate the practical utility of our method by designing optimal perturbations that can shift systems across separatrices, enabling predictions relevant to optogenetic stimulation experiments in neuroscience.'}",https://openreview.net{'value': '/pdf/6954b4778e422e41ecc76f86844fa530e4efc7d8.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=4BsrGHtvW5,{'value': 'Adaptive Context Length Optimization with Low-Frequency Truncation for Multi-Agent Reinforcement Learning'},Wenchang Duan; Yaoliang Yu; Jiwan He; Yi Shi,~Wenchang_Duan1; ~Yaoliang_Yu1; ~Jiwan_He1; ~Yi_Shi8,"{'value': ['multi-agent reinforcement learning', 'adaptive context length', 'low-frequency truncation', 'long-term dependencies']}","{'value': 'Recently, deep multi-agent reinforcement learning (MARL) has demonstrated promising performance for solving challenging tasks, such as long-term dependencies and non-Markovian environments. Its success is partly attributed to conditioning policies on large fixed context length. However, such large fixed context lengths may lead to limited exploration efficiency and redundant information. In this paper, we propose a novel MARL framework to obtain adaptive and effective contextual information. Specifically, we design a central agent that dynamically optimizes context length via temporal gradient analysis, enhancing exploration to facilitate convergence to global optima in MARL. Furthermore, to enhance the adaptive optimization capability of the context length, we present an efficient input representation for the central agent, which effectively filters redundant information. By leveraging a Fourier-based low-frequency truncation method, we extract global temporal trends across decentralized agents, providing an effective and efficient representation of the MARL environment. Extensive experiments demonstrate that the proposed method achieves state-of-the-art (SOTA) performance on long-term dependency tasks, including PettingZoo, MiniGrid, Google Research Football (GRF), and  StarCraft Multi-Agent Challenge v2 (SMACv2).'}",https://openreview.net{'value': '/pdf/4d6d91de9831de82589c5aa2931337aba3a39d34.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=49QC2D8exO,{'value': 'ReDi: Rectified Discrete Flow'},Jaehoon Yoo; Wonjung Kim; Seunghoon Hong,~Jaehoon_Yoo1; ~Wonjung_Kim1; ~Seunghoon_Hong2,"{'value': ['discrete generative models', 'discrete flow matching', 'discrete diffusion', 'few-step distillation']}","{'value': 'Discrete Flow-based Models (DFMs) are powerful generative models for high-quality discrete data but typically suffer from slow sampling speeds due to their reliance on iterative decoding processes. \nThis reliance on a multi-step process originates from the factorization approximation of DFMs, which is necessary for handling high-dimensional data.\nIn this paper, we analyze the factorization approximation error using Conditional Total Correlation (TC), and reveal its dependence on the coupling.\nTo address the challenge of efficient few-step generation, we propose Rectified Discrete Flow (ReDi), a novel iterative method that reduces the underlying factorization error (measured as Conditional TC) by rectifying the coupling between source and target distributions.\nWe theoretically prove that each ReDi step guarantees a monotonic decreasing Conditional TC, ensuring its convergence.\nEmpirically, ReDi significantly reduces Conditional TC and enables few-step generation.\nMoreover, we demonstrate that the rectified couplings are well-suited for training efficient one-step models on image generation.\nReDi offers a simple and theoretically grounded approach for tackling the few-step challenge, providing a new perspective on efficient discrete data synthesis.\nCode is available at https://github.com/Ugness/ReDi_discrete.'}",https://openreview.net{'value': '/pdf/dbbe23c57e589684c895d0d98ebc9113a6fe2980.pdf'},{'abstract_filter': 'Data Synthesis'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=4449zuaaeL,{'value': 'Effects of Dropout on Performance in Long-range Graph Learning Tasks'},Jasraj Singh; Keyue Jiang; Brooks Paige; Laura Toni,~Jasraj_Singh1; ~Keyue_Jiang1; ~Brooks_Paige1; ~Laura_Toni1,"{'value': ['Dropout', 'graph neural networks', 'long-range interactions']}","{'value': 'Message Passing Neural Networks (MPNNs) are a class of Graph Neural Networks (GNNs) that propagate information across the graph via local neighborhoods. The scheme gives rise to two key challenges: over-smoothing and over-squashing. While several Dropout-style algorithms, such as DropEdge and DropMessage, have successfully addressed over-smoothing, their impact on over-squashing remains largely unexplored. This represents a critical gap in the literature, as failure to mitigate over-squashing would make these methods unsuitable for long-range tasks – the intended use case of deep MPNNs. In this work, we study the aforementioned algorithms, and closely related edge-dropping algorithms – DropNode, DropAgg and DropGNN – in the context of over-squashing. We present theoretical results showing that DropEdge-variants reduce sensitivity between distant nodes, limiting their suitability for long-range tasks. To address this, we introduce DropSens, a sensitivity-aware variant of DropEdge, which is developed following the message-passing scheme of GCN. DropSens explicitly controls the proportion of information lost due to edge-dropping, thereby increasing sensitivity to distant nodes despite dropping the same number of edges. Our experiments on long-range synthetic and real-world datasets confirm the predicted limitations of existing edge-dropping and feature-dropping methods. Moreover, DropSens with GCN consistently outperforms graph rewiring techniques designed to mitigate over-squashing, suggesting that simple, targeted modifications can substantially improve a model’s ability to capture long-range interactions. Our conclusions highlight the need to re-evaluate and re-design existing methods for training deep GNNs, with a renewed focus on modelling long-range interactions. The code for reproducing the results in our this work is available at https://github.com/ignasa007/Dropout-Effects-GNNs.'}",https://openreview.net{'value': '/pdf/9fa3cef22d426a0fba39479aa41d677392dad8f7.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=3uUmJzSSOW,{'value': 'UI-Genie: A Self-Improving Approach for Iteratively Boosting MLLM-based Mobile GUI Agents'},Han Xiao; Guozhi Wang; Yuxiang Chai; Zimu Lu; Weifeng Lin; Hao He; Lue Fan; Liuyang Bian; Rui Hu; Liang Liu; Shuai Ren; Yafei Wen; Xiaoxin Chen; Aojun Zhou; Hongsheng Li,~Han_Xiao6; ~Guozhi_Wang1; ~Yuxiang_Chai1; ~Zimu_Lu1; ~Weifeng_Lin1; ~Hao_He7; ~Lue_Fan1; ~Liuyang_Bian2; ~Rui_Hu12; ~Liang_Liu5; ~Shuai_Ren2; ~Yafei_Wen1; ~Xiaoxin_Chen1; ~Aojun_Zhou2; ~Hongsheng_Li3,"{'value': ['Multi-modal Large Language Model', 'GUI Agent']}","{'value': 'In this paper, we introduce UI-Genie, a self-improving framework addressing two key challenges in GUI agents: verification of trajectory outcome is challenging and high-quality training data are not scalable. These challenges are addressed by a reward model and a self-improving pipeline, respectively. The reward model, UI-Genie-RM, features an image-text interleaved architecture that efficiently processes historical context and unifies action-level and task-level rewards. To support the training of UI-Genie-RM, we develop deliberately-designed data generation strategies including rule-based verification, controlled trajectory corruption, and hard negative mining. To address the second challenge, a self-improvement pipeline progressively expands solvable complex GUI tasks by enhancing both the agent and reward models through reward-guided exploration and outcome verification in dynamic environments. For training the model, we generate UI-Genie-RM-517k and UI-Genie-Agent-16k, establishing the first reward-specific dataset for GUI agents while demonstrating high-quality synthetic trajectory generation without manual annotation. Experimental results show that UI-Genie achieves state-of-the-art performance across multiple GUI agent benchmarks with three generations of data-model self-improvement. We open-source our complete framework implementation and generated datasets to facilitate further research in https://github.com/Euphoria16/UI-Genie.'}",https://openreview.net{'value': '/pdf/60b0d40a43feb74b9a8bfe6c1d7e28e83974f25c.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=3qeTs05bRL,{'value': 'Bayesian Ego-graph Inference for Networked Multi-Agent Reinforcement Learning'},Wei Duan; Jie Lu; Junyu Xuan,~Wei_Duan2; ~Jie_Lu4; ~Junyu_Xuan1,"{'value': ['networked multi-agent reinforcement learning', 'Multi-Agent Reinforcement Learning', 'Decentralized Reinforcement Learning', 'Actor–Critic Methods']}","{'value': 'In networked multi-agent reinforcement learning (Networked-MARL), decentralized agents must act autonomously under local observability and constrained communication over fixed physical graphs. Existing methods often assume static neighborhoods, limiting adaptability to dynamic or heterogeneous environments. While centralized frameworks can learn dynamic graphs, their reliance on global state access and centralized infrastructure is impractical in real-world decentralized systems. We propose a stochastic graph-based policy for Networked-MARL, where each agent conditions its decision on a sampled subgraph over its local physical neighborhood. Building on this formulation, we introduce \\textbf{BayesG}, a decentralized actor–critic framework that learns sparse, context-aware interaction structures via Bayesian variational inference. Each agent operates over an ego-graph and samples a latent communication mask to guide message passing and policy computation. The variational distribution is trained end-to-end alongside the policy using an evidence lower bound (ELBO) objective, enabling agents to jointly learn both interaction topology and decision-making strategies.\nBayesG outperforms strong MARL baselines on large-scale traffic control tasks with up to 167 agents, demonstrating superior scalability, efficiency, and performance.'}",https://openreview.net{'value': '/pdf/8fb46b73690bf0d675a87484347d387191d5ac45.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=3fDypdR4VN,{'value': 'Provable Ordering and Continuity in Vision-Language Pretraining for Generalizable Embodied Agents'},Zhizhen Zhang; Lei Zhu; Zhen Fang; Zi Huang; Yadan Luo,~Zhizhen_Zhang1; ~Lei_Zhu8; ~Zhen_Fang2; ~Zi_Huang1; ~Yadan_Luo1,"{'value': ['multimodal pretraining', 'embodied AI', 'robot manipulation']}","{'value': 'Pre-training vision-language representations on human action videos has emerged\nas a promising approach to reduce reliance on large-scale expert demonstrations\nfor training embodied agents. However, prior methods often employ time con-\ntrastive learning based on goal-reaching heuristics, progressively aligning language\ninstructions from the initial to the final frame. This overemphasis on future frames\ncan result in erroneous vision-language associations, as actions may terminate\nearly or include irrelevant moments in the end. To address this issue, we propose\nAction Temporal Coherence Learning (AcTOL) to learn ordered and continuous\nvision-language representations without rigid goal-based constraint. AcTOL treats\na video as a continuous trajectory where it (1) contrasts semantic differences be-\ntween frames to reflect their natural ordering, and (2) imposes a local Brownian\nbridge constraint to ensure smooth transitions across intermediate frames. Exten-\nsive imitation learning experiments on both simulated and real robots show that the\npretrained features significantly enhance downstream manipulation tasks with high\nrobustness to different linguistic styles of instructions, offering a viable pathway\ntoward generalized embodied agents. Our project page is at https://actol-pretrain.github.io/.'}",https://openreview.net{'value': '/pdf/ad6f7cf085d09e25477b9bd0331f2e838aea20c2.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=3XuUnUEI7e,{'value': 'Diversifying Parallel Ergodic Search: A Signature Kernel Evolution Strategy'},Sreevardhan Sirigiri; Christian Hughes; Ian Abraham; Fabio Ramos,~Sreevardhan_Sirigiri1; ~Christian_Hughes1; ~Ian_Abraham1; ~Fabio_Ramos1,"{'value': ['robotics exploration', 'trajectory optimization', 'ergodic search', 'signature transform']}","{'value': 'Effective robotic exploration in continuous domains requires planning trajectories that maximize coverage over a predefined region. A recent development, Stein Variational Ergodic Search (SVES), proposed parallel ergodic exploration (a key approach within the field of robotic exploration), via Stein variational inference that computes a set of candidate trajectories approximating the posterior distribution over the solution space trajectories. While this approach leverages GPU parallelism well, the trajectories in the set might not be distinct enough, leading to a suboptimal set. In this paper, we propose two key methods to diversify the solution set of this approach.\nFirst, we leverage the signature kernel within the SVES framework, introducing a pathwise, sequence-sensitive interaction that preserves the Markovian structure of the trajectories and naturally spreads paths across distinct regions of the search space. Second, we propose a derivative-free evolution-strategy interpretation of SVES that exploits batched, GPU-friendly fitness evaluations and can be paired with approximate gradients whenever analytic gradients of the kernel are unavailable or computationally intractable. The resulting method both retains SVES’s advantages while diversifying the solution set and extending its reach to black-box objectives. Across planar forest search, 3D quadrotor coverage, and model-predictive control benchmarks, our approach consistently reduces ergodic cost and produces markedly richer trajectory sets than SVES without significant extra tuning effort.'}",https://openreview.net{'value': '/pdf/d34ea64903763ae50eec9db731a27b006a58862b.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=3Xmr8WTAld,"{'value': 'Generate, but Verify: Reducing Hallucination in Vision-Language Models with Retrospective Resampling'}",Tsung-Han Wu; Heekyung Lee; Jiaxin Ge; Joseph E. Gonzalez; Trevor Darrell; David M. Chan,~Tsung-Han_Wu1; ~Heekyung_Lee2; ~Jiaxin_Ge1; ~Joseph_E._Gonzalez1; ~Trevor_Darrell2; ~David_M._Chan1,"{'value': ['Visual Hallucination Reduction', 'Hallucination Verification', 'Retrospective Resampling']}","{'value': 'Vision-Language Models (VLMs) excel at visual understanding but often suffer from visual hallucinations, where they generate descriptions of nonexistent objects, actions, or concepts, posing significant risks in safety-critical applications. Existing hallucination mitigation methods typically follow one of two paradigms: generation adjustment, which modifies decoding behavior to align text with visual inputs, and post-hoc verification, where external models assess and correct outputs. While effective, generation adjustment methods often rely on heuristics and lack correction mechanisms, while post-hoc verification is complicated, typically requiring multiple models and tending to reject outputs rather than refine them. In this work, we introduce REVERSE, a unified framework that integrates hallucination-aware training with on-the-fly self-verification. By leveraging a new hallucination-verification dataset containing over 1.3M semi-synthetic samples, along with a novel inference-time retrospective resampling technique, our approach enables VLMs to both detect hallucinations during generation and dynamically revise those hallucinations. Our evaluations show that REVERSE achieves state-of-the-art hallucination reduction, outperforming the best existing methods by up to 12% on CHAIR-MSCOCO and 34% on HaloQuest.'}",https://openreview.net{'value': '/pdf/1a3999d213938c0456861d505dc6e368485c74eb.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=3Sk8CaQWdv,{'value': 'Decoding Causal Structure: End-to-End Mediation Pathways Inference'},Yulong Li; Xiwei Liu; Feilong Tang; Ming Hu; Jionglong Su; Zongyuan Ge; Imran Razzak; Eran Segal,~Yulong_Li7; ~Xiwei_Liu2; ~Feilong_Tang2; ~Ming_Hu4; ~Jionglong_Su1; ~Zongyuan_Ge1; ~Imran_Razzak2; ~Eran_Segal1,{'value': ['Mediation Pathways Inference']},"{'value': 'Causal mediation analysis is crucial for deconstructing complex mechanisms of action. However, in current mediation analysis, complex structures derived from causal discovery lack direct interpretation of mediation pathways, while traditional mediation analysis and effect estimation are limited by the reliance on pre-specified pathways, leading to a disconnection between structure discovery and causal mechanism understanding. Therefore, a unified framework integrating structure discovery, pathway identification, and effect estimation systematically quantifies mediation pathways under structural uncertainty, enabling automated identification and inference of mediation pathways. To this end, we propose Structure-Informed Guided Mediation Analysis (SIGMA), which guides automated mediation pathway identification through probabilistic causal structure discovery and uncertainty quantification, enabling end-to-end propagation of structural uncertainty from structure learning to effect estimation. Specifically, SIGMA employs differentiable Flow-Structural Equation Models to learn structural posteriors, generating diverse Directed Acyclic Graphs (DAGs) to quantify structural uncertainty. Based on these DAGs, we introduce the Path Stability Score to evaluate the marginal probability of pathways, identifying high-confidence mediation paths. For identified mediation pathways, we integrate Efficient Influence Functions with Bayesian model averaging to fuse within-structure estimation uncertainty and between-structure effect variation, propagating uncertainty to the final effect estimates. In synthetic data experiments, SIGMA achieves state-of-the-art performance in pathway identification accuracy and effect quantification precision under structures uncertainty, concurrent multiple pathways, and nonlinear scenarios. In real-world applications using Human Phenotype Project data, SIGMA identifies mediation effects of sleep quality on cardiovascular health through inflammatory and metabolic pathways, uncovering previously unspecified multiple mediation paths.'}",https://openreview.net{'value': '/pdf/de0326314287dd2348a8366d290da9bed71d446a.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=3L1sGJh3Li,{'value': 'VLMs can Aggregate Scattered Training Patches'},Zhanhui Zhou; Lingjie Chen; Chao Yang; Chaochao Lu,~Zhanhui_Zhou1; ~Lingjie_Chen1; ~Chao_Yang3; ~Chaochao_Lu1,"{'value': ['vision-language model', 'safety', 'out-of-context reasoning']}","{'value': 'One way to mitigate risks in vision-language models (VLMs) is to censor dangerous samples from their training data.\nHowever, data moderation can be easily bypassed when harmful images are split into small, benign-looking patches, scattered across many training samples. VLMs may then learn to piece these fragments together and generate harmful responses at inference, either from full images or text references.\nFor instance, if trained on image patches from a bloody scene paired with the descriptions ""safe,"" VLMs may later describe, the full image or a text reference to the scene, as ""safe.""\n\nWe define the core ability of VLMs enabling this attack as $\\textit{visual stitching}$—the ability to integrate visual information spread across multiple training samples that share the same textual descriptions.\nIn our work, we first demonstrate visual stitching abilities in common open-source VLMs on three datasets where each image is labeled with a unique synthetic ID. We split each $(\\texttt{image}, \\texttt{ID})$ pair into $\\{(\\texttt{patch}, \\texttt{ID})\\}$ pairs at different granularities for finetuning, and we find that models can verbalize the correct IDs from full images or text reference.\nBuilding on this, we simulate the adversarial data poisoning scenario mentioned above by using patches from dangerous images and replacing IDs with text descriptions like ""safe"" or ""unsafe"", demonstrating how harmful content can evade moderation in patches and later be reconstructed through visual stitching, posing serious VLM safety risks.'}",https://openreview.net{'value': '/pdf/20f2f3d6dd43ee871e9cd521c5912342fb4bc58d.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=3KtPujOw5z,{'value': 'On the Value of Cross-Modal Misalignment in Multimodal Representation Learning'},Yichao Cai; Yuhang Liu; Erdun Gao; Tianjiao Jiang; Zhen Zhang; Anton van den Hengel; Javen Qinfeng Shi,~Yichao_Cai1; ~Yuhang_Liu1; ~Erdun_Gao1; ~Tianjiao_Jiang1; ~Zhen_Zhang2; ~Anton_van_den_Hengel1; ~Javen_Qinfeng_Shi1,"{'value': ['Representation Learning', 'Multimodal Learning', 'Identifiability', 'Latent Variable Models']}","{'value': 'Multimodal representation learning, exemplified by multimodal contrastive learning (MMCL) using image-text pairs, aims to learn powerful representations by aligning cues across modalities. This approach relies on the core assumption that the exemplar image-text pairs constitute two representations of an identical concept. However, recent research has revealed that real-world datasets often exhibit cross-modal misalignment. There are two distinct viewpoints on how to address this issue: one suggests mitigating the misalignment, and the other leveraging it. We seek here to reconcile these seemingly opposing perspectives, and to provide a practical guide for practitioners. Using latent variable models we thus formalize cross-modal misalignment by introducing two specific mechanisms: Selection bias, where some semantic variables are absent in the text, and perturbation bias, where semantic variables are altered—both leading to misalignment in data pairs. Our theoretical analysis demonstrates that, under mild assumptions, the representations learned by MMCL capture exactly the information related to the subset of the semantic variables invariant to selection and perturbation biases. This provides a unified perspective for understanding misalignment. Based on this, we further offer actionable insights into how misalignment should inform the design of real-world ML systems. We validate our theoretical findings via extensive empirical studies on both synthetic data and real image-text datasets, shedding light on the nuanced impact of cross-modal misalignment on multimodal representation learning.'}",https://openreview.net{'value': '/pdf/f9dfb0944a4708fc71aa217635fd1adebdc1a13b.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=3JlBQRvod7,{'value': 'ResponseRank: Data-Efficient Reward Modeling through Preference Strength Learning'},Timo Kaufmann; Yannick Metz; Daniel A. Keim; Eyke Hüllermeier,~Timo_Kaufmann1; ~Yannick_Metz1; ~Daniel_A._Keim1; ~Eyke_Hüllermeier1,"{'value': ['Reward Modeling', 'Response Time', 'RLHF', 'Preference Learning', 'Preference Strength', 'Learning from Rankings', 'Data Efficiency']}","{'value': 'Binary choices, as often used for reinforcement learning from human feedback (RLHF), convey only the *direction* of a preference.\nA person may choose apples over oranges and bananas over grapes, but *which preference is stronger*?\nStrength is crucial for decision-making under uncertainty and generalization of preference models, but hard to measure reliably.\nMetadata such as response times and inter-annotator agreement can serve as proxies for strength, but are often noisy and confounded.\nWe propose ResponseRank to address the challenge of learning from noisy strength signals.\nOur method uses relative differences in these signals to *rank responses to pairwise comparisons by their inferred preference strength*.\nSignals are only considered locally within carefully constructed strata, controlling for systemic variation.\nThis enables robust learning of utility differences consistent with strength-derived rankings, all while making minimal assumptions.\nOur contributions are threefold:\n(1) ResponseRank, a novel method that robustly learns preference strength by leveraging locally valid relative strength signals;\n(2) empirical evidence of improved sample efficiency and robustness across diverse tasks: synthetic preference learning (with simulated response times), language modeling (with annotator agreement), and RL control tasks (with simulated episode returns); and\n(3) the *Pearson Distance Correlation (PDC)*, a novel metric that isolates cardinal utility learning from ordinal accuracy.'}",https://openreview.net{'value': '/pdf/c03874045a2dc3fedea8614528a2023b845740d7.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=3CYXSMFv55,{'value': 'ENMA: Tokenwise Autoregression for Continuous Neural PDE Operators'},Armand Kassaï Koupaï; Lise Le Boudec; Louis Serrano; Patrick Gallinari,~Armand_Kassaï_Koupaï1; ~Lise_Le_Boudec2; ~Louis_Serrano1; ~Patrick_Gallinari2,"{'value': ['parametric PDE', 'generative models', 'autoregressive transformers', 'operator learning']}","{'value': 'Solving time-dependent parametric partial differential equations (PDEs) remains a fundamental challenge for neural solvers, particularly when generalizing across a wide range of physical parameters and dynamics.\nWhen data is uncertain or incomplete—as is often the case—a natural approach is to turn to generative models.\nWe introduce ENMA, a generative neural operator designed to model spatio-temporal dynamics arising from physical phenomena. ENMA predicts future dynamics in a compressed latent space using a generative masked autoregressive transformer trained with flow matching loss, enabling tokenwise generation. Irregularly sampled spatial observations are encoded into uniform latent representations via attention mechanisms and further compressed through a spatio-temporal convolutional encoder. This allows ENMA to perform in-context learning at inference time by conditioning on either past states of the target trajectory or auxiliary context trajectories with similar dynamics. The result is a robust and adaptable framework that generalizes to new PDE regimes and supports one-shot surrogate modeling of time-dependent parametric PDEs.'}",https://openreview.net{'value': '/pdf/9904777ca1f40ec0dcdaad5623da93fd496cbede.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=3Bxn5XSgrO,{'value': 'Transductive Conformal Inference for Full Ranking'},Jean-Baptiste Fermanian; Pierre Humbert; Gilles Blanchard,~Jean-Baptiste_Fermanian1; ~Pierre_Humbert1; ~Gilles_Blanchard1,"{'value': ['Conformal Prediction', 'Ranking Algorithm', 'False Coverage Proportion']}","{'value': ""We introduce a method based on Conformal Prediction (CP) to quantify the uncertainty of full ranking algorithms. We focus on a specific scenario where $n+m$ items are to be ranked by some ``black box'' algorithm. It is assumed that the relative (ground truth) ranking of $n$ of them is known.  The objective is then to quantify the error made by the algorithm on the ranks of the $m$ new items among the total $(n+m)$. In such a setting, the true ranks of the $n$ original items in the total $(n+m)$ depend on the (unknown) true ranks of the $m$ new ones. Consequently, we have no direct access to a calibration set to apply a classical CP method. To address this challenge, we propose to construct distribution-free bounds of the unknown conformity scores using recent results on the distribution of conformal p-values. Using these scores upper bounds, we provide valid prediction sets for the rank of any item. We also control the false coverage proportion, a crucial quantity when dealing with multiple prediction sets. Finally, we empirically show on both synthetic and real data the efficiency of our CP method for state-of-the-art ranking algorithms such as RankNet or LambdaMart.""}",https://openreview.net{'value': '/pdf/c70b2a70683f7c13a277d1d3fdbf6f5d0c570d8e.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=36TBVGwzAY,{'value': 'GRIP: A Graph-Based Reasoning Instruction Producer'},Jiankang Wang; Jianjun Xu; Xiaorui Wang; Yuxin Wang; Mengting Xing; Shancheng Fang; Hongtao Xie,~Jiankang_Wang3; ~Jianjun_Xu1; ~Xiaorui_Wang3; ~Yuxin_Wang1; ~Mengting_Xing1; ~Shancheng_Fang1; ~Hongtao_Xie2,"{'value': ['Large Language Models', 'Reasoning', 'Data Synthesis']}","{'value': 'Large-scale, high-quality data is essential for advancing the reasoning capabilities of large language models (LLMs). As publicly available Internet data becomes increasingly scarce, synthetic data has emerged as a crucial research direction. However, existing data synthesis methods often suffer from limited scalability, insufficient sample diversity, and a tendency to overfit to seed data, which constrains their practical utility. In this paper, we present \\textit{\\textbf{GRIP}}, a \\textbf{G}raph-based \\textbf{R}easoning \\textbf{I}nstruction \\textbf{P}roducer that efficiently synthesizes high-quality and diverse reasoning instructions. \\textit{GRIP} constructs a knowledge graph by extracting high-level concepts from seed data, and uniquely leverages both explicit and implicit relationships within the graph to drive large-scale and diverse instruction data synthesis, while employing open-source multi-model supervision to ensure data quality. We apply \\textit{GRIP} to the critical and challenging domain of mathematical reasoning. Starting from a seed set of 7.5K math reasoning samples, we construct \\textbf{GRIP-MATH}, a dataset containing 2.1 million synthesized question-answer pairs. Compared to similar synthetic data methods, \\textit{GRIP} achieves greater scalability and diversity while also significantly reducing costs. On mathematical reasoning benchmarks, models trained with GRIP-MATH demonstrate substantial improvements over their base models and significantly outperform previous data synthesis methods.'}",https://openreview.net{'value': '/pdf/9ef2967c43fa97f6b4cfdddaf146abf156250794.pdf'},{'abstract_filter': 'Data Synthesis'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=30iBKSQMXn,{'value': 'Retro-R1: LLM-based Agentic Retrosynthesis'},Wei Liu; Jiangtao Feng; Hongli Yu; Yuxuan Song; Yuqiang Li; Shufei Zhang; LEI BAI; Wei-Ying Ma; Hao Zhou,~Wei_Liu31; ~Jiangtao_Feng1; ~Hongli_Yu1; ~Yuxuan_Song2; ~Yuqiang_Li1; ~Shufei_Zhang1; ~LEI_BAI1; ~Wei-Ying_Ma2; ~Hao_Zhou5,"{'value': ['Reinforcement Learning', 'Retrosynthesis Planning', 'LLM-based Agent']}","{'value': 'Retrosynthetic planning is a fundamental task in chemical discovery. Due to the vast combinatorial search space, identifying viable synthetic routes remains a significant challenge--even for expert chemists. Recent advances in Large Language Models (LLMs), particularly equipped with reinforcement learning, have demonstrated strong human-like reasoning and planning abilities, especially in mathematics and code problem solving. This raises a natural question: Can the reasoning capabilities of LLMs be harnessed to develop an AI chemist capable of learning effective policies for multi-step retrosynthesis? In this study, we introduce Retro-R1, a novel LLM-based retrosynthesis agent trained via reinforcement learning to design molecular synthesis pathways. Unlike prior approaches, which typically rely on single-turn, question-answering formats, Retro-R1 interacts dynamically with plug-in single-step retrosynthesis tools and learns from environmental feedback. Experimental results show that Retro-R1 achieves a 55.79\\% pass@1 success rate, surpassing the previous state of the art by 8.95\\%. Notably, Retro-R1 demonstrates strong generalization to out-of-domain test cases, where existing methods tend to fail despite their high in-domain performance. Our work marks a significant step toward equipping LLMs with advanced, chemist-like reasoning abilities, highlighting the promise of reinforcement learning for enabling data-efficient, generalizable, and sophisticated scientific problem-solving in LLM-based agents.'}",https://openreview.net{'value': '/pdf/470a5ef177e20c474a9e358c1bab0c1cf082f1de.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=2sa13vyCn0,{'value': 'pLSTM: parallelizable Linear Source Transition Mark networks'},Korbinian Pöppel; Richard Freinschlag; Thomas Schmied; Wei Lin; Sepp Hochreiter,~Korbinian_Pöppel1; ~Richard_Freinschlag1; ~Thomas_Schmied1; ~Wei_Lin9; ~Sepp_Hochreiter1,"{'value': ['LSTM', 'MDRNN', 'linear RNN', 'DAG', 'multi-dimensional data', 'graphs']}","{'value': 'Modern recurrent architectures, such as xLSTM and Mamba, have recently challenged the Transformer in language modeling. \n  However, their structure constrains their applicability to sequences only or requires processing multi-dimensional data structures, such as images or molecular graphs, in a pre-defined sequential order. \n  In contrast, Multi-Dimensional RNNs (MDRNNs) are well suited for data with a higher level structure, like 2D grids, trees, and directed acyclic graphs (DAGs). \n  In this work, we extend the notion of multi-dimensionality to linear RNNs.\n  We introduce parallelizable Linear Source Transition Mark networks (pLSTMs) using Source, Transition, and Mark gates that act on the linegraph of a general DAG.\n  This enables parallelization in analogy to parallel associative scans and the chunkwise-recurrent form of sequential linear RNNs, but for DAGs.\n  For regular grids (1D and 2D), like images, this scheme can be efficiently implemented using einsum operations, concatenations, and padding in logarithmic time.\n  pLSTMs tackle the vanishing/exploding activation/gradient problem for long distances in DAGs via two distinct modes: a directed propagation mode (P-mode) and a diffusive distribution mode (D-mode). \n  To showcase the long-range capabilities of pLSTM, we introduce arrow-pointing extrapolation as a synthetic computer vision task that contains long-distance directional information.\n  We demonstrate that pLSTMs generalize well to larger image sizes, whereas Transformers struggle to extrapolate.\n  On established molecular graph and computer vision benchmarks, pLSTMs also show strong performance. The complete code is available at https://github.com/ml-jku/plstm_experiments.'}",https://openreview.net{'value': '/pdf/752c1ab52e1add08a0a0c4519e20a6e25391e7a5.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=2sMk2ShRdP,{'value': 'Precise Diffusion Inversion: Towards Novel Samples and Few-Step Models'},Jing Zuo; Luoping Cui; Chuang Zhu; Yonggang Qi,~Jing_Zuo2; ~Luoping_Cui1; ~Chuang_Zhu1; ~Yonggang_Qi2,{'value': ['Diffusion model; Inversion; Diffusion based real image editing']},"{'value': ""The diffusion inversion problem seeks to recover the latent generative trajectory of a diffusion model given a real image. Faithful inversion is critical for ensuring consistency in diffusion-based image editing. Prior works formulate this task as a fixed-point problem and solve it using numerical methods. However, achieving both accuracy and efficiency remains challenging, especially for few-step models and novel samples. In this paper, we propose ***PreciseInv***, a general-purpose test-time optimization framework that enables fast and faithful inversion in as few as two inference steps. Unlike root-finding methods, we reformulate inversion as a learning problem and introduce a dynamic programming-inspired strategy to recursively estimate a parameterized sequence of noise embeddings. This design leverages the smoothness of the diffusion latent space for accurate gradient-based optimization and ensures memory efficiency via recursive subproblem construction. We further provide a theoretical analysis of ***PreciseInv***'s convergence and derive a provable upper bound on its reconstruction error. Extensive experiments on COCO 2017, DarkFace, and a stylized cartoon dataset show that ***PreciseInv*** achieves state-of-the-art performance in both reconstruction quality and inference speed. Improvements are especially notable for few-step models and under distribution shifts. Moreover, precise inversion yields substantial gains in editing consistency for text-driven image manipulation tasks. Code is available at: https://github.com/panda7777777/PreciseInv""}",https://openreview.net{'value': '/pdf/ce21a9e8f242af8c2898ef7493bd3931e7173182.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=2p4AtivyZz,{'value': 'OPHR: Mastering Volatility Trading with Multi-Agent Deep Reinforcement Learning'},Zeting Chen; Xinyu Cai; Molei Qin; Bo An,~Zeting_Chen1; ~Xinyu_Cai1; ~Molei_Qin1; ~Bo_An2,"{'value': ['Reinforcement Learning', 'Quantatitive Trading', 'Option Trading']}","{'value': 'Options markets represent one of the most sophisticated segments of the financial ecosystem, with prices that directly reflect market uncertainty. In this paper, we introduce the first reinforcement learning (RL) framework specifically designed for volatility trading through options, focusing on profit from the difference between implied volatility and realized volatility. Our multi-agent architecture consists of an Option Position Agent (OP-Agent) responsible for volatility timing by controlling long/short volatility positions, and a Hedger Routing Agent (HR-Agent) that manages risk and maximizes path-dependent profits by selecting optimal hedging strategies with different risk preferences. Evaluating our approach using cryptocurrency options data from 2021-2024, we demonstrate superior performance on BTC and ETH, significantly outperforming traditional strategies and machine learning baselines across all profit and risk-adjusted metrics while exhibiting sophisticated trading behavior. The code framework and sample data of this paper have been released on https://github.com/Edwicn/OPHR-MasteringVolatilityTradingwithMultiAgentDeepReinforcementLearning'}",https://openreview.net{'value': '/pdf/0a54e33013db5c0872e1579260f30cb5ab2f203d.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=2oRz0NNOQQ,{'value': 'Learning from A Single Markovian Trajectory: Optimality and Variance Reduction'},Zhenyu Sun; Ermin Wei,~Zhenyu_Sun1; ~Ermin_Wei1,"{'value': ['stochastic optimization', 'Markov sampling', 'sample complexity']}","{'value': 'In this paper, we consider the general stochastic non-convex optimization problem when the sampling process follows a Markov chain. This problem exhibits its significance in capturing many real-world applications, ranging from asynchronous distributed learning to reinforcement learning. In particular, we consider the worst case where one has no prior knowledge and control of the Markov chain, meaning multiple trajectories cannot be simulated but only a single trajectory is available for algorithm design. We first provide algorithm-independent lower bounds with $\\Omega(\\epsilon^{-3})$ (and $\\Omega(\\epsilon^{-4})$) samples, when objectives are (mean-squared) smooth, for any first-order methods accessing bounded variance gradient oracles to achieve $\\epsilon$-approximate critical solutions of original problems. Then, we propose \\textbf{Ma}rkov-\\textbf{C}hain \\textbf{SPIDER} (MaC-SPIDER), which leverages variance-reduced techniques, to achieve a $\\mathcal{O}(\\epsilon^{-3})$ upper bound for mean-squared smooth objective functions. To the best of our knowledge, MaC-SPIDER is the first to achieve $\\mathcal{O}(\\epsilon^{-3})$ complexity when sampling from a single Markovian trajectory. And our proposed lower bound concludes its (near) optimality.'}",https://openreview.net{'value': '/pdf/5488874876155eec7b2ea08a266ad407a560d4cc.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=2ncMTlR9nC,{'value': 'CamEdit: Continuous Camera Parameter Control for Photorealistic Image Editing'},Xinran Qin; Zhixin Wang; Fan Li; Haoyu Chen; Renjing Pei; Wenbo Li; Xiaochun Cao,~Xinran_Qin1; ~Zhixin_Wang6; ~Fan_Li26; ~Haoyu_Chen2; ~Renjing_Pei1; ~Wenbo_Li6; ~Xiaochun_Cao3,"{'value': ['Photorealistic Image Editing', 'Camera Parameter Control', 'Diffusion model']}","{'value': 'Recent advances in diffusion models have substantially improved text-driven image editing. However, existing frameworks based on discrete textual tokens struggle to support continuous control over camera parameters and smooth transitions in visual effects. These limitations hinder their applications to realistic, camera-aware, and fine-grained editing tasks. In this paper, we present CamEdit, a diffusion-based framework for photorealistic image editing that enables continuous and semantically meaningful manipulation of common camera parameters such as aperture and shutter speed. CamEdit incorporates a continuous parameter prompting mechanism and a parameter-aware modulation module that guides the model in smoothly adjusting focal plane, aperture, and shutter speed, reflecting the effects of varying camera settings within the diffusion process. To support supervised learning in this setting, we introduce CamEdit50K, a dataset specifically designed for photorealistic image editing with continuous camera parameter settings. It contains over 50k image pairs  combining real and synthetic data with dense camera parameter variations across diverse scenes. Extensive experiments demonstrate that CamEdit enables flexible, consistent, and high-fidelity image editing, achieving state-of-the-art performance in camera-aware visual manipulation and fine-grained photographic control.'}",https://openreview.net{'value': '/pdf/7e7f42f9662afb90b60017103c138c74802122ee.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=2hiNrfMmQ7,{'value': 'Information Retrieval Induced Safety Degradation in AI Agents'},Cheng Yu; Benedikt Stroebl; Diyi Yang; Orestis Papakyriakopoulos,~Cheng_Yu4; ~Benedikt_Stroebl1; ~Diyi_Yang2; ~Orestis_Papakyriakopoulos1,"{'value': ['Responsible AI', 'LLM Agents', 'Safety', 'Bias']}","{'value': 'Despite the growing integration of retrieval-enabled AI agents into society, their safety and ethical behavior remain inadequately understood.\nIn particular, the growing integration of LLMs and AI agents with external information sources and real-world environments raises critical questions about how they engage with and are influenced by these external data sources and interactive contexts.\nThis study investigates how expanding retrieval access—from no external sources to Wikipedia-based retrieval and open web search—affects model reliability, bias propagation, and harmful content generation. \nThrough extensive benchmarking of censored and uncensored LLMs and AI Agents, our findings reveal a consistent degradation in refusal rates, bias sensitivity, and harmfulness safeguards as models gain broader access to external sources, culminating in a phenomenon we term safety degradation. Notably, retrieval-enabled agents built on aligned LLMs often behave more unsafely than uncensored models without retrieval. This effect persists even under strong retrieval accuracy and prompt-based mitigation, suggesting that the mere presence of retrieved content reshapes model behavior in structurally unsafe ways.\nThese findings underscore the need for robust mitigation strategies to ensure fairness and reliability in retrieval-enabled and increasingly autonomous AI systems.'}",https://openreview.net{'value': '/pdf/1e319382e526c85a8d468dc155a7b017f99e3dde.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=2h8vXbEufN,{'value': 'Denoising Trajectory Biases for Zero-Shot AI-Generated Image Detection'},Yachao Liang; Min Yu; Gang Li; Jianguo Jiang; Fuqiang Du; Li Jingyuan; Lanchi Xie; Zhen Xu; Weiqing Huang,~Yachao_Liang1; ~Min_Yu1; ~Gang_Li12; ~Jianguo_Jiang3; ~Fuqiang_Du1; ~Li_Jingyuan1; ~Lanchi_Xie1; ~Zhen_Xu9; ~Weiqing_Huang1,"{'value': ['AI-generated image detection', 'diffusion model', 'ddim', 'gan']}","{'value': 'The rapid advancement of generative models has led to the widespread emergence of highly realistic synthetic images, making the detection of AI-generated content increasingly critical. In particular, diffusion models have recently achieved unprecedented levels of visual fidelity, further raising concerns. While most existing approaches rely on supervised learning, zero-shot detection methods have attracted growing interest due to their ability to bypass data collection and maintenance. Nevertheless, the performance of current zero-shot methods remains limited. In this paper, we introduce a novel zero-shot AI-generated image detection method. Unlike previous works that primarily focus on identifying artifacts in the final generated images, our work explores features within the image generation process that can be leveraged for detection. Specifically, we simulate the image sampling process via diffusion-based inversion and observe that the denoising outputs of generated images converge to the target image more rapidly than those of real images.  Inspired by this observation, we compute the similarity between the original image and the outputs along the denoising trajectory, which is then used as an indicator of image authenticity.Since our method requires no training on any generated images, it avoids overfitting to specific generative models or dataset biases. Experiments across a wide range of generators demonstrate that our method achieves significant improvements over state-of-the-art supervised and zero-shot counterparts.'}",https://openreview.net{'value': '/pdf/6bf521dc1912b4d473425bb0c2eff3e02781177f.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=2h8bFmEQwh,{'value': 'Direct Fisher Score Estimation for Likelihood Maximization'},Sherman Khoo; Yakun Wang; Song Liu; Mark Beaumont,~Sherman_Khoo1; ~Yakun_Wang3; ~Song_Liu1; ~Mark_Beaumont1,"{'value': ['Simulation-based inference', 'Likelihood-free inference', 'Score Matching', 'Gradient-Based Optimization', 'Likelihood Maximization']}","{'value': 'We study the problem of likelihood maximization when the likelihood function is intractable but model simulations are readily available. We propose a sequential, gradient-based optimization method that directly models the Fisher score based on a local score matching technique which uses simulations from a localized region around each parameter iterate. By employing a linear parameterization for the surrogate score model, our technique admits a closed-form, least-squares solution. This approach yields a fast, flexible, and efficient approximation to the Fisher score, effectively smoothing the likelihood objective and mitigating the challenges posed by complex likelihood landscapes. We provide theoretical guarantees for our score estimator, including bounds on the bias introduced by the smoothing. Empirical results on a range of synthetic and real-world problems demonstrate the superior performance of our method compared to existing benchmarks.'}",https://openreview.net{'value': '/pdf/0f9f43bc4601b68c6be082310c5c20c9c8bcf528.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=2dpiR9fqUk,{'value': 'CovMatch: Cross-Covariance Guided Multimodal Dataset Distillation with Trainable Text Encoder'},Yongmin Lee; Hye Won Chung,~Yongmin_Lee1; ~Hye_Won_Chung2,"{'value': ['Dataset distillation', 'Dataset condensation', 'Multimodal dataset', 'Image-text contrastive learning']}","{'value': 'Multimodal dataset distillation aims to synthesize a small set of image-text pairs that enables efficient training of large-scale vision-language models. While dataset distillation has shown promise in unimodal tasks, extending it to multimodal contrastive learning presents key challenges: learning cross-modal alignment and managing the high computational cost of large encoders. Prior approaches address scalability by freezing the text encoder and update only the image encoder and text projection layer.  However, we find this severely limits semantic alignment and becomes a bottleneck for performance scaling.\nWe propose CovMatch, a scalable dataset distillation framework that aligns the cross-covariance of real and synthetic features while regularizing feature distributions within each modality. Unlike prior approaches, CovMatch enables joint optimization of both encoders, leading to stronger cross-modal alignment and improved performance. Evaluated on Flickr30K and COCO, CovMatch outperforms state-of-the-art multimodal distillation methods and achieves up to 6.8\\% absolute gains in retrieval accuracy using only 500 synthetic pairs.'}",https://openreview.net{'value': '/pdf/4552be3f3fcf6157b1149d9ba757cc42a1300ba4.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=2Yk4GnB3DY,{'value': 'See through the Dark: Learning Illumination-affined Representations for Nighttime Occupancy Prediction'},Wuyuan; Zhiqiang Yan; Yigong Zhang; Xiang Li; Jian Yang,~Wuyuan1; ~Zhiqiang_Yan1; ~Yigong_Zhang2; ~Xiang_Li20; ~Jian_Yang1,"{'value': ['occupancy prediction', 'nighttime scenes', 'illumination-driven modeling']}","{'value': 'Occupancy prediction aims to estimate the 3D spatial distribution of occupied regions along with their corresponding semantic labels. Existing vision-based methods perform well on daytime benchmarks but struggle in nighttime scenarios due to limited visibility and challenging lighting conditions. To address these challenges, we propose LIAR, a novel framework that learns illumination-affined representations. LIAR first introduces Selective Low-light Image Enhancement (SLLIE), which leverages the illumination priors from daytime scenes to adaptively determine whether a nighttime image is genuinely dark or sufficiently well-lit, enabling more targeted global enhancement. Building on the illumination maps generated by SLLIE, LIAR further incorporates two illumination-aware components: 2D Illumination-guided Sampling (2D-IGS) and 3D Illumination-driven Projection (3D-IDP), to respectively tackle local underexposure and overexposure. Specifically, 2D-IGS modulates feature sampling positions according to illumination maps, assigning larger offsets to darker regions and smaller ones to brighter regions, thereby alleviating feature degradation in underexposed areas. Subsequently, \n3D-IDP enhances semantic understanding in overexposed regions by constructing illumination intensity fields and supplying refined residual queries to the BEV context refinement process. Extensive experiments on both real and synthetic datasets demonstrate the superior performance of LIAR under challenging nighttime scenarios. The source code and pretrained models are available [here](https://github.com/yanzq95/LIAR).'}",https://openreview.net{'value': '/pdf/55da50065049610ae5d89636cefc6fb6ddd81189.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=2XelsPmKV1,{'value': 'Path-specific effects for pulse-oximetry guided decisions in critical care'},Kevin Zhang; Yonghan Jung; Divyat Mahajan; Karthikeyan Shanmugam; Shalmali Joshi,~Kevin_Zhang8; ~Yonghan_Jung1; ~Divyat_Mahajan1; ~Karthikeyan_Shanmugam1; ~Shalmali_Joshi1,"{'value': ['Causal inference', 'Computational healthcare', 'Algorithmic fairness']}","{'value': 'Identifying and measuring biases associated with sensitive attributes is a crucial consideration in healthcare to prevent treatment disparities. One prominent issue is inaccurate pulse oximeter readings, which tend to overestimate oxygen saturation for dark-skinned patients and misrepresent supplemental oxygen needs. Most existing research has revealed *statistical disparities* linking device measurement errors to patient outcomes in intensive care units (ICUs) without causal formalization. This study *causally* investigates how racial discrepancies in oximetry measurements affect invasive ventilation in ICU settings. We employ a causal inference-based approach using *path-specific effects* to isolate the impact of bias by race on clinical decision-making. To estimate these effects, we leverage a doubly robust estimator, propose its self-normalized variant for improved sample efficiency, and provide novel finite-sample guarantees. Our methodology is validated on semi-synthetic data and applied to two large real-world health datasets: MIMIC-IV and eICU. Contrary to prior work, our analysis reveals minimal impact of racial discrepancies on invasive ventilation rates. However, path-specific effects mediated by oxygen saturation disparity are more pronounced on ventilation duration, and the severity differs by dataset. Our work provides a novel pipeline for investigating potential disparities in clinical decision-making and, more importantly, highlights the necessity of causal methods to robustly assess fairness in healthcare.'}",https://openreview.net{'value': '/pdf/3974d0a9187aa5e8eacd2c354bac205ad593adb2.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=2PhVe7p9xD,{'value': 'Unsupervised Trajectory Optimization for 3D Registration in Serial Section Electron Microscopy using Neural ODEs'},Zhenbang Zhang; Jingtong Feng; Hongjia Li; Haythem El-Messiry; zhiqiang xu; Renmin Han,~Zhenbang_Zhang1; ~Jingtong_Feng1; ~Hongjia_Li3; ~Haythem_El-Messiry1; ~zhiqiang_xu1; ~Renmin_Han1,"{'value': ['computer vision', 'biomedical image processing', 'ai for science']}","{'value': ""Series Section Electron Microscopy (ssEM) has emerged as a pivotal technology for deciphering nanoscale biological architectures. Three-dimensional (3D) registration is a critical step in ssEM, tasked with rectifying axial misalignments and nonlinear distortions introduced during serial sectioning. The core scientific challenge lies in achieving distortion mitigation without erasing the natural morphological deformations of biological tissues, thereby enabling faithful reconstruction of 3D ultrastructural organization. In this study, we present a paradigm-shifting optimization framework that rethinks 3D registration through the lens of manifold trajectory optimization. We propose the first continuous trajectory dynamics formulation for 3D registration and introduce a novel optimization strategy. Specifically, we introduce a dual optimization objective that inherently balances global trajectory smoothness with local structural preservation, while developing a solver that combines Gauss-Seidel iteration with Neural ODEs to systematically integrate biophysical priors with data-driven deformation compensation. A key strength of our method is its fully unsupervised training, which avoids reliance on ground truth and suits ssEM scenarios where annotations are difficult to obtain. Extensive experiments on multiple datasets spanning diverse tissue types demonstrate our method's superior performance in structural restoration accuracy and cross-tissue robustness.""}",https://openreview.net{'value': '/pdf/2e566223abbc9b53dadec0e0e0420e13614d7dab.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=2KKqp7MWJM,{'value': 'AgentAuditor: Human-level Safety and Security Evaluation for LLM Agents'},Hanjun Luo; Shenyu Dai; Chiming Ni; Xinfeng Li; Guibin Zhang; Kun Wang; Tongliang Liu; Hanan Salam,~Hanjun_Luo1; ~Shenyu_Dai1; ~Chiming_Ni1; ~Xinfeng_Li1; ~Guibin_Zhang1; ~Kun_Wang15; ~Tongliang_Liu1; ~Hanan_Salam1,"{'value': ['Agent Safety', 'Agent Security', 'LLM-as-a-Judge']}","{'value': 'Despite the rapid advancement of LLM-based agents, the reliable evaluation of their safety and security remains a significant challenge. Existing rule-based or LLM-based evaluators often miss dangers in agents\' step-by-step actions, overlook subtle meanings, fail to see how small issues compound, and get confused by unclear safety or security rules. To overcome this evaluation crisis, we introduce AgentAuditor, a universal, training-free, memory-augmented reasoning framework that empowers LLM evaluators to emulate human expert evaluators. AgentAuditor constructs an experiential memory by having an LLM adaptively extract structured semantic features (e.g., scenario, risk, behavior) and generate associated chain-of-thought reasoning traces for past interactions. A multi-stage, context-aware retrieval-augmented generation process then dynamically retrieves the most relevant reasoning experiences to guide the LLM evaluator\'s assessment of new cases. Moreover, we developed ASSEBench, the first benchmark designed to check how well LLM-based evaluators can spot both safety risks and security threats. ASSEBench comprises 2293 meticulously annotated interaction records, covering 15 risk types across 29 application scenarios. A key feature of ASSEBench is its nuanced approach to ambiguous risk situations, employing ""Strict"" and ""Lenient"" judgment standards. Experiments demonstrate that AgentAuditor not only consistently improves the evaluation performance of LLMs across all benchmarks but also sets a new state-of-the-art in LLM-as-a-judge for agent safety and security, achieving human-level accuracy. Our work is openly accessible at https://github.com/Astarojth/AgentAuditor.'}",https://openreview.net{'value': '/pdf/2ceecf4bf50bffa7cff2d145fadb18c23daf7206.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=2CeGVUpOd7,{'value': 'Spectral Estimation with Free Decompression'},Siavash Ameli; Chris van der Heide; Liam Hodgkinson; Michael W. Mahoney,~Siavash_Ameli1; ~Chris_van_der_Heide1; ~Liam_Hodgkinson1; ~Michael_W._Mahoney1,"{'value': ['Random Matrix Theory', 'Free Decompression', 'Spectral Density Estimation']}","{'value': 'Computing eigenvalues of very large matrices is a critical task in many machine learning applications, including the evaluation of log-determinants, the trace of matrix functions, and other important metrics. As datasets continue to grow in scale, the corresponding covariance and kernel matrices become increasingly large, often reaching magnitudes that make their direct formation impractical or impossible. Existing techniques typically rely on matrix-vector products, which can provide efficient approximations, if the matrix spectrum behaves well. However, in settings like distributed learning, or when the matrix is defined only indirectly, access to the full data set can be restricted to only very small sub-matrices of the original matrix. In these cases, the matrix of nominal interest is not even available as an implicit operator, meaning that even matrix-vector products may not be available. In such settings, the matrix is ""impalpable"", in the sense that we have access to only masked snapshots of it. We draw on principles from free probability theory to introduce a novel method of ""free decompression"" to estimate the spectrum of such matrices. Our method can be used to extrapolate from the empirical spectral densities of small submatrices to infer the eigenspectrum of extremely large (impalpable) matrices (that we cannot form or even evaluate with full matrix-vector products). We demonstrate the effectiveness of this approach through a series of examples, comparing its performance against known limiting distributions from random matrix theory in synthetic settings, as well as applying it to submatrices of real-world datasets, matching them with their full empirical eigenspectra.'}",https://openreview.net{'value': '/pdf/157274a01c6ec6e13815a7c9f79ee39f94f98256.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=28qUA2bSe5,{'value': 'AutoVLA: A Vision-Language-Action Model for End-to-End Autonomous Driving with Adaptive Reasoning and Reinforcement Fine-Tuning'},Zewei Zhou; Tianhui Cai; Seth Z. Zhao; Yun Zhang; Zhiyu Huang; Bolei Zhou; Jiaqi Ma,~Zewei_Zhou1; ~Tianhui_Cai1; ~Seth_Z._Zhao1; ~Yun_Zhang14; ~Zhiyu_Huang2; ~Bolei_Zhou5; ~Jiaqi_Ma4,"{'value': ['End-to-end Autonomous Driving', 'Vision Language Action Model', 'Reinforcement Finetuning']}","{'value': 'Recent advancements in Vision-Language-Action (VLA) models have shown promise for end-to-end autonomous driving by leveraging world knowledge and reasoning capabilities. However, current VLA models often struggle with physically infeasible action outputs, complex model structures, or unnecessarily long reasoning. In this paper, we propose AutoVLA, a novel VLA model that unifies reasoning and action generation within a single autoregressive generation model for end-to-end autonomous driving. AutoVLA performs semantic reasoning and trajectory planning directly from raw visual inputs and language instructions. We tokenize continuous trajectories into discrete, feasible actions, enabling direct integration into the language model. For training, we employ supervised fine-tuning to equip the model with dual thinking modes: fast thinking (trajectory-only) and slow thinking (enhanced with chain-of-thought reasoning). To further enhance planning performance and efficiency, we introduce a reinforcement fine-tuning method based on Group Relative Policy Optimization (GRPO), reducing unnecessary reasoning in straightforward scenarios. Extensive experiments across real-world and simulated datasets and benchmarks, including nuPlan, nuScenes, Waymo, and CARLA, demonstrate the competitive performance of AutoVLA in both open-loop and closed-loop settings. Qualitative results showcase the adaptive reasoning and accurate planning capabilities of AutoVLA in diverse scenarios.'}",https://openreview.net{'value': '/pdf/ac3e0d2216d650bf65be2b1559d68dc79c32c6ed.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=27aIOGfkAV,{'value': 'Sequential Multi-Agent Dynamic Algorithm Configuration'},Chen Lu; Ke Xue; Lei Yuan; Yao Wang; Yaoyuan Wang; Fu Sheng; Chao Qian,~Chen_Lu6; ~Ke_Xue1; ~Lei_Yuan2; ~Yao_Wang15; ~Yaoyuan_Wang1; ~Fu_Sheng1; ~Chao_Qian1,"{'value': ['Dynamic algorithm configuration', 'automl', 'reinforcement leraning', 'multi-agent reinforcement learning']}","{'value': ""The performance of an algorithm often critically depends on its hyperparameter configuration. Dynamic algorithm configuration (DAC) is a recent trend in automated machine learning, which can dynamically adjust the algorithm’s configuration during the execution process and relieve users from tedious trial-and-error tuning tasks. Recently, multi-agent reinforcement learning (MARL) approaches have improved the configuration of multiple heterogeneous hyperparameters, making various parameter configurations for complex algorithms possible. However, many complex algorithms have inherent inter-dependencies among multiple parameters (e.g., determining the operator type first and then the operator's parameter), which are, however, not considered in previous approaches, thus leading to sub-optimal results. In this paper, we propose the sequential multi-agent DAC (Seq-MADAC) framework to address this issue by considering the inherent inter-dependencies of multiple parameters. Specifically, we propose a sequential advantage decomposition network, which can leverage action-order information through sequential advantage decomposition. Experiments from synthetic functions to the configuration of multi-objective optimization algorithms demonstrate Seq-MADAC's superior performance over state-of-the-art MARL methods and show strong generalization across problem classes. Seq-MADAC establishes a new paradigm for the widespread dependency-aware automated algorithm configuration. Our code is available at https://github.com/lamda-bbo/seq-madac.""}",https://openreview.net{'value': '/pdf/e094a87dac837bdb089e8e7ce8634e7ee00b4080.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=24UJqxw1kv,{'value': 'Forecasting in Offline Reinforcement Learning for Non-stationary Environments'},Suzan Ece Ada; Georg Martius; Emre Ugur; Erhan Oztop,~Suzan_Ece_Ada1; ~Georg_Martius1; ~Emre_Ugur1; ~Erhan_Oztop1,"{'value': ['Reinforcement learning', 'Robust Reinforcement learning', 'Offline Reinforcement Learning', 'Diffusion Models']}","{'value': ""Offline Reinforcement Learning (RL) provides a promising avenue for training policies from pre-collected datasets when gathering additional interaction data is infeasible. However, existing offline RL methods often assume stationarity or only consider synthetic perturbations at test time, assumptions that often fail in real-world scenarios characterized by abrupt, time-varying offsets. These offsets can lead to partial observability, causing agents to misperceive their true state and degrade performance. To overcome this challenge, we introduce Forecasting in Non-stationary Offline RL (FORL), a framework that unifies (i) conditional diffusion-based candidate state generation, trained without presupposing any specific pattern of future non-stationarity, and (ii) zero-shot time-series foundation models. FORL targets environments prone to unexpected, potentially non-Markovian offsets, requiring robust agent performance from the onset of each episode. Empirical evaluations on offline RL benchmarks, augmented with real-world time-series data to simulate realistic non-stationarity, demonstrate that FORL consistently improves performance compared to competitive baselines. By integrating zero-shot forecasting with the agent's experience, we aim to bridge the gap between offline RL and the complexities of real-world, non-stationary environments.""}",https://openreview.net{'value': '/pdf/b89636d2b480f773c290433cb2fcc46ebc23c115.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=1v0ULVJOZ9,{'value': 'RHYTHM: Reasoning with Hierarchical Temporal Tokenization for Human Mobility'},Haoyu He; Haozheng Luo; Yan Chen; Qi Wang,~Haoyu_He5; ~Haozheng_Luo2; ~Yan_Chen1; ~Qi_Wang24,"{'value': ['Human mobility prediction', 'large language models (LLMs)', 'spatio-temporal forecasting']}","{'value': 'Predicting human mobility is inherently challenging due to  complex long-range dependencies and multi-scale periodic behaviors. To address this, we introduce RHYTHM (Reasoning with Hierarchical Temporal Tokenization for Human Mobility), a unified framework that leverages large language models (LLMs) as general-purpose spatio-temporal predictors and trajectory reasoners. Methodologically, RHYTHM employs temporal tokenization to partition each trajectory into daily segments and encode them as discrete tokens with hierarchical attention that captures both daily and weekly dependencies, thereby quadratically reducing the sequence length while preserving cyclical information. Additionally, we enrich token representations by adding pre-computed prompt embeddings for trajectory segments and prediction targets via a frozen LLM, and feeding these combined embeddings back into the LLM backbone to capture complex interdependencies. Computationally, RHYTHM keeps the pretrained LLM backbone frozen, yielding faster training and lower memory usage. We evaluate our model against state-of-the-art methods using three real-world datasets. Notably, RHYTHM achieves a 2.4% improvement in overall accuracy, a 5.0% increase on weekends, and a 24.6% reduction in training time. Code is publicly available at https://github.com/he-h/rhythm.'}",https://openreview.net{'value': '/pdf/622c8b2c9662f9f5f151f36a7cb24bf5153f10bd.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=1nL84tQNnK,{'value': 'Conformal Prediction for Causal Effects of Continuous Treatments'},Maresa Schröder; Dennis Frauen; Jonas Schweisthal; Konstantin Hess; Valentyn Melnychuk; Stefan Feuerriegel,~Maresa_Schröder1; ~Dennis_Frauen1; ~Jonas_Schweisthal1; ~Konstantin_Hess1; ~Valentyn_Melnychuk1; ~Stefan_Feuerriegel1,"{'value': ['causality', 'dosage response curves', 'conformal prediction', 'uncertainty quantification']}","{'value': 'Uncertainty quantification of causal effects is crucial for safety-critical applications such as personalized medicine. A powerful approach for this is conformal prediction, which has several practical benefits due to model-agnostic finite-sample guarantees. Yet, existing methods for conformal prediction of causal effects are limited to binary/discrete treatments and make highly restrictive assumptions, such as known propensity scores. In this work, we provide a novel conformal prediction method for potential outcomes of continuous treatments. We account for the additional uncertainty introduced through propensity estimation so that our conformal prediction intervals are valid even if the propensity score is unknown. Our contributions are three-fold: (1) We derive finite-sample validity guarantees for prediction intervals of potential outcomes of continuous treatments. (2) We provide an algorithm for calculating the derived intervals. (3) We demonstrate the effectiveness of the conformal prediction intervals in experiments on synthetic and real-world datasets. To the best of our knowledge, we are the first to propose conformal prediction for continuous treatments when the propensity score is unknown and must be estimated from data.'}",https://openreview.net{'value': '/pdf/aeaafa3f93e6cbe6330acda208d855db3458c34e.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=1m177EsP3V,{'value': 'Multi-Agent Reinforcement Learning with Communication-Constrained Priors'},Guang Yang; Tianpei Yang; Jingwen Qiao; Yanqing Wu; Jing Huo; Xingguo Chen; Yang Gao,~Guang_Yang10; ~Tianpei_Yang1; ~Jingwen_Qiao1; ~Yanqing_Wu2; ~Jing_Huo2; ~Xingguo_Chen2; ~Yang_Gao3,"{'value': ['multi-agent reinforcement learning', 'mutual information', 'lossy communication', 'communication-constrained prior']}","{'value': 'Communication is one of the effective means to improve the learning of cooperative policy in multi-agent systems. However, in most real-world scenarios, lossy communication is a prevalent issue. Existing multi-agent reinforcement learning with communication, due to their limited scalability and robustness, struggles to apply to complex and dynamic real-world environments. To address these challenges, we propose a generalized communication-constrained model to uniformly characterize communication conditions across different scenarios. Based on this, we utilize it as a learning prior to distinguish between lossy and lossless messages for specific scenarios. Additionally, we decouple the impact of lossy and lossless messages on distributed decision-making, drawing on a dual mutual information estimatior, and introduce a communication-constrained multi-agent reinforcement learning framework, quantifying the impact of communication messages into the global reward. Finally, we validate the effectiveness of our approach across several communication-constrained benchmarks.'}",https://openreview.net{'value': '/pdf/b94e2f0bc5ce687580694bfbee64d475128314fd.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=1jDAYXfcS2,{'value': 'This Time is Different: An Observability Perspective on Time Series Foundation Models'},Ben Cohen; Emaad Khwaja; Youssef Doubli; Salahidine Lemaachi; Chris Lettieri; Charles Masson; Hugo Miccinilli; Elise Ramé; Qiqi Ren; Afshin Rostamizadeh; Jean Ogier du Terrail; Anna-Monica Toon; Kan Wang; Stephan Xie; Zongzhe Xu; Viktoriya Zhukova; David Asker; Ameet Talwalkar; Othmane Abou-Amal,~Ben_Cohen2; ~Emaad_Khwaja1; ~Youssef_Doubli1; ~Salahidine_Lemaachi1; ~Chris_Lettieri1; ~Charles_Masson1; ~Hugo_Miccinilli1; ~Elise_Ramé1; ~Qiqi_Ren1; ~Afshin_Rostamizadeh1; ~Jean_Ogier_du_Terrail2; ~Anna-Monica_Toon1; ~Kan_Wang5; ~Stephan_Xie1; ~Zongzhe_Xu1; ~Viktoriya_Zhukova1; ~David_Asker1; ~Ameet_Talwalkar1; ~Othmane_Abou-Amal1,"{'value': ['time series', 'foundation models', 'observability', 'benchmark dataset']}","{'value': ""We introduce Toto, a time series forecasting foundation model with 151 million parameters. Toto uses a modern decoder-only architecture coupled with architectural innovations designed to account for specific challenges found in multivariate observability time series data. Toto's pre-training corpus is a mixture of observability data, open datasets, and synthetic data, and is 4-10$\\times$ larger than those of leading time series foundation models. Additionally, we introduce BOOM, a large-scale  benchmark consisting of 350 million observations across 2,807 real-world time series.  For both Toto and BOOM, we source observability data exclusively from our own telemetry and internal observability metrics. Extensive evaluations demonstrate that Toto achieves state-of-the-art performance on both BOOM and on established general  purpose time series forecasting benchmarks. Toto's model weights, inference code, and evaluation scripts, as well as BOOM's data and evaluation code, are all available as open source under the Apache 2.0 License.""}",https://openreview.net{'value': '/pdf/9bb170db54f9951f80ce70e2568aa28b9bba2693.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=1fOGTbO5Sx,{'value': 'Wonder Wins Ways: Curiosity-Driven Exploration through Multi-Agent Contextual Calibration'},Yiyuan Pan; Zhe Liu; Hesheng Wang,~Yiyuan_Pan1; ~Zhe_Liu16; ~Hesheng_Wang1,"{'value': ['Multi-Agent Reinforcement Learning', 'Intrinsic Reward', 'Artificial Curiosity']}","{'value': 'Autonomous exploration in complex multi-agent reinforcement learning (MARL) with sparse rewards critically depends on providing agents with effective intrinsic motivation. While artificial curiosity offers a powerful self-supervised signal, it often confuses environmental stochasticity with meaningful novelty. Moreover, existing curiosity mechanisms exhibit a uniform novelty bias, treating all unexpected observations equally. However, peer behavior novelty, which encode latent task dynamics, are often overlooked, resulting in suboptimal exploration in decentralized, communication-free MARL settings. To this end, inspired by how human children adaptively calibrate their own exploratory behaviors via observing peers, we propose a novel approach to enhance multi-agent exploration. We introduce CERMIC, a principled framework that empowers agents to robustly filter noisy surprise signals and guide exploration by dynamically calibrating their intrinsic curiosity with inferred multi-agent context. Additionally, CERMIC generates theoretically-grounded intrinsic rewards, encouraging agents to explore state transitions with high information gain. We evaluate CERMIC on benchmark suites including VMAS, Meltingpot, and SMACv2. Empirical results demonstrate that exploration with CERMIC significantly outperforms SoTA algorithms in sparse-reward environments.'}",https://openreview.net{'value': '/pdf/dac815c07ab9f9e54d2b1f128f30787f3774ea58.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=1esFEjMUBS,{'value': 'Flow Field Reconstruction with Sensor Placement Policy Learning'},Ruoyan Li; Guancheng Wan; Zijie Huang; Zixiao Liu; Haixin Wang; Xiao Luo; Wei Wang; Yizhou Sun,~Ruoyan_Li1; ~Guancheng_Wan1; ~Zijie_Huang1; ~Zixiao_Liu1; ~Haixin_Wang3; ~Xiao_Luo3; ~Wei_Wang13; ~Yizhou_Sun1,"{'value': ['Sparse Sensor Measurement', 'Optimal Sensor Placement', 'Graph Neural Network', 'Proximal Policy Optimization']}","{'value': ""Flow‐field reconstruction from sparse sensor measurements remains a central challenge in modern fluid dynamics, as the need for high‐fidelity data often conflicts with practical limits on sensor deployment. Existing deep learning–based methods have demonstrated promising results, but they typically depend on simplifying assumptions such as two‐dimensional domains, predefined governing equations, synthetic datasets derived from idealized flow physics, and unconstrained sensor placement. In this work, we address these limitations by studying flow reconstruction under realistic conditions and introducing a \\emph{directional transport‐aware Graph Neural Network (GNN)} that explicitly encodes both flow directionality and information transport. We further show that conventional sensor placement strategies frequently yield suboptimal configurations. To overcome this, we propose a novel \\emph{Two‐Step Constrained PPO} procedure for Proximal Policy Optimization (PPO), which jointly optimizes sensor layouts by incorporating flow variability and accounts for reconstruction model's performance disparity with respect to sensor placement. We conduct comprehensive experiments under realistic assumptions to benchmark the performance of our reconstruction model and sensor placement policy. Together, they achieve significant improvements over existing methods.""}",https://openreview.net{'value': '/pdf/0e18d3408f6e29d5fa0704146e2fc2c65e05b1c8.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=1bO9wIdyKa,{'value': 'UniRelight: Learning Joint Decomposition and Synthesis for Video Relighting'},Kai He; Ruofan Liang; Jacob Munkberg; Jon Hasselgren; Nandita Vijaykumar; Alexander Keller; Sanja Fidler; Igor Gilitschenski; Zan Gojcic; Zian Wang,~Kai_He5; ~Ruofan_Liang1; ~Jacob_Munkberg1; ~Jon_Hasselgren1; ~Nandita_Vijaykumar1; ~Alexander_Keller1; ~Sanja_Fidler1; ~Igor_Gilitschenski1; ~Zan_Gojcic1; ~Zian_Wang1,"{'value': ['Relighting', 'Inverse Rendering', 'Diffusion Models']}","{'value': 'We address the challenge of relighting a single image or video, a task that demands precise scene intrinsic understanding and high-quality light transport synthesis. Existing end-to-end relighting models are often limited by the scarcity of paired multi-illumination data, restricting their ability to generalize across diverse scenes. Conversely, two-stage pipelines that combine inverse and forward rendering can mitigate data requirements but are susceptible to error accumulation and often fail to produce realistic outputs under complex lighting conditions or with sophisticated materials. In this work, we introduce a general-purpose approach that jointly estimates albedo and synthesizes relit outputs in a single pass, harnessing the generative capabilities of video diffusion models. This joint formulation enhances implicit scene comprehension and facilitates the creation of realistic lighting effects and intricate material interactions, such as shadows, reflections, and transparency. Trained on synthetic multi-illumination data and extensive automatically labeled real-world videos, our model demonstrates strong generalization across diverse domains and surpasses previous methods in both visual fidelity and temporal consistency. Our\nproject page is https://research.nvidia.com/labs/toronto-ai/UniRelight/.'}",https://openreview.net{'value': '/pdf/61e5d2bfb5b501d50f66c8c546a100dc4f17dff0.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=1YzRtbaAzZ,{'value': 'RUAGO: Effective and Practical Retain-Free Unlearning via Adversarial Attack and OOD Generator'},SangYong Lee; Sangjun Chung; Simon S. Woo,~SangYong_Lee1; ~Sangjun_Chung1; ~Simon_S._Woo1,"{'value': ['Machine Unlearning', 'Right to be forgetten', 'User Privacy', 'Data Forgetting', 'Training Dataset Privacy']}","{'value': 'With increasing regulations on private data usage in AI systems, machine unlearning has emerged as a critical solution for selectively removing sensitive information from trained models while preserving their overall utility. While many existing unlearning methods rely on the *retain data* to mitigate the performance decline caused by forgetting, such data may not always be available (*retain-free*) in real-world scenarios. \nTo address this challenge posed by retain-free unlearning, we introduce **RUAGO**, utilizing adversarial soft labels to mitigate over-unlearning and a generative model pretrained on out-of-distribution (OOD) data to effectively distill the original model’s knowledge. We introduce a progressive sampling strategy to incrementally increase synthetic data complexity, coupled with an inversion-based alignment step that ensures the synthetic data closely matches the original training distribution. Our extensive experiments on multiple benchmark datasets and architectures demonstrate that our approach consistently outperforms existing retain-free methods and achieves comparable or superior performance relative to retain-based approaches, demonstrating its effectiveness and practicality in real-world, data-constrained environments.'}",https://openreview.net{'value': '/pdf/ea217c1497aa3f2f1f9df44081ac51f809dcd4b3.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=1YprrVfIp8,{'value': 'Stackelberg Self-Annotation: A Robust Approach to Data-Efficient LLM Alignment'},Xu Chu; Zhixin Zhang; Tianyu Jia; Yujie Jin,~Xu_Chu1; ~Zhixin_Zhang3; ~Tianyu_Jia1; ~Yujie_Jin2,"{'value': ['Data-Efficient', 'Alignment', 'Large Language Models', 'Stackelberg Games']}","{'value': 'Aligning large language models (LLMs) with human preferences typically demands vast amounts of meticulously curated data, which is both expensive and prone to labeling noise. We propose Stackelberg Game Preference Optimization (SGPO), a robust alignment framework that models alignment as a two-player Stackelberg game between a policy (leader) and a worst-case preference distribution (follower). The proposed SGPO guarantees $\\mathcal{O}(\\epsilon)$-bounded regret within an $\\epsilon$-Wasserstein ball, offering formal robustness to (self-)annotation noise. We instantiate SGPO with Stackelberg Self-Annotated Preference Optimization (SSAPO), which uses minimal human-labeled “seed” preferences and iteratively self-annotates new prompts. In each iteration, SSAPO applies a distributionally robust reweighting of synthetic annotations, ensuring that noisy or biased self-labels do not derail training. Remarkably, using only 2K seed preferences—about 1/30 of standard human labels—SSAPO achieves strong win rates against GPT-4 across multiple benchmarks within three iterations. These results highlight that a principled Stackelberg formulation yields data-efficient alignment for LLMs, significantly reducing reliance on costly human annotations.'}",https://openreview.net{'value': '/pdf/89cca5fb48c05a0a570188e4d2d17025a14a0323.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=1XLjrmKZ4p,{'value': 'GUI-G1: Understanding R1-Zero-Like Training for Visual Grounding in GUI Agents'},Yuqi Zhou; Sunhao Dai; Shuai Wang; Kaiwen Zhou; Qinglin Jia; Jun Xu,~Yuqi_Zhou2; ~Sunhao_Dai1; ~Shuai_Wang34; ~Kaiwen_Zhou2; ~Qinglin_Jia1; ~Jun_Xu1,"{'value': ['R1-Zero-Like Training', 'GUI Agents', 'Grounding']}","{'value': 'Recent Graphical User Interface (GUI) agents replicate the R1-Zero paradigm, coupling online Reinforcement Learning (RL) with explicit chain-of-thought reasoning prior to object grounding and thereby achieving substantial performance gains. In this paper, we first conduct extensive analysis experiments of three key components of that training pipeline: input design, output evaluation, and policy update—each revealing distinct challenges arising from blindly applying general-purpose RL without adapting to GUI grounding tasks. Input design: Current templates encourage the model to generate chain-of-thought reasoning, but longer chains unexpectedly lead to worse grounding performance. Output evaluation: Reward functions based on hit signals or box area allow models to exploit box size, leading to reward hacking and poor localization quality. Policy update: Online RL tends to overfit easy examples due to biases in length and sample difficulty, leading to under-optimization on harder cases. To address these issues, we propose three targeted solutions. First, we adopt a $\\textbf{Fast Thinking Template}$ that encourages direct answer generation, reducing excessive reasoning during training. Second, we incorporate a box size constraint into the reward function to mitigate reward hacking. Third, we revise the RL objective by adjusting length normalization and adding a difficulty-aware scaling factor, enabling better optimization on hard samples. Our $\\textbf{GUI-G1-3B}$, trained on 17K public samples with Qwen2.5-VL-3B-Instruct, achieves $\\textbf{90.3\\%}$ accuracy on ScreenSpot and $\\textbf{37.1\\%}$ on ScreenSpot-Pro. This surpasses all prior models of similar size and even outperforms the larger UI-TARS-7B, establishing a new state-of-the-art in GUI agent grounding.'}",https://openreview.net{'value': '/pdf/f6767d3d1ddd7b12b85d94abd6d7a313406de8a8.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=1LPPMAUlaT,{'value': 'Automated Composition of Agents: A Knapsack Approach for Agentic Component Selection'},Michelle Yuan; Khushbu Pahwa; Shuaichen Chang; Mustafa Devrim Kaba; MONICA SUNKARA; Jiarong Jiang; Xiaofei Ma; Yi Zhang,~Michelle_Yuan2; ~Khushbu_Pahwa1; ~Shuaichen_Chang1; ~Mustafa_Devrim_Kaba1; ~MONICA_SUNKARA1; ~Jiarong_Jiang1; ~Xiaofei_Ma1; ~Yi_Zhang13,"{'value': ['large language models', 'llm agents', 'combinatorial optimization', 'knapsack algorithm', 'agent composition']}","{'value': 'Designing effective agentic systems requires the seamless composition and integration of agents, tools, and models within dynamic and uncertain environments. Most existing methods rely on static, semantic retrieval approaches for tool or agent discovery. However, effective reuse and composition of existing components remain challenging due to incomplete capability descriptions and the limitations of retrieval methods. \nComponent selection suffers because the decisions are not based on capability, cost, and real-time utility.\nTo address these challenges, we introduce a structured, automated framework for agentic system composition that is inspired by the knapsack problem. Our framework enables a composer agent to systematically identify, select, and assemble an optimal set of agentic components by jointly considering performance, budget constraints, and compatibility. By dynamically testing candidate components and modeling their utility in real-time, our approach streamlines the assembly of agentic systems and facilitates scalable reuse of resources. Empirical evaluation with Claude 3.5 Sonnet across five benchmarking datasets shows that our online-knapsack-based composer consistently lies on the Pareto frontier, achieving higher success rates at significantly lower component costs compared to our baselines. \nIn the single-agent setup, the online knapsack composer shows a success rate improvement of up to 31.6\\% in comparison to the retrieval baselines. \nIn multi-agent systems, the online knapsack composer increases success rate from 37\\% to 87\\% when agents are selected from an agent inventory of 100+ agents. \nThe substantial performance gap confirms the robust adaptability of our method across diverse domains and budget constraints.'}",https://openreview.net{'value': '/pdf/26b1e763944464b965e20433920eff6eeef74439.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=1GCWcrZTX8,{'value': 'Diffusion Federated Dataset'},Seok-Ju Hahn; Junghye Lee,~Seok-Ju_Hahn1; ~Junghye_Lee1,"{'value': ['federated learning', 'diffusion model', 'collaborative machine learning', 'synthetic data', 'cooperative inference']}","{'value': 'Diffusion models have demonstrated decent generation quality, yet their deployment in federated learning scenarios remains challenging. Due to data heterogeneity and a large number of parameters, conventional parameter averaging schemes often fail to achieve stable collaborative training of diffusion models. We reframe collaborative synthetic data generation as a cooperative sampling procedure from a mixture of decentralized distributions, each encoded by a pre-trained local diffusion model. This leverages the connection between diffusion and energy-based models, which readily supports compositional generation thereof. Consequently, we can directly obtain refined synthetic dataset, optionally with differential privacy guarantee, even without exchanging diffusion model parameters. Our framework reduces communication overhead while maintaining the generation quality, realized through an unadjusted Langevin algorithm with a convergence guarantee.'}",https://openreview.net{'value': '/pdf/318ed684cc1d8fce1921c7102a2575ca4087c67b.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=1A4Nlibwl5,{'value': 'Learning Human-Like RL Agents Through Trajectory Optimization With Action Quantization'},Jian-Ting Guo; Yu-Cheng Chen; Ping-Chun Hsieh; Kuo-Hao Ho; Po-Wei Huang; Ti-Rong Wu; I-Chen Wu,~Jian-Ting_Guo1; ~Yu-Cheng_Chen2; ~Ping-Chun_Hsieh1; ~Kuo-Hao_Ho1; ~Po-Wei_Huang2; ~Ti-Rong_Wu1; ~I-Chen_Wu3,"{'value': ['Trajectory Optimization', 'Human-likeness', 'Reinforcement Learning', 'VQVAE']}","{'value': 'Human-like agents have long been one of the goals in pursuing artificial intelligence.\nAlthough reinforcement learning (RL) has achieved superhuman performance in many domains, relatively little attention has been focused on designing human-like RL agents.\nAs a result, many reward-driven RL agents often exhibit unnatural behaviors compared to humans, raising concerns for both interpretability and trustworthiness.\nTo achieve human-like behavior in RL, this paper first formulates human-likeness as trajectory optimization, where the objective is to find an action sequence that closely aligns with human behavior while also maximizing rewards, and adapts the classic receding-horizon control to human-like learning as a tractable and efficient implementation.\nTo achieve this, we introduce Macro Action Quantization (MAQ), a human-like RL framework that distills human demonstrations into macro actions via Vector-Quantized VAE.\nExperiments on D4RL Adroit benchmarks show that MAQ significantly improves human-likeness, increasing trajectory similarity scores, and achieving the highest human-likeness rankings among all RL agents in the human evaluation study.\nOur results also demonstrate that MAQ can be easily integrated into various off-the-shelf RL algorithms, opening a promising direction for learning human-like RL agents. \nOur code is available at https://rlg.iis.sinica.edu.tw/papers/MAQ.'}",https://openreview.net{'value': '/pdf/3075f74045ae309567070a48e9198a38e8a7b4f6.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=19ygs48nOa,{'value': 'How do Transformers Learn Implicit Reasoning?'},Jiaran Ye; Zijun Yao; Zhidian Huang; Liangming Pan; Jinxin Liu; Yushi Bai; Amy Xin; Liu Weichuan; Xiaoyin Che; Lei Hou; Juanzi Li,~Jiaran_Ye1; ~Zijun_Yao2; ~Zhidian_Huang1; ~Liangming_Pan1; ~Jinxin_Liu2; ~Yushi_Bai1; ~Amy_Xin1; ~Liu_Weichuan1; ~Xiaoyin_Che1; ~Lei_Hou2; ~Juanzi_Li1,"{'value': ['Implicit Reasoning', 'Multi-hop Inference', 'Transformer Models', 'Interpretability']}","{'value': 'Recent work suggests that large language models (LLMs) can perform multi-hop reasoning implicitly---producing correct answers without explicitly verbalizing intermediate steps---but the underlying mechanisms remain poorly understood.\nIn this paper, we study how such implicit reasoning emerges by training transformers from scratch in a controlled symbolic environment.\nOur analysis reveals a three-stage developmental trajectory: early memorization, followed by in-distribution generalization, and eventually cross-distribution generalization.\nWe find that training with atomic triples is not necessary but accelerates learning, and that second-hop generalization relies on query-level exposure to specific compositional structures.\nTo interpret these behaviors, we introduce two diagnostic tools: cross-query semantic patching, which identifies semantically reusable intermediate representations, and a cosine-based representational lens, which reveals that successful reasoning correlates with the cosine-base clustering in hidden space.\nThis clustering phenomenon in turn provides a coherent explanation for the behavioral dynamics observed across training, linking representational structure to reasoning capability. \nThese findings provide new insights into the interpretability of implicit multi-hop reasoning in LLMs, helping to clarify how complex reasoning processes unfold internally and offering pathways to enhance the transparency of such models.'}",https://openreview.net{'value': '/pdf/ad38d1ecc76e644507fb0bca76d2143a06260e52.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=18GBPdnuXs,{'value': 'Adaptive Quantization in Generative Flow Networks for Probabilistic Sequential Prediction'},Nadhir Hassen; Zhen Zhang; Johan W. Verjans,~Nadhir_Hassen2; ~Zhen_Zhang2; ~Johan_W._Verjans1,"{'value': ['Generative Flow Networks', 'Probabilistic Forecasting', 'Quantization', 'Time Series', 'Sequential Prediction', 'Uncertainty Quantification']}","{'value': ""Probabilistic time series forecasting, essential in domains like healthcare and neuroscience, requires models capable of capturing uncertainty and intricate temporal dependencies. While deep learning has advanced forecasting, generating calibrated probability distributions over continuous future values remains challenging. We introduce Temporal Generative Flow Networks (Temporal GFNs), adapting Generative Flow Networks (GFNs) – a powerful framework for generating compositional objects – to this sequential prediction task. GFNs learn policies to construct objects (eg. forecast trajectories) step-by-step, sampling final objects proportionally to a reward signal. However, applying GFNs directly to continuous time series necessitates addressing their inherently discrete action spaces and ensuring differentiability. Our framework tackles this by representing time series segments as states and sequentially generating future values via quantized actions chosen by a forward policy. We introduce two key innovations: (1) An adaptive, curriculum-based quantization strategy that dynamically adjusts the number of discretization bins based on reward improvement and policy entropy, balancing precision and exploration throughout training. (2) A straight-through estimator mechanism enabling the forward policy to output both discrete (hard) samples for trajectory construction and continuous (soft) samples for stable gradient propagation. Training utilizes a trajectory balance loss objective, ensuring flow consistency, augmented by an entropy regularizer. We provide rigorous theoretical bounds on the quantization error's impact and the adaptive factor's range. We demonstrate how Temporal GFNs offer a principled way to leverage the structured generation capabilities of GFNs for probabilistic forecasting in continuous domains.""}",https://openreview.net{'value': '/pdf/55b7e05418130a901f5364f539a47a9b47e2d9d3.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=16mDq7m2OK,{'value': 'MoGe-2: Accurate Monocular Geometry with Metric Scale and Sharp Details'},Ruicheng Wang; Sicheng Xu; Yue Dong; Yu Deng; Jianfeng Xiang; Zelong Lv; Guangzhong Sun; Xin Tong; Jiaolong Yang,~Ruicheng_Wang2; ~Sicheng_Xu1; ~Yue_Dong1; ~Yu_Deng2; ~Jianfeng_Xiang1; ~Zelong_Lv1; ~Guangzhong_Sun1; ~Xin_Tong1; ~Jiaolong_Yang3,"{'value': ['computer vision', 'monocular geometry estimation']}","{'value': 'We propose MoGe-2, an advanced open-domain geometry estimation model that recovers a metric-scale 3D point map of a scene from a single image. Our method builds upon the recent monocular geometry estimation approach, MoGe, which predicts affine-invariant point maps with unknown scales. We explore effective strategies to extend MoGe for metric geometry prediction without compromising the relative geometry accuracy provided by the affine-invariant point representation. Additionally, we discover that noise and errors in real data diminish fine-grained detail in the predicted geometry. We address this by developing a data refinement approach that filters and completes real data using sharp synthetic labels, significantly enhancing the granularity of the reconstructed geometry while maintaining the overall accuracy. We train our model on a large corpus of mixed datasets and conducted comprehensive evaluations, demonstrating its superior performance in achieving accurate relative geometry, precise metric scale, and fine-grained detail recovery -- capabilities that no previous methods have simultaneously achieved.'}",https://openreview.net{'value': '/pdf/d08b17ff5fcab8a2f825383843b57843a42a6674.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=15GCs8DoSm,{'value': 'Memory-Augmented Potential Field Theory: A Framework for Adaptive Control in Non-Convex Domains'},Dongzhe Zheng; Wenjie Mei,~Dongzhe_Zheng1; ~Wenjie_Mei1,"{'value': ['Stochastic optimal control', 'non-convex landscapes', 'potential field', 'model predictive path integral']}","{'value': 'Stochastic optimal control methods often struggle in complex non-convex landscapes, frequently becoming trapped in local optima due to their inability to learn from historical trajectory data. This paper introduces Memory-Augmented Potential Field Theory, a unified mathematical framework that integrates historical experience into stochastic optimal control. Our approach dynamically constructs memory-based potential fields that identify and encode key topological features of the state space, enabling controllers to automatically learn from past experiences and adapt their optimization strategy. We provide a theoretical analysis showing that memory-augmented potential fields possess non-convex escape properties, asymptotic convergence characteristics, and computational efficiency. We implement this theoretical framework in a Memory-Augmented Model Predictive Path Integral (MPPI) controller that demonstrates significantly improved performance in challenging non-convex environments. The framework represents a generalizable approach to experience-based learning within control systems (especially robotic dynamics), enhancing their ability to navigate complex state spaces without requiring specialized domain knowledge or extensive offline training.'}",https://openreview.net{'value': '/pdf/0d2886dc26f5c20b300dcc668524b24b3aa87613.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=14irEkV01l,{'value': 'Gene Regulatory Network Inference in the Presence of Selection Bias and Latent Confounders'},Gongxu Luo; Haoyue Dai; Loka Li; Chengqian Gao; Boyang Sun; Kun Zhang,~Gongxu_Luo1; ~Haoyue_Dai1; ~Loka_Li1; ~Chengqian_Gao1; ~Boyang_Sun1; ~Kun_Zhang1,{'value': ['Selection bias; Causal discovery; latent confounders; Gene regulatory newwork inference']},"{'value': 'Gene regulatory network inference (GRNI) aims to discover how genes causally regulate each other from gene expression data. It is well-known that statistical dependencies in observed data do not necessarily imply causation, as spurious dependencies may arise from *latent confounders*, such as non-coding RNAs. Numerous GRNI methods have thus been proposed to address this confounding issue. However, dependencies may also result from *selection*&mdash;only cells satisfying certain survival or inclusion criteria are observed&mdash;while these selection-induced spurious dependencies are frequently overlooked in gene expression data analyses. In this work, we show that such selection is ubiquitous and, when ignored or conflated with true regulations, can lead to flawed causal interpretation and misguided intervention recommendations. To address this challenge, a fundamental question arises: can we distinguish dependencies due to regulation, confounding, and crucially, selection? We show that gene perturbations offer a simple yet effective answer: selection-induced dependencies are *symmetric* under perturbation, while those from regulation or confounding are not. Building on this motivation, we propose GISL (Gene regulatory network Inference in the presence of Selection bias and Latent confounders), a principled algorithm that leverages perturbation data to uncover both true gene regulatory relations and non-regulatory mechanisms of selection and confounding up to the equivalence class. Experiments on synthetic and real-world gene expression data demonstrate the effectiveness of our method.'}",https://openreview.net{'value': '/pdf/d5e8c2307623331019cb0fb0d1ad6936087479ae.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=11fe8wKkmk,{'value': 'Fully Autonomous Neuromorphic Navigation and Dynamic Obstacle Avoidance'},Xiaochen Shang; Luo Pengwei; Xinning Wang; Jiayue Zhao; Huilin Ge; Bo Dong; Xin Yang,~Xiaochen_Shang1; ~Luo_Pengwei1; ~Xinning_Wang1; ~Jiayue_Zhao2; ~Huilin_Ge1; ~Bo_Dong7; ~Xin_Yang8,"{'value': ['neuromorphic', 'bio-inspred algorithm', 'dynamic obstacle avoidance', 'navigation', 'UAV', 'autonomous robots', 'event camera']}","{'value': 'Unmanned aerial vehicles could accurately accomplish complex navigation and obstacle avoidance tasks under external control. However, enabling unmanned aerial vehicles (UAVs) to rely solely on onboard computation and sensing for real-time navigation and dynamic obstacle avoidance remains a significant challenge due to stringent latency and energy constraints. Inspired by the efficiency of biological systems, we propose a fully neuromorphic framework achieving end-to-end obstacle avoidance during navigation with an overall latency of just 2.3 milliseconds. Specifically, our bio-inspired approach enables accurate moving object detection and avoidance without requiring target recognition or trajectory computation. Additionally, we introduce the first monocular event-based pose correction dataset with over 50,000 paired and labeled event streams. We validate our system on an autonomous quadrotor using only onboard resources, demonstrating reliable navigation and avoidance of diverse obstacles moving at speeds up to 10 m/s.'}",https://openreview.net{'value': '/pdf/7cd45be27655cc2a252d566674cf96c06e69a7bb.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=0qRXETZZwv,{'value': 'A Principled Approach to Randomized Selection under Uncertainty: Applications to Peer Review and Grant Funding'},Alexander Koujianos Goldberg; Giulia Fanti; Nihar B Shah,~Alexander_Koujianos_Goldberg1; ~Giulia_Fanti1; ~Nihar_B_Shah1,"{'value': ['peer review', 'randomized top-k selection', 'robust optimization', 'ranking', 'game theory']}","{'value': ""Many decision-making processes involve evaluating and selecting items, including scientific peer review, job hiring, school admissions, and investment decisions. These domains feature error-prone evaluations and uncertainty about outcomes, which undermine deterministic selection rules. Consequently, randomized selection mechanisms are gaining traction. However, current randomized approaches are ad hoc and, as we prove, inappropriate for their purported objectives. We propose a principled framework for randomized decision-making based on interval estimates of item quality. We introduce MERIT (Maximin Efficient Randomized Interval Top-$k$), which maximizes the worst-case expected number of top candidates selected under uncertainty represented by overlapping intervals. MERIT provides optimal resource allocation under an interpretable robustness notion. We develop a polynomial-time, practically efficient algorithm and prove our approach satisfies desirable axiomatic properties not guaranteed by existing methods. Experiments on synthetic peer review data from grant funding and conferences demonstrate that MERIT matches existing algorithms' expected utility under fully probabilistic models while outperforming them under our worst-case formulation.""}",https://openreview.net{'value': '/pdf/c7f7b9a6b69c3f0b46fcee0230cecc499f8d9332.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=0pbUfmwNTy,{'value': 'DyFlow: Dynamic Workflow Framework for Agentic Reasoning'},Yanbo Wang; Zixiang Xu; Yue Huang; Xiangqi Wang; Zirui Song; Lang Gao; Chenxi Wang; Xiangru Tang; Yue Zhao; Arman Cohan; Xiangliang Zhang; Xiuying Chen,~Yanbo_Wang10; ~Zixiang_Xu1; ~Yue_Huang9; ~Xiangqi_Wang1; ~Zirui_Song1; ~Lang_Gao1; ~Chenxi_Wang6; ~Xiangru_Tang2; ~Yue_Zhao13; ~Arman_Cohan1; ~Xiangliang_Zhang1; ~Xiuying_Chen1,"{'value': ['Large Language Models', 'LLM Agent', 'Workflow Generation']}","{'value': 'Agent systems based on large language models (LLMs) have shown great potential in complex reasoning tasks, but building efficient and generalizable workflows remains a major challenge. Most existing approaches rely on manually designed processes, which limits their adaptability across different tasks. While a few methods attempt automated workflow generation, they are often tied to specific datasets or query types and make limited use of intermediate feedback, reducing system robustness and reasoning depth. Moreover, their operations are typically predefined and inflexible.\nTo address these limitations, we propose **DyFlow**, a dynamic workflow generation framework that adaptively constructs and adjusts reasoning procedures based on task requirements and real-time intermediate feedback, thereby enhancing cross-task generalization.\nDyFlow consists of two core components: a designer and an executor. The designer decomposes complex problems into a sequence of sub-goals defined by high-level objectives and dynamically plans the next steps based on intermediate outputs and feedback. These plans are then carried out by the executor, which executes each operation using dynamic operators with context-aware parameterization, enabling flexible and semantically grounded reasoning.\nWe systematically evaluate DyFlow across diverse domains, including social reasoning, biomedical tasks, mathematical problem solving, and code generation.\nResults demonstrate that DyFlow significantly outperforms existing baselines, achieving substantial Pass@k improvements and exhibiting robust generalization across diverse domains.'}",https://openreview.net{'value': '/pdf/705f64f765b412ab6e17c0dc9c9146763c3e63fe.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=0kAfwgpeug,{'value': 'Sample-Efficient Multi-Round Generative Data Augmentation for Long-Tail Instance Segmentation'},Byunghyun Kim; Minyoung Bae; Jae-Gil Lee,~Byunghyun_Kim1; ~Minyoung_Bae1; ~Jae-Gil_Lee1,"{'value': ['instance segmentation', 'data synthesis', 'diffusion', 'copy-paste augmentation']}","{'value': 'Data synthesis has become increasingly crucial for long-tail instance segmentation tasks to mitigate class imbalance and high annotation costs. Previous methods have primarily prioritized the selection of data from a pre-generated image object pool, which frequently leads to the inefficient utilization of generated data. To address this inefficiency, we propose a **collaborative** approach that incorporates feedback from an instance segmentation model to guide the augmentation process. Specifically, the diffusion model uses feedback to generate objects that exhibit high uncertainty. The number and size of synthesized objects for each class are dynamically adjusted based on the model state to improve learning in underrepresented classes. This augmentation process is further strengthened by running **multiple rounds**, allowing feedback to be refined throughout training. In summary, **multi-round collaborative augmentation (MRCA)** enhances sample efficiency by providing optimal synthetic data at the right moment. Our framework requires **only 6\\%** of the data generation needed by state-of-the-art methods while outperforming them.'}",https://openreview.net{'value': '/pdf/04ef241f6193036be5393aee3a66f93523171503.pdf'},{'abstract_filter': 'Data Synthesis'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=0jQUNQsZra,{'value': 'SwS: Self-aware Weakness-driven Problem Synthesis in Reinforcement Learning for LLM Reasoning'},Xiao Liang; Zhong-Zhi Li; Yeyun Gong; Yang Wang; Hengyuan Zhang; yelong shen; Ying Nian Wu; Weizhu Chen,~Xiao_Liang9; ~Zhong-Zhi_Li1; ~Yeyun_Gong2; ~Yang_Wang11; ~Hengyuan_Zhang1; ~yelong_shen1; ~Ying_Nian_Wu1; ~Weizhu_Chen1,{'value': ['Reinforcement Learning; LLM Reasoning; Data Synthesis']},"{'value': ""Reinforcement Learning with Verifiable Rewards (RLVR) has proven effective for training large language models (LLMs) on complex reasoning tasks, such as mathematical problem solving. A prerequisite for the scalability of RLVR is a high-quality problem set with precise and verifiable answers. However, the scarcity of well-crafted human-labeled math problems and limited-verification answers in existing distillation-oriented synthetic datasets limit their effectiveness in RL. Additionally, most problem synthesis strategies indiscriminately expand the problem set without considering the model’s capabilities, leading to low efficiency in generating useful questions. To mitigate this issue, we introduce a Self-aware Weakness-driven problem Synthesis framework (SwS) that systematically identifies model deficiencies and leverages them for problem augmentation. Specifically, we define weaknesses as questions that the model consistently fails to learn through its iterative sampling during RL training. We then extract the core concepts from these failure cases and synthesize new problems to strengthen the model's weak areas in subsequent augmented training, enabling it to focus on and gradually overcome its weaknesses. Without relying on external knowledge distillation, our framework enables robust generalization by empowering the model to self-identify and address its weaknesses in RL, yielding average performance gains of 10% and 7.7% on 7B and 32B models across eight mainstream reasoning benchmarks. Our code and data are available at https://anonymous.4open.science/r/SwS-E6F5/""}",https://openreview.net{'value': '/pdf/c3403842de341324f63358f1732f1518761661f2.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=0fZoqVoc0o,{'value': 'RGB-Only Supervised Camera Parameter Optimization in Dynamic Scenes'},Fang Li; Hao Zhang; Narendra Ahuja,~Fang_Li8; ~Hao_Zhang47; ~Narendra_Ahuja1,"{'value': ['4D reconstruction', 'camera parameter optimization; visual localization']}","{'value': 'Although COLMAP has long remained the predominant method for camera parameter optimization in static scenes, it is constrained by its lengthy runtime and reliance on ground truth (GT) motion masks for application to dynamic scenes. Many efforts attempted to improve it by incorporating more priors as supervision such as GT focal length, motion masks, 3D point clouds, camera poses, and metric depth, which, however, are typically unavailable in casually captured RGB videos. In this paper, we propose a novel method for more accurate and efficient camera parameter optimization in dynamic scenes solely supervised by a single RGB video, dubbed $\\textbf{\\textit{ROS-Cam}}$. Our method consists of three key components: (1) Patch-wise Tracking Filters, to establish robust and maximally sparse hinge-like relations across the RGB video. (2) Outlier-aware Joint Optimization, for efficient camera parameter optimization by adaptive down-weighting of moving outliers, without reliance on motion priors. (3) A Two-stage Optimization Strategy, to enhance stability and optimization speed by a trade-off between the Softplus limits and convex minima in losses. We visually and numerically evaluate our camera estimates. To further validate accuracy, we feed the camera estimates into a 4D reconstruction method and assess the resulting 3D scenes, and rendered 2D RGB and depth maps.\nWe perform experiments on 4 real-world datasets (NeRF-DS, DAVIS, iPhone, and TUM-dynamics) and 1 synthetic dataset (MPI-Sintel), demonstrating that our method estimates camera parameters more efficiently and accurately with a single RGB video as the only supervision.'}",https://openreview.net{'value': '/pdf/4aff82cecf95c54cadcf7f30a92dffe6cdc83e24.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=0XCZWAo7wN,{'value': 'Online Time Series Forecasting with Theoretical Guarantees'},Zijian Li; Changze Zhou; Minghao Fu; Sanjay Manjunath; Fan Feng; Guangyi Chen; Yingyao Hu; Ruichu Cai; Kun Zhang,~Zijian_Li1; ~Changze_Zhou3; ~Minghao_Fu3; ~Sanjay_Manjunath1; ~Fan_Feng2; ~Guangyi_Chen1; ~Yingyao_Hu1; ~Ruichu_Cai1; ~Kun_Zhang1,{'value': ['Online Time Series Forecasting']},"{'value': 'This paper is concerned with online time series forecasting, where unknown distribution shifts occur over time, i.e., latent variables influence the mapping from historical to future observations. To develop an automated way of online time series forecasting, we propose a Theoretical framework for Online Time-series forecasting (TOT in short) with theoretical guarantees. Specifically, we prove that supplying a forecaster with latent variables tightens the Bayes risk—the benefit endures under estimation uncertainty of latent variables and grows as the latent variables achieve a more precise identifiability. To better introduce latent variables into online forecasting algorithms, we further propose to identify latent variables with minimal adjacent observations. Based on these results, we devise a model-agnostic blueprint by employing a temporal decoder to match the distribution of observed variables and two independent noise estimators to model the causal inference of latent variables and mixing procedures of observed variables, respectively. Experiment results on synthetic data support our theoretical claims. Moreover, plug-in implementations built on several baselines yield general improvement across multiple benchmarks, highlighting the effectiveness in real-world applications.'}",https://openreview.net{'value': '/pdf/e8aca67557b5958853062ccc2bf7e90fdf8bc749.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=0Nq1GvAGR0,{'value': 'A Driving-Style-Adaptive Framework  for Vehicle Trajectory Prediction'},Di Wen; Yu Wang; Zhigang Wu; Zhaocheng He; Zhe Wu; Zheng Qingfang,~Di_Wen3; ~Yu_Wang53; ~Zhigang_Wu1; ~Zhaocheng_He1; ~Zhe_Wu5; ~Zheng_Qingfang1,"{'value': ['Trajectory prediction', 'driver style category', 'Kolmogorov-Arnold Networks', 'model explanation', 'basis function', 'Weierstrass Approximation Theorem']}","{'value': 'Vehicle trajectory prediction serves as a critical enabler for autonomous navigation and intelligent transportation systems. While existing approaches predominantly focus on temporal pattern extraction and vehicle-environment interaction modeling, they exhibit a fundamental limitation in addressing trajectory heterogeneity originating from human driving styles. This oversight constrains prediction reliability in complex real-world scenarios.\nTo bridge this gap, we propose the Driving-Style-Adaptive (\\underline{\\textbf{DSA}}) framework, which establishes the first systematic integration of heterogeneous driving behaviors into trajectory prediction models. Specifically, our framework employs a set of basis functions tailored to each driving style to approximate the trajectory patterns. By dynamically combining and adaptively adjusting the degree of these basis functions, DSA not only enhances prediction accuracy but also provides \\textbf{explanations} insights into the prediction process. Extensive experiments on public real-world datasets demonstrate that the DSA framework outperforms state-of-the-art methods.'}",https://openreview.net{'value': '/pdf/19a4046603d4ecb927c2708967c00e223725333a.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=0J0y9vSCWf,{'value': 'Towards Identifiability of Hierarchical Temporal Causal Representation Learning'},Zijian Li; Minghao Fu; Junxian Huang; Yifan Shen; Ruichu Cai; Yuewen Sun; Guangyi Chen; Kun Zhang,~Zijian_Li1; ~Minghao_Fu3; ~Junxian_Huang2; ~Yifan_Shen4; ~Ruichu_Cai1; ~Yuewen_Sun1; ~Guangyi_Chen1; ~Kun_Zhang1,{'value': ['causal representation learning']},"{'value': 'Modeling hierarchical latent dynamics behind time series data is critical for capturing temporal dependencies across multiple levels of abstraction in real-world tasks. However, existing temporal causal representation learning methods fail to capture such dynamics, as they fail to recover the joint distribution of hierarchical latent variables from \\textit{single-timestep observed variables}. \nInterestingly, we find that the joint distribution of hierarchical latent variables can be uniquely determined using three conditionally independent observations. Building on this insight, we propose a Causally Hierarchical Latent Dynamic (CHiLD) identification framework. Our approach first employs temporal contextual observed variables to identify the joint distribution of multi-layer latent variables. Sequentially, we exploit the natural sparsity of the hierarchical structure among latent variables to identify latent variables within each layer. Guided by the theoretical results, we develop a time series generative model grounded in variational inference. This model incorporates a contextual encoder to reconstruct multi-layer latent variables and normalize flow-based hierarchical prior networks to impose the independent noise condition of hierarchical latent dynamics. Empirical evaluations on both synthetic and real-world datasets validate our theoretical claims and demonstrate the effectiveness of CHiLD in modeling hierarchical latent dynamics.'}",https://openreview.net{'value': '/pdf/fb414543a4171ffe25cc298010be8fd7bb1adf98.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=0IStUxUDGJ,{'value': 'Sculpting Features from Noise: Reward-Guided Hierarchical Diffusion for Task-Optimal Feature Transformation'},Nanxu Gong; Zijun Li; Sixun Dong; Haoyue Bai; Wangyang Ying; Xinyuan Wang; Yanjie Fu,~Nanxu_Gong1; ~Zijun_Li3; ~Sixun_Dong1; ~Haoyue_Bai2; ~Wangyang_Ying1; ~Xinyuan_Wang5; ~Yanjie_Fu2,"{'value': ['Feature Transformation', 'Diffusion Model', 'Reward-Guided Generation']}","{'value': 'Feature Transformation (FT) crafts new features from original ones via mathematical operations to enhance dataset expressiveness for downstream models. However, existing FT methods exhibit critical limitations: discrete search struggles with enormous combinatorial spaces, impeding practical use; and continuous search, being highly sensitive to initialization and step sizes, often becomes trapped in local optima, restricting global exploration. To overcome these limitations, DIFFT redefines FT as a reward-guided generative task. It first learns a compact and expressive latent space for feature sets using a Variational Auto-Encoder (VAE). A Latent Diffusion Model (LDM) then navigates this space to generate high-quality feature embeddings, its trajectory guided by a performance evaluator towards task-specific optima. This synthesis of global distribution learning (from LDM) and targeted optimization (reward guidance) produces potent embeddings, which a novel semi-autoregressive decoder efficiently converts into structured, discrete features, preserving intra-feature dependencies while allowing parallel inter-feature generation. Extensive experiments on 14 benchmark datasets show DIFFT consistently outperforms state-of-the-art baselines in predictive accuracy and robustness, with significantly lower training and inference times.'}",https://openreview.net{'value': '/pdf/c157721a78d3b511092ef35363f981b8d36ca524.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=0E2Um9n3YK,{'value': 'An Efficient Local Search Approach for Polarized Community Discovery in Signed Networks'},Linus Aronsson; Morteza Haghir Chehreghani,~Linus_Aronsson1; ~Morteza_Haghir_Chehreghani2,"{'value': ['Local search', 'clustering', 'correlation clustering', 'polarized community discovery', 'polarized community detection', 'signed networks', 'graph partitioning']}","{'value': 'Signed networks, where edges are labeled as positive or negative to represent friendly or antagonistic interactions, offer a natural framework for analyzing polarization, trust, and conflict in social systems. Detecting meaningful group structures in such networks is crucial for understanding online discourse, political divisions, and trust dynamics. A key challenge is to identify communities that are internally cohesive and externally antagonistic, while allowing for neutral or unaligned vertices. In this paper, we propose a method for identifying $k$ polarized communities that addresses a major limitation of prior methods: their tendency to produce highly size-imbalanced solutions. We introduce a novel optimization objective that avoids such imbalance. In addition, it is well known that approximation algorithms based on *local search* are highly effective for clustering signed networks when neutral vertices are not allowed. We build on this idea and design the first local search algorithm that extends to the setting with neutral vertices while scaling to large networks. By connecting our approach to block-coordinate Frank-Wolfe optimization, we prove a linear convergence rate, enabled by the structure of our objective. Experiments on real-world and synthetic datasets demonstrate that our method consistently outperforms state-of-the-art baselines in solution quality, while remaining competitive in computational efficiency.'}",https://openreview.net{'value': '/pdf/d47fe94ef4e51e526e4f655e320f831708e7de48.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=04p7u1gIsv,{'value': 'Quantifying Uncertainty in the Presence of Distribution Shifts'},Yuli Slavutsky; David Blei,~Yuli_Slavutsky1; ~David_Blei2,"{'value': ['Uncertainty estimation', 'distribution shift', 'variational inference', 'bayesian learning', 'out-of-distribution generalization']}","{'value': 'Neural networks make accurate predictions but often fail to provide reliable uncertainty estimates, especially when test-time covariates differ from those seen during training, as occurs with selection bias or shifts over time. To address this, we propose a Bayesian framework for uncertainty estimation that explicitly accounts for covariate shifts. Unlike conventional approaches that rely on fixed priors, a key idea of our method is an adaptive prior, conditioned on both training and new covariates. This prior naturally increases uncertainty for inputs that lie far from the training distribution in regions where predictive performance is likely to degrade. To efficiently approximate the resulting posterior predictive distribution, we employ amortized variational inference. Finally, we construct synthetic environments by drawing small bootstrap samples from the training data, simulating a range of plausible covariate shifts using only the original dataset. We evaluate our method on both synthetic and real-world data, demonstrating that it yields substantially improved uncertainty estimates under distribution shift compared to existing approaches.'}",https://openreview.net{'value': '/pdf/459301e33bac08b6b09e0caf1ffe0e6c0fd86b93.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
https://openreview.net/forum?id=047VzZEpnu,{'value': 'Spik-NeRF: Spiking Neural Networks for Neural Radiance Fields'},Gang Wan; Qinlong Lan; LiZihan; Huimin Wang; Wu Yitian; wang zhen; Wanhua Li; Yufei Guo,~Gang_Wan1; ~Qinlong_Lan1; ~LiZihan1; ~Huimin_Wang3; ~Wu_Yitian1; ~wang_zhen2; ~Wanhua_Li2; ~Yufei_Guo1,"{'value': ['Spiking Neural Networks', 'Spiking NeRF', 'Neural Radiance Fields']}","{'value': 'Spiking Neural Networks (SNNs), as a biologically inspired neural network architecture, have garnered significant attention due to their exceptional energy efficiency and increasing potential for various applications. In this work, we extend the use of SNNs to neural rendering tasks and introduce Spik-NeRF (Spiking Neural Radiance Fields). \n    We observe that the binary spike activation map of traditional SNNs lacks sufficient information capacity, leading to information loss and a subsequent decline in the performance of spiking neural rendering models. \n    To address this limitation, we propose the use of ternary spike neurons, which enhance the information-carrying capacity in the spiking neural rendering model. With ternary spike neurons, Spik-NeRF achieves performance that is on par with, or nearly identical to, traditional ANN-based rendering models.\n    Additionally, we present a re-parameterization technique for inference that allows Spik-NeRF with ternary spike neurons to retain the event-driven, multiplication-free advantages typical of binary spike neurons. \n    Furthermore, to further boost the performance of Spik-NeRF, we employ a distillation method, using an ANN-based NeRF to guide the training of our Spik-NeRF model, which is more compatible with the ternary neurons compared to the standard binary neurons. \n    We evaluate Spik-NeRF on both realistic and synthetic scenes, and the experimental results demonstrate that Spik-NeRF achieves rendering performance comparable to ANN-based NeRF models.'}",https://openreview.net{'value': '/pdf/fc89fd5ad0e49edff52069d62d63ec4068b5737a.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2025,Conference
