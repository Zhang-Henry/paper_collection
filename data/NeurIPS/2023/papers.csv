forum,title,authors,authorids,keywords,abstract,pdf,match,venue,year,type
https://openreview.net/forum?id=zfHCKDzzC8,{'value': 'Temporal Causal Mediation through a Point Process: Direct and Indirect Effects of Healthcare Interventions'},Çağlar Hızlı; S. T. John; Anne Tuulikki Juuti; Tuure Tapani Saarinen; Kirsi Hannele Pietiläinen; Pekka Marttinen,~Çağlar_Hızlı1; ~S._T._John1; ~Anne_Tuulikki_Juuti1; ~Tuure_Tapani_Saarinen1; ~Kirsi_Hannele_Pietiläinen1; ~Pekka_Marttinen1,"{'value': ['Machine learning for healthcare', 'Causal mediation', 'Gaussian process', 'Point Process']}","{'value': 'Deciding on an appropriate intervention requires a causal model of a treatment, the outcome, and potential mediators. Causal mediation analysis lets us distinguish between direct and indirect effects of the intervention, but has mostly been studied in a static setting. In healthcare, data come in the form of complex, irregularly sampled time-series, with dynamic interdependencies between a treatment, outcomes, and mediators across time. Existing approaches to dynamic causal mediation analysis are limited to regular measurement intervals, simple parametric models, and disregard long-range mediator--outcome interactions. To address these limitations, we propose a non-parametric mediator--outcome model where the mediator is assumed to be a temporal point process that interacts with the outcome process. With this model, we estimate the direct and indirect effects of an external intervention on the outcome, showing how each of these affects the whole future trajectory. We demonstrate on semi-synthetic data that our method can accurately estimate direct and indirect effects. On real-world healthcare data, our model infers clinically  meaningful direct and indirect effect trajectories for blood glucose after a surgery.'}",https://openreview.net{'value': '/pdf/7e09e1cae897c85d00abebac0e52fd9c4ee38c16.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=zTSlm4nmlH,{'value': 'Beta Diffusion'},Mingyuan Zhou; Tianqi Chen; Zhendong Wang; Huangjie Zheng,~Mingyuan_Zhou1; ~Tianqi_Chen2; ~Zhendong_Wang1; ~Huangjie_Zheng1,"{'value': ['Diffusion models', 'KL-divergence upper bounds', 'multiplicative transitions', 'scaled and shifted beta distributions']}","{'value': 'We introduce beta diffusion, a novel generative modeling method that integrates demasking and denoising to generate data within bounded ranges. Using scaled and shifted beta distributions, beta diffusion utilizes multiplicative transitions over time to create both forward and reverse diffusion processes, maintaining beta distributions in both the forward marginals and the reverse conditionals, given the data at any point in time. Unlike traditional diffusion-based generative models relying on additive Gaussian noise and reweighted evidence lower bounds (ELBOs), beta diffusion is multiplicative and optimized with KL-divergence upper bounds (KLUBs) derived from the convexity of the KL divergence. We demonstrate that the proposed KLUBs are more effective for optimizing beta diffusion compared to negative ELBOs, which can also be derived as the KLUBs of the same KL divergence with its two arguments swapped. The loss function of beta diffusion, expressed in terms of Bregman divergence, further supports the efficacy of KLUBs for optimization. Experimental results on both synthetic data and natural images demonstrate the unique capabilities of beta diffusion in generative modeling of range-bounded data and validate the effectiveness of KLUBs in optimizing diffusion models, thereby making them valuable additions to the family of diffusion-based generative models and the optimization techniques used to train them.'}",https://openreview.net{'value': '/pdf/d4b29b4b0595a2c7b5a6d76a12d631ccec860487.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=z3HACY5CMa,{'value': 'Joint Learning of Label and Environment Causal Independence for Graph Out-of-Distribution Generalization'},Shurui Gui; Meng Liu; Xiner Li; Youzhi Luo; Shuiwang Ji,~Shurui_Gui1; ~Meng_Liu3; ~Xiner_Li1; ~Youzhi_Luo1; ~Shuiwang_Ji1,"{'value': ['deep learning', 'graph neural network', 'out-of-distribution generalization', 'distribution shift']}","{'value': 'We tackle the problem of graph out-of-distribution (OOD) generalization. Existing graph OOD algorithms either rely on restricted assumptions or fail to exploit environment information in training data. In this work, we propose to simultaneously incorporate label and environment causal independence (LECI) to fully make use of label and environment information, thereby addressing the challenges faced by prior methods on identifying causal and invariant subgraphs. We further develop an adversarial training strategy to jointly optimize these two properties for casual subgraph discovery with theoretical guarantees. Extensive experiments and analysis show that LECI significantly outperforms prior methods on both synthetic and real-world datasets, establishing LECI as a practical and effective solution for graph OOD generalization.'}",https://openreview.net{'value': '/pdf/739501273cf8778ff3b32363ed12844b23b6fa7f.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=ykvvv0gc4R,{'value': 'Deep Momentum Multi-Marginal Schrödinger Bridge'},Tianrong Chen; Guan-Horng Liu; Molei Tao; Evangelos Theodorou,~Tianrong_Chen1; ~Guan-Horng_Liu1; ~Molei_Tao1; ~Evangelos_Theodorou1,"{'value': ['Schrödinger Bridge', 'Trajectory Inference', 'Optimal Transport']}","{'value': 'It is a crucial challenge to reconstruct population dynamics using unlabeled samples from distributions at coarse time intervals. Recent approaches such as flow-based models or Schrödinger Bridge (SB) models have demonstrated appealing performance, yet the inferred sample trajectories either fail to account for the underlying stochasticity or are unnecessarily rigid. In this article, we extend SB into phase space and propose $\\underline{D}$eep $\\underline{M}$omentum Multi-Marginal $\\underline{S}$chrödinger $\\underline{B}$ridge (DMSB), a novel computational framework that learns the smooth measure-valued spline for stochastic systems that satisfy position marginal constraints across time. By tailoring the celebrated Bregman Iteration and extending the Iteration Proportional Fitting to phase space, we manage to handle high-dimensional multi-marginal trajectory inference tasks efficiently. Our algorithm outperforms baselines significantly, as evidenced by experiments for synthetic datasets and a real-world single-cell RNA sequence dataset. Additionally, the proposed approach can reasonably reconstruct the evolution of velocity distribution, from position snapshots only, when there is a ground truth velocity that is nevertheless inaccessible.'}",https://openreview.net{'value': '/pdf/59558d952f4964c1facdd4fb8983abae319685e1.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=ykMdzevPkJ,{'value': 'DiffTraj: Generating GPS Trajectory with Diffusion Probabilistic Model'},Yuanshao Zhu; Yongchao Ye; Shiyao Zhang; Xiangyu Zhao; James Yu,~Yuanshao_Zhu1; ~Yongchao_Ye1; zhangsy@sustech.edu.cn; ~Xiangyu_Zhao1; ~James_Yu1,"{'value': ['Trajectory Generation', 'Diffusion Model', 'Urban Computing', 'Spatial-temporal Data Mining']}","{'value': 'Pervasive integration of GPS-enabled devices and data acquisition technologies has led to an exponential increase in GPS trajectory data, fostering advancements in spatial-temporal data mining research. Nonetheless, GPS trajectories contain personal geolocation information, rendering serious privacy concerns when working with raw data. A promising approach to address this issue is trajectory generation, which involves replacing original data with generated, privacy-free alternatives. Despite the potential of trajectory generation, the complex nature of human behavior and its inherent stochastic characteristics pose challenges in generating high-quality trajectories. \nIn this work, we propose a spatial-temporal diffusion probabilistic model for trajectory generation (DiffTraj). This model effectively combines the generative abilities of diffusion models with the spatial-temporal features derived from real trajectories. The core idea is to reconstruct and synthesize geographic trajectories from white noise through a reverse trajectory denoising process. Furthermore, we propose a Trajectory UNet (Traj-UNet) deep neural network to embed conditional information and accurately estimate noise levels during the reverse process. Experiments on two real-world datasets show that DiffTraj can be intuitively applied to generate high-fidelity trajectories while retaining the original distributions. Moreover, the generated results can support downstream trajectory analysis tasks and significantly outperform other methods in terms of geo-distribution evaluations.'}",https://openreview.net{'value': '/pdf/f555cd65ef52c9b59703f6cfab7da2af81080ddb.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=yjWVd8Fhqt,{'value': 'OBJECT 3DIT: Language-guided 3D-aware Image Editing'},Oscar Michel; Anand Bhattad; Eli VanderBilt; Ranjay Krishna; Aniruddha Kembhavi; Tanmay Gupta,~Oscar_Michel1; ~Anand_Bhattad1; ~Eli_VanderBilt1; ~Ranjay_Krishna1; ~Aniruddha_Kembhavi1; ~Tanmay_Gupta1,"{'value': ['computer vision', 'image editing', 'generative modeling', 'diffusion models', '3D']}","{'value': 'Existing image editing tools, while powerful, typically disregard the underlying 3D geometry from which the image is projected. As a result, edits made using these tools may become detached from the geometry and lighting conditions that are at the foundation of the image formation process; such edits break the portrayal of a coherent 3D world. 3D-aware generative models are a promising solution, but currently only succeed on small datasets or at the level of a single object. In this work, we formulate the new task of language-guided 3D-aware editing, where objects in an image should be edited according to a language instruction while remaining consistent with the underlying 3D scene. To promote progress towards this goal, we release OBJect: a benchmark dataset of 400K editing examples created from procedurally generated 3D scenes. Each example consists of an input image, editing instruction in language, and the edited image. We also introduce 3DIT: single and multi-task models for four editing tasks. Our models show impressive abilities to understand the 3D composition of entire scenes, factoring in surrounding objects, surfaces, lighting conditions, shadows, and physically-plausible object configurations. Surprisingly, training on only synthetic scenes from \\dataset, editing capabilities of 3DIT generalize to real-world images.'}",https://openreview.net{'value': '/pdf/b286d9e4631400ea90d5604eaa4a0248245cbf95.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=yaJ4vZPnHX,{'value': 'Complexity of Derivative-Free Policy Optimization for Structured $\\mathcal{H}_\\infty$ Control'},Xingang Guo; Darioush Keivan; Geir Dullerud; Peter Seiler; Bin Hu,~Xingang_Guo1; ~Darioush_Keivan1; ~Geir_Dullerud1; ~Peter_Seiler1; ~Bin_Hu2,"{'value': ['Structured $\\mathcal{H}_\\infty$ Control', 'Nonsmooth Optimization', 'Complexity Analysis']}","{'value': 'The applications of direct policy search in reinforcement learning and continuous control have received increasing attention.\nIn this work, we present novel theoretical results on the complexity of derivative-free policy optimization on an important class of robust control tasks, namely the structured $H_\\infty$ synthesis with static output feedback. \nOptimal $H_\\infty$ synthesis under structural constraints leads to a constrained nonconvex nonsmooth problem and is typically\naddressed using subgradient-based policy search techniques that are built upon the concept of Goldstein subdifferential or other notions of enlarged subdifferential.  In this paper, we study the complexity of finding $(\\delta,\\epsilon)$-stationary points for such nonsmooth robust control design tasks using policy optimization methods which can only access the zeroth-order oracle (i.e. the $H_\\infty$ norm of the closed-loop system). First, we study the exact oracle setting and identify the coerciveness of the cost function to prove high-probability feasibility/complexity bounds for derivative-free policy optimization on this problem. Next, we derive a sample complexity result for the multi-input multi-output (MIMO)  $H_\\infty$-norm estimation. We combine this with our analysis to obtain the first sample complexity of model-free, trajectory-based, zeroth-order policy optimization on finding $(\\delta,\\epsilon)$-stationary points for structured $H_\\infty$ control. \nNumerical results are also provided to demonstrate our theory.'}",https://openreview.net{'value': '/pdf/f97f75e682742bda98fe92ae84f4229f89e88d8a.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=yVMlYSL1Bp,{'value': 'Diverse Shape Completion via Style Modulated Generative Adversarial Networks'},Wesley Khademi; Li Fuxin,~Wesley_Khademi1; ~Li_Fuxin1,"{'value': ['multimodal shape completion', 'point cloud completion', '3d shape generation', 'generative modeling', 'generative adversarial networks']}","{'value': 'Shape completion aims to recover the full 3D geometry of an object from a partial observation. This problem is inherently multi-modal since there can be many ways to plausibly complete the missing regions of a shape. Such diversity would be indicative of the underlying uncertainty of the shape and could be preferable for downstream tasks such as planning. In this paper, we propose a novel conditional generative adversarial network that can produce many diverse plausible completions of a partially observed point cloud. To enable our network to produce multiple completions for the same partial input, we introduce stochasticity into our network via style modulation. By extracting style codes from complete shapes during training, and learning a distribution over them, our style codes can explicitly carry shape category information leading to better completions. We further introduce diversity penalties and discriminators at multiple scales to prevent conditional mode collapse and to train without the need for multiple ground truth completions for each partial input. Evaluations across several synthetic and real datasets demonstrate that our method achieves significant improvements in respecting the partial observations while obtaining greater diversity in completions.'}",https://openreview.net{'value': '/pdf/f49032cc72d8735a4a08beb86cdce4932d3f2ab7.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=yN6NHZOXkg,{'value': 'Generalized Information-theoretic Multi-view Clustering'},Weitian Huang; Sirui Yang; Hongmin Cai,~Weitian_Huang1; ~Sirui_Yang1; ~Hongmin_Cai1,"{'value': ['information bottleneck', 'multi-view clustering', 'variational autoencoders']}","{'value': ""In an era of more diverse data modalities, multi-view clustering has become a fundamental tool for comprehensive data analysis and exploration. However, existing multi-view unsupervised learning methods often rely on strict assumptions on semantic consistency among samples. In this paper, we reformulate the multi-view clustering problem from an information-theoretic perspective and propose a general theoretical model. In particular, we define three desiderata under multi-view unsupervised learning in terms of mutual information, namely, comprehensiveness, concentration, and cross-diversity. The multi-view variational lower bound is then obtained by approximating the samples' high-dimensional mutual information. The Kullback–Leibler divergence is utilized to deduce sample assignments. Ultimately the information-based multi-view clustering model leverages deep neural networks and Stochastic Gradient Variational Bayes to achieve representation learning and clustering simultaneously. Extensive experiments on both synthetic and real datasets with wide types demonstrate that the proposed method exhibits a more stable and superior clustering performance than state-of-the-art algorithms.""}",https://openreview.net{'value': '/pdf/b58cdae08385db145c1d82f7d13788da501e82ab.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=yIcCkMUCtL,{'value': 'Towards a Unified Analysis of Kernel-based Methods Under Covariate Shift'},Xingdong Feng; Xin HE; Caixing Wang; Chao Wang; Jingnan Zhang,~Xingdong_Feng1; ~Xin_HE7; ~Caixing_Wang1; ~Chao_Wang39; ~Jingnan_Zhang1,"{'value': ['kernel methods', 'covariate shift', 'reproducing kernel Hilbert space (RKHS)']}","{'value': 'Covariate shift occurs prevalently in practice, where the input distributions of the source and target data are substantially different. Despite its practical importance in various learning problems, most of the existing methods only focus on some specific learning tasks and are not well validated theoretically and numerically. To tackle this problem, we propose a unified analysis of general nonparametric methods in a reproducing kernel Hilbert space (RKHS) under covariate shift.  Our theoretical results are established for a general loss belonging to a rich loss function family, which includes many commonly used methods as special cases, such as mean regression, quantile regression, likelihood-based classification, and margin-based classification. Two types of covariate shift problems are the focus of this paper and the sharp convergence rates are established for a general loss function to provide a unified theoretical analysis, which concurs with the optimal results in literature where the squared loss is used. Extensive numerical studies on synthetic and real examples confirm our theoretical findings and further illustrate the effectiveness of our proposed method.'}",https://openreview.net{'value': '/pdf/456e7e6bb36b1d4f84f11df855bcf424e2f1bfa1.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=yEfmhgwslQ,{'value': 'Encoding Time-Series Explanations through Self-Supervised Model Behavior Consistency'},Owen Queen; Thomas Hartvigsen; Teddy Koker; Huan He; Theodoros Tsiligkaridis; Marinka Zitnik,~Owen_Queen1; ~Thomas_Hartvigsen1; ~Teddy_Koker1; ~Huan_He2; ~Theodoros_Tsiligkaridis1; ~Marinka_Zitnik1,"{'value': ['Explainability', 'Interpretability', 'Time Series', 'Explanations', 'Temporal patterns', 'Model Understanding', 'Latent space', 'Self-supervised learning']}","{'value': 'Interpreting time series models is uniquely challenging because it requires identifying both the location of time series signals that drive model predictions and their matching to an interpretable temporal pattern. While explainers from other modalities can be applied to time series, their inductive biases do not transfer well to the inherently challenging interpretation of time series. We present TimeX, a time series consistency model for training explainers. TimeX trains an interpretable surrogate to mimic the behavior of a pretrained time series model. It addresses the issue of model faithfulness by introducing model behavior consistency, a novel formulation that preserves relations in the latent space induced by the pretrained model with relations in the latent space induced by TimeX. TimeX provides discrete attribution maps and, unlike existing interpretability methods, it learns a latent space of explanations that can be used in various ways, such as to provide landmarks to visually aggregate similar explanations and easily recognize temporal patterns. We evaluate TimeX on eight synthetic and real-world datasets and compare its performance against state-of-the-art interpretability methods. We also conduct case studies using physiological time series. Quantitative evaluations demonstrate that TimeX achieves the highest or second-highest performance in every metric compared to baselines across all datasets. Through case studies, we show that the novel components of TimeX show potential for training faithful, interpretable models that capture the behavior of pretrained time series models.'}",https://openreview.net{'value': '/pdf/6c929f4720cece2dbcfdb739210fda7a6e365afb.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=yEewbkBNzi,{'value': 'Convergence of Adam Under Relaxed Assumptions'},Haochuan Li; Alexander Rakhlin; Ali Jadbabaie,~Haochuan_Li2; ~Alexander_Rakhlin1; ~Ali_Jadbabaie1,"{'value': ['Non-convex optimization', 'Adam', 'Convergence', 'Variance reduction']}","{'value': 'In this paper, we provide a rigorous proof of convergence of the Adaptive Moment Estimate (Adam) algorithm for a wide class of optimization objectives. Despite the popularity and efficiency of the Adam algorithm in training deep neural networks, its theoretical properties are not yet fully understood, and existing convergence proofs require unrealistically strong assumptions, such as globally bounded gradients, to show the convergence to stationary points. In this paper, we show that Adam provably converges to $\\epsilon$-stationary points with $\\mathcal{O}(\\epsilon^{-4})$ gradient complexity under far more realistic conditions. The key to our analysis is a new proof of boundedness of gradients along the optimization trajectory of Adam, under a generalized smoothness assumption according to which the local smoothness (i.e., Hessian norm when it exists) is bounded by a sub-quadratic function of the gradient norm. Moreover, we propose a variance-reduced version of Adam with an accelerated gradient complexity of $\\mathcal{O}(\\epsilon^{-3})$.'}",https://openreview.net{'value': '/pdf/862f2a4fb941567e8c797e2c153beb10dddaba5d.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=y9U0IJ2uFr,{'value': 'SNEkhorn: Dimension Reduction with Symmetric Entropic Affinities'},Hugues Van Assel; Titouan Vayer; Rémi Flamary; Nicolas Courty,~Hugues_Van_Assel1; ~Titouan_Vayer1; ~Rémi_Flamary1; ~Nicolas_Courty1,"{'value': ['Dimension Reduction', 'Optimal Transport', 'Affinities']}","{'value': 'Many approaches in machine learning rely on a weighted graph to encode the\nsimilarities between samples in a dataset. Entropic affinities (EAs), which are notably used in the popular Dimensionality Reduction (DR) algorithm t-SNE, are particular instances of such graphs. To ensure robustness to heterogeneous sampling densities, EAs assign a kernel bandwidth parameter to every sample in such a way that the entropy of each row in the affinity matrix is kept constant at a specific value, whose exponential is known as perplexity. EAs are inherently asymmetric and row-wise stochastic, but they are used in DR approaches after undergoing heuristic symmetrization methods that violate both the row-wise constant entropy and stochasticity properties. In this work, we uncover a novel characterization of EA as an optimal transport problem, allowing a natural symmetrization that can be computed efficiently using dual ascent. \nThe corresponding novel affinity matrix derives advantages from symmetric doubly stochastic normalization in terms of clustering performance, while also effectively controlling the entropy of each row thus making it particularly robust to varying noise levels. Following, we present a new DR algorithm, SNEkhorn, that leverages this new affinity matrix. We show its clear superiority to state-of-the-art approaches with several indicators on both synthetic and real-world datasets.'}",https://openreview.net{'value': '/pdf/1befc2bb2ed5de53b2bb6b777d7586e4b12c382d.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=y0OlQSZsyp,{'value': 'Learning Causal Models under Independent Changes'},Sarah Mameche; David Kaltenpoth; Jilles Vreeken,~Sarah_Mameche1; ~David_Kaltenpoth1; ~Jilles_Vreeken2,"{'value': ['independent mechanisms', 'causal discovery', 'information theory', 'gaussian processes']}","{'value': 'In many scientific applications, we observe a system in different conditions in which its components may change, rather than in isolation. In our work, we are interested in explaining the generating process of such a multi-context system using a finite mixture of causal mechanisms. Recent work shows that this causal model is identifiable from data, but is limited to settings where the sparse mechanism shift hypothesis holds and only a subset of the causal conditionals change. As this assumption is not easily verifiable in practice, we study the more general principle that mechanism shifts are independent, which we formalize using the algorithmic notion of independence. We introduce an approach for causal discovery beyond partially directed graphs using Gaussian Process models, and give conditions under which we provably identify the correct causal model. In our experiments, we show that our method performs well in a range of synthetic settings, on realistic gene expression simulations, as well as on real-world cell signaling data.'}",https://openreview.net{'value': '/pdf/1feb2a4758bdbdaf2caa6dc39fbe0cfec877ce8c.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=xzmaFfw6oh,{'value': 'Molecule Joint Auto-Encoding: Trajectory Pretraining with 2D and 3D Diffusion'},weitao Du; Jiujiu Chen; Xuecang Zhang; Zhi-Ming Ma; Shengchao Liu,~weitao_Du1; ~Jiujiu_Chen1; ~Xuecang_Zhang1; ~Zhi-Ming_Ma1; ~Shengchao_Liu1,"{'value': ['Molecule Joint Auto-encoding', 'Molecule Joint Self-supervised Learning', 'Markov processes', 'contrastive learning', 'molecule representation learning']}","{'value': ""Recently, artificial intelligence for drug discovery has raised increasing interest in both machine learning and chemistry domains. The fundamental building block for drug discovery is molecule geometry and thus, the molecule's geometrical representation is the main bottleneck to better utilize machine learning techniques for drug discovery. In this work, we propose a pretraining method for molecule joint auto-encoding (MoleculeJAE). MoleculeJAE can learn both the 2D bond (topology) and 3D conformation (geometry) information, and a diffusion process model is applied to mimic the augmented trajectories of such two modalities, based on which, MoleculeJAE will learn the inherent chemical structure in a self-supervised manner. Thus, the pretrained geometrical representation in MoleculeJAE is expected to benefit downstream geometry-related tasks. Empirically, MoleculeJAE proves its effectiveness by reaching state-of-the-art performance on 15 out of 20 tasks by comparing it with 12 competitive baselines.""}",https://openreview.net{'value': '/pdf/cbfd52ee704a43a297be3272e141ad64fa365609.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=xpjsOQtKqx,{'value': 'StableRep: Synthetic Images from Text-to-Image Models Make Strong Visual Representation Learners'},Yonglong Tian; Lijie Fan; Phillip Isola; Huiwen Chang; Dilip Krishnan,~Yonglong_Tian1; ~Lijie_Fan1; ~Phillip_Isola1; ~Huiwen_Chang2; ~Dilip_Krishnan1,"{'value': ['representation learning', 'synthetic images', 'text-to-image models']}","{'value': 'We investigate the potential of learning visual representations using synthetic images generated by text-to-image models. This is a natural question in the light of the excellent performance of such models in generating high-quality images. We consider specifically the Stable Diffusion, one of the leading open source text-to-image models. We show that (1) when the generative model is properly configured, training self-supervised methods on synthetic images can match or beat the real image counterpart;\n(2) by treating the multiple images generated from the same text prompt as positives for each other, we develop a multi-positive contrastive learning method, which we call StableRep. \nWith solely synthetic images, the representations learned by StableRep surpass the performance of representations learned by SimCLR and CLIP using the same set of text prompts and corresponding real images, on large scale datasets. \nWhen we further add language supervision, \\name~trained with 20M synthetic images (10M captions) achieves better accuracy than CLIP trained with 50M real images (50M captions).'}",https://openreview.net{'value': '/pdf/e1678099d3fce077fcf242077617687aeec70793.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=xo2lbfQE8I,{'value': 'Fitting trees to $\\ell_1$-hyperbolic distances'},Joon-Hyeok Yim; Anna Gilbert,~Joon-Hyeok_Yim1; ~Anna_Gilbert2,"{'value': ['tree metric fitting', 'ultrametric fitting', '$\\ell_1$-hyperbolicity']}","{'value': ""Building trees to represent or to fit distances is a critical component of phylogenetic analysis, metric embeddings, approximation algorithms, geometric graph neural nets, and the analysis of hierarchical data. Much of the previous algorithmic work, however, has focused on generic metric spaces (i.e., those with no \\emph{a priori} constraints). Leveraging several ideas from the mathematical analysis of hyperbolic geometry and geometric group theory, we study the tree fitting problem as finding the relation between the hyperbolicity (ultrametricity) vector and the error of tree (ultrametric) embedding. That is, we define a vector of hyperbolicity (ultrametric) values over all triples of points and compare the $\\ell_p$ norms of this vector with the $\\ell_q$ norm of the distortion of the best tree fit to the distances. This formulation allows us to define the average hyperbolicity (ultrametricity) in terms of a normalized $\\ell_1$ norm of the hyperbolicity vector. Furthermore, we can interpret the classical tree fitting result of Gromov as a $p = q = \\infty$ result. We present an algorithm \\textsc{HCCRootedTreeFit} such that the $\\ell_1$ error of the output embedding is analytically bounded in terms of the $\\ell_1$-norm of the hyperbolicity vector (i.e., $p = q = 1$) and that this result is tight. Furthermore, this algorithm has significantly different theoretical and empirical performance as compared to Gromov's result and related algorithms. Finally, we show using \\textsc{HCCRootedTreeFit} and related tree fitting algorithms, that supposedly standard data sets for hierarchical data analysis and geometric graph neural networks have radically different tree fits than those of synthetic, truly tree-like data sets, suggesting that a much more refined analysis of these standard data sets is called for.""}",https://openreview.net{'value': '/pdf/9c2a7aa63f0062da7a0cb4888b2350a8dac4a750.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=xWCp0uLcpG,{'value': 'Robust Data Pruning under Label Noise via Maximizing Re-labeling Accuracy'},Dongmin Park; Seola Choi; Doyoung Kim; Hwanjun Song; Jae-Gil Lee,~Dongmin_Park1; ~Seola_Choi1; ~Doyoung_Kim2; ~Hwanjun_Song2; ~Jae-Gil_Lee1,"{'value': ['Data Pruning', 'Data Subset Selection', 'Noisy Labels', 'Relabeling', 'Self-training']}","{'value': 'Data pruning, which aims to downsize a large training set into a small informative subset, is crucial for reducing the enormous computational costs of modern deep learning. Though large-scale data collections invariably contain annotation noise and numerous robust learning methods have been developed, data pruning for the noise-robust learning scenario has received little attention. With state-of-the-art Re-labeling methods that self-correct erroneous labels while training, it is challenging to identify which subset induces the most accurate re-labeling of erroneous labels in the entire training set. In this paper, we formalize the problem of data pruning with re-labeling. We first show that the likelihood of a training example being correctly re-labeled is proportional to the prediction confidence of its neighborhood in the subset. Therefore, we propose a novel data pruning algorithm, Prune4Rel, that finds a subset maximizing the total neighborhood confidence of all training examples, thereby maximizing the re-labeling accuracy and generalization performance. Extensive experiments on four real and one synthetic noisy datasets show that Prune4Rel outperforms the baselines with Re-labeling models by up to 9.1% as well as those with a standard model by up to 21.6%.'}",https://openreview.net{'value': '/pdf/70670d7375e2c414c249bdccc86831f337bf7851.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=xRfTcZdQxq,{'value': 'Robust Model Reasoning and Fitting via Dual Sparsity Pursuit'},Xingyu Jiang; Jiayi Ma,~Xingyu_Jiang1; ~Jiayi_Ma2,{'value': ['Model reasoning; Model fitting; Outliers; Sparse subspace learning; Feature matching']},"{'value': ""In this paper, we contribute to solving a threefold problem: outlier rejection, true model reasoning and parameter estimation with a unified optimization modeling. To this end, we first pose this task as a sparse subspace recovering problem, to search a maximum of independent bases under an over-embedded data space. Then we convert the objective into a continuous optimization paradigm that estimates sparse solutions for both bases and errors. Wherein a fast and robust solver is proposed to accurately estimate the sparse subspace parameters and error entries, which is implemented by a proximal approximation method under the alternating optimization framework with the ``optimal'' sub-gradient descent. Extensive experiments regarding known and unknown model fitting on synthetic and challenging real datasets have demonstrated the superiority of our method against the state-of-the-art. We also apply our method to multi-class multi-model fitting and loop closure detection, and achieve promising results both in accuracy and efficiency. Code is released at: https://github.com/StaRainJ/DSP.""}",https://openreview.net{'value': '/pdf/639371f41f9b3fc2794cb478bb85135e29e503a6.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=xMgO04HDOS,{'value': 'Hierarchical Multi-Agent Skill Discovery'},Mingyu Yang; Yaodong Yang; Zhenbo Lu; Wengang Zhou; Houqiang Li,~Mingyu_Yang1; ~Yaodong_Yang1; ~Zhenbo_Lu1; ~Wengang_Zhou1; ~Houqiang_Li1,"{'value': ['Multi-Agent Reinforcement Learning', 'Hierarchical Skill Discovery', 'Probabilistic Graphical Model']}","{'value': 'Skill discovery has shown significant progress in unsupervised reinforcement learning. This approach enables the discovery of a wide range of skills without any extrinsic reward, which can be effectively combined to tackle complex tasks. However, such unsupervised skill learning has not been well applied to multi-agent reinforcement learning (MARL) due to two primary challenges. One is how to learn skills not only for the individual agents but also for the entire team, and the other is how to coordinate the skills of different agents to accomplish multi-agent tasks. To address these challenges, we present Hierarchical Multi-Agent Skill Discovery (HMASD), a two-level hierarchical algorithm for discovering both team and individual skills in MARL. The high-level policy employs a transformer structure to realize sequential skill assignment, while the low-level policy learns to discover valuable team and individual skills. We evaluate HMASD on sparse reward multi-agent benchmarks, and the results show that HMASD achieves significant performance improvements compared to strong MARL baselines.'}",https://openreview.net{'value': '/pdf/339f44f5c8b82bcadd358b926ed7b51fbd184bf5.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=xGz0wAIJrS,{'value': 'State2Explanation: Concept-Based Explanations to Benefit Agent Learning and User Understanding'},Devleena Das; Sonia Chernova; Been Kim,~Devleena_Das1; ~Sonia_Chernova2; ~Been_Kim1,"{'value': ['Concept-Based Explanations', 'Reinforcement Learning', 'Human-AI Interaction']}","{'value': ""As more non-AI experts use complex AI systems for daily tasks, there has been an increasing effort to develop methods that produce explanations of AI decision making that are understandable by non-AI experts. Towards this effort, leveraging higher-level concepts and producing concept-based explanations have become a popular method. Most concept-based explanations have been developed for classification techniques, and we posit that the few existing methods for sequential decision making are limited in scope. In this work, we first contribute a desiderata for defining ``concepts'' in sequential decision making settings. Additionally, inspired by the Protege Effect which states explaining knowledge often reinforces one's self-learning, we explore how concept-based explanations of an RL agent's decision making can in turn improve the agent's learning rate, as well as improve end-user understanding of the agent's decision making. To this end, we contribute a unified framework, State2Explanation (S2E), that involves learning a joint embedding model between state-action pairs and concept-based explanations, and leveraging such learned model to both (1) inform reward shaping during an agent's training, and (2) provide explanations to end-users at deployment for improved task performance. Our experimental validations, in Connect 4 and Lunar Lander, demonstrate the success of S2E in providing a dual-benefit, successfully informing reward shaping and improving agent learning rate, as well as significantly improving end user task performance at deployment time.""}",https://openreview.net{'value': '/pdf/c31f0b61824abed0e75067f00e0e0d64fbffbc60.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=x7q7w07r6Y,{'value': 'Lending Interaction Wings to Recommender Systems with Conversational Agents'},Jiarui Jin; Xianyu Chen; Fanghua Ye; Mengyue Yang; Yue Feng; Weinan Zhang; Yong Yu; Jun Wang,~Jiarui_Jin1; ~Xianyu_Chen2; ~Fanghua_Ye1; ~Mengyue_Yang1; ~Yue_Feng1; ~Weinan_Zhang1; ~Yong_Yu1; ~Jun_Wang2,"{'value': ['Conversational Agent', 'Recommender System', 'Conversational Recommendation']}","{'value': 'An intelligent conversational agent (a.k.a., chat-bot) could embrace conversational technologies to obtain user preferences online, to overcome inherent limitations of recommender systems trained over the offline historical user behaviors. In this paper, we propose CORE, a new offline-training and online-checking framework to plug a COnversational agent into REcommender systems. Unlike most prior conversational recommendation approaches that systemically combine conversational and recommender parts through a reinforcement learning framework, CORE bridges the conversational agent and recommender system through a unified uncertainty minimization framework, which can be easily applied to any existing recommendation approach. Concretely, CORE treats a recommender system as an offline estimator to produce an estimated relevance score for each item, while CORE regards a conversational agent as an online checker that checks these estimated scores in each online session. We define uncertainty as the sum of unchecked relevance scores. In this regard, the conversational agent acts to minimize uncertainty via querying either attributes or items. Towards uncertainty minimization, we derive the certainty gain of querying each attribute and item, and develop a novel online decision tree algorithm to decide what to query at each turn. Our theoretical analysis reveals the bound of the expected number of turns of CORE in a cold-start setting. Experimental results demonstrate that CORE can be seamlessly employed on a variety of recommendation approaches, and can consistently bring significant improvements in both hot-start and cold-start settings.'}",https://openreview.net{'value': '/pdf/f4b322e7cb15d458a9514322717753aa397a8dfe.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=x6cOcxRnxG,{'value': 'Neural Ideal Large Eddy Simulation: Modeling Turbulence with Neural Stochastic Differential Equations'},Anudhyan Boral; Zhong Yi Wan; Leonardo Zepeda-Nunez; James Lottes; Qing Wang; Yi-Fan Chen; John Roberts Anderson; Fei Sha,~Anudhyan_Boral1; ~Zhong_Yi_Wan1; ~Leonardo_Zepeda-Nunez1; jlottes@google.com; ~Qing_Wang16; yifanchen@google.com; janders@google.com; ~Fei_Sha3,"{'value': ['partial differential equations', 'physics', 'turbulence', 'stochastic differential equations', 'physical simulation', 'neural differential equations']}","{'value': 'We introduce a data-driven learning framework that assimilates two powerful ideas: ideal large eddy simulation (LES) from turbulence closure modeling and neural stochastic differential equations (SDE) for stochastic modeling. The ideal LES models the LES flow by treating each full-order trajectory as a random realization of the underlying dynamics, as such, the effect of small-scales is marginalized to obtain the deterministic evolution of the LES state. However, ideal LES is analytically intractable. In our work, we use a latent neural SDE to model the evolution of the stochastic process and an encoder-decoder pair for transforming between the latent space and the desired ideal flow field. This stands in sharp contrast to other types of neural parameterization of closure models where each trajectory is treated as a deterministic realization of the dynamics. We show the effectiveness of our approach (niLES – neural ideal LES) on two challenging chaotic dynamical systems: Kolmogorov flow at a Reynolds number of 20,000 and flow past a cylinder at Reynolds number 500. Compared to competing methods, our method can handle non-uniform geometries using unstructured meshes seamlessly. In particular, niLES leads to trajectories with more accurate statistics and enhances stability, particularly for long-horizon rollouts. (Source codes and datasets will be made publicly available.)'}",https://openreview.net{'value': '/pdf/69da11cb23049a172f17415920eb0343a08fcc98.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=woptnU6fh1,{'value': 'BayesDAG: Gradient-Based Posterior Inference for Causal Discovery'},Yashas Annadani; Nick Pawlowski; Joel Jennings; Stefan Bauer; Cheng Zhang; Wenbo Gong,~Yashas_Annadani1; ~Nick_Pawlowski2; ~Joel_Jennings1; ~Stefan_Bauer1; ~Cheng_Zhang1; ~Wenbo_Gong1,"{'value': ['Causal Discovery', 'Structure Learning', 'Bayesian Inference', 'Variational Inference', 'MCMC', 'Generative Model']}","{'value': ""Bayesian causal discovery aims to infer the posterior distribution over causal models from observed data, quantifying epistemic uncertainty and benefiting downstream tasks. However, computational challenges arise due to joint inference over combinatorial space of Directed Acyclic Graphs (DAGs) and nonlinear functions. Despite recent progress towards efficient posterior inference over DAGs,  existing methods are either limited to variational inference on node permutation matrices for linear causal models, leading to compromised inference accuracy, or continuous relaxation of adjacency matrices constrained by a DAG regularizer, which cannot ensure resulting graphs are DAGs. In this work, we introduce a scalable Bayesian causal discovery framework based on a combination of stochastic gradient Markov Chain Monte Carlo (SG-MCMC) and Variational Inference (VI) that overcomes these limitations. Our approach directly samples DAGs from the posterior without requiring any DAG regularization, simultaneously draws function parameter samples and is applicable to both linear and nonlinear causal models. To enable our approach, we derive a novel equivalence to the permutation-based DAG learning, which opens up possibilities of using any relaxed gradient estimator defined over permutations. To our knowledge, this is the first framework applying gradient-based MCMC sampling for causal discovery. Empirical evaluation on synthetic and real-world datasets demonstrate our approach's effectiveness compared to state-of-the-art baselines.""}",https://openreview.net{'value': '/pdf/3cd1781d52c7de1b58f53c1920ab36057fb4e503.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=wYkfog48Bq,{'value': 'Optimal Block-wise Asymmetric Graph Construction for Graph-based Semi-supervised Learning'},Zixing Song; Yifei Zhang; Irwin King,~Zixing_Song2; ~Yifei_Zhang6; ~Irwin_King1,"{'value': ['Graph-based Semi-supervised Learning', 'Affinity Graph Construction']}","{'value': 'Graph-based semi-supervised learning (GSSL) serves as a powerful tool to model the underlying manifold structures of samples in high-dimensional spaces. It involves two phases: constructing an affinity graph from available data and inferring labels for unlabeled nodes on this graph. While numerous algorithms have been developed for label inference, the crucial graph construction phase has received comparatively less attention, despite its significant influence on the subsequent phase. In this paper, we present an optimal asymmetric graph structure for the label inference phase with theoretical motivations. Unlike existing graph construction methods, we differentiate the distinct roles that labeled nodes and unlabeled nodes could play. Accordingly, we design an efficient block-wise graph learning algorithm with a global convergence guarantee. Other benefits induced by our method, such as enhanced robustness to noisy node features, are explored as well. Finally, we perform extensive experiments on synthetic and real-world datasets to demonstrate its superiority to the state-of-the-art graph construction methods in GSSL.'}",https://openreview.net{'value': '/pdf/68b290e4978f0b826e52e8f1c37d8aa8d6f97955.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=w7TyuWhGZP,{'value': 'Interpretable Reward Redistribution in Reinforcement Learning: A Causal Approach'},Yudi Zhang; Yali Du; Biwei Huang; Ziyan Wang; Jun Wang; Meng Fang; Mykola Pechenizkiy,~Yudi_Zhang3; ~Yali_Du1; ~Biwei_Huang1; ~Ziyan_Wang3; ~Jun_Wang2; ~Meng_Fang1; ~Mykola_Pechenizkiy1,"{'value': ['Reinforcement learning', 'sparse reward', 'return decomposition', 'causal modeling']}","{'value': 'A major challenge in reinforcement learning is to determine which state-action pairs are responsible for future rewards that are delayed. Reward redistribution serves as a solution to re-assign credits for each time step from observed sequences.  While the majority of current approaches construct the reward redistribution in an uninterpretable manner, we propose to explicitly model the contributions of state and action from a causal perspective, resulting in an interpretable reward redistribution and preserving policy invariance. In this paper, we start by studying the role of causal generative models in reward redistribution by characterizing the generation of Markovian rewards and trajectory-wise long-term return and further propose a framework, called Generative Return Decomposition (GRD), for policy optimization in delayed reward scenarios. Specifically, GRD first identifies the unobservable Markovian rewards and causal relations in the generative process. Then,  GRD makes use of the identified causal generative model to form a compact representation to train policy over the most favorable subspace of the state space of the agent. Theoretically, we show that the unobservable Markovian reward function is identifiable, as well as the underlying causal structure and causal models. Experimental results show that our method outperforms state-of-the-art methods and the provided visualization further demonstrates the interpretability of our method.\nThe project page is located at [https://reedzyd.github.io/GenerativeReturnDecomposition/](https://reedzyd.github.io/GenerativeReturnDecomposition/).'}",https://openreview.net{'value': '/pdf/6c209e8323172cf852e3fe502289f8c46e646566.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=w6krZiUa7t,{'value': 'Hyper-HMM: aligning human brains and semantic features in a common latent event space'},Caroline Lee; Jane Han; Ma Feilong; Guo Jiahui; James Haxby; Christopher Baldassano,~Caroline_Lee1; ~Jane_Han1; ~Ma_Feilong1; ~Guo_Jiahui1; ~James_Haxby1; ~Christopher_Baldassano1,"{'value': ['Brain Imaging', 'Other Cognitive Science', 'Other Neuroscience']}","{'value': ""Naturalistic stimuli evoke complex neural responses with spatial and temporal properties that differ across individuals. Current alignment methods focus on either spatial hyperalignment (assuming exact temporal correspondence) or temporal alignment (assuming exact spatial correspondence). Here, we propose a hybrid model, the Hyper-HMM, that simultaneously aligns both temporal and spatial features across brains. The model learns to linearly project voxels to a reduced-dimension latent space, in which timecourses are segmented into corresponding temporal events. This approach allows tracking of each individual's mental trajectory through an event sequence, and also allows for alignment with other feature spaces such as stimulus content. Using an fMRI dataset in which students watch videos of class lectures, we demonstrate that the Hyper-HMM can be used to map all participants and the semantic content of the videos into a common low-dimensional space, and that these mappings generalize to held-out data. Our model provides a new window into individual cognitive dynamics evoked by complex naturalistic stimuli.""}",https://openreview.net{'value': '/pdf/e6321f673959af15e6b36e42bb0000eb9ac8c68e.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=w0H2xGHlkw,{'value': 'Visual Instruction Tuning'},Haotian Liu; Chunyuan Li; Qingyang Wu; Yong Jae Lee,~Haotian_Liu1; ~Chunyuan_Li1; ~Qingyang_Wu1; ~Yong_Jae_Lee2,"{'value': ['visual instruction tuning', 'instruction tuning', 'multimodal', 'LLM', 'GPT']}","{'value': 'Instruction tuning large language models (LLMs) using machine-generated instruction-following data has been shown to improve zero-shot capabilities on new tasks, but the idea is less explored in the multimodal field. We present the first attempt to use language-only GPT-4 to generate multimodal language-image instruction-following data. By instruction tuning on such generated data, we introduce LLaVA: Large Language and Vision Assistant, an end-to-end trained large multimodal model that connects a vision encoder and an LLM for general-purpose visual and language understanding. To facilitate future research on visual instruction following, we construct two evaluation benchmarks with diverse and challenging application-oriented tasks. Our experiments show that LLaVA demonstrates impressive multimodal chat abilities, sometimes exhibiting the behaviors of multimodal GPT-4 on unseen images/instructions, and yields a 85.1% relative score compared with GPT-4 on a synthetic multimodal instruction-following dataset. When fine-tuned on Science QA, the synergy of LLaVA and GPT-4 achieves a new state-of-the-art accuracy of 92.53%. We make GPT-4 generated visual instruction tuning data, our model, and code publicly available.'}",https://openreview.net{'value': '/pdf/8ec2de30800edb13f33bf46d3f735b91f7561ce0.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=vz7SdRqWGM,{'value': 'Adaptive whitening with fast gain modulation and slow synaptic plasticity'},Lyndon Duong; Eero P Simoncelli; Dmitri Chklovskii; David Lipshutz,~Lyndon_Duong1; ~Eero_P_Simoncelli1; ~Dmitri_Chklovskii1; ~David_Lipshutz1,"{'value': ['neuroscience', 'adaptation', 'whitening', 'efficient coding', 'recurrent neural network', 'gain modulation', 'synaptic plasticity', 'local learning rules']}","{'value': 'Neurons in early sensory areas rapidly adapt to changing sensory statistics, both by normalizing the variance of their individual responses and by reducing correlations between their responses. Together, these transformations may be viewed as an adaptive form of statistical whitening. Existing mechanistic models of adaptive whitening exclusively use either synaptic plasticity or gain modulation as the biological substrate for adaptation; however, on their own, each of these models has significant limitations. In this work, we unify these approaches in a normative multi-timescale mechanistic model that adaptively whitens its responses with complementary computational roles for synaptic plasticity and gain modulation. Gains are modified on a fast timescale to adapt to the current statistical context, whereas synapses are modified on a slow timescale to match structural properties of the input statistics that are invariant across contexts. Our model is derived from a novel multi-timescale whitening objective that factorizes the inverse whitening matrix into basis vectors, which correspond to synaptic weights, and a diagonal matrix, which corresponds to neuronal gains. We test our model on synthetic and natural datasets and find that the synapses learn optimal configurations over long timescales that enable adaptive whitening on short timescales using gain modulation.'}",https://openreview.net{'value': '/pdf/85642724098e98a3bc1c8babf1d25d5f0f183921.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=vF8ukt5l1R,{'value': 'Self-supervised video pretraining yields robust and more human-aligned visual representations'},Nikhil Parthasarathy; S. M. Ali Eslami; Joao Carreira; Olivier J Henaff,~Nikhil_Parthasarathy1; ~S._M._Ali_Eslami1; ~Joao_Carreira1; ~Olivier_J_Henaff1,"{'value': ['self-supervised learning', 'contrastive', 'video pretraining', 'representation learning', 'visual representation', 'human alignment', 'robustness', 'shape-bias', 'saliency']}","{'value': 'Humans learn powerful representations of objects and scenes by observing how they evolve over time. Yet, outside of specific tasks that require explicit temporal understanding, static image pretraining remains the dominant paradigm for learning visual foundation models. We question this mismatch, and ask whether video pretraining can yield visual representations that bear the hallmarks of human perception: generalisation across tasks, robustness to perturbations, and consistency with human judgements. To that end we propose a novel procedure for curating videos, and develop a contrastive framework which learns from the complex transformations therein. This simple paradigm for distilling knowledge from videos, called VITO, yields general representations that far outperform prior video pretraining methods on image understanding tasks, and image pretraining methods on video understanding tasks. Moreover, VITO representations are significantly more robust to natural and synthetic deformations than image-, video-, and adversarially-trained\nones. Finally, VITO’s predictions are strongly aligned with human judgements, surpassing models that were specifically trained for that purpose. Together, these results suggest that video pretraining could be a simple way of learning unified, robust, and human-aligned representations of the visual world.'}",https://openreview.net{'value': '/pdf/66f79edcd3bd67abef2ef5eef2d484718b293549.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=vBwSACOB3x,{'value': 'Neural Algorithmic Reasoning Without Intermediate Supervision'},Gleb Rodionov; Liudmila Prokhorenkova,~Gleb_Rodionov1; ~Liudmila_Prokhorenkova1,"{'value': ['neural algorithmic reasoning', 'graph neural networks', 'self-supervised regularization']}","{'value': 'Neural algorithmic reasoning is an emerging area of machine learning focusing on building models that can imitate the execution of classic algorithms, such as sorting, shortest paths, etc. One of the main challenges is to learn algorithms that are able to generalize to out-of-distribution data, in particular with significantly larger input sizes. Recent work on this problem has demonstrated the advantages of learning algorithms step-by-step, giving models access to all intermediate steps of the original algorithm. In this work, we instead focus on learning neural algorithmic reasoning only from the input-output pairs without appealing to the intermediate supervision. We propose simple but effective architectural improvements and also build a self-supervised objective that can regularise intermediate computations of the model without access to the algorithm trajectory. We demonstrate that our approach is competitive to its trajectory-supervised counterpart on tasks from the CLRS Algorithmic Reasoning Benchmark and achieves new state-of-the-art results for several problems, including sorting, where we obtain significant improvements. Thus, learning without intermediate supervision is a promising direction for further research on neural reasoners.'}",https://openreview.net{'value': '/pdf/e526b0c78faa746d9a6c1a540d873bd9a7a5b01b.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=uzOBDerK1j,{'value': 'Online robust non-stationary estimation'},Abishek Sankararaman; Murali Balakrishnan,~Abishek_Sankararaman1; ~Murali_Balakrishnan1,"{'value': ['Estimation', 'heavy-tails', 'distribution shifts', 'regret']}","{'value': 'The real-time estimation of time-varying parameters from high-dimensional, heavy-tailed and corrupted data-streams is a common sub-routine in systems ranging from those for network monitoring and anomaly detection to those for traffic scheduling in data-centers. For estimation tasks that can be cast as minimizing a strongly convex loss function, we prove that an appropriately tuned version of the {\\ttfamily clipped Stochastic Gradient Descent} (SGD) is simultaneously {\\em(i)} adaptive to drift, {\\em (ii)} robust to heavy-tailed inliers and arbitrary corruptions,  {\\em(iii)} requires no distributional knowledge and {\\em (iv)} can be implemented in an online streaming fashion. All prior estimation algorithms have only been proven to posses a subset of these practical desiderata. A observation we make is that, neither the $\\mathcal{O}\\left(\\frac{1}{t}\\right)$ learning rate for {\\ttfamily clipped SGD} known to be optimal for strongly convex loss functions of a \\emph{stationary} data-stream, nor the $\\mathcal{O}(1)$ learning rate known to be optimal for being adaptive to drift in a \\emph{noiseless} environment can be used. Instead, a learning rate of $T^{-\\alpha}$ for $ \\alpha < 1$ where $T$ is the stream-length is needed to balance adaptivity to potential drift and to combat noise. We develop a new inductive argument and combine it with a martingale concentration result to derive high-probability under \\emph{any learning rate} on data-streams exhibiting \\emph{arbitrary distribution shift} - a proof strategy that may be of independent interest. Further, using the classical doubling-trick, we relax the knowledge of the stream length $T$. Ours is the first online estimation algorithm that is provably robust to heavy-tails, corruptions and distribution shift simultaneously. We complement our theoretical results empirically on synthetic and real data.'}",https://openreview.net{'value': '/pdf/5d6d714ea5737396eb8c11665d05b531fcf140fb.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=uWNqy09dFW,{'value': 'Learning Neural Implicit through Volume Rendering with Attentive Depth Fusion Priors'},Pengchong Hu; Zhizhong Han,~Pengchong_Hu1; ~Zhizhong_Han2,"{'value': ['3D Reconstruction', 'SDF', 'Neural Rendering', 'Implicit Representations', 'SLAM']}","{'value': 'Learning neural implicit representations has achieved remarkable performance in 3D reconstruction from multi-view images. Current methods use volume rendering to render implicit representations into either RGB or depth images that are supervised by the multi-view ground truth. However, rendering a view each time suffers from incomplete depth at holes and unawareness of occluded structures from the depth supervision, which severely affects the accuracy of geometry inference via volume rendering. To resolve this issue, we propose to learn neural implicit representations from multi-view RGBD images through volume rendering with an attentive depth fusion prior. Our prior allows neural networks to sense coarse 3D structures from the Truncated Signed Distance Function (TSDF) fused from all available depth images for rendering. The TSDF enables accessing the missing depth at holes on one depth image and the occluded parts that are invisible from the current view. By introducing a novel attention mechanism, we allow neural networks to directly use the depth fusion prior with the inferred occupancy as the learned implicit function. Our attention mechanism works with either a one-time fused TSDF that represents a whole scene or an incrementally fused TSDF that represents a partial scene in the context of Simultaneous Localization and Mapping (SLAM). Our evaluations on widely used benchmarks including synthetic and real-world scans show our superiority over the latest neural implicit methods.'}",https://openreview.net{'value': '/pdf/d81ea5fecbc3e0850ff4e025b8c071d472ac829a.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=uDV4lA0gZ6,{'value': 'Efficient Robust Bayesian Optimization for Arbitrary Uncertain inputs'},Lin Yang; Junlong Lyu; Wenlong Lyu; Zhitang Chen,~Lin_Yang8; ~Junlong_Lyu1; ~Wenlong_Lyu1; ~Zhitang_Chen1,"{'value': ['bayesian optimization', 'robust optimization']}","{'value': 'Bayesian Optimization (BO) is a sample-efficient optimization algorithm widely employed across various applications. In some challenging BO tasks, input uncertainty arises due to the inevitable randomness in the optimization process, such as machining errors, execution noise, or contextual variability. This uncertainty deviates the input from the intended value before evaluation, resulting in significant performance fluctuations in the final result. In this paper, we introduce a novel robust Bayesian Optimization algorithm, AIRBO, which can effectively identify a robust optimum that performs consistently well under arbitrary input uncertainty. Our method directly models the uncertain inputs of arbitrary distributions by empowering the Gaussian Process with the Maximum Mean Discrepancy (MMD) and further accelerates the posterior inference via Nystrom approximation. Rigorous theoretical regret bound is established under MMD estimation error and extensive experiments on synthetic functions and real problems demonstrate that our approach can handle various input uncertainties and achieve a state-of-the-art performance.'}",https://openreview.net{'value': '/pdf/c5b971bbcbb881bfa4c4ff6c33ff8f7767396cb9.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=u359tNBpxF,{'value': 'Robust Data Valuation with Weighted Banzhaf Values'},Weida Li; Yaoliang Yu,~Weida_Li1; ~Yaoliang_Yu1,"{'value': ['data valuation', 'robustness', 'weighted Banzhaf values']}","{'value': 'Data valuation, a principled way to rank the importance of each training datum, has become increasingly important. However, existing value-based approaches (e.g., Shapley) are known to suffer from the stochasticity inherent in utility functions that render consistent and reliable ranking difficult. Recently, Wang and Jia (2023) proposed the noise-structure-agnostic framework to advocate the Banzhaf value for its robustness against such stochasticity as it achieves the largest safe margin among many alternatives. Surprisingly, our empirical study shows that the Banzhaf value is not always the most robust when compared with a broader family: weighted Banzhaf values. To analyze this scenario, we introduce the concept of Kronecker noise to parameterize stochasticity, through which we prove that the uniquely robust semi-value, which can be analytically derived from the underlying Kronecker noise, lies in the family of weighted Banzhaf values while minimizing the worst-case entropy. In addition, we adopt the maximum sample reuse principle to design an estimator to efficiently approximate weighted Banzhaf values, and show that it enjoys the best time complexity in terms of achieving an $(\\epsilon, \\delta)$-approximation. Our theory is verified under both synthetic and authentic noises. For the latter, we fit a Kronecker noise to the inherent stochasticity, which is then plugged in to generate the predicted most robust semi-value. Our study suggests that weighted Banzhaf values are promising when facing undue noises in data valuation.'}",https://openreview.net{'value': '/pdf/481906560fd0dda7e8e8194cfdd687999839f24c.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=toYvRJ7Zmy,{'value': 'Derandomized novelty detection with FDR control via conformal e-values'},Meshi Bashari; Amir Epstein; Yaniv Romano; Matteo Sesia,~Meshi_Bashari1; ~Amir_Epstein1; ~Yaniv_Romano1; ~Matteo_Sesia1,"{'value': ['Conformal inference', 'Derandomization', 'E-values', 'False discovery rate', 'Out-of-distribution testing', 'Testing for outliers', 'Uncertainty']}","{'value': 'Conformal inference provides a general distribution-free method to rigorously calibrate the output of any machine learning algorithm for novelty detection. While this approach has many strengths, it has the limitation of being randomized, in the sense that it may lead to different results when analyzing twice the same data and this can hinder the interpretation of any findings. We propose to make conformal inferences more stable by leveraging suitable conformal e-values instead of p-values to quantify statistical significance. This solution allows the evidence gathered from multiple analyses of the same data to be aggregated effectively while provably controlling the false discovery rate. Further, we show that the proposed method can reduce randomness without much loss of power compared to standard conformal inference, partly thanks to an innovative way of weighting conformal e-values based on additional side information carefully extracted from the same data. Simulations with synthetic and real data confirm this solution can be effective at eliminating random noise in the inferences obtained with state-of-the-art alternative techniques, sometimes also leading to higher power.'}",https://openreview.net{'value': '/pdf/1e0ee0fa16a5ae8cdd90cc99fdf8f43f2d8fd1cf.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=tn9Dldam9L,{'value': 'Add and Thin: Diffusion for Temporal Point Processes'},David Lüdke; Marin Biloš; Oleksandr Shchur; Marten Lienen; Stephan Günnemann,~David_Lüdke1; ~Marin_Biloš1; ~Oleksandr_Shchur1; ~Marten_Lienen1; ~Stephan_Günnemann1,"{'value': ['Point Processes', 'Diffusion', 'Temporal Data', 'Generative Model', 'Forecasting', 'Density Estimation', 'Denoising']}","{'value': 'Autoregressive neural networks within the temporal point process (TPP) framework have become the standard for modeling continuous-time event data. Even though these models can expressively capture event sequences in a one-step-ahead fashion, they are inherently limited for long-term forecasting applications due to the accumulation of errors caused by their sequential nature. To overcome these limitations, we derive ADD-THIN, a principled probabilistic denoising diffusion model for TPPs that operates on entire event sequences. Unlike existing diffusion approaches, ADD-THIN naturally handles data with discrete and continuous components. In experiments on synthetic and real-world datasets, our model matches the state-of-the-art TPP models in density estimation and strongly outperforms them in forecasting.'}",https://openreview.net{'value': '/pdf/1fb5a7149d8e19e0f23ce3c0e49b9030bfbad250.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=tScBQRNgjk,{'value': 'ForecastPFN: Synthetically-Trained Zero-Shot Forecasting'},Samuel Dooley; Gurnoor Singh Khurana; Chirag Mohapatra; Siddartha Venkat Naidu; Colin White,~Samuel_Dooley1; ~Gurnoor_Singh_Khurana1; ~Chirag_Mohapatra1; ~Siddartha_Venkat_Naidu1; ~Colin_White1,"{'value': ['Forecasting', 'Zero-shot', 'Synthetic Data']}","{'value': ""The vast majority of time-series forecasting approaches require a substantial training dataset. However, many real-life forecasting applications have very little initial observations, sometimes just 40 or fewer. Thus, the applicability of most forecasting methods is restricted in data-sparse commercial applications. While there is recent work in the setting of very limited initial data (so-called `zero-shot' forecasting), its performance is inconsistent depending on the data used for pretraining. In this work, we take a different approach and devise ForecastPFN, the first zero-shot forecasting model trained purely on a novel synthetic data distribution. ForecastPFN is a prior-data fitted network, trained to approximate Bayesian inference, which can make predictions on a new time series dataset in a single forward pass. Through extensive experiments, we show that zero-shot predictions made by ForecastPFN are more accurate and faster compared to state-of-the-art forecasting methods, even when the other methods are allowed to train on hundreds of additional in-distribution data points.""}",https://openreview.net{'value': '/pdf/534c657319322de54e410480ef13490a78fd58ff.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=tJ88RBqupo,{'value': 'Can You Rely on Your Model Evaluation? Improving Model Evaluation with Synthetic Test Data'},Boris van Breugel; Nabeel Seedat; Fergus Imrie; Mihaela van der Schaar,~Boris_van_Breugel2; ~Nabeel_Seedat1; ~Fergus_Imrie1; ~Mihaela_van_der_Schaar2,"{'value': ['model evaluation', 'tabular', 'synthetic data']}","{'value': ""Evaluating the performance of machine learning models on diverse and underrepresented subgroups is essential for ensuring fairness and reliability in real-world applications. However, accurately assessing model performance becomes challenging due to two main issues: (1) a scarcity of test data, especially for small subgroups, and (2) possible distributional shifts in the model's deployment setting, which may not align with the available test data.  In this work, we introduce 3S Testing, a deep generative modeling framework to facilitate model evaluation by generating synthetic test sets for small subgroups and simulating distributional shifts. Our experiments demonstrate that 3S-Testing outperforms traditional baselines---including real test data alone---in estimating model performance on minority subgroups and under plausible distributional shifts. In addition, 3S offers intervals around its performance estimates, exhibiting superior coverage of the ground truth compared to existing approaches.  Overall, these results raise the question of whether we need a paradigm shift away from limited real test data towards synthetic test data.""}",https://openreview.net{'value': '/pdf/a1f3a21731b39eec479905189efd8fe6fd98f4c3.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=tIzbNQko3c,{'value': 'Pre-Training Protein Encoder via Siamese Sequence-Structure Diffusion Trajectory Prediction'},Zuobai Zhang; Minghao Xu; Aurelie Lozano; Vijil Chenthamarakshan; Payel Das; Jian Tang,~Zuobai_Zhang1; ~Minghao_Xu1; ~Aurelie_Lozano1; ~Vijil_Chenthamarakshan1; ~Payel_Das1; ~Jian_Tang1,"{'value': ['Protein representation learning', 'diffusion models', 'self-supervised learning']}","{'value': 'Self-supervised pre-training methods on proteins have recently gained attention, with most approaches focusing on either protein sequences or structures, neglecting the exploration of their joint distribution, which is crucial for a comprehensive understanding of protein functions by integrating co-evolutionary information and structural characteristics. In this work, inspired by the success of denoising diffusion models in generative tasks, we propose the DiffPreT approach to pre-train a protein encoder by sequence-structure joint diffusion modeling. DiffPreT guides the encoder to recover the native protein sequences and structures from the perturbed ones along the joint diffusion trajectory, which acquires the joint distribution of sequences and structures. Considering the essential protein conformational variations, we enhance DiffPreT by a method called Siamese Diffusion Trajectory Prediction (SiamDiff) to capture the correlation between different conformers of a protein. SiamDiff attains this goal by maximizing the mutual information between representations of diffusion trajectories of structurally-correlated conformers. We study the effectiveness of DiffPreT and SiamDiff on both atom- and residue-level structure-based protein understanding tasks. Experimental results show that the performance of DiffPreT is consistently competitive on all tasks, and SiamDiff achieves new state-of-the-art performance, considering the mean ranks on all tasks. Code will be released upon acceptance.'}",https://openreview.net{'value': '/pdf/54557a567d51315f120e9d9917a0d6e3323d44f3.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=tFsxtqGmkn,{'value': 'Maximum State Entropy Exploration using Predecessor and Successor Representations'},Arnav Kumar Jain; Lucas Lehnert; Irina Rish; Glen Berseth,~Arnav_Kumar_Jain2; ~Lucas_Lehnert1; ~Irina_Rish1; ~Glen_Berseth1,"{'value': ['Reinforcement Learning', 'Maximum state entropy exploration', 'Non-Markovian exploration', 'Successor Representation']}","{'value': 'Animals have a developed ability to explore that aids them in important tasks such as locating food, exploring for shelter, and finding misplaced items. These exploration skills necessarily track where they have been so that they can plan for finding items with relative efficiency. Contemporary exploration algorithms often learn a less efficient exploration strategy because they either condition only on the current state or simply rely on making random open-loop exploratory moves. In this work, we propose $\\eta\\psi$-Learning, a method to learn efficient exploratory policies by conditioning on past episodic experience to make the next exploratory move. Specifically, $\\eta\\psi$-Learning learns an exploration policy that maximizes the entropy of the state visitation distribution of a single trajectory. Furthermore, we demonstrate how variants of the predecessor representation and successor representations can be combined to predict the state visitation entropy. Our experiments demonstrate the efficacy of $\\eta\\psi$-Learning to strategically explore the environment and maximize the state coverage with limited samples.'}",https://openreview.net{'value': '/pdf/3172fc912022252a8a8905601f7fe7ef461c9367.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=tAwjG5bM7H,{'value': 'A Bounded Ability Estimation for Computerized Adaptive Testing'},Yan Zhuang; Qi Liu; GuanHao Zhao; Zhenya Huang; Weizhe Huang; Zachary Pardos; Enhong Chen; Jinze Wu; Xin Li,~Yan_Zhuang4; ~Qi_Liu3; ~GuanHao_Zhao1; ~Zhenya_Huang2; ~Weizhe_Huang1; ~Zachary_Pardos1; ~Enhong_Chen1; ~Jinze_Wu1; ~Xin_Li56,"{'value': ['adaptive learning', 'computerized adaptive testing', 'educational measurement', 'cognitive diagnosis']}","{'value': ""Computerized adaptive testing (CAT), as a tool that can efficiently measure student's ability, has been widely used in various standardized tests (e.g., GMAT and GRE). The adaptivity of CAT refers to the selection of the most informative questions for each student, reducing test length. Existing CAT methods do not explicitly target ability estimation accuracy since there is no student's true ability as ground truth; therefore, these methods cannot be guaranteed to make the estimate converge to the true with such limited responses. In this paper, we analyze the statistical properties of estimation and find a theoretical approximation of the true ability: the ability estimated by full responses to question bank. Based on this, a Bounded Ability Estimation framework for CAT (BECAT) is proposed in a data-summary manner, which selects a question subset that closely matches the gradient of the full responses. Thus, we develop an expected gradient difference approximation to design a simple greedy selection algorithm, and show the rigorous theoretical and error upper-bound guarantees of its ability estimate. Experiments on both real-world and synthetic datasets, show that it can reach the same estimation accuracy using 15\\% less questions on average, significantly reducing test length.""}",https://openreview.net{'value': '/pdf/311c02f9f559ebad3c4ae60372169d3a28e8e559.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=t1jLRFvBqm,{'value': 'Object-Centric Learning for Real-World Videos by Predicting Temporal Feature Similarities'},Andrii Zadaianchuk; Maximilian Seitzer; Georg Martius,~Andrii_Zadaianchuk1; ~Maximilian_Seitzer1; ~Georg_Martius1,"{'value': ['object-centric learning', 'video', 'representation learning', 'self-supervised learning', 'unsupervised learning']}","{'value': 'Unsupervised video-based object-centric learning is a promising avenue to learn structured representations from large, unlabeled video collections, but previous approaches have only managed to scale to real-world datasets in restricted domains.\nRecently, it was shown that the reconstruction of pre-trained self-supervised features leads to object-centric representations on unconstrained real-world image datasets.\nBuilding on this approach, we propose a novel way to use such pre-trained features in the form of a temporal feature similarity loss.\nThis loss encodes semantic and temporal correlations between image patches and is a natural way to introduce a motion bias for object discovery.\nWe demonstrate that this loss leads to state-of-the-art performance on the challenging synthetic MOVi datasets.\nWhen used in combination with the feature reconstruction loss, our model is the first object-centric video model that scales to unconstrained video datasets such as YouTube-VIS.\n\nhttps://martius-lab.github.io/videosaur/'}",https://openreview.net{'value': '/pdf/293b5909189a279000e544e32355b67975ef1cda.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=sTjW3JHs2V,{'value': 'Let the Flows Tell:  Solving Graph Combinatorial Problems with GFlowNets'},Dinghuai Zhang; Hanjun Dai; Nikolay Malkin; Aaron Courville; Yoshua Bengio; Ling Pan,~Dinghuai_Zhang1; ~Hanjun_Dai1; ~Nikolay_Malkin1; ~Aaron_Courville3; ~Yoshua_Bengio1; ~Ling_Pan1,{'value': ['graph; combinatorial optimization; sampling; gflownets']},"{'value': 'Combinatorial optimization (CO) problems are often NP-hard and thus out of reach for exact algorithms, making them a tempting domain to apply machine learning methods. The highly structured constraints in these problems can hinder either optimization or sampling directly in the solution space.\nOn the other hand, GFlowNets have recently emerged as a powerful machinery to efficiently sample from composite unnormalized densities sequentially and have the potential to amortize such solution-searching processes in CO, as well as generate diverse solution candidates.\nIn this paper, we design Markov decision processes (MDPs) for different combinatorial problems and propose to train conditional GFlowNets to sample from the solution space. \nEfficient training techniques are also developed to benefit long-range credit assignment.\nThrough extensive experiments on a variety of different CO tasks with synthetic and realistic data, we demonstrate that GFlowNet policies can efficiently find high-quality solutions.\nOur implementation is open-sourced at https://github.com/zdhNarsil/GFlowNet-CombOpt.'}",https://openreview.net{'value': '/pdf/268b2b29e54f46504e1343a3b04df2e15f8414a2.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=rHAX0LRwk8,{'value': 'Adversarial Counterfactual Environment Model Learning'},Xiong-Hui Chen; Yang Yu; Zhengmao Zhu; ZhiHua Yu; Chen Zhenjun; Chenghe Wang; Yinan Wu; Rong-Jun Qin; Hongqiu Wu; Ruijin Ding; Huang Fangsheng,~Xiong-Hui_Chen1; ~Yang_Yu5; ~Zhengmao_Zhu1; ~ZhiHua_Yu2; ~Chen_Zhenjun1; ~Chenghe_Wang1; ~Yinan_Wu2; ~Rong-Jun_Qin1; ~Hongqiu_Wu2; ~Ruijin_Ding1; ~Huang_Fangsheng1,"{'value': ['environment model learning', 'offline reinforcement learning', 'off-policy evaluation', 'individual treatment effects estimation', 'causal inference', 'adversarial learning']}","{'value': ""An accurate environment dynamics model is crucial for various downstream tasks in sequential decision-making, such as counterfactual prediction, off-policy evaluation, and offline reinforcement learning. \nCurrently, these models were learned through empirical risk minimization (ERM) by step-wise fitting of historical transition data. This way was previously believed unreliable over long-horizon rollouts because of the compounding errors, which can lead to uncontrollable inaccuracies in predictions. In this paper, we find that the challenge extends beyond just long-term prediction errors: we reveal that even when planning with one step, learned dynamics models can also perform poorly due to the selection bias of behavior policies during data collection. \nThis issue will significantly mislead the policy optimization process even in identifying single-step optimal actions, further leading to a greater risk in sequential decision-making scenarios.\nTo tackle this problem, we introduce a novel model-learning objective called adversarial weighted empirical risk minimization (AWRM).  AWRM incorporates an adversarial policy that exploits the model to generate a data distribution that weakens the model's prediction accuracy, and subsequently, the model is learned under this adversarial data distribution.\nWe implement a practical algorithm, GALILEO, for AWRM and evaluate it on two synthetic tasks, three continuous-control tasks, and  \\textit{a real-world application}. The experiments demonstrate that GALILEO can accurately predict counterfactual actions and improve various downstream tasks, including offline policy evaluation and improvement, as well as online decision-making.""}",https://openreview.net{'value': '/pdf/f77d9d22df193b793596c178654a3e547dda23a5.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=r8LYNleLf9,{'value': 'TexQ: Zero-shot Network Quantization with Texture Feature Distribution Calibration'},Xinrui Chen; Yizhi Wang; Renao Yan; Yiqing Liu; Tian Guan; Yonghong He,~Xinrui_Chen1; ~Yizhi_Wang3; ~Renao_Yan1; ~Yiqing_Liu1; ~Tian_Guan1; ~Yonghong_He1,"{'value': ['Zero-shot quantization', 'Texture feature calibration', 'Post-training quantization', 'low bit width', 'Neural network compression']}","{'value': 'Quantization is an effective way to compress neural networks. By reducing the bit width of the parameters, the processing efficiency of neural network models at edge devices can be notably improved. Most conventional quantization methods utilize real datasets to optimize quantization parameters and fine-tune. Due to the inevitable privacy and security issues of real samples, the existing real-data-driven methods are no longer applicable. Thus, a natural method is to introduce synthetic samples for zero-shot quantization (ZSQ). However, the conventional synthetic samples fail to retain the detailed texture feature distributions, which severely limits the knowledge transfer and performance of the quantized model. In this paper, a novel ZSQ method, TexQ is proposed to address this issue. We first synthesize a calibration image and extract its calibration center for each class with a texture feature energy distribution calibration method. Then, the calibration centers are used to guide the generator to synthesize samples. Finally, we introduce the mixup knowledge distillation module to diversify synthetic samples for fine-tuning. Extensive experiments on CIFAR10/100 and ImageNet show that TexQ is observed to perform state-of-the-art in ultra-low bit width quantization. For example, when ResNet-18 is quantized to 3-bit, TexQ achieves a 12.18% top-1 accuracy increase on ImageNet compared to state-of-the-art methods. Code at https://github.com/dangsingrue/TexQ.'}",https://openreview.net{'value': '/pdf/036e1e59e632aecf014bd56a4e35796ee2be8cdd.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=r7g9nFsulw,{'value': 'Learning Adaptive Tensorial Density Fields for Clean Cryo-ET Reconstruction'},YUANHAO WANG; Ramzi Idoughi; Wolfgang Heidrich,~YUANHAO_WANG2; ~Ramzi_Idoughi1; ~Wolfgang_Heidrich3,"{'value': ['Neural density fields', 'Coordinate-based representations', 'Quadtree structure', 'Cryo-electron microscope']}","{'value': 'We present a novel learning-based framework for reconstructing 3D structures from tilt-series cryo-Electron Tomography (cryo-ET) data. Cryo-ET is a powerful imaging technique that can achieve near-atomic resolutions. Still, it suffers from challenges such as missing-wedge acquisition, large data size, and high noise levels. Our framework addresses these challenges by using an adaptive tensorial-based representation for the 3D density field of the scanned sample. First, we optimize a quadtree structure to partition the volume of interest. Then, we learn a vector-matrix factorization of the tensor representing the density field in each node. Moreover, we use a loss function that combines a differentiable tomographic formation model with three regularization terms: total variation, boundary consistency constraint, and an isotropic Fourier prior. Our framework allows us to query the density at any location using the learned representation and obtain a high-quality 3D tomogram. We demonstrate the superiority of our framework over existing methods using synthetic and real data. Thus, our framework boosts the quality of the reconstruction while reducing the computation time and the memory footprint. The code is available at https://github.com/yuanhaowang1213/adaptivetensordf.'}",https://openreview.net{'value': '/pdf/6765371f8a791dea71f3a874cac8acd0751c068e.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=qyEm4tF2p1,{'value': 'Landscape Surrogate: Learning Decision Losses for Mathematical Optimization Under Partial Information'},Arman Zharmagambetov; Brandon Amos; Aaron M Ferber; Taoan Huang; Bistra Dilkina; Yuandong Tian,~Arman_Zharmagambetov1; ~Brandon_Amos1; ~Aaron_M_Ferber1; ~Taoan_Huang2; ~Bistra_Dilkina2; ~Yuandong_Tian1,"{'value': ['learning surrogates', 'predict+optimize framework', 'combinatorial nonlinear optimization', 'argmin differentiation']}","{'value': 'Recent works in learning-integrated optimization have shown promise in settings where the optimization problem is only partially observed or where general-purpose optimizers perform poorly without expert tuning. By learning an optimizer $\\mathbf{g}$ to tackle these challenging problems with $f$ as the objective, the optimization process can be substantially accelerated by leveraging past experience. The optimizer can be trained with supervision from known optimal solutions or implicitly by optimizing the compound function $f\\circ \\mathbf{g}$. The implicit approach may not require optimal solutions as labels and is capable of handling problem uncertainty; however, it is slow to train and deploy due to frequent calls to optimizer $\\mathbf{g}$ during both training and testing. The training is further challenged by sparse gradients of $\\mathbf{g}$, especially for combinatorial solvers. To address these challenges, we propose using a smooth and learnable **Landscape Surrogate** $\\mathcal{M}$ as a replacement for $f\\circ \\mathbf{g}$. This surrogate, learnable by neural networks, can be computed faster than the solver $\\mathbf{g}$, provides dense and smooth gradients during training, can generalize to unseen optimization problems, and is efficiently learned via alternating optimization. We test our approach on both synthetic problems, including shortest path and multidimensional knapsack, and real-world problems such as portfolio optimization, achieving comparable or superior objective values compared to state-of-the-art baselines while reducing the number of calls to $\\mathbf{g}$. Notably, our approach outperforms existing methods for computationally expensive high-dimensional problems.'}",https://openreview.net{'value': '/pdf/bed8780ecc4e671fe5bdfe07c58a5f13567d9396.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=qs4swxtIAQ,{'value': 'TabMT: Generating tabular data with masked transformers'},Manbir S Gulati; Paul F Roysdon,~Manbir_S_Gulati1; roysdonp@leidos.com,"{'value': ['Tabular Data', 'Deep Learning', 'Generative Modeling', 'Transformers', 'Masked Transformers', 'Synthetic data']}","{'value': 'Autoregressive and Masked Transformers are incredibly effective as generative models and classifiers.\n    While these models are most prevalent in NLP, they also exhibit strong performance in other domains, such as vision. \n    This work contributes to the exploration of transformer-based models in synthetic data generation for diverse application domains. \n    In this paper, we present TabMT, a novel Masked Transformer design for generating synthetic tabular data. \n    TabMT effectively addresses the unique challenges posed by heterogeneous data fields and is natively able to handle missing data. \n    Our design leverages improved masking techniques to allow for generation and demonstrates state-of-the-art performance from extremely small to extremely large tabular datasets. \n    We evaluate TabMT for privacy-focused applications and find that it is able to generate high quality data with superior privacy tradeoffs.'}",https://openreview.net{'value': '/pdf/a55d0a40ef3808d267e8a0966329c33240f910c7.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=qlnlamFQEa,{'value': 'Aligning Synthetic Medical Images with Clinical Knowledge using Human Feedback'},Shenghuan Sun; Gregory Goldgof; Atul Butte; Ahmed Alaa,shenghuan.sun@ucsf.edu; goldgofg@mskcc.org; atul.butte@ucsf.edu; ~Ahmed_Alaa1,"{'value': ['Synthetic clinical data', 'Machine learning for healthcare']}","{'value': 'Generative models capable of precisely capturing nuanced clinical features in medical images hold great promise for facilitating clinical data sharing, enhancing rare disease datasets, and efficiently synthesizing (annotated) medical images at scale. Despite their potential, assessing the quality of synthetic medical images remains a challenge. While modern generative models can synthesize visually-realistic medical images, the clinical plausibility of these images may be called into question. Domain-agnostic scores, such as FID score, precision, and recall, cannot incorporate clinical knowledge and are, therefore, not suitable for assessing clinical sensibility. Additionally, there are numerous unpredictable ways in which generative models may fail to synthesize clinically plausible images, making it challenging to anticipate potential failures and design automated scores for their detection. To address these challenges, this paper introduces a pathologist-in-the-loop framework for generating clinically-plausible synthetic medical images. Our framework comprises three steps: (1) pretraining a conditional diffusion model to generate medical images conditioned on a clinical concept, (2) expert pathologist evaluation of the generated images to assess whether they satisfy clinical desiderata, and (3) training a reward model that predicts human feedback on new samples, which we use to incorporate expert knowledge into the finetuning objective of the diffusion model. Our results show that human feedback significantly improves the quality of synthetic images in terms of fidelity, diversity, utility in downstream applications, and plausibility as evaluated by experts. We also demonstrate that human feedback can teach the model new clinical concepts not annotated in the original training data. Our results demonstrate the value of incorporating human feedback in clinical applications where generative models may struggle to capture extensive domain knowledge from raw data alone.'}",https://openreview.net{'value': '/pdf/e7974dfbf220744484b1fe53cde36c23670ffab5.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=qlJoo2y3gY,{'value': 'Bayesian nonparametric (non-)renewal processes for analyzing neural spike train variability'},David Liu; Máté Lengyel,~David_Liu4; ~Máté_Lengyel1,"{'value': ['Gaussian processes', 'renewal processes', 'point processes', 'neural data analysis', 'Bayesian machine learning', 'non-stationary time series']}","{'value': 'Neural spiking activity is generally variable, non-stationary, and exhibits complex dependencies on covariates, such as sensory input or behavior. These dependencies have been proposed to be signatures of specific computations, and so characterizing them with quantitative rigor is critical for understanding neural computations. Approaches based on point processes provide a principled statistical framework for modeling neural spiking activity. However, currently, they only allow the instantaneous mean, but not the instantaneous variability, of responses to depend on covariates. To resolve this limitation, we propose a scalable Bayesian approach generalizing modulated renewal processes using sparse variational Gaussian processes. We leverage pathwise conditioning for computing nonparametric priors over conditional interspike interval distributions and rely on automatic relevance determination to detect lagging interspike interval dependencies beyond renewal order.  After systematically validating our method on synthetic data, we apply it to two foundational datasets of animal navigation: head direction cells in freely moving mice and hippocampal place cells in rats running along a linear track. Our model exhibits competitive or better predictive power compared to state-of-the-art baselines, and outperforms them in terms of capturing interspike interval statistics. These results confirm the importance of modeling covariate-dependent spiking variability, and further analyses of our fitted models reveal rich patterns of variability modulation beyond the temporal resolution of flexible count-based approaches.'}",https://openreview.net{'value': '/pdf/5a41add1dc84c44b53b1efcd69b2d3073fe687b5.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=qjqJL2lfkH,{'value': 'Rank-1 Matrix Completion with Gradient Descent and Small Random Initialization'},Daesung Kim; Hye Won Chung,~Daesung_Kim1; ~Hye_Won_Chung2,"{'value': ['Matrix completion', 'gradient descent', 'random initialization']}","{'value': 'The nonconvex formulation of the matrix completion problem has received significant attention in recent years due to its affordable complexity compared to the convex formulation. Gradient Descent (GD) is a simple yet efficient baseline algorithm for solving nonconvex optimization problems. The success of GD has been witnessed in many different problems in both theory and practice when it is combined with random initialization. However, previous works on matrix completion require either careful initialization or regularizers to prove the convergence of GD. In this paper, we study the rank-1 symmetric matrix completion and prove that GD converges to the ground truth when small random initialization is used. We show that in a logarithmic number of iterations, the trajectory enters the region where local convergence occurs. We provide an upper bound on the initialization size that is sufficient to guarantee the convergence, and show that a larger initialization can be used as more samples are available. We observe that the implicit regularization effect of GD plays a critical role in the analysis, and for the entire trajectory, it prevents each entry from becoming much larger than the others.'}",https://openreview.net{'value': '/pdf/be285b3201b5e280111bd80dad55ab46381027fa.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=qUlpDjYnsp,{'value': 'Multi-resolution Spectral Coherence for Graph Generation with Score-based Diffusion'},Hyuna Cho; Minjae Jeong; Sooyeon Jeon; Sungsoo Ahn; Won Hwa Kim,~Hyuna_Cho1; ~Minjae_Jeong1; ~Sooyeon_Jeon1; ~Sungsoo_Ahn1; ~Won_Hwa_Kim4,"{'value': ['graph wavelet transform', 'multi-scale wavelet filtering', 'graph generation', 'diffusion model']}","{'value': 'Successful graph generation depends on the accurate estimation of the joint distribution of graph components such as nodes and edges from training data. While recent deep neural networks have demonstrated sampling of realistic graphs together with diffusion models, however, they still suffer from oversmoothing problems which are inherited from conventional graph convolution and thus high-frequency characteristics of nodes and edges become intractable. To overcome such issues and generate graphs with high fidelity, this paper introduces a novel approach that captures the dependency between nodes and edges at multiple resolutions in the spectral space. By modeling the joint distribution of node and edge signals in a shared graph wavelet space, together with a score-based diffusion model, we propose a Wavelet Graph Diffusion Model (Wave-GD) which lets us sample synthetic graphs with real-like frequency characteristics of nodes and edges. Experimental results on four representative benchmark datasets validate the superiority of the Wave-GD over existing approaches, highlighting its potential for a wide range of applications that involve graph data.'}",https://openreview.net{'value': '/pdf/8c6e44d0acfacdbd03afb56f564961666b356d98.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=q6X038vKgU,"{'value': 'Predict, Refine, Synthesize: Self-Guiding Diffusion Models for Probabilistic Time Series Forecasting'}",Marcel Kollovieh; Abdul Fatir Ansari; Michael Bohlke-Schneider; Jasper Zschiegner; Hao Wang; Bernie Wang,~Marcel_Kollovieh1; ~Abdul_Fatir_Ansari2; ~Michael_Bohlke-Schneider1; ~Jasper_Zschiegner1; ~Hao_Wang3; ~Bernie_Wang1,"{'value': ['diffusion models', 'time series forecasting', 'generative modeling', 'deep learning']}","{'value': 'Diffusion models have achieved state-of-the-art performance in generative modeling tasks across various domains. Prior works on time series diffusion models have primarily focused on developing conditional models tailored to specific forecasting or imputation tasks. In this work, we explore the potential of task-agnostic, unconditional diffusion models for several time series applications. We propose TSDiff, an unconditionally-trained diffusion model for time series. Our proposed self-guidance mechanism enables conditioning TSDiff for downstream tasks during inference, without requiring auxiliary networks or altering the training procedure. We demonstrate the effectiveness of our method on three different time series tasks: forecasting, refinement, and synthetic data generation. First, we show that TSDiff is competitive with several task-specific conditional forecasting methods (*predict*). Second, we leverage the learned implicit probability density of TSDiff to iteratively refine the predictions of base forecasters with reduced computational overhead over reverse diffusion (*refine*). Notably, the generative performance of the model remains intact — downstream forecasters trained on synthetic samples from TSDiff outperform forecasters that are trained on samples from other state-of-the-art generative time series models, occasionally even outperforming models trained on real data (*synthesize*).\n\nOur code is available at https://github.com/amazon-science/unconditional-time-series-diffusion'}",https://openreview.net{'value': '/pdf/e4d1c7d53193eff9e355829afaa15e5f527b7da7.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=q4HlFS7B7Y,{'value': 'Discriminative Feature Attributions: Bridging Post Hoc Explainability and Inherent Interpretability'},Usha Bhalla; Suraj Srinivas; Himabindu Lakkaraju,~Usha_Bhalla1; ~Suraj_Srinivas1; ~Himabindu_Lakkaraju1,"{'value': ['Machine Learning Explainability', 'Machine Learning Interpretability']}","{'value': 'With the increased deployment of machine learning models in various real-world applications, researchers and practitioners alike have emphasized the need for explanations of model behaviour. To this end, two broad strategies have been outlined in prior literature to explain models. Post hoc explanation methods explain the behaviour of complex black-box models by identifying features critical to model predictions; however, prior work has shown that these explanations may not be faithful, in that they incorrectly attribute high importance to features that are unimportant or non-discriminative for the underlying task. Inherently interpretable models, on the other hand, circumvent these issues by explicitly encoding explanations into model architecture, meaning their explanations are naturally faithful, but they often exhibit poor predictive performance due to their limited expressive power. In this work, we identify a key reason for the lack of faithfulness of feature attributions: the lack of robustness of the underlying black-box models, especially the erasure of unimportant distractor features in the input. To address this issue, we propose Distractor Erasure Tuning (DiET), a method that adapts black-box models to be robust to distractor erasure, thus providing discriminative and faithful attributions. This strategy naturally combines the ease-of-use of post hoc explanations with the faithfulness of inherently interpretable models. We perform extensive experiments on semi-synthetic and real-world datasets, and show that DiET produces models that (1) closely approximate the original black-box models they are intended to explain, and (2) yield explanations that match approximate ground truths available by construction.'}",https://openreview.net{'value': '/pdf/521a549c806b29acdbc617c9d629b9cc7676306c.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=prftZp6mDH,{'value': 'Label Poisoning is All You Need'},Rishi Dev Jha; Jonathan Hayase; Sewoong Oh,~Rishi_Dev_Jha1; ~Jonathan_Hayase2; ~Sewoong_Oh1,"{'value': ['security', 'backdoor attack']}","{'value': ""In a backdoor attack, an adversary injects corrupted data into a model's training dataset in order to gain control over its predictions on images with a specific attacker-defined trigger. A typical corrupted training example requires altering both the image, by applying the trigger, and the label. Models trained on clean images, therefore, were considered safe from backdoor attacks. However, in some common machine learning scenarios, the training labels are provided by potentially malicious third-parties. This includes crowd-sourced annotation and knowledge distillation. We, hence, investigate a fundamental question: can we launch a successful backdoor attack by only corrupting labels? We introduce a novel approach to design label-only backdoor attacks, which we call FLIP, and demonstrate its strengths on three datasets (CIFAR-10, CIFAR-100, and Tiny-ImageNet) and four architectures (ResNet-32, ResNet-18, VGG-19, and Vision Transformer). With only 2% of CIFAR-10 labels corrupted, FLIP achieves a near-perfect attack success rate of 99.4% while suffering only a 1.8% drop in the clean test accuracy. Our approach builds upon the recent advances in trajectory matching, originally introduced for dataset distillation.""}",https://openreview.net{'value': '/pdf/e486e936273b3586994916184871eeed90309180.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=pb1OwZNgr2,{'value': 'Learning Generalizable Agents via Saliency-guided Features Decorrelation'},Sili Huang; Yanchao Sun; Jifeng Hu; Siyuan Guo; Hechang Chen; Yi Chang; Lichao Sun; Bo Yang,~Sili_Huang1; ~Yanchao_Sun1; ~Jifeng_Hu1; ~Siyuan_Guo2; ~Hechang_Chen2; ~Yi_Chang4; ~Lichao_Sun1; ~Bo_Yang6,"{'value': ['reinforcement learning', 'generalization']}","{'value': 'In visual-based Reinforcement Learning (RL), agents often struggle to generalize well to environmental variations in the state space that were not observed during training. The variations can arise in both task-irrelevant features, such as background noise, and task-relevant features, such as robot configurations, that are related to the optimal decisions. To achieve generalization in both situations, agents are required to accurately understand the impact of changed features on the decisions, i.e., establishing the true associations between changed features and decisions in the policy model. However, due to the inherent correlations among features in the state space, the associations between features and decisions become entangled, making it difficult for the policy to distinguish them. To this end, we propose Saliency-Guided Features Decorrelation (SGFD) to eliminate these correlations through sample reweighting. Concretely, SGFD consists of two core techniques: Random Fourier Functions (RFF) and the saliency map. RFF is utilized to estimate the complex non-linear correlations in high-dimensional images, while the saliency map is designed to identify the changed features. Under the guidance of the saliency map, SGFD employs sample reweighting to minimize the estimated correlations related to changed features, thereby achieving decorrelation in visual RL tasks. Our experimental results demonstrate that SGFD can generalize well on a wide range of test environments and significantly outperforms state-of-the-art methods in handling both task-irrelevant variations and task-relevant variations.'}",https://openreview.net{'value': '/pdf/59d46abd0dcdde36b337831f9b2eae764f27406b.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=pQF9kbM8Ea,{'value': 'Leveraging Vision-Centric Multi-Modal Expertise for 3D Object Detection'},Linyan Huang; Zhiqi Li; Chonghao Sima; Wenhai Wang; Jingdong Wang; Yu Qiao; Hongyang Li,~Linyan_Huang3; ~Zhiqi_Li2; ~Chonghao_Sima1; ~Wenhai_Wang2; ~Jingdong_Wang1; ~Yu_Qiao1; ~Hongyang_Li1,"{'value': ['camera-only detection', 'multi-modal distillation', 'multi-view object detection']}","{'value': 'Current research is primarily dedicated to advancing the accuracy of camera-only 3D object detectors (apprentice) through the knowledge transferred from LiDAR- or multi-modal-based counterparts (expert). However, the presence of the domain gap between LiDAR and camera features, coupled with the inherent incompatibility in temporal fusion, significantly hinders the effectiveness of distillation-based enhancements for apprentices. Motivated by the success of uni-modal distillation, an apprentice-friendly expert model would predominantly rely on camera features, while still achieving comparable performance to multi-modal models. To this end, we introduce VCD, a framework to improve the camera-only apprentice model, including an apprentice-friendly multi-modal expert and temporal-fusion-friendly distillation supervision. The multi-modal expert VCD-E adopts an identical structure as that of the camera-only apprentice in order to alleviate the feature disparity, and leverages LiDAR input as a depth prior to reconstruct the 3D scene, achieving the performance on par with other heterogeneous multi-modal experts. Additionally, a fine-grained trajectory-based distillation module is introduced with the purpose of individually rectifying the motion misalignment for each object in the scene. With those improvements, our camera-only apprentice VCD-A sets new state-of-the-art on nuScenes with a score of 63.1% NDS. The code will be released at https://github.com/OpenDriveLab/Birds-eye-view-Perception.'}",https://openreview.net{'value': '/pdf/334ffc2b2cf94c25a30e705eea24c9872128c6ac.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=pLsPFxqn7J,{'value': 'Kernelized Cumulants: Beyond Kernel Mean Embeddings'},Patric Bonnier; Harald Oberhauser; Zoltán Szabó,~Patric_Bonnier1; ~Harald_Oberhauser1; ~Zoltán_Szabó1,"{'value': ['kernel', 'cumulant', 'mean embedding', 'Hilbert-Schmidt independence criterion', 'maximum mean discrepancy']}","{'value': 'In $\\mathbb{R}^d$, it is well-known that cumulants provide an alternative to moments that can achieve the same goals with numerous benefits such as lower variance estimators. In this paper we extend cumulants to reproducing kernel Hilbert spaces (RKHS) using tools from tensor algebras and show that they are computationally tractable by a kernel trick. These kernelized cumulants provide a new set of all-purpose statistics; the classical maximum mean discrepancy and Hilbert-Schmidt independence criterion arise as the degree one objects in our general construction. We argue both theoretically and empirically (on synthetic, environmental, and traffic data analysis) that going beyond degree one has several advantages and can be achieved with the same computational complexity and minimal overhead in our experiments.'}",https://openreview.net{'value': '/pdf/59b9cbc263627bbb6ad6de91c9f8384e65e0f202.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=p9k5MS0JAL,{'value': 'Demystifying the Optimal Performance of Multi-Class Classification'},Minoh Jeong; Martina Cardone; Alex Dytso,~Minoh_Jeong1; ~Martina_Cardone1; ~Alex_Dytso1,"{'value': ['Bayes error', 'estimation', 'classification', 'minimum error probability']}","{'value': 'Classification is a fundamental task in science and engineering on which machine learning methods have shown outstanding performances. However, it is challenging to determine whether such methods have achieved the Bayes error rate, that is, the lowest error rate attained by any classifier. This is mainly due to the fact that the Bayes error rate is not known in general and hence, effectively estimating it is paramount. Inspired by the work by Ishida et al. (2023), we propose an estimator for the Bayes error rate of supervised multi-class classification problems. We analyze several theoretical aspects of such estimator, including its consistency, unbiasedness, convergence rate, variance, and robustness. We also propose a denoising method that reduces the noise that potentially corrupts the data labels, and we improve the robustness of the proposed estimator to outliers by incorporating the median-of-means estimator. Our analysis demonstrates the consistency, asymptotic unbiasedness, convergence rate, and robustness of the proposed estimators. Finally, we validate the effectiveness of our theoretical results via experiments both on synthetic data under various noise settings and on real data.'}",https://openreview.net{'value': '/pdf/24b6b06070b840cb5466e7e33ce09a2a15835d99.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=p40XRfBX96,{'value': 'Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision'},Zhiqing Sun; Yikang Shen; Qinhong Zhou; Hongxin Zhang; Zhenfang Chen; David Daniel Cox; Yiming Yang; Chuang Gan,~Zhiqing_Sun1; ~Yikang_Shen1; ~Qinhong_Zhou1; ~Hongxin_Zhang1; ~Zhenfang_Chen1; ~David_Daniel_Cox1; ~Yiming_Yang1; ~Chuang_Gan1,"{'value': ['AI Alignment', 'Large Language Models', 'In Context Learning', 'Neural Symbolics']}","{'value': ""Recent AI-assistant agents, such as ChatGPT, predominantly rely on supervised fine-tuning (SFT) with human annotations and reinforcement learning from human feedback (RLHF) to align the output of large language models (LLMs) with human intentions, ensuring they are helpful, ethical, and reliable. However, this dependence can significantly constrain the true potential of AI-assistant agents due to the high cost of obtaining human supervision and the related issues on quality, reliability, diversity, self-consistency, and undesirable biases. To address these challenges, we propose a novel approach called SELF-ALIGN, which combines principle-driven reasoning and the generative power of LLMs for the self-alignment of AI agents with minimal human supervision. Our approach encompasses four stages: first, we use an LLM to generate synthetic prompts, and a topic-guided method to augment the prompt diversity; second, we use a small set of human-written principles for AI models to follow, and guide the LLM through in-context learning from demonstrations (of principles application) to produce helpful, ethical, and reliable responses to user's queries; third, we fine-tune the original LLM with the high-quality self-aligned responses so that the resulting model can generate desirable responses for each query directly without the principle set and the demonstrations anymore; and finally, we offer a refinement step to address the issues of overly-brief or indirect responses. Applying SELF-ALIGN to the LLaMA-65b base language model, we develop an AI assistant named Dromedary. With fewer than 300 lines of human annotations (including < 200 seed prompts, 16 generic principles, and 5 exemplars for in-context learning). Dromedary significantly surpasses the performance of several state-of-the-art AI systems, including Text-Davinci-003 and Alpaca, on benchmark datasets with various settings.""}",https://openreview.net{'value': '/pdf/1442772fe6da271e24e7b731a570952b813b5f64.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=oaCDiKoJ2w,{'value': 'Follow-ups Also Matter: Improving Contextual Bandits via Post-serving Contexts'},Chaoqi Wang; Ziyu Ye; Zhe Feng; Ashwinkumar Badanidiyuru; Haifeng Xu,~Chaoqi_Wang1; ~Ziyu_Ye1; ~Zhe_Feng3; ~Ashwinkumar_Badanidiyuru1; ~Haifeng_Xu1,"{'value': ['linear stochastic bandits', 'online learning', 'partial information', 'contextual bandits']}","{'value': ""Standard contextual bandit problem assumes that all the relevant contexts are observed before the algorithm chooses an arm. This modeling paradigm, while useful, often falls short when dealing with problems in which additional valuable contexts can be observed after arm selection. For example, content recommendation platforms like Youtube, Instagram, Tiktok receive much additional features about a user's reward after the user clicks a content (e.g., how long the user stayed, what is the user's watch speed, etc.). To improve online learning efficiency in these applications,  we  study a novel contextual bandit problem with post-serving contexts and design a new algorithm, poLinUCB,  that achieves tight regret under standard assumptions. Core to our technical proof is a robustified and generalized version of the well-known Elliptical Potential Lemma (EPL), which can accommodate  noise in data. Such robustification is necessary for tackling our problem, though we believe it could also be of general interest.\nExtensive empirical tests on both synthetic and real-world datasets  demonstrate the significant benefit of utilitzing post-serving contexts as well as the superior performance of  our   algorithm over the state-of-the-art approaches.""}",https://openreview.net{'value': '/pdf/27b692ccfb4049b4dc226f20715337b97df31df0.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=nrbR2F29vU,{'value': 'A Scale-Invariant Sorting Criterion to Find a Causal Order in Additive Noise Models'},Alexander Gilbert Reisach; Myriam Tami; Christof Seiler; Antoine Chambaz; Sebastian Weichwald,~Alexander_Gilbert_Reisach1; ~Myriam_Tami1; ~Christof_Seiler2; ~Antoine_Chambaz2; ~Sebastian_Weichwald1,"{'value': ['Causal Discovery', 'Directed Acyclic Graph', 'Varsortability', 'Additive Noise Model', 'Structural Causal Model', 'Simulation', 'Benchmark']}","{'value': 'Additive Noise Models (ANMs) are a common model class for causal discovery from observational data. Due to a lack of real-world data for which an underlying ANM is known, ANMs with randomly sampled parameters are commonly used to simulate data for the evaluation of causal discovery algorithms. While some parameters may be fixed by explicit assumptions, fully specifying an ANM requires choosing all parameters. Reisach et al. (2021) show that, for many ANM parameter choices, sorting the variables by increasing variance yields an ordering close to a causal order and introduce ‘var-sortability’ to quantify this alignment. Since increasing variances may be unrealistic and cannot be exploited when data scales are arbitrary, ANM data are often rescaled to unit variance in causal discovery benchmarking.\n\nWe show that synthetic ANM data are characterized by another pattern that is scale-invariant and thus persists even after standardization: the explainable fraction of a variable’s variance, as captured by the coefficient of determination $R^2$, tends to increase along the causal order. The result is high ‘$R^2$-sortability’, meaning that sorting the variables by increasing $R^2$ yields an ordering close to a causal order. We propose a computationally efficient baseline algorithm termed ‘$R^2$-SortnRegress’ that exploits high $R^2$-sortability and that can match and exceed the performance of established causal discovery algorithms. We show analytically that sufficiently high edge weights lead to a relative decrease of the noise contributions along causal chains, resulting in increasingly deterministic relationships and high $R^2$. We characterize $R^2$-sortability on synthetic data with different simulation parameters and find high values in common settings. Our findings reveal high $R^2$-sortability as an assumption about the data generating process relevant to causal discovery and implicit in many ANM sampling schemes. It should be made explicit, as its prevalence in real-world data is an open question. For causal discovery benchmarking, we provide implementations of $R^2$-sortability, the $R^2$-SortnRegress algorithm, and ANM simulation procedures in our library CausalDisco at https://causaldisco.github.io/CausalDisco/.'}",https://openreview.net{'value': '/pdf/b9338613e408adf15a4749ac4e344896fa69c122.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=noyleECBam,{'value': 'Marginal Density Ratio for Off-Policy Evaluation in Contextual Bandits'},Muhammad Faaiz Taufiq; Arnaud Doucet; Rob Cornish; Jean-Francois Ton,~Muhammad_Faaiz_Taufiq1; ~Arnaud_Doucet2; ~Rob_Cornish1; ~Jean-Francois_Ton2,"{'value': ['contextual bandits', 'variance reduction', 'off-policy evaluation']}","{'value': 'Off-Policy Evaluation (OPE) in contextual bandits is crucial for assessing new policies using existing data without costly experimentation. However, current OPE methods, such as Inverse Probability Weighting (IPW) and Doubly Robust (DR) estimators, suffer from high variance, particularly in cases of low overlap between target and behaviour policies or large action and context spaces. In this paper, we introduce a new OPE estimator for contextual bandits, the Marginal Ratio (MR) estimator, which focuses on the shift in the marginal distribution of outcomes $Y$ instead of the policies themselves. Through rigorous theoretical analysis, we demonstrate the benefits of the MR estimator compared to conventional methods like IPW and DR in terms of variance reduction. Additionally, we establish a connection between the MR estimator and the state-of-the-art Marginalized Inverse Propensity Score (MIPS) estimator, proving that MR achieves lower variance among a generalized family of MIPS estimators. We further illustrate the utility of the MR estimator in causal inference settings, where it exhibits enhanced performance in estimating Average Treatment Effects (ATE). Our experiments on synthetic and real-world datasets corroborate our theoretical findings and highlight the practical advantages of the MR estimator in OPE for contextual bandits.'}",https://openreview.net{'value': '/pdf/6ba632bdec2aef5db51b1dcefb3bc8d6d6d1257f.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=noMktb4ait,{'value': 'Joint Feature and Differentiable $ k $-NN Graph Learning using Dirichlet Energy'},Lei Xu; Lei Chen; Rong Wang; Feiping Nie; Xuelong Li,~Lei_Xu6; ~Lei_Chen12; ~Rong_Wang2; ~Feiping_Nie2; ~Xuelong_Li2,"{'value': ['Feature Selection', 'Differential k-NN Graph', 'Dirichlet Energy']}","{'value': 'Feature selection (FS) plays an important role in machine learning, which extracts important features and accelerates the learning process. In this paper, we propose a deep FS method that simultaneously conducts feature selection and differentiable $ k $-NN graph learning  based on the Dirichlet Energy. The Dirichlet Energy identifies important features by measuring their smoothness on the graph structure, and facilitates the learning of a new graph that reflects the inherent structure in new feature subspace. We employ Optimal Transport theory to address the non-differentiability issue of learning $ k $-NN graphs in neural networks, which theoretically makes our method applicable to other graph neural networks for dynamic graph learning. Furthermore, the proposed framework is interpretable, since all modules are designed algorithmically. We validate the effectiveness of our model with extensive experiments on both synthetic and real-world datasets.'}",https://openreview.net{'value': '/pdf/a7d4b16d0f0d981c6dfb9b965efae2bda0f90ddf.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=neu9JlNweE,{'value': 'Post-processing Private Synthetic Data for Improving Utility on Selected Measures'},Hao Wang; Shivchander Sudalairaj; John Henning; Kristjan Greenewald; Akash Srivastava,~Hao_Wang22; ~Shivchander_Sudalairaj1; ~John_Henning1; ~Kristjan_Greenewald1; ~Akash_Srivastava1,"{'value': ['differential privacy', 'synthetic data']}","{'value': 'Existing private synthetic data generation algorithms are agnostic to downstream tasks. However, end users may have specific requirements that the synthetic data must satisfy. Failure to meet these requirements could significantly reduce the utility of the data for downstream use. We introduce a post-processing technique that improves the utility of the synthetic data with respect to measures selected by the end user, while preserving strong privacy guarantees and dataset quality. Our technique involves resampling from the synthetic data to filter out samples that do not meet the selected utility measures, using an efficient stochastic first-order algorithm to find optimal resampling weights. Through comprehensive numerical experiments, we demonstrate that our approach consistently improves the utility of synthetic data across multiple benchmark datasets and state-of-the-art synthetic data generation algorithms.'}",https://openreview.net{'value': '/pdf/d7bc1678453c0dc80af91df41914c65d9dbec4a2.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=nG35q8pNL9,{'value': 'What Truly Matters in Trajectory Prediction for Autonomous Driving?'},Tran Phong; Haoran Wu; Cunjun Yu; Panpan Cai; Sifa Zheng; David Hsu,~Tran_Phong1; ~Haoran_Wu9; ~Cunjun_Yu1; ~Panpan_Cai1; ~Sifa_Zheng1; ~David_Hsu1,{'value': ['trajectory prediction; autonomous driving']},"{'value': ""Trajectory prediction plays a vital role in the performance of autonomous driving systems, and prediction accuracy, such as average displacement error (ADE) or final displacement error (FDE), is widely used as a performance metric. However, a significant disparity exists between the accuracy of predictors on fixed datasets and driving performance when the predictors are used downstream for vehicle control, because of a dynamics gap. In the real world, the prediction algorithm influences the behavior of the ego vehicle, which, in turn, influences the behaviors of other vehicles nearby. This interaction results in predictor-specific dynamics that directly impacts prediction results. In fixed datasets, since other vehicles' responses are predetermined, this interaction effect is lost, leading to a significant dynamics gap. This paper studies the overlooked significance of this dynamics gap. We also examine several other factors contributing to the disparity between prediction performance and driving performance. The findings highlight the trade-off between the predictor's computational efficiency and prediction accuracy in determining real-world driving performance. In summary,  an interactive, task-driven evaluation protocol for trajectory prediction is crucial to capture its effectiveness for autonomous driving. Source code along with experimental settings is available online (https://whatmatters23.github.io/).""}",https://openreview.net{'value': '/pdf/e1edc5d5f10612b94236f19632180d1671aeec4d.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=nCLdsEzZBV,{'value': 'The Equivalence of Dynamic and Strategic Stability under Regularized Learning in Games'},Victor Boone; Panayotis Mertikopoulos,~Victor_Boone1; ~Panayotis_Mertikopoulos1,"{'value': ['Regularized learning', 'dynamic stability', 'strategic stability', 'Nash equilibrium']}","{'value': ""In this paper, we examine the long-run behavior of regularized, no-regret learning in finite N-player games. A well-known result in the field states that the empirical frequencies of play under no-regret learning converge to the game’s set of coarse correlated equilibria; however, our understanding of how the players' _actual strategies_ evolve over time is much more limited – and, in many cases, non-existent. This issue is exacerbated further by a series of recent results showing that _only_ strict Nash equilibria are stable and attracting under regularized learning, thus making the relation between learning and _pointwise_ solution concepts particularly elusive. In lieu of this, we take a more general approach and instead seek to characterize the _setwise_ rationality properties of the players' day-to-day trajectory of play. To do so, we focus on one of the most stringent criteria of setwise strategic stability, namely that any unilateral deviation from the set in question incurs a cost to the deviator – a property known as _closedness under better replies_ (club). In so doing, we obtain a remarkable equivalence between strategic and dynamic stability: _a product of pure strategies is closed under better replies if and only if its span is stable and attracting under regularized learning._ In addition, we estimate the rate of convergence to such sets, and we show that methods based on entropic regularization (like the exponential weights algorithm) converge at a geometric rate, while projection-based methods converge within a finite number of iterations, even with bandit, payoff-based feedback.""}",https://openreview.net{'value': '/pdf/1d544402bfdd0dcd8791277c8fd7945f97284a9d.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=nArzDm353Y,{'value': 'Training Transitive and Commutative Multimodal Transformers with LoReTTa'},Manuel Tran; Yashin Dicente Cid; Amal Lahiani; Fabian J Theis; Tingying Peng; Eldad Klaiman,~Manuel_Tran2; ~Yashin_Dicente_Cid3; ~Amal_Lahiani1; ~Fabian_J_Theis1; ~Tingying_Peng1; ~Eldad_Klaiman1,"{'value': ['generative pre-training', 'causal modeling', 'masked modeling', 'commutative modeling', 'transitive modeling', 'multimodal learning']}","{'value': 'Training multimodal foundation models is challenging due to the limited availability of multimodal datasets. While many public datasets pair images with text, few combine images with audio or text with audio. Even rarer are datasets that align all three modalities at once. Critical domains such as healthcare, infrastructure, or transportation are particularly affected by missing modalities. This makes it difficult to integrate all modalities into a large pre-trained neural network that can be used out-of-the-box or fine-tuned for different downstream tasks. We introduce LoReTTa ($\\textbf{L}$inking m$\\textbf{O}$dalities with a t$\\textbf{R}$ansitive and commutativ$\\textbf{E}$ pre-$\\textbf{T}$raining s$\\textbf{T}$r$\\textbf{A}$tegy) to address this understudied problem. Our self-supervised framework unifies causal modeling and masked modeling with the rules of commutativity and transitivity. This allows us to transition within and between modalities. As a result, our pre-trained models are better at exploring the true underlying joint probability distribution. Given a dataset containing only the disjoint combinations $(A, B)$ and $(B, C)$, LoReTTa can model the relation $A \\leftrightarrow C$ with $A \\leftrightarrow B \\leftrightarrow C$. In particular, we show that a transformer pre-trained with LoReTTa can handle any mixture of modalities at inference time, including the never-seen pair $(A, C)$ and the triplet $(A, B, C)$. We extensively evaluate our approach on a synthetic, medical, and reinforcement learning dataset. Across different domains, our universal multimodal transformer consistently outperforms strong baselines such as GPT, BERT, and CLIP on tasks involving the missing modality tuple.'}",https://openreview.net{'value': '/pdf/0cde7f4dc8b36bf7a60fea33b4931c67d510c607.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=n8JWIzYPRz,{'value': 'Environment-Aware Dynamic Graph Learning for Out-of-Distribution Generalization'},Haonan Yuan; Qingyun Sun; Xingcheng Fu; Ziwei Zhang; Cheng Ji; Hao Peng; Jianxin Li,~Haonan_Yuan2; ~Qingyun_Sun2; ~Xingcheng_Fu1; ~Ziwei_Zhang1; ~Cheng_Ji1; ~Hao_Peng10; ~Jianxin_Li3,"{'value': ['dynamic graph learning', 'out-of-distribution generalization', 'invariant learning', 'link prediction']}","{'value': 'Dynamic graph neural networks (DGNNs) are increasingly pervasive in exploiting spatio-temporal patterns on dynamic graphs. However, existing works fail to generalize under distribution shifts, which are common in real-world scenarios. As the generation of dynamic graphs is heavily influenced by latent environments, investigating their impacts on the out-of-distribution (OOD) generalization is critical. However, it remains unexplored with the following two major challenges: **(1)** How to properly model and infer the complex environments on dynamic graphs with distribution shifts? **(2)** How to discover invariant patterns given inferred spatio-temporal environments? To solve these challenges, we propose a novel **E**nvironment-**A**ware dynamic **G**raph **LE**arning (**EAGLE**) framework for OOD generalization by modeling complex coupled environments and exploiting spatio-temporal invariant patterns. Specifically, we first design the environment-aware EA-DGNN to model environments by multi-channel environments disentangling. Then, we propose an environment instantiation mechanism for environment diversification with inferred distributions. Finally, we discriminate spatio-temporal invariant patterns for out-of-distribution prediction by the invariant pattern recognition mechanism and perform fine-grained causal interventions node-wisely with a mixture of instantiated environment samples. Experiments on real-world and synthetic dynamic graph datasets demonstrate the superiority of our method against state-of-the-art baselines under distribution shifts. To the best of our knowledge, we are the first to study OOD generalization on dynamic graphs from the environment learning perspective.'}",https://openreview.net{'value': '/pdf/5b03036b4929153d6fa39fb98940b4ef97a114f2.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=n6ztJ3Lrdj,{'value': 'Learning with Explanation Constraints'},Rattana Pukdee; Dylan Sam; J Zico Kolter; Nina Balcan; Pradeep Kumar Ravikumar,~Rattana_Pukdee1; ~Dylan_Sam1; ~J_Zico_Kolter1; ~Nina_Balcan1; ~Pradeep_Kumar_Ravikumar1,"{'value': ['Interpretable ML', 'Semi-supervised learning', 'Learning theory']}","{'value': 'As larger deep learning models are hard to interpret, there has been a recent focus on generating explanations of these black-box models. \nIn contrast, we may have apriori explanations of how models should behave. In this paper, we formalize this notion as learning from explanation constraints and provide a learning theoretic framework to analyze how such explanations can improve the learning of our models.  One may naturally ask, ""When would these explanations be helpful?""\nOur first key contribution addresses this question via a class of models that satisfies these explanation constraints in expectation over new data. We provide a characterization of the benefits of these models (in terms of the reduction of their Rademacher complexities) for a canonical class of explanations given by gradient information in the settings of both linear models and two layer neural networks. In addition, we provide an algorithmic solution for our framework, via a variational approximation that achieves better performance and satisfies these constraints more frequently, when compared to simpler augmented Lagrangian methods to incorporate these explanations. We demonstrate the benefits of our approach over a large array of synthetic and real-world experiments.'}",https://openreview.net{'value': '/pdf/60d42434fb70dee65c5dddcaae4496629ee68325.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=mlbes5TAAg,{'value': 'Unleashing the Power of Randomization in Auditing Differentially Private ML'},Krishna Pillutla; Galen Andrew; Peter Kairouz; Hugh Brendan McMahan; Alina Oprea; Sewoong Oh,~Krishna_Pillutla1; ~Galen_Andrew1; ~Peter_Kairouz1; ~Hugh_Brendan_McMahan1; ~Alina_Oprea1; ~Sewoong_Oh1,"{'value': ['Differential privacy auditing', 'multiple canaries', 'randomization', 'lifting', 'adaptive confidence intervals']}","{'value': 'We present a rigorous methodology for auditing differentially private machine learning by adding multiple carefully designed examples called canaries. We take a first principles approach based on three key components. First, we introduce Lifted Differential Privacy (LiDP) that expands the definition of differential privacy to handle randomized datasets. This gives us the freedom to design randomized canaries. Second, we audit LiDP by trying to distinguish between the model trained with $K$ canaries versus $K-1$ canaries in the dataset, leaving one canary out. By drawing the canaries i.i.d., LiDP can leverage the symmetry in the design and reuse each privately trained model to run multiple statistical tests, one for each canary. Third, we introduce novel confidence intervals that take advantage of the multiple test statistics by adapting to the empirical higher-order correlations. Together, this new recipe demonstrates significant improvements in sample complexity, both theoretically and empirically, using synthetic and real data. Further, recent advances in designing stronger canaries can be readily incorporated in the new framework.'}",https://openreview.net{'value': '/pdf/fd5d0b47b7dda0ef76093bf7eb936cc8c590ef3e.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=mA7nTGXjD3,{'value': 'Provably Fast Convergence of Independent Natural Policy Gradient for Markov Potential Games'},Youbang Sun; Tao Liu; Ruida Zhou; Panganamala Kumar; Shahin Shahrampour,~Youbang_Sun1; ~Tao_Liu8; ~Ruida_Zhou1; ~Panganamala_Kumar1; ~Shahin_Shahrampour2,"{'value': ['Multi Agent Reinforcement Learning', 'Markov Potential Games', 'Natural Policy Gradient', 'Nash Equilibrium']}","{'value': 'This work studies an independent natural policy gradient (NPG) algorithm for the multi-agent reinforcement learning problem in Markov potential games. It is shown that, under mild technical assumptions and the introduction of the \\textit{suboptimality gap}, the independent NPG method with an oracle providing exact policy evaluation asymptotically reaches an $\\epsilon$-Nash Equilibrium (NE) within $\\mathcal{O}(1/\\epsilon)$ iterations. This improves upon the previous best result of $\\mathcal{O}(1/\\epsilon^2)$ iterations and is of the same order, $\\mathcal{O}(1/\\epsilon)$, that is achievable for the single-agent case. Empirical results for a synthetic potential game and a congestion game are presented to verify the theoretical bounds.'}",https://openreview.net{'value': '/pdf/94d395a0e5402a2da0a9a707b9c293a6e0e02401.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=m11TbsaQQI,{'value': 'Efficient Hyper-parameter Optimization with Cubic Regularization'},Zhenqian Shen; Hansi Yang; Yong Li; James Kwok; quanming yao,~Zhenqian_Shen1; ~Hansi_Yang1; ~Yong_Li7; ~James_Kwok1; ~quanming_yao1,"{'value': ['hyper-parameter optimization', 'cubic regularization']}","{'value': 'As hyper-parameters are ubiquitous and can significantly affect the model performance, hyper-parameter optimization is extremely important in machine learning. In this paper, we consider a sub-class of hyper-parameter optimization problems, where the hyper-gradients are not available. Such problems frequently appear when the performance metric is non-differentiable or the hyper-parameter is not continuous. However, existing algorithms, like Bayesian optimization and reinforcement learning, often get trapped in local optimals with poor performance. To address the above limitations, we propose to use cubic regularization to accelerate convergence and avoid saddle points. First, we adopt stochastic relaxation, which allows obtaining gradient and Hessian information without hyper-gradients. Then, we exploit the rich curvature information by cubic regularization. Theoretically, we prove that the proposed method can converge to approximate second-order stationary points, and the convergence is also guaranteed when the lower-level problem is inexactly solved. Experiments on synthetic and real-world data demonstrate the effectiveness of our proposed method.'}",https://openreview.net{'value': '/pdf/655b8321aaec15356ff6e958aa2c0ea427216018.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=lzqaQRsITh,{'value': 'DiffComplete: Diffusion-based Generative 3D Shape Completion'},Ruihang Chu; Enze Xie; Shentong Mo; Zhenguo Li; Matthias Nießner; Chi-Wing Fu; Jiaya Jia,~Ruihang_Chu1; ~Enze_Xie1; ~Shentong_Mo1; ~Zhenguo_Li1; ~Matthias_Nießner2; ~Chi-Wing_Fu2; ~Jiaya_Jia1,"{'value': ['3d shape completion', 'conditional generation', 'diffusion models']}","{'value': 'We introduce a new diffusion-based approach for shape completion on 3D range scans. Compared with prior deterministic and probabilistic methods, we strike a balance between realism, multi-modality, and high fidelity. We propose DiffComplete by casting shape completion as a generative task conditioned on the incomplete shape. Our key designs are two-fold. First, we devise a hierarchical feature aggregation mechanism to inject conditional features in a spatially-consistent manner. So, we can capture both local details and broader contexts of the conditional inputs to control the shape completion. Second, we propose an occupancy-aware fusion strategy in our model to enable the completion of multiple partial shapes and introduce higher flexibility on the input conditions. DiffComplete sets a new SOTA performance (e.g., 40% decrease on $l_1$ error) on two large-scale 3D shape completion benchmarks. Our completed shapes not only have a realistic outlook compared with the deterministic methods but also exhibit high similarity to the ground truths compared with the probabilistic alternatives. Further, DiffComplete has strong generalizability on objects of entirely unseen classes for both synthetic and real data, eliminating the need for model re-training in various applications.'}",https://openreview.net{'value': '/pdf/10749f608d55f21ea893100d9a141f13f1ef1072.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=luyXPdkNSN,{'value': 'K-Nearest-Neighbor Local Sampling Based Conditional Independence Testing'},Shuai Li; Yingjie Zhang; Hongtu Zhu; Christina Dan Wang; Hai Shu; Ziqi Chen; Zhuoran Sun; Yanfeng Yang,~Shuai_Li22; ~Yingjie_Zhang3; ~Hongtu_Zhu3; ~Christina_Dan_Wang1; ~Hai_Shu1; ~Ziqi_Chen2; ~Zhuoran_Sun1; ~Yanfeng_Yang1,"{'value': ['Conditional Independence testing', 'causal inference', 'conditional mutual information', 'k-nearest neighbor', 'conditional randomization test', 'conditional permutation test']}","{'value': 'Conditional independence (CI) testing is a fundamental task in statistics and machine learning, but its effectiveness is hindered by the challenges posed by high-dimensional conditioning variables and limited data samples. This article introduces a novel testing approach to address these challenges and enhance control of the type I error while achieving high power under alternative hypotheses. The proposed approach incorporates a computationally efficient classifier-based conditional mutual information (CMI) estimator, capable of capturing intricate dependence structures among variables. To approximate a distribution encoding the null hypothesis, a $k$-nearest-neighbor local sampling strategy is employed. An important advantage of this approach is its ability to operate without assumptions about distribution forms or feature dependencies. Furthermore, it eliminates the need to derive asymptotic null distributions for the estimated CMI and avoids dataset splitting, making it particularly suitable for small datasets. The method presented in this article demonstrates asymptotic control of the type I error and consistency against all alternative hypotheses. Extensive analyses using both synthetic and real data highlight the computational efficiency of the proposed test. Moreover, it outperforms existing state-of-the-art methods in terms of type I and II errors, even in scenarios with high-dimensional conditioning sets. Additionally, the proposed approach exhibits robustness in the presence of heavy-tailed data.'}",https://openreview.net{'value': '/pdf/3423552767cece65d11c193f0971f4675213b400.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=lOCHMGO6ow,{'value': 'Energy-Based Cross Attention for Bayesian Context Update in Text-to-Image Diffusion Models'},Geon Yeong Park; Jeongsol Kim; Beomsu Kim; Sang Wan Lee; Jong Chul Ye,~Geon_Yeong_Park1; ~Jeongsol_Kim1; ~Beomsu_Kim1; ~Sang_Wan_Lee1; ~Jong_Chul_Ye1,"{'value': ['Diffusion model', 'Energy-based model', 'Text-to-image generation']}","{'value': 'Despite the remarkable performance of text-to-image diffusion models in image generation tasks, recent studies have raised the issue that generated images sometimes cannot capture the intended semantic contents of the text prompts, which phenomenon is often called semantic misalignment. To address this, here we present a novel energy-based model (EBM) framework for adaptive context control by modeling the posterior of context vectors. Specifically, we first formulate EBMs of latent image representations and text embeddings in each cross-attention layer of the denoising autoencoder. Then, we obtain the gradient of the log posterior of context vectors, which can be updated and transferred to the subsequent cross-attention layer, thereby implicitly minimizing a nested hierarchy of energy functions. \nOur latent EBMs further allow zero-shot compositional generation as a linear combination of cross-attention outputs from different contexts. \nUsing extensive experiments, we demonstrate that the proposed method is highly effective in handling various image generation tasks, including multi-concept generation, text-guided image inpainting, and real and synthetic image editing. Code: https://github.com/EnergyAttention/Energy-Based-CrossAttention.'}",https://openreview.net{'value': '/pdf/3c8a9a13e453219a264c90bb216faad548afeaec.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=l9MbuqzlZt,{'value': 'Globally solving the Gromov-Wasserstein problem for point clouds in low dimensional Euclidean spaces'},Martin Ryner; Jan Kronqvist; Johan Karlsson,~Martin_Ryner1; ~Jan_Kronqvist1; ~Johan_Karlsson2,"{'value': ['Gromov-Wasserstein problem', 'QAP', 'Global optimization']}","{'value': 'This paper presents a framework for computing the Gromov-Wasserstein problem between two sets of points in low dimensional spaces, where the discrepancy is the squared Euclidean norm.\nThe Gromov-Wasserstein problem is a generalization of the optimal transport problem that finds the assignment between two sets preserving pairwise distances as much as possible. This can be used to quantify the similarity between two formations or shapes, a common problem in AI and machine learning.\nThe problem can be formulated as a Quadratic Assignment Problem (QAP), which is in general computationally intractable even for small problems. Our framework addresses this challenge by reformulating the QAP as an optimization problem with a low-dimensional domain, leveraging the fact that the problem can be expressed as a concave quadratic optimization problem with low rank. The method scales well with the number of points, and it can be used to find the global solution for large-scale problems with thousands of points.\nWe compare the computational complexity of our approach with state-of-the-art methods on synthetic problems and apply it to a near-symmetrical problem which is of particular interest in computational biology.'}",https://openreview.net{'value': '/pdf/b5dfb9037b60e29975a8726c3f1493603f7e89fc.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=l3HUgVHqGQ,{'value': 'Scan and Snap: Understanding Training Dynamics and Token Composition in 1-layer Transformer'},Yuandong Tian; Yiping Wang; Beidi Chen; Simon Shaolei Du,~Yuandong_Tian1; ~Yiping_Wang2; ~Beidi_Chen1; ~Simon_Shaolei_Du1,"{'value': ['transformer', 'training dynamics', 'theoretical analysis', 'self-attention', 'interpretability', 'neural network understanding']}","{'value': 'Transformer architecture has shown impressive performance in multiple research domains and has become the backbone of many neural network models. However, there is limited understanding on how it works. In particular, with a simple predictive loss,  how the representation emerges from the gradient \\emph{training dynamics} remains a mystery. In this paper, for 1-layer transformer with one self-attention layer plus one decoder layer, we analyze its SGD training dynamics for the task of next token prediction in a mathematically rigorous manner. We open the black box of the dynamic process of how the self-attention layer combines input tokens, and reveal the nature of underlying inductive bias. More specifically, with the assumption (a) no positional encoding, (b) long input sequence, and (c) the decoder layer learns faster than the self-attention layer, we prove that self-attention acts as a \\emph{discriminative scanning algorithm}: \n starting from uniform attention, it gradually attends more to distinct key tokens for a specific next token to be predicted, and pays less attention to common key tokens that occur across different next tokens. Among distinct tokens, it progressively drops attention weights, following the order of low to high co-occurrence between the key and the query token in the training set. Interestingly, this procedure does not lead to winner-takes-all, but stops due to a \\emph{phase transition} that is controllable by the learning rate of the decoder layer, leaving (almost) fixed token combination. We verify this \\textbf{\\emph{scan and snap}} dynamics on synthetic and real-world data (WikiText-103).'}",https://openreview.net{'value': '/pdf/1cc86c4113f201f47f6daae4c43348b7dc30c9d7.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=kfWzpZvEUh,{'value': 'End-to-End Meta-Bayesian Optimisation with Transformer Neural Processes'},Alexandre Max Maraval; Matthieu Zimmer; Antoine Grosnit; Haitham Bou Ammar,~Alexandre_Max_Maraval1; ~Matthieu_Zimmer1; ~Antoine_Grosnit2; ~Haitham_Bou_Ammar1,"{'value': ['meta-learning', 'bayesian optimisation', 'neural process', 'transformer', 'end-to-end', 'reinforcement learning']}","{'value': 'Meta-Bayesian optimisation (meta-BO) aims to improve the sample efficiency of Bayesian optimisation by leveraging data from related tasks. While previous methods successfully meta-learn either a surrogate model or an acquisition function independently, joint training of both components remains an open challenge. This paper proposes the first end-to-end differentiable meta-BO framework that generalises neural processes to learn acquisition functions via transformer architectures. We enable this end-to-end framework with reinforcement learning (RL) to tackle the lack of labelled acquisition data. Early on, we notice that training transformer-based neural processes from scratch with RL is challenging due to insufficient supervision, especially when rewards are sparse. We formalise this claim with a combinatorial analysis showing that the widely used notion of regret as a reward signal exhibits a logarithmic sparsity pattern in trajectory lengths. To tackle this problem, we augment the RL objective with an auxiliary task that guides part of the architecture to learn a valid probabilistic model as an inductive bias. We demonstrate that our method achieves state-of-the-art regret results against various baselines in experiments on standard hyperparameter optimisation tasks and also outperforms others in the real-world problems of mixed-integer programming tuning, antibody design, and logic synthesis for electronic design automation.'}",https://openreview.net{'value': '/pdf/867947ccf4f165b4f1594525463e9f3fd51d8237.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=kS7ED7eE74,{'value': 'A Fractional Graph Laplacian Approach to Oversmoothing'},Sohir Maskey; Raffaele Paolino; Aras Bacho; Gitta Kutyniok,~Sohir_Maskey1; ~Raffaele_Paolino1; ~Aras_Bacho1; ~Gitta_Kutyniok2,"{'value': ['Graph Neural Networks', 'Graph Neural ODE', 'Fractional Laplacian', 'Oversmoothing']}","{'value': 'Graph neural networks (GNNs) have shown state-of-the-art performances in various applications. However, GNNs often struggle to capture long-range dependencies in graphs due to oversmoothing. In this paper, we generalize the concept of oversmoothing from undirected to directed graphs. To this aim, we extend the notion of Dirichlet energy by considering a directed symmetrically normalized Laplacian. As vanilla graph convolutional networks are prone to oversmooth, we adopt a neural graph ODE framework. Specifically, we propose fractional graph Laplacian neural ODEs, which describe non-local dynamics. We prove that our approach allows propagating information  between distant nodes while maintaining a low probability of long-distance jumps. Moreover, we show that our method is more flexible with respect to the convergence of the graph’s Dirichlet energy, thereby mitigating oversmoothing. We conduct extensive experiments on synthetic and real-world graphs, both  directed and undirected, demonstrating our method’s versatility across diverse graph homophily levels.  Our\ncode is available at https://github.com/RPaolino/fLode'}",https://openreview.net{'value': '/pdf/c5966f9d4fe19f416d890769d429189ff6716570.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=kR21XsZeAr,{'value': 'Subclass-Dominant Label Noise: A Counterexample for the Success of Early Stopping'},Yingbin Bai; Zhongyi Han; Erkun Yang; Jun Yu; Bo Han; Dadong Wang; Tongliang Liu,~Yingbin_Bai1; ~Zhongyi_Han1; ~Erkun_Yang2; ~Jun_Yu3; ~Bo_Han1; ~Dadong_Wang1; ~Tongliang_Liu1,"{'value': ['learning with noisy labels', 'weakly supervised learning']}","{'value': 'In this paper, we empirically investigate a previously overlooked and widespread type of label noise, subclass-dominant label noise (SDN). Our findings reveal that, during the early stages of training, deep neural networks can rapidly memorize mislabeled examples in SDN. This phenomenon poses challenges in effectively selecting confident examples using conventional early stopping techniques. To address this issue, we delve into the properties of SDN and observe that long-trained representations are superior at capturing the high-level semantics of mislabeled examples, leading to a clustering effect where similar examples are grouped together. Based on this observation, we propose a novel method called NoiseCluster that leverages the geometric structures of long-trained representations to identify and correct SDN. Our experiments demonstrate that NoiseCluster outperforms state-of-the-art baselines on both synthetic and real-world datasets, highlighting the importance of addressing SDN in learning with noisy labels. The code is available at https://github.com/tmllab/2023_NeurIPS_SDN.'}",https://openreview.net{'value': '/pdf/76d74379c5cdebf43777fc37ce078aedd3e66ca1.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=kPfd3pcwHV,{'value': 'Online Ad Allocation with Predictions'},Fabian Christian Spaeh; Alina Ene,~Fabian_Christian_Spaeh1; ~Alina_Ene1,"{'value': ['Learning Augmented Algorithms', 'Display Ads', 'Generalized Assignment Problem']}","{'value': 'Display Ads and the generalized assignment problem are two well-studied online packing problems with important applications in ad allocation and other areas. In both problems, ad impressions arrive online and have to be allocated immediately to budget-constrained advertisers. Worst-case algorithms that achieve the ideal competitive ratio are known for both problems, but might act overly conservative given the predictable and usually tame nature of real-world input. Given this discrepancy, we develop an algorithm for both problems that incorporate machine-learned predictions and can thus improve the performance beyond the worst-case. Our algorithm is based on the work of Feldman et al. (2009) and similar in nature to Mahdian et al. (2007) who were the first to develop a learning-augmented algorithm for the related, but more structured Ad Words problem. We use a novel analysis to show that our algorithm is able to capitalize on a good prediction, while being robust against poor predictions. We experimentally evaluate our algorithm on synthetic and real-world data on a wide range of predictions. Our algorithm is consistently outperforming the worst-case algorithm without predictions.'}",https://openreview.net{'value': '/pdf/ebd5e09bba68c91370476ce5d2c630baa6e5be70.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=kJmYu3Ti2z,{'value': 'When Do Graph Neural Networks Help with Node Classification? Investigating the Homophily Principle on Node Distinguishability'},Sitao Luan; Chenqing Hua; Minkai Xu; Qincheng Lu; Jiaqi Zhu; Xiao-Wen Chang; Jie Fu; Jure Leskovec; Doina Precup,~Sitao_Luan1; ~Chenqing_Hua1; ~Minkai_Xu1; ~Qincheng_Lu1; ~Jiaqi_Zhu1; ~Xiao-Wen_Chang1; ~Jie_Fu2; ~Jure_Leskovec1; ~Doina_Precup1,"{'value': ['Graph Neural Networks', 'Homophily', 'Heterophily', 'Low-pass filter', 'High-pass filter', 'Node Distinguishability', 'Metrics']}","{'value': ""Homophily principle, i.e., nodes with the same labels are more likely to be connected, has been believed to be the main reason for the performance superiority of Graph Neural Networks (GNNs) over Neural Networks on node classification tasks. Recent research suggests that, even in the absence of homophily, the advantage of GNNs still exists as long as nodes from the same class share similar neighborhood patterns. However, this argument only considers intra-class Node Distinguishability (ND) but neglects inter-class ND, which provides incomplete understanding of homophily on GNNs. In this paper, we first demonstrate such deficiency with examples and argue that an ideal situation for ND is to have smaller intra-class ND than inter-class ND. To formulate this idea and study ND deeply, we propose Contextual Stochastic Block Model for Homophily (CSBM-H) and define two metrics, Probabilistic Bayes Error (PBE) and negative generalized Jeffreys divergence, to quantify ND. With the metrics, we visualize and analyze how graph filters, node degree distributions and class variances influence ND, and investigate the combined effect of intra- and inter-class ND. Besides, we discovered the mid-homophily pitfall, which occurs widely in graph datasets. Furthermore, we verified that, in real-work tasks, the superiority of GNNs is indeed closely related to both intra- and inter-class ND regardless of homophily levels. Grounded in this observation, we propose a new hypothesis-testing based performance metric beyond homophily, which is non-linear, feature-based and can provide statistical threshold value for GNNs' the superiority. Experiments indicate that it is significantly more effective than the existing homophily metrics on revealing the advantage and disadvantage of graph-aware modes on both synthetic and benchmark real-world datasets.""}",https://openreview.net{'value': '/pdf/ffc670cc2838c9d29120e324534cbfb650374a5a.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=kBBsj9KRgh,{'value': 'SAME: Uncovering GNN Black Box with Structure-aware Shapley-based Multipiece Explanations'},Ziyuan Ye; Rihan Huang; Qilin Wu; Quanying Liu,~Ziyuan_Ye1; ~Rihan_Huang1; kyrinwu@gmail.com; ~Quanying_Liu1,"{'value': ['GNN explainability', 'Shapley value', 'Monte Carlo tree search', 'structure awareness', 'multi-grained explanation']}","{'value': 'Post-hoc explanation techniques on graph neural networks (GNNs) provide economical solutions for opening the black-box graph models without model retraining. Many GNN explanation variants have achieved state-of-the-art explaining results on a diverse set of benchmarks, while they rarely provide theoretical analysis for their inherent properties and explanatory capability. In this work, we propose $\\underline{\\text{S}}$tructure-$\\underline{\\text{A}}$ware Shapley-based $\\underline{\\text{M}}$ultipiece $\\underline{\\text{E}}$xplanation (SAME) method to address the structure-aware feature interactions challenges for GNNs explanation. Specifically, SAME leverages an expansion-based Monte Carlo tree search to explore the multi-grained structure-aware connected substructure. Afterward, the explanation results are encouraged to be informative of the graph properties by optimizing the combination of distinct single substructures. With the consideration of fair feature interactions in the process of investigating multiple connected important substructures, the explanation provided by SAME has the potential to be as explainable as the theoretically optimal explanation obtained by the Shapley value within polynomial time. Extensive experiments on real-world and synthetic benchmarks show that SAME improves the previous state-of-the-art fidelity performance by 12.9\\% on BBBP, 7.01\\% on MUTAG, 42.3\\% on Graph-SST2, 38.9\\% on Graph-SST5, 11.3\\% on BA-2Motifs and 18.2\\% on BA-Shapes under the same testing condition. Code is available at https://github.com/same2023neurips/same.'}",https://openreview.net{'value': '/pdf/2d51deea1a7c895cf241e35290379cd4ef2cacc6.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=k1Xy5zCNOJ,"{'value': 'Lookaround Optimizer: $k$ steps around, 1 step average'}",Jiangtao Zhang; Shunyu Liu; Jie Song; Tongtian Zhu; Zhengqi Xu; Mingli Song,~Jiangtao_Zhang1; ~Shunyu_Liu1; ~Jie_Song3; ~Tongtian_Zhu1; ~Zhengqi_Xu2; ~Mingli_Song1,"{'value': ['Deep Learning', 'Computer Vision', 'Mode Connectivity', 'Weight Average']}","{'value': 'Weight Average (WA) is an active research topic due to its simplicity in ensembling deep networks and the effectiveness in promoting generalization. Existing weight average approaches, however, are often carried out along only one training trajectory in a post-hoc manner (i.e., the weights are averaged after the entire training process is finished), which significantly degrades the diversity between networks and thus impairs the effectiveness. In this paper, inspired by weight average, we propose Lookaround, a straightforward yet effective SGD-based optimizer leading to flatter minima with better generalization. Specifically, Lookaround iterates two steps during the whole training period: the around step and the average step. In each iteration, 1) the around step starts from a common point and trains multiple networks simultaneously, each on transformed data by a different data augmentation, and 2) the average step averages these trained networks to get the averaged network, which serves as the starting point for the next iteration. The around step improves the functionality diversity while the average step guarantees the weight locality of these networks during the whole training, which is essential for WA to work. We theoretically explain the superiority of Lookaround by convergence analysis, and make extensive experiments to evaluate Lookaround on popular benchmarks including CIFAR and ImageNet with both CNNs and ViTs, demonstrating clear superiority over state-of-the-arts. Our code is available at https://github.com/Ardcy/Lookaround.'}",https://openreview.net{'value': '/pdf/1fecc8f586ca7fa43703937f1325ad0425427de1.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=jhs8F63xI6,{'value': 'Adaptive Online Replanning with Diffusion Models'},Siyuan Zhou; Yilun Du; Shun Zhang; Mengdi Xu; Yikang Shen; Wei Xiao; Dit-Yan Yeung; Chuang Gan,~Siyuan_Zhou2; ~Yilun_Du1; ~Shun_Zhang6; ~Mengdi_Xu3; ~Yikang_Shen1; ~Wei_Xiao2; ~Dit-Yan_Yeung2; ~Chuang_Gan1,"{'value': ['Decision making', 'Robotics', 'Planning-based']}","{'value': ""Diffusion models have risen a promising approach to data-driven planning, and have demonstrated impressive robotic control, reinforcement learning, and video planning performance. Given an effective planner, an important question to consider is replanning -- when given plans should be regenerated due to both action execution error and external environment changes.  Direct plan execution, without replanning, is problematic as errors from individual actions rapidly accumulate and environments are partially observable and stochastic. Simultaneously, replanning at each timestep incurs a substantial computational cost, and may prevent successful task execution, as different generated plans prevent consistent progress to any particular goal. In this paper, we explore how we may effectively replan with diffusion models. We propose a principled approach to determine when to replan, based on the diffusion model's estimated likelihood of existing generated plans. We further present an approach to replan existing trajectories to ensure that new plans follow the same goal state as the original trajectory, which may efficiently bootstrap off previously generated plans.  We illustrate how a combination of our proposed additions significantly improves the performance of diffusion planners leading to 38\\% gains over past diffusion planning approaches on Maze2D and further enables handling of stochastic and long-horizon robotic control tasks.""}",https://openreview.net{'value': '/pdf/d071ca735af8d27368640c939173aab5aa7c5448.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=jcRB6xHdJ2,"{'value': 'Interaction Measures, Partition Lattices and Kernel Tests for High-Order Interactions'}",Zhaolu Liu; Robert Peach; Pedro A. M. Mediano; Mauricio Barahona,~Zhaolu_Liu1; ~Robert_Peach1; ~Pedro_A._M._Mediano1; ~Mauricio_Barahona1,{'value': ['High-order interactions; Lattice theory; Kernel tests']},"{'value': 'Models that rely solely on pairwise relationships often fail to capture the complete statistical structure of the complex multivariate data found in diverse domains, such as socio-economic, ecological, or biomedical systems. Non-trivial dependencies between groups of more than two variables can play a significant role in the analysis and modelling of such systems, yet extracting such high-order interactions from data remains challenging. Here, we introduce a hierarchy of $d$-order ($d \\geq 2$) interaction measures, increasingly inclusive of possible factorisations of the joint probability distribution, and define non-parametric, kernel-based tests to establish systematically the statistical significance of $d$-order interactions. We also establish mathematical links with lattice theory, which elucidate the derivation of the interaction measures and their composite permutation tests; clarify the connection of simplicial complexes with kernel matrix centring; and provide a means to enhance computational efficiency. We illustrate our results numerically with validations on synthetic data, and through an application to neuroimaging data.'}",https://openreview.net{'value': '/pdf/f7d01f3a099b7bcbb8d2d6606e31fdbeeb28bb6f.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=jDIlzSU8wJ,{'value': 'The Surprising Effectiveness of Diffusion Models for Optical Flow and Monocular Depth Estimation'},Saurabh Saxena; Charles Herrmann; Junhwa Hur; Abhishek Kar; Mohammad Norouzi; Deqing Sun; David J. Fleet,~Saurabh_Saxena1; ~Charles_Herrmann1; ~Junhwa_Hur1; ~Abhishek_Kar1; ~Mohammad_Norouzi1; ~Deqing_Sun2; ~David_J._Fleet1,"{'value': ['Monocular depth', 'optical flow', 'diffusion', 'depth', 'flow']}","{'value': ""Denoising diffusion probabilistic models have transformed image generation with their impressive fidelity and diversity.\nWe show that they also excel in estimating optical flow and monocular depth, surprisingly without task-specific architectures and loss functions that are predominant for these tasks. \nCompared to the point estimates of conventional regression-based methods, diffusion models also enable Monte Carlo inference, e.g., capturing uncertainty and ambiguity in flow and depth.\nWith self-supervised pre-training, the combined use of synthetic and real data for supervised training, and technical innovations (infilling and step-unrolled denoising diffusion training) to handle noisy-incomplete training data, one can train state-of-the-art diffusion models for depth and optical flow estimation, with additional zero-shot coarse-to-fine refinement for high resolution estimates. \nExtensive experiments focus on quantitative performance against benchmarks, ablations, and the model's ability to capture uncertainty and multimodality, and impute missing values. Our model obtains a state-of-the-art relative depth error of 0.074 on the indoor NYU benchmark and an Fl-all score of 3.26\\% on the KITTI  optical flow benchmark, about 25\\% better than the best published method.""}",https://openreview.net{'value': '/pdf/a9803ecc1ba03bbc2373e4eda61e4a21987c6093.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=jB4wsc1DQW,{'value': 'Hierarchical Adaptive Value Estimation for Multi-modal Visual Reinforcement Learning'},Yangru Huang; Peixi Peng; Yifan Zhao; Haoran Xu; Mengyue Geng; Yonghong Tian,~Yangru_Huang1; ~Peixi_Peng2; ~Yifan_Zhao2; ~Haoran_Xu5; ~Mengyue_Geng1; ~Yonghong_Tian1,"{'value': ['vision-based reinforcement learning', 'multi-modal', 'event camera']}","{'value': ""Integrating RGB frames with alternative modality inputs is gaining increasing traction in many vision-based reinforcement learning (RL) applications. Existing multi-modal vision-based RL methods usually follow a Global Value Estimation (GVE) pipeline, which uses a fused modality feature to obtain a unified global environmental description. However, such a feature-level fusion paradigm with a single critic may fall short in policy learning as it tends to overlook the distinct values of each modality. To remedy this, this paper proposes a Local modality-customized Value Estimation (LVE) paradigm, which dynamically estimates the contribution and adjusts the importance weight of each modality from a value-level perspective. Furthermore, a task-contextual re-fusion process is developed to achieve a task-level re-balance of estimations from both feature and value levels. To this end, a Hierarchical Adaptive Value Estimation (HAVE) framework is formed, which adaptively coordinates the contributions of individual modalities as well as their collective efficacy. Agents trained by HAVE are able to exploit the unique characteristics of various modalities while capturing their intricate interactions, achieving substantially improved performance. We specifically highlight the potency of our approach within the challenging landscape of autonomous driving, utilizing the CARLA benchmark with neuromorphic event and depth data to demonstrate HAVE's capability and the effectiveness of its distinct components.""}",https://openreview.net{'value': '/pdf/5d2ecae63b5855fa6b068ffcdb39345f94e36fc2.pdf'},{'abstract_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=ixcsBZw5pl,{'value': 'Non-adversarial training of Neural SDEs with signature kernel scores'},Zacharia Issa; Blanka Horvath; Maud Lemercier; Cristopher Salvi,zacharia.issa@kcl.ac.uk; ~Blanka_Horvath1; ~Maud_Lemercier1; ~Cristopher_Salvi1,"{'value': ['Neural SDEs', 'score-based generative models', 'signature kernels', 'time series']}","{'value': 'Neural SDEs are continuous-time generative models for sequential data. State-of-the-art performance for irregular time series generation has been previously obtained by training these models adversarially as GANs. However, as typical for GAN architectures, training is notoriously unstable, often suffers from mode collapse, and requires specialised techniques such as weight clipping and gradient penalty to mitigate these issues. In this paper, we introduce a novel class of scoring rules on pathspace based on signature kernels and use them as objective for training Neural SDEs non-adversarially. By showing strict properness of such kernel scores and consistency of the corresponding estimators, we provide existence and uniqueness guarantees for the minimiser. With this formulation, evaluating the generator-discriminator pair amounts to solving a system of linear path-dependent PDEs which allows for memory-efficient adjoint-based backpropagation. Moreover, because the proposed kernel scores are well-defined for paths with values in infinite dimensional spaces of functions, our framework can be easily extended to generate spatiotemporal data. Our procedure significantly outperforms alternative ways of training Neural SDEs on a variety of tasks including the simulation of rough volatility models, the conditional probabilistic forecasts of real-world forex pairs where the conditioning variable is an observed past trajectory, and the mesh-free generation of limit order book dynamics.'}",https://openreview.net{'value': '/pdf/5b8f1bc4e2337fea43d854302b168c2dfe56d7b7.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=iuqCXg1Gng,{'value': 'Saddle-to-Saddle Dynamics in Diagonal Linear Networks'},Scott Pesme; Nicolas Flammarion,~Scott_Pesme1; ~Nicolas_Flammarion1,"{'value': ['gradient flow', 'saddle-to-saddle', 'diagonal linear network', 'incremental learning']}","{'value': 'In this paper we fully describe the trajectory of gradient flow over $2$-layer diagonal linear networks for the regression setting in the limit of vanishing initialisation. We show that the limiting flow successively jumps from a saddle of the training loss to another until reaching the minimum $\\ell_1$-norm solution. We explicitly characterise the visited saddles as well as the jump times through a recursive algorithm reminiscent of the LARS algorithm used for computing the Lasso path.  Starting from the zero vector, coordinates are successively activated until the minimum $\\ell_1$-norm solution is recovered, revealing an incremental learning. Our proof leverages a convenient arc-length time-reparametrisation which enables to keep track of the transitions between the jumps. Our analysis requires negligible assumptions on the data, applies to both under and overparametrised settings and covers complex cases where there is no monotonicity of the number of active coordinates. We provide numerical experiments to support our findings.'}",https://openreview.net{'value': '/pdf/2076d0adc02feb62e5df2cd9acf0eeabff55a83a.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=igE3Zbxvws,{'value': 'Maximum Independent Set: Self-Training through Dynamic Programming'},Lorenzo Brusca; Lars C.P.M. Quaedvlieg; Stratis Skoulakis; Grigorios Chrysos; Volkan Cevher,~Lorenzo_Brusca1; ~Lars_C.P.M._Quaedvlieg1; ~Stratis_Skoulakis2; ~Grigorios_Chrysos1; ~Volkan_Cevher1,"{'value': ['Maximum Independent Set', 'Combinatorial Optimization', 'Graph Neural Networks', 'Dynamic Programming']}","{'value': 'This work presents a graph neural network (GNN) framework for solving the maximum independent set (MIS) problem, inspired by dynamic programming (DP). Specifically, given a graph, we propose a DP-like recursive algorithm based on GNNs that firstly constructs two smaller sub-graphs, predicts the one with the larger MIS, and then uses it in the next recursive call. To train our algorithm, we require annotated comparisons of different graphs concerning their MIS size. Annotating the comparisons with the output of our algorithm leads to a self-training process that results in more accurate self-annotation of the comparisons and vice versa. We provide numerical evidence showing the superiority of our method vs prior methods in multiple synthetic and real-world datasets.'}",https://openreview.net{'value': '/pdf/4edc3fb16d24ee8aafc168d27152a46b9166dacd.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=iajxrSgOSX,{'value': 'DELIFFAS: Deformable Light Fields for Fast Avatar Synthesis'},YoungJoong Kwon; Lingjie Liu; Henry Fuchs; Marc Habermann; Christian Theobalt,~YoungJoong_Kwon1; ~Lingjie_Liu1; ~Henry_Fuchs1; ~Marc_Habermann1; ~Christian_Theobalt2,"{'value': ['DELIFFAS: Avatar Modeling', 'Avatar Synthesis', 'Animatable Human', 'Light Fields', 'Human Performance Capture']}","{'value': 'Generating controllable and photorealistic digital human avatars is a long-standing and important problem in Vision and Graphics. Recent methods have shown great progress in terms of either photorealism or inference speed while the combination of the two desired properties still remains unsolved. To this end, we propose a novel method, called DELIFFAS, which parameterizes the appearance of the human as a surface light field that is attached to a controllable and deforming human mesh model. At the core, we represent the light field around the human with a deformable two-surface parameterization, which enables fast and accurate inference of the human appearance. This allows perceptual supervision on the full image compared to previous approaches that could only supervise individual pixels or small patches due to their slow runtime. Our carefully designed human representation and supervision strategy leads to state-of-the-art synthesis results and inference time. The video results and code are available at https://vcai.mpi-inf.mpg.de/projects/DELIFFAS.'}",https://openreview.net{'value': '/pdf/0e17977d6d3af2b2a64f89790dc2f7b07d5a76cb.pdf'},{'title_filter': 'Data Synthesis'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=i39yXaUKuF,{'value': 'Segment Any Point Cloud Sequences by Distilling Vision Foundation Models'},Youquan Liu; Lingdong Kong; Jun CEN; Runnan Chen; Wenwei Zhang; Liang Pan; Kai Chen; Ziwei Liu,~Youquan_Liu1; ~Lingdong_Kong1; ~Jun_CEN1; ~Runnan_Chen1; ~Wenwei_Zhang1; ~Liang_Pan2; ~Kai_Chen4; ~Ziwei_Liu1,"{'value': ['autonomous driving', 'point cloud segmentation', 'self-supervised learning', '3D scene understanding']}","{'value': 'Recent advancements in vision foundation models (VFMs) have opened up new possibilities for versatile and efficient visual perception. In this work, we introduce Seal, a novel framework that harnesses VFMs for segmenting diverse automotive point cloud sequences. Seal exhibits three appealing properties: i) Scalability: VFMs are directly distilled into point clouds, obviating the need for annotations in either 2D or 3D during pretraining. ii) Consistency: Spatial and temporal relationships are enforced at both the camera-to-LiDAR and point-to-segment regularization stages, facilitating cross-modal representation learning. iii) Generalizability: Seal enables knowledge transfer in an off-the-shelf manner to downstream tasks involving diverse point clouds, including those from real/synthetic, low/high-resolution, large/small-scale, and clean/corrupted datasets. Extensive experiments conducted on eleven different point cloud datasets showcase the effectiveness and superiority of Seal. Notably, Seal achieves a remarkable 45.0% mIoU on nuScenes after linear probing, surpassing random initialization by 36.9% mIoU and outperforming prior arts by 6.1% mIoU. Moreover, Seal demonstrates significant performance gains over existing methods across 20 different few-shot fine-tuning tasks on all eleven tested point cloud datasets. The code is available at this link.'}",https://openreview.net{'value': '/pdf/7d3d077fa1c2341a156744922bec0648efc4a56a.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=htkdwc6jDB,"{'value': '$p$-value Adjustment for Monotonous, Unbiased, and Fast Clustering Comparison'}",Kai Klede; Thomas Altstidl; Dario Zanca; Bjoern Eskofier,~Kai_Klede1; ~Thomas_Altstidl1; ~Dario_Zanca1; ~Bjoern_Eskofier1,"{'value': ['Clustering', '(Other) Machine Learning Topics']}","{'value': 'Popular metrics for clustering comparison, like the Adjusted Rand Index and the Adjusted Mutual Information, are type II biased. The Standardized Mutual Information removes this bias but suffers from counterintuitive non-monotonicity and poor computational efficiency. We introduce the $p$-value adjusted Rand Index ($\\operatorname{PMI}_2$), the first cluster comparison method that is type II unbiased and provably monotonous. The $\\operatorname{PMI}_2$ has fast approximations that outperform the Standardized Mutual information. We demonstrate its unbiased clustering selection, approximation quality, and runtime efficiency on synthetic benchmarks. In experiments on image and social network datasets, we show how the $\\operatorname{PMI}_2$ can help practitioners choose better clustering and community detection algorithms.'}",https://openreview.net{'value': '/pdf/03aa40ff289424992bd55db9f681bd8702cbc40f.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=htM8yp2EwX,{'value': 'AMDP: An Adaptive Detection Procedure for False Discovery Rate Control in High-Dimensional Mediation Analysis'},Jiarong Ding; Xuehu Zhu,djr9901@stu.xjtu.edu.cn; ~Xuehu_Zhu1,"{'value': ['Mediation analysis', 'Composite null hypothesis', 'Local false discovery rate', 'Optimal ranking rule', 'High-dimensional']}","{'value': 'High-dimensional mediation analysis is often associated with a multiple testing problem for detecting significant mediators. Assessing the uncertainty of this detecting process via false discovery rate (FDR) has garnered great interest. To control the FDR in multiple testing, two essential steps are involved: ranking and selection. Existing approaches either construct p-values without calibration or disregard the joint information across tests, leading to conservation in FDR control or non-optimal ranking rules for multiple hypotheses. In this paper, we develop an adaptive mediation detection procedure (referred to as ""AMDP"") to identify relevant mediators while asymptotically controlling the FDR in high-dimensional mediation analysis. AMDP produces the optimal rule for ranking hypotheses and proposes a data-driven strategy to determine the threshold for mediator selection. This novel method captures information from the proportions of composite null hypotheses and the distribution of p-values, which turns the high dimensionality into an advantage instead of a limitation. The numerical studies on synthetic and real data sets illustrate the performances of AMDP compared with existing approaches.'}",https://openreview.net{'value': '/pdf/cd6d250d84e4259b0e4ad34d1bca7bb04ba2d7a5.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=hLPJ7xLbNF,{'value': 'Self-Supervised Motion Magnification by Backpropagating Through Optical Flow'},Zhaoying Pan; Daniel Geng; Andrew Owens,~Zhaoying_Pan1; ~Daniel_Geng1; ~Andrew_Owens1,"{'value': ['Video Processing', 'Motion Processing', 'Motion Magnification', 'Optical Flow']}","{'value': 'This paper presents a simple, self-supervised method for magnifying subtle motions in video: given an input video and a magnification factor, we manipulate the video such that its new optical flow is scaled by the desired amount. To train our model, we propose a loss function that estimates the optical flow of the generated video and penalizes how far if deviates from the given magnification factor. Thus, training involves differentiating through a pretrained optical flow network. Since our model is self-supervised, we can further improve its performance through test-time adaptation, by finetuning it on the input video. It can also be easily extended to magnify the motions of only user-selected objects. Our approach avoids the need for synthetic magnification datasets that have been used to train prior learning-based approaches. Instead, it leverages the existing capabilities of off-the-shelf motion estimators. We demonstrate the effectiveness of our method through evaluations of both visual quality and quantitative metrics on a range of real-world and synthetic videos, and we show our method works for both supervised and unsupervised optical flow methods.'}",https://openreview.net{'value': '/pdf/42d67d8246ccd9831409386a4e598d59b8a5fc5f.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=h3lTrt4Ftb,{'value': 'Large language models implicitly learn to straighten neural sentence trajectories to construct a predictive representation of natural language.'},Eghbal A. Hosseini; Evelina Fedorenko,~Eghbal_A._Hosseini1; ~Evelina_Fedorenko1,"{'value': ['(Cognitive/Neuroscience) Language', 'Structured Prediction', '(Application) Natural Language and Text Processing']}","{'value': 'Predicting upcoming events is critical to our ability to effectively interact with our\nenvironment and conspecifics. In natural language processing, transformer models,\nwhich are trained on next-word prediction, appear to construct a general-purpose\nrepresentation of language that can support diverse downstream tasks. However, we\nstill lack an understanding of how a predictive objective shapes such representations.\nInspired by recent work in vision neuroscience Hénaff et al. (2019), here we test a\nhypothesis about predictive representations of autoregressive transformer models.\nIn particular, we test whether the neural trajectory of a sequence of words in a\nsentence becomes progressively more straight as it passes through the layers of the\nnetwork. The key insight behind this hypothesis is that straighter trajectories should\nfacilitate prediction via linear extrapolation. We quantify straightness using a 1-\ndimensional curvature metric, and present four findings in support of the trajectory\nstraightening hypothesis: i) In trained models, the curvature progressively decreases\nfrom the first to the middle layers of the network. ii) Models that perform better on\nthe next-word prediction objective, including larger models and models trained on\nlarger datasets, exhibit greater decreases in curvature, suggesting that this improved\nability to straighten sentence neural trajectories may be the underlying driver of\nbetter language modeling performance. iii) Given the same linguistic context, the\nsequences that are generated by the model have lower curvature than the ground\ntruth (the actual continuations observed in a language corpus), suggesting that\nthe model favors straighter trajectories for making predictions. iv) A consistent\nrelationship holds between the average curvature and the average surprisal of\nsentences in the middle layers of models, such that sentences with straighter neural\ntrajectories also have lower surprisal. Importantly, untrained models don’t exhibit\nthese behaviors. In tandem, these results support the trajectory straightening\nhypothesis and provide a possible mechanism for how the geometry of the internal\nrepresentations of autoregressive models supports next word prediction.'}",https://openreview.net{'value': '/pdf/4d626c7f1dcb88b770850efb6a4ac4018266188c.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=guyhQMSp2F,{'value': 'Use perturbations when learning from explanations'},Juyeon Heo; Vihari Piratla; Matthew Robert Wicker; Adrian Weller,~Juyeon_Heo1; ~Vihari_Piratla1; ~Matthew_Robert_Wicker1; ~Adrian_Weller1,"{'value': ['Learning from explanation', 'Robustness', 'Interpretability', 'Shortcuts', 'Explanations']}","{'value': 'Machine learning from explanations (MLX) is an approach to learning that uses human-provided explanations of relevant or irrelevant features for each input to ensure that model predictions are right for the right reasons. Existing MLX approaches rely on local model interpretation methods and require strong model smoothing to align model and human explanations, leading to sub-optimal performance. We recast MLX as a robustness problem, where human explanations specify a lower dimensional manifold from which perturbations can be drawn, and show both theoretically and empirically how this approach alleviates the need for strong model smoothing. We consider various approaches to achieving robustness, leading to improved performance over prior MLX methods. Finally, we show how to combine robustness with an earlier MLX method, yielding state-of-the-art results on both synthetic and real-world benchmarks.'}",https://openreview.net{'value': '/pdf/a4e7f3fccd39bfb2c653e04994c3892f72db381f.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=gf5xJVQS5p,{'value': 'Learning to Configure Separators in Branch-and-Cut'},Sirui Li; Wenbin Ouyang; Max B. Paulus; Cathy Wu,~Sirui_Li1; ~Wenbin_Ouyang1; ~Max_B._Paulus1; ~Cathy_Wu1,"{'value': ['Combinatorial Optimization', 'Branch-and-Cut', 'Learning Guided Optimization', 'Deep Learning']}","{'value': 'Cutting planes are crucial in solving mixed integer linear programs (MILP) as they facilitate bound improvements on the optimal solution. Modern MILP solvers rely on a variety of separators to generate a diverse set of cutting planes by invoking the separators frequently during the solving process. This work identifies that MILP solvers can be drastically accelerated by appropriately selecting separators to activate. As the combinatorial separator selection space imposes challenges for machine learning, we *learn to separate* by proposing a novel data-driven strategy to restrict the selection space and a learning-guided algorithm on the restricted space. Our method predicts instance-aware separator configurations which can dynamically adapt during the solve, effectively accelerating the open source MILP solver SCIP by improving the relative solve time up to 72% and 37% on synthetic and real-world MILP benchmarks. Our work complements recent work on learning to select cutting planes and highlights the importance of separator management.'}",https://openreview.net{'value': '/pdf/91178371d3a990923ca8fd8822844ef19b978cb2.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=gdzxWGGxWE,{'value': 'How do Minimum-Norm Shallow Denoisers Look in Function Space?'},Chen Zeno; Greg Ongie; Yaniv Blumenfeld; Nir Weinberger; Daniel Soudry,~Chen_Zeno1; ~Greg_Ongie1; ~Yaniv_Blumenfeld1; ~Nir_Weinberger1; ~Daniel_Soudry1,"{'value': ['Denoiser', 'Denoising', 'Neural network', 'Function space']}","{'value': 'Neural network (NN) denoisers are an essential building block in many common tasks, ranging from image reconstruction to image generation. However, the success of these models is not well understood from a theoretical perspective. In this paper, we aim to characterize the functions realized by shallow ReLU NN denoisers --- in the common theoretical setting of interpolation (i.e., zero training loss) with a minimal representation cost (i.e., minimal $\\ell^2$ norm weights). First, for univariate data, we derive a closed form for the NN denoiser function, find it is contractive toward the clean data points, and prove it generalizes better than the empirical MMSE estimator at a low noise level. Next, for multivariate data, we find the NN denoiser functions in a closed form under various geometric assumptions on the training data: data contained in a low-dimensional subspace, data contained in a union of one-sided rays, or several types of simplexes. These functions decompose into a sum of simple rank-one piecewise linear interpolations aligned with edges and/or faces connecting training samples. \nWe empirically verify this alignment phenomenon on synthetic data and real images.'}",https://openreview.net{'value': '/pdf/8e26a0cdda08966d4e4d8a5c7a1ba8244b5aaf36.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=gdVcFOvxT3,{'value': 'Finding Safe Zones of Markov Decision Processes Policies'},Lee Cohen; Yishay Mansour; Michal Moshkovitz,~Lee_Cohen1; ~Yishay_Mansour2; ~Michal_Moshkovitz2,"{'value': ['Theoretical guarantees', 'algorithms', 'learning theory', 'MDP', 'computational complexity', 'Interpretability']}","{'value': ""Given a policy of a Markov Decision Process, we define a SafeZone as a subset of states, such that most of the policy's trajectories are confined to this subset. The quality of a SafeZone is parameterized by the number of states and the escape probability, i.e., the probability that a random trajectory will leave the subset. SafeZones are especially interesting when they have a small number of states and low escape probability. We study the complexity of finding optimal SafeZones, and show that in general, the problem is computationally hard. For this reason, we concentrate on finding approximate SafeZones. Our main result is a bi-criteria approximation learning algorithm with a factor of almost $2$  approximation for both the escape probability and \\newprob size, using a polynomial size sample complexity.""}",https://openreview.net{'value': '/pdf/f3b4dbcbe17fd098b592e7aa93b9175f551534b1.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=gbhixjg2dX,{'value': 'Synthetic Combinations: A Causal Inference Framework for Combinatorial Interventions'},Abhineet Agarwal; Anish Agarwal; Suhas Vijaykumar,~Abhineet_Agarwal1; ~Anish_Agarwal1; ~Suhas_Vijaykumar1,"{'value': ['Causal Inference', 'Matrix Completion', 'Combinatorial Learning', 'Ranking']}","{'value': 'We consider a setting where there are $N$ heterogeneous units and $p$ interventions. Our goal is to learn unit-specific potential outcomes for any combination of these $p$ interventions, i.e., $N \\times 2^p$ causal parameters. Choosing a combination of interventions is a problem that naturally arises in a variety of applications such as factorial design experiments and recommendation engines (e.g., showing a set of movies that maximizes engagement for a given user). Running $N \\times 2^p$ experiments to estimate the various parameters is likely expensive and/or infeasible as $N$ and $p$ grow. Further, with observational data there is likely confounding, i.e., whether or not a unit is seen under a combination is correlated with its potential outcome under that combination. We study this problem under a novel model that imposes latent structure across both units and combinations of interventions. Specifically, we assume latent similarity in potential outcomes across units (i.e., the matrix of potential outcomes is approximately rank $r$) and regularity in how combinations of interventions interact (i.e., the coefficients in the Fourier expansion of the potential outcomes is approximately $s$ sparse). We establish identification for all $N \\times 2^p$ parameters despite unobserved confounding. We propose an estimation procedure, Synthetic Combinations, and establish finite-sample consistency under precise conditions on the observation pattern. We show that Synthetic Combinations is able to consistently estimate unit-specific potential outcomes given a total of $\\text{poly}(r) \\times \\left( N + s^2p\\right)$ observations. In comparison, previous methods that do not exploit structure across both units and combinations have poorer sample complexity scaling as $\\min(N \\times s^2p, \\ \\ r \\times (N + 2^p))$.'}",https://openreview.net{'value': '/pdf/e983fc88d3376b4988911b32eaeefaf7ed831997.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=ganlU27uvj,{'value': 'Slot-guided Volumetric Object Radiance Fields'},DI QI; Tong Yang; Xiangyu Zhang,~DI_QI3; ~Tong_Yang2; ~Xiangyu_Zhang1,"{'value': ['3D object-centric representation learning', 'NeRF', '3D-aware slot']}","{'value': 'We present a novel framework for 3D object-centric representation learning. Our approach effectively decomposes complex scenes into individual objects from a single image in an unsupervised fashion. This method, called \\underline{s}lot-guided \\underline{V}olumetric \\underline{O}bject \\underline{R}adiance \\underline{F}ields~(sVORF), composes volumetric object radiance fields with object slots as a guidance to implement unsupervised 3D scene decomposition. Specifically, sVORF obtains object slots from a single image via a transformer module, maps these slots to volumetric object radiance fields with a hypernetwork and composes object radiance fields with the guidance of object slots at a 3D location. Moreover, sVORF significantly reduces memory requirement due to small-sized pixel rendering during training. We demonstrate the effectiveness of our approach by showing top results in scene decomposition and generation tasks of complex synthetic datasets (e.g., Room-Diverse). Furthermore, we also confirm the potential of sVORF to segment objects in real-world scenes (e.g., the LLFF dataset).  We hope our approach can provide preliminary understanding of the physical world and help ease future research in 3D object-centric representation learning.'}",https://openreview.net{'value': '/pdf/ae647900a465a209f2987a08ca3ebe531ec535f6.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=gVLKXT9JwG,{'value': 'Global Convergence Analysis of Local SGD for Two-layer Neural Network without Overparameterization'},Yajie Bao; Amarda Shehu; Mingrui Liu,~Yajie_Bao2; ~Amarda_Shehu1; ~Mingrui_Liu2,"{'value': ['convolutional neural network', 'gaussian input', 'local SGD', 'global convergence', 'non-convex optimization']}","{'value': 'Local SGD, a cornerstone algorithm in federated learning, is widely used in training deep neural networks and shown to have strong empirical performance. A theoretical understanding of such performance on nonconvex loss landscapes is currently lacking. Analysis of the global convergence of SGD is challenging, as the noise depends on the model parameters. Indeed, many works narrow their focus to GD and rely on injecting noise to enable convergence to the local or global optimum. When expanding the focus to local SGD, existing analyses in the nonconvex case can only guarantee finding stationary points or assume the neural network is overparameterized so as to guarantee convergence to the global minimum through neural tangent kernel analysis. In this work, we provide the first global convergence analysis of the vanilla local SGD for two-layer neural networks \\emph{without overparameterization} and \\textit{without injecting noise}, when the input data is Gaussian. The main technical ingredients of our proof are \\textit{a self-correction mechanism} and \\textit{a new exact recursive characterization of the direction of global model parameters}. The self-correction mechanism guarantees the algorithm reaches a good region even if the initialization is in a bad region. A good (bad) region means updating the model by gradient descent will move closer to (away from) the optimal solution. The main difficulty in establishing a self-correction mechanism is to cope with the gradient dependency between two layers. To address this challenge, we divide the landscape of the objective into several regions to carefully control the interference of two layers during the correction process. As a result, we show that local SGD can correct the two layers and enter the good region in polynomial time. After that, we establish a new exact recursive characterization of the direction of global parameters, which is the key to showing convergence to the global minimum with linear speedup in the number of machines and reduced communication rounds. Experiments on synthetic data confirm theoretical results.'}",https://openreview.net{'value': '/pdf/5fb515e31457211cbf4ef4e437935ee7ccf5650c.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=gIG8LvTLuc,{'value': 'How Does Adaptive Optimization Impact Local Neural Network Geometry?'},Kaiqi Jiang; Dhruv Malik; Yuanzhi Li,~Kaiqi_Jiang2; ~Dhruv_Malik1; ~Yuanzhi_Li1,"{'value': ['optimization', 'adaptive algorithms', 'neural networks']}","{'value': 'Adaptive optimization methods are well known to achieve superior convergence relative to vanilla gradient methods. The traditional viewpoint in optimization, particularly in convex optimization, explains this improved performance by arguing that, unlike vanilla gradient schemes, adaptive algorithms mimic the behavior of a second-order method by adapting to the *global* geometry of the loss function. We argue that in the context of neural network optimization, this traditional viewpoint is insufficient. Instead, we advocate for a *local* trajectory analysis. For iterate trajectories produced by running a generic optimization algorithm OPT, we introduce $R^{\\text{OPT}}\\_{\\text{med}}$, a statistic that is analogous to the condition number of the loss Hessian evaluated at the iterates. Through extensive experiments on language models where adaptive algorithms converge faster than vanilla gradient methods like SGD, we show that adaptive methods such as Adam bias the trajectories towards regions where $R^{\\text{Adam}}_{\\text{med}}$ is small, where one might expect faster optimization. By contrast, SGD (with momentum) biases the trajectories towards regions where $R^{\\text{SGD}}\\_{\\text{med}}$ is comparatively large. We complement these empirical observations with a theoretical result that provably demonstrates this phenomenon in the simplified setting of a two-layer linear network. We view our findings as evidence for the need of a new explanation of the success of adaptive methods, one that is different than the conventional wisdom.'}",https://openreview.net{'value': '/pdf/7e0aeaa799ab25fa3e6b3f63055279713297792f.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=gI1SOgW3kw,{'value': 'Generalizing Nonlinear ICA Beyond Structural Sparsity'},Yujia Zheng; Kun Zhang,~Yujia_Zheng1; ~Kun_Zhang1,"{'value': ['Latent variable models', 'nonlinear independent component analysis']}","{'value': 'Nonlinear independent component analysis (ICA) aims to uncover the true latent sources from their observable nonlinear mixtures. Despite its significance, the identifiability of nonlinear ICA is known to be impossible without additional assumptions. Recent advances have proposed conditions on the connective structure from sources to observed variables, known as Structural Sparsity, to achieve identifiability in an unsupervised manner. However, the sparsity constraint may not hold universally for all sources in practice. Furthermore, the assumptions of bijectivity of the mixing process and independence among all sources, which arise from the setting of ICA, may also be violated in many real-world scenarios. To address these limitations and generalize nonlinear ICA, we propose a set of new identifiability results in the general settings of undercompleteness, partial sparsity and source dependence, and flexible grouping structures. Specifically, we prove identifiability when there are more observed variables than sources (undercomplete), and when certain sparsity and/or source independence assumptions are not met for some changing sources. Moreover, we show that even in cases with flexible grouping structures (e.g., part of the sources can be divided into irreducible independent groups with various sizes), appropriate identifiability results can also be established. Theoretical claims are supported empirically on both synthetic and real-world datasets.'}",https://openreview.net{'value': '/pdf/c8cacba57be0e9de38f156a8525e062ef65ed2e7.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=gGl0n7Onug,{'value': 'Theoretical and Practical Perspectives on what Influence Functions Do'},Andrea Schioppa; Katja Filippova; Ivan Titov; Polina Zablotskaia,~Andrea_Schioppa1; ~Katja_Filippova1; ~Ivan_Titov1; ~Polina_Zablotskaia1,"{'value': ['Explainable AI', 'Influence Functions', 'Training Data Attribution']}","{'value': 'Influence functions (IF) have been seen as a technique for explaining model predictions through the lens of the training data. Their utility is assumed to be in identifying training examples ""responsible"" for a prediction so that, for example, correcting a prediction is possible by intervening on those examples (removing or editing them) and retraining the model. However, recent empirical studies have shown that the existing methods of estimating IF predict the leave-one-out-and-retrain effect poorly. \nIn order to understand the mismatch between the theoretical promise and the practical results, we analyse five assumptions made by IF methods which are problematic for modern-scale deep neural networks and which concern convexity, numeric stability, training trajectory and parameter divergence. This allows us to clarify what can be expected theoretically from IF. We show that while most assumptions can be addressed successfully, the parameter divergence poses a clear limitation on the predictive power of IF: influence fades over training time even with deterministic training. We illustrate this theoretical result with BERT and ResNet models.\nAnother conclusion from the theoretical analysis is that IF are still useful for model debugging and correcting even though some of the assumptions made in prior work do not hold: using natural language processing and computer vision tasks, we verify that mis-predictions can be successfully corrected by taking only a few fine-tuning steps on influential examples.'}",https://openreview.net{'value': '/pdf/34caf567fde5797c18facef93cd01b7528443fd8.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=g27BggUT3L,{'value': 'LART: Neural Correspondence Learning with Latent Regularization Transformer for 3D Motion Transfer'},Haoyu Chen; Hao Tang; Radu Timofte; Luc Van Gool; Guoying Zhao,~Haoyu_Chen3; ~Hao_Tang6; ~Radu_Timofte1; ~Luc_Van_Gool1; ~Guoying_Zhao3,"{'value': ['3D motion transfer', '3D Transformer', 'geometric preservation', '3D generation', 'correspondence learning']}","{'value': '3D motion transfer aims at transferring the motion from a dynamic input sequence to a static 3D object and outputs an identical motion of the target with high-fidelity and realistic visual effects. In this work, we propose a novel 3D Transformer framework called LART for 3D motion transfer. With carefully-designed architectures, LART is able to implicitly learn the correspondence via a flexible geometry perception. Thus, unlike other existing methods, LART does not require any key point annotations or pre-defined correspondence between the motion source and target meshes and can also handle large-size full-detailed unseen 3D targets. Besides, we introduce a novel latent metric regularization on the Transformer for better motion generation. Our rationale lies in the observation that the decoded motions can be approximately expressed as linearly geometric distortion at the frame level. The metric preservation of motions could be translated to the formation of linear paths in the underlying latent space as a rigorous constraint to control the synthetic motions occurring in the construction of the latent space. The proposed LART shows a high learning efficiency with the need for a few samples from the AMASS dataset to generate motions with plausible visual effects. The experimental results verify the potential of our generative model in applications of motion transfer, content generation, temporal interpolation, and motion denoising. The code is made available: https://github.com/mikecheninoulu/LART.'}",https://openreview.net{'value': '/pdf/26415c78b69bd9110aa4e44bd2501dc38258b72f.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=fwvfxDbUFw,{'value': 'Learning Score-based Grasping Primitive for Human-assisting Dexterous Grasping'},Tianhao Wu; Mingdong Wu; Jiyao Zhang; Yunchong Gan; Hao Dong,~Tianhao_Wu2; ~Mingdong_Wu1; ~Jiyao_Zhang1; ~Yunchong_Gan1; ~Hao_Dong3,"{'value': ['Human-asissting Dexterous Grasping', 'Score-matching', 'Reinforcement Learning']}","{'value': ""The use of anthropomorphic robotic hands for assisting individuals in situations where human hands may be unavailable or unsuitable has gained significant importance. In this paper, we propose a novel task called human-assisting dexterous grasping that aims to train a policy for controlling a robotic hand's fingers to assist users in grasping objects. Unlike conventional dexterous grasping, this task presents a more complex challenge as the policy needs to adapt to diverse user intentions, in addition to the object's geometry.  We address this challenge by proposing an approach consisting of two sub-modules: a hand-object-conditional grasping primitive called Grasping Gradient Field (GraspGF), and a history-conditional residual policy.  GraspGF learns 'how' to grasp by estimating the gradient of a synthesised success grasping example set, while the residual policy determines 'when' and at what speed the grasping action should be executed based on the trajectory history. Experimental results demonstrate the superiority of our proposed method compared to baselines, highlighting the user-awareness and practicality in real-world applications. The codes and demonstrations can be viewed at https://sites.google.com/view/graspgf.""}",https://openreview.net{'value': '/pdf/ed024a4118d603505c1830547a06339e4473091f.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=frVo9MzRuU,{'value': 'Compositional Abilities Emerge Multiplicatively: Exploring Diffusion Models on a Synthetic Task'},Maya Okawa; Ekdeep Singh Lubana; Robert P. Dick; Hidenori Tanaka,~Maya_Okawa1; ~Ekdeep_Singh_Lubana1; ~Robert_P._Dick1; ~Hidenori_Tanaka1,{'value': ['Diffusion model; Emergence; Emergent capabilities; Science of deep learning; Mechanistic interpretability']},"{'value': 'Modern generative models exhibit unprecedented capabilities to generate extremely realistic data. However, given the inherent compositionality of the real world, reliable use of these models in practical applications requires that they exhibit the capability to compose a novel set of concepts to generate outputs not seen in the training data set. Prior work demonstrates that recent diffusion models do exhibit intriguing compositional generalization abilities, but also fail unpredictably. Motivated by this, we perform a controlled study for understanding compositional generalization in conditional diffusion models in a synthetic setting, varying different attributes of the training data and measuring the model\'s ability to generate samples out-of-distribution. Our results show: (i) the order in which the ability to generate samples from a concept and compose them emerges is governed by the structure of the underlying data-generating process; (ii) performance on compositional tasks exhibits a sudden ""emergence"" due to multiplicative reliance on the performance of constituent tasks, partially explaining emergent phenomena seen in generative models; and (iii) composing concepts with lower frequency in the training data to generate out-of-distribution samples requires considerably more optimization steps compared to generating in-distribution samples. Overall, our study lays a foundation for understanding emergent capabilities and compositionality in generative models from a data-centric perspective.'}",https://openreview.net{'value': '/pdf/25331248e505219bc2c53834c6c14b9861722c14.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=fezV91IJIo,{'value': 'Analysis of Variance of Multiple Causal Networks'},Zhongli Jiang; Dabao Zhang,~Zhongli_Jiang1; ~Dabao_Zhang1,"{'value': ['causal inference', 'large graphs', 'multi-task learning', 'structural model', 'directed cyclic graph']}","{'value': 'Constructing a directed cyclic graph (DCG) is challenged by both algorithmic difficulty and computational burden. Comparing multiple DCGs is even more difficult, compounded by the need to identify dynamic causalities across graphs. We propose to unify multiple DCGs with a single structural model and develop a limited-information-based method to simultaneously construct multiple networks and infer their disparities, which can be visualized by appropriate correspondence analysis. The algorithm provides DCGs with robust non-asymptotic theoretical properties. It is designed with two sequential stages, each of which involves parallel computation tasks that are scalable to the network complexity. Taking advantage of high-performance clusters, our method makes it possible to evaluate the statistical significance of DCGs using the bootstrap method. We demonstrated the effectiveness of our method by applying it to synthetic and real datasets.'}",https://openreview.net{'value': '/pdf/2fb3f27df8bb34ca66cb65d00440f9cc43e3ac2c.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=fTyGT5fulj,{'value': 'Curriculum Learning for Graph Neural Networks: Which Edges Should We Learn First'},Zheng Zhang; Junxiang Wang; Liang Zhao,~Zheng_Zhang10; ~Junxiang_Wang1; ~Liang_Zhao6,"{'value': ['Graph neural networks', 'Curriculum learning', 'Graph structure learning']}","{'value': 'Graph Neural Networks (GNNs) have achieved great success in representing data with dependencies by recursively propagating and aggregating messages along the edges. However, edges in real-world graphs often have varying degrees of difficulty, and some edges may even be noisy to the downstream tasks. Therefore, existing GNNs may lead to suboptimal learned representations because they usually treat every edge in the graph equally. On the other hand, Curriculum Learning (CL), which mimics the human learning principle of learning data samples in a meaningful order, has been shown to be effective in improving the generalization ability and robustness of representation learners by gradually proceeding from easy to more difficult samples during training. Unfortunately, existing CL strategies are designed for independent data samples and cannot trivially generalize to handle data dependencies. To address these issues, we propose a novel CL strategy to gradually incorporate more edges into training according to their difficulty from easy to hard, where the degree of difficulty is measured by how well the edges are expected given the model training status. We demonstrate the strength of our proposed method in improving the generalization ability and robustness of learned representations through extensive experiments on nine synthetic datasets and nine real-world datasets. The code for our proposed method is available at https://github.com/rollingstonezz/Curriculum_learning_for_GNNs'}",https://openreview.net{'value': '/pdf/3e1f5b71faa807c95e92380db9caa5c56af94302.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=fHsBNNDroC,{'value': 'Calibrated Stackelberg Games: Learning Optimal Commitments Against Calibrated Agents'},Nika Haghtalab; Chara Podimata; Kunhe Yang,~Nika_Haghtalab2; ~Chara_Podimata1; ~Kunhe_Yang1,"{'value': ['calibration', 'Stackelberg games', 'learning in repeated games', 'strategic agents', 'best response', 'strategic classification', 'Stackelberg Security Games']}","{'value': ""In this paper, we introduce a generalization of the standard Stackelberg Games (SGs) framework: _Calibrated Stackelberg Games_. In CSGs, a principal repeatedly interacts with an agent who (contrary to standard SGs) does not have direct access to the principal's action but instead best responds to _calibrated forecasts_ about it. CSG is a powerful modeling tool that goes beyond assuming that agents use ad hoc and highly specified algorithms for interacting in strategic settings to infer the principal's actions  and thus more robustly addresses real-life applications that SGs were originally intended to capture. Along with CSGs, we also introduce a stronger notion of calibration, termed _adaptive calibration_, that provides fine-grained any-time calibration guarantees against adversarial sequences. We give a general approach for obtaining adaptive calibration algorithms and specialize them for finite CSGs. In our main technical result, we show that in CSGs, the principal can achieve utility that converges to the optimum Stackelberg value of the game both in _finite_ and _continuous_ settings and that no higher utility is achievable. Two prominent and immediate applications of our results are the settings of learning in Stackelberg Security Games and strategic classification, both against _calibrated_ agents.""}",https://openreview.net{'value': '/pdf/6ff644224053b68293ed51fec87a998c9ea98473.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=fAdMly4ki5,{'value': 'Diffusion Model is an Effective Planner and Data Synthesizer for Multi-Task Reinforcement Learning'},Haoran He; Chenjia Bai; Kang Xu; Zhuoran Yang; Weinan Zhang; Dong Wang; Bin Zhao; Xuelong Li,~Haoran_He1; ~Chenjia_Bai2; ~Kang_Xu2; ~Zhuoran_Yang1; ~Weinan_Zhang1; ~Dong_Wang1; ~Bin_Zhao7; ~Xuelong_Li2,"{'value': ['multi-task reinforcement learning', 'diffusion models', 'planning', 'data synthesis']}","{'value': 'Diffusion models have demonstrated highly-expressive generative capabilities in vision and NLP. Recent studies in reinforcement learning (RL) have shown that diffusion models are also powerful in modeling complex policies or trajectories in offline datasets. However, these works have been limited to single-task settings where a generalist agent capable of addressing multi-task predicaments is absent. In this paper, we aim to investigate the effectiveness of a single diffusion model in modeling large-scale multi-task offline data, which can be challenging due to diverse and multimodal data distribution. Specifically, we propose Multi-Task Diffusion Model (\\textsc{MTDiff}), a diffusion-based method that incorporates Transformer backbones and prompt learning for generative planning and data synthesis in multi-task offline settings. \\textsc{MTDiff} leverages vast amounts of knowledge available in multi-task data and performs implicit knowledge sharing among tasks. For generative planning, we find \\textsc{MTDiff} outperforms state-of-the-art algorithms across 50 tasks on Meta-World and 8 maps on Maze2D. For data synthesis, \\textsc{MTDiff} generates high-quality data for testing tasks given a single demonstration as a prompt, which enhances the low-quality datasets for even unseen tasks.'}",https://openreview.net{'value': '/pdf/4456808a4c1958181dbf1c36aefe0dfced8d4b27.pdf'},{'title_filter': 'Data Synthesis'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=ezqI5WgGvY,{'value': 'CROMA: Remote Sensing Representations with Contrastive Radar-Optical Masked Autoencoders'},Anthony Fuller; Koreen Millard; James R Green,~Anthony_Fuller1; ~Koreen_Millard1; ~James_R_Green1,"{'value': ['Remote Sensing', 'Earth Observation', 'Self-supervised learning', 'Multimodal']}","{'value': 'A vital and rapidly growing application, remote sensing offers vast yet sparsely labeled, spatially aligned multimodal data; this makes self-supervised learning algorithms invaluable. We present CROMA: a framework that combines contrastive and reconstruction self-supervised objectives to learn rich unimodal and multimodal representations. Our method separately encodes masked-out multispectral optical and synthetic aperture radar samples—aligned in space and time—and performs cross-modal contrastive learning. Another encoder fuses these sensors, producing joint multimodal encodings that are used to predict the masked patches via a lightweight decoder. We show that these objectives are complementary when leveraged on spatially aligned multimodal data. We also introduce X- and 2D-ALiBi, which spatially biases our cross- and self-attention matrices. These strategies improve representations and allow our models to effectively extrapolate to images up to $17.6\\times$ larger at test-time. CROMA outperforms the current SoTA multispectral model, evaluated on: four classification benchmarks—finetuning (avg.$\\uparrow$ 1.8%), linear (avg.$\\uparrow$ 2.4%) and nonlinear (avg.$\\uparrow$ 1.4%) probing, $k$NN classification (avg.$\\uparrow$ 3.5%), and $K$-means clustering (avg.$\\uparrow$ 8.4%); and three segmentation benchmarks (avg.$\\uparrow$ 6.4%). CROMA’s rich, optionally multimodal representations can be widely leveraged across remote sensing applications.'}",https://openreview.net{'value': '/pdf/94d52ee159662a75cbd6f0e4ba31dde6c4e16ead.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=etYk6TeO2q,{'value': 'Causal Discovery from Subsampled Time Series with Proxy Variables'},Mingzhou Liu; Xinwei Sun; Lingjing Hu; Yizhou Wang,~Mingzhou_Liu1; ~Xinwei_Sun1; ~Lingjing_Hu1; ~Yizhou_Wang1,"{'value': ['causal discovery', 'time series', 'subsampling', 'proxy variables']}","{'value': 'Inferring causal structures from time series data is the central interest of many scientific inquiries. A major barrier to such inference is the problem of subsampling, *i.e.*, the frequency of measurement is much lower than that of causal influence. To overcome this problem, numerous methods have been proposed, yet either was limited to the linear case or failed to achieve identifiability. In this paper, we propose a constraint-based algorithm that can identify the entire causal structure from subsampled time series, without any parametric constraint. Our observation is that the challenge of subsampling arises mainly from hidden variables at the unobserved time steps. Meanwhile, every hidden variable has an observed proxy, which is essentially itself at some observable time in the future, benefiting from the temporal structure. Based on these, we can leverage the proxies to remove the bias induced by the hidden variables and hence achieve identifiability. Following this intuition, we propose a proxy-based causal discovery algorithm. Our algorithm is nonparametric and can achieve full causal identification. Theoretical advantages are reflected in synthetic and real-world experiments.'}",https://openreview.net{'value': '/pdf/c69595be4c3b6f18469976d0dcea479f36840fbf.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=enfx8HM4Rp,{'value': 'Train Once and Explain Everywhere: Pre-training Interpretable Graph Neural Networks'},Jun Yin; Chaozhuo Li; Hao Yan; Jianxun Lian; Senzhang Wang,~Jun_Yin11; ~Chaozhuo_Li1; ~Hao_Yan6; ~Jianxun_Lian1; ~Senzhang_Wang2,"{'value': ['Intrinsic Interpretability', 'Graph Neural Networks', 'Pre-training and Fine-tuning']}","{'value': 'Intrinsic interpretable graph neural networks aim to provide transparent predictions by identifying the influential fraction of the input graph that guides the model prediction, i.e., the explanatory subgraph. However, current interpretable GNNs mostly are dataset-specific and hard to generalize to different graphs. A more generalizable GNN interpretation model which can effectively distill the universal structural patterns of different graphs is until-now unexplored. Motivated by the great success of recent pre-training techniques, we for the first time propose the Pre-training Interpretable Graph Neural Network ($\\pi$-GNN) to distill the universal interpretability of GNNs by pre-training over synthetic graphs with ground-truth explanations. Specifically, we introduce a structural pattern learning module to extract diverse universal structure patterns and integrate them together to comprehensively represent the graphs of different types. Next, a hypergraph refining module is proposed to identify the explanatory subgraph by incorporating the universal structure patterns with local edge interactions. Finally, the task-specific predictor is cascaded with the pre-trained $\\pi$-GNN model and fine-tuned over downstream tasks. Extensive experiments demonstrate that $\\pi$-GNN significantly surpasses the leading interpretable GNN baselines with up to 9.98\\% interpretation improvement and 16.06\\% classification accuracy improvement. Meanwhile, $\\pi$-GNN pre-trained on graph classification task also achieves the top-tier interpretation performance on node classification task, which further verifies its promising generalization performance among different downstream tasks. Our code and datasets are available at https://anonymous.4open.science/r/PI-GNN-F86C'}",https://openreview.net{'value': '/pdf/6cfc84bfe6bb87d34dc992b7cf2fa1879d92a47b.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=eibTaY6qGI,{'value': 'Resilient Multiple Choice Learning: A learned scoring scheme with application to audio scene analysis'},Victor Letzelter; Mathieu Fontaine; Mickael Chen; Patrick Perez; Slim Essid; Gaël Richard,~Victor_Letzelter1; mathieu.fontaine@telecom-paris.fr; ~Mickael_Chen1; ~Patrick_Perez1; ~Slim_Essid1; ~Gaël_Richard1,"{'value': ['Multiple Choice Learning', 'Audio processing.']}","{'value': 'We introduce Resilient Multiple Choice Learning (rMCL), an extension of the MCL approach for conditional distribution estimation in regression settings where multiple targets may be sampled for each training input.\nMultiple Choice Learning is a simple framework to tackle multimodal density estimation, using the Winner-Takes-All (WTA) loss for a set of hypotheses. In regression settings, the existing MCL variants focus on merging the hypotheses, thereby eventually sacrificing the diversity of the predictions. In contrast, our method relies on a novel learned scoring scheme underpinned by a mathematical framework based on Voronoi tessellations of the output space, from which we can derive a probabilistic interpretation.\nAfter empirically validating rMCL with experiments on synthetic data, we further assess its merits on the sound source localization problem, demonstrating its practical usefulness and the relevance of its interpretation.'}",https://openreview.net{'value': '/pdf/561e034e09160e70848ab803c0ac698ad6d429d2.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=ecRaDicXxw,{'value': 'DiffVL: Scaling Up Soft Body Manipulation using Vision-Language Driven Differentiable Physics'},Zhiao Huang; Feng Chen; Yewen Pu; Chunru Lin; Hao Su; Chuang Gan,~Zhiao_Huang1; ~Feng_Chen16; ~Yewen_Pu1; ~Chunru_Lin1; ~Hao_Su1; ~Chuang_Gan1,{'value': ['Differentiable physics; Soft body manipulation']},"{'value': ""Combining gradient-based trajectory optimization with differentiable physics simulation is an efficient technique for solving soft-body manipulation problems.\nUsing a well-crafted optimization objective, the solver can quickly converge onto a valid trajectory.\nHowever, writing the appropriate objective functions requires expert knowledge, making it difficult to collect a large set of naturalistic problems from non-expert users.\nWe introduce DiffVL, a method that enables non-expert users to communicate soft-body manipulation tasks -- a combination of vision and natural language, given in multiple stages -- that can be readily leveraged by a differential physics solver. \nWe have developed GUI tools that enable non-expert users to specify 100 tasks inspired by real-life soft-body manipulations from online videos, which we'll make public.\nWe leverage large language models to translate task descriptions into machine-interpretable optimization objectives. The optimization objectives can help differentiable physics solvers to solve these long-horizon multistage tasks that are challenging for previous baselines.""}",https://openreview.net{'value': '/pdf/8e78ca917c3abb2a676e0846aee3aae00a1f757b.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=eNhW9UnlGG,{'value': 'Contextual Gaussian Process Bandits with Neural Networks'},Haoting Zhang; Jinghai He; Rhonda Righter; Zuo-Jun Shen; Zeyu Zheng,~Haoting_Zhang2; ~Jinghai_He1; rrighter@berkeley.edu; ~Zuo-Jun_Shen1; ~Zeyu_Zheng2,"{'value': ['contextual bandit', 'Gaussian process', 'neural network']}","{'value': 'Contextual decision-making problems have witnessed extensive applications in various fields such as online content recommendation, personalized healthcare, and autonomous vehicles, where a core practical challenge is to select a suitable surrogate model for capturing unknown complicated reward functions. It is often the case that both high approximation accuracy and explicit uncertainty quantification are desired. In this work, we propose a neural network-accompanied Gaussian process (NN-AGP) model, which leverages neural networks to approximate the unknown and potentially complicated reward function regarding the contextual variable, and maintains a Gaussian process surrogate model with respect to the decision variable. Our model is shown to outperform existing approaches by offering better approximation accuracy thanks to the use of neural networks and possessing explicit uncertainty quantification from the Gaussian process. We also analyze the maximum information gain of the NN-AGP model and prove regret bounds for the corresponding algorithms. Moreover, we conduct experiments on both synthetic and practical problems, illustrating the effectiveness of our approach.'}",https://openreview.net{'value': '/pdf/794899e9064b9d1eb280bf23ec2d29a22edf1ede.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=eCgWNU2Imw,{'value': 'On Sparse Modern Hopfield Model'},Jerry Yao-Chieh Hu; Donglin Yang; Dennis Wu; Chenwei Xu; Bo-Yu Chen; Han Liu,~Jerry_Yao-Chieh_Hu1; ~Donglin_Yang1; ~Dennis_Wu1; ~Chenwei_Xu2; ~Bo-Yu_Chen1; ~Han_Liu4,{'value': ['Hopfield Models; Modern Hopfield Networks; Sparse Attention; Memory Networks']},"{'value': 'We introduce the sparse modern Hopfield model as a sparse extension of the modern Hopfield model.\nLike its dense counterpart, the sparse modern Hopfield model equips a memory-retrieval dynamics whose one-step approximation corresponds to the sparse attention mechanism. \nTheoretically, our key contribution is a principled derivation of a closed-form sparse Hopfield energy using the convex conjugate of the sparse entropic regularizer.\nBuilding upon this, we derive the sparse memory retrieval dynamics from the sparse energy function and show its one-step approximation is equivalent to the sparse-structured attention.\nImportantly, we provide a sparsity-dependent memory retrieval error bound which is provably tighter than its dense analog.\nThe conditions for the benefits of sparsity to arise are therefore identified and discussed.\nIn addition, we show that the sparse modern Hopfield model maintains the robust theoretical properties of its dense counterpart, including rapid fixed point convergence and exponential memory capacity.\nEmpirically, we use both synthetic and real-world datasets to demonstrate that the sparse Hopfield model outperforms its dense counterpart in many situations.'}",https://openreview.net{'value': '/pdf/5fa984447317cfec34881d5aae96c28ca43bd6f2.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=e2aCgjtjMR,{'value': 'Estimating and Controlling for Equalized Odds via Sensitive Attribute Predictors'},Beepul Bharti; Paul Yi; Jeremias Sulam,~Beepul_Bharti1; ~Paul_Yi1; ~Jeremias_Sulam1,"{'value': ['fairness', 'sensitive attributes', 'equalized odds', 'missing data', 'proxies']}","{'value': 'As the use of machine learning models in real world high-stakes decision settings continues to grow, it is highly important that we are able to audit and control for any potential fairness violations these models may exhibit towards certain groups. To do so, one naturally requires access to sensitive attributes, such as demographics, biological sex, or other potentially sensitive features that determine group membership. Unfortunately, in many settings, this information is often unavailable. In this work we study the well known equalized odds (EOD) definition of fairness. In a setting without sensitive attributes, we first provide tight and computable upper bounds for the EOD violation of a predictor. These bounds precisely reflect the worst possible EOD violation. Second, we demonstrate how one can provably control the worst-case EOD by a new post-processing correction method. Our results characterize when directly controlling for EOD with respect to the predicted sensitive attributes is -- and when is not -- optimal when it comes to controlling worst-case EOD. Our results hold under assumptions that are milder than previous works, and we illustrate these results with experiments on synthetic and real datasets.'}",https://openreview.net{'value': '/pdf/4823862347f9b472dceb5348bba53f253a6a5d1d.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=e1oe8F2tjV,{'value': 'Multinomial Logistic Regression: Asymptotic Normality on Null Covariates in High-Dimensions'},Kai Tan; Pierre C Bellec,~Kai_Tan1; ~Pierre_C_Bellec1,"{'value': ['High-dimensional statistics', 'statistical inference', 'multi-class classification', 'asymptotic normality', 'multinomial logistic regression']}","{'value': 'This paper investigates the asymptotic distribution of the maximum-likelihood estimate (MLE) in multinomial logistic models in the high-dimensional regime where dimension and sample size are of the same order. While classical large-sample theory provides asymptotic normality of the MLE under certain conditions, such classical results are expected to fail in high-dimensions as documented for the binary logistic case in the seminal work of Sur and Candès [2019]. We address this issue in classification problems with 3 or more classes, by developing asymptotic normality and asymptotic chi-square results for the multinomial logistic MLE (also known as cross-entropy minimizer) on null covariates. Our theory leads to a new methodology to test the significance of a given feature. Extensive simulation studies on synthetic data corroborate these asymptotic results and confirm the validity of proposed p-values for testing the significance of a given feature.'}",https://openreview.net{'value': '/pdf/1b3c13e5ae9c2cbdcbe076f3d323b32dbb9b1c29.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=e1WgjvFGWp,{'value': 'Large Language Models of Code Fail at Completing Code with Potential Bugs'},Tuan Dinh; Jinman Zhao; Samson Tan; Renato Negrinho; Leonard Lausen; Sheng Zha; George Karypis,~Tuan_Dinh1; ~Jinman_Zhao1; ~Samson_Tan1; ~Renato_Negrinho1; ~Leonard_Lausen1; ~Sheng_Zha1; ~George_Karypis1,{'value': ['language model of code; code completion; language model; software engineering; machine learning for code']},"{'value': 'Large language models of code (Code-LLMs) have recently brought tremendous advances to code completion, a fundamental feature of programming assistance and code intelligence. However, most existing works ignore the possible presence of bugs in the code context for generation, which are inevitable in software development. Therefore, we introduce and study the buggy-code completion problem, inspired by the realistic scenario of real-time code suggestion where the code context contains potential bugs – anti-patterns that can become bugs in the completed program. To systematically study the task, we introduce two datasets: one with synthetic bugs derived from semantics-altering operator changes (buggy-HumanEval) and one with realistic bugs derived from user submissions to coding problems (buggy-FixEval). We find that the presence of potential bugs significantly degrades the generation performance of the high-performing Code-LLMs. For instance, the passing rates of CODEGEN-2B-MONO on test cases of buggy-HumanEval drop more than 50% given a single potential bug in the context. Finally, we investigate several post-hoc methods for mitigating the adverse effect of potential bugs and find that there remains a large gap in post-mitigation performance.'}",https://openreview.net{'value': '/pdf/ef78daebca13249fe003a2ceda19a2977efe6feb.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=dz5X8hnfJc,{'value': 'Characterizing Out-of-Distribution Error via Optimal Transport'},Yuzhe Lu; Yilong Qin; Runtian Zhai; Andrew Shen; Ketong Chen; Zhenlin Wang; Soheil Kolouri; Simon Stepputtis; Joseph Campbell; Katia P. Sycara,~Yuzhe_Lu1; ~Yilong_Qin1; ~Runtian_Zhai1; ~Andrew_Shen1; ~Ketong_Chen1; ~Zhenlin_Wang3; ~Soheil_Kolouri1; ~Simon_Stepputtis1; ~Joseph_Campbell1; ~Katia_P._Sycara1,"{'value': ['Distribution Shift', 'OOD Error Prediction', 'Optimal Transport', 'Deep Learning']}","{'value': ""Out-of-distribution (OOD) data poses serious challenges in deployed machine learning models,\nso methods of predicting a model's performance on OOD data without labels are important for machine learning safety.\nWhile a number of methods have been proposed by prior work, they often underestimate the actual error, sometimes by a large margin, which greatly impacts their applicability to real tasks. In this work, we identify *pseudo-label shift*, or the difference between the predicted and true OOD label distributions, as a key indicator of this underestimation. Based on this observation, we introduce a novel method for estimating model performance by leveraging optimal transport theory, Confidence Optimal Transport (COT), and show that it provably provides more robust error estimates in the presence of pseudo-label shift. Additionally, we introduce an empirically-motivated variant of COT, Confidence Optimal Transport with Thresholding (COTT), which applies thresholding to the individual transport costs and further improves the accuracy of COT's error estimates. We evaluate COT and COTT on a variety of standard benchmarks that induce various types of distribution shift -- synthetic, novel subpopulation, and natural -- and show that our approaches significantly outperform existing state-of-the-art methods with up to 3x lower prediction errors.""}",https://openreview.net{'value': '/pdf/5dfe1b228f1857708a8ac9a3f7ee6f2e8e170f01.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=deaHiTb6Cu,{'value': 'Fast Exact Leverage Score Sampling from Khatri-Rao Products with Applications to Tensor Decomposition'},Vivek Bharadwaj; Osman Asif Malik; Riley Murray; Laura Grigori; Aydin Buluc; James Demmel,~Vivek_Bharadwaj1; ~Osman_Asif_Malik1; ~Riley_Murray1; ~Laura_Grigori1; ~Aydin_Buluc1; ~James_Demmel2,"{'value': ['Tensor Decomposition', 'Leverage Scores', 'Randomized Linear Algebra', 'Sketching', 'Khatri-Rao Product', 'Sparse Tensors']}","{'value': 'We present a data structure to randomly sample rows from the Khatri-Rao product of several matrices according to the exact distribution of its leverage scores. Our proposed sampler draws each row in time logarithmic in the height of the Khatri-Rao product and quadratic in its column count, with persistent space overhead at most the size of the input matrices. As a result, it tractably draws samples even when the matrices forming the Khatri-Rao product have tens of millions of rows each. When used to sketch the linear least-squares problems arising in Candecomp / PARAFAC decomposition, our method achieves lower asymptotic complexity per solve than recent state-of-the-art methods. Experiments on billion-scale sparse tensors and synthetic data validate our theoretical claims, with our algorithm achieving higher accuracy than competing methods as the decomposition rank grows.'}",https://openreview.net{'value': '/pdf/3f37eb26b22a4f2d85c90e345310fcad0f68743c.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=dd3KNayGFz,{'value': 'Differentially Private Decoupled Graph Convolutions for Multigranular Topology Protection'},Eli Chien; Wei-Ning Chen; Chao Pan; Pan Li; Ayfer Ozgur; Olgica Milenkovic,~Eli_Chien1; ~Wei-Ning_Chen1; ~Chao_Pan2; ~Pan_Li2; ~Ayfer_Ozgur1; ~Olgica_Milenkovic1,"{'value': ['Graph Neural Networks', 'Differential Privacy', 'Multigranular Topology Protection']}","{'value': 'Graph Neural Networks (GNNs) have proven to be highly effective in solving real-world learning problems that involve graph-structured data. However, GNNs can also inadvertently expose sensitive user information and interactions through their model predictions. To address these privacy concerns, Differential Privacy (DP) protocols are employed to control the trade-off between provable privacy protection and model utility. Applying standard DP approaches to GNNs directly is not advisable due to two main reasons. First, the prediction of node labels, which relies on neighboring node attributes through graph convolutions, can lead to privacy leakage. Second, in practical applications, the privacy requirements for node attributes and graph topology may differ. In the latter setting, existing DP-GNN models fail to provide multigranular trade-offs between graph topology privacy, node attribute privacy, and GNN utility. To address both limitations, we propose a new framework termed Graph Differential Privacy (GDP), specifically tailored to graph learning. GDP ensures both provably private model parameters as well as private predictions. Additionally, we describe a novel unified notion of graph dataset adjacency to analyze the properties of GDP for different levels of graph topology privacy. Our findings reveal that DP-GNNs, which rely on graph convolutions, not only fail to meet the requirements for multigranular graph topology privacy but also necessitate the injection of DP noise that scales at least linearly with the maximum node degree. In contrast, our proposed Differentially Private Decoupled Graph Convolutions (DPDGCs) represent a more flexible and efficient alternative to graph convolutions that still provides the necessary guarantees of GDP. To validate our approach, we conducted extensive experiments on seven node classification benchmarking and illustrative synthetic datasets. The results demonstrate that DPDGCs significantly outperform existing DP-GNNs in terms of privacy-utility trade-offs.'}",https://openreview.net{'value': '/pdf/76d4d024c63afba5ffbbbb886771bc6ca15968fb.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=dR6p49RYLq,{'value': 'NeuralGF: Unsupervised Point Normal Estimation by Learning Neural Gradient Function'},Qing Li; Huifang Feng; Kanle Shi; Yue Gao; Yi Fang; Yu-Shen Liu; Zhizhong Han,~Qing_Li17; ~Huifang_Feng1; ~Kanle_Shi1; ~Yue_Gao4; ~Yi_Fang2; ~Yu-Shen_Liu1; ~Zhizhong_Han2,"{'value': ['Point Clouds', 'Normal Estimation', 'Neural Gradient']}","{'value': 'Normal estimation for 3D point clouds is a fundamental task in 3D geometry processing. The state-of-the-art methods rely on priors of fitting local surfaces learned from normal supervision. However, normal supervision in benchmarks comes from synthetic shapes and is usually not available from real scans, thereby limiting the learned priors of these methods. In addition, normal orientation consistency across shapes remains difficult to achieve without a separate post-processing procedure. To resolve these issues, we propose a novel method for estimating oriented normals directly from point clouds without using ground truth normals as supervision. We achieve this by introducing a new paradigm for learning neural gradient functions, which encourages the neural network to fit the input point clouds and yield unit-norm gradients at the points. Specifically, we introduce loss functions to facilitate query points to iteratively reach the moving targets and aggregate onto the approximated surface, thereby learning a global surface representation of the data. Meanwhile, we incorporate gradients into the surface approximation to measure the minimum signed deviation of queries, resulting in a consistent gradient field associated with the surface. These techniques lead to our deep unsupervised oriented normal estimator that is robust to noise, outliers and density variations. Our excellent results on widely used benchmarks demonstrate that our method can learn more accurate normals for both unoriented and oriented normal estimation tasks than the latest methods. The source code and pre-trained model are publicly available.'}",https://openreview.net{'value': '/pdf/a1cab732620ba2822de7f31d743f3e07a3c1085b.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=dL0GM9Wwtq,{'value': 'Double and Single Descent in Causal Inference with an Application to High-Dimensional Synthetic Control'},Jann Spiess; Guido Imbens; Amar Venugopal,~Jann_Spiess1; ~Guido_Imbens1; amar.venugopal@stanford.edu,"{'value': ['Double descent', 'interpolating regression', 'synthetic control', 'causal inference']}","{'value': 'Motivated by a recent literature on the double-descent phenomenon in machine learning, we consider highly over-parameterized models in causal inference, including synthetic control with many control units. In such models, there may be so many free parameters that the model fits the training data perfectly. We first investigate high-dimensional linear regression for imputing wage data and estimating average treatment effects, where we find that models with many more covariates than sample size can outperform simple ones. We then document the performance of high-dimensional synthetic control estimators with many control units. We find that adding control units can help improve imputation performance even beyond the point where the pre-treatment fit is perfect. We provide a unified theoretical perspective on the performance of these high-dimensional models. Specifically, we show that more complex models can be interpreted as model-averaging estimators over simpler ones, which we link to an improvement in average performance. This perspective yields concrete insights into the use of synthetic control when control units are many relative to the number of pre-treatment periods.'}",https://openreview.net{'value': '/pdf/f12d968539b559b4f8b165db166dfcccaa97e506.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=dJZ3MvDw86,{'value': 'Data Augmentations for Improved (Large) Language Model Generalization'},Amir Feder; Yoav Wald; Claudia Shi; Suchi Saria; David Blei,~Amir_Feder1; ~Yoav_Wald1; ~Claudia_Shi1; ~Suchi_Saria1; ~David_Blei2,"{'value': ['Counterfactually Augmented Data', 'Invariant Learning', 'Out-of-distribution Generalization', 'Clinical NLP']}","{'value': 'The reliance of text classifiers on spurious correlations can lead to poor generalization at deployment, raising concerns about their use in safety-critical domains such as healthcare. In this work, we propose to use counterfactual data augmentation, guided by knowledge of the causal structure of the data, to simulate interventions on spurious features and to learn more robust text classifiers. We show that this strategy is appropriate in prediction problems where the label is spuriously correlated with an attribute. Under the assumptions of such problems, we discuss the favorable sample complexity of counterfactual data augmentation, compared to importance re-weighting. Pragmatically, we match examples using auxiliary data, based on diff-in-diff methodology, and use a large language model (LLM) to represent a conditional probability of text. Through extensive experimentation on learning caregiver-invariant predictors of clinical diagnoses from medical narratives and on semi-synthetic data, we demonstrate that our method for simulating interventions improves out-of-distribution (OOD) accuracy compared to baseline invariant learning algorithms.'}",https://openreview.net{'value': '/pdf/3da2e9b58620b7cf6de7af10f6bc40fadc37f477.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=crZlhMnfeO,{'value': 'RayDF: Neural Ray-surface Distance Fields with Multi-view Consistency'},Zhuoman Liu; Bo Yang; Yan Luximon; Ajay Kumar; Jinxi Li,~Zhuoman_Liu1; ~Bo_Yang7; ~Yan_Luximon1; ~Ajay_Kumar2; ~Jinxi_Li2,"{'value': ['implicit shape representations', 'multi-view consistency', 'novel view synthesis']}","{'value': 'In this paper, we study the problem of continuous 3D shape representations. The majority of existing successful methods are coordinate-based implicit neural representations. However, they are inefficient to render novel views or recover explicit surface points. A few works start to formulate 3D shapes as ray-based neural functions, but the learned structures are inferior due to the lack of multi-view geometry consistency. To tackle these challenges, we propose a new framework called RayDF. It consists of three major components: 1) the simple ray-surface distance field, 2) the novel dual-ray visibility classifier, and 3) a multi-view consistency optimization module to drive the learned ray-surface distances to be multi-view geometry consistent. We extensively evaluate our method on three public datasets, demonstrating remarkable performance in 3D surface point reconstruction on both synthetic and challenging real-world 3D scenes, clearly surpassing existing coordinate-based and ray-based baselines. Most notably, our method achieves a 1000x faster speed than coordinate-based methods to render an 800x800 depth image, showing the superiority of our method for 3D shape representation. Our code and data are available at https://github.com/vLAR-group/RayDF'}",https://openreview.net{'value': '/pdf/e761dfd51f31946a39cc34121df8c01d8e9c72cb.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=cnpkzQZaLU,{'value': 'Context-PIPs: Persistent Independent Particles Demands Spatial Context Features'},Weikang BIAN; Zhaoyang Huang; Xiaoyu Shi; Yitong Dong; Yijin Li; Hongsheng Li,~Weikang_BIAN1; ~Zhaoyang_Huang2; ~Xiaoyu_Shi1; ~Yitong_Dong1; ~Yijin_Li1; ~Hongsheng_Li3,{'value': ['Point Tracking; Optical Flow; Video Correspondence; Computer Vision;']},"{'value': 'We tackle the problem of Persistent Independent Particles (PIPs), also called Tracking Any Point (TAP), in videos, which specifically aims at estimating persistent long-term trajectories of query points in videos. Previous methods attempted to estimate these trajectories independently to incorporate longer image sequences, therefore, ignoring the potential benefits of incorporating spatial context features. \nWe argue that independent video point tracking also demands spatial context features. To this end, we propose a novel framework Context-PIPs, which effectively improves point trajectory accuracy by aggregating spatial context features in videos. Context-PIPs contains two main modules: 1) a SOurse Feature Enhancement (SOFE) module, and 2) a TArget Feature Aggregation (TAFA) module. Context-PIPs significantly improves PIPs all-sided, reducing 11.4\\% Average Trajectory Error of Occluded Points (ATE-Occ) on CroHD and increasing 11.8\\% Average Percentage of Correct Keypoint (A-PCK) on TAP-Vid-Kinetics. Demos are available at \\url{https://wkbian.github.io/Projects/Context-PIPs/}.'}",https://openreview.net{'value': '/pdf/0d762366dd6b0305889c0f0bcd27748a0332162a.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=cANkPsVtsw,{'value': 'Characterization and Learning of Causal Graphs with Small Conditioning Sets'},Murat Kocaoglu,~Murat_Kocaoglu1,{'value': ['causal discovery']},"{'value': 'Constraint-based causal discovery algorithms learn part of the causal graph structure by systematically testing conditional independences  observed in the data. These algorithms, such as the PC algorithm and its variants, rely on graphical characterizations of the so-called equivalence class of causal graphs proposed by Pearl. However, constraint-based causal discovery algorithms struggle when data is limited since conditional independence tests quickly lose their statistical power, especially when the conditioning set is large. To address this, we propose using conditional independence tests where the size of the conditioning set is upper bounded by some integer k for robust causal discovery. The existing graphical characterizations of the equivalence classes of causal graphs are not applicable when we cannot leverage all the conditional independence statements. We first define the notion of k-Markov equivalence: Two causal graphs are k-Markov equivalent if they entail the same conditional independence constraints where the conditioning set size is upper bounded by k. We propose a novel representation that allows us to graphically characterize k-Markov equivalence between two causal graphs. We propose a sound constraint-based algorithm called the k-PC algorithm for learning this equivalence class. Finally, we conduct synthetic, and semi-synthetic experiments to demonstrate that the k-PC algorithm enables more robust causal discovery in the small sample regime compared to the baseline algorithms.'}",https://openreview.net{'value': '/pdf/40bd359547c2f4abd9924d2c4d41cc87b817403c.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=c9fXCzR5fK,{'value': 'Sequential Subset Matching for Dataset Distillation'},Jiawei Du; Qin Shi; Joey Tianyi Zhou,~Jiawei_Du1; ~Qin_Shi2; ~Joey_Tianyi_Zhou1,"{'value': ['Dataset distillation', 'gradients matching']}","{'value': 'Dataset distillation is a newly emerging task that synthesizes a small-size dataset used in training deep neural networks (DNNs) for reducing data storage and model training costs. The synthetic datasets are expected to capture the essence of the knowledge contained in real-world datasets such that the former yields a similar performance as the latter. Recent advancements in distillation methods have produced notable improvements in generating synthetic datasets. However, current state-of-the-art methods treat the entire synthetic dataset as a unified entity and optimize each synthetic instance equally . This static optimization approach may lead to performance degradation in dataset distillation. \nSpecifically, we argue that static optimization can give rise to a coupling issue within the synthetic data, particularly when a larger amount of synthetic data is being optimized. This coupling issue, in turn, leads to the failure of the distilled dataset to extract the high-level features learned by the deep neural network (DNN) in the latter epochs.\nIn this study, we propose a new dataset distillation strategy called Sequential Subset Matching (SeqMatch), which tackles this problem by adaptively optimizing the synthetic data to encourage sequential acquisition of knowledge during dataset distillation. Our analysis indicates that SeqMatch effectively addresses the coupling issue by sequentially generating the synthetic instances, thereby enhancing its performance significantly. Our proposed SeqMatch outperforms state-of-the-art methods in various datasets, including SVNH, CIFAR-10, CIFAR-100, and Tiny ImageNet.'}",https://openreview.net{'value': '/pdf/a305925284b21726184d189947d646a471acc6e3.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=c5WOU7p4ES,{'value': 'PLASTIC: Improving Input and Label Plasticity for Sample Efficient Reinforcement Learning'},Hojoon Lee; Hanseul Cho; Hyunseung Kim; Daehoon Gwak; Joonkee Kim; Jaegul Choo; Se-Young Yun; Chulhee Yun,~Hojoon_Lee1; ~Hanseul_Cho1; ~Hyunseung_Kim1; ~Daehoon_Gwak1; ~Joonkee_Kim1; ~Jaegul_Choo1; ~Se-Young_Yun1; ~Chulhee_Yun1,"{'value': ['Reinforcement Learning', 'Sharpness Minimization', 'Generalization', 'Plasticity', 'Deep Learning']}","{'value': ""In Reinforcement Learning (RL), enhancing sample efficiency is crucial, particularly in scenarios when data acquisition is costly and risky. In principle, off-policy RL algorithms can improve sample efficiency by allowing multiple updates per environment interaction. However, these multiple updates often lead the model to overfit to earlier interactions, which is referred to as the loss of plasticity. Our study investigates the underlying causes of this phenomenon by dividing plasticity into two aspects. Input plasticity, which denotes the model's adaptability to changing input data, and label plasticity, which denotes the model's adaptability to evolving input-output relationships. Synthetic experiments on the CIFAR-10 dataset reveal that finding smoother minima of loss landscape enhances input plasticity, whereas refined gradient propagation improves label plasticity. Leveraging these findings, we introduce the **PLASTIC** algorithm, which harmoniously combines techniques to address both concerns. With minimal architectural modifications, PLASTIC achieves competitive performance on benchmarks including Atari-100k and Deepmind Control Suite. This result emphasizes the importance of preserving the model's plasticity to elevate the sample efficiency in RL. The code is available at https://github.com/dojeon-ai/plastic.""}",https://openreview.net{'value': '/pdf/f3ae9b406bd3fb1f4b4476cb648e41c4c8d0c3a0.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=bzXpQUnule,{'value': 'Federated Linear Bandits with Finite Adversarial Actions'},Li Fan; Ruida Zhou; Chao Tian; Cong Shen,~Li_Fan5; ~Ruida_Zhou1; ~Chao_Tian2; ~Cong_Shen1,"{'value': ['Federated bandits', 'contextual bandits', 'regret analysis']}","{'value': 'We study a federated linear bandits model, where $M$ clients communicate with a central server to solve a linear contextual bandits problem with finite adversarial action sets that may be different across clients. To address the unique challenges of **adversarial finite** action sets, we propose the FedSupLinUCB algorithm, which extends the principles of SupLinUCB and OFUL algorithms in linear contextual bandits. We prove that FedSupLinUCB achieves a total regret of $\\tilde{O}(\\sqrt{d T})$, where $T$ is the total number of arm pulls from all clients, and $d$ is the ambient dimension of the linear model. This matches the minimax lower bound and thus is order-optimal (up to polylog terms). We study both asynchronous and synchronous cases and show that the communication cost can be controlled as $O(d M^2 \\log(d)\\log(T))$ and $O(\\sqrt{d^3 M^3} \\log(d))$, respectively. The FedSupLinUCB design is further extended to two scenarios: (1) variance-adaptive, where a total regret of $\\tilde{O} (\\sqrt{d \\sum \\nolimits_{t=1}^{T} \\sigma_t^2})$ can be achieved with $\\sigma_t^2$ being the noise variance of round $t$; and (2) adversarial corruption, where a total regret of $\\tilde{O}(\\sqrt{dT} + d C_p)$ can be achieved with $C_p$ being the total corruption budget. Experiment results corroborate the theoretical analysis and demonstrate the effectiveness of \\alg on both synthetic and real-world datasets.'}",https://openreview.net{'value': '/pdf/bb25c64a9b239ef6c9a1893a809e563f796a410f.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=bv9mmH0LGF,{'value': 'Global Structure-Aware Diffusion Process for Low-light Image Enhancement'},Jinhui HOU; Zhiyu Zhu; Junhui Hou; Hui LIU; Huanqiang Zeng; Hui Yuan,~Jinhui_HOU1; ~Zhiyu_Zhu1; ~Junhui_Hou2; ~Hui_LIU14; ~Huanqiang_Zeng1; ~Hui_Yuan1,"{'value': ['Image enhancement', 'diffusion models']}","{'value': 'This paper studies a diffusion-based framework to address the low-light image enhancement problem. To harness the capabilities of diffusion models, we delve into this intricate process and advocate for the regularization of its inherent ODE-trajectory. To be specific, inspired by the recent research that low curvature ODE-trajectory results in a stable and effective diffusion process, we formulate a curvature regularization term anchored in the intrinsic non-local structures of image data, i.e., global structure-aware regularization, which gradually facilitates the preservation of complicated details and the augmentation of contrast during the diffusion process. This incorporation mitigates the adverse effects of noise and artifacts resulting from the diffusion process, leading to a more precise and flexible enhancement. To additionally promote learning in challenging regions, we introduce an uncertainty-guided regularization technique, which wisely relaxes constraints on the most extreme regions of the image. Experimental evaluations reveal that the proposed diffusion-based framework, complemented by rank-informed regularization, attains distinguished performance in low-light enhancement. The outcomes indicate substantial advancements in image quality, noise suppression, and contrast amplification in comparison with state-of-the-art methods. We believe this innovative approach will stimulate further exploration and advancement in low-light image processing, with potential implications for other applications of diffusion models. The code is publicly available at https://github.com/jinnh/GSAD.'}",https://openreview.net{'value': '/pdf/633f0937fc37740f3d30a982adae94b87ce88fcd.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=bpmM6SkDUy,{'value': 'EDGI: Equivariant Diffusion for Planning with Embodied Agents'},Johann Brehmer; Joey Bose; Pim De Haan; Taco Cohen,~Johann_Brehmer1; ~Joey_Bose1; ~Pim_De_Haan1; ~Taco_Cohen1,"{'value': ['Planning', 'Diffusion models', 'Equivariance', 'Equivariant generative models']}","{'value': 'Embodied agents operate in a structured world, often solving tasks with spatial, temporal, and permutation symmetries. Most algorithms for planning and model-based reinforcement learning (MBRL) do not take this rich geometric structure into account, leading to sample inefficiency and poor generalization. We introduce the Equivariant Diffuser for Generating Interactions (EDGI), an algorithm for MBRL and planning that is equivariant with respect to the product of the spatial symmetry group SE(3), the discrete-time translation group ℤ, and the object permutation group Sₙ. EDGI follows the Diffuser framework by Janner et al. (2022) in treating both learning a world model and planning in it as a conditional generative modeling problem, training a diffusion model on an offline trajectory dataset. We introduce a new SE(3) × ℤ × Sₙ-equivariant diffusion model that supports multiple representations. We integrate this model in a planning loop, where conditioning and classifier guidance let us softly break the symmetry for specific tasks as needed. On object manipulation and navigation tasks, EDGI is substantially more sample efficient and generalizes better across the symmetry group than non-equivariant models.'}",https://openreview.net{'value': '/pdf/1fbba77049c62a9573302e3d761a841d38e952ae.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=blC2kbzvNC,{'value': 'Adaptive SGD with Polyak stepsize and Line-search: Robust Convergence and Variance Reduction'},Xiaowen Jiang; Sebastian U Stich,~Xiaowen_Jiang1; ~Sebastian_U_Stich1,"{'value': ['Convex Optimization', 'SGD', 'Adaptive Methods', 'Variance Reduction', 'Polyak Stepsize', 'Line-Search']}","{'value': 'The recently proposed stochastic Polyak stepsize (SPS) and stochastic line-search (SLS) for SGD have shown remarkable effectiveness when training over-parameterized models. However, two issues remain unsolved in this line of work. \n\nFirst, in non-interpolation settings, both algorithms only guarantee convergence to a neighborhood of a solution which may result in a worse output than the initial guess. While artificially decreasing the adaptive stepsize has been proposed to address this issue (Orvieto et al.), this approach results in slower convergence rates under interpolation. Second, intuitive line-search methods equipped with variance-reduction (VR) fail to converge (Dubois-Taine et al.). So far, no VR methods successfully accelerate these two stepsizes with a convergence guarantee.\n\nIn this work, we make two contributions:\nFirstly, we propose two new robust variants of SPS and SLS, called AdaSPS and AdaSLS, which achieve optimal asymptotic rates in both strongly-convex or convex and interpolation or non-interpolation settings, except for the case when we have both strong convexity and non-interpolation. AdaSLS requires no knowledge of problem-dependent parameters, and AdaSPS requires only a lower bound of the optimal function value as input. Secondly, we propose a novel VR method that can use Polyak stepsizes or line-search to achieve acceleration. When it is equipped with AdaSPS or AdaSLS, the resulting algorithms obtain the optimal rate\nfor optimizing convex smooth functions. Finally, numerical experiments on synthetic and real datasets validate our theory and demonstrate the effectiveness and robustness of our algorithms.'}",https://openreview.net{'value': '/pdf/7b6a59babc1d365f2e5bc21419781dd18c3837eb.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=bTidcHIK2t,{'value': 'Sample-Efficient and Safe Deep Reinforcement Learning via Reset Deep Ensemble Agents'},Woojun Kim; Yongjae Shin; Jongeui Park; Youngchul Sung,~Woojun_Kim1; ~Yongjae_Shin1; ~Jongeui_Park1; ~Youngchul_Sung1,"{'value': ['deep reinforcement learning', 'primacy bais', 'reset', 'deep ensemble learning']}","{'value': 'Deep reinforcement learning (RL) has achieved remarkable success in solving complex tasks through its integration with deep neural networks (DNNs) as function approximators. However, the reliance on DNNs has introduced a new challenge called primacy bias, whereby these function approximators tend to prioritize early experiences, leading to overfitting. To alleviate this bias, a reset method has been proposed, which involves periodic resets of a portion or the entirety of a deep RL agent while preserving the replay buffer. However, the use of this method can result in performance collapses after executing the reset, raising concerns from the perspective of safe RL and regret minimization. In this paper, we propose a novel reset-based method that leverages deep ensemble learning to address the limitations of the vanilla reset method and enhance sample efficiency. The effectiveness of the proposed method is validated through various experiments including those in the domain of safe RL. Numerical results demonstrate its potential for real-world applications requiring high sample efficiency and safety considerations.'}",https://openreview.net{'value': '/pdf/8fb96c65539c5ae4b7cbbab1b832450820a23e0d.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=bNNIf8F9OU,{'value': 'Empowering Collaborative Filtering with Principled Adversarial Contrastive Loss'},An Zhang; Leheng Sheng; Zhibo Cai; Xiang Wang; Tat-Seng Chua,~An_Zhang2; ~Leheng_Sheng2; ~Zhibo_Cai1; ~Xiang_Wang6; ~Tat-Seng_Chua2,"{'value': ['Collaborative filtering', 'Contrastive loss', 'Recommendation', 'Generalization ability']}","{'value': 'Contrastive Learning (CL) has achieved impressive performance in self-supervised learning tasks, showing superior generalization ability. Inspired by the success, adopting CL into collaborative filtering (CF) is prevailing in semi-supervised topK recommendations. The basic idea is to routinely conduct heuristic-based data augmentation and apply contrastive losses (e.g., InfoNCE) on the augmented views. Yet, some CF-tailored challenges make this adoption suboptimal, such as the issue of out-of-distribution, the risk of false negatives, and the nature of top-K evaluation. They necessitate the CL-based CF scheme to focus more on mining hard negatives and distinguishing false negatives from the vast unlabeled user-item interactions, for informative contrast signals. Worse still, there is limited understanding of contrastive loss in CF methods, especially w.r.t. its generalization ability. To bridge the gap, we delve into the reasons underpinning the success of contrastive loss in CF, and propose a principled Adversarial InfoNCE loss (AdvInfoNCE), which is a variant of InfoNCE, specially tailored for CF methods. AdvInfoNCE adaptively explores and assigns hardness to each negative instance in an adversarial fashion and further utilizes a fine-grained hardness-aware ranking criterion to empower the recommender’s generalization ability. Training CF models with AdvInfoNCE, we validate the effectiveness of AdvInfoNCE on both synthetic and real-world benchmark datasets, thus showing its generalization ability to mitigate out-of-distribution problems. Given the theoretical guarantees and empirical superiority of AdvInfoNCE over most contrastive loss functions, we advocate its adoption as a standard loss in recommender systems, particularly for the out-of-distribution tasks. Codes are available at https://github.com/LehengTHU/AdvInfoNCE.'}",https://openreview.net{'value': '/pdf/fc59dd264ba52092dea608e587d887e9791866f0.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=bM6mynsusR,{'value': 'Function Space Bayesian Pseudocoreset for Bayesian Neural Networks'},Balhae Kim; Hyungi Lee; Juho Lee,~Balhae_Kim1; ~Hyungi_Lee1; ~Juho_Lee2,"{'value': ['Bayesian pseudocoresets', 'Function space variational inference']}","{'value': 'A Bayesian pseudocoreset is a compact synthetic dataset summarizing essential information of a large-scale dataset and thus can be used as a proxy dataset for scalable Bayesian inference. Typically, a Bayesian pseudocoreset is constructed by minimizing a divergence measure between the posterior conditioning on the pseudocoreset and the posterior conditioning on the full dataset. However, evaluating the divergence can be challenging, particularly for the models like deep neural networks having high-dimensional parameters. In this paper, we propose a novel Bayesian pseudocoreset construction method that operates on a function space. Unlike previous methods, which construct and match the coreset and full data posteriors in the space of model parameters (weights), our method constructs variational approximations to the coreset posterior on a function space and matches it to the full data posterior in the function space. By working directly on the function space, our method could bypass several challenges that may arise when working on a weight space, including limited scalability and multi-modality issue. Through various experiments, we demonstrate that the Bayesian pseudocoresets constructed from our method enjoys enhanced uncertainty quantification and better robustness across various model architectures.'}",https://openreview.net{'value': '/pdf/92b60997adf6e44155c91b8d3a7869c98a37cee4.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=b60wLlkBta,{'value': 'On the Robustness of Removal-Based Feature Attributions'},Chris Lin; Ian Connick Covert; Su-In Lee,~Chris_Lin1; ~Ian_Connick_Covert1; ~Su-In_Lee2,"{'value': ['explainable artificial intelligence', 'interpretable machine learning', 'feature attributions', 'removal-based feature attributions', 'robustness']}","{'value': 'To explain predictions made by complex machine learning models, many feature attribution methods have been developed that assign importance scores to input features. Some recent work challenges the robustness of these methods by showing that they are sensitive to input and model perturbations, while other work addresses this issue by proposing robust attribution methods. However, previous work on attribution robustness has focused primarily on gradient-based feature attributions, whereas the robustness of removal-based attribution methods is not currently well understood. To bridge this gap, we theoretically characterize the robustness properties of removal-based feature attributions. Specifically, we provide a unified analysis of such methods and derive upper bounds for the difference between intact and perturbed attributions, under settings of both input and model perturbations. Our empirical results on synthetic and real-world data validate our theoretical results and demonstrate their practical implications, including the ability to increase attribution robustness by improving the model’s Lipschitz regularity.'}",https://openreview.net{'value': '/pdf/b5cee429cd6a9ccadf51aa1f36e11e09927b72b2.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=aw1vLo7TE7,{'value': 'Risk-Averse Active Sensing for Timely Outcome Prediction under Cost Pressure'},Yuchao Qin; Mihaela van der Schaar; Changhee Lee,~Yuchao_Qin1; ~Mihaela_van_der_Schaar2; ~Changhee_Lee1,"{'value': ['active sensing', 'value of information', 'risk-averse learning']}","{'value': ""Timely outcome prediction is essential in healthcare to enable early detection and intervention of adverse events. However, in longitudinal follow-ups to patients' health status, cost-efficient acquisition of patient covariates is usually necessary due to the significant expense involved in screening and lab tests. To balance the timely and accurate outcome predictions with acquisition costs, an effective active sensing strategy is crucial. In this paper, we propose a novel risk-averse active sensing approach RAS that addresses the composite decision problem of when to conduct the acquisition and which measurements to make. Our approach decomposes the policy into two sub-policies: acquisition scheduler and feature selector, respectively. Moreover, we introduce a novel risk-aversion training strategy to focus on the underrepresented subgroup of high-risk patients for whom timely and accurate prediction of disease progression is of greater value. Our method outperforms baseline active sensing approaches in experiments with both synthetic and real-world datasets, and we illustrate the significance of our policy decomposition and the necessity of a risk-averse sensing policy through case studies.""}",https://openreview.net{'value': '/pdf/2f61cd3fad06b099f3895a2a5145d5adf5c98758.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=aky0dKv9ip,{'value': 'Decompose a Task into Generalizable Subtasks in Multi-Agent Reinforcement Learning'},Zikang Tian; Ruizhi Chen; Xing Hu; Ling Li; Rui Zhang; Fan Wu; Shaohui Peng; Jiaming Guo; Zidong Du; Qi Guo; Yunji Chen,~Zikang_Tian1; ~Ruizhi_Chen3; ~Xing_Hu3; ~Ling_Li6; ~Rui_Zhang1; ~Fan_Wu11; ~Shaohui_Peng2; ~Jiaming_Guo2; ~Zidong_Du1; ~Qi_Guo4; ~Yunji_Chen1,"{'value': ['Multi-Agent Reinforcement Learning', 'Transfer Learning', 'Zero-Shot Generalization']}","{'value': 'In recent years, Multi-Agent Reinforcement Learning (MARL) techniques have made significant strides in achieving high asymptotic performance in single task. However, there has been limited exploration of model transferability across tasks. Training a model from scratch for each task can be time-consuming and expensive, especially for large-scale Multi-Agent Systems. Therefore, it is crucial to develop methods for generalizing the model across tasks. Considering that there exist task-independent subtasks across MARL tasks, a model that can decompose such subtasks from the source task could generalize to target tasks. However, ensuring true task-independence of subtasks poses a challenge. In this paper, we propose to \\textbf{d}ecompose a \\textbf{t}ask in\\textbf{to} a series of \\textbf{g}eneralizable \\textbf{s}ubtasks (DT2GS), a novel framework that addresses this challenge by utilizing a scalable subtask encoder and an adaptive subtask semantic module. We show that these components endow subtasks with two properties critical for task-independence: avoiding overfitting to the source task and maintaining consistent yet scalable semantics across tasks. Empirical results demonstrate that DT2GS possesses sound zero-shot generalization capability across tasks, exhibits sufficient transferability, and outperforms existing methods in both multi-task and single-task problems.'}",https://openreview.net{'value': '/pdf/8c0b780c17b5d39ece285b1e0c09028e642644cb.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=afKnrwJBAl,{'value': 'Cross-Episodic Curriculum for Transformer Agents'},Lucy Xiaoyang Shi; Yunfan Jiang; Jake Grigsby; Linxi Fan; Yuke Zhu,~Lucy_Xiaoyang_Shi1; ~Yunfan_Jiang1; ~Jake_Grigsby1; ~Linxi_Fan2; ~Yuke_Zhu1,"{'value': ['Transformers', 'In-context Learning', 'Reinforcement Learning', 'Robotics']}","{'value': ""We present a new algorithm, Cross-Episodic Curriculum (CEC), to boost the learning efficiency and generalization of Transformer agents. Central to CEC is the placement of cross-episodic experiences into a Transformer’s context, which forms the basis of a curriculum. By sequentially structuring online learning trials and mixed-quality demonstrations, CEC constructs curricula that encapsulate learning progression and proficiency increase across episodes. Such synergy combined with the potent pattern recognition capabilities of Transformer models delivers a powerful cross-episodic attention mechanism. The effectiveness of CEC is demonstrated under two representative scenarios: one involving multi-task reinforcement learning with discrete control, such as in DeepMind Lab, where the curriculum captures the learning progression in both individual and progressively complex settings; and the other involving imitation learning with mixed-quality data for continuous control, as seen in RoboMimic, where the curriculum captures the improvement in demonstrators' expertise. In all instances, policies resulting from CEC exhibit superior performance and strong generalization. Code is open-sourced on the project website https://cec-agent.github.io/ to facilitate research on Transformer agent learning.""}",https://openreview.net{'value': '/pdf/fce810149a981354afad34f9f90063e7674fb0a6.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=aZ44Na3l9p,{'value': 'Reproducibility in Multiple Instance Learning: A Case For Algorithmic Unit Tests'},Edward Raff; James Holt,~Edward_Raff1; ~James_Holt1,{'value': ['reproducibility; multiple instance learning']},"{'value': 'Multiple Instance Learning (MIL) is a sub-domain of classification problems with positive and negative labels and a ""bag"" of inputs, where the label is positive if and only if a positive element is contained within the bag, and otherwise is negative. Training in this context requires associating the bag-wide label to instance-level information, and implicitly contains a causal assumption and asymmetry to the task (i.e., you can\'t swap the labels without changing the semantics). MIL problems occur in healthcare (one malignant cell indicates cancer), cyber security (one malicious executable makes an infected computer), and many other tasks. In this work, we examine five of the most prominent deep-MIL models and find that none of them respects the standard MIL assumption. They are able to learn anti-correlated instances, i.e., defaulting to ""positive"" labels until seeing a negative counter-example, which should not be possible for a correct MIL model. We suspect that enhancements and other works derived from these models will share the same issue. In any context in which these models are being used, this creates the potential for learning incorrect models, which creates risk of operational failure.  We identify and demonstrate this problem via a proposed ``algorithmic unit test\'\', where we create synthetic datasets that can be solved by a MIL respecting model, and which clearly reveal learning that violates MIL assumptions. The five evaluated methods each fail one or more of these tests. This provides a model-agnostic way to identify violations of modeling assumptions, which we hope will be useful for future development and evaluation of MIL models.'}",https://openreview.net{'value': '/pdf/c51ba0fd5f256cd1c3c208edd78428583d4707a6.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=ZvDmna23r3,{'value': 'Thought Cloning: Learning to Think while Acting by Imitating Human Thinking'},Shengran Hu; Jeff Clune,~Shengran_Hu2; ~Jeff_Clune3,"{'value': ['Reinforcement learning', 'Imitation Learning', 'AI Safety', 'Interpretability']}","{'value': 'Language is often considered a key aspect of human thinking, providing us with exceptional abilities to generalize, explore, plan, replan, and adapt to new situations. However, Reinforcement Learning (RL) agents are far from human-level performance in any of these abilities. We hypothesize one reason for such cognitive deficiencies is that they lack the benefits of thinking in language and that we can improve AI agents by training them to $\\textit{think like humans do}$. We introduce a novel Imitation Learning framework, Thought Cloning, where the idea is to not just clone the behaviors of human demonstrators, $\\textit{but also the thoughts humans have as they perform these behaviors}$. While we expect Thought Cloning to truly shine at scale on internet-sized datasets (e.g. online videos with transcripts), here we conduct experiments in a domain where the thinking and action data are synthetically generated. Results reveal that Thought Cloning learns much faster than Behavioral Cloning and its performance advantage grows the further out of distribution test tasks are, highlighting its ability to better handle novel situations. Thought Cloning also provides important benefits for AI Safety and Interpretability, and makes it easier to debug and improve AI. Because we can observe the agent’s thoughts, we can (1) more easily diagnose why things are going wrong, making it easier to fix the problem, (2) steer the agent by correcting its thinking, or (3) prevent it from doing unsafe things it plans to do. Overall, by training agents $\\textit{how to think}$ as well as behave, Thought Cloning creates safer, more powerful agents.'}",https://openreview.net{'value': '/pdf/53b8112a015d972cf14baae6ee29f904f8c9e97b.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=ZcJa1R6j3v,{'value': 'Large Language Models Are Semi-Parametric Reinforcement Learning Agents'},Danyang Zhang; Lu Chen; Situo Zhang; Hongshen Xu; Zihan Zhao; Kai Yu,~Danyang_Zhang2; ~Lu_Chen3; ~Situo_Zhang1; ~Hongshen_Xu1; ~Zihan_Zhao1; ~Kai_Yu3,"{'value': ['Learning from Experiences', 'LLM', 'Reinforcement Learning', 'Decision Making', 'Experience Memory']}","{'value': 'Inspired by the insights in cognitive science with respect to human memory and reasoning mechanism, a novel evolvable LLM-based (Large Language Model) agent framework is proposed as Rememberer. By equipping the LLM with a long-term experience memory, Rememberer is capable of exploiting the experiences from the past episodes even for different task goals, which excels an LLM-based agent with fixed exemplars or equipped with a transient working memory. We further introduce **R**einforcement **L**earning with **E**xperience **M**emory (**RLEM**) to update the memory. Thus, the whole system can learn from the experiences of both success and failure, and evolve its capability without fine-tuning the parameters of the LLM. In this way, the proposed Rememberer constitutes a semi-parametric RL agent. Extensive experiments are conducted on two RL task sets to evaluate the proposed framework. The average results with different initialization and training sets exceed the prior SOTA by 4% and 2% for the success rate on two task sets and demonstrate the superiority and robustness of Rememberer.'}",https://openreview.net{'value': '/pdf/9771a8343bb46aae73ab06aad55ce991cbcf441a.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=ZZgfS1DbmO,{'value': 'Continuous Parametric Optical Flow'},Jianqin Luo; Zhexiong Wan; yuxin mao; Bo Li; Yuchao Dai,~Jianqin_Luo2; ~Zhexiong_Wan1; ~yuxin_mao2; ~Bo_Li35; ~Yuchao_Dai1,"{'value': ['optical flow', 'point trajectories', 'continuous motion', 'neural ordinary differential equation']}","{'value': 'In this paper, we present continuous parametric optical flow, a parametric representation of dense and continuous motion over arbitrary time interval. In contrast to existing discrete-time representations (i.e., flow in between consecutive frames), this new representation transforms the frame-to-frame pixel correspondences to dense continuous flow. In particular, we present a temporal-parametric model that employs B-splines to fit point trajectories using a limited number of frames. To further improve the stability and robustness of the trajectories, we also add an encoder with a neural ordinary differential equation (NODE) to represent features associated with specific times. We also contribute a synthetic dataset and introduce two evaluation perspectives to measure the accuracy and robustness of continuous flow estimation. Benefiting from the combination of explicit parametric modeling and implicit feature optimization, our model focuses on motion continuity and outperforms the flow-based and point-tracking approaches for fitting long-term and variable sequences.'}",https://openreview.net{'value': '/pdf/3527881546b3e8a7769a902e75c6289539557164.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=ZXbgVm3PSt,{'value': 'TART: A plug-and-play Transformer module for task-agnostic reasoning'},Kush Bhatia; Avanika Narayan; Christopher De Sa; Christopher Re,~Kush_Bhatia3; ~Avanika_Narayan1; ~Christopher_De_Sa2; ~Christopher_Re1,"{'value': ['In-context learning', 'task-agnostic methods', 'large language models']}","{'value': ""Large language models (LLMs) exhibit in-context learning abilities which enable the same model to perform several tasks without any task-specific training. In contrast, traditional adaptation approaches, such as fine-tuning, modify the underlying models for each specific task. In-context learning, however, consistently underperforms task-specific tuning approaches even when presented with the same examples. While most existing approaches (e.g., prompt engineering) focus on the LLM's learned representations to patch this performance gap, our experiments actually reveal that LLM representations contain sufficient information to make good predictions. As such, we focus on the LLM's reasoning abilities and demonstrate that this performance gap exists due to their inability to perform simple probabilistic reasoning tasks. This raises an intriguing question: Are LLMs actually capable of learning how to reason in a task-agnostic manner? We answer this in the affirmative and, as a proof of concept, propose TART which generically improves an LLM's reasoning abilities using a synthetically trained reasoning module. TART trains this Transformer-based reasoning module in a task-agnostic manner using only synthetic logistic regression tasks and composes it with an arbitrary real-world pre-trained model without any additional training. With a single inference module, TART improves performance across different model families (GPT-Neo, Pythia, Bloom), model sizes (100M - 6B), tasks (14 NLP classification tasks), and even across different modalities (audio and vision). On the RAFT Benchmark, TART improves GPT-Neo (125M)'s performance such that it outperforms Bloom (176B), and is within $4$% of GPT-3.""}",https://openreview.net{'value': '/pdf/1bc7179745183a8b1dc0ead356b054fdd89ac35f.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=ZQMlfNijY5,{'value': 'Normalizing flow neural networks by JKO scheme'},Chen Xu; Xiuyuan Cheng; Yao Xie,~Chen_Xu12; ~Xiuyuan_Cheng1; ~Yao_Xie2,"{'value': ['Normalizing flow', 'invertible neural networks', 'JKO scheme']}","{'value': 'Normalizing flow is a class of deep generative models for efficient sampling and likelihood estimation, which achieves attractive performance, particularly in high dimensions. The flow is often implemented using a sequence of invertible residual blocks. Existing works adopt special network architectures and regularization of flow trajectories. In this paper, we develop a neural ODE flow network called JKO-iFlow, inspired by the Jordan-Kinderleherer-Otto (JKO) scheme, which unfolds the discrete-time dynamic of the Wasserstein gradient flow. The proposed method stacks residual blocks one after another, allowing efficient block-wise training of the residual blocks, avoiding sampling SDE trajectories and score matching or variational learning, thus reducing the memory load and difficulty in end-to-end training. We also develop adaptive time reparameterization of the flow network with a progressive refinement of the induced trajectory in probability space to improve the model accuracy further. Experiments with synthetic and real data show that the proposed JKO-iFlow network achieves competitive performance compared with existing flow and diffusion models at a significantly reduced computational and memory cost.'}",https://openreview.net{'value': '/pdf/16dd0bc4633b4b0da118d255a7a050c17be53507.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=ZPj7ey5fXa,{'value': 'PyNeRF: Pyramidal Neural Radiance Fields'},Haithem Turki; Michael Zollhöfer; Christian Richardt; Deva Ramanan,~Haithem_Turki1; ~Michael_Zollhöfer2; ~Christian_Richardt1; ~Deva_Ramanan1,"{'value': ['view synthesis', '3d reconstruction', 'scene representation', '3d deep learning']}","{'value': 'Neural Radiance Fields (NeRFs) can be dramatically accelerated by spatial grid representations. However, they do not explicitly reason about scale and so introduce aliasing artifacts when reconstructing scenes captured at different camera distances. Mip-NeRF and its extensions propose scale-aware renderers that project volumetric frustums rather than point samples. But such approaches rely on positional encodings that are not readily compatible with grid methods. We propose a simple modification to grid-based models by training model heads at different spatial grid resolutions. At render time, we simply use coarser grids to render samples that cover larger volumes. Our method can be easily applied to existing accelerated NeRF methods and significantly improves rendering quality (reducing error rates by 20–90% across synthetic and unbounded real-world scenes) while incurring minimal performance overhead (as each model head is quick to evaluate). Compared to Mip-NeRF, we reduce error rates by 20% while training over 60x faster.'}",https://openreview.net{'value': '/pdf/7b2da8a9f2972f2bda3ec2618cd1ffaf455f1f8f.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=ZIyAHaLlsn,{'value': 'ResShift: Efficient Diffusion Model for Image Super-resolution by Residual Shifting'},Zongsheng Yue; Jianyi Wang; Chen Change Loy,~Zongsheng_Yue1; ~Jianyi_Wang1; ~Chen_Change_Loy2,{'value': ['Super-resolution; Diffusion model; Efficient']},"{'value': 'Diffusion-based image super-resolution (SR) methods are mainly limited by the low inference speed due to the requirements of hundreds or even thousands of sampling steps. Existing acceleration sampling techniques inevitably sacrifice performance to some extent, leading to over-blurry SR results. To address this issue, we propose a novel and efficient diffusion model for SR that significantly reduces the number of diffusion steps, thereby eliminating the need for post-acceleration during inference and its associated performance deterioration. Our method constructs a Markov chain that transfers between the high-resolution image and the low-resolution image by shifting the residual between them, substantially improving the transition efficiency. Additionally, an elaborate noise schedule is developed to flexibly control the shifting speed and the noise strength during the diffusion process. Extensive experiments demonstrate that the proposed method obtains superior or at least comparable performance to current state-of-the-art methods on both synthetic and real-world datasets, \\textit{\\textbf{even only with 20 sampling steps}}. Our code and model will be made publicly.'}",https://openreview.net{'value': '/pdf/8f70c4f6b1bc6598c74af8d673c243159b0e81d1.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=ZIfhYAE2xg,{'value': 'Sparse Parameterization for Epitomic Dataset Distillation'},Xing Wei; Anjia Cao; Funing Yang; Zhiheng Ma,~Xing_Wei5; ~Anjia_Cao1; ~Funing_Yang1; ~Zhiheng_Ma1,"{'value': ['Dataset Distillation', 'Dataset Condensation', 'Sparse Coding', 'Dictionary Learning']}","{'value': 'The success of deep learning relies heavily on large and diverse datasets, but the storage, preprocessing, and training of such data present significant challenges. To address these challenges, dataset distillation techniques have been proposed to obtain smaller synthetic datasets that capture the essential information of the originals. In this paper, we introduce a Sparse Parameterization for Epitomic datasEt Distillation (SPEED) framework, which leverages the concept of dictionary learning and sparse coding to distill epitomes that represent pivotal information of the dataset. SPEED prioritizes proper parameterization of the synthetic dataset and introduces techniques to capture spatial redundancy within and between synthetic images. We propose Spatial-Agnostic Epitomic Tokens (SAETs) and Sparse Coding Matrices (SCMs) to efficiently represent and select significant features. Additionally, we build a Feature-Recurrent Network (FReeNet) to generate hierarchical features with high compression and storage efficiency. Experimental results demonstrate the superiority of SPEED in handling high-resolution datasets, achieving state-of-the-art performance on multiple benchmarks and downstream applications. Our framework is compatible with a variety of dataset matching approaches, generally enhancing their performance. This work highlights the importance of proper parameterization in epitomic dataset distillation and opens avenues for efficient representation learning. Source code is available at https://github.com/MIV-XJTU/SPEED.'}",https://openreview.net{'value': '/pdf/5828924919f2aef4c1bba2ca3813887d0e65c298.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=ZARAiV25CW,{'value': 'Generalized Bayesian Inference for Scientific Simulators via Amortized Cost Estimation'},Richard Gao; Michael Deistler; Jakob H. Macke,~Richard_Gao1; ~Michael_Deistler1; ~Jakob_H._Macke1,"{'value': ['simulation-based inference', 'generalized bayesian inference', 'neural network', 'machine learning for science']}","{'value': 'Simulation-based inference (SBI) enables amortized Bayesian inference for simulators with implicit likelihoods. But when we are primarily interested in the quality of predictive simulations, or when the model cannot exactly reproduce the observed data (i.e., is misspecified), targeting the Bayesian posterior may be overly restrictive. Generalized Bayesian Inference (GBI) aims to robustify inference for (misspecified) simulator models, replacing the likelihood-function with a cost function that evaluates the goodness of parameters relative to data. However, GBI methods generally require running multiple simulations to estimate the cost function at each parameter value during inference, making the approach computationally infeasible for even moderately complex simulators. Here, we propose amortized cost estimation (ACE) for GBI to address this challenge: We train a neural network to approximate the cost function, which we define as the expected distance between simulations produced by a parameter and observed data. The trained network can then be used with MCMC to infer GBI posteriors for any observation without running additional simulations. We show that, on several benchmark tasks, ACE accurately predicts cost and provides predictive simulations that are closer to synthetic observations than other SBI methods, especially for misspecified simulators. Finally, we apply ACE to infer parameters of the Hodgkin-Huxley model given real intracellular recordings from the Allen Cell Types Database. ACE identifies better data-matching parameters while being an order of magnitude more simulation-efficient than a standard SBI method. In summary, ACE combines the strengths of SBI methods and GBI to perform robust and simulation-amortized inference for scientific simulators.'}",https://openreview.net{'value': '/pdf/752b49ab56d4df297a31cb743536e277df4d6ffa.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Z764QxwETf,{'value': 'Puzzlefusion: Unleashing the Power of Diffusion Models for Spatial Puzzle Solving'},Sepidehsadat Hosseini; Mohammad Amin Shabani; Saghar Irandoust; Yasutaka Furukawa,~Sepidehsadat_Hosseini2; ~Mohammad_Amin_Shabani1; ~Saghar_Irandoust1; ~Yasutaka_Furukawa1,"{'value': ['Diffusion', 'Jigsaw', 'puzzle solving']}","{'value': ""This paper presents an end-to-end neural architecture based on Diffusion Models for spatial puzzle solving, particularly jigsaw puzzle and room arrangement tasks.\nIn the latter task, for instance, the proposed system ``PuzzleFusion'' takes a set of room layouts as polygonal curves in the top-down view and aligns the room layout pieces by estimating their 2D translations and rotations, akin to solving the jigsaw puzzle of room layouts. A surprising discovery of the paper is that the simple use of a Diffusion Model effectively solves these challenging spatial puzzle tasks as a conditional generation process. \nTo enable learning of an end-to-end neural system, the paper introduces new datasets with ground-truth arrangements: 1) 2D Voronoi Jigsaw Dataset, a synthetic one where pieces are generated by voronoi diagram of 2D pointset; and 2) MagicPlan Dataset, a real one from a production pipeline by MagicPlan, where pieces are room layouts constructed by augmented reality App by real-estate consumers.\nThe qualitative and quantitative evaluations demonstrate that the proposed approach outperforms the competing methods by significant margins in all three spatial puzzle tasks. We have provided code and data in https://sepidsh.github.io/puzzlefusion.""}",https://openreview.net{'value': '/pdf/2c871c960c5841b8911dbcd7124e940dbed64d2f.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Z16jo3d6OD,{'value': 'A Unified Framework for Rank-based Loss Minimization'},Rufeng Xiao; Yuze Ge; Rujun Jiang; Yifan Yan,~Rufeng_Xiao1; ~Yuze_Ge1; ~Rujun_Jiang1; yanyf21@m.fudan.edu.cn,"{'value': ['rank-based loss', 'ADMM', 'nonconvex nonsmooth optimization', 'conditional Value-at-Risk', 'human-aligned risk', 'ranked range loss']}","{'value': 'The empirical loss, commonly referred to as the average loss, is extensively utilized for training machine learning models. However, in order to address the diverse performance requirements of machine learning models, the use of the rank-based loss is prevalent, replacing the empirical loss in many cases. The rank-based loss comprises a weighted sum of sorted individual losses, encompassing both convex losses like the spectral risk, which includes the empirical risk and conditional value-at-risk, and nonconvex losses such as the human-aligned risk and the sum of the ranked range loss. In this paper, we introduce a unified framework for the optimization of the rank-based loss through the utilization of a proximal alternating direction method of multipliers. We demonstrate the convergence and convergence rate of the proposed algorithm under mild conditions. Experiments conducted on synthetic and real datasets illustrate the effectiveness and efficiency of the proposed algorithm.'}",https://openreview.net{'value': '/pdf/43d8a2abe09095c77880d689f626c7741d6bb7b4.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Yq6GKgN3RC,"{'value': 'Federated Learning with Client Subsampling, Data Heterogeneity, and Unbounded Smoothness: A New Algorithm and Lower Bounds'}",Michael Crawshaw; Yajie Bao; Mingrui Liu,~Michael_Crawshaw1; ~Yajie_Bao2; ~Mingrui_Liu2,"{'value': ['federated learning', 'client subsampling', 'nonconvex optimization', 'relaxed smoothness', 'data heterogeneity', 'lower bound']}","{'value': 'We study the problem of Federated Learning (FL) under client subsampling and data heterogeneity with an objective function that has potentially unbounded smoothness. This problem is motivated by empirical evidence that the class of relaxed smooth functions, where the Lipschitz constant of the gradient scales linearly with the gradient norm, closely resembles the loss functions of certain neural networks such as recurrent neural networks (RNNs) with possibly exploding gradient. We introduce EPISODE++, the first algorithm to solve this problem. It maintains historical statistics for each client to construct control variates and decide clipping behavior for sampled clients in the current round. We prove that EPISODE++ achieves linear speedup in the number of participating clients, reduced communication rounds, and resilience to data heterogeneity. Our upper bound proof relies on novel techniques of recursively bounding the client updates under unbounded smoothness and client subsampling, together with a refined high probability analysis. In addition, we prove a lower bound showing that the convergence rate of a special case of clipped minibatch SGD (without randomness in the stochastic gradient and with randomness in client subsampling) suffers from an explicit dependence on the maximum gradient norm of the objective in a sublevel set, which may be large. This effectively demonstrates that applying gradient clipping to minibatch SGD in our setting does not eliminate the problem of exploding gradients.  Our lower bound is based on new constructions of hard instances tailored to client subsampling and a novel analysis of the trajectory of the algorithm in the presence of clipping. Lastly, we provide an experimental evaluation of EPISODE++ when training RNNs on federated text classification tasks, demonstrating that EPISODE++ outperforms strong baselines in FL. The code is available at https://github.com/MingruiLiu-ML-Lab/episode_plusplus.'}",https://openreview.net{'value': '/pdf/c121028759cbbd04b2a4b08970a84d7d0f69b6ab.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Ypbke6biDm,"{'value': 'Pareto Frontiers in Deep Feature Learning: Data, Compute, Width, and Luck'}",Benjamin L. Edelman; Surbhi Goel; Sham M. Kakade; eran malach; Cyril Zhang,~Benjamin_L._Edelman1; ~Surbhi_Goel1; ~Sham_M._Kakade1; ~eran_malach1; ~Cyril_Zhang1,"{'value': ['deep learning', 'feature learning', 'parity', 'grokking', 'lottery tickets', 'scaling']}","{'value': 'In modern deep learning, algorithmic choices (such as width, depth, and learning rate) are known to modulate nuanced resource tradeoffs. This work investigates how these complexities necessarily arise for feature learning in the presence of computational-statistical gaps. We begin by considering offline sparse parity learning, a supervised classification problem which admits a statistical query lower bound for gradient-based training of a multilayer perceptron. This lower bound can be interpreted as a *multi-resource tradeoff frontier*: \nsuccessful learning can only occur if one is sufficiently rich (large model), knowledgeable (large dataset), patient (many training iterations), or lucky (many random guesses). We show, theoretically and experimentally, that sparse initialization and increasing network width yield significant improvements in sample efficiency in this setting. Here, width plays the role of parallel search: it amplifies the probability of finding ""lottery ticket"" neurons, which learn sparse features more sample-efficiently. Finally, we show that the synthetic sparse parity task can be useful as a proxy for real problems requiring axis-aligned feature learning. We demonstrate improved sample efficiency on tabular classification benchmarks by using wide, sparsely-initialized MLP models; these networks sometimes outperform tuned random forests.'}",https://openreview.net{'value': '/pdf/6e863d634fe93a3dd748a804d5dc18c38aaabc14.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=YhAZqWhOnS,{'value': 'Autodecoding Latent 3D Diffusion Models'},Evangelos Ntavelis; Aliaksandr Siarohin; Kyle Olszewski; Chaoyang Wang; Luc Van Gool; Sergey Tulyakov,~Evangelos_Ntavelis1; ~Aliaksandr_Siarohin1; ~Kyle_Olszewski1; ~Chaoyang_Wang1; ~Luc_Van_Gool1; ~Sergey_Tulyakov1,"{'value': ['3D Generation', 'Diffusion Models']}","{'value': 'Diffusion-based methods have shown impressive visual results in the text-to-image domain. They first learn a latent space using an autoencoder, then run a denoising process on the bottleneck to generate new samples. However, learning an autoencoder requires substantial data in the target domain. Such data is scarce for 3D generation, prohibiting the learning of large-scale diffusion models for 3D synthesis. We present a novel approach to the generation of static and articulated 3D assets that has a 3D autodecoder at its core. The 3D autodecoder framework embeds properties learned from the target dataset in the latent space, which can then be decoded into a volumetric representation for rendering view-consistent appearance and geometry. We then identify the appropriate intermediate volumetric latent space, and introduce robust normalization and de-normalization operations to learn a 3D diffusion from 2D images or monocular videos of rigid or articulated objects. Our approach is flexible enough to use either existing camera supervision or no camera information at all -- instead efficiently learning it during training. Our evaluations demonstrate that our generation results outperform state-of-the-art alternatives on various benchmark datasets and metrics, including multi-view image datasets of synthetic objects, real in-the-wild videos of moving people, and a large-scale, real video dataset of static objects.'}",https://openreview.net{'value': '/pdf/4a58bc5efc695ed9a8ac480a5dd07ad0de32f6b0.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=YdfcKb4Wif,{'value': 'Learning Trajectories are Generalization Indicators'},Jingwen Fu; Zhizheng Zhang; Dacheng Yin; Yan Lu; Nanning Zheng,~Jingwen_Fu1; ~Zhizheng_Zhang1; ~Dacheng_Yin1; ~Yan_Lu7; ~Nanning_Zheng1,"{'value': ['Generalization', 'Learning Trajectory']}","{'value': ""This paper explores the connection between learning trajectories of Deep Neural Networks (DNNs) and their generalization capabilities when optimized using (stochastic) gradient descent algorithms. \nInstead of concentrating solely on the generalization error of the DNN post-training, we present a novel perspective for analyzing generalization error by investigating the contribution of each update step to the change in generalization error. This perspective enable a more direct comprehension of how the learning trajectory influences generalization error. Building upon this analysis, we propose a new generalization bound that incorporates more extensive trajectory information.\nOur proposed generalization bound depends on the complexity of learning trajectory and the ratio between the bias and diversity of training set. Experimental observations reveal that our method effectively captures the generalization error throughout the training process. Furthermore, our approach can also track changes in generalization error when adjustments are made to learning rates and label noise levels. These results demonstrate that learning trajectory information is a valuable indicator of a model's generalization capabilities.""}",https://openreview.net{'value': '/pdf/c18735668816af591e544a715af607d485139e38.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=YJDz4F2AZu,{'value': 'ContiFormer: Continuous-Time Transformer for Irregular Time Series Modeling'},Yuqi Chen; Kan Ren; Yansen Wang; Yuchen Fang; Weiwei Sun; Dongsheng Li,~Yuqi_Chen3; ~Kan_Ren1; ~Yansen_Wang2; ~Yuchen_Fang2; ~Weiwei_Sun5; ~Dongsheng_Li2,"{'value': ['Irregular Time Series Modeling', 'Transformer', 'Neural Ordinary Differential Equation']}","{'value': 'Modeling continuous-time dynamics on irregular time series is critical to account for data evolution and correlations that occur continuously. Traditional methods including recurrent neural networks or Transformer models leverage inductive bias via powerful neural architectures to capture complex patterns. However, due to their discrete characteristic, they have limitations in generalizing to continuous-time data paradigms. Though neural ordinary differential equations (Neural ODEs) and their variants have shown promising results in dealing with irregular time series, they often fail to capture the intricate correlations within these sequences. It is challenging yet demanding to concurrently model the relationship between input data points and capture the dynamic changes of the continuous-time system. To tackle this problem, we propose ContiFormer that extends the relation modeling of vanilla Transformer to the continuous-time domain, which explicitly incorporates the modeling abilities of continuous dynamics of Neural ODEs with the attention mechanism of Transformers. We mathematically characterize the expressive power of ContiFormer and illustrate that, by curated designs of function hypothesis, many Transformer variants specialized in irregular time series modeling can be covered as a special case of ContiFormer. A wide range of experiments on both synthetic and real-world datasets have illustrated the superior modeling capacities and prediction performance of ContiFormer on irregular time series data. The project link is https://seqml.github.io/contiformer/.'}",https://openreview.net{'value': '/pdf/fe18bfa4acae35a845e410366586d3a6a106c47c.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=YI4bn6aAmz,{'value': 'Conformal Prediction Sets for Ordinal Classification'},PRASENJIT DEY; Srujana Merugu; Sivaramakrishnan R Kaveri,~PRASENJIT_DEY2; ~Srujana_Merugu2; ~Sivaramakrishnan_R_Kaveri1,"{'value': ['Ordinal Classification', 'Conformal Predictions', 'Unimodal modelling']}","{'value': 'Ordinal classification (OC), i.e., labeling instances along classes with a natural ordering, is common in multiple  applications such as size or budget based recommendations and disease severity labeling.  Often in practical scenarios, it is desirable to obtain a small set of likely classes with a guaranteed high chance of including the true class. Recent works on conformal prediction (CP) address this problem for the classification setting with non-ordered labels but the resulting prediction sets (PS) are often non-contiguous and unsuitable for ordinal classification. In this work, we propose a framework to adapt existing CP methods to generate contiguous sets with guaranteed coverage and minimal cardinality. Our framework employs a novel non-parametric approach for modeling unimodal distributions. Empirical results on both synthetic and real-world datasets demonstrate our method outperforms SOTA baselines by 4% on Accuracy@K and 8% on PS size.'}",https://openreview.net{'value': '/pdf/57fe7082babb8a450e693ea48fc6eaa1a4110837.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Y3NjoeO4Q1,{'value': 'Detection Based Part-level Articulated Object Reconstruction from Single RGBD Image'},Yuki Kawana; Tatsuya Harada,~Yuki_Kawana1; ~Tatsuya_Harada1,"{'value': ['articulated objects', 'shape reconstruction', '3D reconstruction']}","{'value': 'We propose an end-to-end trainable, cross-category method for reconstructing multiple man-made articulated objects from a single RGBD image, focusing on part-level shape reconstruction and pose and kinematics estimation. We depart from previous works that rely on learning instance-level latent space, focusing on man-made articulated objects with predefined part counts. Instead, we propose a novel alternative approach that employs part-level representation, representing instances as combinations of detected parts. While our detect-then-group approach effectively handles instances with diverse part structures and various part counts, it faces issues of false positives, varying part sizes and scales, and an increasing model size due to end-to-end training. To address these challenges, we propose 1) test-time kinematics-aware part fusion to improve detection performance while suppressing false positives, 2) anisotropic scale normalization for part shape learning to accommodate various part sizes and scales, and 3) a balancing strategy for cross-refinement between feature space and output space to improve part detection while maintaining model size. Evaluation on both synthetic and real data demonstrates that our method successfully reconstructs variously structured multiple instances that previous works cannot handle, and outperforms prior works in shape reconstruction and kinematics estimation.'}",https://openreview.net{'value': '/pdf/81ad94af1047adb7a6509e4e95bd2ecf06249ae3.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Xyj46OxEhK,"{'value': 'Look Ma, No Hands! Agent-Environment Factorization of Egocentric Videos'}",Matthew Chang; Aditya Prakash; Saurabh Gupta,~Matthew_Chang1; ~Aditya_Prakash1; ~Saurabh_Gupta1,"{'value': ['Inpainting', 'Diffusion', 'Robot Learning', 'Egocentric Vision']}","{'value': 'The analysis and use of egocentric videos for robotics tasks is made challenging by occlusion and the visual mismatch between the human hand and a robot end-effector. Past work views the human hand as a nuisance and removes it from the scene. However, the hand also provides a valuable signal for learning. In this work, we propose to extract a factored representation of the scene that separates the agent (human hand) and the environment. This alleviates both occlusion and mismatch while preserving the signal, thereby easing the design of models for downstream robotics tasks. At the heart of this factorization is our proposed Video Inpainting via Diffusion Model (VIDM) that leverages both a prior on real-world images (through a large-scale pre-trained diffusion model) and the appearance of the object in earlier frames of the video (through attention). Our experiments demonstrate the effectiveness of VIDM at improving the in-painting quality in egocentric videos and the power of our factored representation for numerous tasks: object detection, 3D reconstruction of manipulated objects, and learning of reward functions, policies, and affordances from videos.'}",https://openreview.net{'value': '/pdf/dfbd322d9bc20b8b81201fc51ee34ff3b0a1983d.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=XvfEYqEbIb,{'value': 'Non-Rigid Shape Registration via Deep Functional Maps Prior'},Puhua Jiang; Mingze Sun; Ruqi Huang,~Puhua_Jiang1; ~Mingze_Sun1; ~Ruqi_Huang1,{'value': ['shape registration; functional maps; unsupervised learning']},"{'value': 'In this paper, we propose a learning-based framework for non-rigid shape registra- tion without correspondence supervision. Traditional shape registration techniques typically rely on correspondences induced by extrinsic proximity, therefore can fail in the presence of large intrinsic deformations. Spectral mapping methods overcome this challenge by embedding shapes into, geometric or learned, high- dimensional spaces, where shapes are easier to align. However, due to the dependency on abstract, non-linear embedding schemes, the latter can be vulnerable with respect to perturbed or alien input. In light of this, our framework takes the best of both worlds. Namely, we deform source mesh towards the target point cloud, guided by correspondences induced by high-dimensional embeddings learned from deep functional maps (DFM). In particular, the correspondences are dynamically updated according to the intermediate registrations and filtered by consistency prior, which prominently robustify the overall pipeline. Moreover, in order to alleviate the requirement of extrinsically aligned input, we train an orientation regressor on a set of aligned synthetic shapes independent of the training shapes for DFM. Empirical results show that, with as few as dozens of training shapes of limited variability, our pipeline achieves state-of-the-art results on several benchmarks of non-rigid point cloud matching, but also delivers high-quality correspondences between unseen challenging shape pairs that undergo both significant extrinsic and intrinsic defor- mations, in which case neither traditional registration methods nor intrinsic methods work. The code is available at https://github.com/rqhuang88/DFR.'}",https://openreview.net{'value': '/pdf/a52f06f15ffe15bcd6eaa9c1cda4f8eb847d5045.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=XkcufOcgUc,{'value': 'Structure-free Graph Condensation: From Large-scale Graphs to Condensed Graph-free Data'},Xin Zheng; Miao Zhang; Chunyang Chen; Quoc Viet Hung Nguyen; Xingquan Zhu; Shirui Pan,~Xin_Zheng4; ~Miao_Zhang4; ~Chunyang_Chen1; ~Quoc_Viet_Hung_Nguyen1; ~Xingquan_Zhu1; ~Shirui_Pan1,"{'value': ['graph neural networks (GNNs)', 'graph condensation', 'training trajectory meta-matching', 'graph neural feature score']}","{'value': 'Graph condensation, which reduces the size of a large-scale graph by synthesizing a small-scale condensed graph as its substitution, has immediate benefits for various graph learning tasks.\nHowever, existing graph condensation methods rely on the joint optimization of nodes and structures in the condensed graph, and overlook critical issues in effectiveness and generalization ability.\nIn this paper, we advocate a new Structure-Free Graph Condensation paradigm, named SFGC, to distill a large-scale graph into a small-scale graph node set without explicit graph structures, i.e., graph-free data.\nOur idea is to implicitly encode topology structure information into the node attributes in the synthesized graph-free data, whose topology is reduced to an identity matrix.\nSpecifically, SFGC contains two collaborative components: \n(1) a training trajectory meta-matching scheme for effectively synthesizing small-scale graph-free data;\n(2) a graph neural feature score metric for dynamically evaluating the quality of the condensed data. \nThrough training trajectory meta-matching, SFGC aligns the long-term GNN learning behaviors between the large-scale graph and the condensed small-scale graph-free data, ensuring comprehensive and compact transfer of informative knowledge to the graph-free data.\nAfterward, the underlying condensed graph-free data would be dynamically evaluated with the graph neural feature score, which is a closed-form metric for ensuring the excellent expressiveness of the condensed graph-free data.\nExtensive experiments verify the superiority of SFGC across different condensation ratios.'}",https://openreview.net{'value': '/pdf/f6da01c95f03dc8397ee56522c3f9a3adcecebec.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=XeMryhpniy,{'value': 'Hierarchical Integration Diffusion Model for Realistic Image Deblurring'},Zheng Chen; Yulun Zhang; Ding Liu; Bin Xia; Jinjin Gu; Linghe Kong; Xin Yuan,~Zheng_Chen11; ~Yulun_Zhang1; ~Ding_Liu6; ~Bin_Xia1; ~Jinjin_Gu1; ~Linghe_Kong1; ~Xin_Yuan4,"{'value': ['image deblurring', 'diffusion model']}","{'value': 'Diffusion models (DMs) have recently been introduced in image deblurring and exhibited promising performance, particularly in terms of details reconstruction. However, the diffusion model requires a large number of inference iterations to recover the clean image from pure Gaussian noise, which consumes massive computational resources. Moreover, the distribution synthesized by the diffusion model is often misaligned with the target results, leading to restrictions in distortion-based metrics. To address the above issues, we propose the Hierarchical Integration Diffusion Model (HI-Diff), for realistic image deblurring. Specifically, we perform the DM in a highly compacted latent space to generate the prior feature for the deblurring process. The deblurring process is implemented by a regression-based method to obtain better distortion accuracy. Meanwhile, the highly compact latent space ensures the efficiency of the DM. Furthermore, we design the hierarchical integration module to fuse the prior into the regression-based model from multiple scales, enabling better generalization in complex blurry scenarios. Comprehensive experiments on synthetic and real-world blur datasets demonstrate that our HI-Diff outperforms state-of-the-art methods. Code and trained models are available at https://github.com/zhengchen1999/HI-Diff.'}",https://openreview.net{'value': '/pdf/1d52451a3690f62b18528eedcb064098ba8fd3ec.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=XY6BnwIh4q,{'value': 'Binary Radiance Fields'},Seungjoo Shin; Jaesik Park,~Seungjoo_Shin1; ~Jaesik_Park3,"{'value': ['neural radiance fields', 'inverse rendering', 'binarization']}","{'value': 'In this paper, we propose \\textit{binary radiance fields} (BiRF), a storage-efficient radiance field representation employing binary feature encoding in a format of either $+1$ or $-1$. This binarization strategy lets us represent the feature grid with highly compact feature encoding and a dramatic reduction in storage size. Furthermore, our 2D-3D hybrid feature grid design enhances the compactness of feature encoding as the 3D grid includes main components while 2D grids capture details. In our experiments, binary radiance field representation successfully outperforms the reconstruction performance of state-of-the-art (SOTA) storage-efficient radiance field models with lower storage allocation. In particular, our model achieves impressive results in static scene reconstruction, with a PSNR of 32.03 dB for Synthetic-NeRF scenes, 34.48 dB for Synthetic-NSVF scenes, 28.20 dB for Tanks and Temples scenes while only utilizing 0.5 MB of storage space, respectively. We hope the proposed binary radiance field representation will make radiance fields more accessible without a storage bottleneck.'}",https://openreview.net{'value': '/pdf/0e8f038e4a065d5b7d479a30a16c936d0ab4e106.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=XOotfgPiUF,{'value': 'FreeMask: Synthetic Images with Dense Annotations Make Stronger Segmentation Models'},Lihe Yang; Xiaogang Xu; Bingyi Kang; Yinghuan Shi; Hengshuang Zhao,~Lihe_Yang1; ~Xiaogang_Xu2; ~Bingyi_Kang1; ~Yinghuan_Shi3; ~Hengshuang_Zhao2,"{'value': ['learning from synthetic', 'semantic segmentation', 'generative models']}","{'value': 'Semantic segmentation has witnessed tremendous progress due to the proposal of various advanced network architectures. However, they are extremely hungry for delicate annotations to train, and the acquisition is laborious and unaffordable. Therefore, we present FreeMask in this work, which resorts to synthetic images from generative models to ease the burden of both data collection and annotation procedures. Concretely, we first synthesize abundant training images conditioned on the semantic masks provided by realistic datasets. This yields extra well-aligned image-mask training pairs for semantic segmentation models. We surprisingly observe that, solely trained with synthetic images, we already achieve comparable performance with real ones (e.g., 48.3 vs. 48.5 mIoU on ADE20K, and 49.3 vs. 50.5 on COCO-Stuff). Then, we investigate the role of synthetic images by joint training with real images, or pre-training for real images. Meantime, we design a robust filtering principle to suppress incorrectly synthesized regions. In addition, we propose to inequally treat different semantic masks to prioritize those harder ones and sample more corresponding synthetic images for them. As a result, either jointly trained or pre-trained with our filtered and re-sampled synthesized images, segmentation models can be greatly enhanced, e.g., from 48.7 to 52.0 on ADE20K.'}",https://openreview.net{'value': '/pdf/e998b8541cb359407a99e1843068433ee82e7c9b.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=XKP3mAsNHd,{'value': 'Incentives in Private Collaborative Machine Learning'},Rachael Hwee Ling Sim; Yehong Zhang; Trong Nghia Hoang; Xinyi Xu; Bryan Kian Hsiang Low; Patrick Jaillet,~Rachael_Hwee_Ling_Sim1; ~Yehong_Zhang1; ~Trong_Nghia_Hoang1; ~Xinyi_Xu4; ~Bryan_Kian_Hsiang_Low1; ~Patrick_Jaillet1,"{'value': ['Incentives', 'Privacy', 'Shapley fairness', 'Collaborative machine learning', 'data valuation', 'reward', 'sufficient statistics']}","{'value': ""Collaborative machine learning involves training models on data from multiple parties but must incentivize their participation. Existing data valuation methods fairly value and reward each party based on  shared data or model parameters but neglect the privacy risks involved. To address this, we introduce _differential privacy_ (DP) as an incentive. Each party can select its required DP guarantee and perturb its _sufficient statistic_ (SS) accordingly. The mediator values the perturbed SS by the Bayesian surprise it elicits about the model parameters. As our valuation function enforces a _privacy-valuation trade-off_, parties are deterred from selecting excessive DP guarantees that reduce the utility of the grand coalition's model. Finally, the mediator rewards each party with different posterior samples of the model parameters. Such rewards still satisfy existing incentives like fairness but additionally preserve DP and a high similarity to the grand coalition's posterior. We empirically demonstrate the effectiveness and practicality of our approach on synthetic and real-world datasets.""}",https://openreview.net{'value': '/pdf/125a9b3f42b509b38cb26ba67d744bc69f26c4fd.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=WpuBEtrn0t,{'value': 'Regularizing Neural Networks with Meta-Learning Generative Models'},Shin'ya Yamaguchi; Daiki Chijiwa; Sekitoshi Kanai; Atsutoshi Kumagai; Hisashi Kashima,~Shin'ya_Yamaguchi1; ~Daiki_Chijiwa1; ~Sekitoshi_Kanai1; ~Atsutoshi_Kumagai2; ~Hisashi_Kashima2,"{'value': ['Deep Learning', 'Generative Models', 'Generative Data Augmentation', 'Regularization', 'Meta-Learning']}","{'value': 'This paper investigates methods for improving generative data augmentation for deep learning. Generative data augmentation leverages the synthetic samples produced by generative models as an additional dataset for classification with small dataset settings. A key challenge of generative data augmentation is that the synthetic data contain uninformative samples that degrade accuracy. This can be caused by the synthetic samples not perfectly representing class categories in real data and uniform sampling not necessarily providing useful samples for tasks. In this paper, we present a novel strategy for generative data augmentation called *meta generative regularization* (MGR). To avoid the degradation of generative data augmentation, MGR utilizes synthetic samples for regularizing feature extractors instead of training classifiers. These synthetic samples are dynamically determined to minimize the validation losses through meta-learning. We observed that MGR can avoid the performance degradation of naive generative data augmentation and boost the baselines. Experiments on six datasets showed that MGR is effective particularly when datasets are smaller and stably outperforms baselines by up to 7 percentage points on test accuracy.'}",https://openreview.net{'value': '/pdf/6f0cc01078ca963219a1869cdeb941e8db41d98f.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Wa1GGPqjUn,{'value': 'Online learning of long-range dependencies'},Nicolas Zucchet; Robert Meier; Simon Schug; Asier Mujika; Joao Sacramento,~Nicolas_Zucchet1; ~Robert_Meier2; ~Simon_Schug1; ~Asier_Mujika1; ~Joao_Sacramento1,"{'value': ['online learning', 'linear recurrent units', 'temporal credit assignment', 'biologically-plausible learning', 'local learning rules', 'neuromorphic computing']}","{'value': 'Online learning holds the promise of enabling efficient long-term credit assignment in recurrent neural networks. However, current algorithms fall short of offline backpropagation by either not being scalable or failing to learn long-range dependencies. Here we present a high-performance online learning algorithm that merely doubles the memory and computational requirements of a single inference pass. We achieve this by leveraging independent recurrent modules in multi-layer networks, an architectural motif that has recently been shown to be particularly powerful. Experiments on synthetic memory problems and on the challenging long-range arena benchmark suite reveal that our algorithm performs competitively, establishing a new standard for what can be achieved through online learning. This ability to learn long-range dependencies offers a new perspective on learning in the brain and opens a promising avenue in neuromorphic computing.'}",https://openreview.net{'value': '/pdf/a8cc88641c3c91171e5c4a6a853f4305e07a3c46.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=W3cDd5xlKZ,{'value': 'Fair Canonical Correlation Analysis'},Zhuoping Zhou; Davoud Ataee Tarzanagh; Bojian Hou; Boning Tong; Jia Xu; Yanbo Feng; Qi Long; Li Shen,~Zhuoping_Zhou1; ~Davoud_Ataee_Tarzanagh1; ~Bojian_Hou1; ~Boning_Tong1; jiaxu7@upenn.edu; yanbof@seas.upenn.edu; ~Qi_Long1; ~Li_Shen2,"{'value': ['Fairness', 'Canonical Correlation Analysis', 'Riemannian Optimization', 'Pareto Optimization']}","{'value': 'This paper investigates fairness and bias in Canonical Correlation Analysis (CCA), a widely used statistical technique for examining the relationship between two sets of variables. We present a framework that alleviates unfairness by minimizing the correlation disparity error associated with protected attributes. Our approach enables CCA to learn global projection matrices from all data points while ensuring that these matrices yield comparable correlation levels to group-specific projection matrices. Experimental evaluation on both synthetic and real-world datasets demonstrates the efficacy of our method in reducing correlation disparity error without compromising CCA accuracy.'}",https://openreview.net{'value': '/pdf/d4928dbba190e55cccd00f10a2cce6b1f899382a.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=VzmpXQAn6E,{'value': 'Exposing Attention Glitches with Flip-Flop Language Modeling'},Bingbin Liu; Jordan T. Ash; Surbhi Goel; Akshay Krishnamurthy; Cyril Zhang,~Bingbin_Liu1; ~Jordan_T._Ash1; ~Surbhi_Goel1; ~Akshay_Krishnamurthy1; ~Cyril_Zhang1,"{'value': ['Transformers', 'language models', 'hallucinations', 'long-range dependencies', 'generalization', 'extrapolation', 'out-of-distribution']}","{'value': ""Why do large language models sometimes output factual inaccuracies and exhibit erroneous reasoning? The brittleness of these models, particularly when executing long chains of reasoning, currently seems to be an inevitable price to pay for their advanced capabilities of coherently synthesizing knowledge, pragmatics, and abstract thought. Towards making sense of this fundamentally unsolved problem, this work identifies and analyzes the phenomenon of _attention glitches_, in which the Transformer architecture's inductive biases intermittently fail to capture robust reasoning. To isolate the issue, we introduce _flip-flop language modeling_ (FFLM), a parametric family of synthetic benchmarks designed to probe the extrapolative behavior of neural language models. This simple generative task requires a model to copy binary symbols over long-range dependencies, ignoring the tokens in between. We find that Transformer FFLMs suffer from a long tail of sporadic reasoning errors, some of which we can eliminate using various regularization techniques. Our preliminary mechanistic analyses show why the remaining errors may be very difficult to diagnose and resolve. We hypothesize that attention glitches account for (some of) the closed-domain hallucinations in natural LLMs.""}",https://openreview.net{'value': '/pdf/bd4083f62211869859faf48516b49ffdca0ef705.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=VqIWgUVsXc,{'value': 'Does Graph Distillation See Like Vision Dataset Counterpart?'},Beining Yang; Kai Wang; Qingyun Sun; Cheng Ji; Xingcheng Fu; Hao Tang; Yang You; Jianxin Li,~Beining_Yang1; ~Kai_Wang8; ~Qingyun_Sun2; ~Cheng_Ji1; ~Xingcheng_Fu1; ~Hao_Tang6; ~Yang_You1; ~Jianxin_Li3,"{'value': ['data-efficient learning', 'graph generation', 'graph neural networks']}","{'value': 'Training on large-scale graphs has achieved remarkable results in graph representation learning, but its cost and storage have attracted increasing concerns. Existing graph condensation methods primarily focus on optimizing the feature matrices of condensed graphs while overlooking the impact of the structure information from the original graphs. To investigate the impact of the structure information, we conduct analysis from the spectral domain and empirically identify substantial Laplacian Energy Distribution (LED) shifts in previous works. Such shifts lead to poor performance in cross-architecture generalization and specific tasks, including anomaly detection and link prediction. In this paper, we propose a novel Structure-broadcasting Graph Dataset Distillation (\\textbf{SGDD}) scheme for broadcasting the original structure information to the generation of the synthetic one, which explicitly prevents overlooking the original structure information. \nTheoretically, the synthetic graphs by SGDD are expected to have smaller LED shifts than previous works, leading to superior performance in both cross-architecture settings and specific tasks.\nWe validate the proposed SGDD~across 9 datasets and achieve state-of-the-art results on all of them: for example, on YelpChi dataset, our approach maintains 98.6\\% test accuracy of training on the original graph dataset with 1,000 times saving on the scale of the graph. Moreover, we empirically evaluate there exist 17.6\\% $\\sim$ 31.4\\% reductions in LED shift crossing 9 datasets. Extensive experiments and analysis verify the effectiveness and necessity of the proposed designs. The code will be made public.'}",https://openreview.net{'value': '/pdf/8127382dda9da8f4c6b69155794f6f310d8e0412.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Vm1zeYqwdc,{'value': 'Diffusion Hyperfeatures: Searching Through Time and Space for Semantic Correspondence'},Grace Luo; Lisa Dunlap; Dong Huk Park; Aleksander Holynski; Trevor Darrell,~Grace_Luo1; ~Lisa_Dunlap1; ~Dong_Huk_Park2; ~Aleksander_Holynski1; ~Trevor_Darrell2,"{'value': ['semantic correspondence', 'hypercolumns', 'diffusion models', 'generative model representations']}","{'value': ""Diffusion models have been shown to be capable of generating high-quality images, suggesting that they could contain meaningful internal representations. Unfortunately, the feature maps that encode a diffusion model's internal information are spread not only over layers of the network, but also over diffusion timesteps, making it challenging to extract useful descriptors. We propose Diffusion Hyperfeatures, a framework for consolidating  multi-scale and multi-timestep feature maps into per-pixel feature descriptors that can be used for downstream tasks. These descriptors can be extracted for both synthetic and real images using the generation and inversion processes. We evaluate the utility of our Diffusion Hyperfeatures on the task of semantic keypoint correspondence: our method achieves superior performance on the SPair-71k real image benchmark. We also demonstrate that our method is flexible and transferable: our feature aggregation network trained on the inversion features of real image pairs can be used on the generation features of synthetic image pairs with unseen objects and compositions. Our code is available at https://diffusion-hyperfeatures.github.io.""}",https://openreview.net{'value': '/pdf/47eabcfd6dbd11b1486f03442741bd4bd6438c2d.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Vfp8sDST4g,{'value': 'Learning Large-Scale MTP$_2$ Gaussian Graphical Models via Bridge-Block Decomposition'},Xiwen Wang; Jiaxi Ying; Daniel P. Palomar,~Xiwen_Wang2; ~Jiaxi_Ying1; ~Daniel_P._Palomar1,"{'value': ['MTP2 Gaussian Graphical Model', 'High-dimensional precision matrix estimation', 'Bridge-block decomposition.']}","{'value': 'This paper studies the problem of learning the large-scale Gaussian graphical models that are multivariate totally positive of order two ($\\text{MTP}_2$). By introducing the concept of bridge, which commonly exists in large-scale sparse graphs, we show that the entire problem can be equivalently optimized through (1) several smaller-scaled sub-problems induced by a \\emph{bridge-block decomposition} on the thresholded sample covariance graph and (2) a set of explicit solutions on entries corresponding to  \\emph{bridges}. From practical aspect, this simple and provable discipline can be applied to break down a large problem into small tractable ones, leading to enormous reduction on the computational complexity and substantial improvements for all existing algorithms.  The synthetic and real-world experiments demonstrate that our proposed method presents a significant speed-up compared to the state-of-the-art benchmarks.'}",https://openreview.net{'value': '/pdf/3fcc157dd4195591101ebad0dfee494009ae0e28.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=VeO03T59Sh,{'value': 'Conformal Prediction for Uncertainty-Aware Planning with Diffusion Dynamics Model'},Jiankai Sun; Yiqi Jiang; Jianing Qiu; Parth Talpur Nobel; Mykel Kochenderfer; Mac Schwager,~Jiankai_Sun6; ~Yiqi_Jiang2; ~Jianing_Qiu1; ~Parth_Talpur_Nobel1; ~Mykel_Kochenderfer1; ~Mac_Schwager1,"{'value': ['Uncertainty', 'Conformal Prediction', 'Dynamics Model']}","{'value': 'Robotic applications often involve working in environments that are uncertain, dynamic, and partially observable. Recently, diffusion models have been proposed for learning trajectory prediction models trained from expert demonstrations, which can be used for planning in robot tasks. Such models have demonstrated a strong ability to overcome challenges such as multi-modal action distributions, high-dimensional output spaces, and training instability. It is crucial to quantify the uncertainty of these dynamics models when using them for planning. In this paper, we quantify the uncertainty of diffusion dynamics models using Conformal Prediction (CP). Given a finite number of exchangeable expert trajectory examples (called the “calibration set”), we use CP to obtain a set in the trajectory space (called the “coverage region”) that is guaranteed to contain the output of the diffusion model with a user-defined probability (called the “coverage level”). In PlanCP, inspired by concepts from conformal prediction, we modify the loss function for training the diffusion model to include a quantile term to encourage more robust performance across the variety of training examples. At test time, we then calibrate PlanCP with a conformal prediction process to obtain coverage sets for the trajectory prediction with guaranteed coverage level. We evaluate our algorithm on various planning tasks and model-based offline reinforcement learning tasks and show that it reduces the uncertainty of the learned trajectory prediction model. As a by-product, our algorithm PlanCP outperforms prior algorithms on existing offline RL benchmarks and challenging continuous planning tasks. Our method can be combined with most model-based planning approaches to produce uncertainty estimates of the closed-loop system.'}",https://openreview.net{'value': '/pdf/8fde541eed2bb30f6071042844bbb417203468c0.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=VUvLSnMZdX,{'value': 'Score-based Data Assimilation'},François Rozet; Gilles Louppe,~François_Rozet1; ~Gilles_Louppe1,"{'value': ['data assimilation', 'score-based', 'generative modeling', 'posterior inference', 'dynamical systems']}","{'value': 'Data assimilation, in its most comprehensive form, addresses the Bayesian inverse problem of identifying plausible state trajectories that explain noisy or incomplete observations of stochastic dynamical systems. Various approaches have been proposed to solve this problem, including particle-based and variational methods. However, most algorithms depend on the transition dynamics for inference, which becomes intractable for long time horizons or for high-dimensional systems with complex dynamics, such as oceans or atmospheres. In this work, we introduce score-based data assimilation for trajectory inference. We learn a score-based generative model of state trajectories based on the key insight that the score of an arbitrarily long trajectory can be decomposed into a series of scores over short segments. After training, inference is carried out using the score model, in a non-autoregressive manner by generating all states simultaneously. Quite distinctively, we decouple the observation model from the training procedure and use it only at inference to guide the generative process, which enables a wide range of zero-shot observation scenarios. We present theoretical and empirical evidence supporting the effectiveness of our method.'}",https://openreview.net{'value': '/pdf/d119d8c1bf5d8bd8c81399e4c28aa27fd58a9e0a.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=VPTZVVP4tm,{'value': 'LogSpecT: Feasible Graph Learning Model from Stationary Signals with Recovery Guarantees'},Shangyuan Liu; Linglingzhi Zhu; Anthony Man-Cho So,~Shangyuan_Liu2; ~Linglingzhi_Zhu1; ~Anthony_Man-Cho_So1,"{'value': ['Graph Signal Processing', 'Spectral Template', 'Network Inference', 'Optimization', 'Linearized ADMM']}","{'value': 'Graph learning from signals is a core task in graph signal processing (GSP). A significant subclass of graph signals called the stationary graph signals that broadens the concept of stationarity of data defined on regular domains to signals on graphs is gaining increasing popularity in the GSP community. The most commonly used model to learn graphs from these stationary signals is SpecT, which forms the foundation for nearly all the subsequent, more advanced models. Despite its strengths, the practical formulation of the model, known as rSpecT, has been identified to be susceptible to the choice of hyperparameters. More critically, it may suffer from infeasibility as an optimization problem. In this paper, we introduce the first condition that ensures the infeasibility of rSpecT and design a novel model called LogSpecT, along with its practical formulation rLogSpecT to overcome this issue. Contrary to rSpecT, our novel practical model rLogSpecT is always feasible. Furthermore, we provide recovery guarantees of rLogSpecT from modern optimization tools related to epi-convergence, which could be of independent interest and significant for various learning problems. To demonstrate the practical advantages of rLogSpecT, a highly efficient algorithm based on the linearized alternating direction method of multipliers (L-ADMM) that allows closed-form solutions for each subproblem is proposed with convergence guarantees. Extensive numerical results on both synthetic and real networks not only corroborate the stability of our proposed methods, but also highlight their comparable and even superior performance than existing models.'}",https://openreview.net{'value': '/pdf/926a038eb95443ae671a032c5b3a78a4ddf67138.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=VGLXjbTSYa,{'value': 'Delegated Classification'},Eden Saig; Inbal Talgam-Cohen; Nir Rosenfeld,~Eden_Saig1; ~Inbal_Talgam-Cohen2; ~Nir_Rosenfeld2,"{'value': ['Delegation', 'Algorithmic Contract Design', 'Moral Hazard', 'Learning Curves']}","{'value': 'When machine learning is outsourced to a rational agent, conflicts of interest might arise and severely impact predictive performance. In this work, we propose a theoretical framework for incentive-aware delegation of machine learning tasks. We model delegation as a principal-agent game, in which accurate learning can be incentivized by the principal using performance-based contracts. Adapting the economic theory of contract design to this setting, we define budget-optimal contracts and prove they take a simple threshold form under reasonable assumptions. In the binary-action case, the optimality of such contracts is shown to be equivalent to the classic Neyman-Pearson lemma, establishing a formal connection between contract design and statistical hypothesis testing. Empirically, we demonstrate that budget-optimal contracts can be constructed using small-scale data, leveraging recent advances in the study of learning curves and scaling laws. Performance and economic outcomes are evaluated using synthetic and real-world classification tasks.'}",https://openreview.net{'value': '/pdf/466943f3ab05629a518eb23d46289938a5ccc034.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=VCOZaczCHg,{'value': 'Mixed-Initiative Multiagent Apprenticeship Learning for Human Training of Robot Teams'},Esmaeil Seraj; Jerry Yuyang Xiong; Mariah L Schrum; Matthew Gombolay,~Esmaeil_Seraj1; ~Jerry_Yuyang_Xiong1; ~Mariah_L_Schrum1; ~Matthew_Gombolay1,"{'value': ['Learning from Demonstration', 'Multi-Robot Systems', 'Teaching Robot Teams']}","{'value': ""Extending recent advances in Learning from Demonstration (LfD) frameworks to multi-robot settings poses critical challenges such as environment non-stationarity due to partial observability which is detrimental to the applicability of existing methods. Although prior work has shown that enabling communication among agents of a robot team can alleviate such issues, creating inter-agent communication under existing Multi-Agent LfD (MA-LfD) frameworks requires the human expert to provide demonstrations for both environment actions and communication actions, which necessitates an efficient communication strategy on a known message spaces. To address this problem, we propose Mixed-Initiative Multi-Agent Apprenticeship Learning (MixTURE). MixTURE enables robot teams to learn from a human expert-generated data a preferred policy to accomplish a collaborative task, while simultaneously learning emergent inter-agent communication to enhance team coordination. The key ingredient to MixTURE's success is automatically learning a communication policy, enhanced by a mutual-information maximizing reverse model that rationalizes the underlying expert demonstrations without the need for human generated data or an auxiliary reward function. MixTURE outperforms a variety of relevant baselines on diverse data generated by human experts in complex heterogeneous domains. MixTURE is the first MA-LfD framework to enable learning multi-robot collaborative policies directly from real human data, resulting in ~44% less human workload, and ~46% higher usability score.""}",https://openreview.net{'value': '/pdf/fe81cd3ddf306f231f510fc993d7267ed064c6d6.pdf'},{'abstract_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=V5Oh7Aqfft,{'value': 'Causal Effect Regularization: Automated Detection and Removal of Spurious Correlations'},Abhinav Kumar; Amit Deshpande; Amit Sharma,~Abhinav_Kumar3; ~Amit_Deshpande1; ~Amit_Sharma3,"{'value': ['Spurious Correlation', 'Out of Distribution Generalization']}","{'value': 'In many classification datasets, the task labels are spuriously correlated with some input attributes. Classifiers trained on such datasets often rely on these attributes for prediction, especially when the spurious correlation is high, and thus fail to\ngeneralize whenever there is a shift in the attributes’ correlation at deployment. If we assume that the spurious attributes are known a priori, several methods have been proposed to learn a classifier that is invariant to the specified attributes. However, in real-world data, information about spurious attributes is typically unavailable. Therefore, we propose a method that automatically identifies spurious attributes by estimating their causal effect on the label and then uses a regularization objective to mitigate the classifier’s reliance on them. Although causal effect of an attribute on the label is not always identified, we present two commonly occurring data-generating processes where the effect can be identified. Compared to recent work for identifying spurious attributes, we find that our method, AutoACER, is\nmore accurate in removing the attribute from the learned model, especially when spurious correlation is high. Specifically, across synthetic, semi-synthetic, and real-world datasets, AutoACER shows significant improvement in a metric used to quantify the dependence of a classifier on spurious attributes ($\\Delta$Prob), while obtaining better or similar accuracy. Empirically we find that AutoACER mitigates\nthe reliance on spurious attributes even under noisy estimation of causal effects or when the causal effect is not identified. To explain the empirical robustness of our method, we create a simple linear classification task with two sets of attributes: causal and spurious. Under this setting, we prove that AutoACER only requires the ranking of estimated causal effects to be correct across attributes to select the\ncorrect classifier.'}",https://openreview.net{'value': '/pdf/24b8264af0069dc005b075c13f4f58bd9d197229.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=UuNd9A6noD,{'value': 'Bayesian Optimisation of Functions on Graphs'},Xingchen Wan; Pierre Osselin; Henry Kenlay; Binxin Ru; Michael A Osborne; Xiaowen Dong,~Xingchen_Wan1; ~Pierre_Osselin1; ~Henry_Kenlay1; ~Binxin_Ru1; ~Michael_A_Osborne1; ~Xiaowen_Dong1,"{'value': ['graphs', 'Bayesian optimisation', 'scalability']}","{'value': 'The increasing availability of graph-structured data motivates the task of optimising over functions defined on the node set of graphs. Traditional graph search algorithms can be applied in this case, but they may be sample-inefficient and do not make use of information about the function values; on the other hand, Bayesian optimisation is a class of promising black-box solvers with superior sample efficiency, but it has scarcely been applied to such novel setups. To fill this gap, we propose a novel Bayesian optimisation framework that optimises over functions defined on generic, large-scale and potentially unknown graphs. Through the learning of suitable kernels on graphs, our framework has the advantage of adapting to the behaviour of the target function. The local modelling approach further guarantees the efficiency of our method. Extensive experiments on both synthetic and real-world graphs demonstrate the effectiveness of the proposed optimisation framework.'}",https://openreview.net{'value': '/pdf/e46daf80dbfc5912d04a38bb3c3cf240c3b4053c.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=UkPeUXML7s,{'value': 'Approximate Heavy Tails in Offline (Multi-Pass) Stochastic Gradient Descent'},Krunoslav Lehman Pavasovic; Alain Durmus; Umut Simsekli,~Krunoslav_Lehman_Pavasovic1; ~Alain_Durmus1; ~Umut_Simsekli1,"{'value': ['SGD', 'heavy-tails', 'wasserstein convergence']}","{'value': 'A recent line of empirical studies has demonstrated that SGD might exhibit a heavy-tailed behavior in practical settings, and the heaviness of the tails might correlate with the overall performance. In this paper, we investigate the emergence of such heavy tails. Previous works on this problem only considered, up to our knowledge, online (also called single-pass) SGD, in which the emergence of heavy tails in theoretical findings is contingent upon access to an infinite amount of data. Hence, the underlying mechanism generating the reported heavy-tailed behavior in practical settings, where the amount of training data is finite, is still not well-understood. Our contribution aims to fill this gap. In particular, we show that the stationary distribution of offline (also called multi-pass) SGD exhibits ‘approximate’ power-law tails and the approximation error is controlled by how fast the empirical distribution of the training data converges to the true underlying data distribution in the Wasserstein metric. Our main takeaway is that, as the number of data points increases, offline SGD will behave increasingly ‘power-law-like’. To achieve this result, we first prove nonasymptotic Wasserstein convergence bounds for offline SGD to online SGD as the number of data points increases, which can be interesting on their own. Finally, we illustrate our theory on various experiments conducted on synthetic data and neural networks.'}",https://openreview.net{'value': '/pdf/3540a930f63eb69ed07f357f2f8c704997560b67.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=UgomCjCWjC,{'value': 'Multi-Agent First Order Constrained Optimization in Policy Space'},Youpeng Zhao; Yaodong Yang; Zhenbo Lu; Wengang Zhou; Houqiang Li,~Youpeng_Zhao1; ~Yaodong_Yang1; ~Zhenbo_Lu1; ~Wengang_Zhou1; ~Houqiang_Li1,"{'value': ['Safe Multi-agent Reinforcement Learning', 'constrained policy optimisation', 'first-order optimisation']}","{'value': 'In the realm of multi-agent reinforcement learning (MARL), achieving high performance is crucial for a successful multi-agent system.\nMeanwhile, the ability to avoid unsafe actions is becoming an urgent and imperative problem to solve for real-life applications. \nWhereas, it is still challenging to develop a safety-aware method for multi-agent systems in MARL. In this work, we introduce a novel approach called Multi-Agent First Order Constrained Optimization in Policy Space (MAFOCOPS), which effectively addresses the dual objectives of attaining satisfactory performance and enforcing safety constraints. Using data generated from the current policy, MAFOCOPS first finds the optimal update policy by solving a constrained optimization problem in the nonparameterized policy space. Then, the update policy is projected back into the parametric policy space to achieve a feasible policy. Notably, our method is first-order in nature, ensuring the ease of implementation, and exhibits an approximate upper bound on the worst-case constraint violation. Empirical results show that our approach achieves remarkable performance while satisfying safe constraints on several safe MARL benchmarks.'}",https://openreview.net{'value': '/pdf/94a6431b78ae792577d82bc0413118e12ba8e8b8.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=UXtLrsG4Rf,{'value': 'Intensity Profile Projection: A Framework for Continuous-Time Representation Learning for Dynamic Networks'},Alexander Modell; Ian Gallagher; Emma Ceccherini; Nick Whiteley; Patrick Rubin-Delanchy,~Alexander_Modell1; ~Ian_Gallagher1; gs22311@bristol.ac.uk; ~Nick_Whiteley1; ~Patrick_Rubin-Delanchy1,"{'value': ['dynamic networks', 'representation learning', 'spectral methods']}","{'value': ""We present a new representation learning framework, Intensity Profile Projection, for continuous-time dynamic network data. Given triples $(i,j,t)$, each representing a time-stamped ($t$) interaction between two entities ($i,j$), our procedure returns a continuous-time trajectory for each node, representing its behaviour over time. The framework consists of three stages: estimating pairwise intensity functions, e.g. via kernel smoothing; learning a projection which minimises a notion of intensity reconstruction error; and constructing evolving node representations via the learned projection. The trajectories satisfy two properties, known as structural and temporal coherence, which we see as fundamental for reliable inference. Moreoever, we develop estimation theory providing tight control on the error of any estimated trajectory, indicating that the representations could even be used in quite noise-sensitive follow-on analyses. The theory also elucidates the role of smoothing as a bias-variance trade-off, and shows how we can reduce the level of smoothing as the signal-to-noise ratio increases on account of the algorithm `borrowing strength' across the network.""}",https://openreview.net{'value': '/pdf/cfbf82fa96af353477fea49bf631af76a8cf3181.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=UWd4ysACo4,{'value': 'Expressive Sign Equivariant Networks for Spectral Geometric Learning'},Derek Lim; Joshua Robinson; Stefanie Jegelka; Haggai Maron,~Derek_Lim1; ~Joshua_Robinson4; ~Stefanie_Jegelka3; ~Haggai_Maron1,"{'value': ['Eigenvectors', 'spectral', 'geometry', 'universal approximation', 'graph', 'equivariance', 'invariance']}","{'value': 'Recent work has shown the utility of developing machine learning models that respect the structure and symmetries of eigenvectors. These works promote sign invariance, since for any eigenvector v the negation -v is also an eigenvector. However, we show that sign invariance is theoretically limited for tasks such as building orthogonally equivariant models and learning node positional encodings for link prediction in graphs. In this work, we demonstrate the benefits of sign equivariance for these tasks. To obtain these benefits, we develop novel sign equivariant neural network architectures. Our models are based on a new analytic characterization of sign equivariant polynomials and thus inherit provable expressiveness properties. Controlled synthetic experiments show that our networks can achieve the theoretically predicted benefits of sign equivariant models.'}",https://openreview.net{'value': '/pdf/3fa1f5e01c5cdea046b4fc7b41e55134c431c116.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=UHIDdtxmVS,"{'value': ""Asynchrony-Robust Collaborative Perception via Bird's Eye View Flow""}",Sizhe Wei; Yuxi Wei; Yue Hu; Yifan Lu; Yiqi Zhong; Siheng Chen; Ya Zhang,~Sizhe_Wei1; ~Yuxi_Wei1; ~Yue_Hu1; ~Yifan_Lu1; ~Yiqi_Zhong1; ~Siheng_Chen1; ~Ya_Zhang1,{'value': ['Collaborative Perception; BEV Flow; Time Asynchronization']},"{'value': ""Collaborative perception can substantially boost each agent's perception ability by facilitating communication among multiple agents. However, temporal asynchrony among agents is inevitable in the real world due to communication delays, interruptions, and clock misalignments. This issue causes information mismatch during multi-agent fusion, seriously shaking the foundation of collaboration. To address this issue, we propose CoBEVFlow, an asynchrony-robust collaborative perception system based on bird's eye view (BEV) flow. The key intuition of CoBEVFlow is to compensate motions to align asynchronous collaboration messages sent by multiple agents. To model the motion in a scene, we propose BEV flow, which is a collection of the motion vector corresponding to each spatial location. Based on BEV flow, asynchronous perceptual features can be reassigned to appropriate positions, mitigating the impact of asynchrony. CoBEVFlow has two advantages: (i) CoBEVFlow can handle asynchronous collaboration messages sent at irregular, continuous time stamps without discretization; and (ii) with BEV flow, CoBEVFlow only transports the original perceptual features, instead of generating new perceptual features, avoiding additional noises. To validate CoBEVFlow's efficacy, we create IRregular V2V(IRV2V), the first synthetic collaborative perception dataset with various temporal asynchronies that simulate different real-world scenarios. Extensive experiments conducted on both IRV2V and the real-world dataset DAIR-V2X show that CoBEVFlow consistently outperforms other baselines and is robust in extremely asynchronous settings. The code is available at https://github.com/MediaBrain-SJTU/CoBEVFlow.""}",https://openreview.net{'value': '/pdf/b59550d53ef0dca7711cd08b70e87a874f07026d.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=UBBeUjTja8,{'value': 'Cross-modal Active Complementary Learning with Self-refining Correspondence'},Yang Qin; Yuan Sun; Dezhong Peng; Joey Tianyi Zhou; Xi Peng; Peng Hu,~Yang_Qin4; ~Yuan_Sun2; ~Dezhong_Peng1; ~Joey_Tianyi_Zhou1; ~Xi_Peng3; ~Peng_Hu2,"{'value': ['Cross-modal learning', 'Image-text matching', 'Noisy correspondence.']}","{'value': 'Recently, image-text matching has attracted more and more attention from academia and industry, which is fundamental to understanding the latent correspondence across visual and textual modalities. However, most existing methods implicitly assume the training pairs are well-aligned while ignoring the ubiquitous annotation noise, a.k.a noisy correspondence (NC), thereby inevitably leading to a performance drop. Although some methods attempt to address such noise, they still face two challenging problems: excessive memorizing/overfitting and unreliable correction for NC, especially under high noise. To address the two problems, we propose a generalized Cross-modal Robust Complementary Learning framework (CRCL), which benefits from a novel Active Complementary Loss (ACL) and an efficient Self-refining Correspondence Correction (SCC) to improve the robustness of existing methods.   Specifically, ACL exploits active and complementary learning losses to reduce the risk of providing erroneous supervision, leading to theoretically and experimentally demonstrated robustness against NC. SCC utilizes multiple self-refining processes with momentum correction to enlarge the receptive field for correcting correspondences, thereby alleviating error accumulation and achieving accurate and stable corrections. We carry out extensive experiments on three image-text benchmarks, i.e., Flickr30K, MS-COCO, and CC152K, to verify the superior robustness of our CRCL against synthetic and real-world noisy correspondences.'}",https://openreview.net{'value': '/pdf/55a44c6257c0aa59fea8a6c26aee01a63ee519b3.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=U9zRgpgdFI,{'value': 'A Hierarchical Spatial Transformer for Massive Point Samples  in Continuous Space'},Wenchong He; Zhe Jiang; Tingsong Xiao; Zelin Xu; Shigang Chen; Ronald Fick; MILES D MEDINA; Christine Angelini,~Wenchong_He1; ~Zhe_Jiang1; ~Tingsong_Xiao1; ~Zelin_Xu1; ~Shigang_Chen1; ~Ronald_Fick1; ~MILES_D_MEDINA1; ~Christine_Angelini1,"{'value': ['Spatial representation learning', 'transformer', 'quadtree', 'efficiency']}","{'value': 'Transformers are widely used deep learning architectures. Existing transformers are mostly designed for sequences (texts or time series), images or videos, and graphs. This paper proposes a novel transformer model for massive (up to a million) point samples in continuous space. Such data are ubiquitous in environment sciences (e.g., sensor observations), numerical simulations (e.g., particle-laden flow, astrophysics), and location-based services (e.g., POIs and trajectories). However, designing a transformer for massive spatial points is non-trivial due to several challenges, including implicit long-range and multi-scale dependency on irregular points in continuous space, a non-uniform point distribution, the potential high computational costs of calculating all-pair attention across massive points, and the risks of over-confident predictions due to varying point density. To address these challenges, we propose a new hierarchical spatial transformer model, which includes multi-resolution representation learning within a quad-tree hierarchy and efficient spatial attention via coarse approximation. We also design an uncertainty quantification branch to estimate prediction confidence related to input feature noise and point sparsity. We provide a theoretical analysis of computational time complexity and memory costs. Extensive experiments on both real-world and synthetic datasets show that our method outperforms multiple baselines in prediction accuracy and our model can scale up to one million points on one NVIDIA A100 GPU. The code is available at https://github.com/spatialdatasciencegroup/HST'}",https://openreview.net{'value': '/pdf/18e01a489fda98cf16c07ed9698c9978e16a4af4.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=TjJJmcHw9p,{'value': 'Exact recovery and Bregman hard clustering of node-attributed Stochastic Block Model'},Maximilien Dreveton; Felipe Schreiber Fernandes; Daniel R. Figueiredo,~Maximilien_Dreveton1; felipesc@cos.ufrj.br; ~Daniel_R._Figueiredo1,"{'value': ['community detection', 'stochastic block model', 'bregman divergence']}","{'value': 'Classic network clustering tackles the problem of identifying sets of nodes (communities) that have similar connection patterns. However, in many scenarios nodes also have attributes that are correlated and can also be used to identify node clusters. Thus, network information (edges) and node information (attributes) can be jointly leveraged to design high-performance clustering algorithms. Under a general model for the network and node attributes, this work establishes an information-theoretic criteria for the exact recovery of community labels and characterizes a phase transition determined by the Chernoff-Hellinger divergence of the model. The criteria shows how network and attribute information can be exchanged in order to have exact recovery (e.g., more reliable network information requires less reliable attribute information). This work also presents an iterative clustering algorithm that maximizes the joint likelihood, assuming that the probability distribution of network interactions and node attributes belong to exponential families. This covers a broad range of possible interactions (e.g., edges with weights) and attributes (e.g., non-Gaussian models) while also exploring the connection between exponential families and Bregman divergences. Extensive numerical experiments using synthetic and real data indicate that the proposed algorithm outperforms algorithms that leverage only network or only attribute information as well as recently proposed algorithms that perform clustering using both sources of information. The contributions of this work provide insights into the fundamental limits and practical techniques for inferring community labels on node-attributed networks.'}",https://openreview.net{'value': '/pdf/7846f8fdf5439f2d187d0609ab9440c18c3ca307.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=TZtw5YgxTE,{'value': 'MIM4DD: Mutual Information Maximization for Dataset Distillation'},Yuzhang Shang; Zhihang Yuan; Yan Yan,~Yuzhang_Shang1; ~Zhihang_Yuan1; ~Yan_Yan6,{'value': ['Dataset Distillation']},"{'value': 'Dataset distillation (DD) aims to synthesize a small dataset whose test performance is comparable to a full dataset using the same model. State-of-the-art (SoTA) methods optimize synthetic datasets primarily by matching heuristic indicators extracted from two networks: one from real data and one from synthetic data (see Fig.1, Left), such as gradients and training trajectories. DD is essentially a compression problem that emphasizes on maximizing the preservation of information contained in the data. We argue that well-defined metrics which measure the amount of shared information between variables in information theory are necessary for success measurement, but are never considered by previous works. Thus, we introduce mutual information (MI) as the metric to quantify the shared information between the synthetic and the real datasets, and devise MIM4DD numerically maximizing the MI via a newly designed optimizable objective within a contrastive learning framework to update the synthetic dataset. Specifically, we designate the samples in different datasets who share the same labels as positive pairs, and vice versa negative pairs. Then we respectively pull and push those samples in positive and negative pairs into contrastive space via minimizing NCE loss. As a result, the targeted MI can be transformed into a lower bound represented by feature maps of samples, which is numerically feasible. Experiment results show that MIM4DD can be implemented as an add-on module to existing SoTA DD methods.'}",https://openreview.net{'value': '/pdf/cf67f80eb6e52002362a50d315aee81746f974c1.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=TAIYBdRb3C,{'value': 'Curve Your Enthusiasm: Concurvity Regularization in Differentiable Generalized Additive Models'},Julien Niklas Siems; Konstantin Ditschuneit; Winfried Ripken; Alma Lindborg; Maximilian Schambach; Johannes Otterbach; Martin Genzel,~Julien_Niklas_Siems1; ~Konstantin_Ditschuneit1; ~Winfried_Ripken1; ~Alma_Lindborg1; ~Maximilian_Schambach1; ~Johannes_Otterbach1; ~Martin_Genzel1,"{'value': ['Interpretable Machine Learning', 'Generalized Additive Models', 'Concurvity', 'Multicollinearity', 'Regularization', 'Time-Series Forecasting', 'Interpretability']}","{'value': 'Generalized Additive Models (GAMs) have recently experienced a resurgence in popularity due to their interpretability, which arises from expressing the target value as a sum of non-linear transformations of the features. Despite the current enthusiasm for GAMs, their susceptibility to concurvity — i.e., (possibly non-linear) dependencies between the features — has hitherto been largely overlooked. Here, we demonstrate how concurvity can severly impair the interpretability of GAMs and propose a remedy: a conceptually simple, yet effective regularizer which penalizes pairwise correlations of the non-linearly transformed feature variables. This procedure is applicable to any differentiable additive model, such as Neural Additive Models or NeuralProphet, and enhances interpretability by eliminating ambiguities due to self-canceling feature contributions. \nWe validate the effectiveness of our regularizer in experiments on synthetic as well as real-world datasets for time-series and tabular data. Our experiments show that concurvity in GAMs can be reduced without significantly compromising prediction quality, improving interpretability and reducing variance in the feature importances.'}",https://openreview.net{'value': '/pdf/dfb14e21dc74e166a88c4c13100277b183a306e8.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=StD4J5ZlI5,{'value': 'Dataset Diffusion: Diffusion-based Synthetic Data Generation for Pixel-Level Semantic Segmentation'},Quang Ho Nguyen; Truong Tuan Vu; Anh Tuan Tran; Khoi Nguyen,~Quang_Ho_Nguyen1; ~Truong_Tuan_Vu1; ~Anh_Tuan_Tran2; ~Khoi_Nguyen1,{'value': ['Deep learning; Diffusion Models; Semantic Segmentation; Text-to-Image']},"{'value': 'Preparing training data for deep vision models is a labor-intensive task. To address this, generative models have emerged as an effective solution for generating synthetic data. While current generative models produce image-level category labels, we propose a novel method for generating pixel-level semantic segmentation labels using the text-to-image generative model Stable Diffusion (SD). By utilizing the text prompts, cross-attention, and self-attention of SD, we introduce three new techniques: class-prompt appending, class-prompt cross-attention, and self-attention exponentiation. These techniques enable us to generate segmentation maps corresponding to synthetic images. These maps serve as pseudo-labels for training semantic segmenters, eliminating the need for labor-intensive pixel-wise annotation. To account for the imperfections in our pseudo-labels, we incorporate uncertainty regions into the segmentation, allowing us to disregard loss from those regions. We conduct evaluations on two datasets, PASCAL VOC and MSCOCO, and our approach significantly outperforms concurrent work. Our benchmarks and code will be released at https://github.com/VinAIResearch/Dataset-Diffusion.'}",https://openreview.net{'value': '/pdf/3b7a35af699a40af6dd9721574a5ec8253cb2e8a.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=STrXsSIEiq,{'value': 'Learning Robust Statistics for Simulation-based Inference under Model Misspecification'},Daolang Huang; Ayush Bharti; Amauri H Souza; Luigi Acerbi; Samuel Kaski,~Daolang_Huang1; ~Ayush_Bharti1; ~Amauri_H_Souza1; ~Luigi_Acerbi1; ~Samuel_Kaski1,"{'value': ['Simulation-based inference', 'model misspecification', 'likelihood-free inference', 'approximate Bayesian computation', 'neural posterior estimation']}","{'value': 'Simulation-based inference (SBI) methods such as approximate Bayesian computation (ABC),  synthetic likelihood, and neural posterior estimation (NPE) rely on simulating statistics to infer parameters of intractable likelihood models. However, such methods are known to yield untrustworthy and misleading inference outcomes under model misspecification, thus hindering their widespread applicability. In this work, we propose the first general approach to handle model misspecification that works across different classes of SBI methods. Leveraging the fact that the choice of statistics determines the degree of misspecification in SBI, we introduce a regularized loss function that penalizes those statistics that increase the mismatch between the data and the model. Taking NPE and ABC as use cases, we demonstrate the superior performance of our method on high-dimensional time-series models that are artificially misspecified. We also apply our method to real data from the field of radio propagation where the model is known to be misspecified. We show empirically that the method yields robust inference in misspecified scenarios, whilst still being accurate when the model is well-specified.'}",https://openreview.net{'value': '/pdf/3d435d746061812803f8f0fe80da5c0a035e8c56.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=SOEF0i0G1z,{'value': 'Cognitive Model Discovery via Disentangled RNNs'},Kevin J Miller; Maria K Eckstein; Matthew Botvinick; Zeb Kurth-Nelson,~Kevin_J_Miller1; ~Maria_K_Eckstein1; ~Matthew_Botvinick1; ~Zeb_Kurth-Nelson1,"{'value': ['Cognitive modeling', 'neural networks', 'interpretability', 'disentangling', 'neuroscience', 'rodent behavior']}","{'value': 'Computational cognitive models are a fundamental tool in behavioral neuroscience. They embody in software precise hypotheses about the cognitive mechanisms underlying a particular behavior. Constructing these models is typically a difficult iterative process that requires both inspiration from the literature and the creativity of an individual researcher. Here, we adopt an alternative approach to learn parsimonious cognitive models directly from data. We fit behavior data using a recurrent neural network that is penalized for carrying excess information between timesteps, leading to sparse, interpretable representations and dynamics. When fitting synthetic behavioral data from known cognitive models, our method recovers the underlying form of those models. When fit to choice data from rats performing a bandit task, our method recovers simple and interpretable models that make testable predictions about neural mechanisms.'}",https://openreview.net{'value': '/pdf/fd74478122c098941d7a2d02bbdc6f700dc88c02.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Rzk3GP1HN7,{'value': 'SwiftSage: A Generative Agent with Fast and Slow Thinking for Complex Interactive Tasks'},Bill Yuchen Lin; Yicheng Fu; Karina Yang; Faeze Brahman; Shiyu Huang; Chandra Bhagavatula; Prithviraj Ammanabrolu; Yejin Choi; Xiang Ren,~Bill_Yuchen_Lin1; ~Yicheng_Fu1; ~Karina_Yang1; ~Faeze_Brahman1; ~Shiyu_Huang2; ~Chandra_Bhagavatula1; ~Prithviraj_Ammanabrolu1; ~Yejin_Choi1; ~Xiang_Ren1,"{'value': ['interactive reasoning', 'text game', 'agents', 'action planning', 'large language models']}","{'value': ""We introduce SwiftSage, a novel agent framework inspired by the dual-process theory of human cognition, designed to excel in action planning for complex interactive reasoning tasks. SwiftSage integrates the strengths of behavior cloning and prompting large language models (LLMs) to enhance task completion performance. The framework comprises two primary modules: the Swift module, representing fast and intuitive thinking, and the Sage module, emulating deliberate thought processes. The Swift module is a small encoder-decoder LM fine-tuned on the oracle agent's action trajectories, while the Sage module employs LLMs such as GPT-4 for subgoal planning and grounding. We develop a heuristic method to harmoniously integrate the two modules, resulting in a more efficient and robust problem-solving process. In 30 tasks from the ScienceWorld benchmark, SwiftSage significantly outperforms other methods such as SayCan, ReAct, and Reflexion, demonstrating its effectiveness in solving complex interactive tasks.""}",https://openreview.net{'value': '/pdf/af990bb2c9c8c0ae4a168311d783c18114f0fdff.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Rvk1wdwz1L,"{'value': 'Similarity, Compression and Local Steps: Three Pillars of Efficient Communications for Distributed Variational Inequalities'}",Aleksandr Beznosikov; Martin Takáč; Alexander Gasnikov,~Aleksandr_Beznosikov1; ~Martin_Takáč1; ~Alexander_Gasnikov1,"{'value': ['convex optimization', 'variational inequalities', 'similarity', 'local methods', 'compression', 'partial participation']}","{'value': ""Variational inequalities are a broad and flexible class of problems that includes minimization, saddle point, and fixed point problems as special cases. Therefore, variational inequalities are used in various applications ranging from equilibrium search to adversarial learning. With the increasing size of data and models, today's instances demand parallel and distributed computing for real-world machine learning problems, most of which can be represented as variational inequalities. Meanwhile, most distributed approaches have a significant bottleneck -- the cost of communications. The three main techniques to reduce the total number of communication rounds and the cost of one such round are the similarity of local functions, compression of transmitted information, and local updates. In this paper, we combine all these approaches. Such a triple synergy did not exist before for variational inequalities and saddle problems, nor even for minimization problems. The methods presented in this paper have the best theoretical guarantees of communication complexity and are significantly ahead of other methods for distributed variational inequalities. The theoretical results are confirmed by adversarial learning experiments on synthetic and real datasets.""}",https://openreview.net{'value': '/pdf/f7b8619c47456b90f4aaa955bd7d47d566cea108.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=RiwPYAMLur,{'value': 'Active representation learning for general task space with applications in robotics'},Yifang Chen; Yingbing Huang; Simon Shaolei Du; Kevin Jamieson; Guanya Shi,~Yifang_Chen1; ~Yingbing_Huang1; ~Simon_Shaolei_Du1; ~Kevin_Jamieson1; ~Guanya_Shi1,"{'value': ['active learning', 'representation learning', 'robotics', 'theory']}","{'value': 'Representation learning based on multi-task pretraining has become a powerful approach in many domains. In particular, task-aware representation learning aims to learn an optimal representation for a specific target task by sampling data from a set of source tasks, while task-agnostic representation learning seeks to learn a universal representation for a class of tasks.  In this paper, we propose a general and versatile algorithmic and theoretic framework for \\emph{active representation learning}, where the learner optimally chooses which source tasks to sample from. This framework, along with a tractable meta algorithm, allows most arbitrary target and source task spaces (from discrete to continuous), covers both task-aware and task-agnostic settings, and is compatible with deep representation learning practices. \nWe provide several instantiations under this framework, from bilinear and feature-based nonlinear to general nonlinear cases. In the bilinear case, by leveraging the non-uniform spectrum of the task representation and the calibrated source-target relevance, we prove that the sample complexity to achieve $\\varepsilon$-excess risk on target scales with $(k^*)^2 ||v^*||_2^2 \\varepsilon^{-2}$\n where $k^*$ is the effective dimension of the target and $||v^*||_2^2 \\in (0,1]$ represents the connection between source and target space. Compared to the passive one, this can save up to $\\frac{1}{d_W}$ of sample complexity, where $d_W$ is the task space dimension. \nFinally, we demonstrate different instantiations of our meta algorithm in synthetic datasets and robotics problems, from pendulum simulations to real-world drone flight datasets. On average, our algorithms outperform baselines by 20%-70%.'}",https://openreview.net{'value': '/pdf/a44a7ae3473d6e741ee196ed3b8a3c931aafd2b6.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=RhE01dqo8u,{'value': 'Feature Selection in the Contrastive Analysis Setting'},Ethan Weinberger; Ian Connick Covert; Su-In Lee,~Ethan_Weinberger2; ~Ian_Connick_Covert1; ~Su-In_Lee2,"{'value': ['Feature selection', 'contrastive analysis', 'computational biology', 'representation learning', 'information theory']}","{'value': 'Contrastive analysis (CA) refers to the exploration of variations uniquely enriched in a _target_ dataset as compared to a corresponding _background_ dataset generated from sources of variation that are irrelevant to a given task. For example, a biomedical data analyst may wish to find a small set of genes to use as a proxy for variations in genomic data only present among patients with a given disease (target) as opposed to healthy control subjects (background). However, as of yet the problem of feature selection in the CA setting has received little attention from the machine learning community. In this work we present contrastive feature selection (CFS),\na method for performing feature selection in the CA setting. We motivate our approach with a novel information-theoretic analysis of representation learning in the CA setting, and we empirically validate CFS on a semi-synthetic dataset and four real-world biomedical datasets. We find that our method consistently outperforms previously proposed state-of-the-art supervised and fully unsupervised feature selection methods not designed for the CA setting. An open-source implementation of our method is available at https://github.com/suinleelab/CFS.'}",https://openreview.net{'value': '/pdf/4138b470f77df106f0861ad0c051995c1d534832.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=RW7rZ8Y3Bp,{'value': 'Federated Spectral Clustering via Secure Similarity Reconstruction'},Dong Qiao; Chris Ding; Jicong Fan,~Dong_Qiao1; ~Chris_Ding1; ~Jicong_Fan2,"{'value': ['clustering', 'federated learning', 'privacy']}","{'value': 'Federated learning has a significant advantage in protecting information privacy. Many scholars proposed various secure learning methods within the framework of federated learning but the study on secure federated unsupervised learning especially clustering is limited. We in this work propose a secure kernelized factorization method for federated spectral clustering on distributed dataset. The method is non-trivial because the kernel or similarity matrix for spectral clustering is computed by data pairs, which violates the principle of privacy protection. Our method implicitly constructs an approximation for the kernel matrix on distributed data such that we can perform spectral clustering under the constraint of privacy protection. We provide a convergence guarantee of the optimization algorithm, reconstruction error bounds of the Gaussian kernel matrix, and the sufficient condition of correct clustering of our method. We also present some results of differential privacy. Numerical results on synthetic and real datasets demonstrate that the proposed method is efficient and accurate in comparison to the baselines.'}",https://openreview.net{'value': '/pdf/8f5a21fb7789155674df80ee26b21622067849a6.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=RUCFAKNDb2,{'value': 'Promises and Pitfalls of Threshold-based Auto-labeling'},Harit Vishwakarma; Heguang Lin; Frederic Sala; Ramya Korlakai Vinayak,~Harit_Vishwakarma1; ~Heguang_Lin1; ~Frederic_Sala1; ~Ramya_Korlakai_Vinayak1,"{'value': ['Auto Labeling', 'Active Learning', 'Selective Classification']}","{'value': 'Creating large-scale high-quality labeled datasets is a major bottleneck in supervised machine learning workflows. Threshold-based auto-labeling (TBAL), where validation data obtained from humans is used to find a confidence threshold above which the data is machine-labeled, reduces reliance on manual annotation. TBAL is emerging as a widely-used solution in practice. Given the long shelf-life and diverse usage of the resulting datasets, understanding when the data obtained by such auto-labeling systems can be relied on is crucial. This is the first work to analyze TBAL systems and derive sample complexity bounds on the amount of human-labeled validation data required for guaranteeing the quality of machine-labeled data. Our results provide two crucial insights. First, reasonable chunks of unlabeled data can be automatically and accurately labeled by seemingly bad models. Second, a hidden downside of TBAL systems is potentially prohibitive validation data usage. Together, these insights describe the promise and pitfalls of using such systems. \nWe validate our theoretical guarantees with extensive experiments on synthetic and real datasets.'}",https://openreview.net{'value': '/pdf/375cdfa1d7814c3a7a2ec045495733db41915fc2.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=RRUVZygUtr,{'value': 'Spectral Invariant Learning for Dynamic Graphs under Distribution Shifts'},Zeyang Zhang; Xin Wang; Ziwei Zhang; Zhou Qin; Weigao Wen; Hui Xue'; Haoyang Li; Wenwu Zhu,~Zeyang_Zhang1; ~Xin_Wang17; ~Ziwei_Zhang1; ~Zhou_Qin2; ~Weigao_Wen1; ~Hui_Xue'1; ~Haoyang_Li1; ~Wenwu_Zhu1,"{'value': ['Dynamic Graph Neural Networks', 'Out-of-Distribution Generalization']}","{'value': 'Dynamic graph neural networks (DyGNNs) currently struggle with handling distribution shifts that are inherent in dynamic graphs.\nExisting work on DyGNNs with out-of-distribution settings only focuses on the time domain, failing to handle cases involving distribution shifts in the spectral domain. In this paper, we discover that there exist cases with distribution shifts unobservable in the time domain while observable in the spectral domain, and propose to study distribution shifts on dynamic graphs in the spectral domain for the first time.\nHowever, this investigation poses two key challenges: i) it is non-trivial to capture different graph patterns that are driven by various frequency components entangled in the spectral domain; and ii) it remains unclear how to handle distribution shifts with the discovered spectral patterns. To address these challenges, we propose Spectral Invariant Learning for Dynamic Graphs under Distribution Shifts (SILD), which can handle distribution shifts on dynamic graphs by capturing and utilizing invariant and variant spectral patterns. Specifically, we first design a DyGNN with Fourier transform to obtain the ego-graph trajectory spectrums, allowing the mixed dynamic graph patterns to be transformed into separate frequency components. We then develop a disentangled spectrum mask to filter graph dynamics from various frequency components and discover the invariant and variant spectral patterns. Finally, we propose invariant spectral filtering, which encourages the model to rely on invariant patterns for generalization under distribution shifts. Experimental results on synthetic and real-world dynamic graph datasets demonstrate the superiority of our method for both node classification and link prediction tasks under distribution shifts.'}",https://openreview.net{'value': '/pdf/bca0c1fcf2b242196054696188eadd64bf721230.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=RMeQjexaRj,{'value': 'Elastic Decision Transformer'},Yueh-Hua Wu; Xiaolong Wang; Masashi Hamaya,~Yueh-Hua_Wu1; ~Xiaolong_Wang3; ~Masashi_Hamaya1,"{'value': ['Offline Reinforcement Learning', 'Trajectory Stitching', 'Decision Transformer']}","{'value': 'This paper introduces Elastic Decision Transformer (EDT), a significant advancement over the existing Decision Transformer (DT) and its variants. Although DT purports to generate an optimal trajectory, empirical evidence suggests it struggles with trajectory stitching, a process involving the generation of an optimal or near-optimal trajectory from the best parts of a set of sub-optimal trajectories. The proposed EDT differentiates itself by facilitating trajectory stitching during action inference at test time, achieved by adjusting the history length maintained in DT. Further, the EDT optimizes the trajectory by retaining a longer history when the previous trajectory is optimal and a shorter one when it is sub-optimal, enabling it to ""stitch"" with a more optimal trajectory. Extensive experimentation demonstrates EDT\'s ability to bridge the performance gap between DT-based and Q Learning-based approaches. In particular, the EDT outperforms Q Learning-based methods in a multi-task regime on the D4RL locomotion benchmark and Atari games.'}",https://openreview.net{'value': '/pdf/920e4d2d7995b529a4c04e52326188847a9af897.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=RInTOCEL3l,"{'value': 'Relax, it doesn’t matter how you get there: A new self-supervised approach for multi-timescale behavior analysis'}",Mehdi Azabou; Michael Jacob Mendelson; Nauman Ahad; Maks Sorokin; Shantanu Thakoor; Carolina Urzay; Eva L Dyer,~Mehdi_Azabou2; ~Michael_Jacob_Mendelson1; ~Nauman_Ahad1; ~Maks_Sorokin1; ~Shantanu_Thakoor5; ~Carolina_Urzay1; ~Eva_L_Dyer1,"{'value': ['animal behavior', 'behavioral neuroscience', 'self-supervised learning', 'multi-timescale']}","{'value': 'Unconstrained and natural  behavior consists of dynamics that are complex and  unpredictable, especially when trying to predict what will happen  multiple steps into the future. While some success has been found in building representations of animal behavior under constrained or simplified task-based conditions, many of these models cannot be applied to free and naturalistic settings where behavior becomes increasingly hard to model. In this work, we develop a multi-task representation learning model for animal behavior that combines two novel components: (i) an action-prediction objective that aims to predict the  distribution of actions over future timesteps, and (ii) a multi-scale architecture that builds separate latent spaces to accommodate short- and long-term dynamics. After demonstrating the ability of the method to build representations of both local and global dynamics in robots in varying environments and terrains, we apply our method to the MABe 2022 Multi-Agent Behavior challenge, where our model ranks first overall on both mice and fly benchmarks. In all of these cases, we show that our model can build representations that capture the many different factors that drive behavior and solve a wide range of downstream tasks.'}",https://openreview.net{'value': '/pdf/307c6dca91df2facd1757a88cc7c494fb5f468ac.pdf'},{'abstract_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=RACcp8Zbr9,{'value': 'Beyond Black-Box Advice: Learning-Augmented Algorithms for MDPs with Q-Value Predictions'},Tongxin Li; Yiheng Lin; Shaolei Ren; Adam Wierman,~Tongxin_Li1; ~Yiheng_Lin1; ~Shaolei_Ren1; ~Adam_Wierman1,"{'value': ['Time-varying MDP', 'Learning-augmented online algorithm', 'consistency and robustness tradeoff']}","{'value': 'We study the tradeoff between consistency and robustness in the context of a single-trajectory time-varying Markov Decision Process (MDP) with untrusted machine-learned advice. Our work departs from the typical approach of treating advice as coming from black-box sources by instead considering a setting where additional information about  how the advice is generated is available. We prove a first-of-its-kind consistency and robustness tradeoff given Q-value advice under a general MDP model that includes both continuous and discrete state/action spaces. Our results highlight that utilizing Q-value advice enables dynamic pursuit of the better of machine-learned advice and a robust baseline, thus result in near-optimal performance guarantees, which provably improves what can be obtained solely with black-box advice.'}",https://openreview.net{'value': '/pdf/0587073fbd2333f338d0b489452cad11c5787ba4.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Qu6Ln7d9df,{'value': 'Streaming Factor Trajectory Learning for Temporal Tensor Decomposition'},Shikai Fang; Xin Yu; Shibo Li; Zheng Wang; Robert Kirby; Shandian Zhe,~Shikai_Fang2; ~Xin_Yu4; ~Shibo_Li1; ~Zheng_Wang2; ~Robert_Kirby1; ~Shandian_Zhe1,"{'value': ['Tensor Decomposition', 'streaming method', 'Bayesian model']}","{'value': ""Practical tensor data is often along with time information. Most existing temporal decomposition approaches estimate a set of fixed factors for the objects in each tensor mode, and hence cannot capture the temporal evolution of the objects' representation. More important, we lack an effective approach to capture such evolution from streaming data, which is common in real-world applications.  To address these issues, we propose Streaming Factor Trajectory Learning (SFTL) for temporal tensor decomposition. We use Gaussian processes (GPs) to model the trajectory of  factors so as to flexibly estimate their temporal evolution. To address the computational challenges in handling streaming data, we convert the GPs into a state-space prior by constructing an equivalent stochastic differential equation (SDE).  We develop an efficient online filtering algorithm to estimate a decoupled running posterior of the involved factor states upon receiving new data. The decoupled estimation enables us to conduct standard Rauch-Tung-Striebel smoothing to compute the full posterior of all the  trajectories in parallel, without the need for revisiting any previous data. We have shown the advantage of SFTL in both synthetic tasks and real-world applications.""}",https://openreview.net{'value': '/pdf/6658e3b88dbc0567470a6b1073ad2cabf3e8f9cd.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=QKSejqE8Vp,{'value': 'An Optimal and Scalable Matrix Mechanism for Noisy Marginals under Convex Loss Functions'},Yingtai Xiao; Guanlin He; Danfeng Zhang; Daniel Kifer,~Yingtai_Xiao1; ~Guanlin_He1; ~Danfeng_Zhang1; ~Daniel_Kifer1,"{'value': ['differential privacy', 'marginals', 'matrix mechanism', 'scalability']}","{'value': 'Noisy marginals are a common form of confidentiality-protecting data release and are useful for many downstream tasks such as contingency table analysis, construction of Bayesian networks, and even synthetic data generation. Privacy mechanisms that provide unbiased noisy answers to linear queries (such as marginals) are known as matrix mechanisms.\n\nWe propose ResidualPlanner, a matrix mechanism for marginals with Gaussian noise that is both optimal and scalable. ResidualPlanner can optimize for many loss functions that can be written as a convex function of marginal variances (prior work was restricted to just one predefined objective function). ResidualPlanner can optimize the accuracy of marginals in large scale settings in seconds, even when the previous state of the art (HDMM) runs out of memory. It even runs on datasets with 100 attributes in a couple of minutes. Furthermore ResidualPlanner can efficiently compute variance/covariance values for each marginal (prior methods quickly run out of memory, even for relatively small datasets).'}",https://openreview.net{'value': '/pdf/ba0bed65e575d2f0f84a108cbe48cd516d28f592.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Q5tuGgqJwt,{'value': 'Refining Diffusion Planner for Reliable Behavior Synthesis by Automatic Detection of Infeasible Plans'},Kyowoon Lee; Seongun Kim; Jaesik Choi,~Kyowoon_Lee1; ~Seongun_Kim1; ~Jaesik_Choi1,"{'value': ['Offline Reinforcement Learning', 'Trajectory Optimization', 'Diffusion Models', 'Sequential Decision Making']}","{'value': 'Diffusion-based planning has shown promising results in long-horizon, sparse-reward tasks by training trajectory diffusion models and conditioning the sampled trajectories using auxiliary guidance functions. However, due to their nature as generative models, diffusion models are not guaranteed to generate feasible plans, resulting in failed execution and precluding planners from being useful in safety-critical applications. In this work, we propose a novel approach to refine unreliable plans generated by diffusion models by providing refining guidance to error-prone plans. To this end, we suggest a new metric named restoration gap for evaluating the quality of individual plans generated by the diffusion model. A restoration gap is estimated by a gap predictor which produces restoration gap guidance to refine a diffusion planner. We additionally present an attribution map regularizer to prevent adversarial refining guidance that could be generated from the sub-optimal gap predictor, which enables further refinement of infeasible plans. We demonstrate the effectiveness of our approach on three different benchmarks in offline control settings that require long-horizon planning. We also illustrate that our approach presents explainability by presenting the attribution maps of the gap predictor and highlighting error-prone transitions, allowing for a deeper understanding of the generated plans.'}",https://openreview.net{'value': '/pdf/92a62f60f40316a6b1154b1afaa2fced6d35bbec.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Q3FXnCPZ1X,{'value': 'Fast and Simple Spectral Clustering in Theory and Practice'},Peter Macgregor,~Peter_Macgregor1,"{'value': ['spectral clustering', 'power method', 'spectral graph theory', 'graph algorithms']}","{'value': 'Spectral clustering is a popular and effective algorithm designed to find $k$ clusters in a graph $G$.\nIn the classical spectral clustering algorithm, the vertices of $G$ are embedded into $\\mathbb{R}^k$ using $k$ eigenvectors of the graph Laplacian matrix.\nHowever, computing this embedding is computationally expensive and dominates the running time of the algorithm.\nIn this paper, we present a simple spectral clustering algorithm based on a vertex embedding with $O(\\log(k))$ vectors computed by the power method.\nThe vertex embedding is computed in nearly-linear time with respect to the size of the graph, and\nthe algorithm provably recovers the ground truth clusters under natural assumptions on the input graph.\nWe evaluate the new algorithm on several synthetic and real-world datasets, finding that it is significantly faster than alternative clustering algorithms,\nwhile producing results with approximately the same clustering accuracy.'}",https://openreview.net{'value': '/pdf/15dd611c782df44564ad66b0f610ede333ac6804.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=PnbCA4ylIc,{'value': 'Goal Driven Discovery of Distributional Differences via Language Descriptions'},Ruiqi Zhong; Peter Zhang; Steve Li; Jinwoo Ahn; Dan Klein; Jacob Steinhardt,~Ruiqi_Zhong1; ~Peter_Zhang3; ~Steve_Li1; ~Jinwoo_Ahn3; ~Dan_Klein1; ~Jacob_Steinhardt1,"{'value': ['large language model', 'prompting', 'exploratory text analysis']}","{'value': ""Exploring large corpora can generate useful discoveries but is time-consuming for humans.\n    We formulate a new task, D5, that automatically discovers differences between two large corpora in a goal-driven way. \n    The task input is a problem comprising a user-specified research goal (“*comparing the side effects of drug A and drug*”) and a corpus pair (two large collections of patients' self-reported reactions after taking each drug). \n    The output is a goal-related description (discovery) of how these corpora differ (patients taking drug A “*mention feelings of paranoia*” more often).\n    We build a D5 system, and to quantitatively evaluate its performance, we 1) build a diagnostic benchmark, SynD5, to test whether it can recover known differences between two synthetic corpora, and 2) contribute a meta-dataset, OpenD5, aggregating 675 open-ended problems ranging across business, social sciences, humanities, machine learning, and health.\n    With both synthetic and real datasets, we confirm that language models can leverage the user-specified goals to propose more relevant candidate discoveries, and they sometimes produce discoveries previously unknown to the authors, including demographic differences in discussion topics, political stances in speech, insights in commercial reviews, and error patterns in NLP models.\n    Finally, we discuss the limitations of the current D5 system, which discovers correlation rather than causation and has the potential to reinforce societal biases when misused; therefore, practitioners should treat the outputs of our system with caution.""}",https://openreview.net{'value': '/pdf/c5753f73812c0b3e9c827988def54c1981d203b1.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=PnJaA0A8Lr,{'value': 'Trajectory Alignment: Understanding the Edge of Stability Phenomenon via Bifurcation Theory'},Minhak Song; Chulhee Yun,~Minhak_Song1; ~Chulhee_Yun1,"{'value': ['non-convex optimization', 'trajectory alignment of GD', 'edge of stability', 'progressive sharpening', 'bifurcation theory']}","{'value': 'Cohen et al. (2021) empirically study the evolution of the largest eigenvalue of the loss Hessian, also known as sharpness, along the gradient descent (GD) trajectory and observe the Edge of Stability (EoS) phenomenon. The sharpness increases at the early phase of training (referred to as progressive sharpening), and eventually saturates close to the threshold of $2 / \\text{(step size)}$. In this paper, we start by demonstrating through empirical studies that when the EoS phenomenon occurs, different GD trajectories (after a proper reparameterization) align on a specific bifurcation diagram independent of initialization. We then rigorously prove this trajectory alignment phenomenon for a two-layer fully-connected linear network and a single-neuron nonlinear network trained with a single data point. Our trajectory alignment analysis establishes both progressive sharpening and EoS phenomena, encompassing and extending recent findings in the literature.'}",https://openreview.net{'value': '/pdf/c43aa40a9159d1939d65e72dd855a71b2ea1c4a2.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=PmqBJ02V1p,{'value': 'Adaptive Principal Component Regression with Applications to Panel Data'},Anish Agarwal; Keegan Harris; Justin Whitehouse; Steven Wu,~Anish_Agarwal1; ~Keegan_Harris1; ~Justin_Whitehouse1; ~Steven_Wu1,"{'value': ['adaptive data collection', 'principal component regression', 'error-in-variables regression', 'panel data', 'synthetic controls', 'synthetic interventions', 'causal inference']}","{'value': 'Principal component regression (PCR) is a popular technique for fixed-design error-in-variables regression, a generalization of the linear regression setting in which the observed covariates are corrupted with random noise. We provide the first time-uniform finite sample guarantees for online (regularized) PCR whenever data is collected adaptively. Since the proof techniques for PCR in the fixed design setting do not readily extend to the online setting, our results rely on adapting tools from modern martingale concentration to the error-in-variables setting. As an application of our bounds, we provide a framework for counterfactual estimation of unit-specific treatment effects in panel data settings when interventions are assigned adaptively. Our framework may be thought of as a generalization of the synthetic interventions framework where data is collected via an adaptive intervention assignment policy.'}",https://openreview.net{'value': '/pdf/cc561fc3d1aa89a96c9adf582f617949192b3050.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=PmlNxZoXr4,{'value': 'Neural Processes with Stability'},Huafeng Liu; Liping Jing; Jian Yu,~Huafeng_Liu3; ~Liping_Jing3; ~Jian_Yu1,"{'value': ['Neural processes', 'stability']}","{'value': 'Unlike traditional statistical models depending on hand-specified priors, neural processes (NPs) have recently emerged as a class of powerful neural statistical models that combine the strengths of neural networks and stochastic processes. NPs can define a flexible class of stochastic processes well suited for highly non-trivial functions by encoding contextual knowledge into the function space. However, noisy context points introduce challenges to the algorithmic stability that small changes in training data may significantly change the models and yield lower generalization performance. In this paper, we provide theoretical guidelines for deriving stable solutions with high generalization by introducing the notion of algorithmic stability into NPs, which can be flexible to work with various NPs and achieves less biased approximation with theoretical guarantees. To illustrate the superiority of the proposed model, we perform experiments on both synthetic and real-world data, and the results demonstrate that our approach not only helps to achieve more accurate performance but also improves model robustness.'}",https://openreview.net{'value': '/pdf/fec95d3e40f0dadc51e972fad5740ad6267dfaa4.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=PkKpTK7hJ6,{'value': 'Truncating Trajectories in Monte Carlo Policy Evaluation: an Adaptive Approach'},Riccardo Poiani; Nicole Nobili; Alberto Maria Metelli; Marcello Restelli,~Riccardo_Poiani3; ~Nicole_Nobili1; ~Alberto_Maria_Metelli2; ~Marcello_Restelli1,"{'value': ['Reinforcement Learning', 'Policy Evaluation', 'Budget Optimization', 'Monte Carlo']}","{'value': ""Policy evaluation via Monte Carlo (MC) simulation is at the core of many MC Reinforcement Learning (RL) algorithms (e.g., policy gradient methods). In this context, the designer of the learning system specifies an interaction budget that the agent usually spends by collecting trajectories of *fixed length* within a simulator. However, is this data collection strategy the best option? To answer this question, in this paper, we consider as quality index the variance of an unbiased policy return estimator that uses trajectories of different lengths, i.e., *truncated*. We first derive a closed-form expression of this variance that clearly shows the sub-optimality of the fixed-length trajectory schedule. Furthermore, it suggests that adaptive data collection strategies that spend the available budget sequentially might be able to allocate a larger portion of transitions in timesteps in which more accurate sampling is required to reduce the variance of the final estimate. Building on these findings, we present an *adaptive* algorithm called **R**obust and **I**terative **D**ata collection strategy **O**ptimization (RIDO). The main intuition behind RIDO is to split the available interaction budget into mini-batches. At each round, the agent determines the most convenient schedule of trajectories that minimizes an empirical and robust estimate of the estimator's variance. After discussing the theoretical properties of our method, we conclude by assessing its performance across multiple domains. Our results show that RIDO can adapt its trajectory schedule toward timesteps where more sampling is required to increase the quality of the final estimation.""}",https://openreview.net{'value': '/pdf/e6c985ae9e545e2ff0cab6fb4c25d89cce9a1fd3.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=PXsqbAjpQd,{'value': 'SHOT: Suppressing the Hessian along the Optimization Trajectory for Gradient-Based Meta-Learning'},JunHoo Lee; Jayeon Yoo; Nojun Kwak,~JunHoo_Lee1; ~Jayeon_Yoo1; ~Nojun_Kwak1,"{'value': ['meta learning', 'Hessian', 'Gradient-Based meta learning', 'Feature Reuse', 'Implicit Prior']}","{'value': 'In this paper, we hypothesize that gradient-based meta-learning (GBML) implicitly suppresses the Hessian along the optimization\n  trajectory in the inner loop. Based on this hypothesis, we introduce an algorithm called\n  SHOT (Suppressing the Hessian along the Optimization Trajectory) that minimizes the distance between the parameters of the target and reference models to suppress the Hessian in the inner loop. Despite dealing with\n  high-order terms, SHOT does not increase the computational complexity of the baseline model much.\n  It is agnostic to both the algorithm and architecture used in GBML, making it highly\n  versatile and applicable to any GBML baseline. To validate the effectiveness of SHOT,\n  we conduct empirical tests on standard few-shot learning tasks and qualitatively\n  analyze its dynamics. We confirm our hypothesis empirically and demonstrate that SHOT\n  outperforms the corresponding baseline.'}",https://openreview.net{'value': '/pdf/785784c05f29fc0721c8c924369e3b395eb38e54.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=PTvxck0QDE,{'value': 'Simplicity Bias in 1-Hidden Layer Neural Networks'},Depen Morwani; jatin batra; Prateek Jain; Praneeth Netrapalli,~Depen_Morwani1; ~jatin_batra1; ~Prateek_Jain1; ~Praneeth_Netrapalli1,"{'value': ['Simplicity Bias', 'Gradient Descent', 'Implicit Bias', 'Neural Networks']}","{'value': 'Recent works have demonstrated that neural networks exhibit extreme *simplicity bias* (SB). That is,  they learn *only the simplest* features  to solve a task at hand, even in the presence of other, more robust but more complex features. Due to the lack of a general and rigorous definition of *features*, these works showcase SB on *semi-synthetic* datasets such as Color-MNIST , MNIST-CIFAR where\n defining features is relatively easier. \n\nIn this work, we rigorously define as well as thoroughly establish SB for *one hidden layer* neural networks in the infinite width regime. More concretely, (i) we define SB as the network essentially being a function of a low dimensional projection of the inputs \n(ii) theoretically, we show that when the data is linearly separable, the network primarily depends on only the linearly separable ($1$-dimensional) subspace even in the presence of an arbitrarily large number of other, more complex features which could have led to a significantly more robust classifier,  (iii) empirically, we show that models trained on *real* datasets such as Imagenet and Waterbirds-Landbirds indeed depend on a low dimensional projection of the inputs, thereby demonstrating SB on these datasets, iv) finally, we present a natural ensemble approach that encourages diversity in  models by training successive models on features not used by earlier models, and demonstrate that it yields models that are significantly more robust to Gaussian noise.'}",https://openreview.net{'value': '/pdf/8f47e6373e6a45cd402f974a8580ea23ca9d1670.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=PMvudWa53L,{'value': 'Fair Adaptive Experiments'},Waverly Wei; Xinwei Ma; Jingshen Wang,~Waverly_Wei1; x1ma@ucsd.edu; ~Jingshen_Wang1,{'value': ['Adaptive Randomized Experiment; Adaptive Design; Causal Inference']},"{'value': ""Randomized experiments have been the gold standard for assessing the effectiveness of a treatment, policy, or intervention, spanning various fields, including social sciences, biomedical studies, and e-commerce. The classical complete randomization approach assigns treatments based on a pre-specified probability and may lead to inefficient use of data. Adaptive experiments improve upon complete randomization by sequentially learning and updating treatment assignment probabilities using accrued evidence during the experiment. Hence, they can help achieve efficient data use and higher estimation efficiency. However, their application can also raise fairness and equity concerns, as assignment probabilities may vary drastically across groups of participants. Furthermore, when treatment is expected to be extremely beneficial to certain groups of participants, it is more appropriate to expose many of these participants to favorable treatment. In response to these challenges, we propose a fair adaptive experiment strategy that simultaneously enhances data use efficiency, achieves an ``envy-free'' treatment assignment guarantee, and improves the overall welfare of participants. An important feature of our proposed strategy is that we do not impose parametric modeling assumptions on the outcome variables, making it more versatile and applicable to a wider array of applications. Through our theoretical investigation, we characterize the convergence rate of the estimated treatment effects and the associated standard deviations at the group level and further prove that our adaptive treatment assignment algorithm, despite not having a closed-form expression, approaches the optimal allocation rule asymptotically. Our proof strategy takes into account the fact that the allocation decisions in our design depend on sequentially accumulated data, which poses a significant challenge in characterizing the properties and conducting statistical inference of our method. We further provide simulation evidence and two synthetic data studies to showcase the performance of our fair adaptive experiment strategy.""}",https://openreview.net{'value': '/pdf/2838e84d180e1f22e1504626dc9acea6fcab8e22.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Op9z2QfXbC,{'value': 'Modulated Neural ODEs'},Ilze Amanda Auzina; Cagatay Yildiz; Sara Magliacane; Matthias Bethge; Efstratios Gavves,~Ilze_Amanda_Auzina1; ~Cagatay_Yildiz1; ~Sara_Magliacane1; ~Matthias_Bethge1; ~Efstratios_Gavves1,"{'value': ['Neural ODEs', 'Modulator Variables', 'Dynamical Systems', 'Disentanglment']}","{'value': 'Neural ordinary differential equations (NODEs) have been proven useful for learning non-linear dynamics of arbitrary trajectories. However, current NODE methods capture variations across trajectories only via the initial state value or by auto-regressive encoder updates. In this work, we introduce Modulated Neural ODEs (MoNODEs), a novel framework that sets apart dynamics states from underlying static factors of variation and improves the existing NODE methods.  In particular, we introduce *time-invariant modulator variables* that are learned from the data. We incorporate our proposed framework into four existing NODE variants. We test MoNODE on oscillating systems, videos and human walking trajectories, where each trajectory has trajectory-specific modulation. Our framework consistently improves the existing model ability to generalize to new dynamic parameterizations and to perform far-horizon forecasting. In addition, we verify that the proposed modulator variables are informative of the true unknown factors of variation as measured by $R^2$ scores.'}",https://openreview.net{'value': '/pdf/32fecea16336d49dedd2f46edd5cb34d10eb82ae.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=OitmaxSAUu,{'value': 'Transformers are uninterpretable with myopic methods: a case study with bounded Dyck grammars'},Kaiyue Wen; Yuchen Li; Bingbin Liu; Andrej Risteski,~Kaiyue_Wen1; ~Yuchen_Li5; ~Bingbin_Liu1; ~Andrej_Risteski2,"{'value': ['Transformer', 'Self Attention', 'Dyck Language', 'Context Free Grammar', 'Formal Language', 'Theory', 'Interpretability']}","{'value': 'Transformer interpretability aims to understand the algorithm implemented by a learned Transformer by examining various aspects of the model, such as the weight matrices or the attention patterns.\nIn this work, through a combination of theoretical results and carefully controlled experiments on synthetic data, we take a critical view\nof methods that exclusively focus on individual parts of the model, rather than consider the network as a whole.\nWe consider a simple synthetic setup of learning a (bounded) Dyck language. Theoretically, we show that the set of models that (exactly or approximately) solve this task satisfy a structural characterization derived from ideas in formal languages (the pumping lemma).\nWe use this characterization to show that the set of optima is qualitatively rich; in particular, the attention pattern of a single layer can be ""nearly randomized"", while preserving the functionality of the network.\nWe also show via extensive experiments that these constructions are not merely a theoretical artifact: even with severe constraints to the architecture of the model, vastly different solutions can be reached via standard training. Thus, interpretability claims based on inspecting individual heads or weight matrices in the Transformer can be misleading.'}",https://openreview.net{'value': '/pdf/22540ea1571571f78536dc3cff2153be6fa8b7ef.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Of0GBzow8P,{'value': 'The Transient Nature of Emergent In-Context Learning in Transformers'},Aaditya K Singh; Stephanie C.Y. Chan; Ted Moskovitz; Erin Grant; Andrew M Saxe; Felix Hill,~Aaditya_K_Singh1; ~Stephanie_C.Y._Chan1; ~Ted_Moskovitz1; ~Erin_Grant1; ~Andrew_M_Saxe1; ~Felix_Hill1,"{'value': ['in-context learning', 'transformers', 'emergence', 'transience']}","{'value': ""Transformer neural networks can exhibit a surprising capacity for in-context learning (ICL) despite not being explicitly trained for it.  Prior work has provided a deeper understanding of how ICL emerges in transformers, e.g. through the lens of mechanistic interpretability, Bayesian inference, or by examining the distributional properties of training data. However, in each of these cases, ICL is treated largely as a persistent phenomenon; namely, once ICL emerges, it is assumed to persist asymptotically. Here, we show that the emergence of ICL during transformer training is, in fact, often transient. We train transformers on synthetic data designed so that both ICL and in-weights learning (IWL) strategies can lead to correct predictions. We find that ICL first emerges, then disappears and gives way to IWL, all while the training loss decreases, indicating an asymptotic preference for IWL. The transient nature of ICL is observed in transformers across a range of model sizes and datasets, raising the question of how much to ``overtrain'' transformers when seeking compact, cheaper-to-run models. We find that L2 regularization may offer a path to more persistent ICL that removes the need for early stopping based on ICL-style validation tasks. Finally, we present initial evidence that ICL transience may be caused by competition between ICL and IWL circuits.""}",https://openreview.net{'value': '/pdf/e437bfb2ceb185af0df65b26a3df7726532df15a.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=O63qgtebjH,{'value': 'Scalable Primal-Dual Actor-Critic Method for Safe Multi-Agent RL with General Utilities'},Donghao Ying; Yunkai Zhang; Yuhao Ding; Alec Koppel; Javad Lavaei,~Donghao_Ying1; ~Yunkai_Zhang2; ~Yuhao_Ding2; ~Alec_Koppel1; ~Javad_Lavaei1,"{'value': ['Reinforcement Learning Theory', 'Safe reinforcement learning', 'Multi-agent reinforcement learning']}","{'value': ""We investigate safe multi-agent reinforcement learning, where agents seek to collectively maximize an aggregate sum of local objectives while satisfying their own safety constraints. The objective and constraints are described by general utilities, i.e., nonlinear functions of the long-term state-action occupancy measure, which encompass broader decision-making goals such as risk, exploration, or imitations. The exponential growth of the state-action space size with the number of agents presents challenges for global observability, further exacerbated by the global coupling arising from agents' safety constraints. To tackle this issue, we propose a primal-dual method utilizing shadow reward and $\\kappa$-hop neighbor truncation under a form of correlation decay property, where $\\kappa$ is the communication radius. In the exact setting, our algorithm converges to a first-order stationary point (FOSP) at the rate of $\\mathcal{O}\\left(T^{-2/3}\\right)$. In the sample-based setting, we demonstrate that, with high probability, our algorithm requires $\\widetilde{\\mathcal{O}}\\left(\\epsilon^{-3.5}\\right)$ samples to achieve an $\\epsilon$-FOSP with an approximation error of $\\mathcal{O}(\\phi_0^{2\\kappa})$, where $\\phi_0\\in (0,1)$. Finally, we demonstrate the effectiveness of our model through extensive numerical experiments.""}",https://openreview.net{'value': '/pdf/f5c70505e09647b1b9d4711ee740e5a82dc69802.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=NyQwBttTnG,{'value': 'Information Design in Multi-Agent Reinforcement Learning'},Yue Lin; Wenhao Li; Hongyuan Zha; Baoxiang Wang,~Yue_Lin2; ~Wenhao_Li2; ~Hongyuan_Zha1; ~Baoxiang_Wang1,"{'value': ['multi-agent reinforcement learning', 'multi-agent communication', 'information design', 'signaling gradient', 'obedience constraints']}","{'value': 'Reinforcement learning (RL) is inspired by the way human infants and animals learn from the environment. The setting is somewhat idealized because, in actual tasks, other agents in the environment have their own goals and behave adaptively to the ego agent. To thrive in those environments, the agent needs to influence other agents so their actions become more helpful and less harmful. Research in computational economics distills two ways to influence others directly: by providing tangible goods (mechanism design) and by providing information (information design). This work investigates information design problems for a group of RL agents. The main challenges are two-fold. One is the information provided will immediately affect the transition of the agent trajectories, which introduces additional non-stationarity. The other is the information can be ignored, so the sender must provide information that the receiver is willing to respect. We formulate the Markov signaling game, and develop the notions of signaling gradient and the extended obedience constraints that address these challenges. Our algorithm is efficient on various mixed-motive tasks and provides further insights into computational economics. Our code is publicly available at https://github.com/YueLin301/InformationDesignMARL.'}",https://openreview.net{'value': '/pdf/73b7530f4c3e0005f0522d0f9fa81d6b958e67e6.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Ny3GcHLyzj,{'value': 'Efficient Policy Adaptation with Contrastive Prompt Ensemble for Embodied Agents'},Wonje Choi; Woo Kyung Kim; SeungHyun Kim; Honguk Woo,~Wonje_Choi2; ~Woo_Kyung_Kim1; ~SeungHyun_Kim4; ~Honguk_Woo1,"{'value': ['Prompt Learining', 'Domain Adaptation', 'Embodied AI']}","{'value': ""For embodied reinforcement learning (RL) agents interacting with the environment, it is desirable to have rapid policy adaptation to unseen visual observations, but achieving zero-shot adaptation capability is considered as a challenging problem in the RL context. To address the problem, we present a novel contrastive prompt ensemble (ConPE) framework which utilizes a pretrained vision-language model and a set of visual prompts, thus enables efficient policy learning and adaptation upon a wide range of environmental and physical changes encountered by embodied agents. Specifically, we devise a guided-attention-based ensemble approach with multiple visual prompts on the vision-language model to construct robust state representations. Each prompt is contrastively learned in terms of an individual domain factors that significantly affects the agent's egocentric perception and observation. For a given task, the attention-based ensemble and policy are jointly learned so that the resulting state representations not only generalize to various domains but are also optimized for learning the task. Through experiments, we show that ConPE outperforms other state-of-the-art algorithms for several embodied agent tasks including navigation in AI2THOR, manipulation in Metaworld, and autonomous driving in CARLA, while also improving the sample efficiency of policy learning and adaptation.""}",https://openreview.net{'value': '/pdf/2b304d9f4f08bdb5216c3656ac73dbae1ea1b755.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=NpyZkaEEun,{'value': 'Distributionally Robust Skeleton Learning of Discrete Bayesian Networks'},Yeshu Li; Brian D Ziebart,~Yeshu_Li1; ~Brian_D_Ziebart1,"{'value': ['structure learning', 'Bayesian network', 'robustness']}","{'value': 'We consider the problem of learning the exact skeleton of general discrete Bayesian networks from potentially corrupted data. Building on distributionally robust optimization and a regression approach, we propose to optimize the most adverse risk over a family of distributions within bounded Wasserstein distance or KL divergence to the empirical distribution. The worst-case risk accounts for the effect of outliers. The proposed approach applies for general categorical random variables without assuming faithfulness, an ordinal relationship or a specific form of conditional distribution. We present efficient algorithms and show the proposed methods are closely related to the standard regularized regression approach. Under mild assumptions, we derive non-asymptotic guarantees for successful structure learning with logarithmic sample complexities for bounded-degree graphs. Numerical study on synthetic and real datasets validates the effectiveness of our method.'}",https://openreview.net{'value': '/pdf/a66ed066a92066bc36addce0e8a4de0c6f3c4e78.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=NnXznLurw5,{'value': 'Human spatiotemporal pattern learning as probabilistic program synthesis'},Tracey Mills; Joshua B. Tenenbaum; Samuel J Cheyette,~Tracey_Mills1; ~Joshua_B._Tenenbaum1; ~Samuel_J_Cheyette1,{'value': ['pattern learning; probabilistic programs; program synthesis; gaussian process; human learning']},"{'value': 'People are adept at learning a wide variety of structured patterns from small amounts of data, presenting a conundrum from the standpoint of the bias-variance tradeoff: what kinds of representations and algorithms support the joint flexibility and data-paucity of human learning? One possibility is that people ""learn by programming"": inducing probabilistic models to fit observed data. Here, we experimentally test human learning in the domain of structured 2-dimensional patterns, using a task in which participants repeatedly predicted where a dot would move based on its previous trajectory. We evaluate human performance against standard parametric and non-parametric time-series models, as well as two Bayesian program synthesis models whose hypotheses vary in their degree of structure: a compositional Gaussian Process model and a structured ""Language of Thought"" (LoT) model. We find that signatures of human pattern learning are best explained by the LoT model, supporting the idea that the flexibility and data-efficiency of human structure learning can be understood as probabilistic inference over an expressive space of programs.'}",https://openreview.net{'value': '/pdf/ba983209ca62e876b8a7edc4500c6ae6dba0d086.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=NiQTy0NW1L,{'value': 'Lexinvariant Language Models'},Qian Huang; Eric Zelikman; Sarah Li Chen; Yuhuai Wu; Gregory Valiant; Percy Liang,~Qian_Huang2; ~Eric_Zelikman1; ~Sarah_Li_Chen1; ~Yuhuai_Wu1; ~Gregory_Valiant1; ~Percy_Liang1,"{'value': ['Large Language Model', 'in-context learning', 'pretraining']}","{'value': 'Token embeddings, a mapping from discrete lexical symbols to continuous vectors, are at the heart of any language model (LM). However, lexical symbol meanings can also be determined and even redefined by their structural role in a long context. In this paper, we ask: is it possible for a language model to be performant without \\emph{any} fixed token embeddings? Such a language model would have to rely entirely on the co-occurence and repetition of tokens in the context rather than the \\textit{a priori} identity of any token. To answer this, we study \\textit{lexinvariant}language models that are invariant to lexical symbols and therefore do not need fixed token embeddings in practice. First, we prove that we can construct a lexinvariant LM to converge to the true language model at a uniform rate that is polynomial in terms of the context length, with a constant factor that is sublinear in the vocabulary size. Second, to build a lexinvariant LM, we simply encode tokens using random Gaussian vectors, such that each token maps to the same representation within each sequence but different representations across sequences. Empirically, we demonstrate that it can indeed attain perplexity comparable to that of a standard language model, given a sufficiently long context. We further explore two properties of the lexinvariant language models: First, given text generated from a substitution cipher of English, it implicitly implements Bayesian in-context deciphering and infers the mapping to the underlying real tokens with high accuracy. Second, it has on average 4X better accuracy over synthetic in-context reasoning tasks. Finally, we discuss regularizing standard language models towards lexinvariance and potential practical applications.'}",https://openreview.net{'value': '/pdf/c20f23fbf078b6ada397580eeabf672e8c0eb624.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=NaYAsbv2jF,{'value': 'Geometric Neural Diffusion Processes'},Emile Mathieu; Vincent Dutordoir; Michael John Hutchinson; Valentin De Bortoli; Yee Whye Teh; Richard E Turner,~Emile_Mathieu1; ~Vincent_Dutordoir1; ~Michael_John_Hutchinson1; ~Valentin_De_Bortoli1; ~Yee_Whye_Teh2; ~Richard_E_Turner1,"{'value': ['diffusion model', 'functional space', 'stochastic process', 'time-series', 'neural processes', 'Gaussian processes', 'random fields', 'invariance', 'equivariance', 'symmetries', 'stationarity']}","{'value': 'Denoising diffusion models have proven to be a flexible and effective paradigm for generative modelling.\nTheir recent extension to infinite dimensional Euclidean spaces has allowed for the modelling of stochastic processes.\nHowever, many problems in the natural sciences incorporate symmetries and involve data living in non-Euclidean spaces.\nIn this work, we extend the framework of diffusion models to incorporate a series of geometric priors in infinite-dimension modelling.\nWe do so by a) constructing a noising process which admits, as limiting distribution, a geometric Gaussian process that transforms under the symmetry group of interest, and b) approximating the score with a neural network that is equivariant w.r.t. this group.\nWe show that with these conditions, the generative functional model admits the same symmetry.\nWe demonstrate scalability and capacity of the model, using a novel Langevin-based conditional sampler, to fit complex scalar and vector fields, with Euclidean and spherical codomain, on synthetic and real-world weather data.'}",https://openreview.net{'value': '/pdf/a10af1f179bcce4ea0920152eb3e8b750b821e0b.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=NIrTSCiIZ7,{'value': 'Boundary Guided Learning-Free Semantic Control with Diffusion Models'},Ye Zhu; Yu Wu; Zhiwei Deng; Olga Russakovsky; Yan Yan,~Ye_Zhu3; ~Yu_Wu3; ~Zhiwei_Deng3; ~Olga_Russakovsky1; ~Yan_Yan6,"{'value': ['Diffusion probabilistic models', 'learning-free applications', 'high-dimensional semantic boundary', 'markov mixing']}","{'value': 'Applying pre-trained generative denoising diffusion models (DDMs) for downstream tasks such as image semantic editing usually requires either fine-tuning DDMs or learning auxiliary editing networks in the existing literature. In this work, we present our BoundaryDiffusion method for efficient, effective and light-weight semantic control with frozen pre-trained DDMs, without learning any extra networks. As one of the first learning-free diffusion editing works, we start by seeking a more comprehensive understanding of the intermediate high-dimensional latent spaces by theoretically and empirically analyzing their probabilistic and geometric behaviors in the Markov chain. We then propose to further explore the critical step in the denoising trajectory that characterizes the convergence of a pre-trained DDM and introduce an automatic search method. Last but not least, in contrast to the conventional understanding that DDMs have relatively poor semantic behaviors (in generic latent spaces), we prove that the critical latent space we found already forms semantic subspace boundaries at the generic level in unconditional DDMs, which allows us to do controllable manipulation by guiding the denoising trajectory towards the targeted boundary via a single-step operation. We conduct extensive experiments on multiple DPMs architectures (DDPM, iDDPM) and datasets (CelebA, CelebA-HQ, LSUN-church, LSUN-bedroom, AFHQ-dog) with different resolutions (64, 256), achieving superior or state-of-the-art performance in various task scenarios (image semantic editing, text-based editing, unconditional semantic control) to demonstrate the effectiveness.'}",https://openreview.net{'value': '/pdf/77449eacfd8bc6a501e475e91abb9f7490b99337.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=NEawU0TgKG,{'value': 'Frequency Domain-Based Dataset Distillation'},DongHyeok Shin; Seungjae Shin; Il-chul Moon,~DongHyeok_Shin1; ~Seungjae_Shin1; ~Il-chul_Moon1,"{'value': ['Dataset distillation', 'Frequency domain', 'Dataset condensation']}","{'value': 'This paper presents FreD, a novel parameterization method for dataset distillation, which utilizes the frequency domain to distill a small-sized synthetic dataset from a large-sized original dataset. Unlike conventional approaches that focus on the spatial domain, FreD employs frequency-based transforms to optimize the frequency representations of each data instance. By leveraging the concentration of spatial domain information on specific frequency components, FreD intelligently selects a subset of frequency dimensions for optimization, leading to a significant reduction in the required budget for synthesizing an instance. Through the selection of frequency dimensions based on the explained variance, FreD demonstrates both theoretical and empirical evidence of its ability to operate efficiently within a limited budget, while better preserving the information of the original dataset compared to conventional parameterization methods. Furthermore, Based on the orthogonal compatibility of FreD with existing methods, we confirm that FreD consistently improves the performances of existing distillation methods over the evaluation scenarios with different benchmark datasets. We release the code at https://github.com/sdh0818/FreD.'}",https://openreview.net{'value': '/pdf/fceed185d44ed8701103a140fd2ce0efdc655823.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Murj6wcjRw,{'value': 'An Efficient Dataset Condensation Plugin and Its Application to Continual Learning'},Enneng Yang; Li Shen; Zhenyi Wang; Tongliang Liu; Guibing Guo,~Enneng_Yang1; ~Li_Shen1; ~Zhenyi_Wang1; ~Tongliang_Liu1; ~Guibing_Guo1,"{'value': ['Data Condensation', 'Continual Learning', 'Few-shot Learning']}","{'value': ""Dataset condensation (DC) distills a large real-world dataset into a small synthetic dataset, with the goal of training a network from scratch on the latter that performs similarly to the former. State-of-the-art (SOTA) DC methods have achieved satisfactory results through techniques such as accuracy, gradient, training trajectory, or distribution matching. However, these works all perform matching in the high-dimension pixel spaces, ignoring that natural images are usually locally connected and have lower intrinsic dimensions, resulting in low condensation efficiency.  In this work, we propose a simple-yet-efficient dataset condensation plugin that matches the raw and synthetic datasets in a low-dimensional manifold. Specifically, our plugin condenses raw images into two low-rank matrices instead of parameterized image matrices. Our plugin can be easily incorporated into existing DC methods, thereby containing richer raw dataset information at limited storage costs to improve the downstream applications' performance.  We verify on multiple public datasets that when the proposed plugin is combined with SOTA DC methods, the performance of the network trained on synthetic data is significantly improved compared to traditional DC methods. Moreover, when applying the DC methods as a plugin to continual learning tasks, we observed that our approach effectively mitigates catastrophic forgetting of old tasks under limited memory buffer constraints and avoids the problem of raw data privacy leakage.""}",https://openreview.net{'value': '/pdf/6bc6f76fcba339ebf661e41593d6a1cfdeb40895.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=MIYBTjCVjR,{'value': 'Sequential Preference Ranking for Efficient Reinforcement Learning from Human Feedback'},Minyoung Hwang; Gunmin Lee; Hogun Kee; Chan Woo Kim; Kyungjae Lee; Songhwai Oh,~Minyoung_Hwang1; ~Gunmin_Lee1; ~Hogun_Kee1; ~Chan_Woo_Kim2; ~Kyungjae_Lee1; ~Songhwai_Oh1,{'value': ['Reinforcement Learning; Reinforcement Learning from Human Feedback; Preference-based Reinforcement Learning; Human-Robot Interaction']},"{'value': 'Reinforcement learning from human feedback (RLHF) alleviates the problem of designing a task-specific reward function in reinforcement learning by learning it from human preference. However, existing RLHF models are considered inefficient as they produce only a single preference data from each human feedback. To tackle this problem, we propose a novel RLHF framework called SeqRank, that uses sequential preference ranking to enhance the feedback efficiency. Our method samples trajectories in a sequential manner by iteratively selecting a defender from the set of previously chosen trajectories $\\mathcal{K}$ and a challenger from the set of unchosen trajectories $\\mathcal{U}\\setminus\\mathcal{K}$, where $\\mathcal{U}$ is the replay buffer. We propose two trajectory comparison methods with different defender sampling strategies: (1) sequential pairwise comparison that selects the most recent trajectory and (2) root pairwise comparison that selects the most preferred trajectory from $\\mathcal{K}$. We construct a data structure and rank trajectories by preference to augment additional queries. The proposed method results in at least 39.2% higher average feedback efficiency than the baseline and also achieves a balance between feedback efficiency and data dependency. We examine the convergence of the empirical risk and the generalization bound of the reward model with Rademacher complexity. While both trajectory comparison methods outperform conventional pairwise comparison, root pairwise comparison improves the average reward in locomotion tasks and the average success rate in manipulation tasks by 29.0% and 25.0%, respectively. The source code and the videos are provided in the supplementary material.'}",https://openreview.net{'value': '/pdf/03fd7bb2cab83230de26f0813f2dfa2c166e0863.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=MCj7DLkYqS,{'value': 'Adversarial Attacks on Online Learning to Rank with Click Feedback'},Jinhang Zuo; Zhiyao Zhang; Zhiyong Wang; Shuai Li; Mohammad Hajiesmaili; Adam Wierman,~Jinhang_Zuo1; ~Zhiyao_Zhang2; ~Zhiyong_Wang9; ~Shuai_Li3; ~Mohammad_Hajiesmaili1; ~Adam_Wierman1,"{'value': ['online learning to rank', 'adversarial attack', 'click model']}","{'value': 'Online learning to rank (OLTR) is a sequential decision-making problem where a learning agent selects an ordered list of items and receives feedback through user clicks. Although potential attacks against OLTR algorithms may cause serious losses in real-world applications, there is limited knowledge about adversarial attacks on OLTR. This paper studies attack strategies against multiple variants of OLTR. Our first result provides an attack strategy against the UCB algorithm on classical stochastic bandits with binary feedback, which solves the key issues caused by bounded and discrete feedback that previous works cannot handle. Building on this result, we design attack algorithms against UCB-based OLTR algorithms in position-based and cascade models. Finally, we propose a general attack strategy against any algorithm under the general click model. Each attack algorithm manipulates the learning agent into choosing the target attack item $T-o(T)$ times, incurring a cumulative cost of $o(T)$. Experiments on synthetic and real data further validate the effectiveness of our proposed attack algorithms.'}",https://openreview.net{'value': '/pdf/46fdd276940aa4bca17302cf76a72ed2242ce546.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=MCVfX7HgPO,{'value': 'Testing the General Deductive Reasoning Capacity of Large Language Models Using OOD Examples'},Abulhair Saparov; Richard Yuanzhe Pang; Vishakh Padmakumar; Nitish Joshi; Mehran Kazemi; Najoung Kim; He He,~Abulhair_Saparov1; ~Richard_Yuanzhe_Pang1; ~Vishakh_Padmakumar1; ~Nitish_Joshi1; ~Mehran_Kazemi1; najoung@bu.edu; ~He_He2,"{'value': ['large language models', 'reasoning', 'out-of-distribution generalization', 'chain-of-thought', 'in-context learning']}","{'value': 'Given the intractably large size of the space of proofs, any model that is capable of general deductive reasoning must generalize to proofs of greater complexity. Recent studies have shown that large language models (LLMs) possess some abstract deductive reasoning ability given chain-of-thought prompts. However, they have primarily been tested on proofs using modus ponens or of a specific size, and from the same distribution as the in-context examples. To measure the general deductive reasoning ability of LLMs, we test on a broad set of deduction rules and measure their ability to generalize to more complex proofs from simpler demonstrations from multiple angles: depth-, width-, and compositional generalization. To facilitate systematic exploration, we construct a new synthetic and programmable reasoning dataset that enables control over deduction rules and proof complexity. Our experiments on four LLMs of various sizes and training objectives show that they are able to generalize to compositional proofs. However, they have difficulty generalizing to longer proofs, and they require explicit demonstrations to produce hypothetical subproofs, specifically in proof by cases and proof by contradiction.'}",https://openreview.net{'value': '/pdf/31cb2384469a09172b705930c450e993a434a508.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=M7FQpIdo0X,{'value': 'Enhancing Minority Classes by Mixing: An Adaptative Optimal Transport Approach for Long-tailed Classification'},Jintong Gao; He Zhao; Zhuo Li; Dan dan Guo,~Jintong_Gao2; ~He_Zhao1; ~Zhuo_Li5; ~Dan_dan_Guo1,"{'value': ['Long-tailed Classification', 'Optimal Transport', 'Image-mixing', 'Semantic Similarity']}","{'value': 'Real-world data usually confronts severe class-imbalance problems, where several majority classes have a significantly larger presence in the training set than minority classes. One effective solution is using mixup-based methods to generate synthetic samples to enhance the presence of minority classes. Previous approaches mix the background images from the majority classes and foreground images from the\nminority classes in a random manner, which ignores the sample-level semantic similarity, possibly resulting in less reasonable or less useful images. In this work, we propose an adaptive image-mixing method based on optimal transport (OT) to incorporate both class-level and sample-level information, which is able to generate semantically reasonable and meaningful mixed images for minority classes. Due to\nits flexibility, our method can be combined with existing long-tailed classification methods to enhance their performance and it can also serve as a general data augmentation method for balanced datasets. Extensive experiments indicate that our method achieves effective performance for long-tailed classification tasks. The code is available at https://github.com/JintongGao/Enhancing-Minority-Classes-by-Mixing.'}",https://openreview.net{'value': '/pdf/fe709720dd11f9e93189c539dd92b123345cbef7.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=M6OmjAZ4CX,{'value': 'Language Models can Solve Computer Tasks'},Geunwoo Kim; Pierre Baldi; Stephen Marcus McAleer,~Geunwoo_Kim1; ~Pierre_Baldi1; ~Stephen_Marcus_McAleer1,"{'value': ['Large Language models', 'Web Navigation', 'Foundation Models', 'Decision Making']}","{'value': ""Agents capable of carrying out general tasks on a computer can improve efficiency and productivity by automating repetitive tasks and assisting in complex problem-solving. Ideally, such agents should be able to solve new computer tasks presented to them through natural language commands. However, previous approaches to this problem require large amounts of expert demonstrations and task-specific reward functions, both of which are impractical for new tasks. In this work, we show that a pre-trained large language model (LLM) agent can execute computer tasks guided by natural language using a simple prompting scheme where the agent \\textbf{R}ecursively \\textbf{C}riticizes and \\textbf{I}mproves its output (RCI). The RCI approach significantly outperforms existing LLM methods for automating computer tasks and surpasses supervised learning (SL) and reinforcement learning (RL) approaches on the MiniWoB++ benchmark. \nWe compare multiple LLMs and find that RCI with the InstructGPT-3+RLHF LLM is state-of-the-art on MiniWoB++, using only a handful of demonstrations per task rather than tens of thousands, and without a task-specific reward function. Furthermore, we demonstrate RCI prompting's effectiveness in enhancing LLMs' reasoning abilities on a suite of natural language reasoning tasks, outperforming chain of thought (CoT) prompting with external feedback. We find that RCI combined with CoT performs better than either separately. Our code can be found here: https://github.com/posgnu/rci-agent.""}",https://openreview.net{'value': '/pdf/fa18eaea2d58fadf4b1c3fec15f6fb8563d78702.pdf'},{'abstract_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Lmxo0RVNx2,{'value': 'Individualized Dosing Dynamics via Neural Eigen Decomposition'},Stav Belogolovsky; Ido Greenberg; Danny Eytan; Shie Mannor,~Stav_Belogolovsky1; ~Ido_Greenberg1; ~Danny_Eytan1; ~Shie_Mannor2,"{'value': ['personalized medicine', 'dosing dynamics', 'sequential prediction', 'stochastic differential equations', 'Kalman filter', 'recurrent neural networks', 'medical drug control']}","{'value': 'Dosing models often use differential equations to model biological dynamics. Neural differential equations in particular can learn to predict the derivative of a process, which permits predictions at irregular points of time. However, this temporal flexibility often comes with a high sensitivity to noise, whereas medical problems often present high noise and limited data. Moreover, medical dosing models must generalize reliably over individual patients and changing treatment policies. To address these challenges, we introduce the Neural Eigen Stochastic Differential Equation algorithm (NESDE). NESDE provides individualized modeling (using a hypernetwork over patient-level parameters); generalization to new treatment policies (using decoupled control); tunable expressiveness according to the noise level (using piecewise linearity); and fast, continuous, closed-form prediction (using spectral representation). We demonstrate the robustness of NESDE in both synthetic and real medical problems, and use the learned dynamics to publish simulated medical gym environments.'}",https://openreview.net{'value': '/pdf/3199d0797871babeb8a27308122d48e5950a2aff.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=LmmjiTwYm0,{'value': 'What functions can Graph Neural Networks compute on random graphs? The role of Positional Encoding'},Nicolas Keriven; Samuel Vaiter,~Nicolas_Keriven1; ~Samuel_Vaiter1,{'value': ['graph neural network; random graph; positional encoding']},"{'value': 'We aim to deepen the theoretical understanding of Graph Neural Networks (GNNs) on large graphs, with a focus on their expressive power.\nExisting analyses relate this notion to the graph isomorphism problem, which is mostly relevant for graphs of small sizes, or studied graph classification or regression tasks, while prediction tasks on \\emph{nodes} are far more relevant on large graphs. Recently, several works showed that, on very general random graphs models, GNNs converge to certains functions as the number of nodes grows.\nIn this paper, we provide a more complete and intuitive description of the function space generated by equivariant GNNs for node-tasks, through general notions of convergence that encompass several previous examples. We emphasize the role of input node features, and study the impact of \\emph{node Positional Encodings} (PEs), a recent line of work that has been shown to yield state-of-the-art results in practice. Through the study of several examples of PEs on large random graphs, we extend previously known universality results to significantly more general models. Our theoretical results hint at some normalization tricks, which is shown numerically to have a positive impact on GNN generalization on synthetic and real data. Our proofs contain new concentration inequalities of independent interest.'}",https://openreview.net{'value': '/pdf/2e8c80734f616d3b6ed9beec684f939285fc36e8.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=LhVJdq4cZm,{'value': 'AlberDICE: Addressing Out-Of-Distribution Joint Actions in Offline Multi-Agent RL via Alternating Stationary Distribution Correction Estimation'},Daiki E. Matsunaga; Jongmin Lee; Jaeseok Yoon; Stefanos Leonardos; Pieter Abbeel; Kee-Eung Kim,~Daiki_E._Matsunaga1; ~Jongmin_Lee1; ~Jaeseok_Yoon1; ~Stefanos_Leonardos1; ~Pieter_Abbeel2; ~Kee-Eung_Kim2,"{'value': ['Offline Reinforcement Learning', 'Multi-Agent Reinforcement Learning']}","{'value': 'One of the main challenges in offline Reinforcement Learning (RL) is the distribution shift that arises from the learned policy deviating from the data collection policy. This is often addressed by avoiding out-of-distribution (OOD) actions during policy improvement as their presence can lead to substantial performance degradation. This challenge is amplified in the offline Multi-Agent RL (MARL) setting since the joint action space grows exponentially with the number of agents.\nTo avoid this curse of dimensionality, existing MARL methods adopt either value decomposition methods or fully decentralized training of individual agents. However, even when combined with standard conservatism principles, these methods can still result in the selection of OOD joint actions in offline MARL. To this end, we introduce AlberDICE,\nan offline MARL algorithm that alternatively performs centralized training of individual agents based on stationary distribution optimization. AlberDICE circumvents the exponential complexity of MARL by computing the best response of one agent at a time while effectively avoiding OOD joint action selection. Theoretically, we show that the alternating optimization procedure converges to Nash policies. In the experiments, we demonstrate that AlberDICE significantly outperforms baseline algorithms on a standard suite of MARL benchmarks.'}",https://openreview.net{'value': '/pdf/a100c783b619bf7ba15f6986a9a946c3d96d2616.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=LUT4b9gOtS,{'value': 'Learning Visual Prior via Generative Pre-Training'},Jinheng Xie; Kai Ye; Yudong Li; Yuexiang Li; Kevin Qinghong Lin; Yefeng Zheng; Linlin Shen; Mike Zheng Shou,~Jinheng_Xie1; ~Kai_Ye3; ~Yudong_Li1; ~Yuexiang_Li1; ~Kevin_Qinghong_Lin1; ~Yefeng_Zheng2; ~Linlin_Shen1; ~Mike_Zheng_Shou1,"{'value': ['Visual Prior', 'Generative Pre-Training', 'Conditional Image Synthesis']}","{'value': 'Various stuff and things in visual data possess specific traits, which can be learned by deep neural networks and are implicitly represented as the visual prior, e.g., object location and shape, in the model. Such prior potentially impacts many vision tasks. For example, in conditional image synthesis, spatial conditions failing to adhere to the prior can result in visually inaccurate synthetic results. This work aims to explicitly learn the visual prior and enable the customization of sampling. Inspired by advances in language modeling, we propose to learn Visual prior via Generative Pre-Training, dubbed VisorGPT. By discretizing visual locations, e.g., bounding boxes, human pose, and instance masks, into sequences, VisorGPT can model visual prior through likelihood maximization. Besides, prompt engineering is investigated to unify various visual locations and enable customized sampling of sequential outputs from the learned prior. Experimental results demonstrate the effectiveness of VisorGPT in modeling visual prior and extrapolating to novel scenes, potentially motivating that discrete visual locations can be integrated into the learning paradigm of current language models to further perceive visual world. Code is available at https://sierkinhane.github.io/visor-gpt.'}",https://openreview.net{'value': '/pdf/567db1e086fff38a5704077ebadb65d5c57bea8d.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=KtvPdGb31Z,"{'value': 'Describe, Explain, Plan and Select: Interactive Planning with LLMs Enables Open-World Multi-Task Agents'}",Zihao Wang; Shaofei Cai; Guanzhou Chen; Anji Liu; Xiaojian Ma; Yitao Liang,~Zihao_Wang23; ~Shaofei_Cai2; ~Guanzhou_Chen1; ~Anji_Liu1; ~Xiaojian_Ma1; ~Yitao_Liang1,"{'value': ['open-ended learning', 'multi task', 'large language models', 'zero-shot planning']}","{'value': ""In this paper, we study the problem of planning in Minecraft, a popular, democratized yet challenging open-ended environment for developing multi-task embodied agents. We've found two primary challenges of empowering such agents with planning: 1) planning in an open-ended world like Minecraft requires precise and multi-step reasoning due to the long-term nature of the tasks, and 2) as vanilla planners do not consider the achievability of the current agent when ordering parallel sub-goals within a complicated plan, the resulting plan could be inefficient. To this end, we propose ``$\\underline{D}$escribe, $\\underline{E}$xplain, $\\underline{P}$lan and $\\underline{S}$elect'' ($\\textbf{DEPS}$), an interactive planning approach based on Large Language Models (LLMs). Our approach helps with better error correction from the feedback during the long-haul planning, while also bringing the sense of proximity via goal $\\textbf{Selector}$, a learnable module that ranks parallel sub-goals based on the estimated steps of completion and improves the original plan accordingly. Our experiments mark the milestone of the first zero-shot multi-task agent that can robustly accomplish 70+ Minecraft tasks and nearly double the overall performances. Further testing reveals our method's general effectiveness in popularly adopted non-open-ended domains as well (i.e., ALFWorld and tabletop manipulation). The ablation and exploratory studies detail how our design beats the counterparts and provide a promising update on the $\\texttt{ObtainDiamond}$ grand challenge with our approach.""}",https://openreview.net{'value': '/pdf/55b58f4d498cc7605484fc24b7dbee97f5e0a58f.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=KTfAtro6vP,{'value': 'Reinforcement Learning with Fast and Forgetful Memory'},Steven Morad; Ryan Kortvelesy; Stephan Liwicki; Amanda Prorok,~Steven_Morad1; ~Ryan_Kortvelesy1; ~Stephan_Liwicki3; ~Amanda_Prorok1,"{'value': ['reinforcement learning', 'partially observable', 'POMDP', 'memory', 'rnn', 'transformer']}","{'value': 'Nearly all real world tasks are inherently partially observable, necessitating the use of memory in Reinforcement Learning (RL). Most model-free approaches summarize the trajectory into a latent Markov state using memory models borrowed from Supervised Learning (SL), even though RL tends to exhibit different training and efficiency characteristics. Addressing this discrepancy, we introduce Fast and Forgetful Memory, an algorithm-agnostic memory model designed specifically for RL. Our approach constrains the model search space via strong structural priors inspired by computational psychology. It is a drop-in replacement for recurrent neural networks (RNNs) in recurrent RL algorithms, achieving greater reward than RNNs across various recurrent benchmarks and algorithms _without changing any hyperparameters_. Moreover, Fast and Forgetful Memory exhibits training speeds two orders of magnitude faster than RNNs, attributed to its logarithmic time and linear space complexity. Our implementation is available at https://github.com/proroklab/ffm.'}",https://openreview.net{'value': '/pdf/b4ba3d223fabc3191888a9df7104df8099cb22dc.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=KTZttLZekH,{'value': 'On the Constrained Time-Series Generation Problem'},Andrea Coletta; Sriram Gopalakrishnan; Daniel Borrajo; Svitlana Vyetrenko,~Andrea_Coletta1; ~Sriram_Gopalakrishnan1; ~Daniel_Borrajo1; ~Svitlana_Vyetrenko1,"{'value': ['time-series', 'generative models', 'constrained optimization', 'machine learning']}","{'value': ""Synthetic time series are often used in practical applications to augment the historical time series dataset, \namplify the occurrence of rare events and also create counterfactual scenarios.\nDistributional-similarity (which we refer to as realism) as well as the satisfaction of certain numerical constraints are common requirements for counterfactual time series generation. For instance, the US Federal Reserve publishes synthetic market stress scenarios given by the constrained time series for financial institutions to assess their performance in hypothetical recessions.\nExisting approaches for generating constrained time series usually penalize training loss to enforce constraints, and reject non-conforming samples. However, these approaches would require re-training if we change constraints, and rejection sampling can be computationally expensive, or impractical for complex constraints.\nIn this paper, we propose a novel set of methods to tackle the constrained time series generation problem and provide efficient sampling while ensuring the realism of generated time series.  \nIn particular, we frame the problem using a constrained optimization framework and then we propose a set of generative methods including 'GuidedDiffTime', a guided diffusion model. \nWe empirically evaluate our work on several datasets for financial and energy data, where incorporating constraints is critical. We show that our approaches outperform existing work both qualitatively and quantitatively, and that 'GuidedDiffTime' does not require re-training for new constraints, resulting in a significant carbon footprint reduction, up to 92% w.r.t. existing deep learning methods.""}",https://openreview.net{'value': '/pdf/8d5105360fabdbdff072c74c51b428e309a0a91e.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=KTR33hMnMX,{'value': 'Aligning Optimization Trajectories with Diffusion Models for Constrained Design Generation'},Giorgio Giannone; Akash Srivastava; Ole Winther; Faez Ahmed,~Giorgio_Giannone1; ~Akash_Srivastava1; ~Ole_Winther1; ~Faez_Ahmed1,"{'value': ['diffusion models', 'engineering design', 'generative optimization', 'trajectory matching']}","{'value': ""Generative models have significantly influenced both vision and language domains, ushering in innovative multimodal applications. Although these achievements have motivated exploration in scientific and engineering fields, challenges emerge, particularly in constrained settings with limited data where precision is crucial. Traditional engineering optimization methods rooted in physics often surpass generative models in these contexts. To address these challenges, we introduce Diffusion Optimization Models (DOM) and Trajectory Alignment (TA), a learning framework that demonstrates the efficacy of aligning the sampling trajectory of diffusion models with the trajectory derived from physics-based iterative optimization methods. This alignment ensures that the sampling process remains grounded in the underlying physical principles. This alignment eliminates the need for costly preprocessing, external surrogate models, or extra labeled data, generating feasible and high-performance designs efficiently. We apply our framework to structural topology optimization, a fundamental problem in mechanical design, evaluating its performance on in- and out-of-distribution configurations. Our results demonstrate that TA outperforms state-of-the-art deep generative models on in-distribution configurations and halves the inference computational cost. When coupled with a few steps of optimization, it also improves manufacturability for out-of-distribution conditions. \nDOM's efficiency and performance improvements significantly expedite design processes and steer them toward optimal and manufacturable outcomes, highlighting the potential of generative models in data-driven design.""}",https://openreview.net{'value': '/pdf/a54dc119d2de91d451a4a19009140292834c723c.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=K5e5tFZuur,{'value': 'Invariant Learning via Probability of Sufficient and Necessary Causes'},Mengyue Yang; Zhen Fang; Yonggang Zhang; Yali Du; Furui Liu; Jean-Francois Ton; Jianhong Wang; Jun Wang,~Mengyue_Yang1; ~Zhen_Fang2; ~Yonggang_Zhang1; ~Yali_Du1; ~Furui_Liu1; ~Jean-Francois_Ton2; ~Jianhong_Wang1; ~Jun_Wang2,"{'value': ['OOD Generalization', 'Invariant Representation Learning']}","{'value': 'Out-of-distribution (OOD) generalization is indispensable for learning models in the wild, where testing distribution typically unknown and different from the training. Recent methods derived from causality have shown great potential in achieving OOD generalization. \nHowever, existing methods mainly focus on the invariance property of causes, while largely overlooking the property of sufficiency and necessity conditions. Namely, a necessary but insufficient cause (feature) is invariant to distribution shift, yet it may not have required accuracy. By contrast, a sufficient yet unnecessary cause (feature) tends to fit specific data well but may have a risk of adapting to a new domain. \nTo capture the information of sufficient and necessary causes, we employ a classical concept, the probability of sufficiency and necessary causes (PNS), which indicates the probability of whether one is the necessary and sufficient cause. \nTo associate PNS with OOD generalization, we propose PNS risk and formulate an algorithm to learn representation with a high PNS value. We theoretically analyze and prove the generalizability of the PNS risk. Experiments on both synthetic and real-world benchmarks demonstrate the effectiveness of the proposed method. The detailed implementation can be found at the GitHub repository: https://github.com/ymy4323460/CaSN.'}",https://openreview.net{'value': '/pdf/7b37eabb1ed3dbacbb4c010036d85617e63da6e9.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=JpU5YmMKx7,{'value': 'Attentive Transfer Entropy to Exploit Transient Emergence of Coupling Effect'},Xiaolei Ru; Xin-Ya Zhang; Zijia Liu; Jack Murdoch Moore; Gang Yan,~Xiaolei_Ru1; ~Xin-Ya_Zhang1; ~Zijia_Liu1; ~Jack_Murdoch_Moore1; ~Gang_Yan2,{'value': ['Directed coupled network reconstruction; Neuronal dynamics; Mutual information estimator; Attention mechanism; Transfer entropy.']},"{'value': 'We consider the problem of reconstructing coupled networks (e.g., biological neural networks) connecting large numbers of variables (e.g.,nerve cells), of which state evolution is governed by dissipative dynamics consisting of strong self-drive (dominants the evolution) and weak coupling-drive. The core difficulty is sparseness of coupling effect that emerges (the coupling force is significant) only momentarily and otherwise remains quiescent in time series (e.g., neuronal activity sequence). Here we learn the idea from attention mechanism to guide the classifier to make inference focusing on the critical regions of time series data where coupling effect may manifest. Specifically, attention coefficients are assigned autonomously by artificial neural networks trained to maximise the Attentive Transfer Entropy (ATEn), which is a novel generalization of the iconic transfer entropy metric. Our results show that, without any prior knowledge of dynamics, ATEn explicitly identifies areas where the strength of coupling-drive is distinctly greater than zero. This innovation substantially improves reconstruction performance for both synthetic and real directed coupling networks using data generated by neuronal models widely used in neuroscience.'}",https://openreview.net{'value': '/pdf/e71a0062ef878900c16783f69d0e8a4755d0b065.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=JOkgEY9os2,{'value': 'MMD-Fuse: Learning and Combining Kernels for Two-Sample Testing Without Data Splitting'},Felix Biggs; Antonin Schrab; Arthur Gretton,~Felix_Biggs1; ~Antonin_Schrab1; ~Arthur_Gretton1,"{'value': ['Testing', 'MMD', 'Kernel Methods', 'Two-sample testing']}","{'value': 'We propose novel statistics which maximise the power  of a two-sample test based on the Maximum Mean Discrepancy (MMD), by\nadapting over the set of kernels used in defining it.\nFor finite sets, this reduces to combining (normalised) MMD values under each of these kernels via a weighted soft maximum.\nExponential concentration bounds are proved for our proposed statistics under the null and alternative.\nWe further show how these kernels can be chosen in a data-dependent but permutation-independent way, in a well-calibrated test, avoiding data splitting.\nThis technique applies more broadly to general permutation-based MMD testing, and includes the use of deep kernels with features learnt using unsupervised models such as auto-encoders.\nWe highlight the applicability of our MMD-Fuse tests on both synthetic low-dimensional and real-world high-dimensional data, and compare its performance in terms of power against current state-of-the-art kernel tests.'}",https://openreview.net{'value': '/pdf/bae8c384e04844e2c6dcdbf7e92fed8b2628058e.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=JIKM2vS8XU,{'value': 'DatasetDM: Synthesizing Data with Perception Annotations Using Diffusion Models'},Weijia Wu; Yuzhong Zhao; Hao Chen; Yuchao Gu; Rui Zhao; Yefei He; Hong Zhou; Mike Zheng Shou; Chunhua Shen,~Weijia_Wu2; ~Yuzhong_Zhao1; ~Hao_Chen17; ~Yuchao_Gu1; ~Rui_Zhao12; ~Yefei_He1; ~Hong_Zhou3; ~Mike_Zheng_Shou1; ~Chunhua_Shen2,{'value': ['Diffusion Model; Text-guided dataset generation']},"{'value': 'Current deep networks are very data-hungry and benefit from training on large-scale datasets, which are often time-consuming to collect and annotate. By contrast, synthetic data can be generated infinitely using generative models such as DALL-E and diffusion models, with minimal effort and cost. In this paper, we present DatasetDM, a generic dataset generation model that can produce diverse synthetic\nimages and the corresponding high-quality perception annotations (e.g., segmentation masks, and depth). Our method builds upon the pre-trained diffusion model and extends text-guided image synthesis to perception data generation. We show that the rich latent code of the diffusion model can be effectively decoded as accurate perception annotations using a decoder module. Training the decoder only needs less than 1% (around 100 images) of manually labeled images, enabling the generation of an infinitely large annotated dataset. Then these synthetic data can be used for training various perception models on downstream tasks. To showcase the power of the proposed approach, we generate datasets with rich dense pixel-wise labels for a wide range of downstream tasks, including semantic15\nsegmentation, instance segmentation, and depth estimation. Notably, it achieves 1) state-of-the-art results on semantic segmentation and instance segmentation; 2) significantly more efficient and robust in domain generalization than the real data; 3) state-of-the-art results in zero-shot segmentation setting; and 4) flexibility for efficient application and novel task composition (e.g., image editing)'}",https://openreview.net{'value': '/pdf/6fdc2c2bc7e310efef7751115ab7eda60d662769.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=JDw50IX4TY,{'value': 'Partial Multi-Label Learning with Probabilistic Graphical Disambiguation'},Jun-Yi Hang; Min-Ling Zhang,~Jun-Yi_Hang1; ~Min-Ling_Zhang2,"{'value': ['Machine learning', 'multi-label learning', 'partial multi-label learning', 'label disambiguation']}","{'value': 'In partial multi-label learning (PML), each training example is associated with a set of candidate labels, among which only some labels are valid. As a common strategy to tackle PML problem, disambiguation aims to recover the ground-truth labeling information from such inaccurate annotations. However, existing approaches mainly rely on heuristics or ad-hoc rules to disambiguate candidate labels, which may not be universal enough in complicated real-world scenarios. To provide a principled way for disambiguation, we make a first attempt to explore the probabilistic graphical model for PML problem, where a directed graph is tailored to infer latent ground-truth labeling information from the generative process of partial multi-label data. Under the framework of stochastic gradient variational Bayes, a unified variational lower bound is derived for this graphical model, which is further relaxed probabilistically so that the desired prediction model can be induced with simultaneously identified ground-truth labeling information. Comprehensive experiments on multiple synthetic and real-world data sets show that our approach outperforms the state-of-the-art counterparts.'}",https://openreview.net{'value': '/pdf/bf43e43bfb70cd65392b4bd1434310c02670f4e2.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=JCN9YsZiwB,{'value': 'Deep Non-line-of-sight Imaging from Under-scanning Measurements'},Yue Li; Yueyi Zhang; Juntian Ye; Feihu Xu; Zhiwei Xiong,~Yue_Li11; ~Yueyi_Zhang2; ~Juntian_Ye1; ~Feihu_Xu1; ~Zhiwei_Xiong1,"{'value': ['Non-line-of-sight imaging', 'Transient Recovery', 'Volume Reconstruction']}","{'value': 'Active confocal non-line-of-sight (NLOS) imaging has successfully enabled seeing around corners relying on high-quality transient measurements. However, acquiring spatial-dense transient measurement is time-consuming, raising the question of how to reconstruct satisfactory results from under-scanning measurements (USM). The existing solutions, involving the traditional algorithms, however, are hindered by unsatisfactory results or long computing times. To this end, we propose the first deep-learning-based approach to NLOS imaging from USM. Our proposed end-to-end network is composed of two main components: the transient recovery network (TRN) and the volume reconstruction network (VRN). Specifically, TRN takes the under-scanning measurements as input, utilizes a multiple kernel feature extraction module and a multiple feature fusion module, and outputs sufficient-scanning measurements at the high-spatial resolution. Afterwards, VRN incorporates the linear physics prior of the light-path transport model and reconstructs the hidden volume representation. Besides, we introduce regularized constraints that enhance the perception of more local details while suppressing smoothing effects. The proposed method achieves superior performance on both synthetic data and public real-world data, as demonstrated by extensive experimental results with different under-scanning grids. Moreover, the proposed method delivers impressive robustness at an extremely low scanning grid (i.e., 8$\\times$8) and offers high-speed inference (i.e., 50 times faster than the existing iterative solution).'}",https://openreview.net{'value': '/pdf/8ca21f507a11f8e3a82499ac31767e5f730c18e5.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=JCCi58IUsh,{'value': 'Grounded Decoding: Guiding Text Generation with Grounded Models for Embodied Agents'},Wenlong Huang; Fei Xia; Dhruv Shah; Danny Driess; Andy Zeng; Yao Lu; Pete Florence; Igor Mordatch; Sergey Levine; Karol Hausman; brian ichter,~Wenlong_Huang1; ~Fei_Xia1; ~Dhruv_Shah1; ~Danny_Driess1; ~Andy_Zeng3; ~Yao_Lu13; ~Pete_Florence1; ~Igor_Mordatch5; ~Sergey_Levine1; ~Karol_Hausman2; ~brian_ichter1,"{'value': ['robotics', 'language models', 'embodied agents']}","{'value': 'Recent progress in large language models (LLMs) has demonstrated the ability to learn and leverage Internet-scale knowledge through pre-training with autoregressive models. Unfortunately, applying such models to settings with embodied agents, such as robots, is challenging due to their lack of experience with the physical world, inability to parse non-language observations, and ignorance of rewards or safety constraints that robots may require. On the other hand, language-conditioned robotic policies that learn from interaction data can provide the necessary grounding that allows the agent to be correctly situated in the real world, but such policies are limited by the lack of high-level semantic understanding due to the limited breadth of the interaction data available for training them. Thus, if we want to make use of the semantic knowledge in a language model while still situating it in an embodied setting, we must construct an action sequence that is both likely according to the language model and also realizable according to grounded models of the environment. We frame this as a problem similar to probabilistic filtering: decode a sequence that both has high probability under the language model and high probability under a set of grounded model objectives. We demonstrate how such grounded models can be obtained across three simulation and real-world domains, and that the proposed decoding strategy is able to solve complex, long-horizon embodiment tasks in a robotic setting by leveraging the knowledge of both models.'}",https://openreview.net{'value': '/pdf/7dc83574bcaf3b1245b01026782fe6b45e8c3b23.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=J1gBijopla,{'value': 'Quantifying & Modeling Multimodal Interactions: An Information Decomposition Framework'},Paul Pu Liang; Yun Cheng; Xiang Fan; Chun Kai Ling; Suzanne Nie; Richard J. Chen; Zihao Deng; Nicholas Allen; Randy Auerbach; Faisal Mahmood; Ruslan Salakhutdinov; Louis-Philippe Morency,~Paul_Pu_Liang1; ~Yun_Cheng2; ~Xiang_Fan1; ~Chun_Kai_Ling2; ~Suzanne_Nie1; ~Richard_J._Chen1; ~Zihao_Deng2; ~Nicholas_Allen1; ~Randy_Auerbach1; ~Faisal_Mahmood1; ~Ruslan_Salakhutdinov1; ~Louis-Philippe_Morency1,"{'value': ['multimodal learning', 'feature interactions', 'partial information decomposition', 'information theory', 'quantification', 'model selection']}","{'value': 'The recent explosion of interest in multimodal applications has resulted in a wide selection of datasets and methods for representing and integrating information from different modalities. Despite these empirical advances, there remain fundamental research questions: How can we quantify the interactions that are necessary to solve a multimodal task? Subsequently, what are the most suitable multimodal models to capture these interactions? To answer these questions, we propose an information-theoretic approach to quantify the degree of redundancy, uniqueness, and synergy relating input modalities with an output task. We term these three measures as the PID statistics of a multimodal distribution (or PID for short), and introduce two new estimators for these PID statistics that scale to high-dimensional distributions. To validate PID estimation, we conduct extensive experiments on both synthetic datasets where the PID is known and on large-scale multimodal benchmarks where PID estimations are compared with human annotations. Finally, we demonstrate their usefulness in (1) quantifying interactions within multimodal datasets, (2) quantifying interactions captured by multimodal models, (3) principled approaches for model selection, and (4) three real-world case studies engaging with domain experts in pathology, mood prediction, and robotic perception where our framework helps to recommend strong multimodal models for each application.'}",https://openreview.net{'value': '/pdf/b13b51ca6ddc73b2e8a80fefc4d109e2e25f9933.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=IrEYkhuxup,{'value': 'Why Did This Model Forecast This Future? Information-Theoretic Saliency for Counterfactual Explanations of Probabilistic Regression Models'},Chirag Raman; Alec Nonnemaker; Amelia Villegas-Morcillo; Hayley Hung; Marco Loog,~Chirag_Raman2; ~Alec_Nonnemaker1; ~Amelia_Villegas-Morcillo1; ~Hayley_Hung2; ~Marco_Loog1,"{'value': ['Probabilistic Forecasting', 'Saliency', 'Explainability', 'XAI', 'Probabilistic Regression']}","{'value': ""We propose a post hoc saliency-based explanation framework for counterfactual reasoning in probabilistic multivariate time-series forecasting (regression) settings. Building upon Miller's framework of explanations derived from research in multiple social science disciplines, we establish a conceptual link between counterfactual reasoning and saliency-based explanation techniques. To address the lack of a principled notion of saliency, we leverage a unifying definition of information-theoretic saliency grounded in preattentive human visual cognition and extend it to forecasting settings. Specifically, we obtain a closed-form expression for commonly used density functions to identify which observed timesteps appear salient to an underlying model in making its probabilistic forecasts. We empirically validate our framework in a principled manner using synthetic data to establish ground-truth saliency that is unavailable for real-world data. Finally, using real-world data and forecasting models, we demonstrate how our framework can assist domain experts in forming new data-driven hypotheses about the causal relationships between features in the wild.""}",https://openreview.net{'value': '/pdf/3538b72ded7628ddb32e8ccced061f9e4dad003f.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=IoizwO1NLf,{'value': 'Skill-it! A data-driven skills framework for understanding and training language models'},Mayee F Chen; Nicholas Roberts; Kush Bhatia; Jue WANG; Ce Zhang; Frederic Sala; Christopher Re,~Mayee_F_Chen1; ~Nicholas_Roberts2; ~Kush_Bhatia3; ~Jue_WANG1; ~Ce_Zhang1; ~Frederic_Sala1; ~Christopher_Re1,"{'value': ['language models', 'data selection']}","{'value': 'The quality of training data impacts the performance of pre-trained large language models (LMs). Given a fixed budget of tokens, we study how to best select data that leads to good downstream model performance across tasks. We develop a new framework based on a simple hypothesis: just as humans acquire interdependent skills in a deliberate order, language models also follow a natural order when learning a set of skills from their training data. If such an order exists, it can be utilized for improved understanding of LMs and for data-efficient training. Using this intuition, our framework formalizes the notion of a skill and of an ordered set of skills in terms of the associated data. First, using both synthetic and real data, we demonstrate that these ordered skill sets exist, and that their existence enables more advanced skills to be learned with less data when we train on their prerequisite skills. Second, using our proposed framework, we introduce an online data sampling algorithm, Skill-It, over mixtures of skills for both continual pre-training and fine-tuning regimes, where the objective is to efficiently learn multiple skills in the former and an individual skill in the latter. On the LEGO synthetic in the continual pre-training setting, Skill-It obtains 37.5 points higher accuracy than random sampling. On the Natural Instructions dataset in the fine-tuning setting, Skill-It reduces the validation loss on the target skill by 13.6% versus training on data associated with the target skill itself. \nWe apply our skills framework on the RedPajama dataset to continually pre-train a 3B-parameter LM, achieving higher accuracy on the LM Evaluation Harness with 1B tokens than the baseline approach of sampling uniformly over data sources with 3B tokens.'}",https://openreview.net{'value': '/pdf/2747b41210c890e7d3d00094c8fe2cc353658f22.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=IdF7VT6eEs,{'value': 'Online Performative Gradient Descent for Learning Nash Equilibria in Decision-Dependent Games'},Zihan Zhu; Ethan X Fang; Zhuoran Yang,~Zihan_Zhu2; ~Ethan_X_Fang1; ~Zhuoran_Yang1,"{'value': ['Performative Prediction', 'Nash Equilibrium', 'Reproducing Kernel Hilbert Space', 'Online Learning', 'Stochastic Gradient Methods']}","{'value': 'We study the multi-agent game within the innovative framework of decision-dependent games, which establishes a feedback mechanism that population data reacts to agents’ actions and further characterizes the strategic interactions between agents. We focus on finding the Nash equilibrium of decision-dependent games in the bandit feedback setting. However, since agents are strategically coupled, traditional gradient-based methods are infeasible without the gradient oracle. To overcome this challenge, we model the strategic interactions by a general parametric model and propose a novel online algorithm, Online Performative Gradient Descent (OPGD), which leverages the ideas of online stochastic approximation and projected gradient descent to learn the Nash equilibrium in the context of function approximation for the unknown gradient. In particular, under mild assumptions on the function classes defined in the parametric model, we prove that OPGD can find the Nash equilibrium efficiently for strongly monotone decision-dependent games. Synthetic numerical experiments validate our theory.'}",https://openreview.net{'value': '/pdf/d2bee81432baefe074b0f842aff2433e4d62772a.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Ia4dmqst0Z,{'value': 'ResoNet: Noise-Trained Physics-Informed MRI Off-Resonance Correction'},Alfredo De Goyeneche; Shreya Ramachandran; Ke Wang; Ekin Karasan; Joseph Yitan Cheng; Stella X. Yu; Michael Lustig,~Alfredo_De_Goyeneche1; ~Shreya_Ramachandran1; ~Ke_Wang8; ~Ekin_Karasan1; ~Joseph_Yitan_Cheng1; ~Stella_X._Yu2; ~Michael_Lustig2,"{'value': ['Inverse problem', 'MRI', 'Medical Imaging', 'Computational Imaging', 'Deep Learning', 'Off-Resonance']}","{'value': 'Magnetic Resonance Imaging (MRI) is a powerful medical imaging modality that offers diagnostic information without harmful ionizing radiation. Unlike optical imaging, MRI sequentially samples the spatial Fourier domain (k-space) of the image. \nMeasurements are collected in multiple shots, or readouts, and in each shot, data along a smooth trajectory is sampled.\nConventional MRI data acquisition relies on sampling k-space row-by-row in short intervals, which is slow and inefficient. More efficient, non-Cartesian sampling trajectories (e.g., Spirals) use longer data readout intervals, but are more susceptible to magnetic field inhomogeneities, leading to off-resonance artifacts. Spiral trajectories cause off-resonance blurring in the image, and the mathematics of this blurring resembles that of optical blurring, where magnetic field variation corresponds to depth and readout duration to aperture size. Off-resonance blurring is a system issue with a physics-based, accurate forward model. We present a physics-informed deep learning framework for off-resonance correction in MRI, which is trained exclusively on synthetic, noise-like data with representative marginal statistics. Our approach allows for fat/water separation and is compatible with parallel imaging acceleration. Through end-to-end training using synthetic randomized data (i.e., noise-like images, coil sensitivities, field maps), we train the network to reverse off-resonance effects across diverse anatomies and contrasts without retraining. We demonstrate the effectiveness of our approach through results on phantom and in-vivo data. This work has the potential to facilitate the clinical adoption of non-Cartesian sampling trajectories, enabling efficient, rapid, and motion-robust MRI scans. Code is publicly available at: https://github.com/mikgroup/ResoNet.'}",https://openreview.net{'value': '/pdf/f827572ebe7ad355680c0e8109e7a7c96f9e4971.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=IQRc3FrYOG,{'value': 'Mutual-Information Regularized Multi-Agent Policy Iteration'},Jiangxing Wang; Deheng Ye; Zongqing Lu,~Jiangxing_Wang2; ~Deheng_Ye1; ~Zongqing_Lu2,{'value': ['Multi-Agent Reinforcement Learning']},"{'value': 'Despite the success of cooperative multi-agent reinforcement learning algorithms, most of them focus on a single team composition, which prevents them from being used in more realistic scenarios where dynamic team composition is possible. While some studies attempt to solve this problem via multi-task learning in a fixed set of team compositions, there is still a risk of overfitting to the training set, which may lead to catastrophic performance when facing dramatically varying team compositions during execution. To address this problem, we propose to use mutual information (MI) as an augmented reward to prevent individual policies from relying too much on team-related information and encourage agents to learn policies that are robust in different team compositions. Optimizing this MI-augmented objective in an off-policy manner can be intractable due to the existence of dynamic marginal distribution. To alleviate this problem, we first propose a multi-agent policy iteration algorithm with a fixed marginal distribution and prove its convergence and optimality. Then, we propose to employ the Blahut–Arimoto algorithm and an imaginary team composition distribution for optimization with approximate marginal distribution as the practical implementation. Empirically, our method demonstrates strong zero-shot generalization to dynamic team compositions in complex cooperative tasks.'}",https://openreview.net{'value': '/pdf/7b3b9cbba45a5608bea1b8e0f7e6b50c7a11f6e5.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=IMiGRqltQQ,{'value': '“Why Not Looking backward?” A Robust Two-Step Method to Automatically Terminate Bayesian Optimization'},Shuang Li; Ke Li; Wei Li,~Shuang_Li12; ~Ke_Li5; ~Wei_Li72,"{'value': ['Bayesian Optimization', 'Termination Criterion', 'Looking Backward']}","{'value': 'Bayesian Optimization (BO) is a powerful method for tackling expensive black-box optimization problems. As a sequential model-based optimization strategy, BO iteratively explores promising solutions until a predetermined budget, either iterations or time, is exhausted. The decision on when to terminate BO significantly influences both the quality of solutions and its computational efficiency. In this paper, we propose a simple, yet theoretically grounded, two-step method for automatically terminating BO. Our core concept is to proactively identify if the search is within a convex region by examining previously observed samples. BO is halted once the local regret within this convex region falls below a predetermined threshold. To enhance numerical stability, we propose an approximation method for calculating the termination indicator by solving a bilevel optimization problem. We conduct extensive empirical studies on diverse benchmark problems, including synthetic functions, reinforcement learning, and hyperparameter optimization. Experimental results demonstrate that our proposed method saves up to $\\approx 80\\%$ computational budget yet is with an order of magnitude smaller performance degradation, comparing against the other peer methods. In addition, our proposed termination method is robust in terms of the setting of its termination criterion.'}",https://openreview.net{'value': '/pdf/c40e4eb712eb2a8ff0a5f9b560f27b3162bfa2a2.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=IJblKO45YU,{'value': 'Goal-Conditioned Predictive Coding for Offline Reinforcement Learning'},Zilai Zeng; Ce Zhang; Shijie Wang; Chen Sun,~Zilai_Zeng1; ~Ce_Zhang7; ~Shijie_Wang2; ~Chen_Sun1,"{'value': ['reinforcement learning', 'offline RL', 'self-supervised learning']}","{'value': 'Recent work has demonstrated the effectiveness of formulating decision making as supervised learning on offline-collected trajectories. Powerful sequence models, such as GPT or BERT, are often employed to encode the trajectories. However, the benefits of performing sequence modeling on trajectory data remain unclear. In this work, we investigate whether sequence modeling has the ability to condense trajectories into useful representations that enhance policy learning. We adopt a two-stage framework that first leverages sequence models to encode trajectory-level representations, and then learns a goal-conditioned policy employing the encoded representations as its input. This formulation allows us to consider many existing supervised offline RL methods as specific instances of our framework. Within this framework, we introduce Goal-Conditioned Predictive Coding (GCPC), a sequence modeling objective that yields powerful trajectory representations and leads to performant policies. Through extensive empirical evaluations on AntMaze, FrankaKitchen and Locomotion environments, we observe that sequence modeling can have a significant impact on challenging decision making tasks. Furthermore, we demonstrate that GCPC learns a goal-conditioned latent representation encoding the future trajectory, which enables competitive performance on all three benchmarks.'}",https://openreview.net{'value': '/pdf/66ff9d643d53377df4ee9d7714864183574a7cf2.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=IHR83ufYPy,{'value': 'Leveraging sparse and shared feature activations for disentangled representation learning'},Marco Fumero; Florian Wenzel; Luca Zancato; Alessandro Achille; Emanuele Rodolà; Stefano Soatto; Bernhard Schölkopf; Francesco Locatello,~Marco_Fumero1; ~Florian_Wenzel1; ~Luca_Zancato1; ~Alessandro_Achille1; ~Emanuele_Rodolà1; ~Stefano_Soatto3; ~Bernhard_Schölkopf1; ~Francesco_Locatello1,"{'value': ['disentanglement', 'OOD generalization', 'multitask learning']}","{'value': 'Recovering the latent factors of variation of high dimensional data has so far focused on simple synthetic settings. Mostly building on unsupervised and weakly-supervised objectives, prior work missed out on the positive implications for representation learning on real world data. In this work, we propose to leverage knowledge extracted from a diversified set of supervised tasks to learn a common disentangled representation. Assuming each supervised task only depends on an unknown subset of the factors of variation, we disentangle the feature space of a supervised multi-task model, with features activating sparsely across different tasks and information being shared as appropriate. Importantly, we never directly observe the factors of variations but establish that access to multiple tasks is sufficient for identifiability under sufficiency and minimality assumptions.\nWe validate our approach on six real world distribution shift benchmarks, and different data modalities (images, text), demonstrating how disentangled representations can be transferred to real settings.'}",https://openreview.net{'value': '/pdf/a4d438d017564bfbabefcfc12facd422953e9222.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=IEMLNF4gK4,{'value': 'SHAP-IQ: Unified Approximation of any-order Shapley Interactions'},Fabian Fumagalli; Maximilian Muschalik; Patrick Kolpaczki; Eyke Hüllermeier; Barbara Hammer,~Fabian_Fumagalli1; ~Maximilian_Muschalik1; ~Patrick_Kolpaczki1; ~Eyke_Hüllermeier1; ~Barbara_Hammer4,"{'value': ['Explainable Artificial Intelligence', 'Feature Interaction', 'Shapley Interaction', 'Shapley Value']}","{'value': 'Predominately in explainable artificial intelligence (XAI) research, the Shapley value (SV) is applied to determine feature attributions for any black box model. Shapley interaction indices extend the SV to define any-order feature interactions. Defining a unique Shapley interaction index is an open research question and, so far, three definitions have been proposed, which differ by their choice of axioms. Moreover, each definition requires a specific approximation technique. Here, we propose SHAPley Interaction Quantification (SHAP-IQ), an efficient sampling-based approximator to compute Shapley interactions for arbitrary cardinal interaction indices (CII), i.e. interaction indices that satisfy the linearity, symmetry and dummy axiom. SHAP-IQ is based on a novel representation and, in contrast to existing methods, we provide theoretical guarantees for its approximation quality, as well as estimates for the variance of the point estimates. For the special case of SV, our approach reveals a novel representation of the SV and corresponds to Unbiased KernelSHAP with a greatly simplified calculation. We illustrate the computational efficiency and effectiveness by explaining language, image classification and high-dimensional synthetic models.'}",https://openreview.net{'value': '/pdf/ad9dd10721dfdc7aec1878ddd33f899345abc62d.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=I9GNrInbdf,{'value': 'Formulating Discrete Probability Flow Through Optimal Transport'},Pengze Zhang; Hubery Yin; Chen Li; Xiaohua Xie,~Pengze_Zhang1; ~Hubery_Yin1; ~Chen_Li11; ~Xiaohua_Xie1,"{'value': ['Discrete Probability Flow', 'Optimal Transport']}","{'value': 'Continuous diffusion models are commonly acknowledged to display a deterministic probability flow, whereas discrete diffusion models do not. In this paper, we aim to establish the fundamental theory for the probability flow of discrete diffusion models. Specifically, we first prove that the continuous probability flow is the Monge optimal transport map under certain conditions, and also present an equivalent evidence for discrete cases.  In view of these findings, we are then able to define the discrete probability flow in line with the principles of optimal transport. Finally, drawing upon our newly established definitions, we propose a novel sampling method that surpasses previous discrete diffusion models in its ability to generate more certain outcomes. Extensive experiments on the synthetic toy dataset and the CIFAR-10 dataset have validated the effectiveness of our proposed discrete probability flow. Code is released at: https://github.com/PangzeCheung/Discrete-Probability-Flow.'}",https://openreview.net{'value': '/pdf/4b0b62652c3a51071d52c54921c52cf9a39c590c.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=HvhagNdf5z,{'value': 'Synthetic-to-Real Pose Estimation with Geometric Reconstruction'},Qiuxia Lin; Kerui Gu; Linlin Yang; Angela Yao,~Qiuxia_Lin1; ~Kerui_Gu1; ~Linlin_Yang1; ~Angela_Yao1,"{'value': ['pose estimation', 'domain adaptation']}","{'value': 'Pose estimation is remarkably successful under supervised learning, but obtaining annotations, especially for new deployments, is costly and time-consuming. This work tackles adapting models trained on synthetic data to real-world target domains with only unlabelled data. A common approach is model fine-tuning with pseudo-labels from the target domain; yet many pseudo-labelling strategies cannot provide sufficient high-quality pose labels. This work proposes a reconstruction-based strategy as a complement to pseudo-labelling for synthetic-to-real domain adaptation. We generate the driving image by geometrically transforming a base image according to the predicted keypoints and enforce a reconstruction loss to refine the predictions. It provides a novel solution to effectively correct confident yet inaccurate keypoint locations through image reconstruction in domain adaptation. Our approach outperforms the previous state-of-the-arts by 8% for PCK on four large-scale hand and human real-world datasets. In particular, we excel on endpoints such as fingertips and head, with 7.2% and 29.9% improvements in PCK.'}",https://openreview.net{'value': '/pdf/bffd733896d24f662ad7f1840da7bcbce7839bc9.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Ht79ZTVMsn,{'value': 'Addressing the speed-accuracy simulation trade-off for adaptive spiking neurons'},Luke Taylor; Andrew J King; Nicol Spencer Harper,~Luke_Taylor1; ~Andrew_J_King1; ~Nicol_Spencer_Harper1,"{'value': ['spiking neural network', 'surrogate gradient descent', 'adaptive leaky integrate and fire neuron', 'speed-accuracy trade-off', 'electrophysiological recordings']}","{'value': 'The adaptive leaky integrate-and-fire (ALIF) model is fundamental within computational neuroscience and has been instrumental in studying our brains $\\textit{in silico}$. Due to the sequential nature of simulating these neural models, a commonly faced issue is the speed-accuracy trade-off: either accurately simulate a neuron using a small discretisation time-step (DT), which is slow, or more quickly simulate a neuron using a larger DT and incur a loss in simulation accuracy. Here we provide a solution to this dilemma, by algorithmically reinterpreting the ALIF model, reducing the sequential simulation complexity and permitting a more efficient parallelisation on GPUs. We computationally validate our implementation to obtain over a $50\\times$ training speedup using small DTs on synthetic benchmarks. We also obtained a comparable performance to the standard ALIF implementation on different supervised classification tasks - yet in a fraction of the training time. Lastly, we showcase how our model makes it possible to quickly and accurately fit real electrophysiological recordings of cortical neurons, where very fine sub-millisecond DTs are crucial for capturing exact spike timing.'}",https://openreview.net{'value': '/pdf/e7f24d624356157f86080372611572dd115346c7.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=HszLRiHyfO,{'value': 'Causal Component Analysis'},Wendong Liang; Armin Kekić; Julius von Kügelgen; Simon Buchholz; Michel Besserve; Luigi Gresele; Bernhard Schölkopf,~Wendong_Liang1; ~Armin_Kekić1; ~Julius_von_Kügelgen2; ~Simon_Buchholz1; ~Michel_Besserve1; ~Luigi_Gresele1; ~Bernhard_Schölkopf1,"{'value': ['Causality', 'independent component analysis', 'causal inference', 'interventions', 'latent variable models', 'identifiability']}","{'value': 'Independent Component Analysis (ICA) aims to recover independent latent variables from observed mixtures thereof. Causal Representation Learning (CRL) aims instead to infer causally related (thus often statistically _dependent_) latent variables, together with the unknown graph encoding their causal relationships. We introduce an intermediate problem termed _Causal Component Analysis (CauCA)_. CauCA can be viewed as a generalization of ICA, modelling the causal dependence among the latent components, and as a special case of CRL. In contrast to CRL, it presupposes knowledge of the causal graph, focusing solely on learning the unmixing function and the causal mechanisms. Any impossibility results regarding the recovery of the ground truth in CauCA also apply for CRL, while possibility results may serve as a stepping stone for extensions to CRL. We characterize CauCA identifiability from multiple datasets generated through different types of interventions on the latent causal variables. As a corollary, this interventional perspective also leads to new identifiability results for nonlinear ICA—a special case of CauCA with an empty graph—requiring strictly fewer datasets than previous results. We introduce a likelihood-based approach using normalizing flows to estimate both the unmixing function and the causal mechanisms, and demonstrate its effectiveness through extensive synthetic experiments in the CauCA and ICA setting.'}",https://openreview.net{'value': '/pdf/d77866239c5cd0912f3815941a80e70b73d03c71.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=HUuEMMM8Ik,{'value': 'Detecting hidden confounding in observational data using multiple environments'},Rickard Karlsson; JH Krijthe,~Rickard_Karlsson1; ~JH_Krijthe1,"{'value': ['causal inference', 'hidden confounding', 'multiple environments', 'independent causal mechansisms', 'independence testing']}","{'value': 'A common assumption in causal inference from observational data is that there is no hidden confounding. Yet it is, in general, impossible to verify the presence of hidden confounding factors from a single dataset. Under the assumption of independent causal mechanisms underlying the data-generating process, we demonstrate a way to detect unobserved confounders when having multiple observational datasets coming from different environments. We present a theory for testable conditional independencies that are only absent when there is hidden confounding and examine cases where we violate its assumptions: degenerate & dependent mechanisms, and faithfulness violations. Additionally, we propose a procedure to test these independencies and study its empirical finite-sample behavior using simulation studies and semi-synthetic data based on a real-world dataset. In most cases, the proposed procedure correctly predicts the presence of hidden confounding, particularly when the confounding bias is large.'}",https://openreview.net{'value': '/pdf/e4c64183a6e812c986319a1e63c604d0dc7523d1.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=GxL6PrmEUw,{'value': 'Distributional Learning of Variational AutoEncoder: Application to Synthetic Data Generation'},Seunghwan An; Jong-June Jeon,~Seunghwan_An2; ~Jong-June_Jeon1,"{'value': ['Variational AutoEncoder', 'distributional learning', 'synthetic data generation', 'CRPS', 'asymmetric Laplace distribution']}","{'value': ""The Gaussianity assumption has been consistently criticized as a main limitation of the Variational Autoencoder (VAE) despite its efficiency in computational modeling. In this paper, we propose a new approach that expands the model capacity (i.e., expressive power of distributional family) without sacrificing the computational advantages of the VAE framework. Our VAE model's decoder is composed of an infinite mixture of asymmetric Laplace distribution, which possesses general distribution fitting capabilities for continuous variables. Our model is represented by a special form of a nonparametric M-estimator for estimating general quantile functions, and we theoretically establish the relevance between the proposed model and quantile estimation. We apply the proposed model to synthetic data generation, and particularly, our model demonstrates superiority in easily adjusting the level of data privacy.""}",https://openreview.net{'value': '/pdf/b4dfb0d75b227381d2742fee2a9220e899687d9c.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Gtse4R6iS4,{'value': 'Robustifying Generalizable Implicit Shape Networks with a Tunable Non-Parametric Model'},Amine Ouasfi; Adnane Boukhayma,~Amine_Ouasfi1; ~Adnane_Boukhayma2,"{'value': ['implicit neural representations', '3D reconstruction from unoriented point could', 'kernel ridge regression']}","{'value': 'Feedforward generalizable models for implicit shape reconstruction from unoriented point cloud present multiple advantages, including high performance and inference speed. However, they still suffer from generalization issues, ranging from underfitting the input point cloud, to misrepresenting samples outside of the training data distribution, or with toplogies unseen at training.  We propose here an efficient mechanism to remedy some of these limitations at test time. We combine the inter-shape data prior of the network with an intra-shape regularization prior of a Nyström Kernel Ridge Regression, that we further adapt by fitting its hyperprameters to the current shape. The resulting shape function defined in a shape specific Reproducing Kernel Hilbert Space benefits from desirable stability and efficiency properties and grants a shape adaptive expressiveness-robustness trade-off. We demonstrate the improvement obtained through our method  with respect to baselines and the state-of-the-art using synthetic and real data.'}",https://openreview.net{'value': '/pdf/9c3f0b9ccd2dfe797ba09091407ea8011896a02f.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=GjJRbEZ1dc,{'value': 'Multitask Learning with No Regret: from Improved Confidence Bounds to Active Learning'},Pier Giuseppe Sessa; Pierre Laforgue; Nicolò Cesa-Bianchi; Andreas Krause,~Pier_Giuseppe_Sessa1; ~Pierre_Laforgue1; ~Nicolò_Cesa-Bianchi1; ~Andreas_Krause1,"{'value': ['multitask learning', 'confidence intervals', 'online learning theory', 'active learning', 'regret']}","{'value': ""Multitask learning is a powerful framework that enables one to simultaneously learn multiple related tasks by sharing information between them. Quantifying uncertainty in the estimated tasks is of pivotal importance for many downstream applications, such as online or active learning. In this work, we provide novel confidence intervals for multitask regression in the challenging agnostic setting, i.e., when neither the similarity between tasks nor the tasks' features are available to the learner. The obtained intervals do not require i.i.d. data and can be directly applied to bound the regret in online learning. Through a refined analysis of the multitask information gain, we obtain new regret guarantees that, depending on a task similarity parameter, can significantly improve over treating tasks independently. We further propose a novel online learning algorithm that achieves such improved regret without knowing this parameter in advance, i.e., automatically adapting to task similarity. As a second key application of our results, we introduce a novel multitask active learning setup where several tasks must be simultaneously optimized, but only one of them can be queried for feedback by the learner at each round. For this problem, we design a no-regret algorithm that uses our confidence intervals to decide which task should be queried. Finally, we empirically validate our bounds and algorithms on synthetic and real-world (drug discovery) data.""}",https://openreview.net{'value': '/pdf/3218199bdb9adece68c3672cf898cd8d98dbece6.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Gij638d76O,{'value': 'Neural Latent Geometry Search: Product Manifold Inference via Gromov-Hausdorff-Informed Bayesian Optimization'},Haitz Sáez de Ocáriz Borde; Alvaro Arroyo; Ismael Morales López; Ingmar Posner; Xiaowen Dong,~Haitz_Sáez_de_Ocáriz_Borde1; ~Alvaro_Arroyo1; ismael.morales@hertford.ox.ac.uk; ~Ingmar_Posner1; ~Xiaowen_Dong1,"{'value': ['Representation Learning', 'Product Manifolds', 'Bayesian Optimization', 'Gromov-Hausdorff Distance']}","{'value': 'Recent research indicates that the performance of machine learning models can be improved by aligning the geometry of the latent space with the underlying data structure. Rather than relying solely on Euclidean space, researchers have proposed using hyperbolic and spherical spaces with constant curvature, or combinations thereof, to better model the latent space and enhance model performance. However, little attention has been given to the problem of automatically identifying the optimal latent geometry for the downstream task. We mathematically define this novel formulation and coin it as neural latent geometry search (NLGS). More specifically, we introduce an initial attempt to search for a latent geometry composed of a product of constant curvature model spaces with a small number of query evaluations, under some simplifying assumptions. To accomplish this, we propose a novel notion of distance between candidate latent geometries based on the Gromov-Hausdorff distance from metric geometry. In order to compute the Gromov-Hausdorff distance, we introduce a mapping function that enables the comparison of different manifolds by embedding them in a common high-dimensional ambient space. We then design a graph search space based on the notion of smoothness between latent geometries and employ the calculated distances as an additional inductive bias. Finally, we use Bayesian optimization to search for the optimal latent geometry in a query-efficient manner. This is a general method which can be applied to search for the optimal latent geometry for a variety of models and downstream tasks. We perform experiments on synthetic and real-world datasets to identify the optimal latent geometry for multiple machine learning problems.'}",https://openreview.net{'value': '/pdf/ecac30b142818450cdd50b8a94f6d321cc1be1f4.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=GiUe0ZFiVe,{'value': 'Bi-Level Offline Policy Optimization with Limited Exploration'},Wenzhuo Zhou,~Wenzhuo_Zhou1,"{'value': ['Offline Reinforcement Learning', 'Sample Efficiency', 'Regret Bound', 'Data Coverage']}","{'value': ""We study offline reinforcement learning (RL) which seeks to learn a good policy based on a fixed, pre-collected dataset. A fundamental challenge behind this task is the distributional shift due to the dataset lacking sufficient exploration, especially under function approximation. To tackle this issue, we propose a bi-level structured policy optimization algorithm that models a hierarchical interaction between the policy (upper-level) and the value function (lower-level). The lower level focuses on constructing a confidence set of value estimates that maintain sufficiently small weighted average Bellman errors, while controlling uncertainty arising from distribution mismatch. Subsequently, at the upper level, the policy aims to maximize a conservative value estimate from the confidence set formed at the lower level. This novel formulation preserves the maximum flexibility of the implicitly induced exploratory data distribution, enabling the power of model extrapolation. In practice, it can be solved through a computationally efficient, penalized adversarial estimation procedure. Our theoretical regret guarantees do not rely on any data-coverage and completeness-type assumptions, only requiring realizability. These guarantees also demonstrate that the learned policy represents the ``best effort'' among all policies, as no other policies can outperform it. We evaluate our model using a blend of synthetic, benchmark, and real-world datasets for offline RL, showing that it performs competitively with state-of-the-art methods.""}",https://openreview.net{'value': '/pdf/0b203af29f5b3c9dde37eeaa91e21bf316700021.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Gh67ZZ6zkS,{'value': 'PreDiff: Precipitation Nowcasting with Latent Diffusion Models'},Zhihan Gao; Xingjian Shi; Boran Han; Hao Wang; Xiaoyong Jin; Danielle C. Maddix; Yi Zhu; Mu Li; Bernie Wang,~Zhihan_Gao1; ~Xingjian_Shi1; ~Boran_Han1; ~Hao_Wang3; ~Xiaoyong_Jin1; ~Danielle_C._Maddix1; ~Yi_Zhu1; ~Mu_Li4; ~Bernie_Wang1,"{'value': ['Machine Learning for Earth Science', 'Spatiotemporal Forecasting', 'Generative Models', 'Diffusion Models']}","{'value': 'Earth system forecasting has traditionally relied on complex physical models that are computationally expensive and require significant domain expertise.\nIn the past decade, the unprecedented increase in spatiotemporal Earth observation data has enabled data-driven forecasting models using deep learning techniques.\nThese models have shown promise for diverse Earth system forecasting tasks but either struggle with handling uncertainty or neglect domain-specific prior knowledge, resulting in averaging possible futures to blurred forecasts or generating physically implausible predictions.\nTo address these limitations, we propose a two-stage pipeline for probabilistic spatiotemporal forecasting: 1) We develop *PreDiff*, a conditional latent diffusion model capable of probabilistic forecasts. 2) We incorporate an explicit knowledge alignment mechanism to align forecasts with domain-specific physical constraints. \nThis is achieved by estimating the deviation from imposed constraints at each denoising step and adjusting the transition distribution accordingly.\nWe conduct empirical studies on two datasets: N-body MNIST, a synthetic dataset with chaotic behavior, and SEVIR, a real-world precipitation nowcasting dataset. \nSpecifically, we impose the law of conservation of energy in N-body MNIST and anticipated precipitation intensity in SEVIR. \nExperiments demonstrate the effectiveness of PreDiff in handling uncertainty, incorporating domain-specific prior knowledge, and generating forecasts that exhibit high operational utility.'}",https://openreview.net{'value': '/pdf/f59de76b3a7e0e1f83153cb78506f89dbcf015c8.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=GJtP1ZEzua,{'value': 'D4Explainer: In-distribution Explanations of Graph Neural Network via Discrete Denoising Diffusion'},Jialin Chen; Shirley Wu; Abhijit Gupta; Zhitao Ying,~Jialin_Chen2; ~Shirley_Wu1; ~Abhijit_Gupta1; ~Zhitao_Ying1,"{'value': ['Explainability', 'Graph Neural Network', 'Diffusion Model']}","{'value': 'The widespread deployment of Graph Neural Networks (GNNs) sparks significant interest in their explainability, which plays a vital role in model auditing and ensuring trustworthy graph learning. The objective of GNN explainability is to discern the underlying graph structures that have the most significant impact on model predictions. Ensuring that explanations generated are reliable necessitates consideration of the in-distribution property, particularly due to the vulnerability of GNNs to out-of-distribution data. Unfortunately, prevailing explainability methods tend to constrain the generated explanations to the structure of the original graph, thereby downplaying the significance of the in-distribution property and resulting in explanations that lack reliability.\nTo address these challenges, we propose D4Explainer, a novel approach that provides in-distribution GNN explanations for both counterfactual and model-level explanation scenarios. The proposed D4Explainer incorporates generative graph distribution learning into the optimization objective, which accomplishes two goals: 1) generate a collection of diverse counterfactual graphs that conform to the in-distribution property for a given instance, and 2) identify the most discriminative graph patterns that contribute to a specific class prediction, thus serving as model-level explanations. It is worth mentioning that D4Explainer is the first unified framework that combines both counterfactual and model-level explanations.\nEmpirical evaluations conducted on synthetic and real-world datasets provide compelling evidence of the state-of-the-art performance achieved by D4Explainer in terms of explanation accuracy, faithfulness, diversity, and robustness.'}",https://openreview.net{'value': '/pdf/8ba69e911039af2e1511df3de684d821ea40942b.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=GItLpB1vhK,{'value': 'Estimating Koopman operators with sketching to provably learn large scale dynamical systems'},Giacomo Meanti; Antoine Chatalic; Vladimir R Kostic; Pietro Novelli; Massimiliano Pontil; Lorenzo Rosasco,~Giacomo_Meanti1; ~Antoine_Chatalic1; ~Vladimir_R_Kostic1; ~Pietro_Novelli1; ~Massimiliano_Pontil4; ~Lorenzo_Rosasco1,"{'value': ['dynamical systems', 'kernel methods', 'koopman operator', 'sketching', 'molecular dynamics', 'efficient machine learning']}","{'value': ""The theory of Koopman operators allows to deploy non-parametric machine learning algorithms to predict and analyze complex dynamical systems.\nEstimators such as principal component regression (PCR) or reduced rank regression (RRR) in kernel spaces can be shown to provably learn Koopman operators from finite empirical observations of the system's time evolution. \nScaling these approaches to very long trajectories is a challenge and requires introducing suitable approximations to make computations feasible. \nIn this paper, we boost the efficiency of \ndifferent kernel-based Koopman operator estimators using random projections (sketching).\nWe derive, implement and test the new ``sketched'' estimators with extensive experiments on synthetic and large-scale molecular dynamics datasets. \nFurther, we establish non asymptotic error bounds giving a sharp characterization of the trade-offs between statistical learning rates and computational efficiency.\nOur empirical and theoretical analysis shows that the proposed estimators provide a sound and efficient way to learn large scale dynamical systems.\nIn particular our experiments indicate that the proposed estimators retain the same accuracy of PCR or RRR, while being much faster.""}",https://openreview.net{'value': '/pdf/c1b736e72959b41fb100dafcb870a51da9629c9c.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=GEtXhqKW6X,{'value': 'iSCAN: Identifying Causal Mechanism Shifts among Nonlinear Additive Noise Models'},Tianyu Chen; Kevin Bello; Bryon Aragam; Pradeep Kumar Ravikumar,tianyuchen@uchicago.edu; ~Kevin_Bello1; ~Bryon_Aragam1; ~Pradeep_Kumar_Ravikumar1,"{'value': ['distribution shifts', 'heterogeneous data', 'feature-shift', 'structural causal models', 'additive noise models', 'causality', 'root-cause analysis']}","{'value': 'Structural causal models (SCMs) are widely used in various disciplines to represent causal relationships among variables in complex systems.\nUnfortunately, the underlying causal structure is often unknown, and estimating it from data remains a challenging task. \nIn many situations, however, the end goal is to localize the changes (shifts) in the causal mechanisms between related datasets instead of learning the full causal structure of the individual datasets. \nSome applications include root cause analysis, analyzing gene regulatory network structure changes between healthy and cancerous individuals, or explaining distribution shifts. \nThis paper focuses on identifying the causal mechanism shifts in two or more related datasets over the same set of variables---*without estimating the entire DAG structure of each SCM*.\nPrior work under this setting assumed linear models with Gaussian noises; instead, in this work we assume that each SCM belongs to the more general class of *nonlinear* additive noise models (ANMs).\nA key technical contribution of this work is to show that the Jacobian of the score function for the *mixture distribution* allows for the identification of shifts under general non-parametric functional mechanisms.\nOnce the shifted variables are identified, we leverage recent work to estimate the structural differences, if any, for the shifted variables.\nExperiments on synthetic and real-world data are provided to showcase the applicability of this approach.\nCode implementing the proposed method is open-source and publicly available at  https://github.com/kevinsbello/iSCAN.'}",https://openreview.net{'value': '/pdf/7c90d0db006cc54e295a515facab929854ccd995.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=G8nal7MpIQ,{'value': 'Guide Your Agent with Adaptive Multimodal Rewards'},Changyeon Kim; Younggyo Seo; Hao Liu; Lisa Lee; Jinwoo Shin; Honglak Lee; Kimin Lee,~Changyeon_Kim1; ~Younggyo_Seo1; ~Hao_Liu1; ~Lisa_Lee1; ~Jinwoo_Shin1; ~Honglak_Lee2; ~Kimin_Lee1,"{'value': ['Reinforcement Learning', 'Multimodal Representation', 'Imitation Learning']}","{'value': ""Developing an agent capable of adapting to unseen environments remains a difficult challenge in imitation learning. This work presents Adaptive Return-conditioned Policy (ARP), an efficient framework designed to enhance the agent's generalization ability using natural language task descriptions and pre-trained multimodal encoders. Our key idea is to calculate a similarity between visual observations and natural language instructions in the pre-trained multimodal embedding space (such as CLIP) and use it as a reward signal. We then train a return-conditioned policy using expert demonstrations labeled with multimodal rewards. Because the multimodal rewards provide adaptive signals at each timestep, our ARP effectively mitigates the goal misgeneralization. This results in superior generalization performances even when faced with unseen text instructions, compared to existing text-conditioned policies. To improve the quality of rewards, we also introduce a fine-tuning method for pre-trained multimodal encoders, further enhancing the performance. Video demonstrations and source code are available on the project website: \\url{https://sites.google.com/view/2023arp}.""}",https://openreview.net{'value': '/pdf/7b5068134f25b8c88db8899c8f7e18072b72f7d8.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=G560qr59Gi,{'value': 'Implicit Bias of Gradient Descent for Two-layer ReLU and Leaky ReLU Networks on Nearly-orthogonal Data'},Yiwen Kou; Zixiang Chen; Quanquan Gu,~Yiwen_Kou1; ~Zixiang_Chen1; ~Quanquan_Gu1,"{'value': ['ReLU Neural Networks', 'Implicit Bias', 'Deep Learning Theory']}","{'value': 'The implicit bias towards solutions with favorable properties is believed to be a key reason why neural networks trained by gradient-based optimization can generalize well. While the implicit bias of gradient flow has been widely studied for homogeneous neural networks (including ReLU and leaky ReLU networks), the implicit bias of gradient descent is currently only understood for smooth neural networks. Therefore, implicit bias in non-smooth neural networks trained by gradient descent remains an open question. In this paper, we aim to answer this question by studying the implicit bias of gradient descent for training two-layer fully connected (leaky) ReLU neural networks. We showed that when the training data are nearly-orthogonal, for leaky ReLU activation function, gradient descent will find a network with a stable rank that converges to $1$, whereas for ReLU activation function, gradient descent will find a neural network with a stable rank that is upper bounded by a constant. Additionally, we show that gradient descent will find a neural network such that all the training data points have the same normalized margin asymptotically. Experiments on both synthetic and real data backup our theoretical findings.'}",https://openreview.net{'value': '/pdf/ab6b7def82367ec50b43c91fafc7fc8dfb91384b.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=FskZtRvMJI,{'value': 'RiskQ: Risk-sensitive Multi-Agent Reinforcement Learning Value Factorization'},Siqi Shen; Chennan Ma; Chao Li; Weiquan Liu; Yongquan Fu; Songzhu Mei; Xinwang Liu; Cheng Wang,~Siqi_Shen5; ~Chennan_Ma1; ~Chao_Li29; ~Weiquan_Liu1; ~Yongquan_Fu2; ~Songzhu_Mei1; ~Xinwang_Liu1; ~Cheng_Wang2,"{'value': ['multi-agent reinforcement learning', 'value factorization', 'individual global max', 'risk-sensitive']}","{'value': 'Multi-agent systems are characterized by environmental uncertainty, varying policies of agents, and partial observability, which result in significant risks. In the context of Multi-Agent Reinforcement Learning (MARL), learning coordinated and decentralized policies that are sensitive to risk is challenging. To formulate the coordination requirements in risk-sensitive MARL, we introduce the Risk-sensitive Individual-Global-Max (RIGM) principle as a generalization of the Individual-Global-Max (IGM) and Distributional IGM (DIGM) principles. This principle requires that the collection of risk-sensitive action selections of each agent should be equivalent to the risk-sensitive action selection of the central policy. Current MARL value factorization methods do not satisfy the RIGM principle for common risk metrics such as the Value at Risk (VaR) metric or distorted risk measurements. Therefore, we propose RiskQ to address this limitation, which models the joint return distribution by modeling quantiles of it as weighted quantile mixtures of per-agent return distribution utilities. RiskQ satisfies the RIGM principle for the VaR and distorted risk metrics. We show that RiskQ can obtain promising performance through extensive experiments. The source code of RiskQ is available in https://github.com/xmu-rl-3dv/RiskQ.'}",https://openreview.net{'value': '/pdf/304803860d3360243875995a5251d8a5474d612d.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Fp5uC6YHwe,{'value': '3D-IntPhys: Towards More Generalized 3D-grounded Visual Intuitive Physics under Challenging Scenes'},Haotian Xue; Antonio Torralba; Joshua B. Tenenbaum; Daniel LK Yamins; Yunzhu Li; Hsiao-Yu Tung,~Haotian_Xue1; ~Antonio_Torralba1; ~Joshua_B._Tenenbaum1; ~Daniel_LK_Yamins1; ~Yunzhu_Li1; ~Hsiao-Yu_Tung1,"{'value': ['Intuitive Physics', 'Computer Vision']}","{'value': 'Given a visual scene, humans have strong intuitions about how a scene can evolve over time under given actions. The intuition, often termed visual intuitive physics, is a critical ability that allows us to make effective plans to manipulate the scene to achieve desired outcomes without relying on extensive trial and error. In this paper, we present a framework capable of learning 3D-grounded visual intuitive physics models from videos of complex scenes with fluids. Our method is composed of a conditional Neural Radiance Field (NeRF)-style visual frontend and a 3D point-based dynamics prediction backend, using which we can impose strong relational and structural inductive bias to capture the structure of the underlying environment. Unlike existing intuitive point-based dynamics works that rely on the supervision of dense point trajectory from simulators, we relax the requirements and only assume access to multi-view RGB images and (imperfect) instance masks acquired using color prior. This enables the proposed model to handle scenarios where accurate point estimation and tracking are hard or impossible. We generate datasets including three challenging scenarios involving fluid, granular materials, and rigid objects in the simulation. The datasets do not include any dense particle information so most previous 3D-based intuitive physics pipelines can barely deal with that. We show our model can make long-horizon future predictions by learning from raw images and significantly outperforms models that do not employ an explicit 3D representation space. We also show that once trained, our model can achieve strong generalization in complex scenarios under extrapolate settings.'}",https://openreview.net{'value': '/pdf/739e599bd87f8fd4fcb09b78dd8827c81af83052.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=FmZVRe0gn8,{'value': 'Robust Multi-Agent Reinforcement Learning via Adversarial Regularization: Theoretical Foundation and Stable Algorithms'},Alexander Bukharin; Yan Li; Yue Yu; Qingru Zhang; Zhehui Chen; Simiao Zuo; Chao Zhang; Songan Zhang; Tuo Zhao,~Alexander_Bukharin1; ~Yan_Li9; ~Yue_Yu2; ~Qingru_Zhang2; ~Zhehui_Chen1; ~Simiao_Zuo1; ~Chao_Zhang15; ~Songan_Zhang1; ~Tuo_Zhao1,"{'value': ['Multi-Agent Reinforcement Learning', 'Theory of Robust Reinforcement Learning', 'Adversarial Regularization']}","{'value': 'Multi-Agent Reinforcement Learning (MARL) has shown promising results across several domains. Despite this promise, MARL policies often lack robustness and are therefore sensitive to small changes in their environment. This presents a serious concern for the real world deployment of MARL algorithms, where the testing environment may slightly differ from the training environment. In this work we show that we can gain robustness by controlling a policy’s Lipschitz constant, and under mild conditions, establish the existence of a Lipschitz and close-to-optimal policy. Motivated by these insights, we propose a new robust MARL framework, ERNIE, that promotes the Lipschitz continuity of the policies with respect to the state observations and actions by adversarial regularization. The ERNIE framework provides robustness against noisy observations, changing transition dynamics, and malicious actions of agents. However, ERNIE’s adversarial regularization may introduce some training instability. To reduce this instability, we reformulate adversarial regularization as a Stackelberg game. We demonstrate the effectiveness of the proposed framework with extensive experiments in traffic light control and particle environments. In addition, we extend ERNIE to mean-field MARL with a formulation based on distributionally robust optimization that outperforms its non-robust counterpart and is of independent interest. Our code is available at https://github.com/abukharin3/ERNIE.'}",https://openreview.net{'value': '/pdf/e66b05e7e10a71b29848af8febe181910a745dd5.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=FiClXlUqA7,{'value': 'A Unified Approach to Domain Incremental Learning with Memory: Theory and Algorithm'},Haizhou Shi; Hao Wang,~Haizhou_Shi1; ~Hao_Wang3,"{'value': ['Domain Incremental Learning', 'Continual Learning', 'Theory']}","{'value': 'Domain incremental learning aims to adapt to a sequence of domains with access to only a small subset of data (i.e., memory) from previous domains. Various methods have been proposed for this problem, but it is still unclear how they are related and when practitioners should choose one method over another. In response, we propose a unified framework, dubbed Unified Domain Incremental Learning (UDIL), for domain incremental learning with memory. Our UDIL **unifies** various existing methods, and our theoretical analysis shows that UDIL always achieves a tighter generalization error bound compared to these methods. The key insight is that different existing methods correspond to our bound with different **fixed** coefficients; based on insights from this unification, our UDIL allows **adaptive** coefficients during training, thereby always achieving the tightest bound. Empirical results show that our UDIL outperforms the state-of-the-art domain incremental learning methods on both synthetic and real-world datasets. Code will be available at https://github.com/Wang-ML-Lab/unified-continual-learning.'}",https://openreview.net{'value': '/pdf/6da832130b1985d5bdc64ae1dcf66dcd077c5cba.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=FgakGFpll1,{'value': 'A Metadata-Driven Approach to Understand Graph Neural Networks'},Ting Wei Li; Qiaozhu Mei; Jiaqi Ma,~Ting_Wei_Li1; ~Qiaozhu_Mei1; ~Jiaqi_Ma1,"{'value': ['Graph Neural Networks', 'Metadata-Driven Analysis', 'Gini Coefficient of Degree Distribution']}","{'value': 'Graph Neural Networks (GNNs) have achieved remarkable success in various applications, but their performance can be sensitive to specific data properties of the graph datasets they operate on. Current literature on understanding the limitations of GNNs has primarily employed a \\emph{model-driven} approach that leverage heuristics and domain knowledge from network science or graph theory to model the GNN behaviors, which is time-consuming and highly subjective. In this work, we propose a \\emph{metadata-driven} approach to analyze the sensitivity of GNNs to graph data properties, motivated by the increasing availability of graph learning benchmarks. We perform a multivariate sparse regression analysis on the metadata derived from benchmarking GNN performance across diverse datasets, yielding a set of salient data properties. To validate the effectiveness of our data-driven approach, we focus on one identified data property, the degree distribution, and investigate how this property influences GNN performance through theoretical analysis and controlled experiments. Our theoretical findings reveal that datasets with more balanced degree distribution exhibit better linear separability of node representations, thus leading to better GNN performance. We also conduct controlled experiments using synthetic datasets with varying degree distributions, and the results align well with our theoretical findings. Collectively, both the theoretical analysis and controlled experiments verify that the proposed metadata-driven approach is effective in identifying critical data properties for GNNs.'}",https://openreview.net{'value': '/pdf/fae8b8759c4cb4b431479a2f1ff5ed2b478ce9dd.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=FOFJmR1oxt,{'value': 'BCDiff: Bidirectional Consistent Diffusion for Instantaneous Trajectory Prediction'},Rongqing Li; Changsheng Li; Dongchun Ren; Guangyi Chen; Ye Yuan; Guoren Wang,~Rongqing_Li1; ~Changsheng_Li4; ~Dongchun_Ren2; ~Guangyi_Chen1; ~Ye_Yuan15; ~Guoren_Wang2,"{'value': ['Trajectory prediction', 'instantaneous observation']}","{'value': 'The objective of pedestrian trajectory prediction is to estimate the future paths of pedestrians by leveraging historical observations, which plays a vital role in ensuring the safety of self-driving vehicles and navigation robots. Previous works usually rely on a sufficient amount of observation time to accurately predict future trajectories. However, there are many real-world situations where the model lacks sufficient time to observe, such as when pedestrians abruptly emerge from blind spots, resulting in inaccurate predictions and even safety risks. Therefore, it is necessary to perform trajectory prediction based on instantaneous observations, which has rarely been studied before. In this paper, we propose a Bi-directional Consistent Diffusion framework tailored for instantaneous trajectory prediction, named BCDiff. At its heart, we develop two coupled diffusion models by designing a mutual guidance mechanism which can bidirectionally and consistently generate unobserved historical trajectories and future trajectories step-by-step,  to utilize the complementary information between them. Specifically, at each step, the predicted unobserved historical trajectories and limited observed trajectories guide one diffusion model to generate future trajectories, while the predicted future trajectories and observed trajectories guide the other diffusion model to predict unobserved historical trajectories. Given the presence of relatively high noise in the generated trajectories during the initial steps, we introduce a gating mechanism to learn the weights between the predicted trajectories and the limited observed trajectories for automatically balancing their contributions. By means of this iterative and mutually guided generation process, both the future and unobserved historical trajectories undergo continuous refinement, ultimately leading to accurate predictions. Essentially, BCDiff is an encoder-free framework that can be compatible with existing trajectory prediction models in principle. Experiments show that our proposed BCDiff significantly improves the accuracy of instantaneous trajectory prediction on the ETH/UCY and Stanford Drone datasets, compared to related approaches.'}",https://openreview.net{'value': '/pdf/8557f9cb53bd4a2e8cffc0b9e2752e6b94be8002.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=FFOYWUpBca,{'value': 'C-Disentanglement: Discovering Causally-Independent Generative Factors under  an Inductive Bias of Confounder'},Xiaoyu Liu; Jiaxin Yuan; Bang An; Yuancheng Xu; Yifan Yang; Furong Huang,~Xiaoyu_Liu3; ~Jiaxin_Yuan1; ~Bang_An1; ~Yuancheng_Xu1; ~Yifan_Yang5; ~Furong_Huang1,"{'value': ['causal disentanglement', 'causal generative process', 'generative factors', 'confounder', 'inductive bias', 'disentanglement', 'causal inference']}","{'value': 'Representation learning assumes that real-world data is generated by a few semantically meaningful generative factors (i.e., sources of variation) and aims to discover them in the latent space. These factors are expected to be causally disentangled, meaning that distinct factors are encoded into separate latent variables, and changes in one factor will not affect the values of the others. Compared to statistical independence, causal disentanglement allows more controllable data generation, improved robustness, and better generalization. However, most existing work assumes unconfoundedness in the discovery process, that there are no common causes to the generative factors and thus obtain only statistical independence. In this paper, we recognize the importance of modeling confounders in discovering causal generative factors. Unfortunately, such factors are not identifiable without proper inductive bias. We fill the gap by introducing a framework entitled Confounded-Disentanglement (C-Disentanglement), the first framework that explicitly introduces the inductive bias of confounder via labels from domain expertise. In addition, we accordingly propose an approach to sufficiently identify the causally-disentangled factors under any inductive bias of the confounder.  We conduct extensive experiments on both synthetic and real-world datasets. Our method demonstrates competitive results compared to various SOTA baselines in obtaining causally disentangled features and downstream tasks under domain shifts.'}",https://openreview.net{'value': '/pdf/7b59a50805387dae0ef70761a265781504977751.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=F5FVsfCxt8,{'value': 'Decision Tree for Locally Private Estimation with Public Data'},Yuheng Ma; Han Zhang; Yuchao Cai; Hanfang Yang,~Yuheng_Ma1; ~Han_Zhang21; ~Yuchao_Cai1; ~Hanfang_Yang2,"{'value': ['Local differential privacy', 'non-parametric regression', 'decision tree', 'public data']}","{'value': 'We propose conducting locally differentially private (LDP) estimation with the aid of a small amount of public data to enhance the performance of private estimation. Specifically, we introduce an efficient algorithm called Locally differentially Private Decision Tree (LPDT) for LDP regression. We first use the public data to grow a decision tree partition and then fit an estimator according to the partition privately.  From a theoretical perspective, we show that LPDT is $\\varepsilon$-LDP and has a mini-max optimal convergence rate under a mild assumption of similarity between public and private data, whereas the lower bound of the convergence rate of LPDT without public data is strictly slower, which implies that the public data helps to improve the convergence rates of LDP estimation. We conduct experiments on both synthetic and real-world data to demonstrate the superior performance of LPDT compared with other state-of-the-art LDP regression methods. Moreover, we show that LPDT remains effective despite considerable disparities between public and private data.'}",https://openreview.net{'value': '/pdf/0ddc4c586332d39ef78317002064a301774d2e94.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=F1mv2L7Rkb,{'value': 'Invariant Anomaly Detection under Distribution Shifts: A Causal Perspective'},João B. S. Carvalho; Mengtao Zhang; Robin Geyer; Carlos Cotrini; Joachim M. Buhmann,~João_B._S._Carvalho1; ~Mengtao_Zhang1; ~Robin_Geyer1; ~Carlos_Cotrini1; ~Joachim_M._Buhmann1,"{'value': ['anomaly detection', 'causal inference', 'distribution shifts']}","{'value': 'Anomaly detection (AD) is the machine learning task of identifying highly discrepant abnormal samples by solely relying on the consistency of the normal training samples. Under the constraints of a distribution shift, the assumption that training samples and test samples are drawn from the same distribution breaks down. In this work, by leveraging tools from causal inference we attempt to increase the resilience of anomaly detection models to different kinds of distribution shifts. We begin by elucidating a simple yet necessary statistical property that ensures invariant representations, which is critical for robust AD under both domain and covariate shifts. From this property, we derive a regularization term which, when minimized, leads to partial distribution invariance across environments. \nThrough extensive experimental evaluation on both synthetic and real-world tasks, covering a range of six different AD methods, we demonstrated significant improvements in out-of-distribution performance. Under both covariate and domain shift, models regularized with our proposed term showed marked increased robustness. Code is available at: https://github.com/JoaoCarv/invariant-anomaly-detection'}",https://openreview.net{'value': '/pdf/e37ca6c259978c18c72e0fb2974931c2e256b275.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Eysb8t3MJ5,{'value': 'GlucoSynth: Generating Differentially-Private Synthetic Glucose Traces'},Josephine Lamp; Mark Derdzinski; Christopher Hannemann; Joost Van der Linden; Lu Feng; Tianhao Wang; David Evans,~Josephine_Lamp1; ~Mark_Derdzinski1; ~Christopher_Hannemann1; ~Joost_Van_der_Linden1; ~Lu_Feng4; ~Tianhao_Wang3; ~David_Evans1,"{'value': ['Synthetic Data', 'Time Series', 'Generative Adversarial Networks', 'Differential Privacy', 'Glucose', 'Diabetes']}","{'value': 'We focus on the problem of generating high-quality, private synthetic glucose traces, a task generalizable to many other time series sources. Existing methods for time series data synthesis, such as those using Generative Adversarial Networks (GANs), are not able to capture the innate characteristics of glucose data and cannot provide any formal privacy guarantees without severely degrading the utility of the synthetic data. In this paper we present GlucoSynth, a novel privacy-preserving GAN framework to generate synthetic glucose traces. The core intuition behind our approach is to conserve relationships amongst motifs (glucose events) within the traces, in addition to temporal dynamics. Our framework incorporates differential privacy mechanisms to provide strong formal privacy guarantees. We provide a comprehensive evaluation on the real-world utility of the data using 1.2 million glucose traces; GlucoSynth outperforms all previous methods in its ability to generate high-quality synthetic glucose traces with strong privacy guarantees.'}",https://openreview.net{'value': '/pdf/bd9e53790e27750dfee5e323173ce828207ac0b4.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Eq9AFZlAjt,{'value': 'Unbounded Differentially Private Quantile and Maximum Estimation'},David Durfee,~David_Durfee1,"{'value': ['Differential privacy', 'Theory', 'Spars Vector Technique', 'Quantile']}","{'value': 'In this work we consider the problem of differentially private computation of\nquantiles for the data, especially the highest quantiles such as maximum, but\nwith an unbounded range for the dataset. We show that this can be done\nefficiently through a simple invocation of $\\texttt{AboveThreshold}$, a\nsubroutine that is iteratively called in the fundamental Sparse Vector\nTechnique, even when there is no upper bound on the data. In particular, we\nshow that this procedure can give more accurate and robust estimates on the\nhighest quantiles with applications towards clipping that is essential for\ndifferentially private sum and mean estimation. In addition, we show how two\ninvocations can handle the fully unbounded data setting. Within our study, we\nshow that an improved analysis of $\\texttt{AboveThreshold}$ can improve the\nprivacy guarantees for the widely used Sparse Vector Technique that is of\nindependent interest. We give a more general characterization of privacy loss\nfor $\\texttt{AboveThreshold}$ which we immediately apply to our method for\nimproved privacy guarantees. Our algorithm only requires one $O(n)$ pass\nthrough the data, which can be unsorted, and each subsequent query takes $O(1)$\ntime. We empirically compare our unbounded algorithm with the state-of-the-art\nalgorithms in the bounded setting. For inner quantiles, we find that our method\noften performs better on non-synthetic datasets. For the maximal quantiles,\nwhich we apply to differentially private sum computation, we find that our\nmethod performs significantly better.'}",https://openreview.net{'value': '/pdf/c96f3eec153b1b399f515431d364c1b408c77271.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=EGfYnTyEGv,{'value': 'A Long $N$-step Surrogate Stage Reward for Deep Reinforcement Learning'},Junmin Zhong; Ruofan Wu; Jennie Si,~Junmin_Zhong1; ~Ruofan_Wu3; ~Jennie_Si1,"{'value': ['Deep reinforcement learning', 'Reward Estimation']}","{'value': 'We introduce a new stage reward estimator  named the long $N$-step surrogate stage (LNSS) reward for deep reinforcement learning (RL). It aims at mitigating the high variance problem, which has shown impeding successful convergence of learning, hurting task performance, and hindering applications of deep RL in continuous control problems. In this paper we show that LNSS, which utilizes a long reward trajectory of  rewards of future steps, provides consistent performance improvement measured by average reward, convergence speed, learning success rate,and variance reduction in $Q$ values and rewards.  Our evaluations are based on a variety of environments in DeepMind Control Suite and OpenAI Gym  by using  LNSS in baseline deep RL algorithms such as DDPG, D4PG, and TD3. We show  that LNSS reward has enabled good results that have been challenging to obtain by deep RL previously. Our analysis also shows that  LNSS exponentially reduces the upper bound on the variances of $Q$ values from respective single-step methods.'}",https://openreview.net{'value': '/pdf/0aebd89db1d578e90ec4158426291802ee6d6e19.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=E3ZUEaeFYS,{'value': 'Strategic Distribution Shift of Interacting Agents via Coupled Gradient Flows'},Lauren E Conger; Franca Hoffman; Eric Mazumdar; Lillian J Ratliff,~Lauren_E_Conger1; franca.hoffmann@caltech.edu; ~Eric_Mazumdar1; ~Lillian_J_Ratliff1,"{'value': ['distribution shift', 'partial differential equations']}","{'value': 'We propose a novel framework for analyzing the dynamics of distribution shift in real-world systems that captures the feedback loop between learning algorithms and the distributions on which they are deployed. Prior work largely models feedback-induced distribution shift as adversarial or via an overly simplistic distribution-shift structure. In contrast, we propose a coupled partial differential equation model that captures fine-grained changes in the distribution over time by accounting for complex dynamics that arise due to strategic responses to algorithmic decision-making, non-local endogenous population interactions, and other exogenous sources of distribution shift. We consider two common settings in machine learning: cooperative settings with information asymmetries, and competitive settings where a learner faces strategic users. For both of these settings, when the algorithm retrains via gradient descent, we prove asymptotic convergence of the retraining procedure to a steady-state, both in finite and in infinite dimensions, obtaining explicit rates in terms of the model parameters. To do so we derive new results on the convergence of coupled PDEs that extends what is known on multi-species systems. Empirically, we show that our approach captures well-documented forms of distribution shifts like polarization and disparate impacts that simpler models cannot capture.'}",https://openreview.net{'value': '/pdf/d8b21f397109ee8ecb2da3cd833c35d27b603db7.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=E2zoGTkTbW,{'value': 'Reward Imputation with Sketching for Contextual Batched Bandits'},Xiao Zhang; Ninglu Shao; Zihua Si; Jun Xu; Wenhan Wang; Hanjing Su; Ji-Rong Wen,~Xiao_Zhang7; ~Ninglu_Shao1; ~Zihua_Si1; ~Jun_Xu1; ~Wenhan_Wang3; ~Hanjing_Su2; ~Ji-Rong_Wen1,"{'value': ['batched bandit', 'sketching', 'reward imputation', 'regret bound', 'ridge regression']}","{'value': 'Contextual batched bandit (CBB) is a setting where a batch of rewards is observed from the environment at the end of each episode, but the rewards of the non-executed actions are unobserved, resulting in partial-information feedback. Existing approaches for CBB often ignore the rewards of the non-executed actions, leading to underutilization of feedback information. In this paper, we propose an efficient approach called Sketched Policy Updating with Imputed Rewards (SPUIR) that completes the unobserved rewards using sketching, which approximates the full-information feedbacks. We formulate reward imputation as an imputation regularized ridge regression problem that captures the feedback mechanisms of both executed and non-executed actions. To reduce time complexity, we solve the regression problem using randomized sketching. We prove that our approach achieves an instantaneous regret with controllable bias and smaller variance than approaches without reward imputation. Furthermore, our approach enjoys a sublinear regret bound against the optimal policy. We also present two extensions, a rate-scheduled version and a version for nonlinear rewards, making our approach more practical. Experimental results show that SPUIR outperforms state-of-the-art baselines on synthetic, public benchmark, and real-world datasets.'}",https://openreview.net{'value': '/pdf/56f77e16ec737b93d54c689d992803405f29cb6e.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=DpuphOgJqh,{'value': 'Selectively Sharing Experiences Improves Multi-Agent Reinforcement Learning'},Matthias Gerstgrasser; Tom Danino; Sarah Keren,~Matthias_Gerstgrasser1; ~Tom_Danino1; ~Sarah_Keren1,"{'value': ['multi-agent reinforcement learning', 'reinforcement learning', 'deep q learning', 'cooperative ai']}","{'value': 'We present a novel multi-agent RL approach, Selective Multi-Agent Prioritized Experience Relay, in which agents share with other agents a limited number of transitions they observe during training. The intuition behind this is that even a small number of relevant experiences from other agents could help each agent learn. Unlike many other multi-agent RL algorithms, this approach allows for largely decentralized training, requiring only a limited communication channel between agents. We show that our approach outperforms baseline no-sharing decentralized training and state-of-the art multi-agent RL algorithms. Further, sharing only a small number of highly relevant experiences outperforms sharing all experiences between agents, and the performance uplift from selective experience sharing is robust across a range of hyperparameters and DQN variants.'}",https://openreview.net{'value': '/pdf/ea8e2f6e47715bbf8846ac24f2da9d20cab0e397.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Deb1yP1zMN,{'value': 'Automatic Integration for Spatiotemporal Neural Point Processes'},Zihao Zhou; Rose Yu,~Zihao_Zhou1; ~Rose_Yu1,"{'value': ['spatiotemporal modeling', 'neural point processes', 'integration method']}","{'value': 'Learning continuous-time point processes is essential to many discrete event forecasting tasks. However, integration poses a major challenge, particularly for spatiotemporal point processes (STPPs), as it involves calculating the likelihood through triple integrals over space and time. Existing methods for integrating STPP either assume a parametric form of the intensity function, which lacks flexibility; or approximating the intensity with Monte Carlo sampling, which introduces numerical errors. Recent work by Omi et al. proposes a dual network approach for efficient integration of flexible intensity function. However, their method only focuses on the 1D temporal point process. In this paper, we introduce a novel paradigm: `Auto-STPP` (Automatic Integration for Spatiotemporal Neural Point Processes) that extends the dual network approach to 3D STPP. While previous work provides a foundation, its direct extension overly restricts the intensity function and leads to computational challenges. In response, we introduce a decomposable parametrization for the integral network using ProdNet. This approach, leveraging the product of simplified univariate graphs, effectively sidesteps the computational complexities inherent in multivariate computational graphs. We prove the consistency of `Auto-STPP` and validate it on synthetic data and benchmark real-world datasets. `Auto-STPP` shows a significant advantage in recovering complex intensity functions from irregular spatiotemporal events, particularly when the intensity is sharply localized. Our code is open-source at https://github.com/Rose-STL-Lab/AutoSTPP.'}",https://openreview.net{'value': '/pdf/bef569982e1f76af2946dc7765375af2b5001812.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Dbaxm9ujq6,{'value': 'How2comm: Communication-Efficient and Collaboration-Pragmatic Multi-Agent Perception'},Dingkang Yang; Kun Yang; Yuzheng Wang; Jing Liu; Zhi Xu; Rongbin Yin; Peng Zhai; Lihua Zhang,~Dingkang_Yang1; ~Kun_Yang5; ~Yuzheng_Wang1; ~Jing_Liu14; ~Zhi_Xu3; ~Rongbin_Yin1; ~Peng_Zhai1; ~Lihua_Zhang1,"{'value': ['Collaborative perception', 'multi-agent communication']}","{'value': 'Multi-agent collaborative perception has recently received widespread attention as an emerging application in driving scenarios. Despite the advancements in previous efforts, challenges remain due to various noises in the perception procedure, including communication redundancy, transmission delay, and collaboration heterogeneity. To tackle these issues, we propose \\textit{How2comm}, a collaborative perception framework that seeks a trade-off between perception performance and communication bandwidth. Our novelties lie in three aspects. First, we devise a mutual information-aware communication mechanism to maximally sustain the informative features shared by collaborators. The spatial-channel filtering is adopted to perform effective feature sparsification for efficient communication. Second, we present a flow-guided delay compensation strategy to predict future characteristics from collaborators and eliminate feature misalignment due to temporal asynchrony. Ultimately, a pragmatic collaboration transformer is introduced to integrate holistic spatial semantics and temporal context clues among agents. Our framework is thoroughly evaluated on several LiDAR-based collaborative detection datasets in real-world and simulated scenarios. Comprehensive experiments demonstrate the superiority of How2comm and the effectiveness of all its vital components. The code will be released at https://github.com/ydk122024/How2comm.'}",https://openreview.net{'value': '/pdf/7b21bfe4e91fae6f28ee7da63566386896847687.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=DVjyq5eCAD,{'value': 'Chasing Fairness Under Distribution Shift: A Model Weight Perturbation Approach'},Zhimeng Jiang; Xiaotian Han; Hongye Jin; Guanchu Wang; Rui Chen; Na Zou; Xia Hu,~Zhimeng_Jiang1; ~Xiaotian_Han1; ~Hongye_Jin1; ~Guanchu_Wang1; ~Rui_Chen4; ~Na_Zou2; ~Xia_Hu4,"{'value': ['Model Weight Perturbation', 'fairness', 'distribution shift']}","{'value': 'Fairness in machine learning has attracted increasing attention in recent years. The fairness methods improving algorithmic fairness for in-distribution data may not perform well under distribution shifts. In this paper, we first theoretically demonstrate the inherent connection between distribution shift,  data perturbation, and model weight perturbation.\nSubsequently, we analyze the sufficient conditions to guarantee fairness (i.e., low demographic parity) for the target dataset, including fairness for the source dataset, and low prediction difference between the source and target datasets for each sensitive attribute group. Motivated by these sufficient conditions, we propose robust fairness regularization (RFR) by considering the worst case within the model weight perturbation ball for each sensitive attribute group. We evaluate the effectiveness of our proposed RFR algorithm on synthetic and real distribution shifts across various datasets. Experimental results demonstrate that RFR achieves better fairness-accuracy trade-off performance compared with several baselines. The source code is available at \\url{https://github.com/zhimengj0326/RFR_NeurIPS23}.'}",https://openreview.net{'value': '/pdf/3dcae620954418c5fb70f4599f677e1a1d66d77c.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=DP2lioYIYl,{'value': 'A Theory of Unsupervised Translation Motivated by Understanding Animal Communication'},Shafi Goldwasser; David Gruber; Adam Tauman Kalai; Orr Paradise,~Shafi_Goldwasser2; ~David_Gruber1; ~Adam_Tauman_Kalai1; ~Orr_Paradise1,"{'value': ['Theory', 'Unsupervised Machine Translation']}","{'value': 'Neural networks are capable of translating between languages—in some cases even between two languages where there is little or no access to parallel translations, in what is known as Unsupervised Machine Translation (UMT). Given this progress, it is intriguing to ask whether machine learning tools can ultimately enable understanding animal communication, particularly that of highly intelligent\nanimals. We propose a theoretical framework for analyzing UMT when no parallel translations are available and when it cannot be assumed that the source and target corpora address related subject domains or posses similar linguistic structure. We\nexemplify this theory with two stylized models of language, for which our framework provides bounds on necessary sample complexity; the bounds are formally proven and experimentally verified on synthetic data. These bounds show that the error rates are inversely related to the language complexity and amount of common ground. This suggests that unsupervised translation of animal communication may be feasible if the communication system is sufficiently complex.'}",https://openreview.net{'value': '/pdf/fb6a03e50308a9fd851987952a9fd33fe73956f2.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=DNHGKeOhLl,{'value': 'On the Stability-Plasticity Dilemma in Continual Meta-Learning: Theory and Algorithm'},Qi CHEN; Changjian Shui; Ligong Han; Mario Marchand,~Qi_CHEN6; ~Changjian_Shui2; ~Ligong_Han1; ~Mario_Marchand1,{'value': ['continual meta-learning; transfer learning; stability-plasticity dilemma;']},"{'value': 'We focus on Continual Meta-Learning (CML), which targets accumulating and exploiting meta-knowledge on a sequence of non-i.i.d. tasks. The primary challenge is to strike a balance between stability and plasticity, where a model should be stable to avoid catastrophic forgetting in previous tasks and plastic to learn generalizable concepts from new tasks. To address this, we formulate the CML objective as controlling the average excess risk upper bound of the task sequence, which reflects the trade-off between forgetting and generalization. Based on the objective, we introduce a unified theoretical framework for CML in both static and shifting environments, providing guarantees for various task-specific learning algorithms. Moreover, we first present a rigorous analysis of a bi-level trade-off in shifting environments. To approach the optimal trade-off, we propose a novel algorithm that dynamically adjusts the meta-parameter and its learning rate w.r.t environment change. Empirical evaluations on synthetic and real datasets illustrate the effectiveness of the proposed theory and algorithm.'}",https://openreview.net{'value': '/pdf/0ee9a8d9cb4e5d5580b8cb655f610575ec1f7e7e.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=DEiNSfh1k7,{'value': 'DreamSim: Learning New Dimensions of Human Visual Similarity using Synthetic Data'},Stephanie Fu; Netanel Yakir Tamir; Shobhita Sundaram; Lucy Chai; Richard Zhang; Tali Dekel; Phillip Isola,~Stephanie_Fu1; ~Netanel_Yakir_Tamir1; ~Shobhita_Sundaram1; ~Lucy_Chai1; ~Richard_Zhang1; ~Tali_Dekel1; ~Phillip_Isola1,"{'value': ['perceptual similarity', 'foundation model', 'perception', 'computer vision', 'image metric']}","{'value': 'Current perceptual similarity metrics operate at the level of pixels and patches. These metrics compare images in terms of their low-level colors and textures, but fail to capture mid-level similarities and differences in image layout, object pose, and semantic content. In this paper, we develop a perceptual metric that assesses images holistically. Our first step is to collect a new dataset of human similarity judgments over image pairs that are alike in diverse ways. Critical to this dataset is that judgments are nearly automatic and shared by all observers. To achieve this we use recent text-to-image models to create synthetic pairs that are perturbed along various dimensions. We observe that popular perceptual metrics fall short of explaining our new data, and we introduce a new metric, DreamSim, tuned to better align with human perception. We analyze how our metric is affected by different visual attributes, and find that it focuses heavily on foreground objects and semantic content while also being sensitive to color and layout. Notably, despite being trained on synthetic data, our metric generalizes to real images, giving strong results on retrieval and reconstruction tasks. Furthermore, our metric outperforms both prior learned metrics and recent large vision models on these tasks. Our project page: https://dreamsim-nights.github.io/'}",https://openreview.net{'value': '/pdf/fb6714a8a4a6c793c072c37b2991b8f8b983fd3e.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=DEC7NxDJLh,{'value': 'Coupled Reconstruction of Cortical Surfaces by Diffeomorphic Mesh Deformation'},Hao Zheng; Hongming Li; Yong Fan,~Hao_Zheng1; ~Hongming_Li1; yong.fan@pennmedicine.upenn.edu,"{'value': ['Brain MRIs', 'cortical surface reconstruction', 'deep learning']}","{'value': ""Accurate reconstruction of cortical surfaces from brain magnetic resonance images (MRIs) remains a challenging task due to the notorious partial volume effect in brain MRIs and the cerebral cortex's thin and highly folded patterns. Although many promising deep learning-based cortical surface reconstruction methods have been developed, they typically fail to model the interdependence between inner (white matter) and outer (pial) cortical surfaces, which can help generate cortical surfaces with spherical topology. To robustly reconstruct the cortical surfaces with topological correctness, we develop a new deep learning framework to jointly reconstruct the inner, outer, and their in-between (midthickness) surfaces and estimate cortical thickness directly from 3D MRIs. Our method first estimates the midthickness surface and then learns three diffeomorphic flows jointly to optimize the midthickness surface and deform it inward and outward to the inner and outer cortical surfaces respectively, regularized by topological correctness. Our method also outputs a cortex thickness value for each surface vertex, estimated from its diffeomorphic deformation trajectory. Our method has been evaluated on two large-scale neuroimaging datasets, including ADNI and OASIS, achieving state-of-the-art cortical surface reconstruction performance in terms of accuracy, surface regularity, and computation efficiency.""}",https://openreview.net{'value': '/pdf/3276a92606efb35455dd1359ba3dff704fe85325.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=D9CMRR5Lof,{'value': 'MGDD: A Meta Generator for Fast Dataset Distillation'},Songhua Liu; Xinchao Wang,~Songhua_Liu2; ~Xinchao_Wang1,"{'value': ['Dataset Distillation', 'Dataset Condensation', 'Efficient Learning', 'Conditional Generation', 'Meta Learning']}","{'value': 'Existing dataset distillation (DD) techniques typically rely on iterative strategies to synthesize condensed datasets, where datasets before and after distillation are forward and backward through neural networks a massive number of times. Despite the promising results achieved, the time efficiency of prior approaches is still far from satisfactory. Moreover, when different sizes of synthetic datasets are required, they have to repeat the iterative training procedures, which is highly cumbersome and lacks flexibility. In this paper, different from the time-consuming forward-backward passes, we introduce a generative fashion for dataset distillation with significantly improved efficiency. Specifically, synthetic samples are produced by a generator network conditioned on the initialization of DD, while synthetic labels are obtained by solving a least-squares problem in a feature space. Our theoretical analysis reveals that the errors of synthetic datasets solved in the original space and then processed by any conditional generators are upper-bounded. To find a satisfactory generator efficiently, we propose a meta-learning algorithm, where a meta generator is trained on a large dataset so that only a few steps are required to adapt to a target dataset. The meta generator is termed as MGDD in our approach. Once adapted, it can handle arbitrary sizes of synthetic datasets, even for those unseen during adaptation. Experiments demonstrate that the generator adapted with only a limited number of steps performs on par with those state-of-the-art DD methods and yields $22\\times$ acceleration.'}",https://openreview.net{'value': '/pdf/849d39ff55c93d69c6d22cec9029c711811ac957.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=CtXXOaxDw7,{'value': 'V-InFoR: A Robust Graph Neural Networks Explainer for Structurally Corrupted Graphs'},Senzhang Wang; Jun Yin; Chaozhuo Li; Xing Xie; Jianxin Wang,~Senzhang_Wang2; ~Jun_Yin11; ~Chaozhuo_Li1; ~Xing_Xie3; ~Jianxin_Wang1,"{'value': ['Explainable AI', 'Graph Neural Networks', 'Machine Learning']}","{'value': 'GNN explanation method aims to identify an explanatory subgraph which contains the most informative components of the full graph. However, a major limitation of existing GNN explainers is that they are not robust to the structurally corrupted graphs, e.g., graphs with noisy or adversarial edges. On the one hand, existing GNN explainers mostly explore explanations based on either the raw graph features or the learned latent representations, both of which can be easily corrupted. On the other hand, the corruptions in graphs are irregular in terms of the structural properties, e.g., the size or connectivity of graphs, which makes the rigorous constraints used by previous GNN explainers unfeasible. To address these issues, we propose a robust GNN explainer called V-InfoR. Specifically, a robust graph representation extractor, which takes insights of variational inference, is proposed to infer the latent distribution of graph representations. Instead of directly using the corrupted raw features or representations of each single graph, we sample the graph representations from the inferred distribution for the downstream explanation generator, which can effectively eliminate the minor corruption. We next formulate the explanation exploration as a graph information bottleneck (GIB) optimization problem. As a more general method that does not need any rigorous structural constraints, our GIB-based method can adaptively capture both the regularity and irregularity of the severely corrupted graphs for explanation. Extensive evaluations on both synthetic and real-world datasets indicate that V-InfoR significantly improves the GNN explanation performance for the structurally corrupted graphs. Code and dataset are available at https://anonymous.4open.science/r/V-InfoR-EF88'}",https://openreview.net{'value': '/pdf/6cb765be7bec62e9561b541650364dbb097f074d.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=CruxS0C0LS,{'value': 'Finding Local Minima Efficiently in Decentralized Optimization'},Wenhan Xian; Heng Huang,~Wenhan_Xian1; ~Heng_Huang1,"{'value': ['second-order optimality', 'decentralized optimization']}","{'value': 'In this paper we study the second-order optimality of decentralized stochastic algorithm that escapes saddle point efficiently for nonconvex optimization problems. We propose a new pure gradient-based decentralized stochastic algorithm PEDESTAL with a novel convergence analysis framework to address the technical challenges unique to the decentralized stochastic setting. Our method is the first decentralized stochastic algorithm to achieve second-order optimality with non-asymptotic analysis. We provide theoretical guarantees with the gradient complexity of $\\tilde{O} (\\epsilon^{-3})$ to find $O(\\epsilon, \\sqrt{\\epsilon})$-second-order stationary point, which matches state-of-the-art results of centralized counterparts or decentralized methods to find first-order stationary point. We also conduct two decentralized tasks in our experiments, a matrix sensing task with synthetic data and a matrix factorization task with a real-world dataset to validate the performance of our method.'}",https://openreview.net{'value': '/pdf/1ef9c73f0938c60e940df2c61901d2e3c4f77878.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=CniUitfEY3,{'value': 'Reusable Slotwise Mechanisms'},Trang Nguyen; Amin Mansouri; Kanika Madan; Nguyen Duy Khuong; Kartik Ahuja; Dianbo Liu; Yoshua Bengio,~Trang_Nguyen1; ~Amin_Mansouri1; ~Kanika_Madan3; ~Nguyen_Duy_Khuong1; ~Kartik_Ahuja1; ~Dianbo_Liu2; ~Yoshua_Bengio1,"{'value': ['Out-of-Distribution Generalization', 'Slotwise', 'Visual Reasoning', 'Video Prediction', 'Reusable Mechanism', 'Dynamics modeling']}","{'value': 'Agents with the ability to comprehend and reason about the dynamics of objects would be expected to exhibit improved robustness and generalization in novel scenarios. However, achieving this capability necessitates not only an effective scene representation but also an understanding of the mechanisms governing interactions among object subsets. Recent studies have made significant progress in representing scenes using object slots. In this work, we introduce Reusable Slotwise Mechanisms, or RSM, a framework that models object dynamics by leveraging communication among slots along with a modular architecture capable of dynamically selecting reusable mechanisms for predicting the future states of each object slot. Crucially, RSM leverages the Central Contextual Information (CCI), enabling selected mechanisms to access the remaining slots through a bottleneck, effectively allowing for modeling of higher order and complex interactions that might require a sparse subset of objects. Experimental results demonstrate the superior performance of RSM compared to state-of-the-art methods across various future prediction and related downstream tasks, including Visual Question Answering and action planning. Furthermore, we showcase RSM’s Out-of-Distribution generalization ability to handle scenes in intricate scenarios.'}",https://openreview.net{'value': '/pdf/1b2980d66ac506d8fa9ca1ccbc3906979e450f09.pdf'},{'abstract_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Cc2fjBBlBD,{'value': 'Spuriosity Didn’t Kill the Classifier: Using Invariant Predictions to Harness Spurious Features'},Cian Eastwood; Shashank Singh; Andrei Liviu Nicolicioiu; Marin Vlastelica; Julius von Kügelgen; Bernhard Schölkopf,~Cian_Eastwood1; ~Shashank_Singh1; ~Andrei_Liviu_Nicolicioiu1; ~Marin_Vlastelica1; ~Julius_von_Kügelgen2; ~Bernhard_Schölkopf1,"{'value': ['invariant prediction', 'spurious correlations', 'out-of-distribution generalization', 'domain generalization', 'domain adaptation', 'test-time domain adaptation']}","{'value': 'To avoid failures on out-of-distribution data, recent works have sought to extract features that have an invariant or stable relationship with the label across domains, discarding ""spurious"" or unstable features whose relationship with the label changes across domains. However, unstable features often carry complementary information that could boost performance if used correctly in the test domain. In this work, we show how this can be done without test-domain labels. In particular, we prove that pseudo-labels based on stable features provide sufficient guidance for doing so, provided that stable and unstable features are conditionally independent given the label. Based on this theoretical insight, we propose Stable Feature Boosting (SFB), an algorithm for: (i) learning a predictor that separates stable and conditionally-independent unstable features; and (ii) using the stable-feature predictions to adapt the unstable-feature predictions in the test domain. Theoretically, we prove that SFB can learn an asymptotically-optimal predictor without test-domain labels. Empirically, we demonstrate the effectiveness of SFB on real and synthetic data.'}",https://openreview.net{'value': '/pdf/2e9da61f3c6b4f8ccc80f819ffe98b4098c1049f.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=CYCzfXn6cZ,{'value': 'Survival Permanental Processes for Survival Analysis with Time-Varying Covariates'},Hideaki Kim,~Hideaki_Kim1,"{'value': ['survival analysis', 'temporal point process', 'Bayesian estimation', 'permanental process', 'representer theorem', 'kernel method']}","{'value': 'Survival or time-to-event data with time-varying covariates are common in practice, and exploring the non-stationarity in covariates is essential to accurately analyzing the nonlinear dependence of time-to-event outcomes on covariates. Traditional survival analysis methods such as Cox proportional hazards model have been extended to address the time-varying covariates through a counting process formulation, although sophisticated machine learning methods that can accommodate time-varying covariates have been limited. In this paper, we propose a non-parametric Bayesian survival model to analyze the nonlinear dependence of time-to-event outcomes on time-varying covariates. We focus on a computationally feasible Cox process called permanental process, which assumes the square root of hazard function to be generated from a Gaussian process, and tailor it for survival data with time-varying covariates. We verify that the proposed model holds with the representer theorem, a beneficial property for functional analysis, which offers us a fast Bayesian estimation algorithm that scales linearly with the number of observed events without relying on Markov Chain Monte Carlo computation. We evaluate our algorithm on synthetic and real-world data, and show that it achieves comparable predictive accuracy while being tens to hundreds of times faster than state-of-the-art methods.'}",https://openreview.net{'value': '/pdf/c2708659783388032de7ea87f606ffa08262f280.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=CQuRzAgjg9,{'value': 'Online Clustering of Bandits with Misspecified User Models'},Zhiyong Wang; Jize Xie; Xutong Liu; Shuai Li; John C.S. Lui,~Zhiyong_Wang9; ~Jize_Xie1; ~Xutong_Liu1; ~Shuai_Li3; ~John_C.S._Lui2,{'value': ['online clustering of bandits']},"{'value': 'The contextual linear bandit is an important online learning problem where given arm features, a learning agent selects an arm at each round to maximize the cumulative rewards in the long run. A line of works, called the clustering of bandits (CB), utilize the collaborative effect over user preferences and have shown significant improvements over classic linear bandit algorithms. However, existing CB algorithms require well-specified linear user models and can fail when this critical assumption does not hold. Whether robust CB algorithms can be designed for more practical scenarios with misspecified user models remains an open problem. In this paper, we are the first to present the important problem of clustering of bandits with misspecified user models (CBMUM), where the expected rewards in user models can be perturbed away from perfect linear models. We devise two robust CB algorithms, RCLUMB and RSCLUMB (representing the learned clustering structure with dynamic graph and sets, respectively), that can accommodate the inaccurate user preference estimations and erroneous clustering caused by model misspecifications. We prove regret upper bounds of $O(\\epsilon_*T\\sqrt{md\\log T}  + d\\sqrt{mT}\\log T)$ for our algorithms under milder assumptions than previous CB works, which match the lower bound asymptotically in $T$ up to logarithmic factors, and also match the state-of-the-art results in several degenerate cases. Our regret analysis is novel and different from the typical proof flow of previous CB works. The techniques in proving the regret caused by misclustering users are quite general and may be of independent interest. Experiments on both synthetic and real-world data show our outperformance over previous algorithms.'}",https://openreview.net{'value': '/pdf/88b50fc1b7f51999a78150d0d40d1e3587c2bcf0.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=CGj72TyGJy,{'value': 'Automatic Grouping for Efficient Cooperative Multi-Agent Reinforcement Learning'},Yifan Zang; Jinmin He; Kai Li; Haobo Fu; QIANG FU; Junliang Xing; Jian Cheng,~Yifan_Zang1; ~Jinmin_He1; ~Kai_Li2; ~Haobo_Fu2; ~QIANG_FU8; ~Junliang_Xing1; ~Jian_Cheng7,"{'value': ['MARL', 'Cooperative Multi-Agent Reinforcement Learning', 'Coordination and Cooperation', 'Automatic Grouping', 'Group-Wise Learning']}","{'value': ""Grouping is ubiquitous in natural systems and is essential for promoting efficiency in team coordination. This paper proposes a novel formulation of Group-oriented Multi-Agent Reinforcement Learning (GoMARL), which learns automatic grouping without domain knowledge for efficient cooperation. In contrast to existing approaches that attempt to directly learn the complex relationship between the joint action-values and individual utilities, we empower subgroups as a bridge to model the connection between small sets of agents and encourage cooperation among them, thereby improving the learning efficiency of the whole team. In particular, we factorize the joint action-values as a combination of group-wise values, which guide agents to improve their policies in a fine-grained fashion. We present an automatic grouping mechanism to generate dynamic groups and group action-values. We further introduce a hierarchical control for policy learning that drives the agents in the same group to specialize in similar policies and possess diverse strategies for various groups. Experiments on the StarCraft II micromanagement tasks and Google Research Football scenarios verify our method's effectiveness. Extensive component studies show how grouping works and enhances performance.""}",https://openreview.net{'value': '/pdf/b8a6bee77fa99b8947f0961b591c27abd6b6bb1c.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=C9cgwmJ8Pt,{'value': 'Fast Projected Newton-like Method for Precision Matrix Estimation under Total Positivity'},Jian-Feng CAI; José Vinícius De Miranda Cardoso; Daniel P. Palomar; Jiaxi Ying,~Jian-Feng_CAI1; ~José_Vinícius_De_Miranda_Cardoso1; ~Daniel_P._Palomar1; ~Jiaxi_Ying1,"{'value': ['MTP2', 'Total Positivity', 'Generalized graph Laplacian', 'Precision matrix estimation', 'Nonnegative partial correlations']}","{'value': 'We study the problem of estimating precision matrices in Gaussian distributions that are multivariate totally positive of order two ($\\mathrm{MTP}_2$). The precision matrix in such a distribution is an M-matrix. This problem can be formulated as a sign-constrained log-determinant program. Current algorithms are designed using the block coordinate descent method or the proximal point algorithm, which becomes computationally challenging in high-dimensional cases due to the requirement to solve numerous nonnegative quadratic programs or large-scale linear systems. To address this issue, we propose a novel algorithm based on the two-metric projection method, incorporating a carefully designed search direction and variable partitioning scheme. Our algorithm substantially reduces computational complexity, and its theoretical convergence is established. Experimental results on synthetic and real-world datasets demonstrate that our proposed algorithm provides a significant improvement in computational efficiency compared to the state-of-the-art methods.'}",https://openreview.net{'value': '/pdf/6845ab79f422b338aacde388c2d0eb106633f1d6.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=C8pvL8Qbfa,{'value': 'Conservative Offline Policy Adaptation in Multi-Agent Games'},Chengjie Wu; Pingzhong Tang; Jun Yang; Yujing Hu; Tangjie Lv; Changjie Fan; Chongjie Zhang,~Chengjie_Wu1; ~Pingzhong_Tang1; ~Jun_Yang6; ~Yujing_Hu2; ~Tangjie_Lv1; ~Changjie_Fan1; ~Chongjie_Zhang1,"{'value': ['reinforcement learning', 'opponent exploitation', 'multi-agent']}","{'value': 'Prior research on policy adaptation in multi-agent games has often relied on online interaction with the target agent in training, which can be expensive and impractical in real-world scenarios. Inspired by recent progress in offline reinforcement learn- ing, this paper studies offline policy adaptation, which aims to utilize the target agent’s behavior data to exploit its weakness or enable effective cooperation. We investigate its distinct challenges of distributional shift and risk-free deviation, and propose a novel learning objective, conservative offline adaptation, that optimizes the worst-case performance against any dataset consistent proxy models. We pro- pose an efficient algorithm called Constrained Self-Play (CSP) that incorporates dataset information into regularized policy learning. We prove that CSP learns a near-optimal risk-free offline adaptation policy upon convergence. Empirical results demonstrate that CSP outperforms non-conservative baselines in various environments, including Maze, predator-prey, MuJoCo, and Google Football.'}",https://openreview.net{'value': '/pdf/b7f33f5b4e401a1e19d7abd347b3d83b37583edc.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=BdvCo8RVlx,{'value': 'The Contextual Lasso: Sparse Linear Models via Deep Neural Networks'},Ryan Thompson; Amir Dezfouli; Robert Kohn,~Ryan_Thompson1; ~Amir_Dezfouli2; ~Robert_Kohn1,"{'value': ['feature selection', 'sparsity', 'sparse regression', 'varying coefficients', 'deep learning']}","{'value': ""Sparse linear models are one of several core tools for interpretable machine learning, a field of emerging importance as predictive models permeate decision-making in many domains. Unfortunately, sparse linear models are far less flexible as functions of their input features than black-box models like deep neural networks. With this capability gap in mind, we study a not-uncommon situation where the input features dichotomize into two groups: explanatory features, which are candidates for inclusion as variables in an interpretable model, and contextual features, which select from the candidate variables and determine their effects. This dichotomy leads us to the contextual lasso, a new statistical estimator that fits a sparse linear model to the explanatory features such that the sparsity pattern and coefficients vary as a function of the contextual features. The fitting process learns this function nonparametrically via a deep neural network. To attain sparse coefficients, we train the network with a novel lasso regularizer in the form of a projection layer that maps the network's output onto the space of $\\ell_1$-constrained linear models. An extensive suite of experiments on real and synthetic data suggests that the learned models, which remain highly transparent, can be sparser than the regular lasso without sacrificing the predictive power of a standard deep neural network.""}",https://openreview.net{'value': '/pdf/84de3974738264bc47f2eeca4ca075518d4bbe10.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=BXQtgwA2n0,{'value': 'Offline Multi-Agent Reinforcement Learning with Implicit Global-to-Local Value Regularization'},Xiangsen Wang; Haoran Xu; Yinan Zheng; Xianyuan Zhan,~Xiangsen_Wang1; ~Haoran_Xu4; ~Yinan_Zheng1; ~Xianyuan_Zhan1,{'value': ['Offline reinforcement learning; multi-agent reinforcement learning; multi-agent cooperation']},"{'value': 'Offline reinforcement learning (RL) has received considerable attention in recent years due to its attractive capability of learning policies from offline datasets without environmental interactions. Despite some success in the single-agent setting, offline multi-agent RL (MARL) remains to be a challenge. The large joint state-action space and the coupled multi-agent behaviors pose extra complexities for offline policy optimization. Most existing offline MARL studies simply apply offline data-related regularizations on individual agents, without fully considering the multi-agent system at the global level. In this work, we present OMIGA, a new offline multi-agent RL algorithm with implicit global-to-local value regularization. OMIGA provides a principled framework to convert global-level value regularization into equivalent implicit local value regularizations and simultaneously enables in-sample learning, thus elegantly bridging multi-agent value decomposition and policy learning with offline regularizations. Based on comprehensive experiments on the offline multi-agent MuJoCo and StarCraft II micro-management tasks, we show that OMIGA achieves superior performance over the state-of-the-art offline MARL methods in almost all tasks.'}",https://openreview.net{'value': '/pdf/3dd2ab8d5f8e3728056cfa396f22b3c975c7ca75.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=BRqlkTDvvm,{'value': 'BQ-NCO: Bisimulation Quotienting for Efficient Neural Combinatorial Optimization'},Darko Drakulic; Sofia Michel; Florian Mai; Arnaud Sors; Jean-Marc Andreoli,~Darko_Drakulic1; ~Sofia_Michel1; ~Florian_Mai1; ~Arnaud_Sors1; ~Jean-Marc_Andreoli2,"{'value': ['Combinatorial Optimization', 'Markov Decision Processes', 'Bisimulation', 'Policy Learning', 'Out-of-Distribution Generalization', 'Routing Problems', 'TSP', 'CVRP', 'KP.']}","{'value': 'Despite the success of neural-based combinatorial optimization methods for end-to-end heuristic learning, out-of-distribution generalization remains a challenge. In this paper, we present a novel formulation of Combinatorial Optimization Problems (COPs) as Markov Decision Processes (MDPs) that effectively leverages common symmetries of COPs to improve out-of-distribution robustness. Starting from a direct MDP formulation of a constructive method, we introduce a generic way to reduce the state space, based on Bisimulation Quotienting (BQ) in MDPs. Then, for COPs with a recursive nature, we specialize the bisimulation and show how the reduced state exploits the symmetries of these problems and facilitates MDP solving. Our approach is principled and we prove that an optimal policy for the proposed BQ-MDP actually solves the associated COPs. We illustrate our approach on five classical problems: the Euclidean and Asymmetric Traveling Salesman, Capacitated Vehicle Routing, Orienteering and Knapsack Problems. Furthermore, for each problem, we introduce a simple attention-based policy network for the BQ-MDPs, which we train by imitation of (near) optimal solutions of small instances from a single distribution. We obtain new state-of-the-art results for the five COPs on both synthetic and realistic benchmarks. Notably, in contrast to most existing neural approaches, our learned policies show excellent generalization performance to much larger instances than seen during training, without any additional search procedure. Our code is available at: [link](https://github.com/naver/bq-nco).'}",https://openreview.net{'value': '/pdf/045708a8ecde38df0562afd292b1fe3ec94019f4.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=BHHrX3CRE1,{'value': 'Regularity as Intrinsic Reward for Free Play'},Cansu Sancaktar; Justus Piater; Georg Martius,~Cansu_Sancaktar1; ~Justus_Piater1; ~Georg_Martius1,"{'value': ['Intrinsic Motivation', 'Reinforcement Learning', 'Model-based Planning', 'Regularity', 'Manipulation', 'Zero-shot Generalization', 'Unsupervised Exploration']}","{'value': 'We propose regularity as a novel reward signal for intrinsically-motivated reinforcement learning. Taking inspiration from child development, we postulate that striving for structure and order helps guide exploration towards a subspace of tasks that are not favored by naive uncertainty-based intrinsic rewards. Our generalized formulation of Regularity as Intrinsic Reward (RaIR) allows us to operationalize it within model-based reinforcement learning. In a synthetic environment, we showcase the plethora of structured patterns that can emerge from pursuing this regularity objective. We also demonstrate the strength of our method in a multi-object robotic manipulation environment. We incorporate RaIR into free play and use it to complement the model’s epistemic uncertainty as an intrinsic reward. Doing so, we witness the autonomous construction of towers and other regular structures during free play, which leads to a substantial improvement in zero-shot downstream task performance on assembly tasks.'}",https://openreview.net{'value': '/pdf/6d14c7affdc950661caf850922e76e6575fcf49b.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=AuXd54odxm,{'value': 'Extraction and Recovery of Spatio-Temporal Structure in Latent Dynamics Alignment with Diffusion Models'},Yule Wang; Zijing Wu; Chengrui Li; Anqi Wu,~Yule_Wang1; ~Zijing_Wu1; ~Chengrui_Li1; ~Anqi_Wu4,"{'value': ['Neural distribution alignment', 'Diffusion model', 'Neuroscience', 'Neural decoding']}","{'value': ""In the field of behavior-related brain computation, it is necessary to align raw neural signals against the drastic domain shift among them. A foundational framework within neuroscience research posits that trial-based neural population activities rely on low-dimensional latent dynamics, thus focusing on the latter greatly facilitates the alignment procedure. Despite this field's progress, existing methods ignore the intrinsic spatio-temporal structure during the alignment phase. Hence, their solutions usually lead to poor quality in latent dynamics structures and overall performance. To tackle this problem, we propose an alignment method ERDiff, which leverages the expressivity of the diffusion model to preserve the spatio-temporal structure of latent dynamics. Specifically, the latent dynamics structures of the source domain are first extracted by a diffusion model. Then, under the guidance of this diffusion model, such structures are well-recovered through a maximum likelihood alignment procedure in the target domain. We first demonstrate the effectiveness of our proposed method on a synthetic dataset. Then, when applied to neural recordings from the non-human primate motor cortex, under both cross-day and inter-subject settings, our method consistently manifests its capability of preserving the spatio-temporal structure of latent dynamics and outperforms existing approaches in alignment goodness-of-fit and neural decoding performance.""}",https://openreview.net{'value': '/pdf/e37f3ea604d1ec090a44790a994d1c32a75a5799.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=AtHJ7TLheF,{'value': 'Calibrate and Boost Logical Expressiveness of GNN Over Multi-Relational and Temporal Graphs'},Dingmin Wang; Yeyuan Chen,~Dingmin_Wang1; ~Yeyuan_Chen1,"{'value': ['Knowledge Graphs', 'First-Order Logic', 'Temporal Knowledge Graph', 'Graph Neural Networks']}","{'value': 'As a powerful framework for graph representation learning, Graph Neural Networks (GNNs) have garnered significant attention in recent years. However, to the best of our knowledge, there has been no formal analysis of the logical expressiveness of GNNs as Boolean node classifiers over multi-relational graphs, where each edge carries a specific relation type. In this paper, we investigate $\\mathcal{FOC}_2$, a fragment of first-order logic with two variables and counting quantifiers. On the negative side, we demonstrate that the R$^2$-GNN architecture, which extends the local message passing GNN by incorporating global readout, fails to capture $\\mathcal{FOC}_2$ classifiers in the general case. Nevertheless, on the positive side, we establish that R$^2$-GNNs models are equivalent to $\\mathcal{FOC}_2$ classifiers under certain restricted yet reasonable scenarios. To address the limitations of R$^2$-GNNs regarding expressiveness, we propose a simple graph transformation technique, akin to a preprocessing step, which can be executed in linear time. This transformation enables R$^2$-GNNs to effectively capture any $\\mathcal{FOC}_2$ classifiers when applied to the ""transformed"" input graph. Moreover, we extend our analysis of expressiveness and graph transformation to temporal graphs, exploring several temporal GNN architectures and providing an expressiveness hierarchy for them. To validate our findings, we implement R$^2$-GNNs and the graph transformation technique and conduct empirical tests in node classification tasks against various well-known GNN architectures that support multi-relational or temporal graphs. Our experimental results consistently demonstrate that R$^2$-GNN with the graph transformation outperforms the baseline methods on both synthetic and real-world datasets'}",https://openreview.net{'value': '/pdf/a315bb296babc05ae062e895f00aa7a9bb49905b.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=AiEipk1X0c,{'value': 'A Deep Instance Generative Framework for MILP Solvers Under Limited Data Availability'},Zijie Geng; Xijun Li; Jie Wang; Xiao Li; Yongdong Zhang; Feng Wu,~Zijie_Geng1; ~Xijun_Li1; ~Jie_Wang1; ~Xiao_Li19; ~Yongdong_Zhang2; ~Feng_Wu1,"{'value': ['Learning to Optimize', 'Machine Learning for Combinatorial Optimization', 'Mixed-Integer Linear Programming', 'Graph Generation']}","{'value': 'In the past few years, there has been an explosive surge in the use of machine learning (ML) techniques to address combinatorial optimization (CO) problems, especially mixed-integer linear programs (MILPs). Despite the achievements, the limited availability of real-world instances often leads to sub-optimal decisions and biased solver assessments, which motivates a suite of synthetic MILP instance generation techniques. However, existing methods either rely heavily on expert-designed formulations or struggle to capture the rich features of real-world instances. To tackle this problem, we propose G2MILP, *the first* deep generative framework for MILP instances. Specifically, G2MILP represents MILP instances as bipartite graphs, and applies a masked variational autoencoder to iteratively corrupt and replace parts of the original graphs to generate new ones. The appealing feature of G2MILP is that it can learn to generate novel and realistic MILP instances without prior expert-designed formulations, while preserving the structures and computational hardness of real-world datasets, simultaneously. Thus the generated instances can facilitate downstream tasks for enhancing MILP solvers under limited data availability. We design a suite of benchmarks to evaluate the quality of the generated MILP instances. Experiments demonstrate that our method can produce instances that closely resemble real-world datasets in terms of both structures and computational hardness. The deliverables are released at [https://miralab-ustc.github.io/L2O-G2MILP](https://miralab-ustc.github.io/L2O-G2MILP).'}",https://openreview.net{'value': '/pdf/f8e13c7bc3b63456194664bbb7c8513b4af9f460.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=AYLlZMmUbo,{'value': 'Two Heads are Better Than One: A Simple Exploration Framework for Efficient Multi-Agent Reinforcement Learning'},Jiahui Li; Kun Kuang; Baoxiang Wang; Xingchen Li; Fei Wu; Jun Xiao; Long Chen,~Jiahui_Li2; ~Kun_Kuang1; ~Baoxiang_Wang1; ~Xingchen_Li1; ~Fei_Wu2; ~Jun_Xiao1; ~Long_Chen8,"{'value': ['multi-agent reinforcement learning', 'influence-based exploration']}","{'value': 'Exploration strategy plays an important role in reinforcement learning, especially in sparse-reward tasks. In cooperative multi-agent reinforcement learning~(MARL), designing a suitable exploration strategy is much more challenging due to the large state space and the complex interaction among agents. Currently, mainstream exploration methods in MARL either contribute to exploring the unfamiliar states which are large and sparse, or measuring the interaction among agents with high computational costs. We found an interesting phenomenon that different kinds of exploration plays a different role in different MARL scenarios, and choosing a suitable one is often more effective than designing an exquisite algorithm. In this paper, we propose a exploration method that incorporate the \\underline{C}uri\\underline{O}sity-based and \\underline{IN}fluence-based exploration~(COIN) which is simple but effective in various situations. First, COIN measures the influence of each agent on the other agents based on mutual information theory and designs it as intrinsic rewards which are applied to each individual value function. Moreover, COIN computes the curiosity-based intrinsic rewards via prediction errors which are added to the extrinsic reward. For integrating the two kinds of intrinsic rewards, COIN utilizes a novel framework in which they complement each other and lead to a sufficient and effective exploration on cooperative MARL tasks. We perform extensive experiments on different challenging benchmarks, and results across different scenarios show the superiority of our method.'}",https://openreview.net{'value': '/pdf/6854c6c89e85c2e9d9f19ca18bbbe7bb269c8719.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=AG9A7Ae9r3,{'value': 'DIFFER:Decomposing Individual Reward for Fair Experience Replay in Multi-Agent Reinforcement Learning'},Xunhan Hu; Jian Zhao; Wengang Zhou; Ruili Feng; Houqiang Li,~Xunhan_Hu1; ~Jian_Zhao7; ~Wengang_Zhou1; ~Ruili_Feng1; ~Houqiang_Li1,{'value': ['Experience Replay; Reinforcement Learning; Multi-Agent System']},"{'value': 'Cooperative multi-agent reinforcement learning (MARL) is a challenging task, as agents must learn complex and diverse individual strategies from a shared team reward. However, existing methods struggle to distinguish and exploit important individual experiences, as they lack an effective way to decompose the team reward into individual rewards. To address this challenge, we propose DIFFER, a powerful theoretical framework for decomposing individual rewards to enable fair experience replay in MARL.\nBy enforcing the invariance of network gradients, we establish a partial differential equation whose solution yields the underlying individual reward function. The individual TD-error can then be computed from the solved closed-form individual rewards, indicating the importance of each piece of experience in the learning task and guiding the training process. Our method elegantly achieves an equivalence to the original learning framework when individual experiences are homogeneous, while also adapting to achieve more muscular efficiency and fairness when diversity is observed.\nOur extensive experiments on popular benchmarks validate the effectiveness of our theory and method, demonstrating significant improvements in learning efficiency and fairness. \nCode is available in supplement material.'}",https://openreview.net{'value': '/pdf/6d50d5c9ddb64383ad69f661c93f96c602a7027e.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=A6X9y8n4sT,{'value': 'One-2-3-45: Any Single Image to 3D Mesh in 45 Seconds without Per-Shape Optimization'},Minghua Liu; Chao Xu; Haian Jin; Linghao Chen; Mukund Varma T; Zexiang Xu; Hao Su,~Minghua_Liu1; ~Chao_Xu6; ~Haian_Jin1; ~Linghao_Chen2; ~Mukund_Varma_T1; ~Zexiang_Xu1; ~Hao_Su1,"{'value': ['single image reconstruction', '3d generation', 'mesh reconstruction', 'diffusion models']}","{'value': 'Single image 3D reconstruction is an important but challenging task that requires extensive knowledge of our natural world. Many existing methods solve this problem by optimizing a neural radiance field under the guidance of 2D diffusion models but suffer from lengthy optimization time, 3D inconsistency results, and poor geometry. In this work, we propose a novel method that takes a single image of any object as input and generates a full 360-degree 3D textured mesh in a single feed-forward pass. Given a single image, we first use a view-conditioned 2D diffusion model, Zero123, to generate multi-view images for the input view, and then aim to lift them up to 3D space. Since traditional reconstruction methods struggle with inconsistent multi-view predictions, we build our 3D reconstruction module upon an SDF-based generalizable neural surface reconstruction method and propose several critical training strategies to enable the reconstruction of 360-degree meshes. Without costly optimizations, our method reconstructs 3D shapes in significantly less time than existing methods. Moreover, our method favors better geometry, generates more 3D consistent results, and adheres more closely to the input image. We evaluate our approach on both synthetic data and in-the-wild images and demonstrate its superiority in terms of both mesh quality and runtime. In addition, our approach can seamlessly support the text-to-3D task by integrating with off-the-shelf text-to-image diffusion models.'}",https://openreview.net{'value': '/pdf/2e70089a720284724521cbc786ab46b09f2f8fa5.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=A6JDQDv7Nt,{'value': 'Keep Various Trajectories: Promoting Exploration of Ensemble Policies in Continuous Control'},Chao Li; Chen GONG; Qiang He; Xinwen Hou,~Chao_Li28; ~Chen_GONG8; ~Qiang_He1; ~Xinwen_Hou2,"{'value': ['Reinforcement Learning', 'Ensemble Exploration', 'Control Tasks']}","{'value': 'The combination of deep reinforcement learning (DRL) with ensemble methods has been proved to be highly effective in addressing complex sequential decision-making problems. This success can be primarily attributed to the utilization of multiple models, which enhances both the robustness of the policy and the accuracy of value function estimation. However, there has been limited analysis of the empirical success of current ensemble RL methods thus far. Our new analysis reveals that the sample efficiency of previous ensemble DRL algorithms may be limited by sub-policies that are not as diverse as they could be. Motivated by these findings, our study introduces a new ensemble RL algorithm, termed \\textbf{T}rajectories-awar\\textbf{E} \\textbf{E}nsemble exploratio\\textbf{N} (TEEN). The primary goal of TEEN is to  maximize the expected return while promoting more diverse trajectories. Through extensive experiments, we demonstrate that TEEN not only enhances the sample diversity of the ensemble policy compared to using sub-policies alone but also improves the performance over ensemble RL algorithms. On average, TEEN outperforms the baseline ensemble DRL algorithms by 41\\% in performance on the tested representative environments.'}",https://openreview.net{'value': '/pdf/a0b9adf4a30b63bad5dc1e530e3228d2997f4ba0.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=A5yMv7XPuA,{'value': 'Combinatorial Group Testing with Selfish Agents'},Giorgos Chionas; Dariusz Rafal Kowalski; Piotr Krysta,g.chionas@liverpool.ac.uk; ~Dariusz_Rafal_Kowalski1; ~Piotr_Krysta1,"{'value': ['Combinatorial Group Testing', 'Adversarial Equilibrium', 'Contention Resolution', 'selfish agents', 'learning time', 'adaptive learning algorithms']}","{'value': ""We study the Combinatorial Group Testing (CGT) problem in a novel game-theoretic framework, with a solution concept of Adversarial Equilibrium (AE). In this new framework, we have $n$ selfish agents corresponding to the elements of the universe $[n] =\\{0,1,\\ldots,n-1\\}$ and a hidden set $K \\subseteq [n]$ of active agents of size $|K| = k \\ll n$. In each round of the game, each active agent decides if it is present in a query $Q \\subseteq [n]$, and all agents receive feedback on $Q \\cap K$. The goal of each active agent is to assure that its id could be learned from the feedback as early as possible. \n\nWe present a comprehensive set of results in this new game, where we design and analyze adaptive algorithmic strategies of agents which are AE's. In particular, if $k$ is known to the agents, then we design adaptive AE strategies with provably near optimal learning time of $O(k \\log(n/k))$. In the case of unknown $k$, we design an adaptive AE strategies with learning time of order $n^k$, and we prove a lower bound of $\\Omega(n)$ on the learning time of any such algorithmic strategies. This shows a strong separations between the two models of known and unknown $k$, as well as between the classic CGT, i.e., without selfish agents, and our game theoretic CGT model.""}",https://openreview.net{'value': '/pdf/a422817c9921f7ca9764eb064a8d4e10e66aff62.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=9i8MD9btc8,{'value': '(Almost) Provable Error Bounds Under Distribution Shift via Disagreement Discrepancy'},Elan Rosenfeld; Saurabh Garg,~Elan_Rosenfeld1; ~Saurabh_Garg3,"{'value': ['accuracy estimation', 'error bounds', 'distribution shift', 'unsupervised domain adaptation']}","{'value': 'We derive a new, (almost) guaranteed upper bound on the error of deep neural networks under distribution shift using unlabeled test data. Prior methods are either vacuous in practice or accurate on average but heavily underestimate error for a sizeable fraction of shifts. In particular, the latter only give guarantees based on complex continuous measures such as test calibration, which cannot be identified without labels, and are therefore unreliable. Instead, our bound requires a simple, intuitive condition which is well justified by prior empirical works and holds in practice effectively 100\\% of the time. The bound is inspired by $\\mathcal{H}\\Delta\\mathcal{H}$-divergence but is easier to evaluate and substantially tighter, consistently providing non-vacuous test error upper bounds. Estimating the bound requires optimizing one multiclass classifier to disagree with another, for which some prior works have used sub-optimal proxy losses; we devise a ""disagreement loss"" which is theoretically justified and performs better in practice. We expect this loss can serve as a drop-in replacement for future methods which require maximizing multiclass disagreement. Across a wide range of natural and synthetic distribution shift benchmarks, our method gives valid error bounds while achieving average accuracy comparable to—though not better than—competitive estimation baselines.'}",https://openreview.net{'value': '/pdf/202205a6734e166164d8f4a2f8cbd19ddeba00fa.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=9cQzO3rXgR,{'value': 'Diffusion Representation for Asymmetric Kernels via Magnetic Transform'},Mingzhen He; FAN He; Ruikai Yang; Xiaolin Huang,~Mingzhen_He1; ~FAN_He1; ruikai.yang@sjtu.edu.cn; ~Xiaolin_Huang1,"{'value': ['Asymmetric kernels', 'diffusion maps', 'magnetic transform', 'dimension reduction']}","{'value': 'As a nonlinear dimension reduction technique, the diffusion map (DM) has been widely used. \nIn DM, kernels play an important role for capturing the nonlinear relationship of data. However, only symmetric kernels can be used now, which prevents the use of DM in directed graphs, trophic networks, and other real-world scenarios where the intrinsic and extrinsic geometries in data are asymmetric. A promising technique is the magnetic transform which  converts an asymmetric matrix to a Hermitian one. However, we are facing essential problems, including how diffusion distance could be preserved and how divergence could be avoided during diffusion process. Via theoretical proof, we successfully establish a diffusion representation framework with the magnetic transform, named MagDM. The effectiveness and robustness for dealing data endowed with asymmetric proximity are demonstrated on three synthetic datasets and two trophic networks.'}",https://openreview.net{'value': '/pdf/cd6896954605535d320234c4ce876981201a7322.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=9cF6RUwMe7,{'value': 'Learning Space-Time Continuous Latent Neural PDEs from Partially Observed States'},Valerii Iakovlev; Markus Heinonen; Harri Lähdesmäki,~Valerii_Iakovlev1; ~Markus_Heinonen1; ~Harri_Lähdesmäki1,"{'value': ['neural', 'PDEs', 'neural PDEs', 'partial observations', 'space time continuous']}","{'value': 'We introduce a novel grid-independent model for learning partial differential equations (PDEs) from noisy and partial observations on irregular spatiotemporal grids. We propose a space-time continuous latent neural PDE model with an efficient probabilistic framework and a novel encoder design for improved data efficiency and grid independence. The latent state dynamics are governed by a PDE model that combines the collocation method and the method of lines. We employ amortized variational inference for approximate posterior estimation and utilize a multiple shooting technique for enhanced training speed and stability. Our model demonstrates state-of-the-art performance on complex synthetic and real-world datasets, overcoming limitations of previous approaches and effectively handling partially-observed data. The proposed model outperforms recent methods, showing its potential to advance data-driven PDE modeling and enabling robust, grid-independent modeling of complex partially-observed dynamic processes across various domains.'}",https://openreview.net{'value': '/pdf/39f06a9ef80aed1de24764f262e57c284d0f90d7.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=9S8oVumknA,{'value': 'Intervention Generalization: A View from Factor Graph Models'},Gecia Bravo-Hermsdorff; David Watson; Jialin Yu; Jakob Zeitler; Ricardo Silva,~Gecia_Bravo-Hermsdorff1; ~David_Watson2; ~Jialin_Yu2; ~Jakob_Zeitler1; ~Ricardo_Silva1,"{'value': ['Causality', 'experimental design']}","{'value': 'One of the goals of causal inference is to generalize from past experiments and observational data to novel conditions. While it is in principle possible to eventually learn a mapping from a novel experimental condition to an outcome of interest, provided a sufficient variety of experiments is available in the training data, coping with a large combinatorial space of possible interventions is hard. Under a typical sparse experimental design, this mapping is ill-posed without relying on heavy regularization or prior distributions. Such assumptions may or may not be reliable, and can be hard to defend or test. In this paper, we take a close look at how to warrant a leap from past experiments to novel conditions based on minimal assumptions about the factorization of the distribution of the manipulated system, communicated in the well-understood language of factor graph models. A postulated interventional factor model (IFM) may not always be informative, but it conveniently abstracts away a need for explicitly modeling unmeasured confounding and feedback mechanisms, leading to directly testable claims. Given an IFM and datasets from a collection of experimental regimes, we derive conditions for identifiability of the expected outcomes of new regimes never observed in these training data. We implement our framework using several efficient algorithms, and apply them on a range of semi-synthetic experiments.'}",https://openreview.net{'value': '/pdf/e442d024f583bc23ca5d76b42fcac5ae9bcb7958.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=9QEVJ9qm46,{'value': 'Robust Learning with Progressive Data Expansion Against Spurious Correlation'},Yihe Deng; Yu Yang; Baharan Mirzasoleiman; Quanquan Gu,~Yihe_Deng1; ~Yu_Yang4; ~Baharan_Mirzasoleiman1; ~Quanquan_Gu1,"{'value': ['spurious correlation', 'robustness', 'robust learning']}","{'value': ""While deep learning models have shown remarkable performance in various tasks, they are susceptible to learning non-generalizable _spurious features_ rather than the core features that are genuinely correlated to the true label. In this paper, beyond existing analyses of linear models, we theoretically examine the learning process of a two-layer nonlinear convolutional neural network in the presence of spurious features. Our analysis suggests that imbalanced data groups and easily learnable spurious features can lead to the dominance of spurious features during the learning process. In light of this, we propose a new training algorithm called **PDE** that efficiently enhances the model's robustness for a better worst-group performance. PDE begins with a group-balanced subset of training data and progressively expands it to facilitate the learning of the core features. Experiments on synthetic and real-world benchmark datasets confirm the superior performance of our method on models such as ResNets and Transformers. On average, our method achieves a $2.8$ \\% improvement in worst-group accuracy compared with the state-of-the-art method, while enjoying up to $10\\times$ faster training efficiency.""}",https://openreview.net{'value': '/pdf/88df7e8e1efe1bc5ecb4377d9237cd5b22b6cf10.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=9B9J8X23LK,{'value': 'Accelerating Motion Planning via Optimal Transport'},An Thai Le; Georgia Chalvatzaki; Armin Biess; Jan Peters,~An_Thai_Le1; ~Georgia_Chalvatzaki1; ~Armin_Biess1; ~Jan_Peters3,"{'value': ['Motion Planning', 'Trajectory Optimization', 'Optimal Transport']}","{'value': ""Motion planning is still an open problem for many disciplines, e.g., robotics, autonomous driving, due to their need for high computational resources that hinder real-time, efficient decision-making. A class of methods striving to provide smooth solutions is gradient-based trajectory optimization. However, those methods usually suffer from bad local minima, while for many settings, they may be inapplicable due to the absence of easy-to-access gradients of the optimization objectives. In response to these issues, we introduce Motion Planning via Optimal Transport (MPOT)---a \\textit{gradient-free} method that optimizes a batch of smooth trajectories over highly nonlinear costs, even for high-dimensional tasks, while imposing smoothness through a Gaussian Process dynamics prior via the planning-as-inference perspective. To facilitate batch trajectory optimization, we introduce an original zero-order and highly-parallelizable update rule----the Sinkhorn Step, which uses the regular polytope family for its search directions. Each regular polytope, centered on trajectory waypoints, serves as a local cost-probing neighborhood, acting as a \\textit{trust region} where the Sinkhorn Step ``transports'' local waypoints toward low-cost regions. We theoretically show that Sinkhorn Step guides the optimizing parameters toward local minima regions of non-convex objective functions. We then show the efficiency of MPOT in a range of problems from low-dimensional point-mass navigation to high-dimensional whole-body robot motion planning, evincing its superiority compared to popular motion planners, paving the way for new applications of optimal transport in motion planning.""}",https://openreview.net{'value': '/pdf/d5b6cbf0c010ea92b372c87eba1a7206ef0fb145.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=99MHSB98yZ,{'value': 'Scenario Diffusion: Controllable Driving Scenario Generation With Diffusion'},Ethan Pronovost; Meghana Reddy Ganesina; Noureldin Hendy; Zeyu Wang; Andres Morales; Kai Wang; Nicholas Roy,~Ethan_Pronovost1; ~Meghana_Reddy_Ganesina1; ~Noureldin_Hendy1; ~Zeyu_Wang13; ~Andres_Morales1; kai@zoox.com; ~Nicholas_Roy1,"{'value': ['Deep Learning', '(Other) Applications', '(Other) Machine Learning Topics']}","{'value': 'Automated creation of synthetic traffic scenarios is a key part of scaling the safety validation of autonomous vehicles (AVs). In this paper, we propose Scenario Diffusion, a novel diffusion-based architecture for generating traffic scenarios that enables controllable scenario generation. We combine latent diffusion, object detection and trajectory regression to generate distributions of synthetic agent poses, orientations and trajectories simultaneously. This distribution is conditioned on the map and sets of tokens describing the desired scenario to provide additional control over the generated scenario. We show that our approach has sufficient expressive capacity to model diverse traffic patterns and generalizes to different geographical regions.'}",https://openreview.net{'value': '/pdf/7cea04c54184d6fcc4beb1aa2e633e70478c877a.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=966yOmwk6d,{'value': 'Towards Data-Algorithm Dependent Generalization: a Case Study on Overparameterized Linear Regression'},Jing Xu; Jiaye Teng; Yang Yuan; Andrew C Yao,~Jing_Xu4; ~Jiaye_Teng2; ~Yang_Yuan4; ~Andrew_C_Yao1,"{'value': ['data-algorithm dependent generalization analysis', 'overparameterized linear regression']}","{'value': 'One of the major open problems in machine learning is to characterize generalization in the overparameterized regime, where most traditional generalization bounds become inconsistent even for overparameterized linear regression. In many scenarios, this failure can be attributed to obscuring the crucial interplay between the training algorithm and the underlying data distribution. This paper demonstrate that the generalization behavior of overparameterized model should be analyzed in a both data-relevant and algorithm-relevant manner. To make a formal characterization, We introduce a notion called data-algorithm compatibility, which considers the generalization behavior of the entire data-dependent training trajectory, instead of traditional last-iterate analysis.  We validate our claim by studying the setting of solving overparameterized linear regression with gradient descent. Specifically, we perform a data-dependent trajectory analysis and derive a sufficient condition for compatibility in such a setting. Our theoretical results demonstrate that if we take early stopping iterates into consideration, generalization can hold with significantly weaker restrictions on the problem instance than the previous last-iterate analysis.'}",https://openreview.net{'value': '/pdf/277fbfbb800e3cf082d96404b63a0c76e66deafa.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=94rKFkcm56,{'value': 'Distance-Restricted Folklore Weisfeiler-Leman GNNs with Provable Cycle Counting Power'},Junru Zhou; Jiarui Feng; Xiyuan Wang; Muhan Zhang,~Junru_Zhou1; ~Jiarui_Feng1; ~Xiyuan_Wang1; ~Muhan_Zhang1,"{'value': ['Cycle counting', 'graph neural networks']}","{'value': 'The ability of graph neural networks (GNNs) to count certain graph substructures, especially cycles, is important for the success of GNNs on a wide range of tasks. It has been recently used as a popular metric for evaluating the expressive power of GNNs. Many of the proposed GNN models with provable cycle counting power are based on subgraph GNNs, i.e., extracting a bag of subgraphs from the input graph, generating representations for each subgraph, and using them to augment the representation of the input graph. However, those methods require heavy preprocessing, and suffer from high time and memory costs. In this paper, we overcome the aforementioned limitations of subgraph GNNs by proposing a novel class of GNNs---$d$-Distance-Restricted FWL(2) GNNs, or $d$-DRFWL(2) GNNs, based on the well-known FWL(2) algorithm. As a heuristic method for graph isomorphism testing, FWL(2) colors all node pairs in a graph and performs message passing among those node pairs. In order to balance the expressive power and complexity, $d$-DRFWL(2) GNNs simplify FWL(2) by restricting the range of message passing to node pairs whose mutual distances are at most $d$. This way, $d$-DRFWL(2) GNNs exploit graph sparsity while avoiding the expensive subgraph extraction operations in subgraph GNNs, making both the time and space complexity lower. We theoretically investigate both the discriminative power and the cycle counting power of $d$-DRFWL(2) GNNs. Our most important finding is that $d$-DRFWL(2) GNNs have provably strong cycle counting power even with $d=2$: they can count all 3, 4, 5, 6-cycles. Since 6-cycles (e.g., benzene rings) are ubiquitous in organic molecules, being able to detect and count them is crucial for achieving robust and generalizable performance on molecular tasks. Experiments on both synthetic datasets and molecular datasets verify our theory. To the best of our knowledge, 2-DRFWL(2) GNN is the most efficient GNN model to date (both theoretically and empirically) that can count up to 6-cycles.'}",https://openreview.net{'value': '/pdf/9353fb302ef17d6e38c2f57b613e7111fe1c8a18.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=919tWtJPXe,{'value': 'Self-supervised Object-Centric Learning for Videos'},Görkay Aydemir; Weidi Xie; Fatma Guney,~Görkay_Aydemir1; ~Weidi_Xie3; ~Fatma_Guney1,"{'value': ['Unsupervised Object Discovery', 'Unsupervised Video Object Segmentation', 'Object-Centric Learning', 'Unsupervised Video Multi Object Segmentation']}","{'value': 'Unsupervised multi-object segmentation has shown impressive results on images by utilizing powerful semantics learned from self-supervised pretraining. An additional modality such as depth or motion is often used to facilitate the segmentation in video sequences. However, the performance improvements observed in synthetic sequences, which rely on the robustness of an additional cue, do not translate to more challenging real-world scenarios. In this paper, we propose the first fully unsupervised method for segmenting multiple objects in real-world sequences. Our object-centric learning framework spatially binds objects to slots on each frame and then relates these slots across frames. From these temporally-aware slots, the training objective is to reconstruct the middle frame in a high-level semantic feature space. We propose a masking strategy by dropping a significant portion of tokens in the feature space for efficiency and regularization. Additionally, we address over-clustering by merging slots based on similarity. Our method can successfully segment multiple instances of complex and high-variety classes in YouTube videos.'}",https://openreview.net{'value': '/pdf/56923a879f1c35e105843cc792fbd1a87f08c247.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=90O5cvFZkZ,{'value': 'GUST: Combinatorial Generalization by Unsupervised Grouping with Neuronal Coherence'},Hao Zheng; Hui Lin; Rong Zhao,~Hao_Zheng2; ~Hui_Lin5; ~Rong_Zhao3,"{'value': ['neuronal coherence', 'combinatorial generalization', 'perceptual grouping', 'unsupervised learning']}","{'value': 'Dynamically grouping sensory information into structured entities is essential for understanding the world of combinatorial nature. However, the grouping ability and therefore combinatorial generalization are still challenging artificial neural networks. Inspired by the evidence that successful grouping is indicated by neuronal coherence in the human brain, we introduce GUST (Grouping Unsupervisely by Spike Timing network), an iterative network architecture with biological constraints to bias the network towards a dynamical state of neuronal coherence that softly reflects the grouping information in the temporal structure of its spiking activity. We evaluate and analyze the model on synthetic datasets. Interestingly, the segregation ability is directly learned from superimposed stimuli with a succinct unsupervised objective. Two learning stages are present, from coarsely perceiving global features to additionally capturing local features. Further, the learned symbol-like building blocks can be systematically composed to represent novel scenes in a bio-plausible manner.'}",https://openreview.net{'value': '/pdf/37587afc6ee47f8e58e6fef17daddffc6e2587b3.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=8xx0pyMOW1,{'value': 'Training neural operators to preserve invariant measures of chaotic attractors'},Ruoxi Jiang; Peter Y. Lu; Elena Orlova; Rebecca Willett,~Ruoxi_Jiang1; ~Peter_Y._Lu1; ~Elena_Orlova1; ~Rebecca_Willett1,"{'value': ['Neural operators', 'contrastive learning', 'optimal transport', 'chaotic attractors', 'invariant measures']}","{'value': 'Chaotic systems make long-horizon forecasts difficult because small perturbations in initial conditions cause trajectories to diverge at an exponential rate. In this setting, neural operators trained to minimize squared error losses, while capable of accurate short-term forecasts, often fail to reproduce statistical or structural properties of the dynamics over longer time horizons and can yield degenerate results. In this paper, we propose an alternative framework designed to preserve invariant measures of chaotic attractors that characterize the time-invariant statistical properties of the dynamics. Specifically, in the multi-environment setting (where each sample trajectory is governed by slightly different dynamics),  we consider two novel approaches to training with noisy data. First, we propose a loss based on the optimal transport distance between the observed dynamics and the neural operator outputs. This approach requires expert knowledge of the underlying physics to determine what statistical features should be included in the optimal transport loss. Second, we show that a  contrastive learning framework, which does not require any specialized prior knowledge, can preserve statistical properties of the dynamics nearly as well as the optimal transport approach. On a variety of chaotic systems, our method is shown empirically to preserve invariant measures of chaotic attractors.'}",https://openreview.net{'value': '/pdf/b14a5dfa81903acdb97fbc7b18430ff742f2e28f.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=8aunGrXdkl,{'value': 'Convex and Non-convex Optimization Under Generalized Smoothness'},Haochuan Li; Jian Qian; Yi Tian; Alexander Rakhlin; Ali Jadbabaie,~Haochuan_Li2; ~Jian_Qian2; ~Yi_Tian1; ~Alexander_Rakhlin1; ~Ali_Jadbabaie1,"{'value': ['Optimization', 'Convergence', 'Generalized smoothness']}","{'value': ""Classical analysis of convex and non-convex optimization methods often requires the Lipschitz continuity of the gradient, which limits the analysis to functions bounded by quadratics. Recent work relaxed this requirement to a non-uniform smoothness condition with the Hessian norm  bounded by an affine function of the gradient norm, and proved convergence in the non-convex setting via gradient clipping, assuming bounded noise. In this paper, we further generalize this non-uniform smoothness condition and develop a simple, yet powerful analysis technique that bounds the gradients along the trajectory, thereby leading to  stronger results for both convex and non-convex optimization problems. In particular, we obtain the classical convergence rates for (stochastic) gradient descent and Nesterov's accelerated gradient method in the convex and/or non-convex setting under this general smoothness condition. The new analysis approach does not require gradient clipping and allows heavy-tailed noise with bounded variance in the stochastic setting.""}",https://openreview.net{'value': '/pdf/8155b31c9cecd6c6119f248dbdcd5dcc083336ea.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=8Oukmqfek2,{'value': 'Rethinking Gauss-Newton for learning over-parameterized models'},Michael Arbel; Romain Menegaux; Pierre Wolinski,~Michael_Arbel1; ~Romain_Menegaux1; ~Pierre_Wolinski1,"{'value': ['implicit bias', 'gauss newton']}","{'value': ""This work studies the global convergence and implicit bias of Gauss Newton's (GN) when optimizing over-parameterized one-hidden layer networks in the mean-field regime. \nWe first establish a global convergence result for GN in the continuous-time limit exhibiting a faster convergence rate compared to GD due to improved conditioning. \nWe then perform an empirical study on a synthetic regression task to investigate the implicit bias of GN's method.\nWhile GN is consistently faster than GD in finding a global optimum, the learned model generalizes well on test data when starting from random initial weights with a small variance and using a small step size to slow down convergence. \nSpecifically, our study shows that such a setting results in a hidden learning phenomenon, where the dynamics are able to recover features with good generalization properties despite the model having sub-optimal training and test performances due to an under-optimized linear layer. This study exhibits a trade-off between the convergence speed of GN and the generalization ability of the learned solution.""}",https://openreview.net{'value': '/pdf/7f16160de5a9cae07795ae31b8b7c20181c3af3d.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=898RcRYWCg,{'value': 'Tame a Wild Camera: In-the-Wild Monocular Camera Calibration'},Shengjie Zhu; Abhinav Kumar; Masa Hu; Xiaoming Liu,~Shengjie_Zhu1; ~Abhinav_Kumar1; ~Masa_Hu1; ~Xiaoming_Liu2,{'value': ['Monocular Camera Calibration; Camera Pose Estimation; Image Editing']},"{'value': '3D sensing for monocular in-the-wild images, e.g., depth estimation and 3D object detection, has become increasingly important.\nHowever, the unknown intrinsic parameter hinders their development and deployment.\nPrevious methods for the monocular camera calibration rely on specific 3D objects or strong geometry prior, such as using a checkerboard or imposing a Manhattan World assumption.\nThis work instead calibrates intrinsic via exploiting the monocular 3D prior.\nGiven an undistorted image as input, our method calibrates the complete 4 Degree-of-Freedom (DoF) intrinsic parameters.\nFirst, we show intrinsic is determined by the two well-studied monocular priors: monocular depthmap and surface normal map.\nHowever, this solution necessitates a low-bias and low-variance depth estimation.\nAlternatively, we introduce the incidence field, defined as the incidence rays between points in 3D space and pixels in the 2D imaging plane.\nWe show that: 1) The incidence field is a pixel-wise parametrization of the intrinsic invariant to image cropping and resizing.\n2) The incidence field is a learnable monocular 3D prior, determined pixel-wisely by up-to-sacle monocular depthmap and surface normal.\nWith the estimated incidence field, a robust RANSAC algorithm recovers intrinsic.\nWe show the effectiveness of our method through superior performance on synthetic and zero-shot testing datasets.\nBeyond calibration, we demonstrate downstream applications in image manipulation detection \\& restoration, uncalibrated two-view pose estimation, and 3D sensing.'}",https://openreview.net{'value': '/pdf/72e46f248ef210c03cbdacbf2c0a1044fad61fb7.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=805CW5w2CY,{'value': 'A Simple Solution for Offline Imitation from Observations and Examples with Possibly Incomplete Trajectories'},Kai Yan; Alex Schwing; Yu-Xiong Wang,~Kai_Yan1; ~Alex_Schwing1; ~Yu-Xiong_Wang1,"{'value': ['offline Imitation learning', 'learning from observations', 'positive-unlabeled learning']}","{'value': 'Offline imitation from observations aims to solve MDPs where only task-specific expert states and task-agnostic non-expert state-action pairs are available. Offline imitation is useful in real-world scenarios where arbitrary interactions are costly and expert actions are unavailable. The state-of-the-art ‘DIstribution Correction Estimation’ (DICE) methods minimize divergence of state occupancy between expert and learner policies and retrieve a policy with weighted behavior cloning; however, their results are unstable when learning from incomplete trajectories, due to a non-robust optimization in the dual domain. To address the issue, in this paper, we propose Trajectory-Aware Imitation Learning from Observations (TAILO). TAILO uses a discounted sum along the future trajectory as the weight for weighted behavior cloning. The terms for the sum are scaled by the output of a discriminator, which aims to identify expert states. Despite simplicity, TAILO works well if there exist trajectories or segments of expert behavior in the task-agnostic data, a common assumption in prior work. In experiments across multiple testbeds, we find TAILO to be more robust and effective, particularly with incomplete trajectories.'}",https://openreview.net{'value': '/pdf/968da9db0b0d808d6b1a43b7e9e24756264a3339.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=7rm3OcASkg,{'value': 'DP-Mix: Mixup-based Data Augmentation for Differentially Private Learning'},Wenxuan Bao; Francesco Pittaluga; Vijay Kumar b g; Vincent Bindschaedler,~Wenxuan_Bao2; ~Francesco_Pittaluga2; ~Vijay_Kumar_b_g1; ~Vincent_Bindschaedler1,"{'value': ['differential privacy', 'deep learning', 'data augmentation']}","{'value': 'Data augmentation techniques, such as image transformations and combinations, are highly effective at improving the generalization of computer vision models, especially when training data is limited. However, such techniques are fundamentally incompatible with differentially private learning approaches, due to the latter’s built-in assumption that each training image’s contribution to the learned model is bounded. In this paper, we investigate why naive applications of multi-sample data augmentation techniques, such as mixup, fail to achieve good performance and propose two novel data augmentation techniques specifically designed for the constraints of differentially private learning. Our first technique, DP-Mix_Self, achieves SoTA classification performance across a range of datasets and settings by performing mixup on self-augmented data. Our second technique, DP-Mix_Diff, further improves performance by incorporating synthetic data from a pre-trained diffusion model into the mixup process. We open-source the code at https://github.com/wenxuan-Bao/DP-Mix.'}",https://openreview.net{'value': '/pdf/d0c62cf22805eb821a0426c933a76facb868fa15.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=7qfkImn0dL,{'value': 'ExPT: Synthetic Pretraining for Few-Shot Experimental Design'},Tung Nguyen; Sudhanshu Agrawal; Aditya Grover,~Tung_Nguyen2; sudhanshuagr27@g.ucla.edu; ~Aditya_Grover1,"{'value': ['experimental design', 'few-shot', 'black-box optimization', 'synthetic pretraining', 'in-context learning', 'transformer']}","{'value': 'Experimental design is a fundamental problem in many science and engineering fields. In this problem, sample efficiency is crucial due to the time, money, and safety costs of real-world design evaluations. Existing approaches either rely on active data collection or access to large, labeled datasets of past experiments, making them impractical in many real-world scenarios. In this work, we address the more challenging yet realistic setting of few-shot experimental design, where only a few labeled data points of input designs and their corresponding values are available. We approach this problem as a conditional generation task, where a model conditions on a few labeled examples and the desired output to generate an optimal input design. To this end, we introduce Experiment Pretrained Transformers (ExPT), a foundation model for few-shot experimental design that employs a novel combination of synthetic pretraining with in-context learning. In ExPT, we only assume knowledge of a finite collection of unlabelled data points from the input domain and pretrain a transformer neural network to optimize diverse synthetic functions defined over this domain. Unsupervised pretraining allows ExPT to adapt to any design task at test time in an in-context fashion by conditioning on a few labeled data points from the target task and generating the candidate optima. We evaluate ExPT on few-shot experimental design in challenging domains and demonstrate its superior generality and performance compared to existing methods. The source code is available at https://github.com/tung-nd/ExPT.git.'}",https://openreview.net{'value': '/pdf/421efd46edd799c06357032c33b619d238c97873.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=7ntySBR3Ey,{'value': 'Energy-Efficient Scheduling with Predictions'},Eric Balkanski; Noemie Perivier; Clifford Stein; Hao-Ting Wei,~Eric_Balkanski2; ~Noemie_Perivier1; ~Clifford_Stein1; ~Hao-Ting_Wei1,"{'value': ['Scheduling', 'algorithms with predictions', 'speed scaling', 'energy minimization']}","{'value': ""An  important goal of modern scheduling systems is to efficiently manage power usage. In energy-efficient scheduling,   the operating system controls the speed at which a machine is processing jobs  with the dual objective of  minimizing energy consumption and optimizing the quality of service cost of the resulting schedule. Since  machine-learned predictions  about future  requests can often be learned from historical data, a recent line of work  on learning-augmented algorithms aims to achieve improved performance guarantees by leveraging predictions.   In particular, for energy-efficient scheduling, Bamas et. al. [NeurIPS '20] and Antoniadis et. al. [SWAT '22]\n  designed algorithms with predictions for the  energy minimization with deadlines problem and achieved an improved competitive ratio when the prediction error is small while also maintaining  worst-case bounds even when the prediction error is arbitrarily large.\n\nIn this paper, we consider a general setting for energy-efficient scheduling and provide a flexible learning-augmented algorithmic framework that takes as input an offline and an online algorithm for the desired energy-efficient scheduling problem. We show that, when the prediction error is small, this framework gives improved competitive ratios for many different energy-efficient scheduling problems, including  energy minimization with deadlines, while also maintaining a bounded competitive ratio regardless of the prediction error. Finally, we empirically demonstrate that this framework achieves an improved performance on real and synthetic datasets.""}",https://openreview.net{'value': '/pdf/c8299d546b7e8e900c4906a806403f185a6f8b09.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=7ntI4kcoqG,"{'value': 'AMAG: Additive, Multiplicative and Adaptive Graph Neural Network For Forecasting Neuron Activity'}",Jingyuan Li; Leo Scholl; Trung Le; Pavithra Rajeswaran; Amy L Orsborn; Eli Shlizerman,~Jingyuan_Li3; lscholl@uw.edu; ~Trung_Le4; ~Pavithra_Rajeswaran1; ~Amy_L_Orsborn1; ~Eli_Shlizerman1,"{'value': ['Neuroscience and Cognitive Science', 'Neural Activity Forecasting', 'Graph Neural Network']}","{'value': 'Latent Variable Models (LVMs) propose to model the dynamics of neural populations by capturing low-dimensional structures that represent features involved in neural activity. Recent LVMs are based on deep learning methodology where a deep neural network is trained to reconstruct the same neural activity given as input and as a result to build the latent representation. Without taking past or future activity into account such a task is non-causal. In contrast, the task of forecasting neural activity based on given input extends the reconstruction task. LVMs that are trained on such a task could potentially capture temporal causality constraints within its latent representation. Forecasting has received less attention than reconstruction due to recording challenges such as limited neural measurements and trials. In this work, we address modeling neural population dynamics via the forecasting task and improve forecasting performance by including a prior, which consists of pairwise neural unit interaction as a multivariate dynamic system. Our proposed model---Additive, Multiplicative, and Adaptive Graph Neural Network (AMAG)---leverages additive and multiplicative message-passing operations analogous to the interactions in neuronal systems and adaptively learns the interaction among neural units to forecast their future activity. We demonstrate the advantage of AMAG compared to non-GNN based methods on synthetic data and multiple modalities of neural recordings (field potentials from penetrating electrodes or surface-level micro-electrocorticography) from four rhesus macaques. Our results show the ability of AMAG to recover ground truth spatial interactions and yield estimation for future dynamics of the neural population.'}",https://openreview.net{'value': '/pdf/83f412912e9f581fab6d83d5f10fc657585fd321.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=7nXaoclHed,{'value': 'A Sublinear-Time Spectral Clustering Oracle with Improved Preprocessing Time'},Ranran Shen; Pan Peng,~Ranran_Shen1; ~Pan_Peng1,"{'value': ['Sublinear-time algorithms', 'Spectral Clustering', 'Graph Clustering', 'Random Walks']}","{'value': 'We address the problem of designing a sublinear-time spectral clustering oracle for graphs that exhibit strong clusterability. Such graphs contain $k$ latent clusters, each characterized by a large inner conductance (at least $\\varphi$) and a small outer conductance (at most $\\varepsilon$). Our aim is to preprocess the graph to enable clustering membership queries, with the key requirement that both preprocessing and query answering should be performed in sublinear time, and the resulting partition should be consistent with a $k$-partition that is close to the ground-truth clustering. Previous oracles have relied on either a $\\textrm{poly}(k)\\log n$ gap between inner and outer conductances or exponential (in $k/\\varepsilon$) preprocessing time. Our algorithm relaxes these assumptions, albeit at the cost of a slightly higher misclassification ratio. We also show that our clustering oracle is robust against a few random edge deletions. To validate our theoretical bounds, we conducted experiments on synthetic networks.'}",https://openreview.net{'value': '/pdf/60fb80ab34e772b1720f56bc3d6304f3bfdfe094.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=7gbjsgcN5p,{'value': 'Unsupervised Optical Flow Estimation with Dynamic Timing Representation for Spike Camera'},Lujie Xia; Ziluo Ding; Rui Zhao; Jiyuan Zhang; Lei Ma; Zhaofei Yu; Tiejun Huang; Ruiqin Xiong,~Lujie_Xia1; ~Ziluo_Ding1; ~Rui_Zhao11; ~Jiyuan_Zhang3; ~Lei_Ma3; ~Zhaofei_Yu1; ~Tiejun_Huang1; ~Ruiqin_Xiong1,"{'value': ['Optical flow', 'unsupervised learning', 'spike camera']}","{'value': 'Efficiently selecting an appropriate spike stream data length to extract precise information is the key to the spike vision tasks. To address this issue, we propose a dynamic timing representation for spike streams. Based on multi-layers architecture, it applies dilated convolutions on temporal dimension to extract features on multi-temporal scales with few parameters. And we design layer attention to dynamically fuse these features. Moreover, we propose an unsupervised learning method for optical flow estimation in a spike-based manner to break the dependence on labeled data. In addition, to verify the robustness, we also build a spike-based synthetic validation dataset for extreme scenarios in autonomous driving, denoted as SSES dataset. It consists of various corner cases. Experiments show that our method can predict optical flow from spike streams in different high-speed scenes, including real scenes. For instance, our method achieves $15\\%$ and $19\\%$ error reduction on PHM dataset compared to the best spike-based work, SCFlow, in $\\Delta t=10$ and $\\Delta t=20$ respectively, using the same settings as in previous works. The source code and dataset are available at \\href{https://github.com/Bosserhead/USFlow}{https://github.com/Bosserhead/USFlow}.'}",https://openreview.net{'value': '/pdf/77d7daeb405589da0329562487cb7baa96d21c5e.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=7f6vH3mmhr,{'value': 'Multi-Agent Learning with Heterogeneous Linear Contextual Bandits'},Anh Do; Thanh Nguyen-Tang; Raman Arora,~Anh_Do2; ~Thanh_Nguyen-Tang1; ~Raman_Arora1,"{'value': ['Multi-agent', 'Bandits', 'Cooperative']}","{'value': 'As trained intelligent systems become increasingly pervasive, multiagent learning has emerged as a popular framework for studying complex interactions between autonomous agents. Yet, a formal understanding of how and when learners in heterogeneous environments benefit from sharing their respective experiences is far from complete. In this paper, we seek answers to these questions in the context of linear contextual bandits. We present a novel distributed learning algorithm based on the upper confidence bound (UCB) algorithm, which we refer to as H-LINUCB, wherein agents cooperatively minimize the group regret under the coordination of a central server. In the setting where the level of heterogeneity or dissimilarity across the environments is known to the agents, we show that H-LINUCB is provably optimal in regimes where the tasks are highly similar or highly dissimilar.'}",https://openreview.net{'value': '/pdf/a517b945e594d2b03a665195e8e4ef92dca1a30c.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=7R8noSP4vL,{'value': 'Tempo Adaptation in Non-stationary Reinforcement Learning'},Hyunin Lee; Yuhao Ding; Jongmin Lee; Ming Jin; Javad Lavaei; Somayeh Sojoudi,~Hyunin_Lee1; ~Yuhao_Ding2; ~Jongmin_Lee1; ~Ming_Jin2; ~Javad_Lavaei1; ~Somayeh_Sojoudi1,"{'value': ['Non-stationary RL', 'Reinforcement Learning']}","{'value': ""We first raise and tackle a ``time synchronization'' issue between the agent and the environment in non-stationary reinforcement learning (RL), a crucial factor hindering its real-world applications. In reality, environmental changes occur over wall-clock time ($t$) rather than episode progress ($k$), where wall-clock time signifies the actual elapsed time within the fixed duration $t \\in [0, T]$. In existing works, at episode $k$, the agent rolls a trajectory and trains a policy before transitioning to episode $k+1$. In the context of the time-desynchronized environment, however, the agent at time $t_{k}$ allocates $\\Delta t$ for trajectory generation and training, subsequently moves to the next episode at $t_{k+1}=t_{k}+\\Delta t$. Despite a fixed total number of episodes ($K$), the agent accumulates different trajectories influenced by the choice of interaction times ($t_1,t_2,...,t_K$), significantly impacting the suboptimality gap of the policy. We propose a Proactively Synchronizing Tempo ($\\texttt{ProST}$) framework that computes a suboptimal sequence {$t_1,t_2,...,t_K$} (= { $t_{1:K}$}) by minimizing an upper bound on its performance measure, i.e., the dynamic regret. Our main contribution is that we show that a suboptimal {$t_{1:K}$} trades-off between the policy training time (agent tempo) and how fast the environment changes (environment tempo). Theoretically, this work develops a suboptimal {$t_{1:K}$} as a function of the degree of the environment's non-stationarity while also achieving a sublinear dynamic regret. Our experimental evaluation on various high-dimensional non-stationary environments shows that the $\\texttt{ProST}$ framework achieves a higher online return at suboptimal {$t_{1:K}$} than the existing methods.""}",https://openreview.net{'value': '/pdf/8db7f228453b28a79a307de32e9dcf101d3ef52c.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=7PJ6LaIOO4,{'value': 'Statistical and Computational Trade-off in Multi-Agent Multi-Armed Bandits'},Filippo Vannella; Alexandre Proutiere; Jaeseong Jeong,~Filippo_Vannella1; ~Alexandre_Proutiere1; ~Jaeseong_Jeong1,"{'value': ['Multi-Agent Multi-Armed Bandits', 'Multi-Armed Bandits', 'Regret Minimization']}","{'value': 'We study the problem of regret minimization in Multi-Agent Multi-Armed Bandits (MAMABs) where the rewards are defined through a factor graph. We derive an instance-specific regret lower bound and characterize the minimal expected number of times each global action should be explored. Unfortunately, this bound and the corresponding optimal exploration process are obtained by solving a combinatorial optimization problem with a set of variables and constraints exponentially growing with the number of agents. We approximate the regret lower bound problem via Mean Field techniques to reduce the number of variables and constraints. By tuning the latter, we explore the trade-off between achievable regret and complexity. We devise Efficient Sampling for MAMAB (ESM), an algorithm whose regret asymptotically matches the corresponding approximated lower bound. We assess the regret and computational complexity of ESM numerically, using both synthetic and real-world experiments in radio communications networks.'}",https://openreview.net{'value': '/pdf/21b4afefd53ae63864d2338899e3d4f31edf395d.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=7EMphtUgCI,{'value': 'AVIS: Autonomous Visual Information Seeking with Large Language Model Agent'},Ziniu Hu; Ahmet Iscen; Chen Sun; Kai-Wei Chang; Yizhou Sun; David A Ross; Cordelia Schmid; Alireza Fathi,~Ziniu_Hu1; ~Ahmet_Iscen3; ~Chen_Sun1; ~Kai-Wei_Chang1; ~Yizhou_Sun1; ~David_A_Ross1; ~Cordelia_Schmid1; ~Alireza_Fathi1,"{'value': ['large language model', 'visual question answering', 'dynamic decision making', 'Tool augmented LLM']}","{'value': 'In this paper, we propose an autonomous information seeking visual question answering framework, AVIS. Our method leverages a Large Language Model (LLM) to dynamically strategize the utilization of external tools and to investigate their outputs via tree search, thereby acquiring the indispensable knowledge needed to provide answers to the posed questions. Responding to visual questions that necessitate external knowledge, such as ""What event is commemorated by the building depicted in this image?"", is a complex task. This task presents a combinatorial search space that demands a sequence of actions, including invoking APIs, analyzing their responses, and making informed decisions. We conduct a user study to collect a variety of instances of human decision-making when faced with this task. This data is then used to design a system comprised of three components: an LLM-powered planner that dynamically determines which tool to use next, an LLM-powered reasoner that analyzes and extracts key information from the tool outputs, and a working memory component that retains the acquired information throughout the process. The collected user behavior serves as a guide for our system in two key ways. First, we create a transition graph by analyzing the sequence of decisions made by users. This graph delineates distinct states and confines the set of actions available at each state. Second, we use examples of user decision-making to provide our LLM-powered planner and reasoner with relevant contextual instances, enhancing their capacity to make informed decisions. We show that AVIS achieves state-of-the-art results on knowledge-based visual question answering benchmarks such as Infoseek and OK-VQA.'}",https://openreview.net{'value': '/pdf/fdde686d726cd8f20ae3773fe15894af0a9fd043.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=77i6itptQW,{'value': 'IDEA: An Invariant Perspective for Efficient Domain Adaptive Image Retrieval'},Haixin Wang; Hao Wu; Jinan Sun; Shikun Zhang; Chong Chen; Xian-Sheng Hua; Xiao Luo,~Haixin_Wang3; ~Hao_Wu39; ~Jinan_Sun1; ~Shikun_Zhang2; ~Chong_Chen2; ~Xian-Sheng_Hua1; ~Xiao_Luo3,"{'value': ['domain adaption', 'binary descriptor', 'causal inference']}","{'value': 'In this paper, we investigate the problem of unsupervised domain adaptive hashing, which leverage knowledge from a label-rich source domain to expedite learning to hash on a label-scarce target domain. Although numerous existing approaches attempt to incorporate transfer learning techniques into deep hashing frameworks, they often neglect the essential invariance for adequate alignment between these two domains. Worse yet, these methods fail to distinguish between causal and non-causal effects embedded in images, rendering cross-domain retrieval ineffective. To address these challenges, we propose an Invariance-acquired Domain AdaptivE HAshing (IDEA) model. Our IDEA first decomposes each image into a causal feature representing label information, and a non-causal feature indicating domain information. Subsequently, we generate discriminative hash codes using causal features with consistency learning on both source and target domains. More importantly, we employ a generative model for synthetic samples to simulate the intervention of various non-causal effects, ultimately minimizing their impact on hash codes for domain invariance. Comprehensive experiments conducted on benchmark datasets validate the superior performance of our IDEA compared to a variety of competitive baselines.'}",https://openreview.net{'value': '/pdf/77d7e8bb1e9e32ff56fc4c7712f8cc1e15f9aaa2.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=6jNQ1AY1Uf,{'value': 'Synthetic Experience Replay'},Cong Lu; Philip J. Ball; Yee Whye Teh; Jack Parker-Holder,~Cong_Lu1; ~Philip_J._Ball2; ~Yee_Whye_Teh2; ~Jack_Parker-Holder1,"{'value': ['Reinforcement Learning', 'Diffusion Models', 'Synthetic Data', 'Sample-Efficient RL']}","{'value': ""A key theme in the past decade has been that when large neural networks and large datasets combine they can produce remarkable results. In deep reinforcement learning (RL), this paradigm is commonly made possible through experience replay, whereby a dataset of past experiences is used to train a policy or value function. However, unlike in supervised or self-supervised learning, an RL agent has to collect its own data, which is often limited. Thus, it is challenging to reap the benefits of deep learning, and even small neural networks can overfit at the start of training. In this work, we leverage the tremendous recent progress in generative modeling and propose Synthetic Experience Replay (SynthER), a diffusion-based approach to flexibly upsample an agent's collected experience. We show that SynthER is an effective method for training RL agents across offline and online settings, in both proprioceptive and pixel-based environments. In offline settings, we observe drastic improvements when upsampling small offline datasets and see that additional synthetic data also allows us to effectively train larger networks. Furthermore, SynthER enables online agents to train with a much higher update-to-data ratio than before, leading to a significant increase in sample efficiency, without any algorithmic changes. We believe that synthetic training data could open the door to realizing the full potential of deep learning for replay-based RL algorithms from limited data. Finally, we open-source our code at https://github.com/conglu1997/SynthER.""}",https://openreview.net{'value': '/pdf/270fbf4148b7e8037943bf5d486912098f23addf.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=6XC5iKqRVm,{'value': 'DELTA: Diverse Client Sampling for Fasting Federated Learning'},Lin Wang; Yongxin Guo; Tao Lin; Xiaoying Tang,~Lin_Wang14; ~Yongxin_Guo1; ~Tao_Lin1; ~Xiaoying_Tang2,"{'value': ['federated learning', 'client sampling']}","{'value': ""Partial client participation has been widely adopted in Federated Learning (FL) to reduce the communication burden efficiently. However, an inadequate client sampling scheme can lead to the selection of unrepresentative subsets, resulting in significant variance in model updates and slowed convergence. Existing sampling methods are either biased or can be further optimized for faster convergence.\nIn this paper, we present DELTA, an unbiased sampling scheme designed to alleviate these issues. DELTA characterizes the effects of client diversity and local variance, and samples representative clients with valuable information for global model updates. In addition, DELTA is a proven optimal unbiased sampling scheme that minimizes variance caused by partial client participation and outperforms other unbiased sampling schemes in terms of convergence.  Furthermore, to address full-client gradient dependence, we provide a practical version of DELTA depending on the available clients' information, and also analyze its convergence. Our results are validated through experiments on both synthetic and real-world datasets.""}",https://openreview.net{'value': '/pdf/cf6e8c9825a76b364f078e3a3a31bfcfa3e34332.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=6JJq5TW9Mc,{'value': 'Learning World Models with Identifiable Factorization'},Yu-Ren Liu; Biwei Huang; Zhengmao Zhu; Honglong Tian; Mingming Gong; Yang Yu; Kun Zhang,~Yu-Ren_Liu1; ~Biwei_Huang1; ~Zhengmao_Zhu1; ~Honglong_Tian1; ~Mingming_Gong1; ~Yang_Yu5; ~Kun_Zhang1,{'value': ['Model-based Reinforcement Learning; Causal Representation Learning;']},"{'value': 'Extracting a stable and compact representation of the environment is crucial for efficient reinforcement learning in high-dimensional, noisy, and non-stationary environments.  Different categories of information coexist in such environments -- how to effectively extract and disentangle the information remains a challenging problem. In this paper, we propose IFactor, a general framework to model four distinct categories of latent state variables that capture various aspects of information within the RL system, based on their interactions with actions and rewards. Our analysis establishes block-wise identifiability of these latent variables, which not only provides a stable and compact representation but also discloses that all reward-relevant factors are significant for policy learning. We further present a practical approach to learning the world model with identifiable blocks, ensuring the removal of redundancies but retaining minimal and sufficient information for policy optimization. Experiments in synthetic worlds demonstrate that our method accurately identifies the ground-truth latent variables, substantiating our theoretical findings. Moreover, experiments in variants of the DeepMind Control Suite and RoboDesk showcase the superior performance of our approach over baselines.'}",https://openreview.net{'value': '/pdf/f42fb8e08a233349840c6912f967116ddf1f645a.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=6EaLIw3W7c,{'value': 'LinkerNet: Fragment Poses and Linker Co-Design with 3D Equivariant Diffusion'},Jiaqi Guan; Xingang Peng; PeiQi Jiang; Yunan Luo; Jian Peng; Jianzhu Ma,~Jiaqi_Guan1; ~Xingang_Peng1; ~PeiQi_Jiang2; ~Yunan_Luo1; ~Jian_Peng1; ~Jianzhu_Ma2,"{'value': ['Linker design', 'generative models']}","{'value': 'Targeted protein degradation techniques, such as PROteolysis TArgeting Chimeras (PROTACs), have emerged as powerful tools for selectively removing disease-causing proteins. One challenging problem in this field is designing a linker to connect different molecular fragments to form a stable drug-candidate molecule. Existing models for linker design assume that the relative positions of the fragments are known, which may not be the case in real scenarios. In this work, we address a more general problem where the poses of the fragments are *unknown* in 3D space. We develop a 3D equivariant diffusion model that jointly learns the generative process of both fragment poses and the 3D structure of the linker. By viewing fragments as rigid bodies, we design a fragment pose prediction module inspired by the Newton-Euler equations in rigid body mechanics. Empirical studies on ZINC and PROTAC-DB datasets demonstrate that our model can generate chemically valid, synthetically-accessible,  and low-energy molecules under both unconstrained and constrained generation settings.'}",https://openreview.net{'value': '/pdf/18c4ca5ade0f47732cd4a81cb37e997773ca7d85.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=6EDHfVHicP,{'value': 'DDF-HO: Hand-Held Object Reconstruction via Conditional Directed Distance Field'},Chenyangguang Zhang; Yan Di; Ruida Zhang; Guangyao Zhai; Fabian Manhardt; Federico Tombari; Xiangyang Ji,~Chenyangguang_Zhang1; ~Yan_Di2; ~Ruida_Zhang1; ~Guangyao_Zhai1; ~Fabian_Manhardt1; ~Federico_Tombari1; ~Xiangyang_Ji1,"{'value': ['hand-held object reconstruction', 'directed distance field', 'human-object interaction']}","{'value': 'Reconstructing hand-held objects from a single RGB image is an important and challenging problem. Existing works utilizing Signed Distance Fields (SDF) reveal limitations in comprehensively capturing the complex hand-object interactions, since SDF is  only reliable within the proximity of the target, and hence, infeasible to simultaneously encode local hand and object cues. To address this issue, we propose DDF-HO, a novel approach leveraging Directed Distance Field (DDF) as the shape representation. Unlike SDF, DDF maps a ray in 3D space, consisting of an origin and a direction, to corresponding DDF values, including a binary visibility signal determining whether the ray intersects the objects and a distance value measuring the distance from origin to target in the given direction. We randomly sample multiple rays and collect local to global geometric features for them by introducing a novel 2D ray-based feature aggregation scheme and a 3D intersection-aware hand pose embedding, combining 2D-3D features to model hand-object interactions. Extensive experiments on synthetic and real-world datasets demonstrate that DDF-HO consistently outperforms all baseline methods by a large margin, especially under Chamfer Distance, with about 80% leap forward. Codes are available at https://github.com/ZhangCYG/DDFHO.'}",https://openreview.net{'value': '/pdf/fdc3731967822bde8f03229836d4f516c1f9fb23.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=5ytypAqAsR,{'value': 'No Representation Rules Them All in Category Discovery'},Sagar Vaze; Andrea Vedaldi; Andrew Zisserman,~Sagar_Vaze1; ~Andrea_Vedaldi1; ~Andrew_Zisserman1,"{'value': ['Category discovery', 'semi-supervised learning', 'self-supervised learning', 'classification']}","{'value': ""In this paper we tackle the problem of Generalized Category Discovery (GCD). Specifically, given a dataset with labelled and unlabelled images, the task is to cluster all images in the unlabelled subset, whether or not they belong to the labelled categories. Our first contribution is to recognise that most existing GCD benchmarks only contain labels for a single clustering of the data, making it difficult to ascertain whether models are leveraging the available labels to solve the GCD task, or simply solving an unsupervised clustering problem. As such, we present a synthetic dataset, named 'Clevr-4', for category discovery. Clevr-4 contains four equally valid partitions of the data, i.e based on object 'shape', 'texture' or 'color' or 'count'. To solve the task, models are required to extrapolate the taxonomy specified by labelled set, rather than simply latch onto a single natural grouping of the data. We use this dataset to demonstrate the limitations of unsupervised clustering in the GCD setting, showing that even very strong unsupervised models fail on Clevr-4. We further use Clevr-4 to examine the weaknesses of existing GCD algorithms, and propose a new method which addresses these shortcomings, leveraging consistent findings from the representation learning literature to do so. Our simple solution, which is based on `Mean Teachers' and termed $\\mu$GCD, substantially outperforms implemented baselines on Clevr-4. Finally, when we transfer these findings to real data on the challenging Semantic Shift Benchmark suite, we find that $\\mu$GCD outperforms all prior work, setting a new state-of-the-art.""}",https://openreview.net{'value': '/pdf/ac51480cf4816f6e9e753fbcc38d308d0a4a9a11.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=5gz7npbQ6Z,{'value': 'A Cross-Moment Approach for Causal Effect Estimation'},Yaroslav Kivva; Saber Salehkaleybar; Negar Kiyavash,~Yaroslav_Kivva1; ~Saber_Salehkaleybar1; ~Negar_Kiyavash1,"{'value': ['Causal inference', 'Difference-in-Difference', 'Structural causal models', 'Potential outcome', 'Proxy learning']}","{'value': 'We consider the problem of estimating the causal effect of a treatment on an outcome in  linear structural causal models (SCM) with latent confounders when we have access to a single proxy variable.\nSeveral methods (such as difference-in-difference (DiD) estimator or negative outcome control) have been proposed in this setting in the literature. However, these approaches require either restrictive assumptions on the data generating model or having access to at least two proxy variables.\nWe propose a method to estimate the causal effect using cross moments between the treatment, the outcome, and the proxy variable. In particular, we show that the causal effect can be identified with simple arithmetic operations on the cross moments if the latent confounder in linear SCM is non-Gaussian.\nIn this setting, DiD estimator provides an unbiased estimate only in the special case where the latent confounder has exactly the same direct causal effects on the outcomes in the pre-treatment and post-treatment phases. This translates to the common trend assumption in DiD, which we effectively relax.\nAdditionally, we provide an impossibility result that shows the causal effect cannot be identified if the observational distribution over the treatment, the outcome, and the proxy is jointly Gaussian.\n Our experiments on both synthetic and real-world datasets showcase the effectiveness\nof the proposed approach in estimating the causal effect.'}",https://openreview.net{'value': '/pdf/c88e92ff5e34aa709d95f42e8941fe0b60e87415.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=5VQFAvUHcd,{'value': 'Replicable Clustering'},Hossein Esfandiari; Amin Karbasi; Vahab Mirrokni; Grigoris Velegkas; Felix Zhou,~Hossein_Esfandiari1; ~Amin_Karbasi3; ~Vahab_Mirrokni2; ~Grigoris_Velegkas1; ~Felix_Zhou1,"{'value': ['Theory', 'Clustering Theory', 'Statistical Learning Theory', 'Reproducibility', 'Replicability']}","{'value': 'We design replicable algorithms in the context of statistical clustering under the recently introduced notion of replicability from Impagliazzo et al. [2022]. According to this definition, a clustering algorithm is replicable if, with high probability, its output induces the exact same partition of the sample space after two executions on different inputs drawn from the same distribution, when its internal randomness is shared across the executions. We propose such algorithms for the statistical $k$-medians, statistical $k$-means, and statistical $k$-centers problems by utilizing approximation routines for their combinatorial counterparts in a black-box manner. In particular, we demonstrate a replicable $O(1)$-approximation algorithm for statistical Euclidean $k$-medians ($k$-means) with $\\operatorname{poly}(d)$ sample complexity. We also describe an $O(1)$-approximation algorithm with an additional $O(1)$-additive error for statistical Euclidean $k$-centers, albeit with $\\exp(d)$ sample complexity. In addition, we provide experiments on synthetic distributions in 2D using the $k$-means++ implementation from sklearn as a black-box that validate our theoretical results.'}",https://openreview.net{'value': '/pdf/ff1a592c05f6bb2acb93f5b61494e1744ce625f2.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=5Fgdk3hZpb,"{'value': 'Squeeze, Recover and Relabel: Dataset Condensation at ImageNet Scale From A New Perspective'}",Zeyuan Yin; Eric Xing; Zhiqiang Shen,~Zeyuan_Yin1; ~Eric_Xing1; ~Zhiqiang_Shen1,"{'value': ['Dataset Condensation and Distillation', 'ImageNet Scale']}","{'value': 'We present a new dataset condensation framework termed Squeeze, Recover and Relabel (SRe$^2$L) that decouples the bilevel optimization of model and synthetic data during training, to handle varying scales of datasets, model architectures and image resolutions for efficient dataset condensation. The proposed method demonstrates flexibility across diverse dataset scales and exhibits multiple advantages in terms of arbitrary resolutions of synthesized images, low training cost and memory consumption with high-resolution synthesis, and the ability to scale up to arbitrary evaluation network architectures. Extensive experiments are conducted on Tiny-ImageNet and full ImageNet-1K datasets. Under 50 IPC, our approach achieves the highest 42.5\\% and 60.8\\% validation accuracy on Tiny-ImageNet and ImageNet-1K, outperforming all previous state-of-the-art methods by margins of 14.5\\% and 32.9\\%, respectively. Our approach also surpasses MTT in terms of speed by approximately 52$\\times$ (ConvNet-4) and 16$\\times$ (ResNet-18) faster with less memory consumption of 11.6$\\times$ and 6.4$\\times$ during data synthesis. Our code and condensed datasets of 50, 200 IPC with 4K recovery budget are available at https://github.com/VILA-Lab/SRe2L.'}",https://openreview.net{'value': '/pdf/9bd0f7a26ba0c2916d8fc71375b5a81ec2d390fc.pdf'},{'abstract_filter': 'Data Synthesis'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=4L2OlXhiTM,{'value': 'FIRAL: An Active Learning Algorithm for Multinomial Logistic Regression'},Youguang Chen; George Biros,~Youguang_Chen1; ~George_Biros3,"{'value': ['statistical learning', 'active learning', 'logistic regression', 'regret minimization']}","{'value': 'We investigate theory and algorithms for pool-based active learning for multiclass classification using multinomial logistic regression.  Using finite sample analysis, we prove that the Fisher Information Ratio (FIR)  lower and upper bounds  the excess risk. Based on our theoretical analysis, we propose an active learning algorithm that  employs regret minimization to minimize the FIR. To verify our derived excess risk bounds, we conduct experiments on synthetic datasets. Furthermore, we compare FIRAL with five other methods and found that our scheme  outperforms them: it consistently produces the smallest classification error in the multiclass logistic regression setting, as demonstrated through experiments on MNIST, CIFAR-10, and 50-class ImageNet.'}",https://openreview.net{'value': '/pdf/bb906bcfe26114d51ccdb14b0576212dcd3341d2.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=40L3viVWQN,{'value': 'The Pick-to-Learn Algorithm: Empowering Compression for Tight Generalization Bounds and Improved Post-training Performance'},Dario Paccagnan; Marco Campi; Simone Garatti,~Dario_Paccagnan1; ~Marco_Campi1; ~Simone_Garatti1,"{'value': ['Statistical learning theory', 'Compression theory', 'Generalization bounds']}","{'value': 'Generalization bounds are valuable both for theory and applications. On the one hand, they shed light on the mechanisms that underpin the learning processes; on the other, they certify how well a learned model performs against unseen inputs.  In this work we build upon a recent breakthrough in compression theory to develop a new framework yielding tight generalization bounds of wide practical applicability.  The core idea is to embed any given learning algorithm into a suitably-constructed meta-algorithm (here called Pick-to-Learn, P2L) in order to instill desirable compression properties. When applied to the MNIST classification dataset and to a synthetic regression problem, P2L not only attains generalization bounds that compare favorably with the state of the art (test-set and PAC-Bayes bounds), but it also learns models with better post-training performance.'}",https://openreview.net{'value': '/pdf/596f6209168ad423054afb49c46f556626cb7fa5.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=3ofe0lpwQP,{'value': 'DisDiff: Unsupervised Disentanglement of Diffusion Probabilistic Models'},Tao Yang; Yuwang Wang; Yan Lu; Nanning Zheng,~Tao_Yang9; ~Yuwang_Wang3; ~Yan_Lu7; ~Nanning_Zheng1,"{'value': ['Diffusion Probabilistic Model', 'Disentangled representation']}","{'value': 'Targeting to understand the underlying explainable factors behind observations and modeling the conditional generation process on these factors, we connect disentangled representation learning to diffusion probabilistic models (DPMs) to take advantage of the remarkable modeling ability of DPMs. We propose a new task, disentanglement of (DPMs): given a pre-trained DPM, without any annotations of the factors, the task is to automatically discover the inherent factors behind the observations and disentangle the gradient fields of DPM into sub-gradient fields, each conditioned on the representation of each discovered factor. With disentangled DPMs, those inherent factors can be automatically discovered, explicitly represented and clearly injected into the diffusion process via the sub-gradient fields. To tackle this task, we devise an unsupervised approach, named DisDiff, and for the first time achieving disentangled representation learning in the framework of DPMs. Extensive experiments on synthetic and real-world datasets demonstrate the effectiveness of DisDiff.'}",https://openreview.net{'value': '/pdf/683e70172dd9704b718e53396ddefd2b1961f139.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=3aVZhMfsyz,{'value': 'Volume Feature Rendering for Fast Neural Radiance Field Reconstruction'},Kang Han; Wei Xiang; Lu Yu,~Kang_Han1; ~Wei_Xiang3; ~Lu_Yu8,"{'value': ['neural rendering', 'volume rendering', 'view synthesis', '3D reconstruction']}","{'value': ""Neural radiance fields (NeRFs) are able to synthesize realistic novel views from multi-view images captured from distinct positions and perspectives. In NeRF's rendering pipeline, neural networks are used to represent a scene independently or transform queried learnable feature vector of a point to the expected color or density. With the aid of geometry guides either in the form of occupancy grids or proposal networks, the number of color neural network evaluations can be reduced from hundreds to dozens in the standard volume rendering framework. However, many evaluations of the color neural network are still a bottleneck for fast NeRF reconstruction. This paper revisits volume feature rendering (VFR) for the purpose of fast NeRF reconstruction. The VFR integrates the queried feature vectors of a ray into one feature vector, which is then transformed to the final pixel color by a color neural network. This fundamental change to the standard volume rendering framework requires only one single color neural network evaluation to render a pixel, which substantially lowers the high computational complexity of the rendering framework attributed to a large number of color neural network evaluations. Consequently, we can use a comparably larger color neural network to achieve a better rendering quality while maintaining the same training and rendering time costs. This approach achieves the state-of-the-art rendering quality on both synthetic and real-world datasets while requiring less training time compared with existing methods.""}",https://openreview.net{'value': '/pdf/65167de68d479f9dcdf6649dfce464afa6e3dd01.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=3X2EbBLNsk,{'value': 'Birth of a Transformer: A Memory Viewpoint'},Alberto Bietti; Vivien Cabannes; Diane Bouchacourt; Herve Jegou; Leon Bottou,~Alberto_Bietti1; ~Vivien_Cabannes1; ~Diane_Bouchacourt3; ~Herve_Jegou1; ~Leon_Bottou1,"{'value': ['transformers', 'language models', 'deep learning theory', 'interpretability']}","{'value': 'Large language models based on transformers have achieved great empirical successes. However, as they are deployed more widely, there is a growing need to better understand their internal mechanisms in order to make them more reliable. These models appear to store vast amounts of knowledge from their training data, and to adapt quickly to new information provided in their context or prompt. We study how transformers balance these two types of knowledge by considering a synthetic setup where tokens are generated from either global or context-specific bigram distributions. By a careful empirical analysis of the training process on a simplified two-layer transformer, we illustrate the fast learning of global bigrams and the slower development of an ""induction head"" mechanism for the in-context bigrams. We highlight the role of weight matrices as associative memories, provide theoretical insights on how gradients enable their learning during training, and study the role of data-distributional properties.'}",https://openreview.net{'value': '/pdf/18f0a07370deb3c1db84a94f1c73ee9d3a2bd72c.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=3WAnGWLpSQ,{'value': 'Why Does Sharpness-Aware Minimization Generalize Better Than SGD?'},Zixiang Chen; Junkai Zhang; Yiwen Kou; Xiangning Chen; Cho-Jui Hsieh; Quanquan Gu,~Zixiang_Chen1; ~Junkai_Zhang2; ~Yiwen_Kou1; ~Xiangning_Chen1; ~Cho-Jui_Hsieh1; ~Quanquan_Gu1,"{'value': ['Sharpness Aware Algorithm', 'Deep Learning Theory']}","{'value': 'The challenge of overfitting, in which the model memorizes the training data and fails to generalize to test data, has become increasingly significant in the training of large neural networks. To tackle this challenge, Sharpness-Aware Minimization (SAM) has emerged as a promising training method, which can improve the generalization of neural networks even in the presence of label noise. However, a deep understanding of how SAM works, especially in the setting of nonlinear neural networks and classification tasks, remains largely missing. This paper fills this gap by demonstrating why SAM generalizes better than Stochastic Gradient Descent (SGD) for a certain data model and two-layer convolutional ReLU networks. The loss landscape of our studied problem is nonsmooth, thus current explanations for the success of SAM based on the Hessian information are insufficient. Our result explains the benefits of SAM, particularly its ability to prevent noise learning in the early stages, thereby facilitating more effective learning of features. Experiments on both synthetic and real data corroborate our theory.'}",https://openreview.net{'value': '/pdf/e01bc91c4b9c7d10e417e796d3e9a604a98bac39.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=3NWWgB2SuF,{'value': 'Undirected Probabilistic Model for Tensor Decomposition'},Zerui Tao; Toshihisa Tanaka; Qibin Zhao,~Zerui_Tao1; tanakat@cc.tuat.ac.jp; ~Qibin_Zhao1,"{'value': ['Tensor decomposition', 'tensor completion', 'probabilistic methods']}","{'value': 'Tensor decompositions (TDs) serve as a powerful tool for analyzing multiway data. Traditional TDs incorporate prior knowledge about the data into the model, such as a directed generative process from latent factors to observations. In practice, selecting proper structural or distributional assumptions beforehand is crucial for obtaining a promising TD representation. However, since such prior knowledge is typically unavailable in real-world applications, choosing an appropriate TD model can be challenging. This paper aims to address this issue by introducing a flexible TD framework that discards the structural and distributional assumptions, in order to learn as much information from the data. Specifically, we construct a TD model that captures the joint probability of the data and latent tensor factors through a deep energy-based model (EBM). Neural networks are then employed to parameterize the joint energy function of tensor factors and tensor entries. The flexibility of EBM and neural networks enables the learning of underlying structures and distributions. In addition, by designing the energy function, our model unifies the learning process of different types of tensors, such as static tensors and dynamic tensors with time stamps. The resulting model presents a doubly intractable nature due to the presence of latent tensor factors and the unnormalized probability function. To efficiently train the model, we derive a variational upper bound of the conditional noise-contrastive estimation objective that learns the unnormalized joint probability by distinguishing data from conditional noises. We show advantages of our model on both synthetic and several real-world datasets.'}",https://openreview.net{'value': '/pdf/88817bcc103246e157e373b2236a5a0f38cbd643.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=3IyL2XWDkG,"{'value': 'CAMEL: Communicative Agents for ""Mind"" Exploration of Large Language Model Society'}",Guohao Li; Hasan Abed Al Kader Hammoud; Hani Itani; Dmitrii Khizbullin; Bernard Ghanem,~Guohao_Li1; ~Hasan_Abed_Al_Kader_Hammoud1; ~Hani_Itani1; ~Dmitrii_Khizbullin2; ~Bernard_Ghanem1,"{'value': ['Communicative Agents', 'Large Language Models', 'AI Society', 'Role-Playing', 'Society of Mind']}","{'value': 'The rapid advancement of chat-based language models has led to remarkable progress in complex task-solving. However, their success heavily relies on human input to guide the conversation, which can be challenging and time-consuming. This paper explores the potential of building scalable techniques to facilitate autonomous cooperation among communicative agents, and provides insight into their “cognitive” processes. To address the challenges of achieving autonomous cooperation, we propose a novel communicative agent framework named role-playing . Our approach involves using inception prompting to guide chat agents toward task completion while maintaining consistency with human intentions. We showcase how role-playing can be used to generate conversational data for studying the behaviors and capabilities of a society of agents, providing a valuable resource for investigating conversational language models. In particular, we conduct comprehensive studies on instruction-following cooperation in multi-agent settings. Our contributions include introducing a novel communicative agent framework, offering a scalable approach for studying the cooperative behaviors and capabilities of multi-agent systems, and open-sourcing our library to support research on communicative agents and beyond: https://github.com/camel-ai/camel.'}",https://openreview.net{'value': '/pdf/c3b30e69a77284c793251816c4fb2ce742d1696a.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=3Fc9gnR0fa,{'value': 'Neural Frailty Machine: Beyond proportional hazard assumption in neural survival regressions'},Ruofan Wu; Jiawei Qiao; Mingzhe Wu; Wen Yu; Ming Zheng; Tengfei LIU; Tianyi Zhang; Weiqiang Wang,~Ruofan_Wu1; ~Jiawei_Qiao1; ~Mingzhe_Wu1; ~Wen_Yu1; ~Ming_Zheng1; ~Tengfei_LIU2; ~Tianyi_Zhang5; ~Weiqiang_Wang4,"{'value': ['Survival Analysis', 'Theory', 'Semiparametric statistics']}","{'value': 'We present neural frailty machine (NFM), a powerful and flexible neural modeling framework for survival regressions. The NFM framework utilizes the classical idea of multiplicative frailty in survival analysis as a principled way of extending the proportional hazard assumption, at the same time being able to leverage the strong approximation power of neural architectures for handling nonlinear covariate dependence. Two concrete models are derived under the framework that extends neural proportional hazard models and nonparametric hazard regression models. Both models allow efficient training under the likelihood objective. Theoretically, for both proposed models, we establish statistical guarantees of neural function approximation with respect to nonparametric components via characterizing their rate of convergence. Empirically, we provide synthetic experiments that verify our theoretical statements. We also conduct experimental evaluations over $6$ benchmark datasets of different scales, showing that the proposed NFM models achieve predictive performance comparable to or sometimes surpassing state-of-the-art survival models. Our code is publicly availabel at https://github.com/Rorschach1989/nfm'}",https://openreview.net{'value': '/pdf/5d098edfd61024018a098101da38a620aba04480.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=35nFSbEBks,{'value': 'Equivariant Spatio-Temporal Attentive Graph Networks to Simulate Physical Dynamics'},Liming Wu; Zhichao Hou; Jirui Yuan; Yu Rong; Wenbing Huang,~Liming_Wu1; ~Zhichao_Hou1; ~Jirui_Yuan1; ~Yu_Rong1; ~Wenbing_Huang1,"{'value': ['Equivariance', 'Spatio-Temporal GNNs', 'Physical Dynamics']}","{'value': 'Learning to represent and simulate the dynamics of physical systems is a crucial yet challenging task. Existing equivariant Graph Neural Network (GNN) based methods have encapsulated the symmetry of physics, \\emph{e.g.}, translations, rotations, etc, leading to better generalization ability. Nevertheless, their frame-to-frame formulation of the task overlooks the non-Markov property mainly incurred by unobserved dynamics in the environment. In this paper, we reformulate dynamics simulation as a spatio-temporal prediction task, by employing the trajectory in the past period to recover the Non-Markovian interactions. We propose Equivariant Spatio-Temporal Attentive Graph Networks (ESTAG), an equivariant version of spatio-temporal GNNs, to fulfil our purpose. At its core, we design a novel Equivariant Discrete Fourier Transform (EDFT) to extract periodic patterns from the history frames, and then construct an Equivariant Spatial Module (ESM) to accomplish spatial message passing, and an Equivariant Temporal Module (ETM) with the forward attention and equivariant pooling mechanisms to aggregate temporal message. We evaluate our model on three real datasets corresponding to the molecular-, protein- and macro-level. Experimental results verify the effectiveness of ESTAG compared to typical spatio-temporal GNNs and equivariant GNNs.'}",https://openreview.net{'value': '/pdf/9a43ee0555ced98934e7749112b46dcdb684cbe5.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=2yXExAl0FW,{'value': 'A Diffusion-Model of Joint Interactive Navigation'},Matthew Niedoba; Jonathan Wilder Lavington; Yunpeng Liu; Vasileios Lioutas; Justice Sefas; Xiaoxuan Liang; Dylan Green; Setareh Dabiri; Berend Zwartsenberg; Adam Scibior; Frank Wood,~Matthew_Niedoba2; ~Jonathan_Wilder_Lavington1; ~Yunpeng_Liu1; ~Vasileios_Lioutas1; ~Justice_Sefas1; liang51@cs.ubc.ca; ~Dylan_Green1; ~Setareh_Dabiri1; ~Berend_Zwartsenberg1; ~Adam_Scibior1; ~Frank_Wood2,"{'value': ['Diffusion Models', 'Trajecotry Forecasting', 'Autonomous Vehicles', 'Motion Forecasting', 'Simulation']}","{'value': 'Simulation of autonomous vehicle systems requires that simulated traffic participants exhibit diverse and realistic behaviors. The use of prerecorded real-world traffic scenarios in simulation ensures realism but the rarity of safety critical events makes large scale collection of driving scenarios expensive. In this paper, we present DJINN -- a diffusion based method of generating traffic scenarios. Our approach jointly diffuses the trajectories of all agents, conditioned on a flexible set of state observations from the past, present, or future. On popular trajectory forecasting datasets, we report state of the art performance on joint trajectory metrics. In addition, we demonstrate how DJINN flexibly enables direct test-time sampling from a variety of valuable conditional distributions including goal-based sampling, behavior-class sampling, and scenario editing.'}",https://openreview.net{'value': '/pdf/ea1047dd7c9afc76331d002472119d941a5b8596.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=2URr3mkagy,{'value': 'Revisiting Implicit Differentiation for Learning Problems in Optimal Control'},Ming Xu; Timothy L Molloy; Stephen Gould,~Ming_Xu5; ~Timothy_L_Molloy1; ~Stephen_Gould1,"{'value': ['implicit differentiation', 'bi-level optimization; constrained learning and control; safe learning for control']}","{'value': 'This paper proposes a new method for differentiating through optimal trajectories arising from non-convex, constrained discrete-time optimal control (COC) problems using the implicit function theorem (IFT). Previous works solve a differential Karush-Kuhn-Tucker (KKT) system for the trajectory derivative, and achieve this efficiently by solving an auxiliary Linear Quadratic Regulator (LQR) problem. In contrast, we directly evaluate the matrix equations which arise from applying variable elimination on the Lagrange multiplier terms in the (differential) KKT system. By appropriately accounting for the structure of the terms within the resulting equations, we show that the trajectory derivatives scale linearly with the number of timesteps. Furthermore, our approach allows for easy parallelization, significantly improved scalability with model size, direct computation of vector-Jacobian products and improved numerical stability compared to prior works. As an additional contribution, we unify prior works, addressing claims that computing trajectory derivatives using IFT scales quadratically with the number of timesteps. We evaluate our method on a both synthetic benchmark and four challenging, learning from demonstration benchmarks including a 6-DoF maneuvering quadrotor and 6-DoF rocket powered landing.'}",https://openreview.net{'value': '/pdf/310ce30d729c0581af8e3d1a38f83fa7a92ad789.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=2SScUiWUbn,{'value': 'On the Connection between Pre-training Data Diversity and Fine-tuning Robustness'},Vivek Ramanujan; Thao Nguyen; Sewoong Oh; Ali Farhadi; Ludwig Schmidt,~Vivek_Ramanujan1; ~Thao_Nguyen3; ~Sewoong_Oh1; ~Ali_Farhadi3; ~Ludwig_Schmidt1,"{'value': ['robustness', 'out-of-distribution shifts', 'finetuning', 'pretraining']}","{'value': 'Pre-training has been widely adopted in deep learning to improve model performance, especially when the training data for a target task is limited. In our work, we seek to understand the implications of this training strategy on the generalization properties of downstream models. More specifically, we ask the following question: how do properties of the pre-training distribution affect the robustness of a fine-tuned model? The properties we explore include the label space, label semantics, image diversity, data domains, and data quantity of the pre-training distribution. We find that the primary factor influencing downstream effective robustness (Taori et al., 2020) is data quantity, while other factors have limited significance. For example, reducing the number of ImageNet pre-training classes by 4x while increasing the number of images per class by 4x (that is, keeping total data quantity fixed) does not impact the robustness of fine-tuned models. We demonstrate our findings on pre-training distributions drawn from various natural and synthetic data sources, primarily using the iWildCam-WILDS distribution shift as a test for robustness.'}",https://openreview.net{'value': '/pdf/c7cf28bbf8c9a2d7186940e7790123eb7e5ddb5b.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=2OcNWFHFpk,{'value': 'Group Robust Classification Without Any Group Information'},Christos Tsirigotis; Joao Monteiro; Pau Rodriguez; David Vazquez; Aaron Courville,~Christos_Tsirigotis1; ~Joao_Monteiro1; ~Pau_Rodriguez2; ~David_Vazquez1; ~Aaron_Courville3,"{'value': ['out-of-distribution generalization', 'robustness', 'fairness', 'spurious correlations', 'systematic generalization', 'model selection']}","{'value': 'Empirical risk minimization (ERM) is sensitive to spurious correlations present in training data, which poses a significant risk when deploying systems trained under this paradigm in high-stake applications. While the existing literature focuses on maximizing group-balanced or worst-group accuracy, estimating these quantities is hindered by costly bias annotations. This study contends that current bias-unsupervised approaches to group robustness continue to rely on group information to achieve optimal performance. Firstly, these methods implicitly assume that all group combinations are represented during training. To illustrate this, we introduce a systematic generalization task on the MPI3D dataset and discover that current algorithms fail to improve the ERM baseline when combinations of observed attribute values are missing. Secondly, bias labels are still crucial for effective model selection, restricting the practicality of these methods in real-world scenarios. To address these limitations, we propose a revised methodology for training and validating debiased models in an entirely bias-unsupervised manner. We achieve this by employing pretrained self-supervised models to reliably extract bias information, which enables the integration of a logit adjustment training loss with our validation criterion. Our empirical analysis on synthetic and real-world tasks provides evidence that our approach overcomes the identified challenges and consistently enhances robust accuracy, attaining performance which is competitive with or outperforms that of state-of-the-art methods, which, conversely, rely on bias labels for validation.'}",https://openreview.net{'value': '/pdf/fe4ca36a8baa8d188cd36e368aff44610b1fd98e.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=2BpoGPSDCR,{'value': 'Solving Inverse Physics Problems with Score Matching'},Benjamin Holzschuh; Simona Vegetti; Nils Thuerey,~Benjamin_Holzschuh1; ~Simona_Vegetti1; ~Nils_Thuerey1,"{'value': ['inverse problems', 'diffusion models', 'learned corrections', 'score matching']}","{'value': ""We propose to solve inverse problems involving the temporal evolution of physics systems by leveraging recent advances from diffusion models. \nOur method moves the system's current state backward in time step by step by combining an approximate inverse physics simulator and a learned correction function. \nA central insight of our work is that training the learned correction with a single-step loss is equivalent to a score matching objective, while recursively predicting longer parts of the trajectory during training relates to maximum likelihood training of a corresponding probability flow.\nWe highlight the advantages of our algorithm compared to standard denoising score matching and implicit score matching, as well as fully learned baselines for a wide range of inverse physics problems. The resulting inverse solver has excellent accuracy and temporal stability and, in contrast to other learned inverse solvers, allows for sampling the posterior of the solutions. Code and experiments are available at https://github.com/tum-pbs/SMDP.""}",https://openreview.net{'value': '/pdf/e14d868c93d4bb63690c02fd9c5fcb4f28eed65c.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=1wOkHN9JK8,{'value': 'Hierarchical VAEs provide a normative account of motion processing in the primate brain'},Hadi Vafaii; Jacob L. Yates; Daniel A. Butts,~Hadi_Vafaii1; ~Jacob_L._Yates1; ~Daniel_A._Butts1,"{'value': ['NeuroAI', 'VAE', 'Dorsal stream', 'Hierarchical Bayesian Inference']}","{'value': ""The relationship between perception and inference, as postulated by Helmholtz in the 19th century, is paralleled in modern machine learning by generative models like Variational Autoencoders (VAEs) and their hierarchical variants. Here, we evaluate the role of hierarchical inference and its alignment with brain function in the domain of motion perception. We first introduce a novel synthetic data framework, Retinal Optic Flow Learning (ROFL), which enables control over motion statistics and their causes. We then present a new hierarchical VAE and test it against alternative models on two downstream tasks: (i) predicting ground truth causes of retinal optic flow (e.g., self-motion); and (ii) predicting the responses of neurons in the motion processing pathway of primates. We manipulate the model architectures (hierarchical versus non-hierarchical), loss functions, and the causal structure of the motion stimuli. We find that hierarchical latent structure in the model leads to several improvements. First, it improves the linear decodability of ground truth variables and does so in a sparse and disentangled manner. Second, our hierarchical VAE outperforms previous state-of-the-art models in predicting neuronal responses and exhibits sparse latent-to-neuron relationships. These results depend on the causal structure of the world, indicating that alignment between brains and artificial neural networks depends not only on architecture but also on matching ecologically relevant stimulus statistics. Taken together, our results suggest that hierarchical Bayesian inference underlines the brain's understanding of the world, and hierarchical VAEs can effectively model this understanding.""}",https://openreview.net{'value': '/pdf/d86d8927876b4a47e56df68b2796a5fbc2f191c7.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=1pWNhmbllE,{'value': 'Uncertainty-Aware Instance Reweighting for Off-Policy Learning'},Xiaoying Zhang; Junpu Chen; Hongning Wang; Hong Xie; Yang Liu; John C.S. Lui; Hang Li,~Xiaoying_Zhang3; ~Junpu_Chen1; ~Hongning_Wang1; ~Hong_Xie2; ~Yang_Liu3; ~John_C.S._Lui2; ~Hang_Li4,"{'value': ['off-policy learning', 'uncertainty']}","{'value': 'Off-policy learning, referring to the procedure of policy optimization with access only to logged feedback data, has shown importance in various important real-world applications, such as search engines and recommender systems. While the ground-truth logging policy is usually unknown, previous work simply takes its estimated value for the off-policy learning, ignoring the negative impact from both high bias and high variance resulted from such an estimator. And these impact is often magnified on samples with small and inaccurately estimated logging probabilities. The contribution of this work is to explicitly model the uncertainty in the estimated logging policy, and propose an Uncertainty-aware Inverse Propensity Score estimator (UIPS) for improved off-policy learning, with a theoretical convergence guarantee. Experiment results on the synthetic and real-world recommendation datasets demonstrate that UIPS significantly improves the quality of the discovered policy, when compared against an extensive list of state-of-the-art baselines.'}",https://openreview.net{'value': '/pdf/8210f388161a56af7a203e3c3524972a1dd46490.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=1aQivXgZKj,{'value': 'Incentivized Communication for Federated Bandits'},Zhepei Wei; Chuanhao Li; Haifeng Xu; Hongning Wang,~Zhepei_Wei1; ~Chuanhao_Li1; ~Haifeng_Xu1; ~Hongning_Wang1,"{'value': ['contextual bandit', 'federated learning', 'incentive mechanism']}","{'value': 'Most existing works on federated bandits take it for granted that all clients are altruistic about sharing their data with the server for the collective good whenever needed. Despite their compelling theoretical guarantee on performance and communication efficiency, this assumption is overly idealistic and oftentimes violated in practice, especially when the algorithm is operated over self-interested clients, who are reluctant to share data without explicit benefits. Negligence of such self-interested behaviors can significantly affect the learning efficiency and even the practical operability of federated bandit learning. In light of this, we aim to spark new insights into this under-explored research area by formally introducing an incentivized communication problem for federated bandits, where the server shall motivate clients to share data by providing incentives. Without loss of generality, we instantiate this bandit problem with the contextual linear setting and propose the first incentivized communication protocol, namely, Inc-FedUCB, that achieves near-optimal regret with provable communication and incentive cost guarantees. Extensive empirical experiments on both synthetic and real-world datasets further validate the effectiveness of the proposed method across various environments.'}",https://openreview.net{'value': '/pdf/c0c3b8608c65cee25d021fea25e4461833b0b7b0.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=1B6YKnHYBb,{'value': 'De novo Drug Design using Reinforcement Learning with Multiple GPT Agents'},Xiuyuan Hu; Guoqing Liu; Yang Zhao; Hao Zhang,~Xiuyuan_Hu1; ~Guoqing_Liu3; ~Yang_Zhao11; ~Hao_Zhang37,"{'value': ['De novo drug design', 'Molecular generation', 'Multi-agent reinforcement learning', 'GPT']}","{'value': '*De novo* drug design is a pivotal issue in pharmacology and a new area of focus in AI for science research. A central challenge in this field is to generate molecules with specific properties while also producing a wide range of diverse candidates. Although advanced technologies such as transformer models and reinforcement learning have been applied in drug design, their potential has not been fully realized. Therefore, we propose MolRL-MGPT, a reinforcement learning algorithm with multiple GPT agents for drug molecular generation. To promote molecular diversity, we encourage the agents to collaborate in searching for desirable molecules in diverse directions. Our algorithm has shown promising results on the GuacaMol benchmark and exhibits efficacy in designing inhibitors against SARS-CoV-2 protein targets. The codes are available at: https://github.com/HXYfighter/MolRL-MGPT.'}",https://openreview.net{'value': '/pdf/3cf70b69e2cd6d8f3c8af683c2c8d837a2cab930.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=19AgWnmyoV,{'value': 'Instructing Goal-Conditioned Reinforcement Learning Agents with Temporal Logic Objectives'},Wenjie Qiu; Wensen Mao; He Zhu,~Wenjie_Qiu1; wm300@cs.rutgers.edu; ~He_Zhu4,"{'value': ['Goal-Conditioned Reinforcement Learning', 'Linear Temporal Logic']}","{'value': 'Goal-conditioned reinforcement learning (RL) is a powerful approach for learning general-purpose skills by reaching diverse goals. However, it has limitations when it comes to task-conditioned policies, where goals are specified by temporally extended instructions written in the Linear Temporal Logic (LTL) formal language. Existing approaches for finding LTL-satisfying policies rely on sampling a large set of LTL instructions during training to adapt to unseen tasks at inference time. However, these approaches do not guarantee generalization to out-of-distribution LTL objectives, which may have increased complexity. In this paper, we propose a novel approach to address this challenge. We show that simple goal-conditioned RL agents can be instructed to follow arbitrary LTL specifications without additional training over the LTL task space. Unlike existing approaches that focus on LTL specifications expressible as regular expressions, our technique is unrestricted and generalizes to $\\omega$-regular expressions. Experiment results demonstrate the effectiveness of our approach in adapting goal-conditioned RL agents to satisfy complex temporal logic task specifications zero-shot.'}",https://openreview.net{'value': '/pdf/acf92fe710e42dab207c1c717abf1ebcdef65091.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=0rVXQEeFEL,{'value': 'Transformer-based Planning for Symbolic Regression'},Parshin Shojaee; Kazem Meidani; Amir Barati Farimani; Chandan K. Reddy,~Parshin_Shojaee1; ~Kazem_Meidani1; ~Amir_Barati_Farimani2; ~Chandan_K._Reddy1,"{'value': ['Symbolic Regression', 'Transformers', 'Planning', 'Deep Learning']}","{'value': ""Symbolic regression (SR) is a challenging task in machine learning that involves finding a mathematical expression for a function based on its values. Recent advancements in SR have demonstrated the effectiveness of pre-trained transformer models in generating equations as sequences, leveraging large-scale pre-training on synthetic datasets and offering notable advantages in terms of inference time over classical Genetic Programming (GP) methods. However, these models primarily rely on supervised pre-training objectives borrowed from text generation and overlook equation discovery goals like accuracy and complexity. To address this, we propose TPSR, a Transformer-based Planning strategy for Symbolic Regression that incorporates Monte Carlo Tree Search planning algorithm into the transformer decoding process. Unlike conventional decoding strategies, TPSR enables the integration of non-differentiable equation verification feedback, such as fitting accuracy and complexity, as external sources of knowledge into the transformer equation generation process. Extensive experiments on various datasets show that our approach outperforms state-of-the-art methods, enhancing the model's fitting-complexity trade-off, extrapolation abilities, and robustness to noise.""}",https://openreview.net{'value': '/pdf/758ab88ee6b6c59b9c8f107773d07abacb03fec5.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=0OImBCFsdf,{'value': 'SaVeNet: A Scalable Vector Network for Enhanced Molecular Representation Learning'},Sarp Aykent; Tian Xia,~Sarp_Aykent1; ~Tian_Xia10,"{'value': ['geometric deep learning', 'molecule property prediction', 'geometric representation learning']}","{'value': ""Geometric representation learning of molecules is challenging yet essential for applications in multiple domains. Despite the impressive breakthroughs made by geometric deep learning in various molecular representation learning tasks, effectively capturing complicated geometric features across spatial dimensions is still underexplored due to the significant difficulties in modeling efficient geometric representations and learning the inherent correlation in 3D structural modeling. These include computational inefficiency, underutilization of vectorial embeddings, and limited generalizability to integrate various geometric properties. To address the raised concerns, we introduce an efficient and effective framework, Scalable Vector Network (SaVeNet), designed to accommodate a range of geometric requirements without depending on costly embeddings. In addition, the proposed framework scales effectively with introduced direction noise. Theoretically, we analyze the desired properties (i.e., invariance and equivariant) and framework efficiency of the SaVeNet. Empirically, we conduct a comprehensive series of experiments to evaluate the efficiency and expressiveness of the proposed model. Our efficiency-focused experiments underscore the model's empirical superiority over existing methods. Experimental results on synthetic and real-world datasets demonstrate the expressiveness of our model, which achieves state-of-the-art performance across various tasks within molecular representation learning.""}",https://openreview.net{'value': '/pdf/e1fe16876b7b9e591d904ef1f22f8e134a707b44.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=0Iw2dLh8uq,{'value': 'Multi-Agent Meta-Reinforcement Learning: Sharper Convergence Rates with Task Similarity'},Weichao Mao; Haoran Qiu; Chen Wang; Hubertus Franke; Zbigniew Kalbarczyk; Ravi Iyer; Tamer Basar,~Weichao_Mao1; ~Haoran_Qiu1; ~Chen_Wang17; ~Hubertus_Franke1; ~Zbigniew_Kalbarczyk1; ~Ravi_Iyer1; ~Tamer_Basar1,"{'value': ['Reinforcement learning', 'game theory', 'multi-agent systems', 'meta-learning']}","{'value': 'Multi-agent reinforcement learning (MARL) has primarily focused on solving a single task in isolation, while in practice the environment is often evolving, leaving many related tasks to be solved. In this paper, we investigate the benefits of meta-learning in solving multiple MARL tasks collectively. We establish the first line of theoretical results for meta-learning in a wide range of fundamental MARL settings, including learning Nash equilibria in two-player zero-sum Markov games and Markov potential games, as well as learning coarse correlated equilibria in general-sum Markov games. Under natural notions of task similarity, we show that meta-learning achieves provable sharper convergence to various game-theoretical solution concepts than learning each task separately. As an important intermediate step, we develop multiple MARL algorithms with initialization-dependent convergence guarantees. Such algorithms integrate optimistic policy mirror descents with stage-based value updates, and their refined convergence guarantees (nearly) recover the best known results even when a good initialization is unknown. To our best knowledge, such results are also new and might be of independent interest. We further provide numerical simulations to corroborate our theoretical findings.'}",https://openreview.net{'value': '/pdf/04e42cc67993cd613b562cae3dd21418ffcad371.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=0BwB03qA5T,{'value': 'Gaussian Process Probes (GPP) for Uncertainty-Aware Probing'},Zi Wang; Alexander Ku; Jason Michael Baldridge; Thomas L. Griffiths; Been Kim,~Zi_Wang1; ~Alexander_Ku1; ~Jason_Michael_Baldridge1; ~Thomas_L._Griffiths1; ~Been_Kim1,"{'value': ['Interpretability', 'probing', 'Bayesian', 'Gaussian process', 'transparency']}","{'value': ""Understanding which concepts models can and cannot represent has been fundamental to many tasks: from effective and responsible use of models to detecting out of distribution data. We introduce Gaussian process probes (GPP), a unified and simple framework for probing and measuring uncertainty about concepts represented by models. As a Bayesian extension of linear probing methods, GPP asks what kind of distribution over classifiers (of concepts) is induced by the model. This distribution can be used to measure both what the model represents and how confident the probe is about what the model represents.  GPP can be applied to any pre-trained  model with vector representations of inputs (e.g., activations). It does not require access to training data, gradients, or the architecture. We validate GPP on datasets containing both synthetic and real images. Our experiments show it can (1) probe a model's representations of concepts even with a very small number of examples, (2) accurately measure both epistemic uncertainty (how confident the probe is) and aleatory uncertainty (how fuzzy the concepts are to the model), and (3) detect out of distribution data using those uncertainty measures as well as classic methods do. By using Gaussian processes to expand what probing can offer, GPP provides a data-efficient, versatile and uncertainty-aware tool for understanding and evaluating the capabilities of machine learning models.""}",https://openreview.net{'value': '/pdf/cd744f7de4b5c6cbb69d1de38aaaa494e02fd70c.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=zfHCKDzzC8,{'value': 'Temporal Causal Mediation through a Point Process: Direct and Indirect Effects of Healthcare Interventions'},Çağlar Hızlı; S. T. John; Anne Tuulikki Juuti; Tuure Tapani Saarinen; Kirsi Hannele Pietiläinen; Pekka Marttinen,~Çağlar_Hızlı1; ~S._T._John1; ~Anne_Tuulikki_Juuti1; ~Tuure_Tapani_Saarinen1; ~Kirsi_Hannele_Pietiläinen1; ~Pekka_Marttinen1,"{'value': ['Machine learning for healthcare', 'Causal mediation', 'Gaussian process', 'Point Process']}","{'value': 'Deciding on an appropriate intervention requires a causal model of a treatment, the outcome, and potential mediators. Causal mediation analysis lets us distinguish between direct and indirect effects of the intervention, but has mostly been studied in a static setting. In healthcare, data come in the form of complex, irregularly sampled time-series, with dynamic interdependencies between a treatment, outcomes, and mediators across time. Existing approaches to dynamic causal mediation analysis are limited to regular measurement intervals, simple parametric models, and disregard long-range mediator--outcome interactions. To address these limitations, we propose a non-parametric mediator--outcome model where the mediator is assumed to be a temporal point process that interacts with the outcome process. With this model, we estimate the direct and indirect effects of an external intervention on the outcome, showing how each of these affects the whole future trajectory. We demonstrate on semi-synthetic data that our method can accurately estimate direct and indirect effects. On real-world healthcare data, our model infers clinically  meaningful direct and indirect effect trajectories for blood glucose after a surgery.'}",https://openreview.net{'value': '/pdf/7e09e1cae897c85d00abebac0e52fd9c4ee38c16.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=zTSlm4nmlH,{'value': 'Beta Diffusion'},Mingyuan Zhou; Tianqi Chen; Zhendong Wang; Huangjie Zheng,~Mingyuan_Zhou1; ~Tianqi_Chen2; ~Zhendong_Wang1; ~Huangjie_Zheng1,"{'value': ['Diffusion models', 'KL-divergence upper bounds', 'multiplicative transitions', 'scaled and shifted beta distributions']}","{'value': 'We introduce beta diffusion, a novel generative modeling method that integrates demasking and denoising to generate data within bounded ranges. Using scaled and shifted beta distributions, beta diffusion utilizes multiplicative transitions over time to create both forward and reverse diffusion processes, maintaining beta distributions in both the forward marginals and the reverse conditionals, given the data at any point in time. Unlike traditional diffusion-based generative models relying on additive Gaussian noise and reweighted evidence lower bounds (ELBOs), beta diffusion is multiplicative and optimized with KL-divergence upper bounds (KLUBs) derived from the convexity of the KL divergence. We demonstrate that the proposed KLUBs are more effective for optimizing beta diffusion compared to negative ELBOs, which can also be derived as the KLUBs of the same KL divergence with its two arguments swapped. The loss function of beta diffusion, expressed in terms of Bregman divergence, further supports the efficacy of KLUBs for optimization. Experimental results on both synthetic data and natural images demonstrate the unique capabilities of beta diffusion in generative modeling of range-bounded data and validate the effectiveness of KLUBs in optimizing diffusion models, thereby making them valuable additions to the family of diffusion-based generative models and the optimization techniques used to train them.'}",https://openreview.net{'value': '/pdf/d4b29b4b0595a2c7b5a6d76a12d631ccec860487.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=z3HACY5CMa,{'value': 'Joint Learning of Label and Environment Causal Independence for Graph Out-of-Distribution Generalization'},Shurui Gui; Meng Liu; Xiner Li; Youzhi Luo; Shuiwang Ji,~Shurui_Gui1; ~Meng_Liu3; ~Xiner_Li1; ~Youzhi_Luo1; ~Shuiwang_Ji1,"{'value': ['deep learning', 'graph neural network', 'out-of-distribution generalization', 'distribution shift']}","{'value': 'We tackle the problem of graph out-of-distribution (OOD) generalization. Existing graph OOD algorithms either rely on restricted assumptions or fail to exploit environment information in training data. In this work, we propose to simultaneously incorporate label and environment causal independence (LECI) to fully make use of label and environment information, thereby addressing the challenges faced by prior methods on identifying causal and invariant subgraphs. We further develop an adversarial training strategy to jointly optimize these two properties for casual subgraph discovery with theoretical guarantees. Extensive experiments and analysis show that LECI significantly outperforms prior methods on both synthetic and real-world datasets, establishing LECI as a practical and effective solution for graph OOD generalization.'}",https://openreview.net{'value': '/pdf/739501273cf8778ff3b32363ed12844b23b6fa7f.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=ykvvv0gc4R,{'value': 'Deep Momentum Multi-Marginal Schrödinger Bridge'},Tianrong Chen; Guan-Horng Liu; Molei Tao; Evangelos Theodorou,~Tianrong_Chen1; ~Guan-Horng_Liu1; ~Molei_Tao1; ~Evangelos_Theodorou1,"{'value': ['Schrödinger Bridge', 'Trajectory Inference', 'Optimal Transport']}","{'value': 'It is a crucial challenge to reconstruct population dynamics using unlabeled samples from distributions at coarse time intervals. Recent approaches such as flow-based models or Schrödinger Bridge (SB) models have demonstrated appealing performance, yet the inferred sample trajectories either fail to account for the underlying stochasticity or are unnecessarily rigid. In this article, we extend SB into phase space and propose $\\underline{D}$eep $\\underline{M}$omentum Multi-Marginal $\\underline{S}$chrödinger $\\underline{B}$ridge (DMSB), a novel computational framework that learns the smooth measure-valued spline for stochastic systems that satisfy position marginal constraints across time. By tailoring the celebrated Bregman Iteration and extending the Iteration Proportional Fitting to phase space, we manage to handle high-dimensional multi-marginal trajectory inference tasks efficiently. Our algorithm outperforms baselines significantly, as evidenced by experiments for synthetic datasets and a real-world single-cell RNA sequence dataset. Additionally, the proposed approach can reasonably reconstruct the evolution of velocity distribution, from position snapshots only, when there is a ground truth velocity that is nevertheless inaccessible.'}",https://openreview.net{'value': '/pdf/59558d952f4964c1facdd4fb8983abae319685e1.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=ykMdzevPkJ,{'value': 'DiffTraj: Generating GPS Trajectory with Diffusion Probabilistic Model'},Yuanshao Zhu; Yongchao Ye; Shiyao Zhang; Xiangyu Zhao; James Yu,~Yuanshao_Zhu1; ~Yongchao_Ye1; zhangsy@sustech.edu.cn; ~Xiangyu_Zhao1; ~James_Yu1,"{'value': ['Trajectory Generation', 'Diffusion Model', 'Urban Computing', 'Spatial-temporal Data Mining']}","{'value': 'Pervasive integration of GPS-enabled devices and data acquisition technologies has led to an exponential increase in GPS trajectory data, fostering advancements in spatial-temporal data mining research. Nonetheless, GPS trajectories contain personal geolocation information, rendering serious privacy concerns when working with raw data. A promising approach to address this issue is trajectory generation, which involves replacing original data with generated, privacy-free alternatives. Despite the potential of trajectory generation, the complex nature of human behavior and its inherent stochastic characteristics pose challenges in generating high-quality trajectories. \nIn this work, we propose a spatial-temporal diffusion probabilistic model for trajectory generation (DiffTraj). This model effectively combines the generative abilities of diffusion models with the spatial-temporal features derived from real trajectories. The core idea is to reconstruct and synthesize geographic trajectories from white noise through a reverse trajectory denoising process. Furthermore, we propose a Trajectory UNet (Traj-UNet) deep neural network to embed conditional information and accurately estimate noise levels during the reverse process. Experiments on two real-world datasets show that DiffTraj can be intuitively applied to generate high-fidelity trajectories while retaining the original distributions. Moreover, the generated results can support downstream trajectory analysis tasks and significantly outperform other methods in terms of geo-distribution evaluations.'}",https://openreview.net{'value': '/pdf/f555cd65ef52c9b59703f6cfab7da2af81080ddb.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=yjWVd8Fhqt,{'value': 'OBJECT 3DIT: Language-guided 3D-aware Image Editing'},Oscar Michel; Anand Bhattad; Eli VanderBilt; Ranjay Krishna; Aniruddha Kembhavi; Tanmay Gupta,~Oscar_Michel1; ~Anand_Bhattad1; ~Eli_VanderBilt1; ~Ranjay_Krishna1; ~Aniruddha_Kembhavi1; ~Tanmay_Gupta1,"{'value': ['computer vision', 'image editing', 'generative modeling', 'diffusion models', '3D']}","{'value': 'Existing image editing tools, while powerful, typically disregard the underlying 3D geometry from which the image is projected. As a result, edits made using these tools may become detached from the geometry and lighting conditions that are at the foundation of the image formation process; such edits break the portrayal of a coherent 3D world. 3D-aware generative models are a promising solution, but currently only succeed on small datasets or at the level of a single object. In this work, we formulate the new task of language-guided 3D-aware editing, where objects in an image should be edited according to a language instruction while remaining consistent with the underlying 3D scene. To promote progress towards this goal, we release OBJect: a benchmark dataset of 400K editing examples created from procedurally generated 3D scenes. Each example consists of an input image, editing instruction in language, and the edited image. We also introduce 3DIT: single and multi-task models for four editing tasks. Our models show impressive abilities to understand the 3D composition of entire scenes, factoring in surrounding objects, surfaces, lighting conditions, shadows, and physically-plausible object configurations. Surprisingly, training on only synthetic scenes from \\dataset, editing capabilities of 3DIT generalize to real-world images.'}",https://openreview.net{'value': '/pdf/b286d9e4631400ea90d5604eaa4a0248245cbf95.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=yaJ4vZPnHX,{'value': 'Complexity of Derivative-Free Policy Optimization for Structured $\\mathcal{H}_\\infty$ Control'},Xingang Guo; Darioush Keivan; Geir Dullerud; Peter Seiler; Bin Hu,~Xingang_Guo1; ~Darioush_Keivan1; ~Geir_Dullerud1; ~Peter_Seiler1; ~Bin_Hu2,"{'value': ['Structured $\\mathcal{H}_\\infty$ Control', 'Nonsmooth Optimization', 'Complexity Analysis']}","{'value': 'The applications of direct policy search in reinforcement learning and continuous control have received increasing attention.\nIn this work, we present novel theoretical results on the complexity of derivative-free policy optimization on an important class of robust control tasks, namely the structured $H_\\infty$ synthesis with static output feedback. \nOptimal $H_\\infty$ synthesis under structural constraints leads to a constrained nonconvex nonsmooth problem and is typically\naddressed using subgradient-based policy search techniques that are built upon the concept of Goldstein subdifferential or other notions of enlarged subdifferential.  In this paper, we study the complexity of finding $(\\delta,\\epsilon)$-stationary points for such nonsmooth robust control design tasks using policy optimization methods which can only access the zeroth-order oracle (i.e. the $H_\\infty$ norm of the closed-loop system). First, we study the exact oracle setting and identify the coerciveness of the cost function to prove high-probability feasibility/complexity bounds for derivative-free policy optimization on this problem. Next, we derive a sample complexity result for the multi-input multi-output (MIMO)  $H_\\infty$-norm estimation. We combine this with our analysis to obtain the first sample complexity of model-free, trajectory-based, zeroth-order policy optimization on finding $(\\delta,\\epsilon)$-stationary points for structured $H_\\infty$ control. \nNumerical results are also provided to demonstrate our theory.'}",https://openreview.net{'value': '/pdf/f97f75e682742bda98fe92ae84f4229f89e88d8a.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=yVMlYSL1Bp,{'value': 'Diverse Shape Completion via Style Modulated Generative Adversarial Networks'},Wesley Khademi; Li Fuxin,~Wesley_Khademi1; ~Li_Fuxin1,"{'value': ['multimodal shape completion', 'point cloud completion', '3d shape generation', 'generative modeling', 'generative adversarial networks']}","{'value': 'Shape completion aims to recover the full 3D geometry of an object from a partial observation. This problem is inherently multi-modal since there can be many ways to plausibly complete the missing regions of a shape. Such diversity would be indicative of the underlying uncertainty of the shape and could be preferable for downstream tasks such as planning. In this paper, we propose a novel conditional generative adversarial network that can produce many diverse plausible completions of a partially observed point cloud. To enable our network to produce multiple completions for the same partial input, we introduce stochasticity into our network via style modulation. By extracting style codes from complete shapes during training, and learning a distribution over them, our style codes can explicitly carry shape category information leading to better completions. We further introduce diversity penalties and discriminators at multiple scales to prevent conditional mode collapse and to train without the need for multiple ground truth completions for each partial input. Evaluations across several synthetic and real datasets demonstrate that our method achieves significant improvements in respecting the partial observations while obtaining greater diversity in completions.'}",https://openreview.net{'value': '/pdf/f49032cc72d8735a4a08beb86cdce4932d3f2ab7.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=yN6NHZOXkg,{'value': 'Generalized Information-theoretic Multi-view Clustering'},Weitian Huang; Sirui Yang; Hongmin Cai,~Weitian_Huang1; ~Sirui_Yang1; ~Hongmin_Cai1,"{'value': ['information bottleneck', 'multi-view clustering', 'variational autoencoders']}","{'value': ""In an era of more diverse data modalities, multi-view clustering has become a fundamental tool for comprehensive data analysis and exploration. However, existing multi-view unsupervised learning methods often rely on strict assumptions on semantic consistency among samples. In this paper, we reformulate the multi-view clustering problem from an information-theoretic perspective and propose a general theoretical model. In particular, we define three desiderata under multi-view unsupervised learning in terms of mutual information, namely, comprehensiveness, concentration, and cross-diversity. The multi-view variational lower bound is then obtained by approximating the samples' high-dimensional mutual information. The Kullback–Leibler divergence is utilized to deduce sample assignments. Ultimately the information-based multi-view clustering model leverages deep neural networks and Stochastic Gradient Variational Bayes to achieve representation learning and clustering simultaneously. Extensive experiments on both synthetic and real datasets with wide types demonstrate that the proposed method exhibits a more stable and superior clustering performance than state-of-the-art algorithms.""}",https://openreview.net{'value': '/pdf/b58cdae08385db145c1d82f7d13788da501e82ab.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=yIcCkMUCtL,{'value': 'Towards a Unified Analysis of Kernel-based Methods Under Covariate Shift'},Xingdong Feng; Xin HE; Caixing Wang; Chao Wang; Jingnan Zhang,~Xingdong_Feng1; ~Xin_HE7; ~Caixing_Wang1; ~Chao_Wang39; ~Jingnan_Zhang1,"{'value': ['kernel methods', 'covariate shift', 'reproducing kernel Hilbert space (RKHS)']}","{'value': 'Covariate shift occurs prevalently in practice, where the input distributions of the source and target data are substantially different. Despite its practical importance in various learning problems, most of the existing methods only focus on some specific learning tasks and are not well validated theoretically and numerically. To tackle this problem, we propose a unified analysis of general nonparametric methods in a reproducing kernel Hilbert space (RKHS) under covariate shift.  Our theoretical results are established for a general loss belonging to a rich loss function family, which includes many commonly used methods as special cases, such as mean regression, quantile regression, likelihood-based classification, and margin-based classification. Two types of covariate shift problems are the focus of this paper and the sharp convergence rates are established for a general loss function to provide a unified theoretical analysis, which concurs with the optimal results in literature where the squared loss is used. Extensive numerical studies on synthetic and real examples confirm our theoretical findings and further illustrate the effectiveness of our proposed method.'}",https://openreview.net{'value': '/pdf/456e7e6bb36b1d4f84f11df855bcf424e2f1bfa1.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=yEfmhgwslQ,{'value': 'Encoding Time-Series Explanations through Self-Supervised Model Behavior Consistency'},Owen Queen; Thomas Hartvigsen; Teddy Koker; Huan He; Theodoros Tsiligkaridis; Marinka Zitnik,~Owen_Queen1; ~Thomas_Hartvigsen1; ~Teddy_Koker1; ~Huan_He2; ~Theodoros_Tsiligkaridis1; ~Marinka_Zitnik1,"{'value': ['Explainability', 'Interpretability', 'Time Series', 'Explanations', 'Temporal patterns', 'Model Understanding', 'Latent space', 'Self-supervised learning']}","{'value': 'Interpreting time series models is uniquely challenging because it requires identifying both the location of time series signals that drive model predictions and their matching to an interpretable temporal pattern. While explainers from other modalities can be applied to time series, their inductive biases do not transfer well to the inherently challenging interpretation of time series. We present TimeX, a time series consistency model for training explainers. TimeX trains an interpretable surrogate to mimic the behavior of a pretrained time series model. It addresses the issue of model faithfulness by introducing model behavior consistency, a novel formulation that preserves relations in the latent space induced by the pretrained model with relations in the latent space induced by TimeX. TimeX provides discrete attribution maps and, unlike existing interpretability methods, it learns a latent space of explanations that can be used in various ways, such as to provide landmarks to visually aggregate similar explanations and easily recognize temporal patterns. We evaluate TimeX on eight synthetic and real-world datasets and compare its performance against state-of-the-art interpretability methods. We also conduct case studies using physiological time series. Quantitative evaluations demonstrate that TimeX achieves the highest or second-highest performance in every metric compared to baselines across all datasets. Through case studies, we show that the novel components of TimeX show potential for training faithful, interpretable models that capture the behavior of pretrained time series models.'}",https://openreview.net{'value': '/pdf/6c929f4720cece2dbcfdb739210fda7a6e365afb.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=yEewbkBNzi,{'value': 'Convergence of Adam Under Relaxed Assumptions'},Haochuan Li; Alexander Rakhlin; Ali Jadbabaie,~Haochuan_Li2; ~Alexander_Rakhlin1; ~Ali_Jadbabaie1,"{'value': ['Non-convex optimization', 'Adam', 'Convergence', 'Variance reduction']}","{'value': 'In this paper, we provide a rigorous proof of convergence of the Adaptive Moment Estimate (Adam) algorithm for a wide class of optimization objectives. Despite the popularity and efficiency of the Adam algorithm in training deep neural networks, its theoretical properties are not yet fully understood, and existing convergence proofs require unrealistically strong assumptions, such as globally bounded gradients, to show the convergence to stationary points. In this paper, we show that Adam provably converges to $\\epsilon$-stationary points with $\\mathcal{O}(\\epsilon^{-4})$ gradient complexity under far more realistic conditions. The key to our analysis is a new proof of boundedness of gradients along the optimization trajectory of Adam, under a generalized smoothness assumption according to which the local smoothness (i.e., Hessian norm when it exists) is bounded by a sub-quadratic function of the gradient norm. Moreover, we propose a variance-reduced version of Adam with an accelerated gradient complexity of $\\mathcal{O}(\\epsilon^{-3})$.'}",https://openreview.net{'value': '/pdf/862f2a4fb941567e8c797e2c153beb10dddaba5d.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=y9U0IJ2uFr,{'value': 'SNEkhorn: Dimension Reduction with Symmetric Entropic Affinities'},Hugues Van Assel; Titouan Vayer; Rémi Flamary; Nicolas Courty,~Hugues_Van_Assel1; ~Titouan_Vayer1; ~Rémi_Flamary1; ~Nicolas_Courty1,"{'value': ['Dimension Reduction', 'Optimal Transport', 'Affinities']}","{'value': 'Many approaches in machine learning rely on a weighted graph to encode the\nsimilarities between samples in a dataset. Entropic affinities (EAs), which are notably used in the popular Dimensionality Reduction (DR) algorithm t-SNE, are particular instances of such graphs. To ensure robustness to heterogeneous sampling densities, EAs assign a kernel bandwidth parameter to every sample in such a way that the entropy of each row in the affinity matrix is kept constant at a specific value, whose exponential is known as perplexity. EAs are inherently asymmetric and row-wise stochastic, but they are used in DR approaches after undergoing heuristic symmetrization methods that violate both the row-wise constant entropy and stochasticity properties. In this work, we uncover a novel characterization of EA as an optimal transport problem, allowing a natural symmetrization that can be computed efficiently using dual ascent. \nThe corresponding novel affinity matrix derives advantages from symmetric doubly stochastic normalization in terms of clustering performance, while also effectively controlling the entropy of each row thus making it particularly robust to varying noise levels. Following, we present a new DR algorithm, SNEkhorn, that leverages this new affinity matrix. We show its clear superiority to state-of-the-art approaches with several indicators on both synthetic and real-world datasets.'}",https://openreview.net{'value': '/pdf/1befc2bb2ed5de53b2bb6b777d7586e4b12c382d.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=y0OlQSZsyp,{'value': 'Learning Causal Models under Independent Changes'},Sarah Mameche; David Kaltenpoth; Jilles Vreeken,~Sarah_Mameche1; ~David_Kaltenpoth1; ~Jilles_Vreeken2,"{'value': ['independent mechanisms', 'causal discovery', 'information theory', 'gaussian processes']}","{'value': 'In many scientific applications, we observe a system in different conditions in which its components may change, rather than in isolation. In our work, we are interested in explaining the generating process of such a multi-context system using a finite mixture of causal mechanisms. Recent work shows that this causal model is identifiable from data, but is limited to settings where the sparse mechanism shift hypothesis holds and only a subset of the causal conditionals change. As this assumption is not easily verifiable in practice, we study the more general principle that mechanism shifts are independent, which we formalize using the algorithmic notion of independence. We introduce an approach for causal discovery beyond partially directed graphs using Gaussian Process models, and give conditions under which we provably identify the correct causal model. In our experiments, we show that our method performs well in a range of synthetic settings, on realistic gene expression simulations, as well as on real-world cell signaling data.'}",https://openreview.net{'value': '/pdf/1feb2a4758bdbdaf2caa6dc39fbe0cfec877ce8c.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=xzmaFfw6oh,{'value': 'Molecule Joint Auto-Encoding: Trajectory Pretraining with 2D and 3D Diffusion'},weitao Du; Jiujiu Chen; Xuecang Zhang; Zhi-Ming Ma; Shengchao Liu,~weitao_Du1; ~Jiujiu_Chen1; ~Xuecang_Zhang1; ~Zhi-Ming_Ma1; ~Shengchao_Liu1,"{'value': ['Molecule Joint Auto-encoding', 'Molecule Joint Self-supervised Learning', 'Markov processes', 'contrastive learning', 'molecule representation learning']}","{'value': ""Recently, artificial intelligence for drug discovery has raised increasing interest in both machine learning and chemistry domains. The fundamental building block for drug discovery is molecule geometry and thus, the molecule's geometrical representation is the main bottleneck to better utilize machine learning techniques for drug discovery. In this work, we propose a pretraining method for molecule joint auto-encoding (MoleculeJAE). MoleculeJAE can learn both the 2D bond (topology) and 3D conformation (geometry) information, and a diffusion process model is applied to mimic the augmented trajectories of such two modalities, based on which, MoleculeJAE will learn the inherent chemical structure in a self-supervised manner. Thus, the pretrained geometrical representation in MoleculeJAE is expected to benefit downstream geometry-related tasks. Empirically, MoleculeJAE proves its effectiveness by reaching state-of-the-art performance on 15 out of 20 tasks by comparing it with 12 competitive baselines.""}",https://openreview.net{'value': '/pdf/cbfd52ee704a43a297be3272e141ad64fa365609.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=xpjsOQtKqx,{'value': 'StableRep: Synthetic Images from Text-to-Image Models Make Strong Visual Representation Learners'},Yonglong Tian; Lijie Fan; Phillip Isola; Huiwen Chang; Dilip Krishnan,~Yonglong_Tian1; ~Lijie_Fan1; ~Phillip_Isola1; ~Huiwen_Chang2; ~Dilip_Krishnan1,"{'value': ['representation learning', 'synthetic images', 'text-to-image models']}","{'value': 'We investigate the potential of learning visual representations using synthetic images generated by text-to-image models. This is a natural question in the light of the excellent performance of such models in generating high-quality images. We consider specifically the Stable Diffusion, one of the leading open source text-to-image models. We show that (1) when the generative model is properly configured, training self-supervised methods on synthetic images can match or beat the real image counterpart;\n(2) by treating the multiple images generated from the same text prompt as positives for each other, we develop a multi-positive contrastive learning method, which we call StableRep. \nWith solely synthetic images, the representations learned by StableRep surpass the performance of representations learned by SimCLR and CLIP using the same set of text prompts and corresponding real images, on large scale datasets. \nWhen we further add language supervision, \\name~trained with 20M synthetic images (10M captions) achieves better accuracy than CLIP trained with 50M real images (50M captions).'}",https://openreview.net{'value': '/pdf/e1678099d3fce077fcf242077617687aeec70793.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=xo2lbfQE8I,{'value': 'Fitting trees to $\\ell_1$-hyperbolic distances'},Joon-Hyeok Yim; Anna Gilbert,~Joon-Hyeok_Yim1; ~Anna_Gilbert2,"{'value': ['tree metric fitting', 'ultrametric fitting', '$\\ell_1$-hyperbolicity']}","{'value': ""Building trees to represent or to fit distances is a critical component of phylogenetic analysis, metric embeddings, approximation algorithms, geometric graph neural nets, and the analysis of hierarchical data. Much of the previous algorithmic work, however, has focused on generic metric spaces (i.e., those with no \\emph{a priori} constraints). Leveraging several ideas from the mathematical analysis of hyperbolic geometry and geometric group theory, we study the tree fitting problem as finding the relation between the hyperbolicity (ultrametricity) vector and the error of tree (ultrametric) embedding. That is, we define a vector of hyperbolicity (ultrametric) values over all triples of points and compare the $\\ell_p$ norms of this vector with the $\\ell_q$ norm of the distortion of the best tree fit to the distances. This formulation allows us to define the average hyperbolicity (ultrametricity) in terms of a normalized $\\ell_1$ norm of the hyperbolicity vector. Furthermore, we can interpret the classical tree fitting result of Gromov as a $p = q = \\infty$ result. We present an algorithm \\textsc{HCCRootedTreeFit} such that the $\\ell_1$ error of the output embedding is analytically bounded in terms of the $\\ell_1$-norm of the hyperbolicity vector (i.e., $p = q = 1$) and that this result is tight. Furthermore, this algorithm has significantly different theoretical and empirical performance as compared to Gromov's result and related algorithms. Finally, we show using \\textsc{HCCRootedTreeFit} and related tree fitting algorithms, that supposedly standard data sets for hierarchical data analysis and geometric graph neural networks have radically different tree fits than those of synthetic, truly tree-like data sets, suggesting that a much more refined analysis of these standard data sets is called for.""}",https://openreview.net{'value': '/pdf/9c2a7aa63f0062da7a0cb4888b2350a8dac4a750.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=xWCp0uLcpG,{'value': 'Robust Data Pruning under Label Noise via Maximizing Re-labeling Accuracy'},Dongmin Park; Seola Choi; Doyoung Kim; Hwanjun Song; Jae-Gil Lee,~Dongmin_Park1; ~Seola_Choi1; ~Doyoung_Kim2; ~Hwanjun_Song2; ~Jae-Gil_Lee1,"{'value': ['Data Pruning', 'Data Subset Selection', 'Noisy Labels', 'Relabeling', 'Self-training']}","{'value': 'Data pruning, which aims to downsize a large training set into a small informative subset, is crucial for reducing the enormous computational costs of modern deep learning. Though large-scale data collections invariably contain annotation noise and numerous robust learning methods have been developed, data pruning for the noise-robust learning scenario has received little attention. With state-of-the-art Re-labeling methods that self-correct erroneous labels while training, it is challenging to identify which subset induces the most accurate re-labeling of erroneous labels in the entire training set. In this paper, we formalize the problem of data pruning with re-labeling. We first show that the likelihood of a training example being correctly re-labeled is proportional to the prediction confidence of its neighborhood in the subset. Therefore, we propose a novel data pruning algorithm, Prune4Rel, that finds a subset maximizing the total neighborhood confidence of all training examples, thereby maximizing the re-labeling accuracy and generalization performance. Extensive experiments on four real and one synthetic noisy datasets show that Prune4Rel outperforms the baselines with Re-labeling models by up to 9.1% as well as those with a standard model by up to 21.6%.'}",https://openreview.net{'value': '/pdf/70670d7375e2c414c249bdccc86831f337bf7851.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=xRfTcZdQxq,{'value': 'Robust Model Reasoning and Fitting via Dual Sparsity Pursuit'},Xingyu Jiang; Jiayi Ma,~Xingyu_Jiang1; ~Jiayi_Ma2,{'value': ['Model reasoning; Model fitting; Outliers; Sparse subspace learning; Feature matching']},"{'value': ""In this paper, we contribute to solving a threefold problem: outlier rejection, true model reasoning and parameter estimation with a unified optimization modeling. To this end, we first pose this task as a sparse subspace recovering problem, to search a maximum of independent bases under an over-embedded data space. Then we convert the objective into a continuous optimization paradigm that estimates sparse solutions for both bases and errors. Wherein a fast and robust solver is proposed to accurately estimate the sparse subspace parameters and error entries, which is implemented by a proximal approximation method under the alternating optimization framework with the ``optimal'' sub-gradient descent. Extensive experiments regarding known and unknown model fitting on synthetic and challenging real datasets have demonstrated the superiority of our method against the state-of-the-art. We also apply our method to multi-class multi-model fitting and loop closure detection, and achieve promising results both in accuracy and efficiency. Code is released at: https://github.com/StaRainJ/DSP.""}",https://openreview.net{'value': '/pdf/639371f41f9b3fc2794cb478bb85135e29e503a6.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=xMgO04HDOS,{'value': 'Hierarchical Multi-Agent Skill Discovery'},Mingyu Yang; Yaodong Yang; Zhenbo Lu; Wengang Zhou; Houqiang Li,~Mingyu_Yang1; ~Yaodong_Yang1; ~Zhenbo_Lu1; ~Wengang_Zhou1; ~Houqiang_Li1,"{'value': ['Multi-Agent Reinforcement Learning', 'Hierarchical Skill Discovery', 'Probabilistic Graphical Model']}","{'value': 'Skill discovery has shown significant progress in unsupervised reinforcement learning. This approach enables the discovery of a wide range of skills without any extrinsic reward, which can be effectively combined to tackle complex tasks. However, such unsupervised skill learning has not been well applied to multi-agent reinforcement learning (MARL) due to two primary challenges. One is how to learn skills not only for the individual agents but also for the entire team, and the other is how to coordinate the skills of different agents to accomplish multi-agent tasks. To address these challenges, we present Hierarchical Multi-Agent Skill Discovery (HMASD), a two-level hierarchical algorithm for discovering both team and individual skills in MARL. The high-level policy employs a transformer structure to realize sequential skill assignment, while the low-level policy learns to discover valuable team and individual skills. We evaluate HMASD on sparse reward multi-agent benchmarks, and the results show that HMASD achieves significant performance improvements compared to strong MARL baselines.'}",https://openreview.net{'value': '/pdf/339f44f5c8b82bcadd358b926ed7b51fbd184bf5.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=xGz0wAIJrS,{'value': 'State2Explanation: Concept-Based Explanations to Benefit Agent Learning and User Understanding'},Devleena Das; Sonia Chernova; Been Kim,~Devleena_Das1; ~Sonia_Chernova2; ~Been_Kim1,"{'value': ['Concept-Based Explanations', 'Reinforcement Learning', 'Human-AI Interaction']}","{'value': ""As more non-AI experts use complex AI systems for daily tasks, there has been an increasing effort to develop methods that produce explanations of AI decision making that are understandable by non-AI experts. Towards this effort, leveraging higher-level concepts and producing concept-based explanations have become a popular method. Most concept-based explanations have been developed for classification techniques, and we posit that the few existing methods for sequential decision making are limited in scope. In this work, we first contribute a desiderata for defining ``concepts'' in sequential decision making settings. Additionally, inspired by the Protege Effect which states explaining knowledge often reinforces one's self-learning, we explore how concept-based explanations of an RL agent's decision making can in turn improve the agent's learning rate, as well as improve end-user understanding of the agent's decision making. To this end, we contribute a unified framework, State2Explanation (S2E), that involves learning a joint embedding model between state-action pairs and concept-based explanations, and leveraging such learned model to both (1) inform reward shaping during an agent's training, and (2) provide explanations to end-users at deployment for improved task performance. Our experimental validations, in Connect 4 and Lunar Lander, demonstrate the success of S2E in providing a dual-benefit, successfully informing reward shaping and improving agent learning rate, as well as significantly improving end user task performance at deployment time.""}",https://openreview.net{'value': '/pdf/c31f0b61824abed0e75067f00e0e0d64fbffbc60.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=x7q7w07r6Y,{'value': 'Lending Interaction Wings to Recommender Systems with Conversational Agents'},Jiarui Jin; Xianyu Chen; Fanghua Ye; Mengyue Yang; Yue Feng; Weinan Zhang; Yong Yu; Jun Wang,~Jiarui_Jin1; ~Xianyu_Chen2; ~Fanghua_Ye1; ~Mengyue_Yang1; ~Yue_Feng1; ~Weinan_Zhang1; ~Yong_Yu1; ~Jun_Wang2,"{'value': ['Conversational Agent', 'Recommender System', 'Conversational Recommendation']}","{'value': 'An intelligent conversational agent (a.k.a., chat-bot) could embrace conversational technologies to obtain user preferences online, to overcome inherent limitations of recommender systems trained over the offline historical user behaviors. In this paper, we propose CORE, a new offline-training and online-checking framework to plug a COnversational agent into REcommender systems. Unlike most prior conversational recommendation approaches that systemically combine conversational and recommender parts through a reinforcement learning framework, CORE bridges the conversational agent and recommender system through a unified uncertainty minimization framework, which can be easily applied to any existing recommendation approach. Concretely, CORE treats a recommender system as an offline estimator to produce an estimated relevance score for each item, while CORE regards a conversational agent as an online checker that checks these estimated scores in each online session. We define uncertainty as the sum of unchecked relevance scores. In this regard, the conversational agent acts to minimize uncertainty via querying either attributes or items. Towards uncertainty minimization, we derive the certainty gain of querying each attribute and item, and develop a novel online decision tree algorithm to decide what to query at each turn. Our theoretical analysis reveals the bound of the expected number of turns of CORE in a cold-start setting. Experimental results demonstrate that CORE can be seamlessly employed on a variety of recommendation approaches, and can consistently bring significant improvements in both hot-start and cold-start settings.'}",https://openreview.net{'value': '/pdf/f4b322e7cb15d458a9514322717753aa397a8dfe.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=x6cOcxRnxG,{'value': 'Neural Ideal Large Eddy Simulation: Modeling Turbulence with Neural Stochastic Differential Equations'},Anudhyan Boral; Zhong Yi Wan; Leonardo Zepeda-Nunez; James Lottes; Qing Wang; Yi-Fan Chen; John Roberts Anderson; Fei Sha,~Anudhyan_Boral1; ~Zhong_Yi_Wan1; ~Leonardo_Zepeda-Nunez1; jlottes@google.com; ~Qing_Wang16; yifanchen@google.com; janders@google.com; ~Fei_Sha3,"{'value': ['partial differential equations', 'physics', 'turbulence', 'stochastic differential equations', 'physical simulation', 'neural differential equations']}","{'value': 'We introduce a data-driven learning framework that assimilates two powerful ideas: ideal large eddy simulation (LES) from turbulence closure modeling and neural stochastic differential equations (SDE) for stochastic modeling. The ideal LES models the LES flow by treating each full-order trajectory as a random realization of the underlying dynamics, as such, the effect of small-scales is marginalized to obtain the deterministic evolution of the LES state. However, ideal LES is analytically intractable. In our work, we use a latent neural SDE to model the evolution of the stochastic process and an encoder-decoder pair for transforming between the latent space and the desired ideal flow field. This stands in sharp contrast to other types of neural parameterization of closure models where each trajectory is treated as a deterministic realization of the dynamics. We show the effectiveness of our approach (niLES – neural ideal LES) on two challenging chaotic dynamical systems: Kolmogorov flow at a Reynolds number of 20,000 and flow past a cylinder at Reynolds number 500. Compared to competing methods, our method can handle non-uniform geometries using unstructured meshes seamlessly. In particular, niLES leads to trajectories with more accurate statistics and enhances stability, particularly for long-horizon rollouts. (Source codes and datasets will be made publicly available.)'}",https://openreview.net{'value': '/pdf/69da11cb23049a172f17415920eb0343a08fcc98.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=woptnU6fh1,{'value': 'BayesDAG: Gradient-Based Posterior Inference for Causal Discovery'},Yashas Annadani; Nick Pawlowski; Joel Jennings; Stefan Bauer; Cheng Zhang; Wenbo Gong,~Yashas_Annadani1; ~Nick_Pawlowski2; ~Joel_Jennings1; ~Stefan_Bauer1; ~Cheng_Zhang1; ~Wenbo_Gong1,"{'value': ['Causal Discovery', 'Structure Learning', 'Bayesian Inference', 'Variational Inference', 'MCMC', 'Generative Model']}","{'value': ""Bayesian causal discovery aims to infer the posterior distribution over causal models from observed data, quantifying epistemic uncertainty and benefiting downstream tasks. However, computational challenges arise due to joint inference over combinatorial space of Directed Acyclic Graphs (DAGs) and nonlinear functions. Despite recent progress towards efficient posterior inference over DAGs,  existing methods are either limited to variational inference on node permutation matrices for linear causal models, leading to compromised inference accuracy, or continuous relaxation of adjacency matrices constrained by a DAG regularizer, which cannot ensure resulting graphs are DAGs. In this work, we introduce a scalable Bayesian causal discovery framework based on a combination of stochastic gradient Markov Chain Monte Carlo (SG-MCMC) and Variational Inference (VI) that overcomes these limitations. Our approach directly samples DAGs from the posterior without requiring any DAG regularization, simultaneously draws function parameter samples and is applicable to both linear and nonlinear causal models. To enable our approach, we derive a novel equivalence to the permutation-based DAG learning, which opens up possibilities of using any relaxed gradient estimator defined over permutations. To our knowledge, this is the first framework applying gradient-based MCMC sampling for causal discovery. Empirical evaluation on synthetic and real-world datasets demonstrate our approach's effectiveness compared to state-of-the-art baselines.""}",https://openreview.net{'value': '/pdf/3cd1781d52c7de1b58f53c1920ab36057fb4e503.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=wYkfog48Bq,{'value': 'Optimal Block-wise Asymmetric Graph Construction for Graph-based Semi-supervised Learning'},Zixing Song; Yifei Zhang; Irwin King,~Zixing_Song2; ~Yifei_Zhang6; ~Irwin_King1,"{'value': ['Graph-based Semi-supervised Learning', 'Affinity Graph Construction']}","{'value': 'Graph-based semi-supervised learning (GSSL) serves as a powerful tool to model the underlying manifold structures of samples in high-dimensional spaces. It involves two phases: constructing an affinity graph from available data and inferring labels for unlabeled nodes on this graph. While numerous algorithms have been developed for label inference, the crucial graph construction phase has received comparatively less attention, despite its significant influence on the subsequent phase. In this paper, we present an optimal asymmetric graph structure for the label inference phase with theoretical motivations. Unlike existing graph construction methods, we differentiate the distinct roles that labeled nodes and unlabeled nodes could play. Accordingly, we design an efficient block-wise graph learning algorithm with a global convergence guarantee. Other benefits induced by our method, such as enhanced robustness to noisy node features, are explored as well. Finally, we perform extensive experiments on synthetic and real-world datasets to demonstrate its superiority to the state-of-the-art graph construction methods in GSSL.'}",https://openreview.net{'value': '/pdf/68b290e4978f0b826e52e8f1c37d8aa8d6f97955.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=w7TyuWhGZP,{'value': 'Interpretable Reward Redistribution in Reinforcement Learning: A Causal Approach'},Yudi Zhang; Yali Du; Biwei Huang; Ziyan Wang; Jun Wang; Meng Fang; Mykola Pechenizkiy,~Yudi_Zhang3; ~Yali_Du1; ~Biwei_Huang1; ~Ziyan_Wang3; ~Jun_Wang2; ~Meng_Fang1; ~Mykola_Pechenizkiy1,"{'value': ['Reinforcement learning', 'sparse reward', 'return decomposition', 'causal modeling']}","{'value': 'A major challenge in reinforcement learning is to determine which state-action pairs are responsible for future rewards that are delayed. Reward redistribution serves as a solution to re-assign credits for each time step from observed sequences.  While the majority of current approaches construct the reward redistribution in an uninterpretable manner, we propose to explicitly model the contributions of state and action from a causal perspective, resulting in an interpretable reward redistribution and preserving policy invariance. In this paper, we start by studying the role of causal generative models in reward redistribution by characterizing the generation of Markovian rewards and trajectory-wise long-term return and further propose a framework, called Generative Return Decomposition (GRD), for policy optimization in delayed reward scenarios. Specifically, GRD first identifies the unobservable Markovian rewards and causal relations in the generative process. Then,  GRD makes use of the identified causal generative model to form a compact representation to train policy over the most favorable subspace of the state space of the agent. Theoretically, we show that the unobservable Markovian reward function is identifiable, as well as the underlying causal structure and causal models. Experimental results show that our method outperforms state-of-the-art methods and the provided visualization further demonstrates the interpretability of our method.\nThe project page is located at [https://reedzyd.github.io/GenerativeReturnDecomposition/](https://reedzyd.github.io/GenerativeReturnDecomposition/).'}",https://openreview.net{'value': '/pdf/6c209e8323172cf852e3fe502289f8c46e646566.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=w6krZiUa7t,{'value': 'Hyper-HMM: aligning human brains and semantic features in a common latent event space'},Caroline Lee; Jane Han; Ma Feilong; Guo Jiahui; James Haxby; Christopher Baldassano,~Caroline_Lee1; ~Jane_Han1; ~Ma_Feilong1; ~Guo_Jiahui1; ~James_Haxby1; ~Christopher_Baldassano1,"{'value': ['Brain Imaging', 'Other Cognitive Science', 'Other Neuroscience']}","{'value': ""Naturalistic stimuli evoke complex neural responses with spatial and temporal properties that differ across individuals. Current alignment methods focus on either spatial hyperalignment (assuming exact temporal correspondence) or temporal alignment (assuming exact spatial correspondence). Here, we propose a hybrid model, the Hyper-HMM, that simultaneously aligns both temporal and spatial features across brains. The model learns to linearly project voxels to a reduced-dimension latent space, in which timecourses are segmented into corresponding temporal events. This approach allows tracking of each individual's mental trajectory through an event sequence, and also allows for alignment with other feature spaces such as stimulus content. Using an fMRI dataset in which students watch videos of class lectures, we demonstrate that the Hyper-HMM can be used to map all participants and the semantic content of the videos into a common low-dimensional space, and that these mappings generalize to held-out data. Our model provides a new window into individual cognitive dynamics evoked by complex naturalistic stimuli.""}",https://openreview.net{'value': '/pdf/e6321f673959af15e6b36e42bb0000eb9ac8c68e.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=w0H2xGHlkw,{'value': 'Visual Instruction Tuning'},Haotian Liu; Chunyuan Li; Qingyang Wu; Yong Jae Lee,~Haotian_Liu1; ~Chunyuan_Li1; ~Qingyang_Wu1; ~Yong_Jae_Lee2,"{'value': ['visual instruction tuning', 'instruction tuning', 'multimodal', 'LLM', 'GPT']}","{'value': 'Instruction tuning large language models (LLMs) using machine-generated instruction-following data has been shown to improve zero-shot capabilities on new tasks, but the idea is less explored in the multimodal field. We present the first attempt to use language-only GPT-4 to generate multimodal language-image instruction-following data. By instruction tuning on such generated data, we introduce LLaVA: Large Language and Vision Assistant, an end-to-end trained large multimodal model that connects a vision encoder and an LLM for general-purpose visual and language understanding. To facilitate future research on visual instruction following, we construct two evaluation benchmarks with diverse and challenging application-oriented tasks. Our experiments show that LLaVA demonstrates impressive multimodal chat abilities, sometimes exhibiting the behaviors of multimodal GPT-4 on unseen images/instructions, and yields a 85.1% relative score compared with GPT-4 on a synthetic multimodal instruction-following dataset. When fine-tuned on Science QA, the synergy of LLaVA and GPT-4 achieves a new state-of-the-art accuracy of 92.53%. We make GPT-4 generated visual instruction tuning data, our model, and code publicly available.'}",https://openreview.net{'value': '/pdf/8ec2de30800edb13f33bf46d3f735b91f7561ce0.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=vz7SdRqWGM,{'value': 'Adaptive whitening with fast gain modulation and slow synaptic plasticity'},Lyndon Duong; Eero P Simoncelli; Dmitri Chklovskii; David Lipshutz,~Lyndon_Duong1; ~Eero_P_Simoncelli1; ~Dmitri_Chklovskii1; ~David_Lipshutz1,"{'value': ['neuroscience', 'adaptation', 'whitening', 'efficient coding', 'recurrent neural network', 'gain modulation', 'synaptic plasticity', 'local learning rules']}","{'value': 'Neurons in early sensory areas rapidly adapt to changing sensory statistics, both by normalizing the variance of their individual responses and by reducing correlations between their responses. Together, these transformations may be viewed as an adaptive form of statistical whitening. Existing mechanistic models of adaptive whitening exclusively use either synaptic plasticity or gain modulation as the biological substrate for adaptation; however, on their own, each of these models has significant limitations. In this work, we unify these approaches in a normative multi-timescale mechanistic model that adaptively whitens its responses with complementary computational roles for synaptic plasticity and gain modulation. Gains are modified on a fast timescale to adapt to the current statistical context, whereas synapses are modified on a slow timescale to match structural properties of the input statistics that are invariant across contexts. Our model is derived from a novel multi-timescale whitening objective that factorizes the inverse whitening matrix into basis vectors, which correspond to synaptic weights, and a diagonal matrix, which corresponds to neuronal gains. We test our model on synthetic and natural datasets and find that the synapses learn optimal configurations over long timescales that enable adaptive whitening on short timescales using gain modulation.'}",https://openreview.net{'value': '/pdf/85642724098e98a3bc1c8babf1d25d5f0f183921.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=vF8ukt5l1R,{'value': 'Self-supervised video pretraining yields robust and more human-aligned visual representations'},Nikhil Parthasarathy; S. M. Ali Eslami; Joao Carreira; Olivier J Henaff,~Nikhil_Parthasarathy1; ~S._M._Ali_Eslami1; ~Joao_Carreira1; ~Olivier_J_Henaff1,"{'value': ['self-supervised learning', 'contrastive', 'video pretraining', 'representation learning', 'visual representation', 'human alignment', 'robustness', 'shape-bias', 'saliency']}","{'value': 'Humans learn powerful representations of objects and scenes by observing how they evolve over time. Yet, outside of specific tasks that require explicit temporal understanding, static image pretraining remains the dominant paradigm for learning visual foundation models. We question this mismatch, and ask whether video pretraining can yield visual representations that bear the hallmarks of human perception: generalisation across tasks, robustness to perturbations, and consistency with human judgements. To that end we propose a novel procedure for curating videos, and develop a contrastive framework which learns from the complex transformations therein. This simple paradigm for distilling knowledge from videos, called VITO, yields general representations that far outperform prior video pretraining methods on image understanding tasks, and image pretraining methods on video understanding tasks. Moreover, VITO representations are significantly more robust to natural and synthetic deformations than image-, video-, and adversarially-trained\nones. Finally, VITO’s predictions are strongly aligned with human judgements, surpassing models that were specifically trained for that purpose. Together, these results suggest that video pretraining could be a simple way of learning unified, robust, and human-aligned representations of the visual world.'}",https://openreview.net{'value': '/pdf/66f79edcd3bd67abef2ef5eef2d484718b293549.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=vBwSACOB3x,{'value': 'Neural Algorithmic Reasoning Without Intermediate Supervision'},Gleb Rodionov; Liudmila Prokhorenkova,~Gleb_Rodionov1; ~Liudmila_Prokhorenkova1,"{'value': ['neural algorithmic reasoning', 'graph neural networks', 'self-supervised regularization']}","{'value': 'Neural algorithmic reasoning is an emerging area of machine learning focusing on building models that can imitate the execution of classic algorithms, such as sorting, shortest paths, etc. One of the main challenges is to learn algorithms that are able to generalize to out-of-distribution data, in particular with significantly larger input sizes. Recent work on this problem has demonstrated the advantages of learning algorithms step-by-step, giving models access to all intermediate steps of the original algorithm. In this work, we instead focus on learning neural algorithmic reasoning only from the input-output pairs without appealing to the intermediate supervision. We propose simple but effective architectural improvements and also build a self-supervised objective that can regularise intermediate computations of the model without access to the algorithm trajectory. We demonstrate that our approach is competitive to its trajectory-supervised counterpart on tasks from the CLRS Algorithmic Reasoning Benchmark and achieves new state-of-the-art results for several problems, including sorting, where we obtain significant improvements. Thus, learning without intermediate supervision is a promising direction for further research on neural reasoners.'}",https://openreview.net{'value': '/pdf/e526b0c78faa746d9a6c1a540d873bd9a7a5b01b.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=uzOBDerK1j,{'value': 'Online robust non-stationary estimation'},Abishek Sankararaman; Murali Balakrishnan,~Abishek_Sankararaman1; ~Murali_Balakrishnan1,"{'value': ['Estimation', 'heavy-tails', 'distribution shifts', 'regret']}","{'value': 'The real-time estimation of time-varying parameters from high-dimensional, heavy-tailed and corrupted data-streams is a common sub-routine in systems ranging from those for network monitoring and anomaly detection to those for traffic scheduling in data-centers. For estimation tasks that can be cast as minimizing a strongly convex loss function, we prove that an appropriately tuned version of the {\\ttfamily clipped Stochastic Gradient Descent} (SGD) is simultaneously {\\em(i)} adaptive to drift, {\\em (ii)} robust to heavy-tailed inliers and arbitrary corruptions,  {\\em(iii)} requires no distributional knowledge and {\\em (iv)} can be implemented in an online streaming fashion. All prior estimation algorithms have only been proven to posses a subset of these practical desiderata. A observation we make is that, neither the $\\mathcal{O}\\left(\\frac{1}{t}\\right)$ learning rate for {\\ttfamily clipped SGD} known to be optimal for strongly convex loss functions of a \\emph{stationary} data-stream, nor the $\\mathcal{O}(1)$ learning rate known to be optimal for being adaptive to drift in a \\emph{noiseless} environment can be used. Instead, a learning rate of $T^{-\\alpha}$ for $ \\alpha < 1$ where $T$ is the stream-length is needed to balance adaptivity to potential drift and to combat noise. We develop a new inductive argument and combine it with a martingale concentration result to derive high-probability under \\emph{any learning rate} on data-streams exhibiting \\emph{arbitrary distribution shift} - a proof strategy that may be of independent interest. Further, using the classical doubling-trick, we relax the knowledge of the stream length $T$. Ours is the first online estimation algorithm that is provably robust to heavy-tails, corruptions and distribution shift simultaneously. We complement our theoretical results empirically on synthetic and real data.'}",https://openreview.net{'value': '/pdf/5d6d714ea5737396eb8c11665d05b531fcf140fb.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=uWNqy09dFW,{'value': 'Learning Neural Implicit through Volume Rendering with Attentive Depth Fusion Priors'},Pengchong Hu; Zhizhong Han,~Pengchong_Hu1; ~Zhizhong_Han2,"{'value': ['3D Reconstruction', 'SDF', 'Neural Rendering', 'Implicit Representations', 'SLAM']}","{'value': 'Learning neural implicit representations has achieved remarkable performance in 3D reconstruction from multi-view images. Current methods use volume rendering to render implicit representations into either RGB or depth images that are supervised by the multi-view ground truth. However, rendering a view each time suffers from incomplete depth at holes and unawareness of occluded structures from the depth supervision, which severely affects the accuracy of geometry inference via volume rendering. To resolve this issue, we propose to learn neural implicit representations from multi-view RGBD images through volume rendering with an attentive depth fusion prior. Our prior allows neural networks to sense coarse 3D structures from the Truncated Signed Distance Function (TSDF) fused from all available depth images for rendering. The TSDF enables accessing the missing depth at holes on one depth image and the occluded parts that are invisible from the current view. By introducing a novel attention mechanism, we allow neural networks to directly use the depth fusion prior with the inferred occupancy as the learned implicit function. Our attention mechanism works with either a one-time fused TSDF that represents a whole scene or an incrementally fused TSDF that represents a partial scene in the context of Simultaneous Localization and Mapping (SLAM). Our evaluations on widely used benchmarks including synthetic and real-world scans show our superiority over the latest neural implicit methods.'}",https://openreview.net{'value': '/pdf/d81ea5fecbc3e0850ff4e025b8c071d472ac829a.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=uDV4lA0gZ6,{'value': 'Efficient Robust Bayesian Optimization for Arbitrary Uncertain inputs'},Lin Yang; Junlong Lyu; Wenlong Lyu; Zhitang Chen,~Lin_Yang8; ~Junlong_Lyu1; ~Wenlong_Lyu1; ~Zhitang_Chen1,"{'value': ['bayesian optimization', 'robust optimization']}","{'value': 'Bayesian Optimization (BO) is a sample-efficient optimization algorithm widely employed across various applications. In some challenging BO tasks, input uncertainty arises due to the inevitable randomness in the optimization process, such as machining errors, execution noise, or contextual variability. This uncertainty deviates the input from the intended value before evaluation, resulting in significant performance fluctuations in the final result. In this paper, we introduce a novel robust Bayesian Optimization algorithm, AIRBO, which can effectively identify a robust optimum that performs consistently well under arbitrary input uncertainty. Our method directly models the uncertain inputs of arbitrary distributions by empowering the Gaussian Process with the Maximum Mean Discrepancy (MMD) and further accelerates the posterior inference via Nystrom approximation. Rigorous theoretical regret bound is established under MMD estimation error and extensive experiments on synthetic functions and real problems demonstrate that our approach can handle various input uncertainties and achieve a state-of-the-art performance.'}",https://openreview.net{'value': '/pdf/c5b971bbcbb881bfa4c4ff6c33ff8f7767396cb9.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=u359tNBpxF,{'value': 'Robust Data Valuation with Weighted Banzhaf Values'},Weida Li; Yaoliang Yu,~Weida_Li1; ~Yaoliang_Yu1,"{'value': ['data valuation', 'robustness', 'weighted Banzhaf values']}","{'value': 'Data valuation, a principled way to rank the importance of each training datum, has become increasingly important. However, existing value-based approaches (e.g., Shapley) are known to suffer from the stochasticity inherent in utility functions that render consistent and reliable ranking difficult. Recently, Wang and Jia (2023) proposed the noise-structure-agnostic framework to advocate the Banzhaf value for its robustness against such stochasticity as it achieves the largest safe margin among many alternatives. Surprisingly, our empirical study shows that the Banzhaf value is not always the most robust when compared with a broader family: weighted Banzhaf values. To analyze this scenario, we introduce the concept of Kronecker noise to parameterize stochasticity, through which we prove that the uniquely robust semi-value, which can be analytically derived from the underlying Kronecker noise, lies in the family of weighted Banzhaf values while minimizing the worst-case entropy. In addition, we adopt the maximum sample reuse principle to design an estimator to efficiently approximate weighted Banzhaf values, and show that it enjoys the best time complexity in terms of achieving an $(\\epsilon, \\delta)$-approximation. Our theory is verified under both synthetic and authentic noises. For the latter, we fit a Kronecker noise to the inherent stochasticity, which is then plugged in to generate the predicted most robust semi-value. Our study suggests that weighted Banzhaf values are promising when facing undue noises in data valuation.'}",https://openreview.net{'value': '/pdf/481906560fd0dda7e8e8194cfdd687999839f24c.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=toYvRJ7Zmy,{'value': 'Derandomized novelty detection with FDR control via conformal e-values'},Meshi Bashari; Amir Epstein; Yaniv Romano; Matteo Sesia,~Meshi_Bashari1; ~Amir_Epstein1; ~Yaniv_Romano1; ~Matteo_Sesia1,"{'value': ['Conformal inference', 'Derandomization', 'E-values', 'False discovery rate', 'Out-of-distribution testing', 'Testing for outliers', 'Uncertainty']}","{'value': 'Conformal inference provides a general distribution-free method to rigorously calibrate the output of any machine learning algorithm for novelty detection. While this approach has many strengths, it has the limitation of being randomized, in the sense that it may lead to different results when analyzing twice the same data and this can hinder the interpretation of any findings. We propose to make conformal inferences more stable by leveraging suitable conformal e-values instead of p-values to quantify statistical significance. This solution allows the evidence gathered from multiple analyses of the same data to be aggregated effectively while provably controlling the false discovery rate. Further, we show that the proposed method can reduce randomness without much loss of power compared to standard conformal inference, partly thanks to an innovative way of weighting conformal e-values based on additional side information carefully extracted from the same data. Simulations with synthetic and real data confirm this solution can be effective at eliminating random noise in the inferences obtained with state-of-the-art alternative techniques, sometimes also leading to higher power.'}",https://openreview.net{'value': '/pdf/1e0ee0fa16a5ae8cdd90cc99fdf8f43f2d8fd1cf.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=tn9Dldam9L,{'value': 'Add and Thin: Diffusion for Temporal Point Processes'},David Lüdke; Marin Biloš; Oleksandr Shchur; Marten Lienen; Stephan Günnemann,~David_Lüdke1; ~Marin_Biloš1; ~Oleksandr_Shchur1; ~Marten_Lienen1; ~Stephan_Günnemann1,"{'value': ['Point Processes', 'Diffusion', 'Temporal Data', 'Generative Model', 'Forecasting', 'Density Estimation', 'Denoising']}","{'value': 'Autoregressive neural networks within the temporal point process (TPP) framework have become the standard for modeling continuous-time event data. Even though these models can expressively capture event sequences in a one-step-ahead fashion, they are inherently limited for long-term forecasting applications due to the accumulation of errors caused by their sequential nature. To overcome these limitations, we derive ADD-THIN, a principled probabilistic denoising diffusion model for TPPs that operates on entire event sequences. Unlike existing diffusion approaches, ADD-THIN naturally handles data with discrete and continuous components. In experiments on synthetic and real-world datasets, our model matches the state-of-the-art TPP models in density estimation and strongly outperforms them in forecasting.'}",https://openreview.net{'value': '/pdf/1fb5a7149d8e19e0f23ce3c0e49b9030bfbad250.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=tScBQRNgjk,{'value': 'ForecastPFN: Synthetically-Trained Zero-Shot Forecasting'},Samuel Dooley; Gurnoor Singh Khurana; Chirag Mohapatra; Siddartha Venkat Naidu; Colin White,~Samuel_Dooley1; ~Gurnoor_Singh_Khurana1; ~Chirag_Mohapatra1; ~Siddartha_Venkat_Naidu1; ~Colin_White1,"{'value': ['Forecasting', 'Zero-shot', 'Synthetic Data']}","{'value': ""The vast majority of time-series forecasting approaches require a substantial training dataset. However, many real-life forecasting applications have very little initial observations, sometimes just 40 or fewer. Thus, the applicability of most forecasting methods is restricted in data-sparse commercial applications. While there is recent work in the setting of very limited initial data (so-called `zero-shot' forecasting), its performance is inconsistent depending on the data used for pretraining. In this work, we take a different approach and devise ForecastPFN, the first zero-shot forecasting model trained purely on a novel synthetic data distribution. ForecastPFN is a prior-data fitted network, trained to approximate Bayesian inference, which can make predictions on a new time series dataset in a single forward pass. Through extensive experiments, we show that zero-shot predictions made by ForecastPFN are more accurate and faster compared to state-of-the-art forecasting methods, even when the other methods are allowed to train on hundreds of additional in-distribution data points.""}",https://openreview.net{'value': '/pdf/534c657319322de54e410480ef13490a78fd58ff.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=tJ88RBqupo,{'value': 'Can You Rely on Your Model Evaluation? Improving Model Evaluation with Synthetic Test Data'},Boris van Breugel; Nabeel Seedat; Fergus Imrie; Mihaela van der Schaar,~Boris_van_Breugel2; ~Nabeel_Seedat1; ~Fergus_Imrie1; ~Mihaela_van_der_Schaar2,"{'value': ['model evaluation', 'tabular', 'synthetic data']}","{'value': ""Evaluating the performance of machine learning models on diverse and underrepresented subgroups is essential for ensuring fairness and reliability in real-world applications. However, accurately assessing model performance becomes challenging due to two main issues: (1) a scarcity of test data, especially for small subgroups, and (2) possible distributional shifts in the model's deployment setting, which may not align with the available test data.  In this work, we introduce 3S Testing, a deep generative modeling framework to facilitate model evaluation by generating synthetic test sets for small subgroups and simulating distributional shifts. Our experiments demonstrate that 3S-Testing outperforms traditional baselines---including real test data alone---in estimating model performance on minority subgroups and under plausible distributional shifts. In addition, 3S offers intervals around its performance estimates, exhibiting superior coverage of the ground truth compared to existing approaches.  Overall, these results raise the question of whether we need a paradigm shift away from limited real test data towards synthetic test data.""}",https://openreview.net{'value': '/pdf/a1f3a21731b39eec479905189efd8fe6fd98f4c3.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=tIzbNQko3c,{'value': 'Pre-Training Protein Encoder via Siamese Sequence-Structure Diffusion Trajectory Prediction'},Zuobai Zhang; Minghao Xu; Aurelie Lozano; Vijil Chenthamarakshan; Payel Das; Jian Tang,~Zuobai_Zhang1; ~Minghao_Xu1; ~Aurelie_Lozano1; ~Vijil_Chenthamarakshan1; ~Payel_Das1; ~Jian_Tang1,"{'value': ['Protein representation learning', 'diffusion models', 'self-supervised learning']}","{'value': 'Self-supervised pre-training methods on proteins have recently gained attention, with most approaches focusing on either protein sequences or structures, neglecting the exploration of their joint distribution, which is crucial for a comprehensive understanding of protein functions by integrating co-evolutionary information and structural characteristics. In this work, inspired by the success of denoising diffusion models in generative tasks, we propose the DiffPreT approach to pre-train a protein encoder by sequence-structure joint diffusion modeling. DiffPreT guides the encoder to recover the native protein sequences and structures from the perturbed ones along the joint diffusion trajectory, which acquires the joint distribution of sequences and structures. Considering the essential protein conformational variations, we enhance DiffPreT by a method called Siamese Diffusion Trajectory Prediction (SiamDiff) to capture the correlation between different conformers of a protein. SiamDiff attains this goal by maximizing the mutual information between representations of diffusion trajectories of structurally-correlated conformers. We study the effectiveness of DiffPreT and SiamDiff on both atom- and residue-level structure-based protein understanding tasks. Experimental results show that the performance of DiffPreT is consistently competitive on all tasks, and SiamDiff achieves new state-of-the-art performance, considering the mean ranks on all tasks. Code will be released upon acceptance.'}",https://openreview.net{'value': '/pdf/54557a567d51315f120e9d9917a0d6e3323d44f3.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=tFsxtqGmkn,{'value': 'Maximum State Entropy Exploration using Predecessor and Successor Representations'},Arnav Kumar Jain; Lucas Lehnert; Irina Rish; Glen Berseth,~Arnav_Kumar_Jain2; ~Lucas_Lehnert1; ~Irina_Rish1; ~Glen_Berseth1,"{'value': ['Reinforcement Learning', 'Maximum state entropy exploration', 'Non-Markovian exploration', 'Successor Representation']}","{'value': 'Animals have a developed ability to explore that aids them in important tasks such as locating food, exploring for shelter, and finding misplaced items. These exploration skills necessarily track where they have been so that they can plan for finding items with relative efficiency. Contemporary exploration algorithms often learn a less efficient exploration strategy because they either condition only on the current state or simply rely on making random open-loop exploratory moves. In this work, we propose $\\eta\\psi$-Learning, a method to learn efficient exploratory policies by conditioning on past episodic experience to make the next exploratory move. Specifically, $\\eta\\psi$-Learning learns an exploration policy that maximizes the entropy of the state visitation distribution of a single trajectory. Furthermore, we demonstrate how variants of the predecessor representation and successor representations can be combined to predict the state visitation entropy. Our experiments demonstrate the efficacy of $\\eta\\psi$-Learning to strategically explore the environment and maximize the state coverage with limited samples.'}",https://openreview.net{'value': '/pdf/3172fc912022252a8a8905601f7fe7ef461c9367.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=tAwjG5bM7H,{'value': 'A Bounded Ability Estimation for Computerized Adaptive Testing'},Yan Zhuang; Qi Liu; GuanHao Zhao; Zhenya Huang; Weizhe Huang; Zachary Pardos; Enhong Chen; Jinze Wu; Xin Li,~Yan_Zhuang4; ~Qi_Liu3; ~GuanHao_Zhao1; ~Zhenya_Huang2; ~Weizhe_Huang1; ~Zachary_Pardos1; ~Enhong_Chen1; ~Jinze_Wu1; ~Xin_Li56,"{'value': ['adaptive learning', 'computerized adaptive testing', 'educational measurement', 'cognitive diagnosis']}","{'value': ""Computerized adaptive testing (CAT), as a tool that can efficiently measure student's ability, has been widely used in various standardized tests (e.g., GMAT and GRE). The adaptivity of CAT refers to the selection of the most informative questions for each student, reducing test length. Existing CAT methods do not explicitly target ability estimation accuracy since there is no student's true ability as ground truth; therefore, these methods cannot be guaranteed to make the estimate converge to the true with such limited responses. In this paper, we analyze the statistical properties of estimation and find a theoretical approximation of the true ability: the ability estimated by full responses to question bank. Based on this, a Bounded Ability Estimation framework for CAT (BECAT) is proposed in a data-summary manner, which selects a question subset that closely matches the gradient of the full responses. Thus, we develop an expected gradient difference approximation to design a simple greedy selection algorithm, and show the rigorous theoretical and error upper-bound guarantees of its ability estimate. Experiments on both real-world and synthetic datasets, show that it can reach the same estimation accuracy using 15\\% less questions on average, significantly reducing test length.""}",https://openreview.net{'value': '/pdf/311c02f9f559ebad3c4ae60372169d3a28e8e559.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=t1jLRFvBqm,{'value': 'Object-Centric Learning for Real-World Videos by Predicting Temporal Feature Similarities'},Andrii Zadaianchuk; Maximilian Seitzer; Georg Martius,~Andrii_Zadaianchuk1; ~Maximilian_Seitzer1; ~Georg_Martius1,"{'value': ['object-centric learning', 'video', 'representation learning', 'self-supervised learning', 'unsupervised learning']}","{'value': 'Unsupervised video-based object-centric learning is a promising avenue to learn structured representations from large, unlabeled video collections, but previous approaches have only managed to scale to real-world datasets in restricted domains.\nRecently, it was shown that the reconstruction of pre-trained self-supervised features leads to object-centric representations on unconstrained real-world image datasets.\nBuilding on this approach, we propose a novel way to use such pre-trained features in the form of a temporal feature similarity loss.\nThis loss encodes semantic and temporal correlations between image patches and is a natural way to introduce a motion bias for object discovery.\nWe demonstrate that this loss leads to state-of-the-art performance on the challenging synthetic MOVi datasets.\nWhen used in combination with the feature reconstruction loss, our model is the first object-centric video model that scales to unconstrained video datasets such as YouTube-VIS.\n\nhttps://martius-lab.github.io/videosaur/'}",https://openreview.net{'value': '/pdf/293b5909189a279000e544e32355b67975ef1cda.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=sTjW3JHs2V,{'value': 'Let the Flows Tell:  Solving Graph Combinatorial Problems with GFlowNets'},Dinghuai Zhang; Hanjun Dai; Nikolay Malkin; Aaron Courville; Yoshua Bengio; Ling Pan,~Dinghuai_Zhang1; ~Hanjun_Dai1; ~Nikolay_Malkin1; ~Aaron_Courville3; ~Yoshua_Bengio1; ~Ling_Pan1,{'value': ['graph; combinatorial optimization; sampling; gflownets']},"{'value': 'Combinatorial optimization (CO) problems are often NP-hard and thus out of reach for exact algorithms, making them a tempting domain to apply machine learning methods. The highly structured constraints in these problems can hinder either optimization or sampling directly in the solution space.\nOn the other hand, GFlowNets have recently emerged as a powerful machinery to efficiently sample from composite unnormalized densities sequentially and have the potential to amortize such solution-searching processes in CO, as well as generate diverse solution candidates.\nIn this paper, we design Markov decision processes (MDPs) for different combinatorial problems and propose to train conditional GFlowNets to sample from the solution space. \nEfficient training techniques are also developed to benefit long-range credit assignment.\nThrough extensive experiments on a variety of different CO tasks with synthetic and realistic data, we demonstrate that GFlowNet policies can efficiently find high-quality solutions.\nOur implementation is open-sourced at https://github.com/zdhNarsil/GFlowNet-CombOpt.'}",https://openreview.net{'value': '/pdf/268b2b29e54f46504e1343a3b04df2e15f8414a2.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=rHAX0LRwk8,{'value': 'Adversarial Counterfactual Environment Model Learning'},Xiong-Hui Chen; Yang Yu; Zhengmao Zhu; ZhiHua Yu; Chen Zhenjun; Chenghe Wang; Yinan Wu; Rong-Jun Qin; Hongqiu Wu; Ruijin Ding; Huang Fangsheng,~Xiong-Hui_Chen1; ~Yang_Yu5; ~Zhengmao_Zhu1; ~ZhiHua_Yu2; ~Chen_Zhenjun1; ~Chenghe_Wang1; ~Yinan_Wu2; ~Rong-Jun_Qin1; ~Hongqiu_Wu2; ~Ruijin_Ding1; ~Huang_Fangsheng1,"{'value': ['environment model learning', 'offline reinforcement learning', 'off-policy evaluation', 'individual treatment effects estimation', 'causal inference', 'adversarial learning']}","{'value': ""An accurate environment dynamics model is crucial for various downstream tasks in sequential decision-making, such as counterfactual prediction, off-policy evaluation, and offline reinforcement learning. \nCurrently, these models were learned through empirical risk minimization (ERM) by step-wise fitting of historical transition data. This way was previously believed unreliable over long-horizon rollouts because of the compounding errors, which can lead to uncontrollable inaccuracies in predictions. In this paper, we find that the challenge extends beyond just long-term prediction errors: we reveal that even when planning with one step, learned dynamics models can also perform poorly due to the selection bias of behavior policies during data collection. \nThis issue will significantly mislead the policy optimization process even in identifying single-step optimal actions, further leading to a greater risk in sequential decision-making scenarios.\nTo tackle this problem, we introduce a novel model-learning objective called adversarial weighted empirical risk minimization (AWRM).  AWRM incorporates an adversarial policy that exploits the model to generate a data distribution that weakens the model's prediction accuracy, and subsequently, the model is learned under this adversarial data distribution.\nWe implement a practical algorithm, GALILEO, for AWRM and evaluate it on two synthetic tasks, three continuous-control tasks, and  \\textit{a real-world application}. The experiments demonstrate that GALILEO can accurately predict counterfactual actions and improve various downstream tasks, including offline policy evaluation and improvement, as well as online decision-making.""}",https://openreview.net{'value': '/pdf/f77d9d22df193b793596c178654a3e547dda23a5.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=r8LYNleLf9,{'value': 'TexQ: Zero-shot Network Quantization with Texture Feature Distribution Calibration'},Xinrui Chen; Yizhi Wang; Renao Yan; Yiqing Liu; Tian Guan; Yonghong He,~Xinrui_Chen1; ~Yizhi_Wang3; ~Renao_Yan1; ~Yiqing_Liu1; ~Tian_Guan1; ~Yonghong_He1,"{'value': ['Zero-shot quantization', 'Texture feature calibration', 'Post-training quantization', 'low bit width', 'Neural network compression']}","{'value': 'Quantization is an effective way to compress neural networks. By reducing the bit width of the parameters, the processing efficiency of neural network models at edge devices can be notably improved. Most conventional quantization methods utilize real datasets to optimize quantization parameters and fine-tune. Due to the inevitable privacy and security issues of real samples, the existing real-data-driven methods are no longer applicable. Thus, a natural method is to introduce synthetic samples for zero-shot quantization (ZSQ). However, the conventional synthetic samples fail to retain the detailed texture feature distributions, which severely limits the knowledge transfer and performance of the quantized model. In this paper, a novel ZSQ method, TexQ is proposed to address this issue. We first synthesize a calibration image and extract its calibration center for each class with a texture feature energy distribution calibration method. Then, the calibration centers are used to guide the generator to synthesize samples. Finally, we introduce the mixup knowledge distillation module to diversify synthetic samples for fine-tuning. Extensive experiments on CIFAR10/100 and ImageNet show that TexQ is observed to perform state-of-the-art in ultra-low bit width quantization. For example, when ResNet-18 is quantized to 3-bit, TexQ achieves a 12.18% top-1 accuracy increase on ImageNet compared to state-of-the-art methods. Code at https://github.com/dangsingrue/TexQ.'}",https://openreview.net{'value': '/pdf/036e1e59e632aecf014bd56a4e35796ee2be8cdd.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=r7g9nFsulw,{'value': 'Learning Adaptive Tensorial Density Fields for Clean Cryo-ET Reconstruction'},YUANHAO WANG; Ramzi Idoughi; Wolfgang Heidrich,~YUANHAO_WANG2; ~Ramzi_Idoughi1; ~Wolfgang_Heidrich3,"{'value': ['Neural density fields', 'Coordinate-based representations', 'Quadtree structure', 'Cryo-electron microscope']}","{'value': 'We present a novel learning-based framework for reconstructing 3D structures from tilt-series cryo-Electron Tomography (cryo-ET) data. Cryo-ET is a powerful imaging technique that can achieve near-atomic resolutions. Still, it suffers from challenges such as missing-wedge acquisition, large data size, and high noise levels. Our framework addresses these challenges by using an adaptive tensorial-based representation for the 3D density field of the scanned sample. First, we optimize a quadtree structure to partition the volume of interest. Then, we learn a vector-matrix factorization of the tensor representing the density field in each node. Moreover, we use a loss function that combines a differentiable tomographic formation model with three regularization terms: total variation, boundary consistency constraint, and an isotropic Fourier prior. Our framework allows us to query the density at any location using the learned representation and obtain a high-quality 3D tomogram. We demonstrate the superiority of our framework over existing methods using synthetic and real data. Thus, our framework boosts the quality of the reconstruction while reducing the computation time and the memory footprint. The code is available at https://github.com/yuanhaowang1213/adaptivetensordf.'}",https://openreview.net{'value': '/pdf/6765371f8a791dea71f3a874cac8acd0751c068e.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=qyEm4tF2p1,{'value': 'Landscape Surrogate: Learning Decision Losses for Mathematical Optimization Under Partial Information'},Arman Zharmagambetov; Brandon Amos; Aaron M Ferber; Taoan Huang; Bistra Dilkina; Yuandong Tian,~Arman_Zharmagambetov1; ~Brandon_Amos1; ~Aaron_M_Ferber1; ~Taoan_Huang2; ~Bistra_Dilkina2; ~Yuandong_Tian1,"{'value': ['learning surrogates', 'predict+optimize framework', 'combinatorial nonlinear optimization', 'argmin differentiation']}","{'value': 'Recent works in learning-integrated optimization have shown promise in settings where the optimization problem is only partially observed or where general-purpose optimizers perform poorly without expert tuning. By learning an optimizer $\\mathbf{g}$ to tackle these challenging problems with $f$ as the objective, the optimization process can be substantially accelerated by leveraging past experience. The optimizer can be trained with supervision from known optimal solutions or implicitly by optimizing the compound function $f\\circ \\mathbf{g}$. The implicit approach may not require optimal solutions as labels and is capable of handling problem uncertainty; however, it is slow to train and deploy due to frequent calls to optimizer $\\mathbf{g}$ during both training and testing. The training is further challenged by sparse gradients of $\\mathbf{g}$, especially for combinatorial solvers. To address these challenges, we propose using a smooth and learnable **Landscape Surrogate** $\\mathcal{M}$ as a replacement for $f\\circ \\mathbf{g}$. This surrogate, learnable by neural networks, can be computed faster than the solver $\\mathbf{g}$, provides dense and smooth gradients during training, can generalize to unseen optimization problems, and is efficiently learned via alternating optimization. We test our approach on both synthetic problems, including shortest path and multidimensional knapsack, and real-world problems such as portfolio optimization, achieving comparable or superior objective values compared to state-of-the-art baselines while reducing the number of calls to $\\mathbf{g}$. Notably, our approach outperforms existing methods for computationally expensive high-dimensional problems.'}",https://openreview.net{'value': '/pdf/bed8780ecc4e671fe5bdfe07c58a5f13567d9396.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=qs4swxtIAQ,{'value': 'TabMT: Generating tabular data with masked transformers'},Manbir S Gulati; Paul F Roysdon,~Manbir_S_Gulati1; roysdonp@leidos.com,"{'value': ['Tabular Data', 'Deep Learning', 'Generative Modeling', 'Transformers', 'Masked Transformers', 'Synthetic data']}","{'value': 'Autoregressive and Masked Transformers are incredibly effective as generative models and classifiers.\n    While these models are most prevalent in NLP, they also exhibit strong performance in other domains, such as vision. \n    This work contributes to the exploration of transformer-based models in synthetic data generation for diverse application domains. \n    In this paper, we present TabMT, a novel Masked Transformer design for generating synthetic tabular data. \n    TabMT effectively addresses the unique challenges posed by heterogeneous data fields and is natively able to handle missing data. \n    Our design leverages improved masking techniques to allow for generation and demonstrates state-of-the-art performance from extremely small to extremely large tabular datasets. \n    We evaluate TabMT for privacy-focused applications and find that it is able to generate high quality data with superior privacy tradeoffs.'}",https://openreview.net{'value': '/pdf/a55d0a40ef3808d267e8a0966329c33240f910c7.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=qlnlamFQEa,{'value': 'Aligning Synthetic Medical Images with Clinical Knowledge using Human Feedback'},Shenghuan Sun; Gregory Goldgof; Atul Butte; Ahmed Alaa,shenghuan.sun@ucsf.edu; goldgofg@mskcc.org; atul.butte@ucsf.edu; ~Ahmed_Alaa1,"{'value': ['Synthetic clinical data', 'Machine learning for healthcare']}","{'value': 'Generative models capable of precisely capturing nuanced clinical features in medical images hold great promise for facilitating clinical data sharing, enhancing rare disease datasets, and efficiently synthesizing (annotated) medical images at scale. Despite their potential, assessing the quality of synthetic medical images remains a challenge. While modern generative models can synthesize visually-realistic medical images, the clinical plausibility of these images may be called into question. Domain-agnostic scores, such as FID score, precision, and recall, cannot incorporate clinical knowledge and are, therefore, not suitable for assessing clinical sensibility. Additionally, there are numerous unpredictable ways in which generative models may fail to synthesize clinically plausible images, making it challenging to anticipate potential failures and design automated scores for their detection. To address these challenges, this paper introduces a pathologist-in-the-loop framework for generating clinically-plausible synthetic medical images. Our framework comprises three steps: (1) pretraining a conditional diffusion model to generate medical images conditioned on a clinical concept, (2) expert pathologist evaluation of the generated images to assess whether they satisfy clinical desiderata, and (3) training a reward model that predicts human feedback on new samples, which we use to incorporate expert knowledge into the finetuning objective of the diffusion model. Our results show that human feedback significantly improves the quality of synthetic images in terms of fidelity, diversity, utility in downstream applications, and plausibility as evaluated by experts. We also demonstrate that human feedback can teach the model new clinical concepts not annotated in the original training data. Our results demonstrate the value of incorporating human feedback in clinical applications where generative models may struggle to capture extensive domain knowledge from raw data alone.'}",https://openreview.net{'value': '/pdf/e7974dfbf220744484b1fe53cde36c23670ffab5.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=qlJoo2y3gY,{'value': 'Bayesian nonparametric (non-)renewal processes for analyzing neural spike train variability'},David Liu; Máté Lengyel,~David_Liu4; ~Máté_Lengyel1,"{'value': ['Gaussian processes', 'renewal processes', 'point processes', 'neural data analysis', 'Bayesian machine learning', 'non-stationary time series']}","{'value': 'Neural spiking activity is generally variable, non-stationary, and exhibits complex dependencies on covariates, such as sensory input or behavior. These dependencies have been proposed to be signatures of specific computations, and so characterizing them with quantitative rigor is critical for understanding neural computations. Approaches based on point processes provide a principled statistical framework for modeling neural spiking activity. However, currently, they only allow the instantaneous mean, but not the instantaneous variability, of responses to depend on covariates. To resolve this limitation, we propose a scalable Bayesian approach generalizing modulated renewal processes using sparse variational Gaussian processes. We leverage pathwise conditioning for computing nonparametric priors over conditional interspike interval distributions and rely on automatic relevance determination to detect lagging interspike interval dependencies beyond renewal order.  After systematically validating our method on synthetic data, we apply it to two foundational datasets of animal navigation: head direction cells in freely moving mice and hippocampal place cells in rats running along a linear track. Our model exhibits competitive or better predictive power compared to state-of-the-art baselines, and outperforms them in terms of capturing interspike interval statistics. These results confirm the importance of modeling covariate-dependent spiking variability, and further analyses of our fitted models reveal rich patterns of variability modulation beyond the temporal resolution of flexible count-based approaches.'}",https://openreview.net{'value': '/pdf/5a41add1dc84c44b53b1efcd69b2d3073fe687b5.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=qjqJL2lfkH,{'value': 'Rank-1 Matrix Completion with Gradient Descent and Small Random Initialization'},Daesung Kim; Hye Won Chung,~Daesung_Kim1; ~Hye_Won_Chung2,"{'value': ['Matrix completion', 'gradient descent', 'random initialization']}","{'value': 'The nonconvex formulation of the matrix completion problem has received significant attention in recent years due to its affordable complexity compared to the convex formulation. Gradient Descent (GD) is a simple yet efficient baseline algorithm for solving nonconvex optimization problems. The success of GD has been witnessed in many different problems in both theory and practice when it is combined with random initialization. However, previous works on matrix completion require either careful initialization or regularizers to prove the convergence of GD. In this paper, we study the rank-1 symmetric matrix completion and prove that GD converges to the ground truth when small random initialization is used. We show that in a logarithmic number of iterations, the trajectory enters the region where local convergence occurs. We provide an upper bound on the initialization size that is sufficient to guarantee the convergence, and show that a larger initialization can be used as more samples are available. We observe that the implicit regularization effect of GD plays a critical role in the analysis, and for the entire trajectory, it prevents each entry from becoming much larger than the others.'}",https://openreview.net{'value': '/pdf/be285b3201b5e280111bd80dad55ab46381027fa.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=qUlpDjYnsp,{'value': 'Multi-resolution Spectral Coherence for Graph Generation with Score-based Diffusion'},Hyuna Cho; Minjae Jeong; Sooyeon Jeon; Sungsoo Ahn; Won Hwa Kim,~Hyuna_Cho1; ~Minjae_Jeong1; ~Sooyeon_Jeon1; ~Sungsoo_Ahn1; ~Won_Hwa_Kim4,"{'value': ['graph wavelet transform', 'multi-scale wavelet filtering', 'graph generation', 'diffusion model']}","{'value': 'Successful graph generation depends on the accurate estimation of the joint distribution of graph components such as nodes and edges from training data. While recent deep neural networks have demonstrated sampling of realistic graphs together with diffusion models, however, they still suffer from oversmoothing problems which are inherited from conventional graph convolution and thus high-frequency characteristics of nodes and edges become intractable. To overcome such issues and generate graphs with high fidelity, this paper introduces a novel approach that captures the dependency between nodes and edges at multiple resolutions in the spectral space. By modeling the joint distribution of node and edge signals in a shared graph wavelet space, together with a score-based diffusion model, we propose a Wavelet Graph Diffusion Model (Wave-GD) which lets us sample synthetic graphs with real-like frequency characteristics of nodes and edges. Experimental results on four representative benchmark datasets validate the superiority of the Wave-GD over existing approaches, highlighting its potential for a wide range of applications that involve graph data.'}",https://openreview.net{'value': '/pdf/8c6e44d0acfacdbd03afb56f564961666b356d98.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=q6X038vKgU,"{'value': 'Predict, Refine, Synthesize: Self-Guiding Diffusion Models for Probabilistic Time Series Forecasting'}",Marcel Kollovieh; Abdul Fatir Ansari; Michael Bohlke-Schneider; Jasper Zschiegner; Hao Wang; Bernie Wang,~Marcel_Kollovieh1; ~Abdul_Fatir_Ansari2; ~Michael_Bohlke-Schneider1; ~Jasper_Zschiegner1; ~Hao_Wang3; ~Bernie_Wang1,"{'value': ['diffusion models', 'time series forecasting', 'generative modeling', 'deep learning']}","{'value': 'Diffusion models have achieved state-of-the-art performance in generative modeling tasks across various domains. Prior works on time series diffusion models have primarily focused on developing conditional models tailored to specific forecasting or imputation tasks. In this work, we explore the potential of task-agnostic, unconditional diffusion models for several time series applications. We propose TSDiff, an unconditionally-trained diffusion model for time series. Our proposed self-guidance mechanism enables conditioning TSDiff for downstream tasks during inference, without requiring auxiliary networks or altering the training procedure. We demonstrate the effectiveness of our method on three different time series tasks: forecasting, refinement, and synthetic data generation. First, we show that TSDiff is competitive with several task-specific conditional forecasting methods (*predict*). Second, we leverage the learned implicit probability density of TSDiff to iteratively refine the predictions of base forecasters with reduced computational overhead over reverse diffusion (*refine*). Notably, the generative performance of the model remains intact — downstream forecasters trained on synthetic samples from TSDiff outperform forecasters that are trained on samples from other state-of-the-art generative time series models, occasionally even outperforming models trained on real data (*synthesize*).\n\nOur code is available at https://github.com/amazon-science/unconditional-time-series-diffusion'}",https://openreview.net{'value': '/pdf/e4d1c7d53193eff9e355829afaa15e5f527b7da7.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=q4HlFS7B7Y,{'value': 'Discriminative Feature Attributions: Bridging Post Hoc Explainability and Inherent Interpretability'},Usha Bhalla; Suraj Srinivas; Himabindu Lakkaraju,~Usha_Bhalla1; ~Suraj_Srinivas1; ~Himabindu_Lakkaraju1,"{'value': ['Machine Learning Explainability', 'Machine Learning Interpretability']}","{'value': 'With the increased deployment of machine learning models in various real-world applications, researchers and practitioners alike have emphasized the need for explanations of model behaviour. To this end, two broad strategies have been outlined in prior literature to explain models. Post hoc explanation methods explain the behaviour of complex black-box models by identifying features critical to model predictions; however, prior work has shown that these explanations may not be faithful, in that they incorrectly attribute high importance to features that are unimportant or non-discriminative for the underlying task. Inherently interpretable models, on the other hand, circumvent these issues by explicitly encoding explanations into model architecture, meaning their explanations are naturally faithful, but they often exhibit poor predictive performance due to their limited expressive power. In this work, we identify a key reason for the lack of faithfulness of feature attributions: the lack of robustness of the underlying black-box models, especially the erasure of unimportant distractor features in the input. To address this issue, we propose Distractor Erasure Tuning (DiET), a method that adapts black-box models to be robust to distractor erasure, thus providing discriminative and faithful attributions. This strategy naturally combines the ease-of-use of post hoc explanations with the faithfulness of inherently interpretable models. We perform extensive experiments on semi-synthetic and real-world datasets, and show that DiET produces models that (1) closely approximate the original black-box models they are intended to explain, and (2) yield explanations that match approximate ground truths available by construction.'}",https://openreview.net{'value': '/pdf/521a549c806b29acdbc617c9d629b9cc7676306c.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=prftZp6mDH,{'value': 'Label Poisoning is All You Need'},Rishi Dev Jha; Jonathan Hayase; Sewoong Oh,~Rishi_Dev_Jha1; ~Jonathan_Hayase2; ~Sewoong_Oh1,"{'value': ['security', 'backdoor attack']}","{'value': ""In a backdoor attack, an adversary injects corrupted data into a model's training dataset in order to gain control over its predictions on images with a specific attacker-defined trigger. A typical corrupted training example requires altering both the image, by applying the trigger, and the label. Models trained on clean images, therefore, were considered safe from backdoor attacks. However, in some common machine learning scenarios, the training labels are provided by potentially malicious third-parties. This includes crowd-sourced annotation and knowledge distillation. We, hence, investigate a fundamental question: can we launch a successful backdoor attack by only corrupting labels? We introduce a novel approach to design label-only backdoor attacks, which we call FLIP, and demonstrate its strengths on three datasets (CIFAR-10, CIFAR-100, and Tiny-ImageNet) and four architectures (ResNet-32, ResNet-18, VGG-19, and Vision Transformer). With only 2% of CIFAR-10 labels corrupted, FLIP achieves a near-perfect attack success rate of 99.4% while suffering only a 1.8% drop in the clean test accuracy. Our approach builds upon the recent advances in trajectory matching, originally introduced for dataset distillation.""}",https://openreview.net{'value': '/pdf/e486e936273b3586994916184871eeed90309180.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=pb1OwZNgr2,{'value': 'Learning Generalizable Agents via Saliency-guided Features Decorrelation'},Sili Huang; Yanchao Sun; Jifeng Hu; Siyuan Guo; Hechang Chen; Yi Chang; Lichao Sun; Bo Yang,~Sili_Huang1; ~Yanchao_Sun1; ~Jifeng_Hu1; ~Siyuan_Guo2; ~Hechang_Chen2; ~Yi_Chang4; ~Lichao_Sun1; ~Bo_Yang6,"{'value': ['reinforcement learning', 'generalization']}","{'value': 'In visual-based Reinforcement Learning (RL), agents often struggle to generalize well to environmental variations in the state space that were not observed during training. The variations can arise in both task-irrelevant features, such as background noise, and task-relevant features, such as robot configurations, that are related to the optimal decisions. To achieve generalization in both situations, agents are required to accurately understand the impact of changed features on the decisions, i.e., establishing the true associations between changed features and decisions in the policy model. However, due to the inherent correlations among features in the state space, the associations between features and decisions become entangled, making it difficult for the policy to distinguish them. To this end, we propose Saliency-Guided Features Decorrelation (SGFD) to eliminate these correlations through sample reweighting. Concretely, SGFD consists of two core techniques: Random Fourier Functions (RFF) and the saliency map. RFF is utilized to estimate the complex non-linear correlations in high-dimensional images, while the saliency map is designed to identify the changed features. Under the guidance of the saliency map, SGFD employs sample reweighting to minimize the estimated correlations related to changed features, thereby achieving decorrelation in visual RL tasks. Our experimental results demonstrate that SGFD can generalize well on a wide range of test environments and significantly outperforms state-of-the-art methods in handling both task-irrelevant variations and task-relevant variations.'}",https://openreview.net{'value': '/pdf/59d46abd0dcdde36b337831f9b2eae764f27406b.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=pQF9kbM8Ea,{'value': 'Leveraging Vision-Centric Multi-Modal Expertise for 3D Object Detection'},Linyan Huang; Zhiqi Li; Chonghao Sima; Wenhai Wang; Jingdong Wang; Yu Qiao; Hongyang Li,~Linyan_Huang3; ~Zhiqi_Li2; ~Chonghao_Sima1; ~Wenhai_Wang2; ~Jingdong_Wang1; ~Yu_Qiao1; ~Hongyang_Li1,"{'value': ['camera-only detection', 'multi-modal distillation', 'multi-view object detection']}","{'value': 'Current research is primarily dedicated to advancing the accuracy of camera-only 3D object detectors (apprentice) through the knowledge transferred from LiDAR- or multi-modal-based counterparts (expert). However, the presence of the domain gap between LiDAR and camera features, coupled with the inherent incompatibility in temporal fusion, significantly hinders the effectiveness of distillation-based enhancements for apprentices. Motivated by the success of uni-modal distillation, an apprentice-friendly expert model would predominantly rely on camera features, while still achieving comparable performance to multi-modal models. To this end, we introduce VCD, a framework to improve the camera-only apprentice model, including an apprentice-friendly multi-modal expert and temporal-fusion-friendly distillation supervision. The multi-modal expert VCD-E adopts an identical structure as that of the camera-only apprentice in order to alleviate the feature disparity, and leverages LiDAR input as a depth prior to reconstruct the 3D scene, achieving the performance on par with other heterogeneous multi-modal experts. Additionally, a fine-grained trajectory-based distillation module is introduced with the purpose of individually rectifying the motion misalignment for each object in the scene. With those improvements, our camera-only apprentice VCD-A sets new state-of-the-art on nuScenes with a score of 63.1% NDS. The code will be released at https://github.com/OpenDriveLab/Birds-eye-view-Perception.'}",https://openreview.net{'value': '/pdf/334ffc2b2cf94c25a30e705eea24c9872128c6ac.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=pLsPFxqn7J,{'value': 'Kernelized Cumulants: Beyond Kernel Mean Embeddings'},Patric Bonnier; Harald Oberhauser; Zoltán Szabó,~Patric_Bonnier1; ~Harald_Oberhauser1; ~Zoltán_Szabó1,"{'value': ['kernel', 'cumulant', 'mean embedding', 'Hilbert-Schmidt independence criterion', 'maximum mean discrepancy']}","{'value': 'In $\\mathbb{R}^d$, it is well-known that cumulants provide an alternative to moments that can achieve the same goals with numerous benefits such as lower variance estimators. In this paper we extend cumulants to reproducing kernel Hilbert spaces (RKHS) using tools from tensor algebras and show that they are computationally tractable by a kernel trick. These kernelized cumulants provide a new set of all-purpose statistics; the classical maximum mean discrepancy and Hilbert-Schmidt independence criterion arise as the degree one objects in our general construction. We argue both theoretically and empirically (on synthetic, environmental, and traffic data analysis) that going beyond degree one has several advantages and can be achieved with the same computational complexity and minimal overhead in our experiments.'}",https://openreview.net{'value': '/pdf/59b9cbc263627bbb6ad6de91c9f8384e65e0f202.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=p9k5MS0JAL,{'value': 'Demystifying the Optimal Performance of Multi-Class Classification'},Minoh Jeong; Martina Cardone; Alex Dytso,~Minoh_Jeong1; ~Martina_Cardone1; ~Alex_Dytso1,"{'value': ['Bayes error', 'estimation', 'classification', 'minimum error probability']}","{'value': 'Classification is a fundamental task in science and engineering on which machine learning methods have shown outstanding performances. However, it is challenging to determine whether such methods have achieved the Bayes error rate, that is, the lowest error rate attained by any classifier. This is mainly due to the fact that the Bayes error rate is not known in general and hence, effectively estimating it is paramount. Inspired by the work by Ishida et al. (2023), we propose an estimator for the Bayes error rate of supervised multi-class classification problems. We analyze several theoretical aspects of such estimator, including its consistency, unbiasedness, convergence rate, variance, and robustness. We also propose a denoising method that reduces the noise that potentially corrupts the data labels, and we improve the robustness of the proposed estimator to outliers by incorporating the median-of-means estimator. Our analysis demonstrates the consistency, asymptotic unbiasedness, convergence rate, and robustness of the proposed estimators. Finally, we validate the effectiveness of our theoretical results via experiments both on synthetic data under various noise settings and on real data.'}",https://openreview.net{'value': '/pdf/24b6b06070b840cb5466e7e33ce09a2a15835d99.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=p40XRfBX96,{'value': 'Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision'},Zhiqing Sun; Yikang Shen; Qinhong Zhou; Hongxin Zhang; Zhenfang Chen; David Daniel Cox; Yiming Yang; Chuang Gan,~Zhiqing_Sun1; ~Yikang_Shen1; ~Qinhong_Zhou1; ~Hongxin_Zhang1; ~Zhenfang_Chen1; ~David_Daniel_Cox1; ~Yiming_Yang1; ~Chuang_Gan1,"{'value': ['AI Alignment', 'Large Language Models', 'In Context Learning', 'Neural Symbolics']}","{'value': ""Recent AI-assistant agents, such as ChatGPT, predominantly rely on supervised fine-tuning (SFT) with human annotations and reinforcement learning from human feedback (RLHF) to align the output of large language models (LLMs) with human intentions, ensuring they are helpful, ethical, and reliable. However, this dependence can significantly constrain the true potential of AI-assistant agents due to the high cost of obtaining human supervision and the related issues on quality, reliability, diversity, self-consistency, and undesirable biases. To address these challenges, we propose a novel approach called SELF-ALIGN, which combines principle-driven reasoning and the generative power of LLMs for the self-alignment of AI agents with minimal human supervision. Our approach encompasses four stages: first, we use an LLM to generate synthetic prompts, and a topic-guided method to augment the prompt diversity; second, we use a small set of human-written principles for AI models to follow, and guide the LLM through in-context learning from demonstrations (of principles application) to produce helpful, ethical, and reliable responses to user's queries; third, we fine-tune the original LLM with the high-quality self-aligned responses so that the resulting model can generate desirable responses for each query directly without the principle set and the demonstrations anymore; and finally, we offer a refinement step to address the issues of overly-brief or indirect responses. Applying SELF-ALIGN to the LLaMA-65b base language model, we develop an AI assistant named Dromedary. With fewer than 300 lines of human annotations (including < 200 seed prompts, 16 generic principles, and 5 exemplars for in-context learning). Dromedary significantly surpasses the performance of several state-of-the-art AI systems, including Text-Davinci-003 and Alpaca, on benchmark datasets with various settings.""}",https://openreview.net{'value': '/pdf/1442772fe6da271e24e7b731a570952b813b5f64.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=oaCDiKoJ2w,{'value': 'Follow-ups Also Matter: Improving Contextual Bandits via Post-serving Contexts'},Chaoqi Wang; Ziyu Ye; Zhe Feng; Ashwinkumar Badanidiyuru; Haifeng Xu,~Chaoqi_Wang1; ~Ziyu_Ye1; ~Zhe_Feng3; ~Ashwinkumar_Badanidiyuru1; ~Haifeng_Xu1,"{'value': ['linear stochastic bandits', 'online learning', 'partial information', 'contextual bandits']}","{'value': ""Standard contextual bandit problem assumes that all the relevant contexts are observed before the algorithm chooses an arm. This modeling paradigm, while useful, often falls short when dealing with problems in which additional valuable contexts can be observed after arm selection. For example, content recommendation platforms like Youtube, Instagram, Tiktok receive much additional features about a user's reward after the user clicks a content (e.g., how long the user stayed, what is the user's watch speed, etc.). To improve online learning efficiency in these applications,  we  study a novel contextual bandit problem with post-serving contexts and design a new algorithm, poLinUCB,  that achieves tight regret under standard assumptions. Core to our technical proof is a robustified and generalized version of the well-known Elliptical Potential Lemma (EPL), which can accommodate  noise in data. Such robustification is necessary for tackling our problem, though we believe it could also be of general interest.\nExtensive empirical tests on both synthetic and real-world datasets  demonstrate the significant benefit of utilitzing post-serving contexts as well as the superior performance of  our   algorithm over the state-of-the-art approaches.""}",https://openreview.net{'value': '/pdf/27b692ccfb4049b4dc226f20715337b97df31df0.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=nrbR2F29vU,{'value': 'A Scale-Invariant Sorting Criterion to Find a Causal Order in Additive Noise Models'},Alexander Gilbert Reisach; Myriam Tami; Christof Seiler; Antoine Chambaz; Sebastian Weichwald,~Alexander_Gilbert_Reisach1; ~Myriam_Tami1; ~Christof_Seiler2; ~Antoine_Chambaz2; ~Sebastian_Weichwald1,"{'value': ['Causal Discovery', 'Directed Acyclic Graph', 'Varsortability', 'Additive Noise Model', 'Structural Causal Model', 'Simulation', 'Benchmark']}","{'value': 'Additive Noise Models (ANMs) are a common model class for causal discovery from observational data. Due to a lack of real-world data for which an underlying ANM is known, ANMs with randomly sampled parameters are commonly used to simulate data for the evaluation of causal discovery algorithms. While some parameters may be fixed by explicit assumptions, fully specifying an ANM requires choosing all parameters. Reisach et al. (2021) show that, for many ANM parameter choices, sorting the variables by increasing variance yields an ordering close to a causal order and introduce ‘var-sortability’ to quantify this alignment. Since increasing variances may be unrealistic and cannot be exploited when data scales are arbitrary, ANM data are often rescaled to unit variance in causal discovery benchmarking.\n\nWe show that synthetic ANM data are characterized by another pattern that is scale-invariant and thus persists even after standardization: the explainable fraction of a variable’s variance, as captured by the coefficient of determination $R^2$, tends to increase along the causal order. The result is high ‘$R^2$-sortability’, meaning that sorting the variables by increasing $R^2$ yields an ordering close to a causal order. We propose a computationally efficient baseline algorithm termed ‘$R^2$-SortnRegress’ that exploits high $R^2$-sortability and that can match and exceed the performance of established causal discovery algorithms. We show analytically that sufficiently high edge weights lead to a relative decrease of the noise contributions along causal chains, resulting in increasingly deterministic relationships and high $R^2$. We characterize $R^2$-sortability on synthetic data with different simulation parameters and find high values in common settings. Our findings reveal high $R^2$-sortability as an assumption about the data generating process relevant to causal discovery and implicit in many ANM sampling schemes. It should be made explicit, as its prevalence in real-world data is an open question. For causal discovery benchmarking, we provide implementations of $R^2$-sortability, the $R^2$-SortnRegress algorithm, and ANM simulation procedures in our library CausalDisco at https://causaldisco.github.io/CausalDisco/.'}",https://openreview.net{'value': '/pdf/b9338613e408adf15a4749ac4e344896fa69c122.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=noyleECBam,{'value': 'Marginal Density Ratio for Off-Policy Evaluation in Contextual Bandits'},Muhammad Faaiz Taufiq; Arnaud Doucet; Rob Cornish; Jean-Francois Ton,~Muhammad_Faaiz_Taufiq1; ~Arnaud_Doucet2; ~Rob_Cornish1; ~Jean-Francois_Ton2,"{'value': ['contextual bandits', 'variance reduction', 'off-policy evaluation']}","{'value': 'Off-Policy Evaluation (OPE) in contextual bandits is crucial for assessing new policies using existing data without costly experimentation. However, current OPE methods, such as Inverse Probability Weighting (IPW) and Doubly Robust (DR) estimators, suffer from high variance, particularly in cases of low overlap between target and behaviour policies or large action and context spaces. In this paper, we introduce a new OPE estimator for contextual bandits, the Marginal Ratio (MR) estimator, which focuses on the shift in the marginal distribution of outcomes $Y$ instead of the policies themselves. Through rigorous theoretical analysis, we demonstrate the benefits of the MR estimator compared to conventional methods like IPW and DR in terms of variance reduction. Additionally, we establish a connection between the MR estimator and the state-of-the-art Marginalized Inverse Propensity Score (MIPS) estimator, proving that MR achieves lower variance among a generalized family of MIPS estimators. We further illustrate the utility of the MR estimator in causal inference settings, where it exhibits enhanced performance in estimating Average Treatment Effects (ATE). Our experiments on synthetic and real-world datasets corroborate our theoretical findings and highlight the practical advantages of the MR estimator in OPE for contextual bandits.'}",https://openreview.net{'value': '/pdf/6ba632bdec2aef5db51b1dcefb3bc8d6d6d1257f.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=noMktb4ait,{'value': 'Joint Feature and Differentiable $ k $-NN Graph Learning using Dirichlet Energy'},Lei Xu; Lei Chen; Rong Wang; Feiping Nie; Xuelong Li,~Lei_Xu6; ~Lei_Chen12; ~Rong_Wang2; ~Feiping_Nie2; ~Xuelong_Li2,"{'value': ['Feature Selection', 'Differential k-NN Graph', 'Dirichlet Energy']}","{'value': 'Feature selection (FS) plays an important role in machine learning, which extracts important features and accelerates the learning process. In this paper, we propose a deep FS method that simultaneously conducts feature selection and differentiable $ k $-NN graph learning  based on the Dirichlet Energy. The Dirichlet Energy identifies important features by measuring their smoothness on the graph structure, and facilitates the learning of a new graph that reflects the inherent structure in new feature subspace. We employ Optimal Transport theory to address the non-differentiability issue of learning $ k $-NN graphs in neural networks, which theoretically makes our method applicable to other graph neural networks for dynamic graph learning. Furthermore, the proposed framework is interpretable, since all modules are designed algorithmically. We validate the effectiveness of our model with extensive experiments on both synthetic and real-world datasets.'}",https://openreview.net{'value': '/pdf/a7d4b16d0f0d981c6dfb9b965efae2bda0f90ddf.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=neu9JlNweE,{'value': 'Post-processing Private Synthetic Data for Improving Utility on Selected Measures'},Hao Wang; Shivchander Sudalairaj; John Henning; Kristjan Greenewald; Akash Srivastava,~Hao_Wang22; ~Shivchander_Sudalairaj1; ~John_Henning1; ~Kristjan_Greenewald1; ~Akash_Srivastava1,"{'value': ['differential privacy', 'synthetic data']}","{'value': 'Existing private synthetic data generation algorithms are agnostic to downstream tasks. However, end users may have specific requirements that the synthetic data must satisfy. Failure to meet these requirements could significantly reduce the utility of the data for downstream use. We introduce a post-processing technique that improves the utility of the synthetic data with respect to measures selected by the end user, while preserving strong privacy guarantees and dataset quality. Our technique involves resampling from the synthetic data to filter out samples that do not meet the selected utility measures, using an efficient stochastic first-order algorithm to find optimal resampling weights. Through comprehensive numerical experiments, we demonstrate that our approach consistently improves the utility of synthetic data across multiple benchmark datasets and state-of-the-art synthetic data generation algorithms.'}",https://openreview.net{'value': '/pdf/d7bc1678453c0dc80af91df41914c65d9dbec4a2.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=nG35q8pNL9,{'value': 'What Truly Matters in Trajectory Prediction for Autonomous Driving?'},Tran Phong; Haoran Wu; Cunjun Yu; Panpan Cai; Sifa Zheng; David Hsu,~Tran_Phong1; ~Haoran_Wu9; ~Cunjun_Yu1; ~Panpan_Cai1; ~Sifa_Zheng1; ~David_Hsu1,{'value': ['trajectory prediction; autonomous driving']},"{'value': ""Trajectory prediction plays a vital role in the performance of autonomous driving systems, and prediction accuracy, such as average displacement error (ADE) or final displacement error (FDE), is widely used as a performance metric. However, a significant disparity exists between the accuracy of predictors on fixed datasets and driving performance when the predictors are used downstream for vehicle control, because of a dynamics gap. In the real world, the prediction algorithm influences the behavior of the ego vehicle, which, in turn, influences the behaviors of other vehicles nearby. This interaction results in predictor-specific dynamics that directly impacts prediction results. In fixed datasets, since other vehicles' responses are predetermined, this interaction effect is lost, leading to a significant dynamics gap. This paper studies the overlooked significance of this dynamics gap. We also examine several other factors contributing to the disparity between prediction performance and driving performance. The findings highlight the trade-off between the predictor's computational efficiency and prediction accuracy in determining real-world driving performance. In summary,  an interactive, task-driven evaluation protocol for trajectory prediction is crucial to capture its effectiveness for autonomous driving. Source code along with experimental settings is available online (https://whatmatters23.github.io/).""}",https://openreview.net{'value': '/pdf/e1edc5d5f10612b94236f19632180d1671aeec4d.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=nCLdsEzZBV,{'value': 'The Equivalence of Dynamic and Strategic Stability under Regularized Learning in Games'},Victor Boone; Panayotis Mertikopoulos,~Victor_Boone1; ~Panayotis_Mertikopoulos1,"{'value': ['Regularized learning', 'dynamic stability', 'strategic stability', 'Nash equilibrium']}","{'value': ""In this paper, we examine the long-run behavior of regularized, no-regret learning in finite N-player games. A well-known result in the field states that the empirical frequencies of play under no-regret learning converge to the game’s set of coarse correlated equilibria; however, our understanding of how the players' _actual strategies_ evolve over time is much more limited – and, in many cases, non-existent. This issue is exacerbated further by a series of recent results showing that _only_ strict Nash equilibria are stable and attracting under regularized learning, thus making the relation between learning and _pointwise_ solution concepts particularly elusive. In lieu of this, we take a more general approach and instead seek to characterize the _setwise_ rationality properties of the players' day-to-day trajectory of play. To do so, we focus on one of the most stringent criteria of setwise strategic stability, namely that any unilateral deviation from the set in question incurs a cost to the deviator – a property known as _closedness under better replies_ (club). In so doing, we obtain a remarkable equivalence between strategic and dynamic stability: _a product of pure strategies is closed under better replies if and only if its span is stable and attracting under regularized learning._ In addition, we estimate the rate of convergence to such sets, and we show that methods based on entropic regularization (like the exponential weights algorithm) converge at a geometric rate, while projection-based methods converge within a finite number of iterations, even with bandit, payoff-based feedback.""}",https://openreview.net{'value': '/pdf/1d544402bfdd0dcd8791277c8fd7945f97284a9d.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=nArzDm353Y,{'value': 'Training Transitive and Commutative Multimodal Transformers with LoReTTa'},Manuel Tran; Yashin Dicente Cid; Amal Lahiani; Fabian J Theis; Tingying Peng; Eldad Klaiman,~Manuel_Tran2; ~Yashin_Dicente_Cid3; ~Amal_Lahiani1; ~Fabian_J_Theis1; ~Tingying_Peng1; ~Eldad_Klaiman1,"{'value': ['generative pre-training', 'causal modeling', 'masked modeling', 'commutative modeling', 'transitive modeling', 'multimodal learning']}","{'value': 'Training multimodal foundation models is challenging due to the limited availability of multimodal datasets. While many public datasets pair images with text, few combine images with audio or text with audio. Even rarer are datasets that align all three modalities at once. Critical domains such as healthcare, infrastructure, or transportation are particularly affected by missing modalities. This makes it difficult to integrate all modalities into a large pre-trained neural network that can be used out-of-the-box or fine-tuned for different downstream tasks. We introduce LoReTTa ($\\textbf{L}$inking m$\\textbf{O}$dalities with a t$\\textbf{R}$ansitive and commutativ$\\textbf{E}$ pre-$\\textbf{T}$raining s$\\textbf{T}$r$\\textbf{A}$tegy) to address this understudied problem. Our self-supervised framework unifies causal modeling and masked modeling with the rules of commutativity and transitivity. This allows us to transition within and between modalities. As a result, our pre-trained models are better at exploring the true underlying joint probability distribution. Given a dataset containing only the disjoint combinations $(A, B)$ and $(B, C)$, LoReTTa can model the relation $A \\leftrightarrow C$ with $A \\leftrightarrow B \\leftrightarrow C$. In particular, we show that a transformer pre-trained with LoReTTa can handle any mixture of modalities at inference time, including the never-seen pair $(A, C)$ and the triplet $(A, B, C)$. We extensively evaluate our approach on a synthetic, medical, and reinforcement learning dataset. Across different domains, our universal multimodal transformer consistently outperforms strong baselines such as GPT, BERT, and CLIP on tasks involving the missing modality tuple.'}",https://openreview.net{'value': '/pdf/0cde7f4dc8b36bf7a60fea33b4931c67d510c607.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=n8JWIzYPRz,{'value': 'Environment-Aware Dynamic Graph Learning for Out-of-Distribution Generalization'},Haonan Yuan; Qingyun Sun; Xingcheng Fu; Ziwei Zhang; Cheng Ji; Hao Peng; Jianxin Li,~Haonan_Yuan2; ~Qingyun_Sun2; ~Xingcheng_Fu1; ~Ziwei_Zhang1; ~Cheng_Ji1; ~Hao_Peng10; ~Jianxin_Li3,"{'value': ['dynamic graph learning', 'out-of-distribution generalization', 'invariant learning', 'link prediction']}","{'value': 'Dynamic graph neural networks (DGNNs) are increasingly pervasive in exploiting spatio-temporal patterns on dynamic graphs. However, existing works fail to generalize under distribution shifts, which are common in real-world scenarios. As the generation of dynamic graphs is heavily influenced by latent environments, investigating their impacts on the out-of-distribution (OOD) generalization is critical. However, it remains unexplored with the following two major challenges: **(1)** How to properly model and infer the complex environments on dynamic graphs with distribution shifts? **(2)** How to discover invariant patterns given inferred spatio-temporal environments? To solve these challenges, we propose a novel **E**nvironment-**A**ware dynamic **G**raph **LE**arning (**EAGLE**) framework for OOD generalization by modeling complex coupled environments and exploiting spatio-temporal invariant patterns. Specifically, we first design the environment-aware EA-DGNN to model environments by multi-channel environments disentangling. Then, we propose an environment instantiation mechanism for environment diversification with inferred distributions. Finally, we discriminate spatio-temporal invariant patterns for out-of-distribution prediction by the invariant pattern recognition mechanism and perform fine-grained causal interventions node-wisely with a mixture of instantiated environment samples. Experiments on real-world and synthetic dynamic graph datasets demonstrate the superiority of our method against state-of-the-art baselines under distribution shifts. To the best of our knowledge, we are the first to study OOD generalization on dynamic graphs from the environment learning perspective.'}",https://openreview.net{'value': '/pdf/5b03036b4929153d6fa39fb98940b4ef97a114f2.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=n6ztJ3Lrdj,{'value': 'Learning with Explanation Constraints'},Rattana Pukdee; Dylan Sam; J Zico Kolter; Nina Balcan; Pradeep Kumar Ravikumar,~Rattana_Pukdee1; ~Dylan_Sam1; ~J_Zico_Kolter1; ~Nina_Balcan1; ~Pradeep_Kumar_Ravikumar1,"{'value': ['Interpretable ML', 'Semi-supervised learning', 'Learning theory']}","{'value': 'As larger deep learning models are hard to interpret, there has been a recent focus on generating explanations of these black-box models. \nIn contrast, we may have apriori explanations of how models should behave. In this paper, we formalize this notion as learning from explanation constraints and provide a learning theoretic framework to analyze how such explanations can improve the learning of our models.  One may naturally ask, ""When would these explanations be helpful?""\nOur first key contribution addresses this question via a class of models that satisfies these explanation constraints in expectation over new data. We provide a characterization of the benefits of these models (in terms of the reduction of their Rademacher complexities) for a canonical class of explanations given by gradient information in the settings of both linear models and two layer neural networks. In addition, we provide an algorithmic solution for our framework, via a variational approximation that achieves better performance and satisfies these constraints more frequently, when compared to simpler augmented Lagrangian methods to incorporate these explanations. We demonstrate the benefits of our approach over a large array of synthetic and real-world experiments.'}",https://openreview.net{'value': '/pdf/60d42434fb70dee65c5dddcaae4496629ee68325.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=mlbes5TAAg,{'value': 'Unleashing the Power of Randomization in Auditing Differentially Private ML'},Krishna Pillutla; Galen Andrew; Peter Kairouz; Hugh Brendan McMahan; Alina Oprea; Sewoong Oh,~Krishna_Pillutla1; ~Galen_Andrew1; ~Peter_Kairouz1; ~Hugh_Brendan_McMahan1; ~Alina_Oprea1; ~Sewoong_Oh1,"{'value': ['Differential privacy auditing', 'multiple canaries', 'randomization', 'lifting', 'adaptive confidence intervals']}","{'value': 'We present a rigorous methodology for auditing differentially private machine learning by adding multiple carefully designed examples called canaries. We take a first principles approach based on three key components. First, we introduce Lifted Differential Privacy (LiDP) that expands the definition of differential privacy to handle randomized datasets. This gives us the freedom to design randomized canaries. Second, we audit LiDP by trying to distinguish between the model trained with $K$ canaries versus $K-1$ canaries in the dataset, leaving one canary out. By drawing the canaries i.i.d., LiDP can leverage the symmetry in the design and reuse each privately trained model to run multiple statistical tests, one for each canary. Third, we introduce novel confidence intervals that take advantage of the multiple test statistics by adapting to the empirical higher-order correlations. Together, this new recipe demonstrates significant improvements in sample complexity, both theoretically and empirically, using synthetic and real data. Further, recent advances in designing stronger canaries can be readily incorporated in the new framework.'}",https://openreview.net{'value': '/pdf/fd5d0b47b7dda0ef76093bf7eb936cc8c590ef3e.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=mA7nTGXjD3,{'value': 'Provably Fast Convergence of Independent Natural Policy Gradient for Markov Potential Games'},Youbang Sun; Tao Liu; Ruida Zhou; Panganamala Kumar; Shahin Shahrampour,~Youbang_Sun1; ~Tao_Liu8; ~Ruida_Zhou1; ~Panganamala_Kumar1; ~Shahin_Shahrampour2,"{'value': ['Multi Agent Reinforcement Learning', 'Markov Potential Games', 'Natural Policy Gradient', 'Nash Equilibrium']}","{'value': 'This work studies an independent natural policy gradient (NPG) algorithm for the multi-agent reinforcement learning problem in Markov potential games. It is shown that, under mild technical assumptions and the introduction of the \\textit{suboptimality gap}, the independent NPG method with an oracle providing exact policy evaluation asymptotically reaches an $\\epsilon$-Nash Equilibrium (NE) within $\\mathcal{O}(1/\\epsilon)$ iterations. This improves upon the previous best result of $\\mathcal{O}(1/\\epsilon^2)$ iterations and is of the same order, $\\mathcal{O}(1/\\epsilon)$, that is achievable for the single-agent case. Empirical results for a synthetic potential game and a congestion game are presented to verify the theoretical bounds.'}",https://openreview.net{'value': '/pdf/94d395a0e5402a2da0a9a707b9c293a6e0e02401.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=m11TbsaQQI,{'value': 'Efficient Hyper-parameter Optimization with Cubic Regularization'},Zhenqian Shen; Hansi Yang; Yong Li; James Kwok; quanming yao,~Zhenqian_Shen1; ~Hansi_Yang1; ~Yong_Li7; ~James_Kwok1; ~quanming_yao1,"{'value': ['hyper-parameter optimization', 'cubic regularization']}","{'value': 'As hyper-parameters are ubiquitous and can significantly affect the model performance, hyper-parameter optimization is extremely important in machine learning. In this paper, we consider a sub-class of hyper-parameter optimization problems, where the hyper-gradients are not available. Such problems frequently appear when the performance metric is non-differentiable or the hyper-parameter is not continuous. However, existing algorithms, like Bayesian optimization and reinforcement learning, often get trapped in local optimals with poor performance. To address the above limitations, we propose to use cubic regularization to accelerate convergence and avoid saddle points. First, we adopt stochastic relaxation, which allows obtaining gradient and Hessian information without hyper-gradients. Then, we exploit the rich curvature information by cubic regularization. Theoretically, we prove that the proposed method can converge to approximate second-order stationary points, and the convergence is also guaranteed when the lower-level problem is inexactly solved. Experiments on synthetic and real-world data demonstrate the effectiveness of our proposed method.'}",https://openreview.net{'value': '/pdf/655b8321aaec15356ff6e958aa2c0ea427216018.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=lzqaQRsITh,{'value': 'DiffComplete: Diffusion-based Generative 3D Shape Completion'},Ruihang Chu; Enze Xie; Shentong Mo; Zhenguo Li; Matthias Nießner; Chi-Wing Fu; Jiaya Jia,~Ruihang_Chu1; ~Enze_Xie1; ~Shentong_Mo1; ~Zhenguo_Li1; ~Matthias_Nießner2; ~Chi-Wing_Fu2; ~Jiaya_Jia1,"{'value': ['3d shape completion', 'conditional generation', 'diffusion models']}","{'value': 'We introduce a new diffusion-based approach for shape completion on 3D range scans. Compared with prior deterministic and probabilistic methods, we strike a balance between realism, multi-modality, and high fidelity. We propose DiffComplete by casting shape completion as a generative task conditioned on the incomplete shape. Our key designs are two-fold. First, we devise a hierarchical feature aggregation mechanism to inject conditional features in a spatially-consistent manner. So, we can capture both local details and broader contexts of the conditional inputs to control the shape completion. Second, we propose an occupancy-aware fusion strategy in our model to enable the completion of multiple partial shapes and introduce higher flexibility on the input conditions. DiffComplete sets a new SOTA performance (e.g., 40% decrease on $l_1$ error) on two large-scale 3D shape completion benchmarks. Our completed shapes not only have a realistic outlook compared with the deterministic methods but also exhibit high similarity to the ground truths compared with the probabilistic alternatives. Further, DiffComplete has strong generalizability on objects of entirely unseen classes for both synthetic and real data, eliminating the need for model re-training in various applications.'}",https://openreview.net{'value': '/pdf/10749f608d55f21ea893100d9a141f13f1ef1072.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=luyXPdkNSN,{'value': 'K-Nearest-Neighbor Local Sampling Based Conditional Independence Testing'},Shuai Li; Yingjie Zhang; Hongtu Zhu; Christina Dan Wang; Hai Shu; Ziqi Chen; Zhuoran Sun; Yanfeng Yang,~Shuai_Li22; ~Yingjie_Zhang3; ~Hongtu_Zhu3; ~Christina_Dan_Wang1; ~Hai_Shu1; ~Ziqi_Chen2; ~Zhuoran_Sun1; ~Yanfeng_Yang1,"{'value': ['Conditional Independence testing', 'causal inference', 'conditional mutual information', 'k-nearest neighbor', 'conditional randomization test', 'conditional permutation test']}","{'value': 'Conditional independence (CI) testing is a fundamental task in statistics and machine learning, but its effectiveness is hindered by the challenges posed by high-dimensional conditioning variables and limited data samples. This article introduces a novel testing approach to address these challenges and enhance control of the type I error while achieving high power under alternative hypotheses. The proposed approach incorporates a computationally efficient classifier-based conditional mutual information (CMI) estimator, capable of capturing intricate dependence structures among variables. To approximate a distribution encoding the null hypothesis, a $k$-nearest-neighbor local sampling strategy is employed. An important advantage of this approach is its ability to operate without assumptions about distribution forms or feature dependencies. Furthermore, it eliminates the need to derive asymptotic null distributions for the estimated CMI and avoids dataset splitting, making it particularly suitable for small datasets. The method presented in this article demonstrates asymptotic control of the type I error and consistency against all alternative hypotheses. Extensive analyses using both synthetic and real data highlight the computational efficiency of the proposed test. Moreover, it outperforms existing state-of-the-art methods in terms of type I and II errors, even in scenarios with high-dimensional conditioning sets. Additionally, the proposed approach exhibits robustness in the presence of heavy-tailed data.'}",https://openreview.net{'value': '/pdf/3423552767cece65d11c193f0971f4675213b400.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=lOCHMGO6ow,{'value': 'Energy-Based Cross Attention for Bayesian Context Update in Text-to-Image Diffusion Models'},Geon Yeong Park; Jeongsol Kim; Beomsu Kim; Sang Wan Lee; Jong Chul Ye,~Geon_Yeong_Park1; ~Jeongsol_Kim1; ~Beomsu_Kim1; ~Sang_Wan_Lee1; ~Jong_Chul_Ye1,"{'value': ['Diffusion model', 'Energy-based model', 'Text-to-image generation']}","{'value': 'Despite the remarkable performance of text-to-image diffusion models in image generation tasks, recent studies have raised the issue that generated images sometimes cannot capture the intended semantic contents of the text prompts, which phenomenon is often called semantic misalignment. To address this, here we present a novel energy-based model (EBM) framework for adaptive context control by modeling the posterior of context vectors. Specifically, we first formulate EBMs of latent image representations and text embeddings in each cross-attention layer of the denoising autoencoder. Then, we obtain the gradient of the log posterior of context vectors, which can be updated and transferred to the subsequent cross-attention layer, thereby implicitly minimizing a nested hierarchy of energy functions. \nOur latent EBMs further allow zero-shot compositional generation as a linear combination of cross-attention outputs from different contexts. \nUsing extensive experiments, we demonstrate that the proposed method is highly effective in handling various image generation tasks, including multi-concept generation, text-guided image inpainting, and real and synthetic image editing. Code: https://github.com/EnergyAttention/Energy-Based-CrossAttention.'}",https://openreview.net{'value': '/pdf/3c8a9a13e453219a264c90bb216faad548afeaec.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=l9MbuqzlZt,{'value': 'Globally solving the Gromov-Wasserstein problem for point clouds in low dimensional Euclidean spaces'},Martin Ryner; Jan Kronqvist; Johan Karlsson,~Martin_Ryner1; ~Jan_Kronqvist1; ~Johan_Karlsson2,"{'value': ['Gromov-Wasserstein problem', 'QAP', 'Global optimization']}","{'value': 'This paper presents a framework for computing the Gromov-Wasserstein problem between two sets of points in low dimensional spaces, where the discrepancy is the squared Euclidean norm.\nThe Gromov-Wasserstein problem is a generalization of the optimal transport problem that finds the assignment between two sets preserving pairwise distances as much as possible. This can be used to quantify the similarity between two formations or shapes, a common problem in AI and machine learning.\nThe problem can be formulated as a Quadratic Assignment Problem (QAP), which is in general computationally intractable even for small problems. Our framework addresses this challenge by reformulating the QAP as an optimization problem with a low-dimensional domain, leveraging the fact that the problem can be expressed as a concave quadratic optimization problem with low rank. The method scales well with the number of points, and it can be used to find the global solution for large-scale problems with thousands of points.\nWe compare the computational complexity of our approach with state-of-the-art methods on synthetic problems and apply it to a near-symmetrical problem which is of particular interest in computational biology.'}",https://openreview.net{'value': '/pdf/b5dfb9037b60e29975a8726c3f1493603f7e89fc.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=l3HUgVHqGQ,{'value': 'Scan and Snap: Understanding Training Dynamics and Token Composition in 1-layer Transformer'},Yuandong Tian; Yiping Wang; Beidi Chen; Simon Shaolei Du,~Yuandong_Tian1; ~Yiping_Wang2; ~Beidi_Chen1; ~Simon_Shaolei_Du1,"{'value': ['transformer', 'training dynamics', 'theoretical analysis', 'self-attention', 'interpretability', 'neural network understanding']}","{'value': 'Transformer architecture has shown impressive performance in multiple research domains and has become the backbone of many neural network models. However, there is limited understanding on how it works. In particular, with a simple predictive loss,  how the representation emerges from the gradient \\emph{training dynamics} remains a mystery. In this paper, for 1-layer transformer with one self-attention layer plus one decoder layer, we analyze its SGD training dynamics for the task of next token prediction in a mathematically rigorous manner. We open the black box of the dynamic process of how the self-attention layer combines input tokens, and reveal the nature of underlying inductive bias. More specifically, with the assumption (a) no positional encoding, (b) long input sequence, and (c) the decoder layer learns faster than the self-attention layer, we prove that self-attention acts as a \\emph{discriminative scanning algorithm}: \n starting from uniform attention, it gradually attends more to distinct key tokens for a specific next token to be predicted, and pays less attention to common key tokens that occur across different next tokens. Among distinct tokens, it progressively drops attention weights, following the order of low to high co-occurrence between the key and the query token in the training set. Interestingly, this procedure does not lead to winner-takes-all, but stops due to a \\emph{phase transition} that is controllable by the learning rate of the decoder layer, leaving (almost) fixed token combination. We verify this \\textbf{\\emph{scan and snap}} dynamics on synthetic and real-world data (WikiText-103).'}",https://openreview.net{'value': '/pdf/1cc86c4113f201f47f6daae4c43348b7dc30c9d7.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=kfWzpZvEUh,{'value': 'End-to-End Meta-Bayesian Optimisation with Transformer Neural Processes'},Alexandre Max Maraval; Matthieu Zimmer; Antoine Grosnit; Haitham Bou Ammar,~Alexandre_Max_Maraval1; ~Matthieu_Zimmer1; ~Antoine_Grosnit2; ~Haitham_Bou_Ammar1,"{'value': ['meta-learning', 'bayesian optimisation', 'neural process', 'transformer', 'end-to-end', 'reinforcement learning']}","{'value': 'Meta-Bayesian optimisation (meta-BO) aims to improve the sample efficiency of Bayesian optimisation by leveraging data from related tasks. While previous methods successfully meta-learn either a surrogate model or an acquisition function independently, joint training of both components remains an open challenge. This paper proposes the first end-to-end differentiable meta-BO framework that generalises neural processes to learn acquisition functions via transformer architectures. We enable this end-to-end framework with reinforcement learning (RL) to tackle the lack of labelled acquisition data. Early on, we notice that training transformer-based neural processes from scratch with RL is challenging due to insufficient supervision, especially when rewards are sparse. We formalise this claim with a combinatorial analysis showing that the widely used notion of regret as a reward signal exhibits a logarithmic sparsity pattern in trajectory lengths. To tackle this problem, we augment the RL objective with an auxiliary task that guides part of the architecture to learn a valid probabilistic model as an inductive bias. We demonstrate that our method achieves state-of-the-art regret results against various baselines in experiments on standard hyperparameter optimisation tasks and also outperforms others in the real-world problems of mixed-integer programming tuning, antibody design, and logic synthesis for electronic design automation.'}",https://openreview.net{'value': '/pdf/867947ccf4f165b4f1594525463e9f3fd51d8237.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=kS7ED7eE74,{'value': 'A Fractional Graph Laplacian Approach to Oversmoothing'},Sohir Maskey; Raffaele Paolino; Aras Bacho; Gitta Kutyniok,~Sohir_Maskey1; ~Raffaele_Paolino1; ~Aras_Bacho1; ~Gitta_Kutyniok2,"{'value': ['Graph Neural Networks', 'Graph Neural ODE', 'Fractional Laplacian', 'Oversmoothing']}","{'value': 'Graph neural networks (GNNs) have shown state-of-the-art performances in various applications. However, GNNs often struggle to capture long-range dependencies in graphs due to oversmoothing. In this paper, we generalize the concept of oversmoothing from undirected to directed graphs. To this aim, we extend the notion of Dirichlet energy by considering a directed symmetrically normalized Laplacian. As vanilla graph convolutional networks are prone to oversmooth, we adopt a neural graph ODE framework. Specifically, we propose fractional graph Laplacian neural ODEs, which describe non-local dynamics. We prove that our approach allows propagating information  between distant nodes while maintaining a low probability of long-distance jumps. Moreover, we show that our method is more flexible with respect to the convergence of the graph’s Dirichlet energy, thereby mitigating oversmoothing. We conduct extensive experiments on synthetic and real-world graphs, both  directed and undirected, demonstrating our method’s versatility across diverse graph homophily levels.  Our\ncode is available at https://github.com/RPaolino/fLode'}",https://openreview.net{'value': '/pdf/c5966f9d4fe19f416d890769d429189ff6716570.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=kR21XsZeAr,{'value': 'Subclass-Dominant Label Noise: A Counterexample for the Success of Early Stopping'},Yingbin Bai; Zhongyi Han; Erkun Yang; Jun Yu; Bo Han; Dadong Wang; Tongliang Liu,~Yingbin_Bai1; ~Zhongyi_Han1; ~Erkun_Yang2; ~Jun_Yu3; ~Bo_Han1; ~Dadong_Wang1; ~Tongliang_Liu1,"{'value': ['learning with noisy labels', 'weakly supervised learning']}","{'value': 'In this paper, we empirically investigate a previously overlooked and widespread type of label noise, subclass-dominant label noise (SDN). Our findings reveal that, during the early stages of training, deep neural networks can rapidly memorize mislabeled examples in SDN. This phenomenon poses challenges in effectively selecting confident examples using conventional early stopping techniques. To address this issue, we delve into the properties of SDN and observe that long-trained representations are superior at capturing the high-level semantics of mislabeled examples, leading to a clustering effect where similar examples are grouped together. Based on this observation, we propose a novel method called NoiseCluster that leverages the geometric structures of long-trained representations to identify and correct SDN. Our experiments demonstrate that NoiseCluster outperforms state-of-the-art baselines on both synthetic and real-world datasets, highlighting the importance of addressing SDN in learning with noisy labels. The code is available at https://github.com/tmllab/2023_NeurIPS_SDN.'}",https://openreview.net{'value': '/pdf/76d74379c5cdebf43777fc37ce078aedd3e66ca1.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=kPfd3pcwHV,{'value': 'Online Ad Allocation with Predictions'},Fabian Christian Spaeh; Alina Ene,~Fabian_Christian_Spaeh1; ~Alina_Ene1,"{'value': ['Learning Augmented Algorithms', 'Display Ads', 'Generalized Assignment Problem']}","{'value': 'Display Ads and the generalized assignment problem are two well-studied online packing problems with important applications in ad allocation and other areas. In both problems, ad impressions arrive online and have to be allocated immediately to budget-constrained advertisers. Worst-case algorithms that achieve the ideal competitive ratio are known for both problems, but might act overly conservative given the predictable and usually tame nature of real-world input. Given this discrepancy, we develop an algorithm for both problems that incorporate machine-learned predictions and can thus improve the performance beyond the worst-case. Our algorithm is based on the work of Feldman et al. (2009) and similar in nature to Mahdian et al. (2007) who were the first to develop a learning-augmented algorithm for the related, but more structured Ad Words problem. We use a novel analysis to show that our algorithm is able to capitalize on a good prediction, while being robust against poor predictions. We experimentally evaluate our algorithm on synthetic and real-world data on a wide range of predictions. Our algorithm is consistently outperforming the worst-case algorithm without predictions.'}",https://openreview.net{'value': '/pdf/ebd5e09bba68c91370476ce5d2c630baa6e5be70.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=kJmYu3Ti2z,{'value': 'When Do Graph Neural Networks Help with Node Classification? Investigating the Homophily Principle on Node Distinguishability'},Sitao Luan; Chenqing Hua; Minkai Xu; Qincheng Lu; Jiaqi Zhu; Xiao-Wen Chang; Jie Fu; Jure Leskovec; Doina Precup,~Sitao_Luan1; ~Chenqing_Hua1; ~Minkai_Xu1; ~Qincheng_Lu1; ~Jiaqi_Zhu1; ~Xiao-Wen_Chang1; ~Jie_Fu2; ~Jure_Leskovec1; ~Doina_Precup1,"{'value': ['Graph Neural Networks', 'Homophily', 'Heterophily', 'Low-pass filter', 'High-pass filter', 'Node Distinguishability', 'Metrics']}","{'value': ""Homophily principle, i.e., nodes with the same labels are more likely to be connected, has been believed to be the main reason for the performance superiority of Graph Neural Networks (GNNs) over Neural Networks on node classification tasks. Recent research suggests that, even in the absence of homophily, the advantage of GNNs still exists as long as nodes from the same class share similar neighborhood patterns. However, this argument only considers intra-class Node Distinguishability (ND) but neglects inter-class ND, which provides incomplete understanding of homophily on GNNs. In this paper, we first demonstrate such deficiency with examples and argue that an ideal situation for ND is to have smaller intra-class ND than inter-class ND. To formulate this idea and study ND deeply, we propose Contextual Stochastic Block Model for Homophily (CSBM-H) and define two metrics, Probabilistic Bayes Error (PBE) and negative generalized Jeffreys divergence, to quantify ND. With the metrics, we visualize and analyze how graph filters, node degree distributions and class variances influence ND, and investigate the combined effect of intra- and inter-class ND. Besides, we discovered the mid-homophily pitfall, which occurs widely in graph datasets. Furthermore, we verified that, in real-work tasks, the superiority of GNNs is indeed closely related to both intra- and inter-class ND regardless of homophily levels. Grounded in this observation, we propose a new hypothesis-testing based performance metric beyond homophily, which is non-linear, feature-based and can provide statistical threshold value for GNNs' the superiority. Experiments indicate that it is significantly more effective than the existing homophily metrics on revealing the advantage and disadvantage of graph-aware modes on both synthetic and benchmark real-world datasets.""}",https://openreview.net{'value': '/pdf/ffc670cc2838c9d29120e324534cbfb650374a5a.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=kBBsj9KRgh,{'value': 'SAME: Uncovering GNN Black Box with Structure-aware Shapley-based Multipiece Explanations'},Ziyuan Ye; Rihan Huang; Qilin Wu; Quanying Liu,~Ziyuan_Ye1; ~Rihan_Huang1; kyrinwu@gmail.com; ~Quanying_Liu1,"{'value': ['GNN explainability', 'Shapley value', 'Monte Carlo tree search', 'structure awareness', 'multi-grained explanation']}","{'value': 'Post-hoc explanation techniques on graph neural networks (GNNs) provide economical solutions for opening the black-box graph models without model retraining. Many GNN explanation variants have achieved state-of-the-art explaining results on a diverse set of benchmarks, while they rarely provide theoretical analysis for their inherent properties and explanatory capability. In this work, we propose $\\underline{\\text{S}}$tructure-$\\underline{\\text{A}}$ware Shapley-based $\\underline{\\text{M}}$ultipiece $\\underline{\\text{E}}$xplanation (SAME) method to address the structure-aware feature interactions challenges for GNNs explanation. Specifically, SAME leverages an expansion-based Monte Carlo tree search to explore the multi-grained structure-aware connected substructure. Afterward, the explanation results are encouraged to be informative of the graph properties by optimizing the combination of distinct single substructures. With the consideration of fair feature interactions in the process of investigating multiple connected important substructures, the explanation provided by SAME has the potential to be as explainable as the theoretically optimal explanation obtained by the Shapley value within polynomial time. Extensive experiments on real-world and synthetic benchmarks show that SAME improves the previous state-of-the-art fidelity performance by 12.9\\% on BBBP, 7.01\\% on MUTAG, 42.3\\% on Graph-SST2, 38.9\\% on Graph-SST5, 11.3\\% on BA-2Motifs and 18.2\\% on BA-Shapes under the same testing condition. Code is available at https://github.com/same2023neurips/same.'}",https://openreview.net{'value': '/pdf/2d51deea1a7c895cf241e35290379cd4ef2cacc6.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=k1Xy5zCNOJ,"{'value': 'Lookaround Optimizer: $k$ steps around, 1 step average'}",Jiangtao Zhang; Shunyu Liu; Jie Song; Tongtian Zhu; Zhengqi Xu; Mingli Song,~Jiangtao_Zhang1; ~Shunyu_Liu1; ~Jie_Song3; ~Tongtian_Zhu1; ~Zhengqi_Xu2; ~Mingli_Song1,"{'value': ['Deep Learning', 'Computer Vision', 'Mode Connectivity', 'Weight Average']}","{'value': 'Weight Average (WA) is an active research topic due to its simplicity in ensembling deep networks and the effectiveness in promoting generalization. Existing weight average approaches, however, are often carried out along only one training trajectory in a post-hoc manner (i.e., the weights are averaged after the entire training process is finished), which significantly degrades the diversity between networks and thus impairs the effectiveness. In this paper, inspired by weight average, we propose Lookaround, a straightforward yet effective SGD-based optimizer leading to flatter minima with better generalization. Specifically, Lookaround iterates two steps during the whole training period: the around step and the average step. In each iteration, 1) the around step starts from a common point and trains multiple networks simultaneously, each on transformed data by a different data augmentation, and 2) the average step averages these trained networks to get the averaged network, which serves as the starting point for the next iteration. The around step improves the functionality diversity while the average step guarantees the weight locality of these networks during the whole training, which is essential for WA to work. We theoretically explain the superiority of Lookaround by convergence analysis, and make extensive experiments to evaluate Lookaround on popular benchmarks including CIFAR and ImageNet with both CNNs and ViTs, demonstrating clear superiority over state-of-the-arts. Our code is available at https://github.com/Ardcy/Lookaround.'}",https://openreview.net{'value': '/pdf/1fecc8f586ca7fa43703937f1325ad0425427de1.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=jhs8F63xI6,{'value': 'Adaptive Online Replanning with Diffusion Models'},Siyuan Zhou; Yilun Du; Shun Zhang; Mengdi Xu; Yikang Shen; Wei Xiao; Dit-Yan Yeung; Chuang Gan,~Siyuan_Zhou2; ~Yilun_Du1; ~Shun_Zhang6; ~Mengdi_Xu3; ~Yikang_Shen1; ~Wei_Xiao2; ~Dit-Yan_Yeung2; ~Chuang_Gan1,"{'value': ['Decision making', 'Robotics', 'Planning-based']}","{'value': ""Diffusion models have risen a promising approach to data-driven planning, and have demonstrated impressive robotic control, reinforcement learning, and video planning performance. Given an effective planner, an important question to consider is replanning -- when given plans should be regenerated due to both action execution error and external environment changes.  Direct plan execution, without replanning, is problematic as errors from individual actions rapidly accumulate and environments are partially observable and stochastic. Simultaneously, replanning at each timestep incurs a substantial computational cost, and may prevent successful task execution, as different generated plans prevent consistent progress to any particular goal. In this paper, we explore how we may effectively replan with diffusion models. We propose a principled approach to determine when to replan, based on the diffusion model's estimated likelihood of existing generated plans. We further present an approach to replan existing trajectories to ensure that new plans follow the same goal state as the original trajectory, which may efficiently bootstrap off previously generated plans.  We illustrate how a combination of our proposed additions significantly improves the performance of diffusion planners leading to 38\\% gains over past diffusion planning approaches on Maze2D and further enables handling of stochastic and long-horizon robotic control tasks.""}",https://openreview.net{'value': '/pdf/d071ca735af8d27368640c939173aab5aa7c5448.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=jcRB6xHdJ2,"{'value': 'Interaction Measures, Partition Lattices and Kernel Tests for High-Order Interactions'}",Zhaolu Liu; Robert Peach; Pedro A. M. Mediano; Mauricio Barahona,~Zhaolu_Liu1; ~Robert_Peach1; ~Pedro_A._M._Mediano1; ~Mauricio_Barahona1,{'value': ['High-order interactions; Lattice theory; Kernel tests']},"{'value': 'Models that rely solely on pairwise relationships often fail to capture the complete statistical structure of the complex multivariate data found in diverse domains, such as socio-economic, ecological, or biomedical systems. Non-trivial dependencies between groups of more than two variables can play a significant role in the analysis and modelling of such systems, yet extracting such high-order interactions from data remains challenging. Here, we introduce a hierarchy of $d$-order ($d \\geq 2$) interaction measures, increasingly inclusive of possible factorisations of the joint probability distribution, and define non-parametric, kernel-based tests to establish systematically the statistical significance of $d$-order interactions. We also establish mathematical links with lattice theory, which elucidate the derivation of the interaction measures and their composite permutation tests; clarify the connection of simplicial complexes with kernel matrix centring; and provide a means to enhance computational efficiency. We illustrate our results numerically with validations on synthetic data, and through an application to neuroimaging data.'}",https://openreview.net{'value': '/pdf/f7d01f3a099b7bcbb8d2d6606e31fdbeeb28bb6f.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=jDIlzSU8wJ,{'value': 'The Surprising Effectiveness of Diffusion Models for Optical Flow and Monocular Depth Estimation'},Saurabh Saxena; Charles Herrmann; Junhwa Hur; Abhishek Kar; Mohammad Norouzi; Deqing Sun; David J. Fleet,~Saurabh_Saxena1; ~Charles_Herrmann1; ~Junhwa_Hur1; ~Abhishek_Kar1; ~Mohammad_Norouzi1; ~Deqing_Sun2; ~David_J._Fleet1,"{'value': ['Monocular depth', 'optical flow', 'diffusion', 'depth', 'flow']}","{'value': ""Denoising diffusion probabilistic models have transformed image generation with their impressive fidelity and diversity.\nWe show that they also excel in estimating optical flow and monocular depth, surprisingly without task-specific architectures and loss functions that are predominant for these tasks. \nCompared to the point estimates of conventional regression-based methods, diffusion models also enable Monte Carlo inference, e.g., capturing uncertainty and ambiguity in flow and depth.\nWith self-supervised pre-training, the combined use of synthetic and real data for supervised training, and technical innovations (infilling and step-unrolled denoising diffusion training) to handle noisy-incomplete training data, one can train state-of-the-art diffusion models for depth and optical flow estimation, with additional zero-shot coarse-to-fine refinement for high resolution estimates. \nExtensive experiments focus on quantitative performance against benchmarks, ablations, and the model's ability to capture uncertainty and multimodality, and impute missing values. Our model obtains a state-of-the-art relative depth error of 0.074 on the indoor NYU benchmark and an Fl-all score of 3.26\\% on the KITTI  optical flow benchmark, about 25\\% better than the best published method.""}",https://openreview.net{'value': '/pdf/a9803ecc1ba03bbc2373e4eda61e4a21987c6093.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=jB4wsc1DQW,{'value': 'Hierarchical Adaptive Value Estimation for Multi-modal Visual Reinforcement Learning'},Yangru Huang; Peixi Peng; Yifan Zhao; Haoran Xu; Mengyue Geng; Yonghong Tian,~Yangru_Huang1; ~Peixi_Peng2; ~Yifan_Zhao2; ~Haoran_Xu5; ~Mengyue_Geng1; ~Yonghong_Tian1,"{'value': ['vision-based reinforcement learning', 'multi-modal', 'event camera']}","{'value': ""Integrating RGB frames with alternative modality inputs is gaining increasing traction in many vision-based reinforcement learning (RL) applications. Existing multi-modal vision-based RL methods usually follow a Global Value Estimation (GVE) pipeline, which uses a fused modality feature to obtain a unified global environmental description. However, such a feature-level fusion paradigm with a single critic may fall short in policy learning as it tends to overlook the distinct values of each modality. To remedy this, this paper proposes a Local modality-customized Value Estimation (LVE) paradigm, which dynamically estimates the contribution and adjusts the importance weight of each modality from a value-level perspective. Furthermore, a task-contextual re-fusion process is developed to achieve a task-level re-balance of estimations from both feature and value levels. To this end, a Hierarchical Adaptive Value Estimation (HAVE) framework is formed, which adaptively coordinates the contributions of individual modalities as well as their collective efficacy. Agents trained by HAVE are able to exploit the unique characteristics of various modalities while capturing their intricate interactions, achieving substantially improved performance. We specifically highlight the potency of our approach within the challenging landscape of autonomous driving, utilizing the CARLA benchmark with neuromorphic event and depth data to demonstrate HAVE's capability and the effectiveness of its distinct components.""}",https://openreview.net{'value': '/pdf/5d2ecae63b5855fa6b068ffcdb39345f94e36fc2.pdf'},{'abstract_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=ixcsBZw5pl,{'value': 'Non-adversarial training of Neural SDEs with signature kernel scores'},Zacharia Issa; Blanka Horvath; Maud Lemercier; Cristopher Salvi,zacharia.issa@kcl.ac.uk; ~Blanka_Horvath1; ~Maud_Lemercier1; ~Cristopher_Salvi1,"{'value': ['Neural SDEs', 'score-based generative models', 'signature kernels', 'time series']}","{'value': 'Neural SDEs are continuous-time generative models for sequential data. State-of-the-art performance for irregular time series generation has been previously obtained by training these models adversarially as GANs. However, as typical for GAN architectures, training is notoriously unstable, often suffers from mode collapse, and requires specialised techniques such as weight clipping and gradient penalty to mitigate these issues. In this paper, we introduce a novel class of scoring rules on pathspace based on signature kernels and use them as objective for training Neural SDEs non-adversarially. By showing strict properness of such kernel scores and consistency of the corresponding estimators, we provide existence and uniqueness guarantees for the minimiser. With this formulation, evaluating the generator-discriminator pair amounts to solving a system of linear path-dependent PDEs which allows for memory-efficient adjoint-based backpropagation. Moreover, because the proposed kernel scores are well-defined for paths with values in infinite dimensional spaces of functions, our framework can be easily extended to generate spatiotemporal data. Our procedure significantly outperforms alternative ways of training Neural SDEs on a variety of tasks including the simulation of rough volatility models, the conditional probabilistic forecasts of real-world forex pairs where the conditioning variable is an observed past trajectory, and the mesh-free generation of limit order book dynamics.'}",https://openreview.net{'value': '/pdf/5b8f1bc4e2337fea43d854302b168c2dfe56d7b7.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=iuqCXg1Gng,{'value': 'Saddle-to-Saddle Dynamics in Diagonal Linear Networks'},Scott Pesme; Nicolas Flammarion,~Scott_Pesme1; ~Nicolas_Flammarion1,"{'value': ['gradient flow', 'saddle-to-saddle', 'diagonal linear network', 'incremental learning']}","{'value': 'In this paper we fully describe the trajectory of gradient flow over $2$-layer diagonal linear networks for the regression setting in the limit of vanishing initialisation. We show that the limiting flow successively jumps from a saddle of the training loss to another until reaching the minimum $\\ell_1$-norm solution. We explicitly characterise the visited saddles as well as the jump times through a recursive algorithm reminiscent of the LARS algorithm used for computing the Lasso path.  Starting from the zero vector, coordinates are successively activated until the minimum $\\ell_1$-norm solution is recovered, revealing an incremental learning. Our proof leverages a convenient arc-length time-reparametrisation which enables to keep track of the transitions between the jumps. Our analysis requires negligible assumptions on the data, applies to both under and overparametrised settings and covers complex cases where there is no monotonicity of the number of active coordinates. We provide numerical experiments to support our findings.'}",https://openreview.net{'value': '/pdf/2076d0adc02feb62e5df2cd9acf0eeabff55a83a.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=igE3Zbxvws,{'value': 'Maximum Independent Set: Self-Training through Dynamic Programming'},Lorenzo Brusca; Lars C.P.M. Quaedvlieg; Stratis Skoulakis; Grigorios Chrysos; Volkan Cevher,~Lorenzo_Brusca1; ~Lars_C.P.M._Quaedvlieg1; ~Stratis_Skoulakis2; ~Grigorios_Chrysos1; ~Volkan_Cevher1,"{'value': ['Maximum Independent Set', 'Combinatorial Optimization', 'Graph Neural Networks', 'Dynamic Programming']}","{'value': 'This work presents a graph neural network (GNN) framework for solving the maximum independent set (MIS) problem, inspired by dynamic programming (DP). Specifically, given a graph, we propose a DP-like recursive algorithm based on GNNs that firstly constructs two smaller sub-graphs, predicts the one with the larger MIS, and then uses it in the next recursive call. To train our algorithm, we require annotated comparisons of different graphs concerning their MIS size. Annotating the comparisons with the output of our algorithm leads to a self-training process that results in more accurate self-annotation of the comparisons and vice versa. We provide numerical evidence showing the superiority of our method vs prior methods in multiple synthetic and real-world datasets.'}",https://openreview.net{'value': '/pdf/4edc3fb16d24ee8aafc168d27152a46b9166dacd.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=iajxrSgOSX,{'value': 'DELIFFAS: Deformable Light Fields for Fast Avatar Synthesis'},YoungJoong Kwon; Lingjie Liu; Henry Fuchs; Marc Habermann; Christian Theobalt,~YoungJoong_Kwon1; ~Lingjie_Liu1; ~Henry_Fuchs1; ~Marc_Habermann1; ~Christian_Theobalt2,"{'value': ['DELIFFAS: Avatar Modeling', 'Avatar Synthesis', 'Animatable Human', 'Light Fields', 'Human Performance Capture']}","{'value': 'Generating controllable and photorealistic digital human avatars is a long-standing and important problem in Vision and Graphics. Recent methods have shown great progress in terms of either photorealism or inference speed while the combination of the two desired properties still remains unsolved. To this end, we propose a novel method, called DELIFFAS, which parameterizes the appearance of the human as a surface light field that is attached to a controllable and deforming human mesh model. At the core, we represent the light field around the human with a deformable two-surface parameterization, which enables fast and accurate inference of the human appearance. This allows perceptual supervision on the full image compared to previous approaches that could only supervise individual pixels or small patches due to their slow runtime. Our carefully designed human representation and supervision strategy leads to state-of-the-art synthesis results and inference time. The video results and code are available at https://vcai.mpi-inf.mpg.de/projects/DELIFFAS.'}",https://openreview.net{'value': '/pdf/0e17977d6d3af2b2a64f89790dc2f7b07d5a76cb.pdf'},{'title_filter': 'Data Synthesis'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=i39yXaUKuF,{'value': 'Segment Any Point Cloud Sequences by Distilling Vision Foundation Models'},Youquan Liu; Lingdong Kong; Jun CEN; Runnan Chen; Wenwei Zhang; Liang Pan; Kai Chen; Ziwei Liu,~Youquan_Liu1; ~Lingdong_Kong1; ~Jun_CEN1; ~Runnan_Chen1; ~Wenwei_Zhang1; ~Liang_Pan2; ~Kai_Chen4; ~Ziwei_Liu1,"{'value': ['autonomous driving', 'point cloud segmentation', 'self-supervised learning', '3D scene understanding']}","{'value': 'Recent advancements in vision foundation models (VFMs) have opened up new possibilities for versatile and efficient visual perception. In this work, we introduce Seal, a novel framework that harnesses VFMs for segmenting diverse automotive point cloud sequences. Seal exhibits three appealing properties: i) Scalability: VFMs are directly distilled into point clouds, obviating the need for annotations in either 2D or 3D during pretraining. ii) Consistency: Spatial and temporal relationships are enforced at both the camera-to-LiDAR and point-to-segment regularization stages, facilitating cross-modal representation learning. iii) Generalizability: Seal enables knowledge transfer in an off-the-shelf manner to downstream tasks involving diverse point clouds, including those from real/synthetic, low/high-resolution, large/small-scale, and clean/corrupted datasets. Extensive experiments conducted on eleven different point cloud datasets showcase the effectiveness and superiority of Seal. Notably, Seal achieves a remarkable 45.0% mIoU on nuScenes after linear probing, surpassing random initialization by 36.9% mIoU and outperforming prior arts by 6.1% mIoU. Moreover, Seal demonstrates significant performance gains over existing methods across 20 different few-shot fine-tuning tasks on all eleven tested point cloud datasets. The code is available at this link.'}",https://openreview.net{'value': '/pdf/7d3d077fa1c2341a156744922bec0648efc4a56a.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=htkdwc6jDB,"{'value': '$p$-value Adjustment for Monotonous, Unbiased, and Fast Clustering Comparison'}",Kai Klede; Thomas Altstidl; Dario Zanca; Bjoern Eskofier,~Kai_Klede1; ~Thomas_Altstidl1; ~Dario_Zanca1; ~Bjoern_Eskofier1,"{'value': ['Clustering', '(Other) Machine Learning Topics']}","{'value': 'Popular metrics for clustering comparison, like the Adjusted Rand Index and the Adjusted Mutual Information, are type II biased. The Standardized Mutual Information removes this bias but suffers from counterintuitive non-monotonicity and poor computational efficiency. We introduce the $p$-value adjusted Rand Index ($\\operatorname{PMI}_2$), the first cluster comparison method that is type II unbiased and provably monotonous. The $\\operatorname{PMI}_2$ has fast approximations that outperform the Standardized Mutual information. We demonstrate its unbiased clustering selection, approximation quality, and runtime efficiency on synthetic benchmarks. In experiments on image and social network datasets, we show how the $\\operatorname{PMI}_2$ can help practitioners choose better clustering and community detection algorithms.'}",https://openreview.net{'value': '/pdf/03aa40ff289424992bd55db9f681bd8702cbc40f.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=htM8yp2EwX,{'value': 'AMDP: An Adaptive Detection Procedure for False Discovery Rate Control in High-Dimensional Mediation Analysis'},Jiarong Ding; Xuehu Zhu,djr9901@stu.xjtu.edu.cn; ~Xuehu_Zhu1,"{'value': ['Mediation analysis', 'Composite null hypothesis', 'Local false discovery rate', 'Optimal ranking rule', 'High-dimensional']}","{'value': 'High-dimensional mediation analysis is often associated with a multiple testing problem for detecting significant mediators. Assessing the uncertainty of this detecting process via false discovery rate (FDR) has garnered great interest. To control the FDR in multiple testing, two essential steps are involved: ranking and selection. Existing approaches either construct p-values without calibration or disregard the joint information across tests, leading to conservation in FDR control or non-optimal ranking rules for multiple hypotheses. In this paper, we develop an adaptive mediation detection procedure (referred to as ""AMDP"") to identify relevant mediators while asymptotically controlling the FDR in high-dimensional mediation analysis. AMDP produces the optimal rule for ranking hypotheses and proposes a data-driven strategy to determine the threshold for mediator selection. This novel method captures information from the proportions of composite null hypotheses and the distribution of p-values, which turns the high dimensionality into an advantage instead of a limitation. The numerical studies on synthetic and real data sets illustrate the performances of AMDP compared with existing approaches.'}",https://openreview.net{'value': '/pdf/cd6d250d84e4259b0e4ad34d1bca7bb04ba2d7a5.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=hLPJ7xLbNF,{'value': 'Self-Supervised Motion Magnification by Backpropagating Through Optical Flow'},Zhaoying Pan; Daniel Geng; Andrew Owens,~Zhaoying_Pan1; ~Daniel_Geng1; ~Andrew_Owens1,"{'value': ['Video Processing', 'Motion Processing', 'Motion Magnification', 'Optical Flow']}","{'value': 'This paper presents a simple, self-supervised method for magnifying subtle motions in video: given an input video and a magnification factor, we manipulate the video such that its new optical flow is scaled by the desired amount. To train our model, we propose a loss function that estimates the optical flow of the generated video and penalizes how far if deviates from the given magnification factor. Thus, training involves differentiating through a pretrained optical flow network. Since our model is self-supervised, we can further improve its performance through test-time adaptation, by finetuning it on the input video. It can also be easily extended to magnify the motions of only user-selected objects. Our approach avoids the need for synthetic magnification datasets that have been used to train prior learning-based approaches. Instead, it leverages the existing capabilities of off-the-shelf motion estimators. We demonstrate the effectiveness of our method through evaluations of both visual quality and quantitative metrics on a range of real-world and synthetic videos, and we show our method works for both supervised and unsupervised optical flow methods.'}",https://openreview.net{'value': '/pdf/42d67d8246ccd9831409386a4e598d59b8a5fc5f.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=h3lTrt4Ftb,{'value': 'Large language models implicitly learn to straighten neural sentence trajectories to construct a predictive representation of natural language.'},Eghbal A. Hosseini; Evelina Fedorenko,~Eghbal_A._Hosseini1; ~Evelina_Fedorenko1,"{'value': ['(Cognitive/Neuroscience) Language', 'Structured Prediction', '(Application) Natural Language and Text Processing']}","{'value': 'Predicting upcoming events is critical to our ability to effectively interact with our\nenvironment and conspecifics. In natural language processing, transformer models,\nwhich are trained on next-word prediction, appear to construct a general-purpose\nrepresentation of language that can support diverse downstream tasks. However, we\nstill lack an understanding of how a predictive objective shapes such representations.\nInspired by recent work in vision neuroscience Hénaff et al. (2019), here we test a\nhypothesis about predictive representations of autoregressive transformer models.\nIn particular, we test whether the neural trajectory of a sequence of words in a\nsentence becomes progressively more straight as it passes through the layers of the\nnetwork. The key insight behind this hypothesis is that straighter trajectories should\nfacilitate prediction via linear extrapolation. We quantify straightness using a 1-\ndimensional curvature metric, and present four findings in support of the trajectory\nstraightening hypothesis: i) In trained models, the curvature progressively decreases\nfrom the first to the middle layers of the network. ii) Models that perform better on\nthe next-word prediction objective, including larger models and models trained on\nlarger datasets, exhibit greater decreases in curvature, suggesting that this improved\nability to straighten sentence neural trajectories may be the underlying driver of\nbetter language modeling performance. iii) Given the same linguistic context, the\nsequences that are generated by the model have lower curvature than the ground\ntruth (the actual continuations observed in a language corpus), suggesting that\nthe model favors straighter trajectories for making predictions. iv) A consistent\nrelationship holds between the average curvature and the average surprisal of\nsentences in the middle layers of models, such that sentences with straighter neural\ntrajectories also have lower surprisal. Importantly, untrained models don’t exhibit\nthese behaviors. In tandem, these results support the trajectory straightening\nhypothesis and provide a possible mechanism for how the geometry of the internal\nrepresentations of autoregressive models supports next word prediction.'}",https://openreview.net{'value': '/pdf/4d626c7f1dcb88b770850efb6a4ac4018266188c.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=guyhQMSp2F,{'value': 'Use perturbations when learning from explanations'},Juyeon Heo; Vihari Piratla; Matthew Robert Wicker; Adrian Weller,~Juyeon_Heo1; ~Vihari_Piratla1; ~Matthew_Robert_Wicker1; ~Adrian_Weller1,"{'value': ['Learning from explanation', 'Robustness', 'Interpretability', 'Shortcuts', 'Explanations']}","{'value': 'Machine learning from explanations (MLX) is an approach to learning that uses human-provided explanations of relevant or irrelevant features for each input to ensure that model predictions are right for the right reasons. Existing MLX approaches rely on local model interpretation methods and require strong model smoothing to align model and human explanations, leading to sub-optimal performance. We recast MLX as a robustness problem, where human explanations specify a lower dimensional manifold from which perturbations can be drawn, and show both theoretically and empirically how this approach alleviates the need for strong model smoothing. We consider various approaches to achieving robustness, leading to improved performance over prior MLX methods. Finally, we show how to combine robustness with an earlier MLX method, yielding state-of-the-art results on both synthetic and real-world benchmarks.'}",https://openreview.net{'value': '/pdf/a4e7f3fccd39bfb2c653e04994c3892f72db381f.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=gf5xJVQS5p,{'value': 'Learning to Configure Separators in Branch-and-Cut'},Sirui Li; Wenbin Ouyang; Max B. Paulus; Cathy Wu,~Sirui_Li1; ~Wenbin_Ouyang1; ~Max_B._Paulus1; ~Cathy_Wu1,"{'value': ['Combinatorial Optimization', 'Branch-and-Cut', 'Learning Guided Optimization', 'Deep Learning']}","{'value': 'Cutting planes are crucial in solving mixed integer linear programs (MILP) as they facilitate bound improvements on the optimal solution. Modern MILP solvers rely on a variety of separators to generate a diverse set of cutting planes by invoking the separators frequently during the solving process. This work identifies that MILP solvers can be drastically accelerated by appropriately selecting separators to activate. As the combinatorial separator selection space imposes challenges for machine learning, we *learn to separate* by proposing a novel data-driven strategy to restrict the selection space and a learning-guided algorithm on the restricted space. Our method predicts instance-aware separator configurations which can dynamically adapt during the solve, effectively accelerating the open source MILP solver SCIP by improving the relative solve time up to 72% and 37% on synthetic and real-world MILP benchmarks. Our work complements recent work on learning to select cutting planes and highlights the importance of separator management.'}",https://openreview.net{'value': '/pdf/91178371d3a990923ca8fd8822844ef19b978cb2.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=gdzxWGGxWE,{'value': 'How do Minimum-Norm Shallow Denoisers Look in Function Space?'},Chen Zeno; Greg Ongie; Yaniv Blumenfeld; Nir Weinberger; Daniel Soudry,~Chen_Zeno1; ~Greg_Ongie1; ~Yaniv_Blumenfeld1; ~Nir_Weinberger1; ~Daniel_Soudry1,"{'value': ['Denoiser', 'Denoising', 'Neural network', 'Function space']}","{'value': 'Neural network (NN) denoisers are an essential building block in many common tasks, ranging from image reconstruction to image generation. However, the success of these models is not well understood from a theoretical perspective. In this paper, we aim to characterize the functions realized by shallow ReLU NN denoisers --- in the common theoretical setting of interpolation (i.e., zero training loss) with a minimal representation cost (i.e., minimal $\\ell^2$ norm weights). First, for univariate data, we derive a closed form for the NN denoiser function, find it is contractive toward the clean data points, and prove it generalizes better than the empirical MMSE estimator at a low noise level. Next, for multivariate data, we find the NN denoiser functions in a closed form under various geometric assumptions on the training data: data contained in a low-dimensional subspace, data contained in a union of one-sided rays, or several types of simplexes. These functions decompose into a sum of simple rank-one piecewise linear interpolations aligned with edges and/or faces connecting training samples. \nWe empirically verify this alignment phenomenon on synthetic data and real images.'}",https://openreview.net{'value': '/pdf/8e26a0cdda08966d4e4d8a5c7a1ba8244b5aaf36.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=gdVcFOvxT3,{'value': 'Finding Safe Zones of Markov Decision Processes Policies'},Lee Cohen; Yishay Mansour; Michal Moshkovitz,~Lee_Cohen1; ~Yishay_Mansour2; ~Michal_Moshkovitz2,"{'value': ['Theoretical guarantees', 'algorithms', 'learning theory', 'MDP', 'computational complexity', 'Interpretability']}","{'value': ""Given a policy of a Markov Decision Process, we define a SafeZone as a subset of states, such that most of the policy's trajectories are confined to this subset. The quality of a SafeZone is parameterized by the number of states and the escape probability, i.e., the probability that a random trajectory will leave the subset. SafeZones are especially interesting when they have a small number of states and low escape probability. We study the complexity of finding optimal SafeZones, and show that in general, the problem is computationally hard. For this reason, we concentrate on finding approximate SafeZones. Our main result is a bi-criteria approximation learning algorithm with a factor of almost $2$  approximation for both the escape probability and \\newprob size, using a polynomial size sample complexity.""}",https://openreview.net{'value': '/pdf/f3b4dbcbe17fd098b592e7aa93b9175f551534b1.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=gbhixjg2dX,{'value': 'Synthetic Combinations: A Causal Inference Framework for Combinatorial Interventions'},Abhineet Agarwal; Anish Agarwal; Suhas Vijaykumar,~Abhineet_Agarwal1; ~Anish_Agarwal1; ~Suhas_Vijaykumar1,"{'value': ['Causal Inference', 'Matrix Completion', 'Combinatorial Learning', 'Ranking']}","{'value': 'We consider a setting where there are $N$ heterogeneous units and $p$ interventions. Our goal is to learn unit-specific potential outcomes for any combination of these $p$ interventions, i.e., $N \\times 2^p$ causal parameters. Choosing a combination of interventions is a problem that naturally arises in a variety of applications such as factorial design experiments and recommendation engines (e.g., showing a set of movies that maximizes engagement for a given user). Running $N \\times 2^p$ experiments to estimate the various parameters is likely expensive and/or infeasible as $N$ and $p$ grow. Further, with observational data there is likely confounding, i.e., whether or not a unit is seen under a combination is correlated with its potential outcome under that combination. We study this problem under a novel model that imposes latent structure across both units and combinations of interventions. Specifically, we assume latent similarity in potential outcomes across units (i.e., the matrix of potential outcomes is approximately rank $r$) and regularity in how combinations of interventions interact (i.e., the coefficients in the Fourier expansion of the potential outcomes is approximately $s$ sparse). We establish identification for all $N \\times 2^p$ parameters despite unobserved confounding. We propose an estimation procedure, Synthetic Combinations, and establish finite-sample consistency under precise conditions on the observation pattern. We show that Synthetic Combinations is able to consistently estimate unit-specific potential outcomes given a total of $\\text{poly}(r) \\times \\left( N + s^2p\\right)$ observations. In comparison, previous methods that do not exploit structure across both units and combinations have poorer sample complexity scaling as $\\min(N \\times s^2p, \\ \\ r \\times (N + 2^p))$.'}",https://openreview.net{'value': '/pdf/e983fc88d3376b4988911b32eaeefaf7ed831997.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=ganlU27uvj,{'value': 'Slot-guided Volumetric Object Radiance Fields'},DI QI; Tong Yang; Xiangyu Zhang,~DI_QI3; ~Tong_Yang2; ~Xiangyu_Zhang1,"{'value': ['3D object-centric representation learning', 'NeRF', '3D-aware slot']}","{'value': 'We present a novel framework for 3D object-centric representation learning. Our approach effectively decomposes complex scenes into individual objects from a single image in an unsupervised fashion. This method, called \\underline{s}lot-guided \\underline{V}olumetric \\underline{O}bject \\underline{R}adiance \\underline{F}ields~(sVORF), composes volumetric object radiance fields with object slots as a guidance to implement unsupervised 3D scene decomposition. Specifically, sVORF obtains object slots from a single image via a transformer module, maps these slots to volumetric object radiance fields with a hypernetwork and composes object radiance fields with the guidance of object slots at a 3D location. Moreover, sVORF significantly reduces memory requirement due to small-sized pixel rendering during training. We demonstrate the effectiveness of our approach by showing top results in scene decomposition and generation tasks of complex synthetic datasets (e.g., Room-Diverse). Furthermore, we also confirm the potential of sVORF to segment objects in real-world scenes (e.g., the LLFF dataset).  We hope our approach can provide preliminary understanding of the physical world and help ease future research in 3D object-centric representation learning.'}",https://openreview.net{'value': '/pdf/ae647900a465a209f2987a08ca3ebe531ec535f6.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=gVLKXT9JwG,{'value': 'Global Convergence Analysis of Local SGD for Two-layer Neural Network without Overparameterization'},Yajie Bao; Amarda Shehu; Mingrui Liu,~Yajie_Bao2; ~Amarda_Shehu1; ~Mingrui_Liu2,"{'value': ['convolutional neural network', 'gaussian input', 'local SGD', 'global convergence', 'non-convex optimization']}","{'value': 'Local SGD, a cornerstone algorithm in federated learning, is widely used in training deep neural networks and shown to have strong empirical performance. A theoretical understanding of such performance on nonconvex loss landscapes is currently lacking. Analysis of the global convergence of SGD is challenging, as the noise depends on the model parameters. Indeed, many works narrow their focus to GD and rely on injecting noise to enable convergence to the local or global optimum. When expanding the focus to local SGD, existing analyses in the nonconvex case can only guarantee finding stationary points or assume the neural network is overparameterized so as to guarantee convergence to the global minimum through neural tangent kernel analysis. In this work, we provide the first global convergence analysis of the vanilla local SGD for two-layer neural networks \\emph{without overparameterization} and \\textit{without injecting noise}, when the input data is Gaussian. The main technical ingredients of our proof are \\textit{a self-correction mechanism} and \\textit{a new exact recursive characterization of the direction of global model parameters}. The self-correction mechanism guarantees the algorithm reaches a good region even if the initialization is in a bad region. A good (bad) region means updating the model by gradient descent will move closer to (away from) the optimal solution. The main difficulty in establishing a self-correction mechanism is to cope with the gradient dependency between two layers. To address this challenge, we divide the landscape of the objective into several regions to carefully control the interference of two layers during the correction process. As a result, we show that local SGD can correct the two layers and enter the good region in polynomial time. After that, we establish a new exact recursive characterization of the direction of global parameters, which is the key to showing convergence to the global minimum with linear speedup in the number of machines and reduced communication rounds. Experiments on synthetic data confirm theoretical results.'}",https://openreview.net{'value': '/pdf/5fb515e31457211cbf4ef4e437935ee7ccf5650c.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=gIG8LvTLuc,{'value': 'How Does Adaptive Optimization Impact Local Neural Network Geometry?'},Kaiqi Jiang; Dhruv Malik; Yuanzhi Li,~Kaiqi_Jiang2; ~Dhruv_Malik1; ~Yuanzhi_Li1,"{'value': ['optimization', 'adaptive algorithms', 'neural networks']}","{'value': 'Adaptive optimization methods are well known to achieve superior convergence relative to vanilla gradient methods. The traditional viewpoint in optimization, particularly in convex optimization, explains this improved performance by arguing that, unlike vanilla gradient schemes, adaptive algorithms mimic the behavior of a second-order method by adapting to the *global* geometry of the loss function. We argue that in the context of neural network optimization, this traditional viewpoint is insufficient. Instead, we advocate for a *local* trajectory analysis. For iterate trajectories produced by running a generic optimization algorithm OPT, we introduce $R^{\\text{OPT}}\\_{\\text{med}}$, a statistic that is analogous to the condition number of the loss Hessian evaluated at the iterates. Through extensive experiments on language models where adaptive algorithms converge faster than vanilla gradient methods like SGD, we show that adaptive methods such as Adam bias the trajectories towards regions where $R^{\\text{Adam}}_{\\text{med}}$ is small, where one might expect faster optimization. By contrast, SGD (with momentum) biases the trajectories towards regions where $R^{\\text{SGD}}\\_{\\text{med}}$ is comparatively large. We complement these empirical observations with a theoretical result that provably demonstrates this phenomenon in the simplified setting of a two-layer linear network. We view our findings as evidence for the need of a new explanation of the success of adaptive methods, one that is different than the conventional wisdom.'}",https://openreview.net{'value': '/pdf/7e0aeaa799ab25fa3e6b3f63055279713297792f.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=gI1SOgW3kw,{'value': 'Generalizing Nonlinear ICA Beyond Structural Sparsity'},Yujia Zheng; Kun Zhang,~Yujia_Zheng1; ~Kun_Zhang1,"{'value': ['Latent variable models', 'nonlinear independent component analysis']}","{'value': 'Nonlinear independent component analysis (ICA) aims to uncover the true latent sources from their observable nonlinear mixtures. Despite its significance, the identifiability of nonlinear ICA is known to be impossible without additional assumptions. Recent advances have proposed conditions on the connective structure from sources to observed variables, known as Structural Sparsity, to achieve identifiability in an unsupervised manner. However, the sparsity constraint may not hold universally for all sources in practice. Furthermore, the assumptions of bijectivity of the mixing process and independence among all sources, which arise from the setting of ICA, may also be violated in many real-world scenarios. To address these limitations and generalize nonlinear ICA, we propose a set of new identifiability results in the general settings of undercompleteness, partial sparsity and source dependence, and flexible grouping structures. Specifically, we prove identifiability when there are more observed variables than sources (undercomplete), and when certain sparsity and/or source independence assumptions are not met for some changing sources. Moreover, we show that even in cases with flexible grouping structures (e.g., part of the sources can be divided into irreducible independent groups with various sizes), appropriate identifiability results can also be established. Theoretical claims are supported empirically on both synthetic and real-world datasets.'}",https://openreview.net{'value': '/pdf/c8cacba57be0e9de38f156a8525e062ef65ed2e7.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=gGl0n7Onug,{'value': 'Theoretical and Practical Perspectives on what Influence Functions Do'},Andrea Schioppa; Katja Filippova; Ivan Titov; Polina Zablotskaia,~Andrea_Schioppa1; ~Katja_Filippova1; ~Ivan_Titov1; ~Polina_Zablotskaia1,"{'value': ['Explainable AI', 'Influence Functions', 'Training Data Attribution']}","{'value': 'Influence functions (IF) have been seen as a technique for explaining model predictions through the lens of the training data. Their utility is assumed to be in identifying training examples ""responsible"" for a prediction so that, for example, correcting a prediction is possible by intervening on those examples (removing or editing them) and retraining the model. However, recent empirical studies have shown that the existing methods of estimating IF predict the leave-one-out-and-retrain effect poorly. \nIn order to understand the mismatch between the theoretical promise and the practical results, we analyse five assumptions made by IF methods which are problematic for modern-scale deep neural networks and which concern convexity, numeric stability, training trajectory and parameter divergence. This allows us to clarify what can be expected theoretically from IF. We show that while most assumptions can be addressed successfully, the parameter divergence poses a clear limitation on the predictive power of IF: influence fades over training time even with deterministic training. We illustrate this theoretical result with BERT and ResNet models.\nAnother conclusion from the theoretical analysis is that IF are still useful for model debugging and correcting even though some of the assumptions made in prior work do not hold: using natural language processing and computer vision tasks, we verify that mis-predictions can be successfully corrected by taking only a few fine-tuning steps on influential examples.'}",https://openreview.net{'value': '/pdf/34caf567fde5797c18facef93cd01b7528443fd8.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=g27BggUT3L,{'value': 'LART: Neural Correspondence Learning with Latent Regularization Transformer for 3D Motion Transfer'},Haoyu Chen; Hao Tang; Radu Timofte; Luc Van Gool; Guoying Zhao,~Haoyu_Chen3; ~Hao_Tang6; ~Radu_Timofte1; ~Luc_Van_Gool1; ~Guoying_Zhao3,"{'value': ['3D motion transfer', '3D Transformer', 'geometric preservation', '3D generation', 'correspondence learning']}","{'value': '3D motion transfer aims at transferring the motion from a dynamic input sequence to a static 3D object and outputs an identical motion of the target with high-fidelity and realistic visual effects. In this work, we propose a novel 3D Transformer framework called LART for 3D motion transfer. With carefully-designed architectures, LART is able to implicitly learn the correspondence via a flexible geometry perception. Thus, unlike other existing methods, LART does not require any key point annotations or pre-defined correspondence between the motion source and target meshes and can also handle large-size full-detailed unseen 3D targets. Besides, we introduce a novel latent metric regularization on the Transformer for better motion generation. Our rationale lies in the observation that the decoded motions can be approximately expressed as linearly geometric distortion at the frame level. The metric preservation of motions could be translated to the formation of linear paths in the underlying latent space as a rigorous constraint to control the synthetic motions occurring in the construction of the latent space. The proposed LART shows a high learning efficiency with the need for a few samples from the AMASS dataset to generate motions with plausible visual effects. The experimental results verify the potential of our generative model in applications of motion transfer, content generation, temporal interpolation, and motion denoising. The code is made available: https://github.com/mikecheninoulu/LART.'}",https://openreview.net{'value': '/pdf/26415c78b69bd9110aa4e44bd2501dc38258b72f.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=fwvfxDbUFw,{'value': 'Learning Score-based Grasping Primitive for Human-assisting Dexterous Grasping'},Tianhao Wu; Mingdong Wu; Jiyao Zhang; Yunchong Gan; Hao Dong,~Tianhao_Wu2; ~Mingdong_Wu1; ~Jiyao_Zhang1; ~Yunchong_Gan1; ~Hao_Dong3,"{'value': ['Human-asissting Dexterous Grasping', 'Score-matching', 'Reinforcement Learning']}","{'value': ""The use of anthropomorphic robotic hands for assisting individuals in situations where human hands may be unavailable or unsuitable has gained significant importance. In this paper, we propose a novel task called human-assisting dexterous grasping that aims to train a policy for controlling a robotic hand's fingers to assist users in grasping objects. Unlike conventional dexterous grasping, this task presents a more complex challenge as the policy needs to adapt to diverse user intentions, in addition to the object's geometry.  We address this challenge by proposing an approach consisting of two sub-modules: a hand-object-conditional grasping primitive called Grasping Gradient Field (GraspGF), and a history-conditional residual policy.  GraspGF learns 'how' to grasp by estimating the gradient of a synthesised success grasping example set, while the residual policy determines 'when' and at what speed the grasping action should be executed based on the trajectory history. Experimental results demonstrate the superiority of our proposed method compared to baselines, highlighting the user-awareness and practicality in real-world applications. The codes and demonstrations can be viewed at https://sites.google.com/view/graspgf.""}",https://openreview.net{'value': '/pdf/ed024a4118d603505c1830547a06339e4473091f.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=frVo9MzRuU,{'value': 'Compositional Abilities Emerge Multiplicatively: Exploring Diffusion Models on a Synthetic Task'},Maya Okawa; Ekdeep Singh Lubana; Robert P. Dick; Hidenori Tanaka,~Maya_Okawa1; ~Ekdeep_Singh_Lubana1; ~Robert_P._Dick1; ~Hidenori_Tanaka1,{'value': ['Diffusion model; Emergence; Emergent capabilities; Science of deep learning; Mechanistic interpretability']},"{'value': 'Modern generative models exhibit unprecedented capabilities to generate extremely realistic data. However, given the inherent compositionality of the real world, reliable use of these models in practical applications requires that they exhibit the capability to compose a novel set of concepts to generate outputs not seen in the training data set. Prior work demonstrates that recent diffusion models do exhibit intriguing compositional generalization abilities, but also fail unpredictably. Motivated by this, we perform a controlled study for understanding compositional generalization in conditional diffusion models in a synthetic setting, varying different attributes of the training data and measuring the model\'s ability to generate samples out-of-distribution. Our results show: (i) the order in which the ability to generate samples from a concept and compose them emerges is governed by the structure of the underlying data-generating process; (ii) performance on compositional tasks exhibits a sudden ""emergence"" due to multiplicative reliance on the performance of constituent tasks, partially explaining emergent phenomena seen in generative models; and (iii) composing concepts with lower frequency in the training data to generate out-of-distribution samples requires considerably more optimization steps compared to generating in-distribution samples. Overall, our study lays a foundation for understanding emergent capabilities and compositionality in generative models from a data-centric perspective.'}",https://openreview.net{'value': '/pdf/25331248e505219bc2c53834c6c14b9861722c14.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=fezV91IJIo,{'value': 'Analysis of Variance of Multiple Causal Networks'},Zhongli Jiang; Dabao Zhang,~Zhongli_Jiang1; ~Dabao_Zhang1,"{'value': ['causal inference', 'large graphs', 'multi-task learning', 'structural model', 'directed cyclic graph']}","{'value': 'Constructing a directed cyclic graph (DCG) is challenged by both algorithmic difficulty and computational burden. Comparing multiple DCGs is even more difficult, compounded by the need to identify dynamic causalities across graphs. We propose to unify multiple DCGs with a single structural model and develop a limited-information-based method to simultaneously construct multiple networks and infer their disparities, which can be visualized by appropriate correspondence analysis. The algorithm provides DCGs with robust non-asymptotic theoretical properties. It is designed with two sequential stages, each of which involves parallel computation tasks that are scalable to the network complexity. Taking advantage of high-performance clusters, our method makes it possible to evaluate the statistical significance of DCGs using the bootstrap method. We demonstrated the effectiveness of our method by applying it to synthetic and real datasets.'}",https://openreview.net{'value': '/pdf/2fb3f27df8bb34ca66cb65d00440f9cc43e3ac2c.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=fTyGT5fulj,{'value': 'Curriculum Learning for Graph Neural Networks: Which Edges Should We Learn First'},Zheng Zhang; Junxiang Wang; Liang Zhao,~Zheng_Zhang10; ~Junxiang_Wang1; ~Liang_Zhao6,"{'value': ['Graph neural networks', 'Curriculum learning', 'Graph structure learning']}","{'value': 'Graph Neural Networks (GNNs) have achieved great success in representing data with dependencies by recursively propagating and aggregating messages along the edges. However, edges in real-world graphs often have varying degrees of difficulty, and some edges may even be noisy to the downstream tasks. Therefore, existing GNNs may lead to suboptimal learned representations because they usually treat every edge in the graph equally. On the other hand, Curriculum Learning (CL), which mimics the human learning principle of learning data samples in a meaningful order, has been shown to be effective in improving the generalization ability and robustness of representation learners by gradually proceeding from easy to more difficult samples during training. Unfortunately, existing CL strategies are designed for independent data samples and cannot trivially generalize to handle data dependencies. To address these issues, we propose a novel CL strategy to gradually incorporate more edges into training according to their difficulty from easy to hard, where the degree of difficulty is measured by how well the edges are expected given the model training status. We demonstrate the strength of our proposed method in improving the generalization ability and robustness of learned representations through extensive experiments on nine synthetic datasets and nine real-world datasets. The code for our proposed method is available at https://github.com/rollingstonezz/Curriculum_learning_for_GNNs'}",https://openreview.net{'value': '/pdf/3e1f5b71faa807c95e92380db9caa5c56af94302.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=fHsBNNDroC,{'value': 'Calibrated Stackelberg Games: Learning Optimal Commitments Against Calibrated Agents'},Nika Haghtalab; Chara Podimata; Kunhe Yang,~Nika_Haghtalab2; ~Chara_Podimata1; ~Kunhe_Yang1,"{'value': ['calibration', 'Stackelberg games', 'learning in repeated games', 'strategic agents', 'best response', 'strategic classification', 'Stackelberg Security Games']}","{'value': ""In this paper, we introduce a generalization of the standard Stackelberg Games (SGs) framework: _Calibrated Stackelberg Games_. In CSGs, a principal repeatedly interacts with an agent who (contrary to standard SGs) does not have direct access to the principal's action but instead best responds to _calibrated forecasts_ about it. CSG is a powerful modeling tool that goes beyond assuming that agents use ad hoc and highly specified algorithms for interacting in strategic settings to infer the principal's actions  and thus more robustly addresses real-life applications that SGs were originally intended to capture. Along with CSGs, we also introduce a stronger notion of calibration, termed _adaptive calibration_, that provides fine-grained any-time calibration guarantees against adversarial sequences. We give a general approach for obtaining adaptive calibration algorithms and specialize them for finite CSGs. In our main technical result, we show that in CSGs, the principal can achieve utility that converges to the optimum Stackelberg value of the game both in _finite_ and _continuous_ settings and that no higher utility is achievable. Two prominent and immediate applications of our results are the settings of learning in Stackelberg Security Games and strategic classification, both against _calibrated_ agents.""}",https://openreview.net{'value': '/pdf/6ff644224053b68293ed51fec87a998c9ea98473.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=fAdMly4ki5,{'value': 'Diffusion Model is an Effective Planner and Data Synthesizer for Multi-Task Reinforcement Learning'},Haoran He; Chenjia Bai; Kang Xu; Zhuoran Yang; Weinan Zhang; Dong Wang; Bin Zhao; Xuelong Li,~Haoran_He1; ~Chenjia_Bai2; ~Kang_Xu2; ~Zhuoran_Yang1; ~Weinan_Zhang1; ~Dong_Wang1; ~Bin_Zhao7; ~Xuelong_Li2,"{'value': ['multi-task reinforcement learning', 'diffusion models', 'planning', 'data synthesis']}","{'value': 'Diffusion models have demonstrated highly-expressive generative capabilities in vision and NLP. Recent studies in reinforcement learning (RL) have shown that diffusion models are also powerful in modeling complex policies or trajectories in offline datasets. However, these works have been limited to single-task settings where a generalist agent capable of addressing multi-task predicaments is absent. In this paper, we aim to investigate the effectiveness of a single diffusion model in modeling large-scale multi-task offline data, which can be challenging due to diverse and multimodal data distribution. Specifically, we propose Multi-Task Diffusion Model (\\textsc{MTDiff}), a diffusion-based method that incorporates Transformer backbones and prompt learning for generative planning and data synthesis in multi-task offline settings. \\textsc{MTDiff} leverages vast amounts of knowledge available in multi-task data and performs implicit knowledge sharing among tasks. For generative planning, we find \\textsc{MTDiff} outperforms state-of-the-art algorithms across 50 tasks on Meta-World and 8 maps on Maze2D. For data synthesis, \\textsc{MTDiff} generates high-quality data for testing tasks given a single demonstration as a prompt, which enhances the low-quality datasets for even unseen tasks.'}",https://openreview.net{'value': '/pdf/4456808a4c1958181dbf1c36aefe0dfced8d4b27.pdf'},{'title_filter': 'Data Synthesis'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=ezqI5WgGvY,{'value': 'CROMA: Remote Sensing Representations with Contrastive Radar-Optical Masked Autoencoders'},Anthony Fuller; Koreen Millard; James R Green,~Anthony_Fuller1; ~Koreen_Millard1; ~James_R_Green1,"{'value': ['Remote Sensing', 'Earth Observation', 'Self-supervised learning', 'Multimodal']}","{'value': 'A vital and rapidly growing application, remote sensing offers vast yet sparsely labeled, spatially aligned multimodal data; this makes self-supervised learning algorithms invaluable. We present CROMA: a framework that combines contrastive and reconstruction self-supervised objectives to learn rich unimodal and multimodal representations. Our method separately encodes masked-out multispectral optical and synthetic aperture radar samples—aligned in space and time—and performs cross-modal contrastive learning. Another encoder fuses these sensors, producing joint multimodal encodings that are used to predict the masked patches via a lightweight decoder. We show that these objectives are complementary when leveraged on spatially aligned multimodal data. We also introduce X- and 2D-ALiBi, which spatially biases our cross- and self-attention matrices. These strategies improve representations and allow our models to effectively extrapolate to images up to $17.6\\times$ larger at test-time. CROMA outperforms the current SoTA multispectral model, evaluated on: four classification benchmarks—finetuning (avg.$\\uparrow$ 1.8%), linear (avg.$\\uparrow$ 2.4%) and nonlinear (avg.$\\uparrow$ 1.4%) probing, $k$NN classification (avg.$\\uparrow$ 3.5%), and $K$-means clustering (avg.$\\uparrow$ 8.4%); and three segmentation benchmarks (avg.$\\uparrow$ 6.4%). CROMA’s rich, optionally multimodal representations can be widely leveraged across remote sensing applications.'}",https://openreview.net{'value': '/pdf/94d52ee159662a75cbd6f0e4ba31dde6c4e16ead.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=etYk6TeO2q,{'value': 'Causal Discovery from Subsampled Time Series with Proxy Variables'},Mingzhou Liu; Xinwei Sun; Lingjing Hu; Yizhou Wang,~Mingzhou_Liu1; ~Xinwei_Sun1; ~Lingjing_Hu1; ~Yizhou_Wang1,"{'value': ['causal discovery', 'time series', 'subsampling', 'proxy variables']}","{'value': 'Inferring causal structures from time series data is the central interest of many scientific inquiries. A major barrier to such inference is the problem of subsampling, *i.e.*, the frequency of measurement is much lower than that of causal influence. To overcome this problem, numerous methods have been proposed, yet either was limited to the linear case or failed to achieve identifiability. In this paper, we propose a constraint-based algorithm that can identify the entire causal structure from subsampled time series, without any parametric constraint. Our observation is that the challenge of subsampling arises mainly from hidden variables at the unobserved time steps. Meanwhile, every hidden variable has an observed proxy, which is essentially itself at some observable time in the future, benefiting from the temporal structure. Based on these, we can leverage the proxies to remove the bias induced by the hidden variables and hence achieve identifiability. Following this intuition, we propose a proxy-based causal discovery algorithm. Our algorithm is nonparametric and can achieve full causal identification. Theoretical advantages are reflected in synthetic and real-world experiments.'}",https://openreview.net{'value': '/pdf/c69595be4c3b6f18469976d0dcea479f36840fbf.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=enfx8HM4Rp,{'value': 'Train Once and Explain Everywhere: Pre-training Interpretable Graph Neural Networks'},Jun Yin; Chaozhuo Li; Hao Yan; Jianxun Lian; Senzhang Wang,~Jun_Yin11; ~Chaozhuo_Li1; ~Hao_Yan6; ~Jianxun_Lian1; ~Senzhang_Wang2,"{'value': ['Intrinsic Interpretability', 'Graph Neural Networks', 'Pre-training and Fine-tuning']}","{'value': 'Intrinsic interpretable graph neural networks aim to provide transparent predictions by identifying the influential fraction of the input graph that guides the model prediction, i.e., the explanatory subgraph. However, current interpretable GNNs mostly are dataset-specific and hard to generalize to different graphs. A more generalizable GNN interpretation model which can effectively distill the universal structural patterns of different graphs is until-now unexplored. Motivated by the great success of recent pre-training techniques, we for the first time propose the Pre-training Interpretable Graph Neural Network ($\\pi$-GNN) to distill the universal interpretability of GNNs by pre-training over synthetic graphs with ground-truth explanations. Specifically, we introduce a structural pattern learning module to extract diverse universal structure patterns and integrate them together to comprehensively represent the graphs of different types. Next, a hypergraph refining module is proposed to identify the explanatory subgraph by incorporating the universal structure patterns with local edge interactions. Finally, the task-specific predictor is cascaded with the pre-trained $\\pi$-GNN model and fine-tuned over downstream tasks. Extensive experiments demonstrate that $\\pi$-GNN significantly surpasses the leading interpretable GNN baselines with up to 9.98\\% interpretation improvement and 16.06\\% classification accuracy improvement. Meanwhile, $\\pi$-GNN pre-trained on graph classification task also achieves the top-tier interpretation performance on node classification task, which further verifies its promising generalization performance among different downstream tasks. Our code and datasets are available at https://anonymous.4open.science/r/PI-GNN-F86C'}",https://openreview.net{'value': '/pdf/6cfc84bfe6bb87d34dc992b7cf2fa1879d92a47b.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=eibTaY6qGI,{'value': 'Resilient Multiple Choice Learning: A learned scoring scheme with application to audio scene analysis'},Victor Letzelter; Mathieu Fontaine; Mickael Chen; Patrick Perez; Slim Essid; Gaël Richard,~Victor_Letzelter1; mathieu.fontaine@telecom-paris.fr; ~Mickael_Chen1; ~Patrick_Perez1; ~Slim_Essid1; ~Gaël_Richard1,"{'value': ['Multiple Choice Learning', 'Audio processing.']}","{'value': 'We introduce Resilient Multiple Choice Learning (rMCL), an extension of the MCL approach for conditional distribution estimation in regression settings where multiple targets may be sampled for each training input.\nMultiple Choice Learning is a simple framework to tackle multimodal density estimation, using the Winner-Takes-All (WTA) loss for a set of hypotheses. In regression settings, the existing MCL variants focus on merging the hypotheses, thereby eventually sacrificing the diversity of the predictions. In contrast, our method relies on a novel learned scoring scheme underpinned by a mathematical framework based on Voronoi tessellations of the output space, from which we can derive a probabilistic interpretation.\nAfter empirically validating rMCL with experiments on synthetic data, we further assess its merits on the sound source localization problem, demonstrating its practical usefulness and the relevance of its interpretation.'}",https://openreview.net{'value': '/pdf/561e034e09160e70848ab803c0ac698ad6d429d2.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=ecRaDicXxw,{'value': 'DiffVL: Scaling Up Soft Body Manipulation using Vision-Language Driven Differentiable Physics'},Zhiao Huang; Feng Chen; Yewen Pu; Chunru Lin; Hao Su; Chuang Gan,~Zhiao_Huang1; ~Feng_Chen16; ~Yewen_Pu1; ~Chunru_Lin1; ~Hao_Su1; ~Chuang_Gan1,{'value': ['Differentiable physics; Soft body manipulation']},"{'value': ""Combining gradient-based trajectory optimization with differentiable physics simulation is an efficient technique for solving soft-body manipulation problems.\nUsing a well-crafted optimization objective, the solver can quickly converge onto a valid trajectory.\nHowever, writing the appropriate objective functions requires expert knowledge, making it difficult to collect a large set of naturalistic problems from non-expert users.\nWe introduce DiffVL, a method that enables non-expert users to communicate soft-body manipulation tasks -- a combination of vision and natural language, given in multiple stages -- that can be readily leveraged by a differential physics solver. \nWe have developed GUI tools that enable non-expert users to specify 100 tasks inspired by real-life soft-body manipulations from online videos, which we'll make public.\nWe leverage large language models to translate task descriptions into machine-interpretable optimization objectives. The optimization objectives can help differentiable physics solvers to solve these long-horizon multistage tasks that are challenging for previous baselines.""}",https://openreview.net{'value': '/pdf/8e78ca917c3abb2a676e0846aee3aae00a1f757b.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=eNhW9UnlGG,{'value': 'Contextual Gaussian Process Bandits with Neural Networks'},Haoting Zhang; Jinghai He; Rhonda Righter; Zuo-Jun Shen; Zeyu Zheng,~Haoting_Zhang2; ~Jinghai_He1; rrighter@berkeley.edu; ~Zuo-Jun_Shen1; ~Zeyu_Zheng2,"{'value': ['contextual bandit', 'Gaussian process', 'neural network']}","{'value': 'Contextual decision-making problems have witnessed extensive applications in various fields such as online content recommendation, personalized healthcare, and autonomous vehicles, where a core practical challenge is to select a suitable surrogate model for capturing unknown complicated reward functions. It is often the case that both high approximation accuracy and explicit uncertainty quantification are desired. In this work, we propose a neural network-accompanied Gaussian process (NN-AGP) model, which leverages neural networks to approximate the unknown and potentially complicated reward function regarding the contextual variable, and maintains a Gaussian process surrogate model with respect to the decision variable. Our model is shown to outperform existing approaches by offering better approximation accuracy thanks to the use of neural networks and possessing explicit uncertainty quantification from the Gaussian process. We also analyze the maximum information gain of the NN-AGP model and prove regret bounds for the corresponding algorithms. Moreover, we conduct experiments on both synthetic and practical problems, illustrating the effectiveness of our approach.'}",https://openreview.net{'value': '/pdf/794899e9064b9d1eb280bf23ec2d29a22edf1ede.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=eCgWNU2Imw,{'value': 'On Sparse Modern Hopfield Model'},Jerry Yao-Chieh Hu; Donglin Yang; Dennis Wu; Chenwei Xu; Bo-Yu Chen; Han Liu,~Jerry_Yao-Chieh_Hu1; ~Donglin_Yang1; ~Dennis_Wu1; ~Chenwei_Xu2; ~Bo-Yu_Chen1; ~Han_Liu4,{'value': ['Hopfield Models; Modern Hopfield Networks; Sparse Attention; Memory Networks']},"{'value': 'We introduce the sparse modern Hopfield model as a sparse extension of the modern Hopfield model.\nLike its dense counterpart, the sparse modern Hopfield model equips a memory-retrieval dynamics whose one-step approximation corresponds to the sparse attention mechanism. \nTheoretically, our key contribution is a principled derivation of a closed-form sparse Hopfield energy using the convex conjugate of the sparse entropic regularizer.\nBuilding upon this, we derive the sparse memory retrieval dynamics from the sparse energy function and show its one-step approximation is equivalent to the sparse-structured attention.\nImportantly, we provide a sparsity-dependent memory retrieval error bound which is provably tighter than its dense analog.\nThe conditions for the benefits of sparsity to arise are therefore identified and discussed.\nIn addition, we show that the sparse modern Hopfield model maintains the robust theoretical properties of its dense counterpart, including rapid fixed point convergence and exponential memory capacity.\nEmpirically, we use both synthetic and real-world datasets to demonstrate that the sparse Hopfield model outperforms its dense counterpart in many situations.'}",https://openreview.net{'value': '/pdf/5fa984447317cfec34881d5aae96c28ca43bd6f2.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=e2aCgjtjMR,{'value': 'Estimating and Controlling for Equalized Odds via Sensitive Attribute Predictors'},Beepul Bharti; Paul Yi; Jeremias Sulam,~Beepul_Bharti1; ~Paul_Yi1; ~Jeremias_Sulam1,"{'value': ['fairness', 'sensitive attributes', 'equalized odds', 'missing data', 'proxies']}","{'value': 'As the use of machine learning models in real world high-stakes decision settings continues to grow, it is highly important that we are able to audit and control for any potential fairness violations these models may exhibit towards certain groups. To do so, one naturally requires access to sensitive attributes, such as demographics, biological sex, or other potentially sensitive features that determine group membership. Unfortunately, in many settings, this information is often unavailable. In this work we study the well known equalized odds (EOD) definition of fairness. In a setting without sensitive attributes, we first provide tight and computable upper bounds for the EOD violation of a predictor. These bounds precisely reflect the worst possible EOD violation. Second, we demonstrate how one can provably control the worst-case EOD by a new post-processing correction method. Our results characterize when directly controlling for EOD with respect to the predicted sensitive attributes is -- and when is not -- optimal when it comes to controlling worst-case EOD. Our results hold under assumptions that are milder than previous works, and we illustrate these results with experiments on synthetic and real datasets.'}",https://openreview.net{'value': '/pdf/4823862347f9b472dceb5348bba53f253a6a5d1d.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=e1oe8F2tjV,{'value': 'Multinomial Logistic Regression: Asymptotic Normality on Null Covariates in High-Dimensions'},Kai Tan; Pierre C Bellec,~Kai_Tan1; ~Pierre_C_Bellec1,"{'value': ['High-dimensional statistics', 'statistical inference', 'multi-class classification', 'asymptotic normality', 'multinomial logistic regression']}","{'value': 'This paper investigates the asymptotic distribution of the maximum-likelihood estimate (MLE) in multinomial logistic models in the high-dimensional regime where dimension and sample size are of the same order. While classical large-sample theory provides asymptotic normality of the MLE under certain conditions, such classical results are expected to fail in high-dimensions as documented for the binary logistic case in the seminal work of Sur and Candès [2019]. We address this issue in classification problems with 3 or more classes, by developing asymptotic normality and asymptotic chi-square results for the multinomial logistic MLE (also known as cross-entropy minimizer) on null covariates. Our theory leads to a new methodology to test the significance of a given feature. Extensive simulation studies on synthetic data corroborate these asymptotic results and confirm the validity of proposed p-values for testing the significance of a given feature.'}",https://openreview.net{'value': '/pdf/1b3c13e5ae9c2cbdcbe076f3d323b32dbb9b1c29.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=e1WgjvFGWp,{'value': 'Large Language Models of Code Fail at Completing Code with Potential Bugs'},Tuan Dinh; Jinman Zhao; Samson Tan; Renato Negrinho; Leonard Lausen; Sheng Zha; George Karypis,~Tuan_Dinh1; ~Jinman_Zhao1; ~Samson_Tan1; ~Renato_Negrinho1; ~Leonard_Lausen1; ~Sheng_Zha1; ~George_Karypis1,{'value': ['language model of code; code completion; language model; software engineering; machine learning for code']},"{'value': 'Large language models of code (Code-LLMs) have recently brought tremendous advances to code completion, a fundamental feature of programming assistance and code intelligence. However, most existing works ignore the possible presence of bugs in the code context for generation, which are inevitable in software development. Therefore, we introduce and study the buggy-code completion problem, inspired by the realistic scenario of real-time code suggestion where the code context contains potential bugs – anti-patterns that can become bugs in the completed program. To systematically study the task, we introduce two datasets: one with synthetic bugs derived from semantics-altering operator changes (buggy-HumanEval) and one with realistic bugs derived from user submissions to coding problems (buggy-FixEval). We find that the presence of potential bugs significantly degrades the generation performance of the high-performing Code-LLMs. For instance, the passing rates of CODEGEN-2B-MONO on test cases of buggy-HumanEval drop more than 50% given a single potential bug in the context. Finally, we investigate several post-hoc methods for mitigating the adverse effect of potential bugs and find that there remains a large gap in post-mitigation performance.'}",https://openreview.net{'value': '/pdf/ef78daebca13249fe003a2ceda19a2977efe6feb.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=dz5X8hnfJc,{'value': 'Characterizing Out-of-Distribution Error via Optimal Transport'},Yuzhe Lu; Yilong Qin; Runtian Zhai; Andrew Shen; Ketong Chen; Zhenlin Wang; Soheil Kolouri; Simon Stepputtis; Joseph Campbell; Katia P. Sycara,~Yuzhe_Lu1; ~Yilong_Qin1; ~Runtian_Zhai1; ~Andrew_Shen1; ~Ketong_Chen1; ~Zhenlin_Wang3; ~Soheil_Kolouri1; ~Simon_Stepputtis1; ~Joseph_Campbell1; ~Katia_P._Sycara1,"{'value': ['Distribution Shift', 'OOD Error Prediction', 'Optimal Transport', 'Deep Learning']}","{'value': ""Out-of-distribution (OOD) data poses serious challenges in deployed machine learning models,\nso methods of predicting a model's performance on OOD data without labels are important for machine learning safety.\nWhile a number of methods have been proposed by prior work, they often underestimate the actual error, sometimes by a large margin, which greatly impacts their applicability to real tasks. In this work, we identify *pseudo-label shift*, or the difference between the predicted and true OOD label distributions, as a key indicator of this underestimation. Based on this observation, we introduce a novel method for estimating model performance by leveraging optimal transport theory, Confidence Optimal Transport (COT), and show that it provably provides more robust error estimates in the presence of pseudo-label shift. Additionally, we introduce an empirically-motivated variant of COT, Confidence Optimal Transport with Thresholding (COTT), which applies thresholding to the individual transport costs and further improves the accuracy of COT's error estimates. We evaluate COT and COTT on a variety of standard benchmarks that induce various types of distribution shift -- synthetic, novel subpopulation, and natural -- and show that our approaches significantly outperform existing state-of-the-art methods with up to 3x lower prediction errors.""}",https://openreview.net{'value': '/pdf/5dfe1b228f1857708a8ac9a3f7ee6f2e8e170f01.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=deaHiTb6Cu,{'value': 'Fast Exact Leverage Score Sampling from Khatri-Rao Products with Applications to Tensor Decomposition'},Vivek Bharadwaj; Osman Asif Malik; Riley Murray; Laura Grigori; Aydin Buluc; James Demmel,~Vivek_Bharadwaj1; ~Osman_Asif_Malik1; ~Riley_Murray1; ~Laura_Grigori1; ~Aydin_Buluc1; ~James_Demmel2,"{'value': ['Tensor Decomposition', 'Leverage Scores', 'Randomized Linear Algebra', 'Sketching', 'Khatri-Rao Product', 'Sparse Tensors']}","{'value': 'We present a data structure to randomly sample rows from the Khatri-Rao product of several matrices according to the exact distribution of its leverage scores. Our proposed sampler draws each row in time logarithmic in the height of the Khatri-Rao product and quadratic in its column count, with persistent space overhead at most the size of the input matrices. As a result, it tractably draws samples even when the matrices forming the Khatri-Rao product have tens of millions of rows each. When used to sketch the linear least-squares problems arising in Candecomp / PARAFAC decomposition, our method achieves lower asymptotic complexity per solve than recent state-of-the-art methods. Experiments on billion-scale sparse tensors and synthetic data validate our theoretical claims, with our algorithm achieving higher accuracy than competing methods as the decomposition rank grows.'}",https://openreview.net{'value': '/pdf/3f37eb26b22a4f2d85c90e345310fcad0f68743c.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=dd3KNayGFz,{'value': 'Differentially Private Decoupled Graph Convolutions for Multigranular Topology Protection'},Eli Chien; Wei-Ning Chen; Chao Pan; Pan Li; Ayfer Ozgur; Olgica Milenkovic,~Eli_Chien1; ~Wei-Ning_Chen1; ~Chao_Pan2; ~Pan_Li2; ~Ayfer_Ozgur1; ~Olgica_Milenkovic1,"{'value': ['Graph Neural Networks', 'Differential Privacy', 'Multigranular Topology Protection']}","{'value': 'Graph Neural Networks (GNNs) have proven to be highly effective in solving real-world learning problems that involve graph-structured data. However, GNNs can also inadvertently expose sensitive user information and interactions through their model predictions. To address these privacy concerns, Differential Privacy (DP) protocols are employed to control the trade-off between provable privacy protection and model utility. Applying standard DP approaches to GNNs directly is not advisable due to two main reasons. First, the prediction of node labels, which relies on neighboring node attributes through graph convolutions, can lead to privacy leakage. Second, in practical applications, the privacy requirements for node attributes and graph topology may differ. In the latter setting, existing DP-GNN models fail to provide multigranular trade-offs between graph topology privacy, node attribute privacy, and GNN utility. To address both limitations, we propose a new framework termed Graph Differential Privacy (GDP), specifically tailored to graph learning. GDP ensures both provably private model parameters as well as private predictions. Additionally, we describe a novel unified notion of graph dataset adjacency to analyze the properties of GDP for different levels of graph topology privacy. Our findings reveal that DP-GNNs, which rely on graph convolutions, not only fail to meet the requirements for multigranular graph topology privacy but also necessitate the injection of DP noise that scales at least linearly with the maximum node degree. In contrast, our proposed Differentially Private Decoupled Graph Convolutions (DPDGCs) represent a more flexible and efficient alternative to graph convolutions that still provides the necessary guarantees of GDP. To validate our approach, we conducted extensive experiments on seven node classification benchmarking and illustrative synthetic datasets. The results demonstrate that DPDGCs significantly outperform existing DP-GNNs in terms of privacy-utility trade-offs.'}",https://openreview.net{'value': '/pdf/76d4d024c63afba5ffbbbb886771bc6ca15968fb.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=dR6p49RYLq,{'value': 'NeuralGF: Unsupervised Point Normal Estimation by Learning Neural Gradient Function'},Qing Li; Huifang Feng; Kanle Shi; Yue Gao; Yi Fang; Yu-Shen Liu; Zhizhong Han,~Qing_Li17; ~Huifang_Feng1; ~Kanle_Shi1; ~Yue_Gao4; ~Yi_Fang2; ~Yu-Shen_Liu1; ~Zhizhong_Han2,"{'value': ['Point Clouds', 'Normal Estimation', 'Neural Gradient']}","{'value': 'Normal estimation for 3D point clouds is a fundamental task in 3D geometry processing. The state-of-the-art methods rely on priors of fitting local surfaces learned from normal supervision. However, normal supervision in benchmarks comes from synthetic shapes and is usually not available from real scans, thereby limiting the learned priors of these methods. In addition, normal orientation consistency across shapes remains difficult to achieve without a separate post-processing procedure. To resolve these issues, we propose a novel method for estimating oriented normals directly from point clouds without using ground truth normals as supervision. We achieve this by introducing a new paradigm for learning neural gradient functions, which encourages the neural network to fit the input point clouds and yield unit-norm gradients at the points. Specifically, we introduce loss functions to facilitate query points to iteratively reach the moving targets and aggregate onto the approximated surface, thereby learning a global surface representation of the data. Meanwhile, we incorporate gradients into the surface approximation to measure the minimum signed deviation of queries, resulting in a consistent gradient field associated with the surface. These techniques lead to our deep unsupervised oriented normal estimator that is robust to noise, outliers and density variations. Our excellent results on widely used benchmarks demonstrate that our method can learn more accurate normals for both unoriented and oriented normal estimation tasks than the latest methods. The source code and pre-trained model are publicly available.'}",https://openreview.net{'value': '/pdf/a1cab732620ba2822de7f31d743f3e07a3c1085b.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=dL0GM9Wwtq,{'value': 'Double and Single Descent in Causal Inference with an Application to High-Dimensional Synthetic Control'},Jann Spiess; Guido Imbens; Amar Venugopal,~Jann_Spiess1; ~Guido_Imbens1; amar.venugopal@stanford.edu,"{'value': ['Double descent', 'interpolating regression', 'synthetic control', 'causal inference']}","{'value': 'Motivated by a recent literature on the double-descent phenomenon in machine learning, we consider highly over-parameterized models in causal inference, including synthetic control with many control units. In such models, there may be so many free parameters that the model fits the training data perfectly. We first investigate high-dimensional linear regression for imputing wage data and estimating average treatment effects, where we find that models with many more covariates than sample size can outperform simple ones. We then document the performance of high-dimensional synthetic control estimators with many control units. We find that adding control units can help improve imputation performance even beyond the point where the pre-treatment fit is perfect. We provide a unified theoretical perspective on the performance of these high-dimensional models. Specifically, we show that more complex models can be interpreted as model-averaging estimators over simpler ones, which we link to an improvement in average performance. This perspective yields concrete insights into the use of synthetic control when control units are many relative to the number of pre-treatment periods.'}",https://openreview.net{'value': '/pdf/f12d968539b559b4f8b165db166dfcccaa97e506.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=dJZ3MvDw86,{'value': 'Data Augmentations for Improved (Large) Language Model Generalization'},Amir Feder; Yoav Wald; Claudia Shi; Suchi Saria; David Blei,~Amir_Feder1; ~Yoav_Wald1; ~Claudia_Shi1; ~Suchi_Saria1; ~David_Blei2,"{'value': ['Counterfactually Augmented Data', 'Invariant Learning', 'Out-of-distribution Generalization', 'Clinical NLP']}","{'value': 'The reliance of text classifiers on spurious correlations can lead to poor generalization at deployment, raising concerns about their use in safety-critical domains such as healthcare. In this work, we propose to use counterfactual data augmentation, guided by knowledge of the causal structure of the data, to simulate interventions on spurious features and to learn more robust text classifiers. We show that this strategy is appropriate in prediction problems where the label is spuriously correlated with an attribute. Under the assumptions of such problems, we discuss the favorable sample complexity of counterfactual data augmentation, compared to importance re-weighting. Pragmatically, we match examples using auxiliary data, based on diff-in-diff methodology, and use a large language model (LLM) to represent a conditional probability of text. Through extensive experimentation on learning caregiver-invariant predictors of clinical diagnoses from medical narratives and on semi-synthetic data, we demonstrate that our method for simulating interventions improves out-of-distribution (OOD) accuracy compared to baseline invariant learning algorithms.'}",https://openreview.net{'value': '/pdf/3da2e9b58620b7cf6de7af10f6bc40fadc37f477.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=crZlhMnfeO,{'value': 'RayDF: Neural Ray-surface Distance Fields with Multi-view Consistency'},Zhuoman Liu; Bo Yang; Yan Luximon; Ajay Kumar; Jinxi Li,~Zhuoman_Liu1; ~Bo_Yang7; ~Yan_Luximon1; ~Ajay_Kumar2; ~Jinxi_Li2,"{'value': ['implicit shape representations', 'multi-view consistency', 'novel view synthesis']}","{'value': 'In this paper, we study the problem of continuous 3D shape representations. The majority of existing successful methods are coordinate-based implicit neural representations. However, they are inefficient to render novel views or recover explicit surface points. A few works start to formulate 3D shapes as ray-based neural functions, but the learned structures are inferior due to the lack of multi-view geometry consistency. To tackle these challenges, we propose a new framework called RayDF. It consists of three major components: 1) the simple ray-surface distance field, 2) the novel dual-ray visibility classifier, and 3) a multi-view consistency optimization module to drive the learned ray-surface distances to be multi-view geometry consistent. We extensively evaluate our method on three public datasets, demonstrating remarkable performance in 3D surface point reconstruction on both synthetic and challenging real-world 3D scenes, clearly surpassing existing coordinate-based and ray-based baselines. Most notably, our method achieves a 1000x faster speed than coordinate-based methods to render an 800x800 depth image, showing the superiority of our method for 3D shape representation. Our code and data are available at https://github.com/vLAR-group/RayDF'}",https://openreview.net{'value': '/pdf/e761dfd51f31946a39cc34121df8c01d8e9c72cb.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=cnpkzQZaLU,{'value': 'Context-PIPs: Persistent Independent Particles Demands Spatial Context Features'},Weikang BIAN; Zhaoyang Huang; Xiaoyu Shi; Yitong Dong; Yijin Li; Hongsheng Li,~Weikang_BIAN1; ~Zhaoyang_Huang2; ~Xiaoyu_Shi1; ~Yitong_Dong1; ~Yijin_Li1; ~Hongsheng_Li3,{'value': ['Point Tracking; Optical Flow; Video Correspondence; Computer Vision;']},"{'value': 'We tackle the problem of Persistent Independent Particles (PIPs), also called Tracking Any Point (TAP), in videos, which specifically aims at estimating persistent long-term trajectories of query points in videos. Previous methods attempted to estimate these trajectories independently to incorporate longer image sequences, therefore, ignoring the potential benefits of incorporating spatial context features. \nWe argue that independent video point tracking also demands spatial context features. To this end, we propose a novel framework Context-PIPs, which effectively improves point trajectory accuracy by aggregating spatial context features in videos. Context-PIPs contains two main modules: 1) a SOurse Feature Enhancement (SOFE) module, and 2) a TArget Feature Aggregation (TAFA) module. Context-PIPs significantly improves PIPs all-sided, reducing 11.4\\% Average Trajectory Error of Occluded Points (ATE-Occ) on CroHD and increasing 11.8\\% Average Percentage of Correct Keypoint (A-PCK) on TAP-Vid-Kinetics. Demos are available at \\url{https://wkbian.github.io/Projects/Context-PIPs/}.'}",https://openreview.net{'value': '/pdf/0d762366dd6b0305889c0f0bcd27748a0332162a.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=cANkPsVtsw,{'value': 'Characterization and Learning of Causal Graphs with Small Conditioning Sets'},Murat Kocaoglu,~Murat_Kocaoglu1,{'value': ['causal discovery']},"{'value': 'Constraint-based causal discovery algorithms learn part of the causal graph structure by systematically testing conditional independences  observed in the data. These algorithms, such as the PC algorithm and its variants, rely on graphical characterizations of the so-called equivalence class of causal graphs proposed by Pearl. However, constraint-based causal discovery algorithms struggle when data is limited since conditional independence tests quickly lose their statistical power, especially when the conditioning set is large. To address this, we propose using conditional independence tests where the size of the conditioning set is upper bounded by some integer k for robust causal discovery. The existing graphical characterizations of the equivalence classes of causal graphs are not applicable when we cannot leverage all the conditional independence statements. We first define the notion of k-Markov equivalence: Two causal graphs are k-Markov equivalent if they entail the same conditional independence constraints where the conditioning set size is upper bounded by k. We propose a novel representation that allows us to graphically characterize k-Markov equivalence between two causal graphs. We propose a sound constraint-based algorithm called the k-PC algorithm for learning this equivalence class. Finally, we conduct synthetic, and semi-synthetic experiments to demonstrate that the k-PC algorithm enables more robust causal discovery in the small sample regime compared to the baseline algorithms.'}",https://openreview.net{'value': '/pdf/40bd359547c2f4abd9924d2c4d41cc87b817403c.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=c9fXCzR5fK,{'value': 'Sequential Subset Matching for Dataset Distillation'},Jiawei Du; Qin Shi; Joey Tianyi Zhou,~Jiawei_Du1; ~Qin_Shi2; ~Joey_Tianyi_Zhou1,"{'value': ['Dataset distillation', 'gradients matching']}","{'value': 'Dataset distillation is a newly emerging task that synthesizes a small-size dataset used in training deep neural networks (DNNs) for reducing data storage and model training costs. The synthetic datasets are expected to capture the essence of the knowledge contained in real-world datasets such that the former yields a similar performance as the latter. Recent advancements in distillation methods have produced notable improvements in generating synthetic datasets. However, current state-of-the-art methods treat the entire synthetic dataset as a unified entity and optimize each synthetic instance equally . This static optimization approach may lead to performance degradation in dataset distillation. \nSpecifically, we argue that static optimization can give rise to a coupling issue within the synthetic data, particularly when a larger amount of synthetic data is being optimized. This coupling issue, in turn, leads to the failure of the distilled dataset to extract the high-level features learned by the deep neural network (DNN) in the latter epochs.\nIn this study, we propose a new dataset distillation strategy called Sequential Subset Matching (SeqMatch), which tackles this problem by adaptively optimizing the synthetic data to encourage sequential acquisition of knowledge during dataset distillation. Our analysis indicates that SeqMatch effectively addresses the coupling issue by sequentially generating the synthetic instances, thereby enhancing its performance significantly. Our proposed SeqMatch outperforms state-of-the-art methods in various datasets, including SVNH, CIFAR-10, CIFAR-100, and Tiny ImageNet.'}",https://openreview.net{'value': '/pdf/a305925284b21726184d189947d646a471acc6e3.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=c5WOU7p4ES,{'value': 'PLASTIC: Improving Input and Label Plasticity for Sample Efficient Reinforcement Learning'},Hojoon Lee; Hanseul Cho; Hyunseung Kim; Daehoon Gwak; Joonkee Kim; Jaegul Choo; Se-Young Yun; Chulhee Yun,~Hojoon_Lee1; ~Hanseul_Cho1; ~Hyunseung_Kim1; ~Daehoon_Gwak1; ~Joonkee_Kim1; ~Jaegul_Choo1; ~Se-Young_Yun1; ~Chulhee_Yun1,"{'value': ['Reinforcement Learning', 'Sharpness Minimization', 'Generalization', 'Plasticity', 'Deep Learning']}","{'value': ""In Reinforcement Learning (RL), enhancing sample efficiency is crucial, particularly in scenarios when data acquisition is costly and risky. In principle, off-policy RL algorithms can improve sample efficiency by allowing multiple updates per environment interaction. However, these multiple updates often lead the model to overfit to earlier interactions, which is referred to as the loss of plasticity. Our study investigates the underlying causes of this phenomenon by dividing plasticity into two aspects. Input plasticity, which denotes the model's adaptability to changing input data, and label plasticity, which denotes the model's adaptability to evolving input-output relationships. Synthetic experiments on the CIFAR-10 dataset reveal that finding smoother minima of loss landscape enhances input plasticity, whereas refined gradient propagation improves label plasticity. Leveraging these findings, we introduce the **PLASTIC** algorithm, which harmoniously combines techniques to address both concerns. With minimal architectural modifications, PLASTIC achieves competitive performance on benchmarks including Atari-100k and Deepmind Control Suite. This result emphasizes the importance of preserving the model's plasticity to elevate the sample efficiency in RL. The code is available at https://github.com/dojeon-ai/plastic.""}",https://openreview.net{'value': '/pdf/f3ae9b406bd3fb1f4b4476cb648e41c4c8d0c3a0.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=bzXpQUnule,{'value': 'Federated Linear Bandits with Finite Adversarial Actions'},Li Fan; Ruida Zhou; Chao Tian; Cong Shen,~Li_Fan5; ~Ruida_Zhou1; ~Chao_Tian2; ~Cong_Shen1,"{'value': ['Federated bandits', 'contextual bandits', 'regret analysis']}","{'value': 'We study a federated linear bandits model, where $M$ clients communicate with a central server to solve a linear contextual bandits problem with finite adversarial action sets that may be different across clients. To address the unique challenges of **adversarial finite** action sets, we propose the FedSupLinUCB algorithm, which extends the principles of SupLinUCB and OFUL algorithms in linear contextual bandits. We prove that FedSupLinUCB achieves a total regret of $\\tilde{O}(\\sqrt{d T})$, where $T$ is the total number of arm pulls from all clients, and $d$ is the ambient dimension of the linear model. This matches the minimax lower bound and thus is order-optimal (up to polylog terms). We study both asynchronous and synchronous cases and show that the communication cost can be controlled as $O(d M^2 \\log(d)\\log(T))$ and $O(\\sqrt{d^3 M^3} \\log(d))$, respectively. The FedSupLinUCB design is further extended to two scenarios: (1) variance-adaptive, where a total regret of $\\tilde{O} (\\sqrt{d \\sum \\nolimits_{t=1}^{T} \\sigma_t^2})$ can be achieved with $\\sigma_t^2$ being the noise variance of round $t$; and (2) adversarial corruption, where a total regret of $\\tilde{O}(\\sqrt{dT} + d C_p)$ can be achieved with $C_p$ being the total corruption budget. Experiment results corroborate the theoretical analysis and demonstrate the effectiveness of \\alg on both synthetic and real-world datasets.'}",https://openreview.net{'value': '/pdf/bb25c64a9b239ef6c9a1893a809e563f796a410f.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=bv9mmH0LGF,{'value': 'Global Structure-Aware Diffusion Process for Low-light Image Enhancement'},Jinhui HOU; Zhiyu Zhu; Junhui Hou; Hui LIU; Huanqiang Zeng; Hui Yuan,~Jinhui_HOU1; ~Zhiyu_Zhu1; ~Junhui_Hou2; ~Hui_LIU14; ~Huanqiang_Zeng1; ~Hui_Yuan1,"{'value': ['Image enhancement', 'diffusion models']}","{'value': 'This paper studies a diffusion-based framework to address the low-light image enhancement problem. To harness the capabilities of diffusion models, we delve into this intricate process and advocate for the regularization of its inherent ODE-trajectory. To be specific, inspired by the recent research that low curvature ODE-trajectory results in a stable and effective diffusion process, we formulate a curvature regularization term anchored in the intrinsic non-local structures of image data, i.e., global structure-aware regularization, which gradually facilitates the preservation of complicated details and the augmentation of contrast during the diffusion process. This incorporation mitigates the adverse effects of noise and artifacts resulting from the diffusion process, leading to a more precise and flexible enhancement. To additionally promote learning in challenging regions, we introduce an uncertainty-guided regularization technique, which wisely relaxes constraints on the most extreme regions of the image. Experimental evaluations reveal that the proposed diffusion-based framework, complemented by rank-informed regularization, attains distinguished performance in low-light enhancement. The outcomes indicate substantial advancements in image quality, noise suppression, and contrast amplification in comparison with state-of-the-art methods. We believe this innovative approach will stimulate further exploration and advancement in low-light image processing, with potential implications for other applications of diffusion models. The code is publicly available at https://github.com/jinnh/GSAD.'}",https://openreview.net{'value': '/pdf/633f0937fc37740f3d30a982adae94b87ce88fcd.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=bpmM6SkDUy,{'value': 'EDGI: Equivariant Diffusion for Planning with Embodied Agents'},Johann Brehmer; Joey Bose; Pim De Haan; Taco Cohen,~Johann_Brehmer1; ~Joey_Bose1; ~Pim_De_Haan1; ~Taco_Cohen1,"{'value': ['Planning', 'Diffusion models', 'Equivariance', 'Equivariant generative models']}","{'value': 'Embodied agents operate in a structured world, often solving tasks with spatial, temporal, and permutation symmetries. Most algorithms for planning and model-based reinforcement learning (MBRL) do not take this rich geometric structure into account, leading to sample inefficiency and poor generalization. We introduce the Equivariant Diffuser for Generating Interactions (EDGI), an algorithm for MBRL and planning that is equivariant with respect to the product of the spatial symmetry group SE(3), the discrete-time translation group ℤ, and the object permutation group Sₙ. EDGI follows the Diffuser framework by Janner et al. (2022) in treating both learning a world model and planning in it as a conditional generative modeling problem, training a diffusion model on an offline trajectory dataset. We introduce a new SE(3) × ℤ × Sₙ-equivariant diffusion model that supports multiple representations. We integrate this model in a planning loop, where conditioning and classifier guidance let us softly break the symmetry for specific tasks as needed. On object manipulation and navigation tasks, EDGI is substantially more sample efficient and generalizes better across the symmetry group than non-equivariant models.'}",https://openreview.net{'value': '/pdf/1fbba77049c62a9573302e3d761a841d38e952ae.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=blC2kbzvNC,{'value': 'Adaptive SGD with Polyak stepsize and Line-search: Robust Convergence and Variance Reduction'},Xiaowen Jiang; Sebastian U Stich,~Xiaowen_Jiang1; ~Sebastian_U_Stich1,"{'value': ['Convex Optimization', 'SGD', 'Adaptive Methods', 'Variance Reduction', 'Polyak Stepsize', 'Line-Search']}","{'value': 'The recently proposed stochastic Polyak stepsize (SPS) and stochastic line-search (SLS) for SGD have shown remarkable effectiveness when training over-parameterized models. However, two issues remain unsolved in this line of work. \n\nFirst, in non-interpolation settings, both algorithms only guarantee convergence to a neighborhood of a solution which may result in a worse output than the initial guess. While artificially decreasing the adaptive stepsize has been proposed to address this issue (Orvieto et al.), this approach results in slower convergence rates under interpolation. Second, intuitive line-search methods equipped with variance-reduction (VR) fail to converge (Dubois-Taine et al.). So far, no VR methods successfully accelerate these two stepsizes with a convergence guarantee.\n\nIn this work, we make two contributions:\nFirstly, we propose two new robust variants of SPS and SLS, called AdaSPS and AdaSLS, which achieve optimal asymptotic rates in both strongly-convex or convex and interpolation or non-interpolation settings, except for the case when we have both strong convexity and non-interpolation. AdaSLS requires no knowledge of problem-dependent parameters, and AdaSPS requires only a lower bound of the optimal function value as input. Secondly, we propose a novel VR method that can use Polyak stepsizes or line-search to achieve acceleration. When it is equipped with AdaSPS or AdaSLS, the resulting algorithms obtain the optimal rate\nfor optimizing convex smooth functions. Finally, numerical experiments on synthetic and real datasets validate our theory and demonstrate the effectiveness and robustness of our algorithms.'}",https://openreview.net{'value': '/pdf/7b6a59babc1d365f2e5bc21419781dd18c3837eb.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=bTidcHIK2t,{'value': 'Sample-Efficient and Safe Deep Reinforcement Learning via Reset Deep Ensemble Agents'},Woojun Kim; Yongjae Shin; Jongeui Park; Youngchul Sung,~Woojun_Kim1; ~Yongjae_Shin1; ~Jongeui_Park1; ~Youngchul_Sung1,"{'value': ['deep reinforcement learning', 'primacy bais', 'reset', 'deep ensemble learning']}","{'value': 'Deep reinforcement learning (RL) has achieved remarkable success in solving complex tasks through its integration with deep neural networks (DNNs) as function approximators. However, the reliance on DNNs has introduced a new challenge called primacy bias, whereby these function approximators tend to prioritize early experiences, leading to overfitting. To alleviate this bias, a reset method has been proposed, which involves periodic resets of a portion or the entirety of a deep RL agent while preserving the replay buffer. However, the use of this method can result in performance collapses after executing the reset, raising concerns from the perspective of safe RL and regret minimization. In this paper, we propose a novel reset-based method that leverages deep ensemble learning to address the limitations of the vanilla reset method and enhance sample efficiency. The effectiveness of the proposed method is validated through various experiments including those in the domain of safe RL. Numerical results demonstrate its potential for real-world applications requiring high sample efficiency and safety considerations.'}",https://openreview.net{'value': '/pdf/8fb96c65539c5ae4b7cbbab1b832450820a23e0d.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=bNNIf8F9OU,{'value': 'Empowering Collaborative Filtering with Principled Adversarial Contrastive Loss'},An Zhang; Leheng Sheng; Zhibo Cai; Xiang Wang; Tat-Seng Chua,~An_Zhang2; ~Leheng_Sheng2; ~Zhibo_Cai1; ~Xiang_Wang6; ~Tat-Seng_Chua2,"{'value': ['Collaborative filtering', 'Contrastive loss', 'Recommendation', 'Generalization ability']}","{'value': 'Contrastive Learning (CL) has achieved impressive performance in self-supervised learning tasks, showing superior generalization ability. Inspired by the success, adopting CL into collaborative filtering (CF) is prevailing in semi-supervised topK recommendations. The basic idea is to routinely conduct heuristic-based data augmentation and apply contrastive losses (e.g., InfoNCE) on the augmented views. Yet, some CF-tailored challenges make this adoption suboptimal, such as the issue of out-of-distribution, the risk of false negatives, and the nature of top-K evaluation. They necessitate the CL-based CF scheme to focus more on mining hard negatives and distinguishing false negatives from the vast unlabeled user-item interactions, for informative contrast signals. Worse still, there is limited understanding of contrastive loss in CF methods, especially w.r.t. its generalization ability. To bridge the gap, we delve into the reasons underpinning the success of contrastive loss in CF, and propose a principled Adversarial InfoNCE loss (AdvInfoNCE), which is a variant of InfoNCE, specially tailored for CF methods. AdvInfoNCE adaptively explores and assigns hardness to each negative instance in an adversarial fashion and further utilizes a fine-grained hardness-aware ranking criterion to empower the recommender’s generalization ability. Training CF models with AdvInfoNCE, we validate the effectiveness of AdvInfoNCE on both synthetic and real-world benchmark datasets, thus showing its generalization ability to mitigate out-of-distribution problems. Given the theoretical guarantees and empirical superiority of AdvInfoNCE over most contrastive loss functions, we advocate its adoption as a standard loss in recommender systems, particularly for the out-of-distribution tasks. Codes are available at https://github.com/LehengTHU/AdvInfoNCE.'}",https://openreview.net{'value': '/pdf/fc59dd264ba52092dea608e587d887e9791866f0.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=bM6mynsusR,{'value': 'Function Space Bayesian Pseudocoreset for Bayesian Neural Networks'},Balhae Kim; Hyungi Lee; Juho Lee,~Balhae_Kim1; ~Hyungi_Lee1; ~Juho_Lee2,"{'value': ['Bayesian pseudocoresets', 'Function space variational inference']}","{'value': 'A Bayesian pseudocoreset is a compact synthetic dataset summarizing essential information of a large-scale dataset and thus can be used as a proxy dataset for scalable Bayesian inference. Typically, a Bayesian pseudocoreset is constructed by minimizing a divergence measure between the posterior conditioning on the pseudocoreset and the posterior conditioning on the full dataset. However, evaluating the divergence can be challenging, particularly for the models like deep neural networks having high-dimensional parameters. In this paper, we propose a novel Bayesian pseudocoreset construction method that operates on a function space. Unlike previous methods, which construct and match the coreset and full data posteriors in the space of model parameters (weights), our method constructs variational approximations to the coreset posterior on a function space and matches it to the full data posterior in the function space. By working directly on the function space, our method could bypass several challenges that may arise when working on a weight space, including limited scalability and multi-modality issue. Through various experiments, we demonstrate that the Bayesian pseudocoresets constructed from our method enjoys enhanced uncertainty quantification and better robustness across various model architectures.'}",https://openreview.net{'value': '/pdf/92b60997adf6e44155c91b8d3a7869c98a37cee4.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=b60wLlkBta,{'value': 'On the Robustness of Removal-Based Feature Attributions'},Chris Lin; Ian Connick Covert; Su-In Lee,~Chris_Lin1; ~Ian_Connick_Covert1; ~Su-In_Lee2,"{'value': ['explainable artificial intelligence', 'interpretable machine learning', 'feature attributions', 'removal-based feature attributions', 'robustness']}","{'value': 'To explain predictions made by complex machine learning models, many feature attribution methods have been developed that assign importance scores to input features. Some recent work challenges the robustness of these methods by showing that they are sensitive to input and model perturbations, while other work addresses this issue by proposing robust attribution methods. However, previous work on attribution robustness has focused primarily on gradient-based feature attributions, whereas the robustness of removal-based attribution methods is not currently well understood. To bridge this gap, we theoretically characterize the robustness properties of removal-based feature attributions. Specifically, we provide a unified analysis of such methods and derive upper bounds for the difference between intact and perturbed attributions, under settings of both input and model perturbations. Our empirical results on synthetic and real-world data validate our theoretical results and demonstrate their practical implications, including the ability to increase attribution robustness by improving the model’s Lipschitz regularity.'}",https://openreview.net{'value': '/pdf/b5cee429cd6a9ccadf51aa1f36e11e09927b72b2.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=aw1vLo7TE7,{'value': 'Risk-Averse Active Sensing for Timely Outcome Prediction under Cost Pressure'},Yuchao Qin; Mihaela van der Schaar; Changhee Lee,~Yuchao_Qin1; ~Mihaela_van_der_Schaar2; ~Changhee_Lee1,"{'value': ['active sensing', 'value of information', 'risk-averse learning']}","{'value': ""Timely outcome prediction is essential in healthcare to enable early detection and intervention of adverse events. However, in longitudinal follow-ups to patients' health status, cost-efficient acquisition of patient covariates is usually necessary due to the significant expense involved in screening and lab tests. To balance the timely and accurate outcome predictions with acquisition costs, an effective active sensing strategy is crucial. In this paper, we propose a novel risk-averse active sensing approach RAS that addresses the composite decision problem of when to conduct the acquisition and which measurements to make. Our approach decomposes the policy into two sub-policies: acquisition scheduler and feature selector, respectively. Moreover, we introduce a novel risk-aversion training strategy to focus on the underrepresented subgroup of high-risk patients for whom timely and accurate prediction of disease progression is of greater value. Our method outperforms baseline active sensing approaches in experiments with both synthetic and real-world datasets, and we illustrate the significance of our policy decomposition and the necessity of a risk-averse sensing policy through case studies.""}",https://openreview.net{'value': '/pdf/2f61cd3fad06b099f3895a2a5145d5adf5c98758.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=aky0dKv9ip,{'value': 'Decompose a Task into Generalizable Subtasks in Multi-Agent Reinforcement Learning'},Zikang Tian; Ruizhi Chen; Xing Hu; Ling Li; Rui Zhang; Fan Wu; Shaohui Peng; Jiaming Guo; Zidong Du; Qi Guo; Yunji Chen,~Zikang_Tian1; ~Ruizhi_Chen3; ~Xing_Hu3; ~Ling_Li6; ~Rui_Zhang1; ~Fan_Wu11; ~Shaohui_Peng2; ~Jiaming_Guo2; ~Zidong_Du1; ~Qi_Guo4; ~Yunji_Chen1,"{'value': ['Multi-Agent Reinforcement Learning', 'Transfer Learning', 'Zero-Shot Generalization']}","{'value': 'In recent years, Multi-Agent Reinforcement Learning (MARL) techniques have made significant strides in achieving high asymptotic performance in single task. However, there has been limited exploration of model transferability across tasks. Training a model from scratch for each task can be time-consuming and expensive, especially for large-scale Multi-Agent Systems. Therefore, it is crucial to develop methods for generalizing the model across tasks. Considering that there exist task-independent subtasks across MARL tasks, a model that can decompose such subtasks from the source task could generalize to target tasks. However, ensuring true task-independence of subtasks poses a challenge. In this paper, we propose to \\textbf{d}ecompose a \\textbf{t}ask in\\textbf{to} a series of \\textbf{g}eneralizable \\textbf{s}ubtasks (DT2GS), a novel framework that addresses this challenge by utilizing a scalable subtask encoder and an adaptive subtask semantic module. We show that these components endow subtasks with two properties critical for task-independence: avoiding overfitting to the source task and maintaining consistent yet scalable semantics across tasks. Empirical results demonstrate that DT2GS possesses sound zero-shot generalization capability across tasks, exhibits sufficient transferability, and outperforms existing methods in both multi-task and single-task problems.'}",https://openreview.net{'value': '/pdf/8c0b780c17b5d39ece285b1e0c09028e642644cb.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=afKnrwJBAl,{'value': 'Cross-Episodic Curriculum for Transformer Agents'},Lucy Xiaoyang Shi; Yunfan Jiang; Jake Grigsby; Linxi Fan; Yuke Zhu,~Lucy_Xiaoyang_Shi1; ~Yunfan_Jiang1; ~Jake_Grigsby1; ~Linxi_Fan2; ~Yuke_Zhu1,"{'value': ['Transformers', 'In-context Learning', 'Reinforcement Learning', 'Robotics']}","{'value': ""We present a new algorithm, Cross-Episodic Curriculum (CEC), to boost the learning efficiency and generalization of Transformer agents. Central to CEC is the placement of cross-episodic experiences into a Transformer’s context, which forms the basis of a curriculum. By sequentially structuring online learning trials and mixed-quality demonstrations, CEC constructs curricula that encapsulate learning progression and proficiency increase across episodes. Such synergy combined with the potent pattern recognition capabilities of Transformer models delivers a powerful cross-episodic attention mechanism. The effectiveness of CEC is demonstrated under two representative scenarios: one involving multi-task reinforcement learning with discrete control, such as in DeepMind Lab, where the curriculum captures the learning progression in both individual and progressively complex settings; and the other involving imitation learning with mixed-quality data for continuous control, as seen in RoboMimic, where the curriculum captures the improvement in demonstrators' expertise. In all instances, policies resulting from CEC exhibit superior performance and strong generalization. Code is open-sourced on the project website https://cec-agent.github.io/ to facilitate research on Transformer agent learning.""}",https://openreview.net{'value': '/pdf/fce810149a981354afad34f9f90063e7674fb0a6.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=aZ44Na3l9p,{'value': 'Reproducibility in Multiple Instance Learning: A Case For Algorithmic Unit Tests'},Edward Raff; James Holt,~Edward_Raff1; ~James_Holt1,{'value': ['reproducibility; multiple instance learning']},"{'value': 'Multiple Instance Learning (MIL) is a sub-domain of classification problems with positive and negative labels and a ""bag"" of inputs, where the label is positive if and only if a positive element is contained within the bag, and otherwise is negative. Training in this context requires associating the bag-wide label to instance-level information, and implicitly contains a causal assumption and asymmetry to the task (i.e., you can\'t swap the labels without changing the semantics). MIL problems occur in healthcare (one malignant cell indicates cancer), cyber security (one malicious executable makes an infected computer), and many other tasks. In this work, we examine five of the most prominent deep-MIL models and find that none of them respects the standard MIL assumption. They are able to learn anti-correlated instances, i.e., defaulting to ""positive"" labels until seeing a negative counter-example, which should not be possible for a correct MIL model. We suspect that enhancements and other works derived from these models will share the same issue. In any context in which these models are being used, this creates the potential for learning incorrect models, which creates risk of operational failure.  We identify and demonstrate this problem via a proposed ``algorithmic unit test\'\', where we create synthetic datasets that can be solved by a MIL respecting model, and which clearly reveal learning that violates MIL assumptions. The five evaluated methods each fail one or more of these tests. This provides a model-agnostic way to identify violations of modeling assumptions, which we hope will be useful for future development and evaluation of MIL models.'}",https://openreview.net{'value': '/pdf/c51ba0fd5f256cd1c3c208edd78428583d4707a6.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=ZvDmna23r3,{'value': 'Thought Cloning: Learning to Think while Acting by Imitating Human Thinking'},Shengran Hu; Jeff Clune,~Shengran_Hu2; ~Jeff_Clune3,"{'value': ['Reinforcement learning', 'Imitation Learning', 'AI Safety', 'Interpretability']}","{'value': 'Language is often considered a key aspect of human thinking, providing us with exceptional abilities to generalize, explore, plan, replan, and adapt to new situations. However, Reinforcement Learning (RL) agents are far from human-level performance in any of these abilities. We hypothesize one reason for such cognitive deficiencies is that they lack the benefits of thinking in language and that we can improve AI agents by training them to $\\textit{think like humans do}$. We introduce a novel Imitation Learning framework, Thought Cloning, where the idea is to not just clone the behaviors of human demonstrators, $\\textit{but also the thoughts humans have as they perform these behaviors}$. While we expect Thought Cloning to truly shine at scale on internet-sized datasets (e.g. online videos with transcripts), here we conduct experiments in a domain where the thinking and action data are synthetically generated. Results reveal that Thought Cloning learns much faster than Behavioral Cloning and its performance advantage grows the further out of distribution test tasks are, highlighting its ability to better handle novel situations. Thought Cloning also provides important benefits for AI Safety and Interpretability, and makes it easier to debug and improve AI. Because we can observe the agent’s thoughts, we can (1) more easily diagnose why things are going wrong, making it easier to fix the problem, (2) steer the agent by correcting its thinking, or (3) prevent it from doing unsafe things it plans to do. Overall, by training agents $\\textit{how to think}$ as well as behave, Thought Cloning creates safer, more powerful agents.'}",https://openreview.net{'value': '/pdf/53b8112a015d972cf14baae6ee29f904f8c9e97b.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=ZcJa1R6j3v,{'value': 'Large Language Models Are Semi-Parametric Reinforcement Learning Agents'},Danyang Zhang; Lu Chen; Situo Zhang; Hongshen Xu; Zihan Zhao; Kai Yu,~Danyang_Zhang2; ~Lu_Chen3; ~Situo_Zhang1; ~Hongshen_Xu1; ~Zihan_Zhao1; ~Kai_Yu3,"{'value': ['Learning from Experiences', 'LLM', 'Reinforcement Learning', 'Decision Making', 'Experience Memory']}","{'value': 'Inspired by the insights in cognitive science with respect to human memory and reasoning mechanism, a novel evolvable LLM-based (Large Language Model) agent framework is proposed as Rememberer. By equipping the LLM with a long-term experience memory, Rememberer is capable of exploiting the experiences from the past episodes even for different task goals, which excels an LLM-based agent with fixed exemplars or equipped with a transient working memory. We further introduce **R**einforcement **L**earning with **E**xperience **M**emory (**RLEM**) to update the memory. Thus, the whole system can learn from the experiences of both success and failure, and evolve its capability without fine-tuning the parameters of the LLM. In this way, the proposed Rememberer constitutes a semi-parametric RL agent. Extensive experiments are conducted on two RL task sets to evaluate the proposed framework. The average results with different initialization and training sets exceed the prior SOTA by 4% and 2% for the success rate on two task sets and demonstrate the superiority and robustness of Rememberer.'}",https://openreview.net{'value': '/pdf/9771a8343bb46aae73ab06aad55ce991cbcf441a.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=ZZgfS1DbmO,{'value': 'Continuous Parametric Optical Flow'},Jianqin Luo; Zhexiong Wan; yuxin mao; Bo Li; Yuchao Dai,~Jianqin_Luo2; ~Zhexiong_Wan1; ~yuxin_mao2; ~Bo_Li35; ~Yuchao_Dai1,"{'value': ['optical flow', 'point trajectories', 'continuous motion', 'neural ordinary differential equation']}","{'value': 'In this paper, we present continuous parametric optical flow, a parametric representation of dense and continuous motion over arbitrary time interval. In contrast to existing discrete-time representations (i.e., flow in between consecutive frames), this new representation transforms the frame-to-frame pixel correspondences to dense continuous flow. In particular, we present a temporal-parametric model that employs B-splines to fit point trajectories using a limited number of frames. To further improve the stability and robustness of the trajectories, we also add an encoder with a neural ordinary differential equation (NODE) to represent features associated with specific times. We also contribute a synthetic dataset and introduce two evaluation perspectives to measure the accuracy and robustness of continuous flow estimation. Benefiting from the combination of explicit parametric modeling and implicit feature optimization, our model focuses on motion continuity and outperforms the flow-based and point-tracking approaches for fitting long-term and variable sequences.'}",https://openreview.net{'value': '/pdf/3527881546b3e8a7769a902e75c6289539557164.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=ZXbgVm3PSt,{'value': 'TART: A plug-and-play Transformer module for task-agnostic reasoning'},Kush Bhatia; Avanika Narayan; Christopher De Sa; Christopher Re,~Kush_Bhatia3; ~Avanika_Narayan1; ~Christopher_De_Sa2; ~Christopher_Re1,"{'value': ['In-context learning', 'task-agnostic methods', 'large language models']}","{'value': ""Large language models (LLMs) exhibit in-context learning abilities which enable the same model to perform several tasks without any task-specific training. In contrast, traditional adaptation approaches, such as fine-tuning, modify the underlying models for each specific task. In-context learning, however, consistently underperforms task-specific tuning approaches even when presented with the same examples. While most existing approaches (e.g., prompt engineering) focus on the LLM's learned representations to patch this performance gap, our experiments actually reveal that LLM representations contain sufficient information to make good predictions. As such, we focus on the LLM's reasoning abilities and demonstrate that this performance gap exists due to their inability to perform simple probabilistic reasoning tasks. This raises an intriguing question: Are LLMs actually capable of learning how to reason in a task-agnostic manner? We answer this in the affirmative and, as a proof of concept, propose TART which generically improves an LLM's reasoning abilities using a synthetically trained reasoning module. TART trains this Transformer-based reasoning module in a task-agnostic manner using only synthetic logistic regression tasks and composes it with an arbitrary real-world pre-trained model without any additional training. With a single inference module, TART improves performance across different model families (GPT-Neo, Pythia, Bloom), model sizes (100M - 6B), tasks (14 NLP classification tasks), and even across different modalities (audio and vision). On the RAFT Benchmark, TART improves GPT-Neo (125M)'s performance such that it outperforms Bloom (176B), and is within $4$% of GPT-3.""}",https://openreview.net{'value': '/pdf/1bc7179745183a8b1dc0ead356b054fdd89ac35f.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=ZQMlfNijY5,{'value': 'Normalizing flow neural networks by JKO scheme'},Chen Xu; Xiuyuan Cheng; Yao Xie,~Chen_Xu12; ~Xiuyuan_Cheng1; ~Yao_Xie2,"{'value': ['Normalizing flow', 'invertible neural networks', 'JKO scheme']}","{'value': 'Normalizing flow is a class of deep generative models for efficient sampling and likelihood estimation, which achieves attractive performance, particularly in high dimensions. The flow is often implemented using a sequence of invertible residual blocks. Existing works adopt special network architectures and regularization of flow trajectories. In this paper, we develop a neural ODE flow network called JKO-iFlow, inspired by the Jordan-Kinderleherer-Otto (JKO) scheme, which unfolds the discrete-time dynamic of the Wasserstein gradient flow. The proposed method stacks residual blocks one after another, allowing efficient block-wise training of the residual blocks, avoiding sampling SDE trajectories and score matching or variational learning, thus reducing the memory load and difficulty in end-to-end training. We also develop adaptive time reparameterization of the flow network with a progressive refinement of the induced trajectory in probability space to improve the model accuracy further. Experiments with synthetic and real data show that the proposed JKO-iFlow network achieves competitive performance compared with existing flow and diffusion models at a significantly reduced computational and memory cost.'}",https://openreview.net{'value': '/pdf/16dd0bc4633b4b0da118d255a7a050c17be53507.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=ZPj7ey5fXa,{'value': 'PyNeRF: Pyramidal Neural Radiance Fields'},Haithem Turki; Michael Zollhöfer; Christian Richardt; Deva Ramanan,~Haithem_Turki1; ~Michael_Zollhöfer2; ~Christian_Richardt1; ~Deva_Ramanan1,"{'value': ['view synthesis', '3d reconstruction', 'scene representation', '3d deep learning']}","{'value': 'Neural Radiance Fields (NeRFs) can be dramatically accelerated by spatial grid representations. However, they do not explicitly reason about scale and so introduce aliasing artifacts when reconstructing scenes captured at different camera distances. Mip-NeRF and its extensions propose scale-aware renderers that project volumetric frustums rather than point samples. But such approaches rely on positional encodings that are not readily compatible with grid methods. We propose a simple modification to grid-based models by training model heads at different spatial grid resolutions. At render time, we simply use coarser grids to render samples that cover larger volumes. Our method can be easily applied to existing accelerated NeRF methods and significantly improves rendering quality (reducing error rates by 20–90% across synthetic and unbounded real-world scenes) while incurring minimal performance overhead (as each model head is quick to evaluate). Compared to Mip-NeRF, we reduce error rates by 20% while training over 60x faster.'}",https://openreview.net{'value': '/pdf/7b2da8a9f2972f2bda3ec2618cd1ffaf455f1f8f.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=ZIyAHaLlsn,{'value': 'ResShift: Efficient Diffusion Model for Image Super-resolution by Residual Shifting'},Zongsheng Yue; Jianyi Wang; Chen Change Loy,~Zongsheng_Yue1; ~Jianyi_Wang1; ~Chen_Change_Loy2,{'value': ['Super-resolution; Diffusion model; Efficient']},"{'value': 'Diffusion-based image super-resolution (SR) methods are mainly limited by the low inference speed due to the requirements of hundreds or even thousands of sampling steps. Existing acceleration sampling techniques inevitably sacrifice performance to some extent, leading to over-blurry SR results. To address this issue, we propose a novel and efficient diffusion model for SR that significantly reduces the number of diffusion steps, thereby eliminating the need for post-acceleration during inference and its associated performance deterioration. Our method constructs a Markov chain that transfers between the high-resolution image and the low-resolution image by shifting the residual between them, substantially improving the transition efficiency. Additionally, an elaborate noise schedule is developed to flexibly control the shifting speed and the noise strength during the diffusion process. Extensive experiments demonstrate that the proposed method obtains superior or at least comparable performance to current state-of-the-art methods on both synthetic and real-world datasets, \\textit{\\textbf{even only with 20 sampling steps}}. Our code and model will be made publicly.'}",https://openreview.net{'value': '/pdf/8f70c4f6b1bc6598c74af8d673c243159b0e81d1.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=ZIfhYAE2xg,{'value': 'Sparse Parameterization for Epitomic Dataset Distillation'},Xing Wei; Anjia Cao; Funing Yang; Zhiheng Ma,~Xing_Wei5; ~Anjia_Cao1; ~Funing_Yang1; ~Zhiheng_Ma1,"{'value': ['Dataset Distillation', 'Dataset Condensation', 'Sparse Coding', 'Dictionary Learning']}","{'value': 'The success of deep learning relies heavily on large and diverse datasets, but the storage, preprocessing, and training of such data present significant challenges. To address these challenges, dataset distillation techniques have been proposed to obtain smaller synthetic datasets that capture the essential information of the originals. In this paper, we introduce a Sparse Parameterization for Epitomic datasEt Distillation (SPEED) framework, which leverages the concept of dictionary learning and sparse coding to distill epitomes that represent pivotal information of the dataset. SPEED prioritizes proper parameterization of the synthetic dataset and introduces techniques to capture spatial redundancy within and between synthetic images. We propose Spatial-Agnostic Epitomic Tokens (SAETs) and Sparse Coding Matrices (SCMs) to efficiently represent and select significant features. Additionally, we build a Feature-Recurrent Network (FReeNet) to generate hierarchical features with high compression and storage efficiency. Experimental results demonstrate the superiority of SPEED in handling high-resolution datasets, achieving state-of-the-art performance on multiple benchmarks and downstream applications. Our framework is compatible with a variety of dataset matching approaches, generally enhancing their performance. This work highlights the importance of proper parameterization in epitomic dataset distillation and opens avenues for efficient representation learning. Source code is available at https://github.com/MIV-XJTU/SPEED.'}",https://openreview.net{'value': '/pdf/5828924919f2aef4c1bba2ca3813887d0e65c298.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=ZARAiV25CW,{'value': 'Generalized Bayesian Inference for Scientific Simulators via Amortized Cost Estimation'},Richard Gao; Michael Deistler; Jakob H. Macke,~Richard_Gao1; ~Michael_Deistler1; ~Jakob_H._Macke1,"{'value': ['simulation-based inference', 'generalized bayesian inference', 'neural network', 'machine learning for science']}","{'value': 'Simulation-based inference (SBI) enables amortized Bayesian inference for simulators with implicit likelihoods. But when we are primarily interested in the quality of predictive simulations, or when the model cannot exactly reproduce the observed data (i.e., is misspecified), targeting the Bayesian posterior may be overly restrictive. Generalized Bayesian Inference (GBI) aims to robustify inference for (misspecified) simulator models, replacing the likelihood-function with a cost function that evaluates the goodness of parameters relative to data. However, GBI methods generally require running multiple simulations to estimate the cost function at each parameter value during inference, making the approach computationally infeasible for even moderately complex simulators. Here, we propose amortized cost estimation (ACE) for GBI to address this challenge: We train a neural network to approximate the cost function, which we define as the expected distance between simulations produced by a parameter and observed data. The trained network can then be used with MCMC to infer GBI posteriors for any observation without running additional simulations. We show that, on several benchmark tasks, ACE accurately predicts cost and provides predictive simulations that are closer to synthetic observations than other SBI methods, especially for misspecified simulators. Finally, we apply ACE to infer parameters of the Hodgkin-Huxley model given real intracellular recordings from the Allen Cell Types Database. ACE identifies better data-matching parameters while being an order of magnitude more simulation-efficient than a standard SBI method. In summary, ACE combines the strengths of SBI methods and GBI to perform robust and simulation-amortized inference for scientific simulators.'}",https://openreview.net{'value': '/pdf/752b49ab56d4df297a31cb743536e277df4d6ffa.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Z764QxwETf,{'value': 'Puzzlefusion: Unleashing the Power of Diffusion Models for Spatial Puzzle Solving'},Sepidehsadat Hosseini; Mohammad Amin Shabani; Saghar Irandoust; Yasutaka Furukawa,~Sepidehsadat_Hosseini2; ~Mohammad_Amin_Shabani1; ~Saghar_Irandoust1; ~Yasutaka_Furukawa1,"{'value': ['Diffusion', 'Jigsaw', 'puzzle solving']}","{'value': ""This paper presents an end-to-end neural architecture based on Diffusion Models for spatial puzzle solving, particularly jigsaw puzzle and room arrangement tasks.\nIn the latter task, for instance, the proposed system ``PuzzleFusion'' takes a set of room layouts as polygonal curves in the top-down view and aligns the room layout pieces by estimating their 2D translations and rotations, akin to solving the jigsaw puzzle of room layouts. A surprising discovery of the paper is that the simple use of a Diffusion Model effectively solves these challenging spatial puzzle tasks as a conditional generation process. \nTo enable learning of an end-to-end neural system, the paper introduces new datasets with ground-truth arrangements: 1) 2D Voronoi Jigsaw Dataset, a synthetic one where pieces are generated by voronoi diagram of 2D pointset; and 2) MagicPlan Dataset, a real one from a production pipeline by MagicPlan, where pieces are room layouts constructed by augmented reality App by real-estate consumers.\nThe qualitative and quantitative evaluations demonstrate that the proposed approach outperforms the competing methods by significant margins in all three spatial puzzle tasks. We have provided code and data in https://sepidsh.github.io/puzzlefusion.""}",https://openreview.net{'value': '/pdf/2c871c960c5841b8911dbcd7124e940dbed64d2f.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Z16jo3d6OD,{'value': 'A Unified Framework for Rank-based Loss Minimization'},Rufeng Xiao; Yuze Ge; Rujun Jiang; Yifan Yan,~Rufeng_Xiao1; ~Yuze_Ge1; ~Rujun_Jiang1; yanyf21@m.fudan.edu.cn,"{'value': ['rank-based loss', 'ADMM', 'nonconvex nonsmooth optimization', 'conditional Value-at-Risk', 'human-aligned risk', 'ranked range loss']}","{'value': 'The empirical loss, commonly referred to as the average loss, is extensively utilized for training machine learning models. However, in order to address the diverse performance requirements of machine learning models, the use of the rank-based loss is prevalent, replacing the empirical loss in many cases. The rank-based loss comprises a weighted sum of sorted individual losses, encompassing both convex losses like the spectral risk, which includes the empirical risk and conditional value-at-risk, and nonconvex losses such as the human-aligned risk and the sum of the ranked range loss. In this paper, we introduce a unified framework for the optimization of the rank-based loss through the utilization of a proximal alternating direction method of multipliers. We demonstrate the convergence and convergence rate of the proposed algorithm under mild conditions. Experiments conducted on synthetic and real datasets illustrate the effectiveness and efficiency of the proposed algorithm.'}",https://openreview.net{'value': '/pdf/43d8a2abe09095c77880d689f626c7741d6bb7b4.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Yq6GKgN3RC,"{'value': 'Federated Learning with Client Subsampling, Data Heterogeneity, and Unbounded Smoothness: A New Algorithm and Lower Bounds'}",Michael Crawshaw; Yajie Bao; Mingrui Liu,~Michael_Crawshaw1; ~Yajie_Bao2; ~Mingrui_Liu2,"{'value': ['federated learning', 'client subsampling', 'nonconvex optimization', 'relaxed smoothness', 'data heterogeneity', 'lower bound']}","{'value': 'We study the problem of Federated Learning (FL) under client subsampling and data heterogeneity with an objective function that has potentially unbounded smoothness. This problem is motivated by empirical evidence that the class of relaxed smooth functions, where the Lipschitz constant of the gradient scales linearly with the gradient norm, closely resembles the loss functions of certain neural networks such as recurrent neural networks (RNNs) with possibly exploding gradient. We introduce EPISODE++, the first algorithm to solve this problem. It maintains historical statistics for each client to construct control variates and decide clipping behavior for sampled clients in the current round. We prove that EPISODE++ achieves linear speedup in the number of participating clients, reduced communication rounds, and resilience to data heterogeneity. Our upper bound proof relies on novel techniques of recursively bounding the client updates under unbounded smoothness and client subsampling, together with a refined high probability analysis. In addition, we prove a lower bound showing that the convergence rate of a special case of clipped minibatch SGD (without randomness in the stochastic gradient and with randomness in client subsampling) suffers from an explicit dependence on the maximum gradient norm of the objective in a sublevel set, which may be large. This effectively demonstrates that applying gradient clipping to minibatch SGD in our setting does not eliminate the problem of exploding gradients.  Our lower bound is based on new constructions of hard instances tailored to client subsampling and a novel analysis of the trajectory of the algorithm in the presence of clipping. Lastly, we provide an experimental evaluation of EPISODE++ when training RNNs on federated text classification tasks, demonstrating that EPISODE++ outperforms strong baselines in FL. The code is available at https://github.com/MingruiLiu-ML-Lab/episode_plusplus.'}",https://openreview.net{'value': '/pdf/c121028759cbbd04b2a4b08970a84d7d0f69b6ab.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Ypbke6biDm,"{'value': 'Pareto Frontiers in Deep Feature Learning: Data, Compute, Width, and Luck'}",Benjamin L. Edelman; Surbhi Goel; Sham M. Kakade; eran malach; Cyril Zhang,~Benjamin_L._Edelman1; ~Surbhi_Goel1; ~Sham_M._Kakade1; ~eran_malach1; ~Cyril_Zhang1,"{'value': ['deep learning', 'feature learning', 'parity', 'grokking', 'lottery tickets', 'scaling']}","{'value': 'In modern deep learning, algorithmic choices (such as width, depth, and learning rate) are known to modulate nuanced resource tradeoffs. This work investigates how these complexities necessarily arise for feature learning in the presence of computational-statistical gaps. We begin by considering offline sparse parity learning, a supervised classification problem which admits a statistical query lower bound for gradient-based training of a multilayer perceptron. This lower bound can be interpreted as a *multi-resource tradeoff frontier*: \nsuccessful learning can only occur if one is sufficiently rich (large model), knowledgeable (large dataset), patient (many training iterations), or lucky (many random guesses). We show, theoretically and experimentally, that sparse initialization and increasing network width yield significant improvements in sample efficiency in this setting. Here, width plays the role of parallel search: it amplifies the probability of finding ""lottery ticket"" neurons, which learn sparse features more sample-efficiently. Finally, we show that the synthetic sparse parity task can be useful as a proxy for real problems requiring axis-aligned feature learning. We demonstrate improved sample efficiency on tabular classification benchmarks by using wide, sparsely-initialized MLP models; these networks sometimes outperform tuned random forests.'}",https://openreview.net{'value': '/pdf/6e863d634fe93a3dd748a804d5dc18c38aaabc14.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=YhAZqWhOnS,{'value': 'Autodecoding Latent 3D Diffusion Models'},Evangelos Ntavelis; Aliaksandr Siarohin; Kyle Olszewski; Chaoyang Wang; Luc Van Gool; Sergey Tulyakov,~Evangelos_Ntavelis1; ~Aliaksandr_Siarohin1; ~Kyle_Olszewski1; ~Chaoyang_Wang1; ~Luc_Van_Gool1; ~Sergey_Tulyakov1,"{'value': ['3D Generation', 'Diffusion Models']}","{'value': 'Diffusion-based methods have shown impressive visual results in the text-to-image domain. They first learn a latent space using an autoencoder, then run a denoising process on the bottleneck to generate new samples. However, learning an autoencoder requires substantial data in the target domain. Such data is scarce for 3D generation, prohibiting the learning of large-scale diffusion models for 3D synthesis. We present a novel approach to the generation of static and articulated 3D assets that has a 3D autodecoder at its core. The 3D autodecoder framework embeds properties learned from the target dataset in the latent space, which can then be decoded into a volumetric representation for rendering view-consistent appearance and geometry. We then identify the appropriate intermediate volumetric latent space, and introduce robust normalization and de-normalization operations to learn a 3D diffusion from 2D images or monocular videos of rigid or articulated objects. Our approach is flexible enough to use either existing camera supervision or no camera information at all -- instead efficiently learning it during training. Our evaluations demonstrate that our generation results outperform state-of-the-art alternatives on various benchmark datasets and metrics, including multi-view image datasets of synthetic objects, real in-the-wild videos of moving people, and a large-scale, real video dataset of static objects.'}",https://openreview.net{'value': '/pdf/4a58bc5efc695ed9a8ac480a5dd07ad0de32f6b0.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=YdfcKb4Wif,{'value': 'Learning Trajectories are Generalization Indicators'},Jingwen Fu; Zhizheng Zhang; Dacheng Yin; Yan Lu; Nanning Zheng,~Jingwen_Fu1; ~Zhizheng_Zhang1; ~Dacheng_Yin1; ~Yan_Lu7; ~Nanning_Zheng1,"{'value': ['Generalization', 'Learning Trajectory']}","{'value': ""This paper explores the connection between learning trajectories of Deep Neural Networks (DNNs) and their generalization capabilities when optimized using (stochastic) gradient descent algorithms. \nInstead of concentrating solely on the generalization error of the DNN post-training, we present a novel perspective for analyzing generalization error by investigating the contribution of each update step to the change in generalization error. This perspective enable a more direct comprehension of how the learning trajectory influences generalization error. Building upon this analysis, we propose a new generalization bound that incorporates more extensive trajectory information.\nOur proposed generalization bound depends on the complexity of learning trajectory and the ratio between the bias and diversity of training set. Experimental observations reveal that our method effectively captures the generalization error throughout the training process. Furthermore, our approach can also track changes in generalization error when adjustments are made to learning rates and label noise levels. These results demonstrate that learning trajectory information is a valuable indicator of a model's generalization capabilities.""}",https://openreview.net{'value': '/pdf/c18735668816af591e544a715af607d485139e38.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=YJDz4F2AZu,{'value': 'ContiFormer: Continuous-Time Transformer for Irregular Time Series Modeling'},Yuqi Chen; Kan Ren; Yansen Wang; Yuchen Fang; Weiwei Sun; Dongsheng Li,~Yuqi_Chen3; ~Kan_Ren1; ~Yansen_Wang2; ~Yuchen_Fang2; ~Weiwei_Sun5; ~Dongsheng_Li2,"{'value': ['Irregular Time Series Modeling', 'Transformer', 'Neural Ordinary Differential Equation']}","{'value': 'Modeling continuous-time dynamics on irregular time series is critical to account for data evolution and correlations that occur continuously. Traditional methods including recurrent neural networks or Transformer models leverage inductive bias via powerful neural architectures to capture complex patterns. However, due to their discrete characteristic, they have limitations in generalizing to continuous-time data paradigms. Though neural ordinary differential equations (Neural ODEs) and their variants have shown promising results in dealing with irregular time series, they often fail to capture the intricate correlations within these sequences. It is challenging yet demanding to concurrently model the relationship between input data points and capture the dynamic changes of the continuous-time system. To tackle this problem, we propose ContiFormer that extends the relation modeling of vanilla Transformer to the continuous-time domain, which explicitly incorporates the modeling abilities of continuous dynamics of Neural ODEs with the attention mechanism of Transformers. We mathematically characterize the expressive power of ContiFormer and illustrate that, by curated designs of function hypothesis, many Transformer variants specialized in irregular time series modeling can be covered as a special case of ContiFormer. A wide range of experiments on both synthetic and real-world datasets have illustrated the superior modeling capacities and prediction performance of ContiFormer on irregular time series data. The project link is https://seqml.github.io/contiformer/.'}",https://openreview.net{'value': '/pdf/fe18bfa4acae35a845e410366586d3a6a106c47c.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=YI4bn6aAmz,{'value': 'Conformal Prediction Sets for Ordinal Classification'},PRASENJIT DEY; Srujana Merugu; Sivaramakrishnan R Kaveri,~PRASENJIT_DEY2; ~Srujana_Merugu2; ~Sivaramakrishnan_R_Kaveri1,"{'value': ['Ordinal Classification', 'Conformal Predictions', 'Unimodal modelling']}","{'value': 'Ordinal classification (OC), i.e., labeling instances along classes with a natural ordering, is common in multiple  applications such as size or budget based recommendations and disease severity labeling.  Often in practical scenarios, it is desirable to obtain a small set of likely classes with a guaranteed high chance of including the true class. Recent works on conformal prediction (CP) address this problem for the classification setting with non-ordered labels but the resulting prediction sets (PS) are often non-contiguous and unsuitable for ordinal classification. In this work, we propose a framework to adapt existing CP methods to generate contiguous sets with guaranteed coverage and minimal cardinality. Our framework employs a novel non-parametric approach for modeling unimodal distributions. Empirical results on both synthetic and real-world datasets demonstrate our method outperforms SOTA baselines by 4% on Accuracy@K and 8% on PS size.'}",https://openreview.net{'value': '/pdf/57fe7082babb8a450e693ea48fc6eaa1a4110837.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Y3NjoeO4Q1,{'value': 'Detection Based Part-level Articulated Object Reconstruction from Single RGBD Image'},Yuki Kawana; Tatsuya Harada,~Yuki_Kawana1; ~Tatsuya_Harada1,"{'value': ['articulated objects', 'shape reconstruction', '3D reconstruction']}","{'value': 'We propose an end-to-end trainable, cross-category method for reconstructing multiple man-made articulated objects from a single RGBD image, focusing on part-level shape reconstruction and pose and kinematics estimation. We depart from previous works that rely on learning instance-level latent space, focusing on man-made articulated objects with predefined part counts. Instead, we propose a novel alternative approach that employs part-level representation, representing instances as combinations of detected parts. While our detect-then-group approach effectively handles instances with diverse part structures and various part counts, it faces issues of false positives, varying part sizes and scales, and an increasing model size due to end-to-end training. To address these challenges, we propose 1) test-time kinematics-aware part fusion to improve detection performance while suppressing false positives, 2) anisotropic scale normalization for part shape learning to accommodate various part sizes and scales, and 3) a balancing strategy for cross-refinement between feature space and output space to improve part detection while maintaining model size. Evaluation on both synthetic and real data demonstrates that our method successfully reconstructs variously structured multiple instances that previous works cannot handle, and outperforms prior works in shape reconstruction and kinematics estimation.'}",https://openreview.net{'value': '/pdf/81ad94af1047adb7a6509e4e95bd2ecf06249ae3.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Xyj46OxEhK,"{'value': 'Look Ma, No Hands! Agent-Environment Factorization of Egocentric Videos'}",Matthew Chang; Aditya Prakash; Saurabh Gupta,~Matthew_Chang1; ~Aditya_Prakash1; ~Saurabh_Gupta1,"{'value': ['Inpainting', 'Diffusion', 'Robot Learning', 'Egocentric Vision']}","{'value': 'The analysis and use of egocentric videos for robotics tasks is made challenging by occlusion and the visual mismatch between the human hand and a robot end-effector. Past work views the human hand as a nuisance and removes it from the scene. However, the hand also provides a valuable signal for learning. In this work, we propose to extract a factored representation of the scene that separates the agent (human hand) and the environment. This alleviates both occlusion and mismatch while preserving the signal, thereby easing the design of models for downstream robotics tasks. At the heart of this factorization is our proposed Video Inpainting via Diffusion Model (VIDM) that leverages both a prior on real-world images (through a large-scale pre-trained diffusion model) and the appearance of the object in earlier frames of the video (through attention). Our experiments demonstrate the effectiveness of VIDM at improving the in-painting quality in egocentric videos and the power of our factored representation for numerous tasks: object detection, 3D reconstruction of manipulated objects, and learning of reward functions, policies, and affordances from videos.'}",https://openreview.net{'value': '/pdf/dfbd322d9bc20b8b81201fc51ee34ff3b0a1983d.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=XvfEYqEbIb,{'value': 'Non-Rigid Shape Registration via Deep Functional Maps Prior'},Puhua Jiang; Mingze Sun; Ruqi Huang,~Puhua_Jiang1; ~Mingze_Sun1; ~Ruqi_Huang1,{'value': ['shape registration; functional maps; unsupervised learning']},"{'value': 'In this paper, we propose a learning-based framework for non-rigid shape registra- tion without correspondence supervision. Traditional shape registration techniques typically rely on correspondences induced by extrinsic proximity, therefore can fail in the presence of large intrinsic deformations. Spectral mapping methods overcome this challenge by embedding shapes into, geometric or learned, high- dimensional spaces, where shapes are easier to align. However, due to the dependency on abstract, non-linear embedding schemes, the latter can be vulnerable with respect to perturbed or alien input. In light of this, our framework takes the best of both worlds. Namely, we deform source mesh towards the target point cloud, guided by correspondences induced by high-dimensional embeddings learned from deep functional maps (DFM). In particular, the correspondences are dynamically updated according to the intermediate registrations and filtered by consistency prior, which prominently robustify the overall pipeline. Moreover, in order to alleviate the requirement of extrinsically aligned input, we train an orientation regressor on a set of aligned synthetic shapes independent of the training shapes for DFM. Empirical results show that, with as few as dozens of training shapes of limited variability, our pipeline achieves state-of-the-art results on several benchmarks of non-rigid point cloud matching, but also delivers high-quality correspondences between unseen challenging shape pairs that undergo both significant extrinsic and intrinsic defor- mations, in which case neither traditional registration methods nor intrinsic methods work. The code is available at https://github.com/rqhuang88/DFR.'}",https://openreview.net{'value': '/pdf/a52f06f15ffe15bcd6eaa9c1cda4f8eb847d5045.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=XkcufOcgUc,{'value': 'Structure-free Graph Condensation: From Large-scale Graphs to Condensed Graph-free Data'},Xin Zheng; Miao Zhang; Chunyang Chen; Quoc Viet Hung Nguyen; Xingquan Zhu; Shirui Pan,~Xin_Zheng4; ~Miao_Zhang4; ~Chunyang_Chen1; ~Quoc_Viet_Hung_Nguyen1; ~Xingquan_Zhu1; ~Shirui_Pan1,"{'value': ['graph neural networks (GNNs)', 'graph condensation', 'training trajectory meta-matching', 'graph neural feature score']}","{'value': 'Graph condensation, which reduces the size of a large-scale graph by synthesizing a small-scale condensed graph as its substitution, has immediate benefits for various graph learning tasks.\nHowever, existing graph condensation methods rely on the joint optimization of nodes and structures in the condensed graph, and overlook critical issues in effectiveness and generalization ability.\nIn this paper, we advocate a new Structure-Free Graph Condensation paradigm, named SFGC, to distill a large-scale graph into a small-scale graph node set without explicit graph structures, i.e., graph-free data.\nOur idea is to implicitly encode topology structure information into the node attributes in the synthesized graph-free data, whose topology is reduced to an identity matrix.\nSpecifically, SFGC contains two collaborative components: \n(1) a training trajectory meta-matching scheme for effectively synthesizing small-scale graph-free data;\n(2) a graph neural feature score metric for dynamically evaluating the quality of the condensed data. \nThrough training trajectory meta-matching, SFGC aligns the long-term GNN learning behaviors between the large-scale graph and the condensed small-scale graph-free data, ensuring comprehensive and compact transfer of informative knowledge to the graph-free data.\nAfterward, the underlying condensed graph-free data would be dynamically evaluated with the graph neural feature score, which is a closed-form metric for ensuring the excellent expressiveness of the condensed graph-free data.\nExtensive experiments verify the superiority of SFGC across different condensation ratios.'}",https://openreview.net{'value': '/pdf/f6da01c95f03dc8397ee56522c3f9a3adcecebec.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=XeMryhpniy,{'value': 'Hierarchical Integration Diffusion Model for Realistic Image Deblurring'},Zheng Chen; Yulun Zhang; Ding Liu; Bin Xia; Jinjin Gu; Linghe Kong; Xin Yuan,~Zheng_Chen11; ~Yulun_Zhang1; ~Ding_Liu6; ~Bin_Xia1; ~Jinjin_Gu1; ~Linghe_Kong1; ~Xin_Yuan4,"{'value': ['image deblurring', 'diffusion model']}","{'value': 'Diffusion models (DMs) have recently been introduced in image deblurring and exhibited promising performance, particularly in terms of details reconstruction. However, the diffusion model requires a large number of inference iterations to recover the clean image from pure Gaussian noise, which consumes massive computational resources. Moreover, the distribution synthesized by the diffusion model is often misaligned with the target results, leading to restrictions in distortion-based metrics. To address the above issues, we propose the Hierarchical Integration Diffusion Model (HI-Diff), for realistic image deblurring. Specifically, we perform the DM in a highly compacted latent space to generate the prior feature for the deblurring process. The deblurring process is implemented by a regression-based method to obtain better distortion accuracy. Meanwhile, the highly compact latent space ensures the efficiency of the DM. Furthermore, we design the hierarchical integration module to fuse the prior into the regression-based model from multiple scales, enabling better generalization in complex blurry scenarios. Comprehensive experiments on synthetic and real-world blur datasets demonstrate that our HI-Diff outperforms state-of-the-art methods. Code and trained models are available at https://github.com/zhengchen1999/HI-Diff.'}",https://openreview.net{'value': '/pdf/1d52451a3690f62b18528eedcb064098ba8fd3ec.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=XY6BnwIh4q,{'value': 'Binary Radiance Fields'},Seungjoo Shin; Jaesik Park,~Seungjoo_Shin1; ~Jaesik_Park3,"{'value': ['neural radiance fields', 'inverse rendering', 'binarization']}","{'value': 'In this paper, we propose \\textit{binary radiance fields} (BiRF), a storage-efficient radiance field representation employing binary feature encoding in a format of either $+1$ or $-1$. This binarization strategy lets us represent the feature grid with highly compact feature encoding and a dramatic reduction in storage size. Furthermore, our 2D-3D hybrid feature grid design enhances the compactness of feature encoding as the 3D grid includes main components while 2D grids capture details. In our experiments, binary radiance field representation successfully outperforms the reconstruction performance of state-of-the-art (SOTA) storage-efficient radiance field models with lower storage allocation. In particular, our model achieves impressive results in static scene reconstruction, with a PSNR of 32.03 dB for Synthetic-NeRF scenes, 34.48 dB for Synthetic-NSVF scenes, 28.20 dB for Tanks and Temples scenes while only utilizing 0.5 MB of storage space, respectively. We hope the proposed binary radiance field representation will make radiance fields more accessible without a storage bottleneck.'}",https://openreview.net{'value': '/pdf/0e8f038e4a065d5b7d479a30a16c936d0ab4e106.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=XOotfgPiUF,{'value': 'FreeMask: Synthetic Images with Dense Annotations Make Stronger Segmentation Models'},Lihe Yang; Xiaogang Xu; Bingyi Kang; Yinghuan Shi; Hengshuang Zhao,~Lihe_Yang1; ~Xiaogang_Xu2; ~Bingyi_Kang1; ~Yinghuan_Shi3; ~Hengshuang_Zhao2,"{'value': ['learning from synthetic', 'semantic segmentation', 'generative models']}","{'value': 'Semantic segmentation has witnessed tremendous progress due to the proposal of various advanced network architectures. However, they are extremely hungry for delicate annotations to train, and the acquisition is laborious and unaffordable. Therefore, we present FreeMask in this work, which resorts to synthetic images from generative models to ease the burden of both data collection and annotation procedures. Concretely, we first synthesize abundant training images conditioned on the semantic masks provided by realistic datasets. This yields extra well-aligned image-mask training pairs for semantic segmentation models. We surprisingly observe that, solely trained with synthetic images, we already achieve comparable performance with real ones (e.g., 48.3 vs. 48.5 mIoU on ADE20K, and 49.3 vs. 50.5 on COCO-Stuff). Then, we investigate the role of synthetic images by joint training with real images, or pre-training for real images. Meantime, we design a robust filtering principle to suppress incorrectly synthesized regions. In addition, we propose to inequally treat different semantic masks to prioritize those harder ones and sample more corresponding synthetic images for them. As a result, either jointly trained or pre-trained with our filtered and re-sampled synthesized images, segmentation models can be greatly enhanced, e.g., from 48.7 to 52.0 on ADE20K.'}",https://openreview.net{'value': '/pdf/e998b8541cb359407a99e1843068433ee82e7c9b.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=XKP3mAsNHd,{'value': 'Incentives in Private Collaborative Machine Learning'},Rachael Hwee Ling Sim; Yehong Zhang; Trong Nghia Hoang; Xinyi Xu; Bryan Kian Hsiang Low; Patrick Jaillet,~Rachael_Hwee_Ling_Sim1; ~Yehong_Zhang1; ~Trong_Nghia_Hoang1; ~Xinyi_Xu4; ~Bryan_Kian_Hsiang_Low1; ~Patrick_Jaillet1,"{'value': ['Incentives', 'Privacy', 'Shapley fairness', 'Collaborative machine learning', 'data valuation', 'reward', 'sufficient statistics']}","{'value': ""Collaborative machine learning involves training models on data from multiple parties but must incentivize their participation. Existing data valuation methods fairly value and reward each party based on  shared data or model parameters but neglect the privacy risks involved. To address this, we introduce _differential privacy_ (DP) as an incentive. Each party can select its required DP guarantee and perturb its _sufficient statistic_ (SS) accordingly. The mediator values the perturbed SS by the Bayesian surprise it elicits about the model parameters. As our valuation function enforces a _privacy-valuation trade-off_, parties are deterred from selecting excessive DP guarantees that reduce the utility of the grand coalition's model. Finally, the mediator rewards each party with different posterior samples of the model parameters. Such rewards still satisfy existing incentives like fairness but additionally preserve DP and a high similarity to the grand coalition's posterior. We empirically demonstrate the effectiveness and practicality of our approach on synthetic and real-world datasets.""}",https://openreview.net{'value': '/pdf/125a9b3f42b509b38cb26ba67d744bc69f26c4fd.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=WpuBEtrn0t,{'value': 'Regularizing Neural Networks with Meta-Learning Generative Models'},Shin'ya Yamaguchi; Daiki Chijiwa; Sekitoshi Kanai; Atsutoshi Kumagai; Hisashi Kashima,~Shin'ya_Yamaguchi1; ~Daiki_Chijiwa1; ~Sekitoshi_Kanai1; ~Atsutoshi_Kumagai2; ~Hisashi_Kashima2,"{'value': ['Deep Learning', 'Generative Models', 'Generative Data Augmentation', 'Regularization', 'Meta-Learning']}","{'value': 'This paper investigates methods for improving generative data augmentation for deep learning. Generative data augmentation leverages the synthetic samples produced by generative models as an additional dataset for classification with small dataset settings. A key challenge of generative data augmentation is that the synthetic data contain uninformative samples that degrade accuracy. This can be caused by the synthetic samples not perfectly representing class categories in real data and uniform sampling not necessarily providing useful samples for tasks. In this paper, we present a novel strategy for generative data augmentation called *meta generative regularization* (MGR). To avoid the degradation of generative data augmentation, MGR utilizes synthetic samples for regularizing feature extractors instead of training classifiers. These synthetic samples are dynamically determined to minimize the validation losses through meta-learning. We observed that MGR can avoid the performance degradation of naive generative data augmentation and boost the baselines. Experiments on six datasets showed that MGR is effective particularly when datasets are smaller and stably outperforms baselines by up to 7 percentage points on test accuracy.'}",https://openreview.net{'value': '/pdf/6f0cc01078ca963219a1869cdeb941e8db41d98f.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Wa1GGPqjUn,{'value': 'Online learning of long-range dependencies'},Nicolas Zucchet; Robert Meier; Simon Schug; Asier Mujika; Joao Sacramento,~Nicolas_Zucchet1; ~Robert_Meier2; ~Simon_Schug1; ~Asier_Mujika1; ~Joao_Sacramento1,"{'value': ['online learning', 'linear recurrent units', 'temporal credit assignment', 'biologically-plausible learning', 'local learning rules', 'neuromorphic computing']}","{'value': 'Online learning holds the promise of enabling efficient long-term credit assignment in recurrent neural networks. However, current algorithms fall short of offline backpropagation by either not being scalable or failing to learn long-range dependencies. Here we present a high-performance online learning algorithm that merely doubles the memory and computational requirements of a single inference pass. We achieve this by leveraging independent recurrent modules in multi-layer networks, an architectural motif that has recently been shown to be particularly powerful. Experiments on synthetic memory problems and on the challenging long-range arena benchmark suite reveal that our algorithm performs competitively, establishing a new standard for what can be achieved through online learning. This ability to learn long-range dependencies offers a new perspective on learning in the brain and opens a promising avenue in neuromorphic computing.'}",https://openreview.net{'value': '/pdf/a8cc88641c3c91171e5c4a6a853f4305e07a3c46.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=W3cDd5xlKZ,{'value': 'Fair Canonical Correlation Analysis'},Zhuoping Zhou; Davoud Ataee Tarzanagh; Bojian Hou; Boning Tong; Jia Xu; Yanbo Feng; Qi Long; Li Shen,~Zhuoping_Zhou1; ~Davoud_Ataee_Tarzanagh1; ~Bojian_Hou1; ~Boning_Tong1; jiaxu7@upenn.edu; yanbof@seas.upenn.edu; ~Qi_Long1; ~Li_Shen2,"{'value': ['Fairness', 'Canonical Correlation Analysis', 'Riemannian Optimization', 'Pareto Optimization']}","{'value': 'This paper investigates fairness and bias in Canonical Correlation Analysis (CCA), a widely used statistical technique for examining the relationship between two sets of variables. We present a framework that alleviates unfairness by minimizing the correlation disparity error associated with protected attributes. Our approach enables CCA to learn global projection matrices from all data points while ensuring that these matrices yield comparable correlation levels to group-specific projection matrices. Experimental evaluation on both synthetic and real-world datasets demonstrates the efficacy of our method in reducing correlation disparity error without compromising CCA accuracy.'}",https://openreview.net{'value': '/pdf/d4928dbba190e55cccd00f10a2cce6b1f899382a.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=VzmpXQAn6E,{'value': 'Exposing Attention Glitches with Flip-Flop Language Modeling'},Bingbin Liu; Jordan T. Ash; Surbhi Goel; Akshay Krishnamurthy; Cyril Zhang,~Bingbin_Liu1; ~Jordan_T._Ash1; ~Surbhi_Goel1; ~Akshay_Krishnamurthy1; ~Cyril_Zhang1,"{'value': ['Transformers', 'language models', 'hallucinations', 'long-range dependencies', 'generalization', 'extrapolation', 'out-of-distribution']}","{'value': ""Why do large language models sometimes output factual inaccuracies and exhibit erroneous reasoning? The brittleness of these models, particularly when executing long chains of reasoning, currently seems to be an inevitable price to pay for their advanced capabilities of coherently synthesizing knowledge, pragmatics, and abstract thought. Towards making sense of this fundamentally unsolved problem, this work identifies and analyzes the phenomenon of _attention glitches_, in which the Transformer architecture's inductive biases intermittently fail to capture robust reasoning. To isolate the issue, we introduce _flip-flop language modeling_ (FFLM), a parametric family of synthetic benchmarks designed to probe the extrapolative behavior of neural language models. This simple generative task requires a model to copy binary symbols over long-range dependencies, ignoring the tokens in between. We find that Transformer FFLMs suffer from a long tail of sporadic reasoning errors, some of which we can eliminate using various regularization techniques. Our preliminary mechanistic analyses show why the remaining errors may be very difficult to diagnose and resolve. We hypothesize that attention glitches account for (some of) the closed-domain hallucinations in natural LLMs.""}",https://openreview.net{'value': '/pdf/bd4083f62211869859faf48516b49ffdca0ef705.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=VqIWgUVsXc,{'value': 'Does Graph Distillation See Like Vision Dataset Counterpart?'},Beining Yang; Kai Wang; Qingyun Sun; Cheng Ji; Xingcheng Fu; Hao Tang; Yang You; Jianxin Li,~Beining_Yang1; ~Kai_Wang8; ~Qingyun_Sun2; ~Cheng_Ji1; ~Xingcheng_Fu1; ~Hao_Tang6; ~Yang_You1; ~Jianxin_Li3,"{'value': ['data-efficient learning', 'graph generation', 'graph neural networks']}","{'value': 'Training on large-scale graphs has achieved remarkable results in graph representation learning, but its cost and storage have attracted increasing concerns. Existing graph condensation methods primarily focus on optimizing the feature matrices of condensed graphs while overlooking the impact of the structure information from the original graphs. To investigate the impact of the structure information, we conduct analysis from the spectral domain and empirically identify substantial Laplacian Energy Distribution (LED) shifts in previous works. Such shifts lead to poor performance in cross-architecture generalization and specific tasks, including anomaly detection and link prediction. In this paper, we propose a novel Structure-broadcasting Graph Dataset Distillation (\\textbf{SGDD}) scheme for broadcasting the original structure information to the generation of the synthetic one, which explicitly prevents overlooking the original structure information. \nTheoretically, the synthetic graphs by SGDD are expected to have smaller LED shifts than previous works, leading to superior performance in both cross-architecture settings and specific tasks.\nWe validate the proposed SGDD~across 9 datasets and achieve state-of-the-art results on all of them: for example, on YelpChi dataset, our approach maintains 98.6\\% test accuracy of training on the original graph dataset with 1,000 times saving on the scale of the graph. Moreover, we empirically evaluate there exist 17.6\\% $\\sim$ 31.4\\% reductions in LED shift crossing 9 datasets. Extensive experiments and analysis verify the effectiveness and necessity of the proposed designs. The code will be made public.'}",https://openreview.net{'value': '/pdf/8127382dda9da8f4c6b69155794f6f310d8e0412.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Vm1zeYqwdc,{'value': 'Diffusion Hyperfeatures: Searching Through Time and Space for Semantic Correspondence'},Grace Luo; Lisa Dunlap; Dong Huk Park; Aleksander Holynski; Trevor Darrell,~Grace_Luo1; ~Lisa_Dunlap1; ~Dong_Huk_Park2; ~Aleksander_Holynski1; ~Trevor_Darrell2,"{'value': ['semantic correspondence', 'hypercolumns', 'diffusion models', 'generative model representations']}","{'value': ""Diffusion models have been shown to be capable of generating high-quality images, suggesting that they could contain meaningful internal representations. Unfortunately, the feature maps that encode a diffusion model's internal information are spread not only over layers of the network, but also over diffusion timesteps, making it challenging to extract useful descriptors. We propose Diffusion Hyperfeatures, a framework for consolidating  multi-scale and multi-timestep feature maps into per-pixel feature descriptors that can be used for downstream tasks. These descriptors can be extracted for both synthetic and real images using the generation and inversion processes. We evaluate the utility of our Diffusion Hyperfeatures on the task of semantic keypoint correspondence: our method achieves superior performance on the SPair-71k real image benchmark. We also demonstrate that our method is flexible and transferable: our feature aggregation network trained on the inversion features of real image pairs can be used on the generation features of synthetic image pairs with unseen objects and compositions. Our code is available at https://diffusion-hyperfeatures.github.io.""}",https://openreview.net{'value': '/pdf/47eabcfd6dbd11b1486f03442741bd4bd6438c2d.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Vfp8sDST4g,{'value': 'Learning Large-Scale MTP$_2$ Gaussian Graphical Models via Bridge-Block Decomposition'},Xiwen Wang; Jiaxi Ying; Daniel P. Palomar,~Xiwen_Wang2; ~Jiaxi_Ying1; ~Daniel_P._Palomar1,"{'value': ['MTP2 Gaussian Graphical Model', 'High-dimensional precision matrix estimation', 'Bridge-block decomposition.']}","{'value': 'This paper studies the problem of learning the large-scale Gaussian graphical models that are multivariate totally positive of order two ($\\text{MTP}_2$). By introducing the concept of bridge, which commonly exists in large-scale sparse graphs, we show that the entire problem can be equivalently optimized through (1) several smaller-scaled sub-problems induced by a \\emph{bridge-block decomposition} on the thresholded sample covariance graph and (2) a set of explicit solutions on entries corresponding to  \\emph{bridges}. From practical aspect, this simple and provable discipline can be applied to break down a large problem into small tractable ones, leading to enormous reduction on the computational complexity and substantial improvements for all existing algorithms.  The synthetic and real-world experiments demonstrate that our proposed method presents a significant speed-up compared to the state-of-the-art benchmarks.'}",https://openreview.net{'value': '/pdf/3fcc157dd4195591101ebad0dfee494009ae0e28.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=VeO03T59Sh,{'value': 'Conformal Prediction for Uncertainty-Aware Planning with Diffusion Dynamics Model'},Jiankai Sun; Yiqi Jiang; Jianing Qiu; Parth Talpur Nobel; Mykel Kochenderfer; Mac Schwager,~Jiankai_Sun6; ~Yiqi_Jiang2; ~Jianing_Qiu1; ~Parth_Talpur_Nobel1; ~Mykel_Kochenderfer1; ~Mac_Schwager1,"{'value': ['Uncertainty', 'Conformal Prediction', 'Dynamics Model']}","{'value': 'Robotic applications often involve working in environments that are uncertain, dynamic, and partially observable. Recently, diffusion models have been proposed for learning trajectory prediction models trained from expert demonstrations, which can be used for planning in robot tasks. Such models have demonstrated a strong ability to overcome challenges such as multi-modal action distributions, high-dimensional output spaces, and training instability. It is crucial to quantify the uncertainty of these dynamics models when using them for planning. In this paper, we quantify the uncertainty of diffusion dynamics models using Conformal Prediction (CP). Given a finite number of exchangeable expert trajectory examples (called the “calibration set”), we use CP to obtain a set in the trajectory space (called the “coverage region”) that is guaranteed to contain the output of the diffusion model with a user-defined probability (called the “coverage level”). In PlanCP, inspired by concepts from conformal prediction, we modify the loss function for training the diffusion model to include a quantile term to encourage more robust performance across the variety of training examples. At test time, we then calibrate PlanCP with a conformal prediction process to obtain coverage sets for the trajectory prediction with guaranteed coverage level. We evaluate our algorithm on various planning tasks and model-based offline reinforcement learning tasks and show that it reduces the uncertainty of the learned trajectory prediction model. As a by-product, our algorithm PlanCP outperforms prior algorithms on existing offline RL benchmarks and challenging continuous planning tasks. Our method can be combined with most model-based planning approaches to produce uncertainty estimates of the closed-loop system.'}",https://openreview.net{'value': '/pdf/8fde541eed2bb30f6071042844bbb417203468c0.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=VUvLSnMZdX,{'value': 'Score-based Data Assimilation'},François Rozet; Gilles Louppe,~François_Rozet1; ~Gilles_Louppe1,"{'value': ['data assimilation', 'score-based', 'generative modeling', 'posterior inference', 'dynamical systems']}","{'value': 'Data assimilation, in its most comprehensive form, addresses the Bayesian inverse problem of identifying plausible state trajectories that explain noisy or incomplete observations of stochastic dynamical systems. Various approaches have been proposed to solve this problem, including particle-based and variational methods. However, most algorithms depend on the transition dynamics for inference, which becomes intractable for long time horizons or for high-dimensional systems with complex dynamics, such as oceans or atmospheres. In this work, we introduce score-based data assimilation for trajectory inference. We learn a score-based generative model of state trajectories based on the key insight that the score of an arbitrarily long trajectory can be decomposed into a series of scores over short segments. After training, inference is carried out using the score model, in a non-autoregressive manner by generating all states simultaneously. Quite distinctively, we decouple the observation model from the training procedure and use it only at inference to guide the generative process, which enables a wide range of zero-shot observation scenarios. We present theoretical and empirical evidence supporting the effectiveness of our method.'}",https://openreview.net{'value': '/pdf/d119d8c1bf5d8bd8c81399e4c28aa27fd58a9e0a.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=VPTZVVP4tm,{'value': 'LogSpecT: Feasible Graph Learning Model from Stationary Signals with Recovery Guarantees'},Shangyuan Liu; Linglingzhi Zhu; Anthony Man-Cho So,~Shangyuan_Liu2; ~Linglingzhi_Zhu1; ~Anthony_Man-Cho_So1,"{'value': ['Graph Signal Processing', 'Spectral Template', 'Network Inference', 'Optimization', 'Linearized ADMM']}","{'value': 'Graph learning from signals is a core task in graph signal processing (GSP). A significant subclass of graph signals called the stationary graph signals that broadens the concept of stationarity of data defined on regular domains to signals on graphs is gaining increasing popularity in the GSP community. The most commonly used model to learn graphs from these stationary signals is SpecT, which forms the foundation for nearly all the subsequent, more advanced models. Despite its strengths, the practical formulation of the model, known as rSpecT, has been identified to be susceptible to the choice of hyperparameters. More critically, it may suffer from infeasibility as an optimization problem. In this paper, we introduce the first condition that ensures the infeasibility of rSpecT and design a novel model called LogSpecT, along with its practical formulation rLogSpecT to overcome this issue. Contrary to rSpecT, our novel practical model rLogSpecT is always feasible. Furthermore, we provide recovery guarantees of rLogSpecT from modern optimization tools related to epi-convergence, which could be of independent interest and significant for various learning problems. To demonstrate the practical advantages of rLogSpecT, a highly efficient algorithm based on the linearized alternating direction method of multipliers (L-ADMM) that allows closed-form solutions for each subproblem is proposed with convergence guarantees. Extensive numerical results on both synthetic and real networks not only corroborate the stability of our proposed methods, but also highlight their comparable and even superior performance than existing models.'}",https://openreview.net{'value': '/pdf/926a038eb95443ae671a032c5b3a78a4ddf67138.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=VGLXjbTSYa,{'value': 'Delegated Classification'},Eden Saig; Inbal Talgam-Cohen; Nir Rosenfeld,~Eden_Saig1; ~Inbal_Talgam-Cohen2; ~Nir_Rosenfeld2,"{'value': ['Delegation', 'Algorithmic Contract Design', 'Moral Hazard', 'Learning Curves']}","{'value': 'When machine learning is outsourced to a rational agent, conflicts of interest might arise and severely impact predictive performance. In this work, we propose a theoretical framework for incentive-aware delegation of machine learning tasks. We model delegation as a principal-agent game, in which accurate learning can be incentivized by the principal using performance-based contracts. Adapting the economic theory of contract design to this setting, we define budget-optimal contracts and prove they take a simple threshold form under reasonable assumptions. In the binary-action case, the optimality of such contracts is shown to be equivalent to the classic Neyman-Pearson lemma, establishing a formal connection between contract design and statistical hypothesis testing. Empirically, we demonstrate that budget-optimal contracts can be constructed using small-scale data, leveraging recent advances in the study of learning curves and scaling laws. Performance and economic outcomes are evaluated using synthetic and real-world classification tasks.'}",https://openreview.net{'value': '/pdf/466943f3ab05629a518eb23d46289938a5ccc034.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=VCOZaczCHg,{'value': 'Mixed-Initiative Multiagent Apprenticeship Learning for Human Training of Robot Teams'},Esmaeil Seraj; Jerry Yuyang Xiong; Mariah L Schrum; Matthew Gombolay,~Esmaeil_Seraj1; ~Jerry_Yuyang_Xiong1; ~Mariah_L_Schrum1; ~Matthew_Gombolay1,"{'value': ['Learning from Demonstration', 'Multi-Robot Systems', 'Teaching Robot Teams']}","{'value': ""Extending recent advances in Learning from Demonstration (LfD) frameworks to multi-robot settings poses critical challenges such as environment non-stationarity due to partial observability which is detrimental to the applicability of existing methods. Although prior work has shown that enabling communication among agents of a robot team can alleviate such issues, creating inter-agent communication under existing Multi-Agent LfD (MA-LfD) frameworks requires the human expert to provide demonstrations for both environment actions and communication actions, which necessitates an efficient communication strategy on a known message spaces. To address this problem, we propose Mixed-Initiative Multi-Agent Apprenticeship Learning (MixTURE). MixTURE enables robot teams to learn from a human expert-generated data a preferred policy to accomplish a collaborative task, while simultaneously learning emergent inter-agent communication to enhance team coordination. The key ingredient to MixTURE's success is automatically learning a communication policy, enhanced by a mutual-information maximizing reverse model that rationalizes the underlying expert demonstrations without the need for human generated data or an auxiliary reward function. MixTURE outperforms a variety of relevant baselines on diverse data generated by human experts in complex heterogeneous domains. MixTURE is the first MA-LfD framework to enable learning multi-robot collaborative policies directly from real human data, resulting in ~44% less human workload, and ~46% higher usability score.""}",https://openreview.net{'value': '/pdf/fe81cd3ddf306f231f510fc993d7267ed064c6d6.pdf'},{'abstract_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=V5Oh7Aqfft,{'value': 'Causal Effect Regularization: Automated Detection and Removal of Spurious Correlations'},Abhinav Kumar; Amit Deshpande; Amit Sharma,~Abhinav_Kumar3; ~Amit_Deshpande1; ~Amit_Sharma3,"{'value': ['Spurious Correlation', 'Out of Distribution Generalization']}","{'value': 'In many classification datasets, the task labels are spuriously correlated with some input attributes. Classifiers trained on such datasets often rely on these attributes for prediction, especially when the spurious correlation is high, and thus fail to\ngeneralize whenever there is a shift in the attributes’ correlation at deployment. If we assume that the spurious attributes are known a priori, several methods have been proposed to learn a classifier that is invariant to the specified attributes. However, in real-world data, information about spurious attributes is typically unavailable. Therefore, we propose a method that automatically identifies spurious attributes by estimating their causal effect on the label and then uses a regularization objective to mitigate the classifier’s reliance on them. Although causal effect of an attribute on the label is not always identified, we present two commonly occurring data-generating processes where the effect can be identified. Compared to recent work for identifying spurious attributes, we find that our method, AutoACER, is\nmore accurate in removing the attribute from the learned model, especially when spurious correlation is high. Specifically, across synthetic, semi-synthetic, and real-world datasets, AutoACER shows significant improvement in a metric used to quantify the dependence of a classifier on spurious attributes ($\\Delta$Prob), while obtaining better or similar accuracy. Empirically we find that AutoACER mitigates\nthe reliance on spurious attributes even under noisy estimation of causal effects or when the causal effect is not identified. To explain the empirical robustness of our method, we create a simple linear classification task with two sets of attributes: causal and spurious. Under this setting, we prove that AutoACER only requires the ranking of estimated causal effects to be correct across attributes to select the\ncorrect classifier.'}",https://openreview.net{'value': '/pdf/24b8264af0069dc005b075c13f4f58bd9d197229.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=UuNd9A6noD,{'value': 'Bayesian Optimisation of Functions on Graphs'},Xingchen Wan; Pierre Osselin; Henry Kenlay; Binxin Ru; Michael A Osborne; Xiaowen Dong,~Xingchen_Wan1; ~Pierre_Osselin1; ~Henry_Kenlay1; ~Binxin_Ru1; ~Michael_A_Osborne1; ~Xiaowen_Dong1,"{'value': ['graphs', 'Bayesian optimisation', 'scalability']}","{'value': 'The increasing availability of graph-structured data motivates the task of optimising over functions defined on the node set of graphs. Traditional graph search algorithms can be applied in this case, but they may be sample-inefficient and do not make use of information about the function values; on the other hand, Bayesian optimisation is a class of promising black-box solvers with superior sample efficiency, but it has scarcely been applied to such novel setups. To fill this gap, we propose a novel Bayesian optimisation framework that optimises over functions defined on generic, large-scale and potentially unknown graphs. Through the learning of suitable kernels on graphs, our framework has the advantage of adapting to the behaviour of the target function. The local modelling approach further guarantees the efficiency of our method. Extensive experiments on both synthetic and real-world graphs demonstrate the effectiveness of the proposed optimisation framework.'}",https://openreview.net{'value': '/pdf/e46daf80dbfc5912d04a38bb3c3cf240c3b4053c.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=UkPeUXML7s,{'value': 'Approximate Heavy Tails in Offline (Multi-Pass) Stochastic Gradient Descent'},Krunoslav Lehman Pavasovic; Alain Durmus; Umut Simsekli,~Krunoslav_Lehman_Pavasovic1; ~Alain_Durmus1; ~Umut_Simsekli1,"{'value': ['SGD', 'heavy-tails', 'wasserstein convergence']}","{'value': 'A recent line of empirical studies has demonstrated that SGD might exhibit a heavy-tailed behavior in practical settings, and the heaviness of the tails might correlate with the overall performance. In this paper, we investigate the emergence of such heavy tails. Previous works on this problem only considered, up to our knowledge, online (also called single-pass) SGD, in which the emergence of heavy tails in theoretical findings is contingent upon access to an infinite amount of data. Hence, the underlying mechanism generating the reported heavy-tailed behavior in practical settings, where the amount of training data is finite, is still not well-understood. Our contribution aims to fill this gap. In particular, we show that the stationary distribution of offline (also called multi-pass) SGD exhibits ‘approximate’ power-law tails and the approximation error is controlled by how fast the empirical distribution of the training data converges to the true underlying data distribution in the Wasserstein metric. Our main takeaway is that, as the number of data points increases, offline SGD will behave increasingly ‘power-law-like’. To achieve this result, we first prove nonasymptotic Wasserstein convergence bounds for offline SGD to online SGD as the number of data points increases, which can be interesting on their own. Finally, we illustrate our theory on various experiments conducted on synthetic data and neural networks.'}",https://openreview.net{'value': '/pdf/3540a930f63eb69ed07f357f2f8c704997560b67.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=UgomCjCWjC,{'value': 'Multi-Agent First Order Constrained Optimization in Policy Space'},Youpeng Zhao; Yaodong Yang; Zhenbo Lu; Wengang Zhou; Houqiang Li,~Youpeng_Zhao1; ~Yaodong_Yang1; ~Zhenbo_Lu1; ~Wengang_Zhou1; ~Houqiang_Li1,"{'value': ['Safe Multi-agent Reinforcement Learning', 'constrained policy optimisation', 'first-order optimisation']}","{'value': 'In the realm of multi-agent reinforcement learning (MARL), achieving high performance is crucial for a successful multi-agent system.\nMeanwhile, the ability to avoid unsafe actions is becoming an urgent and imperative problem to solve for real-life applications. \nWhereas, it is still challenging to develop a safety-aware method for multi-agent systems in MARL. In this work, we introduce a novel approach called Multi-Agent First Order Constrained Optimization in Policy Space (MAFOCOPS), which effectively addresses the dual objectives of attaining satisfactory performance and enforcing safety constraints. Using data generated from the current policy, MAFOCOPS first finds the optimal update policy by solving a constrained optimization problem in the nonparameterized policy space. Then, the update policy is projected back into the parametric policy space to achieve a feasible policy. Notably, our method is first-order in nature, ensuring the ease of implementation, and exhibits an approximate upper bound on the worst-case constraint violation. Empirical results show that our approach achieves remarkable performance while satisfying safe constraints on several safe MARL benchmarks.'}",https://openreview.net{'value': '/pdf/94a6431b78ae792577d82bc0413118e12ba8e8b8.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=UXtLrsG4Rf,{'value': 'Intensity Profile Projection: A Framework for Continuous-Time Representation Learning for Dynamic Networks'},Alexander Modell; Ian Gallagher; Emma Ceccherini; Nick Whiteley; Patrick Rubin-Delanchy,~Alexander_Modell1; ~Ian_Gallagher1; gs22311@bristol.ac.uk; ~Nick_Whiteley1; ~Patrick_Rubin-Delanchy1,"{'value': ['dynamic networks', 'representation learning', 'spectral methods']}","{'value': ""We present a new representation learning framework, Intensity Profile Projection, for continuous-time dynamic network data. Given triples $(i,j,t)$, each representing a time-stamped ($t$) interaction between two entities ($i,j$), our procedure returns a continuous-time trajectory for each node, representing its behaviour over time. The framework consists of three stages: estimating pairwise intensity functions, e.g. via kernel smoothing; learning a projection which minimises a notion of intensity reconstruction error; and constructing evolving node representations via the learned projection. The trajectories satisfy two properties, known as structural and temporal coherence, which we see as fundamental for reliable inference. Moreoever, we develop estimation theory providing tight control on the error of any estimated trajectory, indicating that the representations could even be used in quite noise-sensitive follow-on analyses. The theory also elucidates the role of smoothing as a bias-variance trade-off, and shows how we can reduce the level of smoothing as the signal-to-noise ratio increases on account of the algorithm `borrowing strength' across the network.""}",https://openreview.net{'value': '/pdf/cfbf82fa96af353477fea49bf631af76a8cf3181.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=UWd4ysACo4,{'value': 'Expressive Sign Equivariant Networks for Spectral Geometric Learning'},Derek Lim; Joshua Robinson; Stefanie Jegelka; Haggai Maron,~Derek_Lim1; ~Joshua_Robinson4; ~Stefanie_Jegelka3; ~Haggai_Maron1,"{'value': ['Eigenvectors', 'spectral', 'geometry', 'universal approximation', 'graph', 'equivariance', 'invariance']}","{'value': 'Recent work has shown the utility of developing machine learning models that respect the structure and symmetries of eigenvectors. These works promote sign invariance, since for any eigenvector v the negation -v is also an eigenvector. However, we show that sign invariance is theoretically limited for tasks such as building orthogonally equivariant models and learning node positional encodings for link prediction in graphs. In this work, we demonstrate the benefits of sign equivariance for these tasks. To obtain these benefits, we develop novel sign equivariant neural network architectures. Our models are based on a new analytic characterization of sign equivariant polynomials and thus inherit provable expressiveness properties. Controlled synthetic experiments show that our networks can achieve the theoretically predicted benefits of sign equivariant models.'}",https://openreview.net{'value': '/pdf/3fa1f5e01c5cdea046b4fc7b41e55134c431c116.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=UHIDdtxmVS,"{'value': ""Asynchrony-Robust Collaborative Perception via Bird's Eye View Flow""}",Sizhe Wei; Yuxi Wei; Yue Hu; Yifan Lu; Yiqi Zhong; Siheng Chen; Ya Zhang,~Sizhe_Wei1; ~Yuxi_Wei1; ~Yue_Hu1; ~Yifan_Lu1; ~Yiqi_Zhong1; ~Siheng_Chen1; ~Ya_Zhang1,{'value': ['Collaborative Perception; BEV Flow; Time Asynchronization']},"{'value': ""Collaborative perception can substantially boost each agent's perception ability by facilitating communication among multiple agents. However, temporal asynchrony among agents is inevitable in the real world due to communication delays, interruptions, and clock misalignments. This issue causes information mismatch during multi-agent fusion, seriously shaking the foundation of collaboration. To address this issue, we propose CoBEVFlow, an asynchrony-robust collaborative perception system based on bird's eye view (BEV) flow. The key intuition of CoBEVFlow is to compensate motions to align asynchronous collaboration messages sent by multiple agents. To model the motion in a scene, we propose BEV flow, which is a collection of the motion vector corresponding to each spatial location. Based on BEV flow, asynchronous perceptual features can be reassigned to appropriate positions, mitigating the impact of asynchrony. CoBEVFlow has two advantages: (i) CoBEVFlow can handle asynchronous collaboration messages sent at irregular, continuous time stamps without discretization; and (ii) with BEV flow, CoBEVFlow only transports the original perceptual features, instead of generating new perceptual features, avoiding additional noises. To validate CoBEVFlow's efficacy, we create IRregular V2V(IRV2V), the first synthetic collaborative perception dataset with various temporal asynchronies that simulate different real-world scenarios. Extensive experiments conducted on both IRV2V and the real-world dataset DAIR-V2X show that CoBEVFlow consistently outperforms other baselines and is robust in extremely asynchronous settings. The code is available at https://github.com/MediaBrain-SJTU/CoBEVFlow.""}",https://openreview.net{'value': '/pdf/b59550d53ef0dca7711cd08b70e87a874f07026d.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=UBBeUjTja8,{'value': 'Cross-modal Active Complementary Learning with Self-refining Correspondence'},Yang Qin; Yuan Sun; Dezhong Peng; Joey Tianyi Zhou; Xi Peng; Peng Hu,~Yang_Qin4; ~Yuan_Sun2; ~Dezhong_Peng1; ~Joey_Tianyi_Zhou1; ~Xi_Peng3; ~Peng_Hu2,"{'value': ['Cross-modal learning', 'Image-text matching', 'Noisy correspondence.']}","{'value': 'Recently, image-text matching has attracted more and more attention from academia and industry, which is fundamental to understanding the latent correspondence across visual and textual modalities. However, most existing methods implicitly assume the training pairs are well-aligned while ignoring the ubiquitous annotation noise, a.k.a noisy correspondence (NC), thereby inevitably leading to a performance drop. Although some methods attempt to address such noise, they still face two challenging problems: excessive memorizing/overfitting and unreliable correction for NC, especially under high noise. To address the two problems, we propose a generalized Cross-modal Robust Complementary Learning framework (CRCL), which benefits from a novel Active Complementary Loss (ACL) and an efficient Self-refining Correspondence Correction (SCC) to improve the robustness of existing methods.   Specifically, ACL exploits active and complementary learning losses to reduce the risk of providing erroneous supervision, leading to theoretically and experimentally demonstrated robustness against NC. SCC utilizes multiple self-refining processes with momentum correction to enlarge the receptive field for correcting correspondences, thereby alleviating error accumulation and achieving accurate and stable corrections. We carry out extensive experiments on three image-text benchmarks, i.e., Flickr30K, MS-COCO, and CC152K, to verify the superior robustness of our CRCL against synthetic and real-world noisy correspondences.'}",https://openreview.net{'value': '/pdf/55a44c6257c0aa59fea8a6c26aee01a63ee519b3.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=U9zRgpgdFI,{'value': 'A Hierarchical Spatial Transformer for Massive Point Samples  in Continuous Space'},Wenchong He; Zhe Jiang; Tingsong Xiao; Zelin Xu; Shigang Chen; Ronald Fick; MILES D MEDINA; Christine Angelini,~Wenchong_He1; ~Zhe_Jiang1; ~Tingsong_Xiao1; ~Zelin_Xu1; ~Shigang_Chen1; ~Ronald_Fick1; ~MILES_D_MEDINA1; ~Christine_Angelini1,"{'value': ['Spatial representation learning', 'transformer', 'quadtree', 'efficiency']}","{'value': 'Transformers are widely used deep learning architectures. Existing transformers are mostly designed for sequences (texts or time series), images or videos, and graphs. This paper proposes a novel transformer model for massive (up to a million) point samples in continuous space. Such data are ubiquitous in environment sciences (e.g., sensor observations), numerical simulations (e.g., particle-laden flow, astrophysics), and location-based services (e.g., POIs and trajectories). However, designing a transformer for massive spatial points is non-trivial due to several challenges, including implicit long-range and multi-scale dependency on irregular points in continuous space, a non-uniform point distribution, the potential high computational costs of calculating all-pair attention across massive points, and the risks of over-confident predictions due to varying point density. To address these challenges, we propose a new hierarchical spatial transformer model, which includes multi-resolution representation learning within a quad-tree hierarchy and efficient spatial attention via coarse approximation. We also design an uncertainty quantification branch to estimate prediction confidence related to input feature noise and point sparsity. We provide a theoretical analysis of computational time complexity and memory costs. Extensive experiments on both real-world and synthetic datasets show that our method outperforms multiple baselines in prediction accuracy and our model can scale up to one million points on one NVIDIA A100 GPU. The code is available at https://github.com/spatialdatasciencegroup/HST'}",https://openreview.net{'value': '/pdf/18e01a489fda98cf16c07ed9698c9978e16a4af4.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=TjJJmcHw9p,{'value': 'Exact recovery and Bregman hard clustering of node-attributed Stochastic Block Model'},Maximilien Dreveton; Felipe Schreiber Fernandes; Daniel R. Figueiredo,~Maximilien_Dreveton1; felipesc@cos.ufrj.br; ~Daniel_R._Figueiredo1,"{'value': ['community detection', 'stochastic block model', 'bregman divergence']}","{'value': 'Classic network clustering tackles the problem of identifying sets of nodes (communities) that have similar connection patterns. However, in many scenarios nodes also have attributes that are correlated and can also be used to identify node clusters. Thus, network information (edges) and node information (attributes) can be jointly leveraged to design high-performance clustering algorithms. Under a general model for the network and node attributes, this work establishes an information-theoretic criteria for the exact recovery of community labels and characterizes a phase transition determined by the Chernoff-Hellinger divergence of the model. The criteria shows how network and attribute information can be exchanged in order to have exact recovery (e.g., more reliable network information requires less reliable attribute information). This work also presents an iterative clustering algorithm that maximizes the joint likelihood, assuming that the probability distribution of network interactions and node attributes belong to exponential families. This covers a broad range of possible interactions (e.g., edges with weights) and attributes (e.g., non-Gaussian models) while also exploring the connection between exponential families and Bregman divergences. Extensive numerical experiments using synthetic and real data indicate that the proposed algorithm outperforms algorithms that leverage only network or only attribute information as well as recently proposed algorithms that perform clustering using both sources of information. The contributions of this work provide insights into the fundamental limits and practical techniques for inferring community labels on node-attributed networks.'}",https://openreview.net{'value': '/pdf/7846f8fdf5439f2d187d0609ab9440c18c3ca307.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=TZtw5YgxTE,{'value': 'MIM4DD: Mutual Information Maximization for Dataset Distillation'},Yuzhang Shang; Zhihang Yuan; Yan Yan,~Yuzhang_Shang1; ~Zhihang_Yuan1; ~Yan_Yan6,{'value': ['Dataset Distillation']},"{'value': 'Dataset distillation (DD) aims to synthesize a small dataset whose test performance is comparable to a full dataset using the same model. State-of-the-art (SoTA) methods optimize synthetic datasets primarily by matching heuristic indicators extracted from two networks: one from real data and one from synthetic data (see Fig.1, Left), such as gradients and training trajectories. DD is essentially a compression problem that emphasizes on maximizing the preservation of information contained in the data. We argue that well-defined metrics which measure the amount of shared information between variables in information theory are necessary for success measurement, but are never considered by previous works. Thus, we introduce mutual information (MI) as the metric to quantify the shared information between the synthetic and the real datasets, and devise MIM4DD numerically maximizing the MI via a newly designed optimizable objective within a contrastive learning framework to update the synthetic dataset. Specifically, we designate the samples in different datasets who share the same labels as positive pairs, and vice versa negative pairs. Then we respectively pull and push those samples in positive and negative pairs into contrastive space via minimizing NCE loss. As a result, the targeted MI can be transformed into a lower bound represented by feature maps of samples, which is numerically feasible. Experiment results show that MIM4DD can be implemented as an add-on module to existing SoTA DD methods.'}",https://openreview.net{'value': '/pdf/cf67f80eb6e52002362a50d315aee81746f974c1.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=TAIYBdRb3C,{'value': 'Curve Your Enthusiasm: Concurvity Regularization in Differentiable Generalized Additive Models'},Julien Niklas Siems; Konstantin Ditschuneit; Winfried Ripken; Alma Lindborg; Maximilian Schambach; Johannes Otterbach; Martin Genzel,~Julien_Niklas_Siems1; ~Konstantin_Ditschuneit1; ~Winfried_Ripken1; ~Alma_Lindborg1; ~Maximilian_Schambach1; ~Johannes_Otterbach1; ~Martin_Genzel1,"{'value': ['Interpretable Machine Learning', 'Generalized Additive Models', 'Concurvity', 'Multicollinearity', 'Regularization', 'Time-Series Forecasting', 'Interpretability']}","{'value': 'Generalized Additive Models (GAMs) have recently experienced a resurgence in popularity due to their interpretability, which arises from expressing the target value as a sum of non-linear transformations of the features. Despite the current enthusiasm for GAMs, their susceptibility to concurvity — i.e., (possibly non-linear) dependencies between the features — has hitherto been largely overlooked. Here, we demonstrate how concurvity can severly impair the interpretability of GAMs and propose a remedy: a conceptually simple, yet effective regularizer which penalizes pairwise correlations of the non-linearly transformed feature variables. This procedure is applicable to any differentiable additive model, such as Neural Additive Models or NeuralProphet, and enhances interpretability by eliminating ambiguities due to self-canceling feature contributions. \nWe validate the effectiveness of our regularizer in experiments on synthetic as well as real-world datasets for time-series and tabular data. Our experiments show that concurvity in GAMs can be reduced without significantly compromising prediction quality, improving interpretability and reducing variance in the feature importances.'}",https://openreview.net{'value': '/pdf/dfb14e21dc74e166a88c4c13100277b183a306e8.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=StD4J5ZlI5,{'value': 'Dataset Diffusion: Diffusion-based Synthetic Data Generation for Pixel-Level Semantic Segmentation'},Quang Ho Nguyen; Truong Tuan Vu; Anh Tuan Tran; Khoi Nguyen,~Quang_Ho_Nguyen1; ~Truong_Tuan_Vu1; ~Anh_Tuan_Tran2; ~Khoi_Nguyen1,{'value': ['Deep learning; Diffusion Models; Semantic Segmentation; Text-to-Image']},"{'value': 'Preparing training data for deep vision models is a labor-intensive task. To address this, generative models have emerged as an effective solution for generating synthetic data. While current generative models produce image-level category labels, we propose a novel method for generating pixel-level semantic segmentation labels using the text-to-image generative model Stable Diffusion (SD). By utilizing the text prompts, cross-attention, and self-attention of SD, we introduce three new techniques: class-prompt appending, class-prompt cross-attention, and self-attention exponentiation. These techniques enable us to generate segmentation maps corresponding to synthetic images. These maps serve as pseudo-labels for training semantic segmenters, eliminating the need for labor-intensive pixel-wise annotation. To account for the imperfections in our pseudo-labels, we incorporate uncertainty regions into the segmentation, allowing us to disregard loss from those regions. We conduct evaluations on two datasets, PASCAL VOC and MSCOCO, and our approach significantly outperforms concurrent work. Our benchmarks and code will be released at https://github.com/VinAIResearch/Dataset-Diffusion.'}",https://openreview.net{'value': '/pdf/3b7a35af699a40af6dd9721574a5ec8253cb2e8a.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=STrXsSIEiq,{'value': 'Learning Robust Statistics for Simulation-based Inference under Model Misspecification'},Daolang Huang; Ayush Bharti; Amauri H Souza; Luigi Acerbi; Samuel Kaski,~Daolang_Huang1; ~Ayush_Bharti1; ~Amauri_H_Souza1; ~Luigi_Acerbi1; ~Samuel_Kaski1,"{'value': ['Simulation-based inference', 'model misspecification', 'likelihood-free inference', 'approximate Bayesian computation', 'neural posterior estimation']}","{'value': 'Simulation-based inference (SBI) methods such as approximate Bayesian computation (ABC),  synthetic likelihood, and neural posterior estimation (NPE) rely on simulating statistics to infer parameters of intractable likelihood models. However, such methods are known to yield untrustworthy and misleading inference outcomes under model misspecification, thus hindering their widespread applicability. In this work, we propose the first general approach to handle model misspecification that works across different classes of SBI methods. Leveraging the fact that the choice of statistics determines the degree of misspecification in SBI, we introduce a regularized loss function that penalizes those statistics that increase the mismatch between the data and the model. Taking NPE and ABC as use cases, we demonstrate the superior performance of our method on high-dimensional time-series models that are artificially misspecified. We also apply our method to real data from the field of radio propagation where the model is known to be misspecified. We show empirically that the method yields robust inference in misspecified scenarios, whilst still being accurate when the model is well-specified.'}",https://openreview.net{'value': '/pdf/3d435d746061812803f8f0fe80da5c0a035e8c56.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=SOEF0i0G1z,{'value': 'Cognitive Model Discovery via Disentangled RNNs'},Kevin J Miller; Maria K Eckstein; Matthew Botvinick; Zeb Kurth-Nelson,~Kevin_J_Miller1; ~Maria_K_Eckstein1; ~Matthew_Botvinick1; ~Zeb_Kurth-Nelson1,"{'value': ['Cognitive modeling', 'neural networks', 'interpretability', 'disentangling', 'neuroscience', 'rodent behavior']}","{'value': 'Computational cognitive models are a fundamental tool in behavioral neuroscience. They embody in software precise hypotheses about the cognitive mechanisms underlying a particular behavior. Constructing these models is typically a difficult iterative process that requires both inspiration from the literature and the creativity of an individual researcher. Here, we adopt an alternative approach to learn parsimonious cognitive models directly from data. We fit behavior data using a recurrent neural network that is penalized for carrying excess information between timesteps, leading to sparse, interpretable representations and dynamics. When fitting synthetic behavioral data from known cognitive models, our method recovers the underlying form of those models. When fit to choice data from rats performing a bandit task, our method recovers simple and interpretable models that make testable predictions about neural mechanisms.'}",https://openreview.net{'value': '/pdf/fd74478122c098941d7a2d02bbdc6f700dc88c02.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Rzk3GP1HN7,{'value': 'SwiftSage: A Generative Agent with Fast and Slow Thinking for Complex Interactive Tasks'},Bill Yuchen Lin; Yicheng Fu; Karina Yang; Faeze Brahman; Shiyu Huang; Chandra Bhagavatula; Prithviraj Ammanabrolu; Yejin Choi; Xiang Ren,~Bill_Yuchen_Lin1; ~Yicheng_Fu1; ~Karina_Yang1; ~Faeze_Brahman1; ~Shiyu_Huang2; ~Chandra_Bhagavatula1; ~Prithviraj_Ammanabrolu1; ~Yejin_Choi1; ~Xiang_Ren1,"{'value': ['interactive reasoning', 'text game', 'agents', 'action planning', 'large language models']}","{'value': ""We introduce SwiftSage, a novel agent framework inspired by the dual-process theory of human cognition, designed to excel in action planning for complex interactive reasoning tasks. SwiftSage integrates the strengths of behavior cloning and prompting large language models (LLMs) to enhance task completion performance. The framework comprises two primary modules: the Swift module, representing fast and intuitive thinking, and the Sage module, emulating deliberate thought processes. The Swift module is a small encoder-decoder LM fine-tuned on the oracle agent's action trajectories, while the Sage module employs LLMs such as GPT-4 for subgoal planning and grounding. We develop a heuristic method to harmoniously integrate the two modules, resulting in a more efficient and robust problem-solving process. In 30 tasks from the ScienceWorld benchmark, SwiftSage significantly outperforms other methods such as SayCan, ReAct, and Reflexion, demonstrating its effectiveness in solving complex interactive tasks.""}",https://openreview.net{'value': '/pdf/af990bb2c9c8c0ae4a168311d783c18114f0fdff.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Rvk1wdwz1L,"{'value': 'Similarity, Compression and Local Steps: Three Pillars of Efficient Communications for Distributed Variational Inequalities'}",Aleksandr Beznosikov; Martin Takáč; Alexander Gasnikov,~Aleksandr_Beznosikov1; ~Martin_Takáč1; ~Alexander_Gasnikov1,"{'value': ['convex optimization', 'variational inequalities', 'similarity', 'local methods', 'compression', 'partial participation']}","{'value': ""Variational inequalities are a broad and flexible class of problems that includes minimization, saddle point, and fixed point problems as special cases. Therefore, variational inequalities are used in various applications ranging from equilibrium search to adversarial learning. With the increasing size of data and models, today's instances demand parallel and distributed computing for real-world machine learning problems, most of which can be represented as variational inequalities. Meanwhile, most distributed approaches have a significant bottleneck -- the cost of communications. The three main techniques to reduce the total number of communication rounds and the cost of one such round are the similarity of local functions, compression of transmitted information, and local updates. In this paper, we combine all these approaches. Such a triple synergy did not exist before for variational inequalities and saddle problems, nor even for minimization problems. The methods presented in this paper have the best theoretical guarantees of communication complexity and are significantly ahead of other methods for distributed variational inequalities. The theoretical results are confirmed by adversarial learning experiments on synthetic and real datasets.""}",https://openreview.net{'value': '/pdf/f7b8619c47456b90f4aaa955bd7d47d566cea108.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=RiwPYAMLur,{'value': 'Active representation learning for general task space with applications in robotics'},Yifang Chen; Yingbing Huang; Simon Shaolei Du; Kevin Jamieson; Guanya Shi,~Yifang_Chen1; ~Yingbing_Huang1; ~Simon_Shaolei_Du1; ~Kevin_Jamieson1; ~Guanya_Shi1,"{'value': ['active learning', 'representation learning', 'robotics', 'theory']}","{'value': 'Representation learning based on multi-task pretraining has become a powerful approach in many domains. In particular, task-aware representation learning aims to learn an optimal representation for a specific target task by sampling data from a set of source tasks, while task-agnostic representation learning seeks to learn a universal representation for a class of tasks.  In this paper, we propose a general and versatile algorithmic and theoretic framework for \\emph{active representation learning}, where the learner optimally chooses which source tasks to sample from. This framework, along with a tractable meta algorithm, allows most arbitrary target and source task spaces (from discrete to continuous), covers both task-aware and task-agnostic settings, and is compatible with deep representation learning practices. \nWe provide several instantiations under this framework, from bilinear and feature-based nonlinear to general nonlinear cases. In the bilinear case, by leveraging the non-uniform spectrum of the task representation and the calibrated source-target relevance, we prove that the sample complexity to achieve $\\varepsilon$-excess risk on target scales with $(k^*)^2 ||v^*||_2^2 \\varepsilon^{-2}$\n where $k^*$ is the effective dimension of the target and $||v^*||_2^2 \\in (0,1]$ represents the connection between source and target space. Compared to the passive one, this can save up to $\\frac{1}{d_W}$ of sample complexity, where $d_W$ is the task space dimension. \nFinally, we demonstrate different instantiations of our meta algorithm in synthetic datasets and robotics problems, from pendulum simulations to real-world drone flight datasets. On average, our algorithms outperform baselines by 20%-70%.'}",https://openreview.net{'value': '/pdf/a44a7ae3473d6e741ee196ed3b8a3c931aafd2b6.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=RhE01dqo8u,{'value': 'Feature Selection in the Contrastive Analysis Setting'},Ethan Weinberger; Ian Connick Covert; Su-In Lee,~Ethan_Weinberger2; ~Ian_Connick_Covert1; ~Su-In_Lee2,"{'value': ['Feature selection', 'contrastive analysis', 'computational biology', 'representation learning', 'information theory']}","{'value': 'Contrastive analysis (CA) refers to the exploration of variations uniquely enriched in a _target_ dataset as compared to a corresponding _background_ dataset generated from sources of variation that are irrelevant to a given task. For example, a biomedical data analyst may wish to find a small set of genes to use as a proxy for variations in genomic data only present among patients with a given disease (target) as opposed to healthy control subjects (background). However, as of yet the problem of feature selection in the CA setting has received little attention from the machine learning community. In this work we present contrastive feature selection (CFS),\na method for performing feature selection in the CA setting. We motivate our approach with a novel information-theoretic analysis of representation learning in the CA setting, and we empirically validate CFS on a semi-synthetic dataset and four real-world biomedical datasets. We find that our method consistently outperforms previously proposed state-of-the-art supervised and fully unsupervised feature selection methods not designed for the CA setting. An open-source implementation of our method is available at https://github.com/suinleelab/CFS.'}",https://openreview.net{'value': '/pdf/4138b470f77df106f0861ad0c051995c1d534832.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=RW7rZ8Y3Bp,{'value': 'Federated Spectral Clustering via Secure Similarity Reconstruction'},Dong Qiao; Chris Ding; Jicong Fan,~Dong_Qiao1; ~Chris_Ding1; ~Jicong_Fan2,"{'value': ['clustering', 'federated learning', 'privacy']}","{'value': 'Federated learning has a significant advantage in protecting information privacy. Many scholars proposed various secure learning methods within the framework of federated learning but the study on secure federated unsupervised learning especially clustering is limited. We in this work propose a secure kernelized factorization method for federated spectral clustering on distributed dataset. The method is non-trivial because the kernel or similarity matrix for spectral clustering is computed by data pairs, which violates the principle of privacy protection. Our method implicitly constructs an approximation for the kernel matrix on distributed data such that we can perform spectral clustering under the constraint of privacy protection. We provide a convergence guarantee of the optimization algorithm, reconstruction error bounds of the Gaussian kernel matrix, and the sufficient condition of correct clustering of our method. We also present some results of differential privacy. Numerical results on synthetic and real datasets demonstrate that the proposed method is efficient and accurate in comparison to the baselines.'}",https://openreview.net{'value': '/pdf/8f5a21fb7789155674df80ee26b21622067849a6.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=RUCFAKNDb2,{'value': 'Promises and Pitfalls of Threshold-based Auto-labeling'},Harit Vishwakarma; Heguang Lin; Frederic Sala; Ramya Korlakai Vinayak,~Harit_Vishwakarma1; ~Heguang_Lin1; ~Frederic_Sala1; ~Ramya_Korlakai_Vinayak1,"{'value': ['Auto Labeling', 'Active Learning', 'Selective Classification']}","{'value': 'Creating large-scale high-quality labeled datasets is a major bottleneck in supervised machine learning workflows. Threshold-based auto-labeling (TBAL), where validation data obtained from humans is used to find a confidence threshold above which the data is machine-labeled, reduces reliance on manual annotation. TBAL is emerging as a widely-used solution in practice. Given the long shelf-life and diverse usage of the resulting datasets, understanding when the data obtained by such auto-labeling systems can be relied on is crucial. This is the first work to analyze TBAL systems and derive sample complexity bounds on the amount of human-labeled validation data required for guaranteeing the quality of machine-labeled data. Our results provide two crucial insights. First, reasonable chunks of unlabeled data can be automatically and accurately labeled by seemingly bad models. Second, a hidden downside of TBAL systems is potentially prohibitive validation data usage. Together, these insights describe the promise and pitfalls of using such systems. \nWe validate our theoretical guarantees with extensive experiments on synthetic and real datasets.'}",https://openreview.net{'value': '/pdf/375cdfa1d7814c3a7a2ec045495733db41915fc2.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=RRUVZygUtr,{'value': 'Spectral Invariant Learning for Dynamic Graphs under Distribution Shifts'},Zeyang Zhang; Xin Wang; Ziwei Zhang; Zhou Qin; Weigao Wen; Hui Xue'; Haoyang Li; Wenwu Zhu,~Zeyang_Zhang1; ~Xin_Wang17; ~Ziwei_Zhang1; ~Zhou_Qin2; ~Weigao_Wen1; ~Hui_Xue'1; ~Haoyang_Li1; ~Wenwu_Zhu1,"{'value': ['Dynamic Graph Neural Networks', 'Out-of-Distribution Generalization']}","{'value': 'Dynamic graph neural networks (DyGNNs) currently struggle with handling distribution shifts that are inherent in dynamic graphs.\nExisting work on DyGNNs with out-of-distribution settings only focuses on the time domain, failing to handle cases involving distribution shifts in the spectral domain. In this paper, we discover that there exist cases with distribution shifts unobservable in the time domain while observable in the spectral domain, and propose to study distribution shifts on dynamic graphs in the spectral domain for the first time.\nHowever, this investigation poses two key challenges: i) it is non-trivial to capture different graph patterns that are driven by various frequency components entangled in the spectral domain; and ii) it remains unclear how to handle distribution shifts with the discovered spectral patterns. To address these challenges, we propose Spectral Invariant Learning for Dynamic Graphs under Distribution Shifts (SILD), which can handle distribution shifts on dynamic graphs by capturing and utilizing invariant and variant spectral patterns. Specifically, we first design a DyGNN with Fourier transform to obtain the ego-graph trajectory spectrums, allowing the mixed dynamic graph patterns to be transformed into separate frequency components. We then develop a disentangled spectrum mask to filter graph dynamics from various frequency components and discover the invariant and variant spectral patterns. Finally, we propose invariant spectral filtering, which encourages the model to rely on invariant patterns for generalization under distribution shifts. Experimental results on synthetic and real-world dynamic graph datasets demonstrate the superiority of our method for both node classification and link prediction tasks under distribution shifts.'}",https://openreview.net{'value': '/pdf/bca0c1fcf2b242196054696188eadd64bf721230.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=RMeQjexaRj,{'value': 'Elastic Decision Transformer'},Yueh-Hua Wu; Xiaolong Wang; Masashi Hamaya,~Yueh-Hua_Wu1; ~Xiaolong_Wang3; ~Masashi_Hamaya1,"{'value': ['Offline Reinforcement Learning', 'Trajectory Stitching', 'Decision Transformer']}","{'value': 'This paper introduces Elastic Decision Transformer (EDT), a significant advancement over the existing Decision Transformer (DT) and its variants. Although DT purports to generate an optimal trajectory, empirical evidence suggests it struggles with trajectory stitching, a process involving the generation of an optimal or near-optimal trajectory from the best parts of a set of sub-optimal trajectories. The proposed EDT differentiates itself by facilitating trajectory stitching during action inference at test time, achieved by adjusting the history length maintained in DT. Further, the EDT optimizes the trajectory by retaining a longer history when the previous trajectory is optimal and a shorter one when it is sub-optimal, enabling it to ""stitch"" with a more optimal trajectory. Extensive experimentation demonstrates EDT\'s ability to bridge the performance gap between DT-based and Q Learning-based approaches. In particular, the EDT outperforms Q Learning-based methods in a multi-task regime on the D4RL locomotion benchmark and Atari games.'}",https://openreview.net{'value': '/pdf/920e4d2d7995b529a4c04e52326188847a9af897.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=RInTOCEL3l,"{'value': 'Relax, it doesn’t matter how you get there: A new self-supervised approach for multi-timescale behavior analysis'}",Mehdi Azabou; Michael Jacob Mendelson; Nauman Ahad; Maks Sorokin; Shantanu Thakoor; Carolina Urzay; Eva L Dyer,~Mehdi_Azabou2; ~Michael_Jacob_Mendelson1; ~Nauman_Ahad1; ~Maks_Sorokin1; ~Shantanu_Thakoor5; ~Carolina_Urzay1; ~Eva_L_Dyer1,"{'value': ['animal behavior', 'behavioral neuroscience', 'self-supervised learning', 'multi-timescale']}","{'value': 'Unconstrained and natural  behavior consists of dynamics that are complex and  unpredictable, especially when trying to predict what will happen  multiple steps into the future. While some success has been found in building representations of animal behavior under constrained or simplified task-based conditions, many of these models cannot be applied to free and naturalistic settings where behavior becomes increasingly hard to model. In this work, we develop a multi-task representation learning model for animal behavior that combines two novel components: (i) an action-prediction objective that aims to predict the  distribution of actions over future timesteps, and (ii) a multi-scale architecture that builds separate latent spaces to accommodate short- and long-term dynamics. After demonstrating the ability of the method to build representations of both local and global dynamics in robots in varying environments and terrains, we apply our method to the MABe 2022 Multi-Agent Behavior challenge, where our model ranks first overall on both mice and fly benchmarks. In all of these cases, we show that our model can build representations that capture the many different factors that drive behavior and solve a wide range of downstream tasks.'}",https://openreview.net{'value': '/pdf/307c6dca91df2facd1757a88cc7c494fb5f468ac.pdf'},{'abstract_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=RACcp8Zbr9,{'value': 'Beyond Black-Box Advice: Learning-Augmented Algorithms for MDPs with Q-Value Predictions'},Tongxin Li; Yiheng Lin; Shaolei Ren; Adam Wierman,~Tongxin_Li1; ~Yiheng_Lin1; ~Shaolei_Ren1; ~Adam_Wierman1,"{'value': ['Time-varying MDP', 'Learning-augmented online algorithm', 'consistency and robustness tradeoff']}","{'value': 'We study the tradeoff between consistency and robustness in the context of a single-trajectory time-varying Markov Decision Process (MDP) with untrusted machine-learned advice. Our work departs from the typical approach of treating advice as coming from black-box sources by instead considering a setting where additional information about  how the advice is generated is available. We prove a first-of-its-kind consistency and robustness tradeoff given Q-value advice under a general MDP model that includes both continuous and discrete state/action spaces. Our results highlight that utilizing Q-value advice enables dynamic pursuit of the better of machine-learned advice and a robust baseline, thus result in near-optimal performance guarantees, which provably improves what can be obtained solely with black-box advice.'}",https://openreview.net{'value': '/pdf/0587073fbd2333f338d0b489452cad11c5787ba4.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Qu6Ln7d9df,{'value': 'Streaming Factor Trajectory Learning for Temporal Tensor Decomposition'},Shikai Fang; Xin Yu; Shibo Li; Zheng Wang; Robert Kirby; Shandian Zhe,~Shikai_Fang2; ~Xin_Yu4; ~Shibo_Li1; ~Zheng_Wang2; ~Robert_Kirby1; ~Shandian_Zhe1,"{'value': ['Tensor Decomposition', 'streaming method', 'Bayesian model']}","{'value': ""Practical tensor data is often along with time information. Most existing temporal decomposition approaches estimate a set of fixed factors for the objects in each tensor mode, and hence cannot capture the temporal evolution of the objects' representation. More important, we lack an effective approach to capture such evolution from streaming data, which is common in real-world applications.  To address these issues, we propose Streaming Factor Trajectory Learning (SFTL) for temporal tensor decomposition. We use Gaussian processes (GPs) to model the trajectory of  factors so as to flexibly estimate their temporal evolution. To address the computational challenges in handling streaming data, we convert the GPs into a state-space prior by constructing an equivalent stochastic differential equation (SDE).  We develop an efficient online filtering algorithm to estimate a decoupled running posterior of the involved factor states upon receiving new data. The decoupled estimation enables us to conduct standard Rauch-Tung-Striebel smoothing to compute the full posterior of all the  trajectories in parallel, without the need for revisiting any previous data. We have shown the advantage of SFTL in both synthetic tasks and real-world applications.""}",https://openreview.net{'value': '/pdf/6658e3b88dbc0567470a6b1073ad2cabf3e8f9cd.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=QKSejqE8Vp,{'value': 'An Optimal and Scalable Matrix Mechanism for Noisy Marginals under Convex Loss Functions'},Yingtai Xiao; Guanlin He; Danfeng Zhang; Daniel Kifer,~Yingtai_Xiao1; ~Guanlin_He1; ~Danfeng_Zhang1; ~Daniel_Kifer1,"{'value': ['differential privacy', 'marginals', 'matrix mechanism', 'scalability']}","{'value': 'Noisy marginals are a common form of confidentiality-protecting data release and are useful for many downstream tasks such as contingency table analysis, construction of Bayesian networks, and even synthetic data generation. Privacy mechanisms that provide unbiased noisy answers to linear queries (such as marginals) are known as matrix mechanisms.\n\nWe propose ResidualPlanner, a matrix mechanism for marginals with Gaussian noise that is both optimal and scalable. ResidualPlanner can optimize for many loss functions that can be written as a convex function of marginal variances (prior work was restricted to just one predefined objective function). ResidualPlanner can optimize the accuracy of marginals in large scale settings in seconds, even when the previous state of the art (HDMM) runs out of memory. It even runs on datasets with 100 attributes in a couple of minutes. Furthermore ResidualPlanner can efficiently compute variance/covariance values for each marginal (prior methods quickly run out of memory, even for relatively small datasets).'}",https://openreview.net{'value': '/pdf/ba0bed65e575d2f0f84a108cbe48cd516d28f592.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Q5tuGgqJwt,{'value': 'Refining Diffusion Planner for Reliable Behavior Synthesis by Automatic Detection of Infeasible Plans'},Kyowoon Lee; Seongun Kim; Jaesik Choi,~Kyowoon_Lee1; ~Seongun_Kim1; ~Jaesik_Choi1,"{'value': ['Offline Reinforcement Learning', 'Trajectory Optimization', 'Diffusion Models', 'Sequential Decision Making']}","{'value': 'Diffusion-based planning has shown promising results in long-horizon, sparse-reward tasks by training trajectory diffusion models and conditioning the sampled trajectories using auxiliary guidance functions. However, due to their nature as generative models, diffusion models are not guaranteed to generate feasible plans, resulting in failed execution and precluding planners from being useful in safety-critical applications. In this work, we propose a novel approach to refine unreliable plans generated by diffusion models by providing refining guidance to error-prone plans. To this end, we suggest a new metric named restoration gap for evaluating the quality of individual plans generated by the diffusion model. A restoration gap is estimated by a gap predictor which produces restoration gap guidance to refine a diffusion planner. We additionally present an attribution map regularizer to prevent adversarial refining guidance that could be generated from the sub-optimal gap predictor, which enables further refinement of infeasible plans. We demonstrate the effectiveness of our approach on three different benchmarks in offline control settings that require long-horizon planning. We also illustrate that our approach presents explainability by presenting the attribution maps of the gap predictor and highlighting error-prone transitions, allowing for a deeper understanding of the generated plans.'}",https://openreview.net{'value': '/pdf/92a62f60f40316a6b1154b1afaa2fced6d35bbec.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Q3FXnCPZ1X,{'value': 'Fast and Simple Spectral Clustering in Theory and Practice'},Peter Macgregor,~Peter_Macgregor1,"{'value': ['spectral clustering', 'power method', 'spectral graph theory', 'graph algorithms']}","{'value': 'Spectral clustering is a popular and effective algorithm designed to find $k$ clusters in a graph $G$.\nIn the classical spectral clustering algorithm, the vertices of $G$ are embedded into $\\mathbb{R}^k$ using $k$ eigenvectors of the graph Laplacian matrix.\nHowever, computing this embedding is computationally expensive and dominates the running time of the algorithm.\nIn this paper, we present a simple spectral clustering algorithm based on a vertex embedding with $O(\\log(k))$ vectors computed by the power method.\nThe vertex embedding is computed in nearly-linear time with respect to the size of the graph, and\nthe algorithm provably recovers the ground truth clusters under natural assumptions on the input graph.\nWe evaluate the new algorithm on several synthetic and real-world datasets, finding that it is significantly faster than alternative clustering algorithms,\nwhile producing results with approximately the same clustering accuracy.'}",https://openreview.net{'value': '/pdf/15dd611c782df44564ad66b0f610ede333ac6804.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=PnbCA4ylIc,{'value': 'Goal Driven Discovery of Distributional Differences via Language Descriptions'},Ruiqi Zhong; Peter Zhang; Steve Li; Jinwoo Ahn; Dan Klein; Jacob Steinhardt,~Ruiqi_Zhong1; ~Peter_Zhang3; ~Steve_Li1; ~Jinwoo_Ahn3; ~Dan_Klein1; ~Jacob_Steinhardt1,"{'value': ['large language model', 'prompting', 'exploratory text analysis']}","{'value': ""Exploring large corpora can generate useful discoveries but is time-consuming for humans.\n    We formulate a new task, D5, that automatically discovers differences between two large corpora in a goal-driven way. \n    The task input is a problem comprising a user-specified research goal (“*comparing the side effects of drug A and drug*”) and a corpus pair (two large collections of patients' self-reported reactions after taking each drug). \n    The output is a goal-related description (discovery) of how these corpora differ (patients taking drug A “*mention feelings of paranoia*” more often).\n    We build a D5 system, and to quantitatively evaluate its performance, we 1) build a diagnostic benchmark, SynD5, to test whether it can recover known differences between two synthetic corpora, and 2) contribute a meta-dataset, OpenD5, aggregating 675 open-ended problems ranging across business, social sciences, humanities, machine learning, and health.\n    With both synthetic and real datasets, we confirm that language models can leverage the user-specified goals to propose more relevant candidate discoveries, and they sometimes produce discoveries previously unknown to the authors, including demographic differences in discussion topics, political stances in speech, insights in commercial reviews, and error patterns in NLP models.\n    Finally, we discuss the limitations of the current D5 system, which discovers correlation rather than causation and has the potential to reinforce societal biases when misused; therefore, practitioners should treat the outputs of our system with caution.""}",https://openreview.net{'value': '/pdf/c5753f73812c0b3e9c827988def54c1981d203b1.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=PnJaA0A8Lr,{'value': 'Trajectory Alignment: Understanding the Edge of Stability Phenomenon via Bifurcation Theory'},Minhak Song; Chulhee Yun,~Minhak_Song1; ~Chulhee_Yun1,"{'value': ['non-convex optimization', 'trajectory alignment of GD', 'edge of stability', 'progressive sharpening', 'bifurcation theory']}","{'value': 'Cohen et al. (2021) empirically study the evolution of the largest eigenvalue of the loss Hessian, also known as sharpness, along the gradient descent (GD) trajectory and observe the Edge of Stability (EoS) phenomenon. The sharpness increases at the early phase of training (referred to as progressive sharpening), and eventually saturates close to the threshold of $2 / \\text{(step size)}$. In this paper, we start by demonstrating through empirical studies that when the EoS phenomenon occurs, different GD trajectories (after a proper reparameterization) align on a specific bifurcation diagram independent of initialization. We then rigorously prove this trajectory alignment phenomenon for a two-layer fully-connected linear network and a single-neuron nonlinear network trained with a single data point. Our trajectory alignment analysis establishes both progressive sharpening and EoS phenomena, encompassing and extending recent findings in the literature.'}",https://openreview.net{'value': '/pdf/c43aa40a9159d1939d65e72dd855a71b2ea1c4a2.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=PmqBJ02V1p,{'value': 'Adaptive Principal Component Regression with Applications to Panel Data'},Anish Agarwal; Keegan Harris; Justin Whitehouse; Steven Wu,~Anish_Agarwal1; ~Keegan_Harris1; ~Justin_Whitehouse1; ~Steven_Wu1,"{'value': ['adaptive data collection', 'principal component regression', 'error-in-variables regression', 'panel data', 'synthetic controls', 'synthetic interventions', 'causal inference']}","{'value': 'Principal component regression (PCR) is a popular technique for fixed-design error-in-variables regression, a generalization of the linear regression setting in which the observed covariates are corrupted with random noise. We provide the first time-uniform finite sample guarantees for online (regularized) PCR whenever data is collected adaptively. Since the proof techniques for PCR in the fixed design setting do not readily extend to the online setting, our results rely on adapting tools from modern martingale concentration to the error-in-variables setting. As an application of our bounds, we provide a framework for counterfactual estimation of unit-specific treatment effects in panel data settings when interventions are assigned adaptively. Our framework may be thought of as a generalization of the synthetic interventions framework where data is collected via an adaptive intervention assignment policy.'}",https://openreview.net{'value': '/pdf/cc561fc3d1aa89a96c9adf582f617949192b3050.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=PmlNxZoXr4,{'value': 'Neural Processes with Stability'},Huafeng Liu; Liping Jing; Jian Yu,~Huafeng_Liu3; ~Liping_Jing3; ~Jian_Yu1,"{'value': ['Neural processes', 'stability']}","{'value': 'Unlike traditional statistical models depending on hand-specified priors, neural processes (NPs) have recently emerged as a class of powerful neural statistical models that combine the strengths of neural networks and stochastic processes. NPs can define a flexible class of stochastic processes well suited for highly non-trivial functions by encoding contextual knowledge into the function space. However, noisy context points introduce challenges to the algorithmic stability that small changes in training data may significantly change the models and yield lower generalization performance. In this paper, we provide theoretical guidelines for deriving stable solutions with high generalization by introducing the notion of algorithmic stability into NPs, which can be flexible to work with various NPs and achieves less biased approximation with theoretical guarantees. To illustrate the superiority of the proposed model, we perform experiments on both synthetic and real-world data, and the results demonstrate that our approach not only helps to achieve more accurate performance but also improves model robustness.'}",https://openreview.net{'value': '/pdf/fec95d3e40f0dadc51e972fad5740ad6267dfaa4.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=PkKpTK7hJ6,{'value': 'Truncating Trajectories in Monte Carlo Policy Evaluation: an Adaptive Approach'},Riccardo Poiani; Nicole Nobili; Alberto Maria Metelli; Marcello Restelli,~Riccardo_Poiani3; ~Nicole_Nobili1; ~Alberto_Maria_Metelli2; ~Marcello_Restelli1,"{'value': ['Reinforcement Learning', 'Policy Evaluation', 'Budget Optimization', 'Monte Carlo']}","{'value': ""Policy evaluation via Monte Carlo (MC) simulation is at the core of many MC Reinforcement Learning (RL) algorithms (e.g., policy gradient methods). In this context, the designer of the learning system specifies an interaction budget that the agent usually spends by collecting trajectories of *fixed length* within a simulator. However, is this data collection strategy the best option? To answer this question, in this paper, we consider as quality index the variance of an unbiased policy return estimator that uses trajectories of different lengths, i.e., *truncated*. We first derive a closed-form expression of this variance that clearly shows the sub-optimality of the fixed-length trajectory schedule. Furthermore, it suggests that adaptive data collection strategies that spend the available budget sequentially might be able to allocate a larger portion of transitions in timesteps in which more accurate sampling is required to reduce the variance of the final estimate. Building on these findings, we present an *adaptive* algorithm called **R**obust and **I**terative **D**ata collection strategy **O**ptimization (RIDO). The main intuition behind RIDO is to split the available interaction budget into mini-batches. At each round, the agent determines the most convenient schedule of trajectories that minimizes an empirical and robust estimate of the estimator's variance. After discussing the theoretical properties of our method, we conclude by assessing its performance across multiple domains. Our results show that RIDO can adapt its trajectory schedule toward timesteps where more sampling is required to increase the quality of the final estimation.""}",https://openreview.net{'value': '/pdf/e6c985ae9e545e2ff0cab6fb4c25d89cce9a1fd3.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=PXsqbAjpQd,{'value': 'SHOT: Suppressing the Hessian along the Optimization Trajectory for Gradient-Based Meta-Learning'},JunHoo Lee; Jayeon Yoo; Nojun Kwak,~JunHoo_Lee1; ~Jayeon_Yoo1; ~Nojun_Kwak1,"{'value': ['meta learning', 'Hessian', 'Gradient-Based meta learning', 'Feature Reuse', 'Implicit Prior']}","{'value': 'In this paper, we hypothesize that gradient-based meta-learning (GBML) implicitly suppresses the Hessian along the optimization\n  trajectory in the inner loop. Based on this hypothesis, we introduce an algorithm called\n  SHOT (Suppressing the Hessian along the Optimization Trajectory) that minimizes the distance between the parameters of the target and reference models to suppress the Hessian in the inner loop. Despite dealing with\n  high-order terms, SHOT does not increase the computational complexity of the baseline model much.\n  It is agnostic to both the algorithm and architecture used in GBML, making it highly\n  versatile and applicable to any GBML baseline. To validate the effectiveness of SHOT,\n  we conduct empirical tests on standard few-shot learning tasks and qualitatively\n  analyze its dynamics. We confirm our hypothesis empirically and demonstrate that SHOT\n  outperforms the corresponding baseline.'}",https://openreview.net{'value': '/pdf/785784c05f29fc0721c8c924369e3b395eb38e54.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=PTvxck0QDE,{'value': 'Simplicity Bias in 1-Hidden Layer Neural Networks'},Depen Morwani; jatin batra; Prateek Jain; Praneeth Netrapalli,~Depen_Morwani1; ~jatin_batra1; ~Prateek_Jain1; ~Praneeth_Netrapalli1,"{'value': ['Simplicity Bias', 'Gradient Descent', 'Implicit Bias', 'Neural Networks']}","{'value': 'Recent works have demonstrated that neural networks exhibit extreme *simplicity bias* (SB). That is,  they learn *only the simplest* features  to solve a task at hand, even in the presence of other, more robust but more complex features. Due to the lack of a general and rigorous definition of *features*, these works showcase SB on *semi-synthetic* datasets such as Color-MNIST , MNIST-CIFAR where\n defining features is relatively easier. \n\nIn this work, we rigorously define as well as thoroughly establish SB for *one hidden layer* neural networks in the infinite width regime. More concretely, (i) we define SB as the network essentially being a function of a low dimensional projection of the inputs \n(ii) theoretically, we show that when the data is linearly separable, the network primarily depends on only the linearly separable ($1$-dimensional) subspace even in the presence of an arbitrarily large number of other, more complex features which could have led to a significantly more robust classifier,  (iii) empirically, we show that models trained on *real* datasets such as Imagenet and Waterbirds-Landbirds indeed depend on a low dimensional projection of the inputs, thereby demonstrating SB on these datasets, iv) finally, we present a natural ensemble approach that encourages diversity in  models by training successive models on features not used by earlier models, and demonstrate that it yields models that are significantly more robust to Gaussian noise.'}",https://openreview.net{'value': '/pdf/8f47e6373e6a45cd402f974a8580ea23ca9d1670.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=PMvudWa53L,{'value': 'Fair Adaptive Experiments'},Waverly Wei; Xinwei Ma; Jingshen Wang,~Waverly_Wei1; x1ma@ucsd.edu; ~Jingshen_Wang1,{'value': ['Adaptive Randomized Experiment; Adaptive Design; Causal Inference']},"{'value': ""Randomized experiments have been the gold standard for assessing the effectiveness of a treatment, policy, or intervention, spanning various fields, including social sciences, biomedical studies, and e-commerce. The classical complete randomization approach assigns treatments based on a pre-specified probability and may lead to inefficient use of data. Adaptive experiments improve upon complete randomization by sequentially learning and updating treatment assignment probabilities using accrued evidence during the experiment. Hence, they can help achieve efficient data use and higher estimation efficiency. However, their application can also raise fairness and equity concerns, as assignment probabilities may vary drastically across groups of participants. Furthermore, when treatment is expected to be extremely beneficial to certain groups of participants, it is more appropriate to expose many of these participants to favorable treatment. In response to these challenges, we propose a fair adaptive experiment strategy that simultaneously enhances data use efficiency, achieves an ``envy-free'' treatment assignment guarantee, and improves the overall welfare of participants. An important feature of our proposed strategy is that we do not impose parametric modeling assumptions on the outcome variables, making it more versatile and applicable to a wider array of applications. Through our theoretical investigation, we characterize the convergence rate of the estimated treatment effects and the associated standard deviations at the group level and further prove that our adaptive treatment assignment algorithm, despite not having a closed-form expression, approaches the optimal allocation rule asymptotically. Our proof strategy takes into account the fact that the allocation decisions in our design depend on sequentially accumulated data, which poses a significant challenge in characterizing the properties and conducting statistical inference of our method. We further provide simulation evidence and two synthetic data studies to showcase the performance of our fair adaptive experiment strategy.""}",https://openreview.net{'value': '/pdf/2838e84d180e1f22e1504626dc9acea6fcab8e22.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Op9z2QfXbC,{'value': 'Modulated Neural ODEs'},Ilze Amanda Auzina; Cagatay Yildiz; Sara Magliacane; Matthias Bethge; Efstratios Gavves,~Ilze_Amanda_Auzina1; ~Cagatay_Yildiz1; ~Sara_Magliacane1; ~Matthias_Bethge1; ~Efstratios_Gavves1,"{'value': ['Neural ODEs', 'Modulator Variables', 'Dynamical Systems', 'Disentanglment']}","{'value': 'Neural ordinary differential equations (NODEs) have been proven useful for learning non-linear dynamics of arbitrary trajectories. However, current NODE methods capture variations across trajectories only via the initial state value or by auto-regressive encoder updates. In this work, we introduce Modulated Neural ODEs (MoNODEs), a novel framework that sets apart dynamics states from underlying static factors of variation and improves the existing NODE methods.  In particular, we introduce *time-invariant modulator variables* that are learned from the data. We incorporate our proposed framework into four existing NODE variants. We test MoNODE on oscillating systems, videos and human walking trajectories, where each trajectory has trajectory-specific modulation. Our framework consistently improves the existing model ability to generalize to new dynamic parameterizations and to perform far-horizon forecasting. In addition, we verify that the proposed modulator variables are informative of the true unknown factors of variation as measured by $R^2$ scores.'}",https://openreview.net{'value': '/pdf/32fecea16336d49dedd2f46edd5cb34d10eb82ae.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=OitmaxSAUu,{'value': 'Transformers are uninterpretable with myopic methods: a case study with bounded Dyck grammars'},Kaiyue Wen; Yuchen Li; Bingbin Liu; Andrej Risteski,~Kaiyue_Wen1; ~Yuchen_Li5; ~Bingbin_Liu1; ~Andrej_Risteski2,"{'value': ['Transformer', 'Self Attention', 'Dyck Language', 'Context Free Grammar', 'Formal Language', 'Theory', 'Interpretability']}","{'value': 'Transformer interpretability aims to understand the algorithm implemented by a learned Transformer by examining various aspects of the model, such as the weight matrices or the attention patterns.\nIn this work, through a combination of theoretical results and carefully controlled experiments on synthetic data, we take a critical view\nof methods that exclusively focus on individual parts of the model, rather than consider the network as a whole.\nWe consider a simple synthetic setup of learning a (bounded) Dyck language. Theoretically, we show that the set of models that (exactly or approximately) solve this task satisfy a structural characterization derived from ideas in formal languages (the pumping lemma).\nWe use this characterization to show that the set of optima is qualitatively rich; in particular, the attention pattern of a single layer can be ""nearly randomized"", while preserving the functionality of the network.\nWe also show via extensive experiments that these constructions are not merely a theoretical artifact: even with severe constraints to the architecture of the model, vastly different solutions can be reached via standard training. Thus, interpretability claims based on inspecting individual heads or weight matrices in the Transformer can be misleading.'}",https://openreview.net{'value': '/pdf/22540ea1571571f78536dc3cff2153be6fa8b7ef.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Of0GBzow8P,{'value': 'The Transient Nature of Emergent In-Context Learning in Transformers'},Aaditya K Singh; Stephanie C.Y. Chan; Ted Moskovitz; Erin Grant; Andrew M Saxe; Felix Hill,~Aaditya_K_Singh1; ~Stephanie_C.Y._Chan1; ~Ted_Moskovitz1; ~Erin_Grant1; ~Andrew_M_Saxe1; ~Felix_Hill1,"{'value': ['in-context learning', 'transformers', 'emergence', 'transience']}","{'value': ""Transformer neural networks can exhibit a surprising capacity for in-context learning (ICL) despite not being explicitly trained for it.  Prior work has provided a deeper understanding of how ICL emerges in transformers, e.g. through the lens of mechanistic interpretability, Bayesian inference, or by examining the distributional properties of training data. However, in each of these cases, ICL is treated largely as a persistent phenomenon; namely, once ICL emerges, it is assumed to persist asymptotically. Here, we show that the emergence of ICL during transformer training is, in fact, often transient. We train transformers on synthetic data designed so that both ICL and in-weights learning (IWL) strategies can lead to correct predictions. We find that ICL first emerges, then disappears and gives way to IWL, all while the training loss decreases, indicating an asymptotic preference for IWL. The transient nature of ICL is observed in transformers across a range of model sizes and datasets, raising the question of how much to ``overtrain'' transformers when seeking compact, cheaper-to-run models. We find that L2 regularization may offer a path to more persistent ICL that removes the need for early stopping based on ICL-style validation tasks. Finally, we present initial evidence that ICL transience may be caused by competition between ICL and IWL circuits.""}",https://openreview.net{'value': '/pdf/e437bfb2ceb185af0df65b26a3df7726532df15a.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=O63qgtebjH,{'value': 'Scalable Primal-Dual Actor-Critic Method for Safe Multi-Agent RL with General Utilities'},Donghao Ying; Yunkai Zhang; Yuhao Ding; Alec Koppel; Javad Lavaei,~Donghao_Ying1; ~Yunkai_Zhang2; ~Yuhao_Ding2; ~Alec_Koppel1; ~Javad_Lavaei1,"{'value': ['Reinforcement Learning Theory', 'Safe reinforcement learning', 'Multi-agent reinforcement learning']}","{'value': ""We investigate safe multi-agent reinforcement learning, where agents seek to collectively maximize an aggregate sum of local objectives while satisfying their own safety constraints. The objective and constraints are described by general utilities, i.e., nonlinear functions of the long-term state-action occupancy measure, which encompass broader decision-making goals such as risk, exploration, or imitations. The exponential growth of the state-action space size with the number of agents presents challenges for global observability, further exacerbated by the global coupling arising from agents' safety constraints. To tackle this issue, we propose a primal-dual method utilizing shadow reward and $\\kappa$-hop neighbor truncation under a form of correlation decay property, where $\\kappa$ is the communication radius. In the exact setting, our algorithm converges to a first-order stationary point (FOSP) at the rate of $\\mathcal{O}\\left(T^{-2/3}\\right)$. In the sample-based setting, we demonstrate that, with high probability, our algorithm requires $\\widetilde{\\mathcal{O}}\\left(\\epsilon^{-3.5}\\right)$ samples to achieve an $\\epsilon$-FOSP with an approximation error of $\\mathcal{O}(\\phi_0^{2\\kappa})$, where $\\phi_0\\in (0,1)$. Finally, we demonstrate the effectiveness of our model through extensive numerical experiments.""}",https://openreview.net{'value': '/pdf/f5c70505e09647b1b9d4711ee740e5a82dc69802.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=NyQwBttTnG,{'value': 'Information Design in Multi-Agent Reinforcement Learning'},Yue Lin; Wenhao Li; Hongyuan Zha; Baoxiang Wang,~Yue_Lin2; ~Wenhao_Li2; ~Hongyuan_Zha1; ~Baoxiang_Wang1,"{'value': ['multi-agent reinforcement learning', 'multi-agent communication', 'information design', 'signaling gradient', 'obedience constraints']}","{'value': 'Reinforcement learning (RL) is inspired by the way human infants and animals learn from the environment. The setting is somewhat idealized because, in actual tasks, other agents in the environment have their own goals and behave adaptively to the ego agent. To thrive in those environments, the agent needs to influence other agents so their actions become more helpful and less harmful. Research in computational economics distills two ways to influence others directly: by providing tangible goods (mechanism design) and by providing information (information design). This work investigates information design problems for a group of RL agents. The main challenges are two-fold. One is the information provided will immediately affect the transition of the agent trajectories, which introduces additional non-stationarity. The other is the information can be ignored, so the sender must provide information that the receiver is willing to respect. We formulate the Markov signaling game, and develop the notions of signaling gradient and the extended obedience constraints that address these challenges. Our algorithm is efficient on various mixed-motive tasks and provides further insights into computational economics. Our code is publicly available at https://github.com/YueLin301/InformationDesignMARL.'}",https://openreview.net{'value': '/pdf/73b7530f4c3e0005f0522d0f9fa81d6b958e67e6.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Ny3GcHLyzj,{'value': 'Efficient Policy Adaptation with Contrastive Prompt Ensemble for Embodied Agents'},Wonje Choi; Woo Kyung Kim; SeungHyun Kim; Honguk Woo,~Wonje_Choi2; ~Woo_Kyung_Kim1; ~SeungHyun_Kim4; ~Honguk_Woo1,"{'value': ['Prompt Learining', 'Domain Adaptation', 'Embodied AI']}","{'value': ""For embodied reinforcement learning (RL) agents interacting with the environment, it is desirable to have rapid policy adaptation to unseen visual observations, but achieving zero-shot adaptation capability is considered as a challenging problem in the RL context. To address the problem, we present a novel contrastive prompt ensemble (ConPE) framework which utilizes a pretrained vision-language model and a set of visual prompts, thus enables efficient policy learning and adaptation upon a wide range of environmental and physical changes encountered by embodied agents. Specifically, we devise a guided-attention-based ensemble approach with multiple visual prompts on the vision-language model to construct robust state representations. Each prompt is contrastively learned in terms of an individual domain factors that significantly affects the agent's egocentric perception and observation. For a given task, the attention-based ensemble and policy are jointly learned so that the resulting state representations not only generalize to various domains but are also optimized for learning the task. Through experiments, we show that ConPE outperforms other state-of-the-art algorithms for several embodied agent tasks including navigation in AI2THOR, manipulation in Metaworld, and autonomous driving in CARLA, while also improving the sample efficiency of policy learning and adaptation.""}",https://openreview.net{'value': '/pdf/2b304d9f4f08bdb5216c3656ac73dbae1ea1b755.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=NpyZkaEEun,{'value': 'Distributionally Robust Skeleton Learning of Discrete Bayesian Networks'},Yeshu Li; Brian D Ziebart,~Yeshu_Li1; ~Brian_D_Ziebart1,"{'value': ['structure learning', 'Bayesian network', 'robustness']}","{'value': 'We consider the problem of learning the exact skeleton of general discrete Bayesian networks from potentially corrupted data. Building on distributionally robust optimization and a regression approach, we propose to optimize the most adverse risk over a family of distributions within bounded Wasserstein distance or KL divergence to the empirical distribution. The worst-case risk accounts for the effect of outliers. The proposed approach applies for general categorical random variables without assuming faithfulness, an ordinal relationship or a specific form of conditional distribution. We present efficient algorithms and show the proposed methods are closely related to the standard regularized regression approach. Under mild assumptions, we derive non-asymptotic guarantees for successful structure learning with logarithmic sample complexities for bounded-degree graphs. Numerical study on synthetic and real datasets validates the effectiveness of our method.'}",https://openreview.net{'value': '/pdf/a66ed066a92066bc36addce0e8a4de0c6f3c4e78.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=NnXznLurw5,{'value': 'Human spatiotemporal pattern learning as probabilistic program synthesis'},Tracey Mills; Joshua B. Tenenbaum; Samuel J Cheyette,~Tracey_Mills1; ~Joshua_B._Tenenbaum1; ~Samuel_J_Cheyette1,{'value': ['pattern learning; probabilistic programs; program synthesis; gaussian process; human learning']},"{'value': 'People are adept at learning a wide variety of structured patterns from small amounts of data, presenting a conundrum from the standpoint of the bias-variance tradeoff: what kinds of representations and algorithms support the joint flexibility and data-paucity of human learning? One possibility is that people ""learn by programming"": inducing probabilistic models to fit observed data. Here, we experimentally test human learning in the domain of structured 2-dimensional patterns, using a task in which participants repeatedly predicted where a dot would move based on its previous trajectory. We evaluate human performance against standard parametric and non-parametric time-series models, as well as two Bayesian program synthesis models whose hypotheses vary in their degree of structure: a compositional Gaussian Process model and a structured ""Language of Thought"" (LoT) model. We find that signatures of human pattern learning are best explained by the LoT model, supporting the idea that the flexibility and data-efficiency of human structure learning can be understood as probabilistic inference over an expressive space of programs.'}",https://openreview.net{'value': '/pdf/ba983209ca62e876b8a7edc4500c6ae6dba0d086.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=NiQTy0NW1L,{'value': 'Lexinvariant Language Models'},Qian Huang; Eric Zelikman; Sarah Li Chen; Yuhuai Wu; Gregory Valiant; Percy Liang,~Qian_Huang2; ~Eric_Zelikman1; ~Sarah_Li_Chen1; ~Yuhuai_Wu1; ~Gregory_Valiant1; ~Percy_Liang1,"{'value': ['Large Language Model', 'in-context learning', 'pretraining']}","{'value': 'Token embeddings, a mapping from discrete lexical symbols to continuous vectors, are at the heart of any language model (LM). However, lexical symbol meanings can also be determined and even redefined by their structural role in a long context. In this paper, we ask: is it possible for a language model to be performant without \\emph{any} fixed token embeddings? Such a language model would have to rely entirely on the co-occurence and repetition of tokens in the context rather than the \\textit{a priori} identity of any token. To answer this, we study \\textit{lexinvariant}language models that are invariant to lexical symbols and therefore do not need fixed token embeddings in practice. First, we prove that we can construct a lexinvariant LM to converge to the true language model at a uniform rate that is polynomial in terms of the context length, with a constant factor that is sublinear in the vocabulary size. Second, to build a lexinvariant LM, we simply encode tokens using random Gaussian vectors, such that each token maps to the same representation within each sequence but different representations across sequences. Empirically, we demonstrate that it can indeed attain perplexity comparable to that of a standard language model, given a sufficiently long context. We further explore two properties of the lexinvariant language models: First, given text generated from a substitution cipher of English, it implicitly implements Bayesian in-context deciphering and infers the mapping to the underlying real tokens with high accuracy. Second, it has on average 4X better accuracy over synthetic in-context reasoning tasks. Finally, we discuss regularizing standard language models towards lexinvariance and potential practical applications.'}",https://openreview.net{'value': '/pdf/c20f23fbf078b6ada397580eeabf672e8c0eb624.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=NaYAsbv2jF,{'value': 'Geometric Neural Diffusion Processes'},Emile Mathieu; Vincent Dutordoir; Michael John Hutchinson; Valentin De Bortoli; Yee Whye Teh; Richard E Turner,~Emile_Mathieu1; ~Vincent_Dutordoir1; ~Michael_John_Hutchinson1; ~Valentin_De_Bortoli1; ~Yee_Whye_Teh2; ~Richard_E_Turner1,"{'value': ['diffusion model', 'functional space', 'stochastic process', 'time-series', 'neural processes', 'Gaussian processes', 'random fields', 'invariance', 'equivariance', 'symmetries', 'stationarity']}","{'value': 'Denoising diffusion models have proven to be a flexible and effective paradigm for generative modelling.\nTheir recent extension to infinite dimensional Euclidean spaces has allowed for the modelling of stochastic processes.\nHowever, many problems in the natural sciences incorporate symmetries and involve data living in non-Euclidean spaces.\nIn this work, we extend the framework of diffusion models to incorporate a series of geometric priors in infinite-dimension modelling.\nWe do so by a) constructing a noising process which admits, as limiting distribution, a geometric Gaussian process that transforms under the symmetry group of interest, and b) approximating the score with a neural network that is equivariant w.r.t. this group.\nWe show that with these conditions, the generative functional model admits the same symmetry.\nWe demonstrate scalability and capacity of the model, using a novel Langevin-based conditional sampler, to fit complex scalar and vector fields, with Euclidean and spherical codomain, on synthetic and real-world weather data.'}",https://openreview.net{'value': '/pdf/a10af1f179bcce4ea0920152eb3e8b750b821e0b.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=NIrTSCiIZ7,{'value': 'Boundary Guided Learning-Free Semantic Control with Diffusion Models'},Ye Zhu; Yu Wu; Zhiwei Deng; Olga Russakovsky; Yan Yan,~Ye_Zhu3; ~Yu_Wu3; ~Zhiwei_Deng3; ~Olga_Russakovsky1; ~Yan_Yan6,"{'value': ['Diffusion probabilistic models', 'learning-free applications', 'high-dimensional semantic boundary', 'markov mixing']}","{'value': 'Applying pre-trained generative denoising diffusion models (DDMs) for downstream tasks such as image semantic editing usually requires either fine-tuning DDMs or learning auxiliary editing networks in the existing literature. In this work, we present our BoundaryDiffusion method for efficient, effective and light-weight semantic control with frozen pre-trained DDMs, without learning any extra networks. As one of the first learning-free diffusion editing works, we start by seeking a more comprehensive understanding of the intermediate high-dimensional latent spaces by theoretically and empirically analyzing their probabilistic and geometric behaviors in the Markov chain. We then propose to further explore the critical step in the denoising trajectory that characterizes the convergence of a pre-trained DDM and introduce an automatic search method. Last but not least, in contrast to the conventional understanding that DDMs have relatively poor semantic behaviors (in generic latent spaces), we prove that the critical latent space we found already forms semantic subspace boundaries at the generic level in unconditional DDMs, which allows us to do controllable manipulation by guiding the denoising trajectory towards the targeted boundary via a single-step operation. We conduct extensive experiments on multiple DPMs architectures (DDPM, iDDPM) and datasets (CelebA, CelebA-HQ, LSUN-church, LSUN-bedroom, AFHQ-dog) with different resolutions (64, 256), achieving superior or state-of-the-art performance in various task scenarios (image semantic editing, text-based editing, unconditional semantic control) to demonstrate the effectiveness.'}",https://openreview.net{'value': '/pdf/77449eacfd8bc6a501e475e91abb9f7490b99337.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=NEawU0TgKG,{'value': 'Frequency Domain-Based Dataset Distillation'},DongHyeok Shin; Seungjae Shin; Il-chul Moon,~DongHyeok_Shin1; ~Seungjae_Shin1; ~Il-chul_Moon1,"{'value': ['Dataset distillation', 'Frequency domain', 'Dataset condensation']}","{'value': 'This paper presents FreD, a novel parameterization method for dataset distillation, which utilizes the frequency domain to distill a small-sized synthetic dataset from a large-sized original dataset. Unlike conventional approaches that focus on the spatial domain, FreD employs frequency-based transforms to optimize the frequency representations of each data instance. By leveraging the concentration of spatial domain information on specific frequency components, FreD intelligently selects a subset of frequency dimensions for optimization, leading to a significant reduction in the required budget for synthesizing an instance. Through the selection of frequency dimensions based on the explained variance, FreD demonstrates both theoretical and empirical evidence of its ability to operate efficiently within a limited budget, while better preserving the information of the original dataset compared to conventional parameterization methods. Furthermore, Based on the orthogonal compatibility of FreD with existing methods, we confirm that FreD consistently improves the performances of existing distillation methods over the evaluation scenarios with different benchmark datasets. We release the code at https://github.com/sdh0818/FreD.'}",https://openreview.net{'value': '/pdf/fceed185d44ed8701103a140fd2ce0efdc655823.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Murj6wcjRw,{'value': 'An Efficient Dataset Condensation Plugin and Its Application to Continual Learning'},Enneng Yang; Li Shen; Zhenyi Wang; Tongliang Liu; Guibing Guo,~Enneng_Yang1; ~Li_Shen1; ~Zhenyi_Wang1; ~Tongliang_Liu1; ~Guibing_Guo1,"{'value': ['Data Condensation', 'Continual Learning', 'Few-shot Learning']}","{'value': ""Dataset condensation (DC) distills a large real-world dataset into a small synthetic dataset, with the goal of training a network from scratch on the latter that performs similarly to the former. State-of-the-art (SOTA) DC methods have achieved satisfactory results through techniques such as accuracy, gradient, training trajectory, or distribution matching. However, these works all perform matching in the high-dimension pixel spaces, ignoring that natural images are usually locally connected and have lower intrinsic dimensions, resulting in low condensation efficiency.  In this work, we propose a simple-yet-efficient dataset condensation plugin that matches the raw and synthetic datasets in a low-dimensional manifold. Specifically, our plugin condenses raw images into two low-rank matrices instead of parameterized image matrices. Our plugin can be easily incorporated into existing DC methods, thereby containing richer raw dataset information at limited storage costs to improve the downstream applications' performance.  We verify on multiple public datasets that when the proposed plugin is combined with SOTA DC methods, the performance of the network trained on synthetic data is significantly improved compared to traditional DC methods. Moreover, when applying the DC methods as a plugin to continual learning tasks, we observed that our approach effectively mitigates catastrophic forgetting of old tasks under limited memory buffer constraints and avoids the problem of raw data privacy leakage.""}",https://openreview.net{'value': '/pdf/6bc6f76fcba339ebf661e41593d6a1cfdeb40895.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=MIYBTjCVjR,{'value': 'Sequential Preference Ranking for Efficient Reinforcement Learning from Human Feedback'},Minyoung Hwang; Gunmin Lee; Hogun Kee; Chan Woo Kim; Kyungjae Lee; Songhwai Oh,~Minyoung_Hwang1; ~Gunmin_Lee1; ~Hogun_Kee1; ~Chan_Woo_Kim2; ~Kyungjae_Lee1; ~Songhwai_Oh1,{'value': ['Reinforcement Learning; Reinforcement Learning from Human Feedback; Preference-based Reinforcement Learning; Human-Robot Interaction']},"{'value': 'Reinforcement learning from human feedback (RLHF) alleviates the problem of designing a task-specific reward function in reinforcement learning by learning it from human preference. However, existing RLHF models are considered inefficient as they produce only a single preference data from each human feedback. To tackle this problem, we propose a novel RLHF framework called SeqRank, that uses sequential preference ranking to enhance the feedback efficiency. Our method samples trajectories in a sequential manner by iteratively selecting a defender from the set of previously chosen trajectories $\\mathcal{K}$ and a challenger from the set of unchosen trajectories $\\mathcal{U}\\setminus\\mathcal{K}$, where $\\mathcal{U}$ is the replay buffer. We propose two trajectory comparison methods with different defender sampling strategies: (1) sequential pairwise comparison that selects the most recent trajectory and (2) root pairwise comparison that selects the most preferred trajectory from $\\mathcal{K}$. We construct a data structure and rank trajectories by preference to augment additional queries. The proposed method results in at least 39.2% higher average feedback efficiency than the baseline and also achieves a balance between feedback efficiency and data dependency. We examine the convergence of the empirical risk and the generalization bound of the reward model with Rademacher complexity. While both trajectory comparison methods outperform conventional pairwise comparison, root pairwise comparison improves the average reward in locomotion tasks and the average success rate in manipulation tasks by 29.0% and 25.0%, respectively. The source code and the videos are provided in the supplementary material.'}",https://openreview.net{'value': '/pdf/03fd7bb2cab83230de26f0813f2dfa2c166e0863.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=MCj7DLkYqS,{'value': 'Adversarial Attacks on Online Learning to Rank with Click Feedback'},Jinhang Zuo; Zhiyao Zhang; Zhiyong Wang; Shuai Li; Mohammad Hajiesmaili; Adam Wierman,~Jinhang_Zuo1; ~Zhiyao_Zhang2; ~Zhiyong_Wang9; ~Shuai_Li3; ~Mohammad_Hajiesmaili1; ~Adam_Wierman1,"{'value': ['online learning to rank', 'adversarial attack', 'click model']}","{'value': 'Online learning to rank (OLTR) is a sequential decision-making problem where a learning agent selects an ordered list of items and receives feedback through user clicks. Although potential attacks against OLTR algorithms may cause serious losses in real-world applications, there is limited knowledge about adversarial attacks on OLTR. This paper studies attack strategies against multiple variants of OLTR. Our first result provides an attack strategy against the UCB algorithm on classical stochastic bandits with binary feedback, which solves the key issues caused by bounded and discrete feedback that previous works cannot handle. Building on this result, we design attack algorithms against UCB-based OLTR algorithms in position-based and cascade models. Finally, we propose a general attack strategy against any algorithm under the general click model. Each attack algorithm manipulates the learning agent into choosing the target attack item $T-o(T)$ times, incurring a cumulative cost of $o(T)$. Experiments on synthetic and real data further validate the effectiveness of our proposed attack algorithms.'}",https://openreview.net{'value': '/pdf/46fdd276940aa4bca17302cf76a72ed2242ce546.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=MCVfX7HgPO,{'value': 'Testing the General Deductive Reasoning Capacity of Large Language Models Using OOD Examples'},Abulhair Saparov; Richard Yuanzhe Pang; Vishakh Padmakumar; Nitish Joshi; Mehran Kazemi; Najoung Kim; He He,~Abulhair_Saparov1; ~Richard_Yuanzhe_Pang1; ~Vishakh_Padmakumar1; ~Nitish_Joshi1; ~Mehran_Kazemi1; najoung@bu.edu; ~He_He2,"{'value': ['large language models', 'reasoning', 'out-of-distribution generalization', 'chain-of-thought', 'in-context learning']}","{'value': 'Given the intractably large size of the space of proofs, any model that is capable of general deductive reasoning must generalize to proofs of greater complexity. Recent studies have shown that large language models (LLMs) possess some abstract deductive reasoning ability given chain-of-thought prompts. However, they have primarily been tested on proofs using modus ponens or of a specific size, and from the same distribution as the in-context examples. To measure the general deductive reasoning ability of LLMs, we test on a broad set of deduction rules and measure their ability to generalize to more complex proofs from simpler demonstrations from multiple angles: depth-, width-, and compositional generalization. To facilitate systematic exploration, we construct a new synthetic and programmable reasoning dataset that enables control over deduction rules and proof complexity. Our experiments on four LLMs of various sizes and training objectives show that they are able to generalize to compositional proofs. However, they have difficulty generalizing to longer proofs, and they require explicit demonstrations to produce hypothetical subproofs, specifically in proof by cases and proof by contradiction.'}",https://openreview.net{'value': '/pdf/31cb2384469a09172b705930c450e993a434a508.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=M7FQpIdo0X,{'value': 'Enhancing Minority Classes by Mixing: An Adaptative Optimal Transport Approach for Long-tailed Classification'},Jintong Gao; He Zhao; Zhuo Li; Dan dan Guo,~Jintong_Gao2; ~He_Zhao1; ~Zhuo_Li5; ~Dan_dan_Guo1,"{'value': ['Long-tailed Classification', 'Optimal Transport', 'Image-mixing', 'Semantic Similarity']}","{'value': 'Real-world data usually confronts severe class-imbalance problems, where several majority classes have a significantly larger presence in the training set than minority classes. One effective solution is using mixup-based methods to generate synthetic samples to enhance the presence of minority classes. Previous approaches mix the background images from the majority classes and foreground images from the\nminority classes in a random manner, which ignores the sample-level semantic similarity, possibly resulting in less reasonable or less useful images. In this work, we propose an adaptive image-mixing method based on optimal transport (OT) to incorporate both class-level and sample-level information, which is able to generate semantically reasonable and meaningful mixed images for minority classes. Due to\nits flexibility, our method can be combined with existing long-tailed classification methods to enhance their performance and it can also serve as a general data augmentation method for balanced datasets. Extensive experiments indicate that our method achieves effective performance for long-tailed classification tasks. The code is available at https://github.com/JintongGao/Enhancing-Minority-Classes-by-Mixing.'}",https://openreview.net{'value': '/pdf/fe709720dd11f9e93189c539dd92b123345cbef7.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=M6OmjAZ4CX,{'value': 'Language Models can Solve Computer Tasks'},Geunwoo Kim; Pierre Baldi; Stephen Marcus McAleer,~Geunwoo_Kim1; ~Pierre_Baldi1; ~Stephen_Marcus_McAleer1,"{'value': ['Large Language models', 'Web Navigation', 'Foundation Models', 'Decision Making']}","{'value': ""Agents capable of carrying out general tasks on a computer can improve efficiency and productivity by automating repetitive tasks and assisting in complex problem-solving. Ideally, such agents should be able to solve new computer tasks presented to them through natural language commands. However, previous approaches to this problem require large amounts of expert demonstrations and task-specific reward functions, both of which are impractical for new tasks. In this work, we show that a pre-trained large language model (LLM) agent can execute computer tasks guided by natural language using a simple prompting scheme where the agent \\textbf{R}ecursively \\textbf{C}riticizes and \\textbf{I}mproves its output (RCI). The RCI approach significantly outperforms existing LLM methods for automating computer tasks and surpasses supervised learning (SL) and reinforcement learning (RL) approaches on the MiniWoB++ benchmark. \nWe compare multiple LLMs and find that RCI with the InstructGPT-3+RLHF LLM is state-of-the-art on MiniWoB++, using only a handful of demonstrations per task rather than tens of thousands, and without a task-specific reward function. Furthermore, we demonstrate RCI prompting's effectiveness in enhancing LLMs' reasoning abilities on a suite of natural language reasoning tasks, outperforming chain of thought (CoT) prompting with external feedback. We find that RCI combined with CoT performs better than either separately. Our code can be found here: https://github.com/posgnu/rci-agent.""}",https://openreview.net{'value': '/pdf/fa18eaea2d58fadf4b1c3fec15f6fb8563d78702.pdf'},{'abstract_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Lmxo0RVNx2,{'value': 'Individualized Dosing Dynamics via Neural Eigen Decomposition'},Stav Belogolovsky; Ido Greenberg; Danny Eytan; Shie Mannor,~Stav_Belogolovsky1; ~Ido_Greenberg1; ~Danny_Eytan1; ~Shie_Mannor2,"{'value': ['personalized medicine', 'dosing dynamics', 'sequential prediction', 'stochastic differential equations', 'Kalman filter', 'recurrent neural networks', 'medical drug control']}","{'value': 'Dosing models often use differential equations to model biological dynamics. Neural differential equations in particular can learn to predict the derivative of a process, which permits predictions at irregular points of time. However, this temporal flexibility often comes with a high sensitivity to noise, whereas medical problems often present high noise and limited data. Moreover, medical dosing models must generalize reliably over individual patients and changing treatment policies. To address these challenges, we introduce the Neural Eigen Stochastic Differential Equation algorithm (NESDE). NESDE provides individualized modeling (using a hypernetwork over patient-level parameters); generalization to new treatment policies (using decoupled control); tunable expressiveness according to the noise level (using piecewise linearity); and fast, continuous, closed-form prediction (using spectral representation). We demonstrate the robustness of NESDE in both synthetic and real medical problems, and use the learned dynamics to publish simulated medical gym environments.'}",https://openreview.net{'value': '/pdf/3199d0797871babeb8a27308122d48e5950a2aff.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=LmmjiTwYm0,{'value': 'What functions can Graph Neural Networks compute on random graphs? The role of Positional Encoding'},Nicolas Keriven; Samuel Vaiter,~Nicolas_Keriven1; ~Samuel_Vaiter1,{'value': ['graph neural network; random graph; positional encoding']},"{'value': 'We aim to deepen the theoretical understanding of Graph Neural Networks (GNNs) on large graphs, with a focus on their expressive power.\nExisting analyses relate this notion to the graph isomorphism problem, which is mostly relevant for graphs of small sizes, or studied graph classification or regression tasks, while prediction tasks on \\emph{nodes} are far more relevant on large graphs. Recently, several works showed that, on very general random graphs models, GNNs converge to certains functions as the number of nodes grows.\nIn this paper, we provide a more complete and intuitive description of the function space generated by equivariant GNNs for node-tasks, through general notions of convergence that encompass several previous examples. We emphasize the role of input node features, and study the impact of \\emph{node Positional Encodings} (PEs), a recent line of work that has been shown to yield state-of-the-art results in practice. Through the study of several examples of PEs on large random graphs, we extend previously known universality results to significantly more general models. Our theoretical results hint at some normalization tricks, which is shown numerically to have a positive impact on GNN generalization on synthetic and real data. Our proofs contain new concentration inequalities of independent interest.'}",https://openreview.net{'value': '/pdf/2e8c80734f616d3b6ed9beec684f939285fc36e8.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=LhVJdq4cZm,{'value': 'AlberDICE: Addressing Out-Of-Distribution Joint Actions in Offline Multi-Agent RL via Alternating Stationary Distribution Correction Estimation'},Daiki E. Matsunaga; Jongmin Lee; Jaeseok Yoon; Stefanos Leonardos; Pieter Abbeel; Kee-Eung Kim,~Daiki_E._Matsunaga1; ~Jongmin_Lee1; ~Jaeseok_Yoon1; ~Stefanos_Leonardos1; ~Pieter_Abbeel2; ~Kee-Eung_Kim2,"{'value': ['Offline Reinforcement Learning', 'Multi-Agent Reinforcement Learning']}","{'value': 'One of the main challenges in offline Reinforcement Learning (RL) is the distribution shift that arises from the learned policy deviating from the data collection policy. This is often addressed by avoiding out-of-distribution (OOD) actions during policy improvement as their presence can lead to substantial performance degradation. This challenge is amplified in the offline Multi-Agent RL (MARL) setting since the joint action space grows exponentially with the number of agents.\nTo avoid this curse of dimensionality, existing MARL methods adopt either value decomposition methods or fully decentralized training of individual agents. However, even when combined with standard conservatism principles, these methods can still result in the selection of OOD joint actions in offline MARL. To this end, we introduce AlberDICE,\nan offline MARL algorithm that alternatively performs centralized training of individual agents based on stationary distribution optimization. AlberDICE circumvents the exponential complexity of MARL by computing the best response of one agent at a time while effectively avoiding OOD joint action selection. Theoretically, we show that the alternating optimization procedure converges to Nash policies. In the experiments, we demonstrate that AlberDICE significantly outperforms baseline algorithms on a standard suite of MARL benchmarks.'}",https://openreview.net{'value': '/pdf/a100c783b619bf7ba15f6986a9a946c3d96d2616.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=LUT4b9gOtS,{'value': 'Learning Visual Prior via Generative Pre-Training'},Jinheng Xie; Kai Ye; Yudong Li; Yuexiang Li; Kevin Qinghong Lin; Yefeng Zheng; Linlin Shen; Mike Zheng Shou,~Jinheng_Xie1; ~Kai_Ye3; ~Yudong_Li1; ~Yuexiang_Li1; ~Kevin_Qinghong_Lin1; ~Yefeng_Zheng2; ~Linlin_Shen1; ~Mike_Zheng_Shou1,"{'value': ['Visual Prior', 'Generative Pre-Training', 'Conditional Image Synthesis']}","{'value': 'Various stuff and things in visual data possess specific traits, which can be learned by deep neural networks and are implicitly represented as the visual prior, e.g., object location and shape, in the model. Such prior potentially impacts many vision tasks. For example, in conditional image synthesis, spatial conditions failing to adhere to the prior can result in visually inaccurate synthetic results. This work aims to explicitly learn the visual prior and enable the customization of sampling. Inspired by advances in language modeling, we propose to learn Visual prior via Generative Pre-Training, dubbed VisorGPT. By discretizing visual locations, e.g., bounding boxes, human pose, and instance masks, into sequences, VisorGPT can model visual prior through likelihood maximization. Besides, prompt engineering is investigated to unify various visual locations and enable customized sampling of sequential outputs from the learned prior. Experimental results demonstrate the effectiveness of VisorGPT in modeling visual prior and extrapolating to novel scenes, potentially motivating that discrete visual locations can be integrated into the learning paradigm of current language models to further perceive visual world. Code is available at https://sierkinhane.github.io/visor-gpt.'}",https://openreview.net{'value': '/pdf/567db1e086fff38a5704077ebadb65d5c57bea8d.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=KtvPdGb31Z,"{'value': 'Describe, Explain, Plan and Select: Interactive Planning with LLMs Enables Open-World Multi-Task Agents'}",Zihao Wang; Shaofei Cai; Guanzhou Chen; Anji Liu; Xiaojian Ma; Yitao Liang,~Zihao_Wang23; ~Shaofei_Cai2; ~Guanzhou_Chen1; ~Anji_Liu1; ~Xiaojian_Ma1; ~Yitao_Liang1,"{'value': ['open-ended learning', 'multi task', 'large language models', 'zero-shot planning']}","{'value': ""In this paper, we study the problem of planning in Minecraft, a popular, democratized yet challenging open-ended environment for developing multi-task embodied agents. We've found two primary challenges of empowering such agents with planning: 1) planning in an open-ended world like Minecraft requires precise and multi-step reasoning due to the long-term nature of the tasks, and 2) as vanilla planners do not consider the achievability of the current agent when ordering parallel sub-goals within a complicated plan, the resulting plan could be inefficient. To this end, we propose ``$\\underline{D}$escribe, $\\underline{E}$xplain, $\\underline{P}$lan and $\\underline{S}$elect'' ($\\textbf{DEPS}$), an interactive planning approach based on Large Language Models (LLMs). Our approach helps with better error correction from the feedback during the long-haul planning, while also bringing the sense of proximity via goal $\\textbf{Selector}$, a learnable module that ranks parallel sub-goals based on the estimated steps of completion and improves the original plan accordingly. Our experiments mark the milestone of the first zero-shot multi-task agent that can robustly accomplish 70+ Minecraft tasks and nearly double the overall performances. Further testing reveals our method's general effectiveness in popularly adopted non-open-ended domains as well (i.e., ALFWorld and tabletop manipulation). The ablation and exploratory studies detail how our design beats the counterparts and provide a promising update on the $\\texttt{ObtainDiamond}$ grand challenge with our approach.""}",https://openreview.net{'value': '/pdf/55b58f4d498cc7605484fc24b7dbee97f5e0a58f.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=KTfAtro6vP,{'value': 'Reinforcement Learning with Fast and Forgetful Memory'},Steven Morad; Ryan Kortvelesy; Stephan Liwicki; Amanda Prorok,~Steven_Morad1; ~Ryan_Kortvelesy1; ~Stephan_Liwicki3; ~Amanda_Prorok1,"{'value': ['reinforcement learning', 'partially observable', 'POMDP', 'memory', 'rnn', 'transformer']}","{'value': 'Nearly all real world tasks are inherently partially observable, necessitating the use of memory in Reinforcement Learning (RL). Most model-free approaches summarize the trajectory into a latent Markov state using memory models borrowed from Supervised Learning (SL), even though RL tends to exhibit different training and efficiency characteristics. Addressing this discrepancy, we introduce Fast and Forgetful Memory, an algorithm-agnostic memory model designed specifically for RL. Our approach constrains the model search space via strong structural priors inspired by computational psychology. It is a drop-in replacement for recurrent neural networks (RNNs) in recurrent RL algorithms, achieving greater reward than RNNs across various recurrent benchmarks and algorithms _without changing any hyperparameters_. Moreover, Fast and Forgetful Memory exhibits training speeds two orders of magnitude faster than RNNs, attributed to its logarithmic time and linear space complexity. Our implementation is available at https://github.com/proroklab/ffm.'}",https://openreview.net{'value': '/pdf/b4ba3d223fabc3191888a9df7104df8099cb22dc.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=KTZttLZekH,{'value': 'On the Constrained Time-Series Generation Problem'},Andrea Coletta; Sriram Gopalakrishnan; Daniel Borrajo; Svitlana Vyetrenko,~Andrea_Coletta1; ~Sriram_Gopalakrishnan1; ~Daniel_Borrajo1; ~Svitlana_Vyetrenko1,"{'value': ['time-series', 'generative models', 'constrained optimization', 'machine learning']}","{'value': ""Synthetic time series are often used in practical applications to augment the historical time series dataset, \namplify the occurrence of rare events and also create counterfactual scenarios.\nDistributional-similarity (which we refer to as realism) as well as the satisfaction of certain numerical constraints are common requirements for counterfactual time series generation. For instance, the US Federal Reserve publishes synthetic market stress scenarios given by the constrained time series for financial institutions to assess their performance in hypothetical recessions.\nExisting approaches for generating constrained time series usually penalize training loss to enforce constraints, and reject non-conforming samples. However, these approaches would require re-training if we change constraints, and rejection sampling can be computationally expensive, or impractical for complex constraints.\nIn this paper, we propose a novel set of methods to tackle the constrained time series generation problem and provide efficient sampling while ensuring the realism of generated time series.  \nIn particular, we frame the problem using a constrained optimization framework and then we propose a set of generative methods including 'GuidedDiffTime', a guided diffusion model. \nWe empirically evaluate our work on several datasets for financial and energy data, where incorporating constraints is critical. We show that our approaches outperform existing work both qualitatively and quantitatively, and that 'GuidedDiffTime' does not require re-training for new constraints, resulting in a significant carbon footprint reduction, up to 92% w.r.t. existing deep learning methods.""}",https://openreview.net{'value': '/pdf/8d5105360fabdbdff072c74c51b428e309a0a91e.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=KTR33hMnMX,{'value': 'Aligning Optimization Trajectories with Diffusion Models for Constrained Design Generation'},Giorgio Giannone; Akash Srivastava; Ole Winther; Faez Ahmed,~Giorgio_Giannone1; ~Akash_Srivastava1; ~Ole_Winther1; ~Faez_Ahmed1,"{'value': ['diffusion models', 'engineering design', 'generative optimization', 'trajectory matching']}","{'value': ""Generative models have significantly influenced both vision and language domains, ushering in innovative multimodal applications. Although these achievements have motivated exploration in scientific and engineering fields, challenges emerge, particularly in constrained settings with limited data where precision is crucial. Traditional engineering optimization methods rooted in physics often surpass generative models in these contexts. To address these challenges, we introduce Diffusion Optimization Models (DOM) and Trajectory Alignment (TA), a learning framework that demonstrates the efficacy of aligning the sampling trajectory of diffusion models with the trajectory derived from physics-based iterative optimization methods. This alignment ensures that the sampling process remains grounded in the underlying physical principles. This alignment eliminates the need for costly preprocessing, external surrogate models, or extra labeled data, generating feasible and high-performance designs efficiently. We apply our framework to structural topology optimization, a fundamental problem in mechanical design, evaluating its performance on in- and out-of-distribution configurations. Our results demonstrate that TA outperforms state-of-the-art deep generative models on in-distribution configurations and halves the inference computational cost. When coupled with a few steps of optimization, it also improves manufacturability for out-of-distribution conditions. \nDOM's efficiency and performance improvements significantly expedite design processes and steer them toward optimal and manufacturable outcomes, highlighting the potential of generative models in data-driven design.""}",https://openreview.net{'value': '/pdf/a54dc119d2de91d451a4a19009140292834c723c.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=K5e5tFZuur,{'value': 'Invariant Learning via Probability of Sufficient and Necessary Causes'},Mengyue Yang; Zhen Fang; Yonggang Zhang; Yali Du; Furui Liu; Jean-Francois Ton; Jianhong Wang; Jun Wang,~Mengyue_Yang1; ~Zhen_Fang2; ~Yonggang_Zhang1; ~Yali_Du1; ~Furui_Liu1; ~Jean-Francois_Ton2; ~Jianhong_Wang1; ~Jun_Wang2,"{'value': ['OOD Generalization', 'Invariant Representation Learning']}","{'value': 'Out-of-distribution (OOD) generalization is indispensable for learning models in the wild, where testing distribution typically unknown and different from the training. Recent methods derived from causality have shown great potential in achieving OOD generalization. \nHowever, existing methods mainly focus on the invariance property of causes, while largely overlooking the property of sufficiency and necessity conditions. Namely, a necessary but insufficient cause (feature) is invariant to distribution shift, yet it may not have required accuracy. By contrast, a sufficient yet unnecessary cause (feature) tends to fit specific data well but may have a risk of adapting to a new domain. \nTo capture the information of sufficient and necessary causes, we employ a classical concept, the probability of sufficiency and necessary causes (PNS), which indicates the probability of whether one is the necessary and sufficient cause. \nTo associate PNS with OOD generalization, we propose PNS risk and formulate an algorithm to learn representation with a high PNS value. We theoretically analyze and prove the generalizability of the PNS risk. Experiments on both synthetic and real-world benchmarks demonstrate the effectiveness of the proposed method. The detailed implementation can be found at the GitHub repository: https://github.com/ymy4323460/CaSN.'}",https://openreview.net{'value': '/pdf/7b37eabb1ed3dbacbb4c010036d85617e63da6e9.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=JpU5YmMKx7,{'value': 'Attentive Transfer Entropy to Exploit Transient Emergence of Coupling Effect'},Xiaolei Ru; Xin-Ya Zhang; Zijia Liu; Jack Murdoch Moore; Gang Yan,~Xiaolei_Ru1; ~Xin-Ya_Zhang1; ~Zijia_Liu1; ~Jack_Murdoch_Moore1; ~Gang_Yan2,{'value': ['Directed coupled network reconstruction; Neuronal dynamics; Mutual information estimator; Attention mechanism; Transfer entropy.']},"{'value': 'We consider the problem of reconstructing coupled networks (e.g., biological neural networks) connecting large numbers of variables (e.g.,nerve cells), of which state evolution is governed by dissipative dynamics consisting of strong self-drive (dominants the evolution) and weak coupling-drive. The core difficulty is sparseness of coupling effect that emerges (the coupling force is significant) only momentarily and otherwise remains quiescent in time series (e.g., neuronal activity sequence). Here we learn the idea from attention mechanism to guide the classifier to make inference focusing on the critical regions of time series data where coupling effect may manifest. Specifically, attention coefficients are assigned autonomously by artificial neural networks trained to maximise the Attentive Transfer Entropy (ATEn), which is a novel generalization of the iconic transfer entropy metric. Our results show that, without any prior knowledge of dynamics, ATEn explicitly identifies areas where the strength of coupling-drive is distinctly greater than zero. This innovation substantially improves reconstruction performance for both synthetic and real directed coupling networks using data generated by neuronal models widely used in neuroscience.'}",https://openreview.net{'value': '/pdf/e71a0062ef878900c16783f69d0e8a4755d0b065.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=JOkgEY9os2,{'value': 'MMD-Fuse: Learning and Combining Kernels for Two-Sample Testing Without Data Splitting'},Felix Biggs; Antonin Schrab; Arthur Gretton,~Felix_Biggs1; ~Antonin_Schrab1; ~Arthur_Gretton1,"{'value': ['Testing', 'MMD', 'Kernel Methods', 'Two-sample testing']}","{'value': 'We propose novel statistics which maximise the power  of a two-sample test based on the Maximum Mean Discrepancy (MMD), by\nadapting over the set of kernels used in defining it.\nFor finite sets, this reduces to combining (normalised) MMD values under each of these kernels via a weighted soft maximum.\nExponential concentration bounds are proved for our proposed statistics under the null and alternative.\nWe further show how these kernels can be chosen in a data-dependent but permutation-independent way, in a well-calibrated test, avoiding data splitting.\nThis technique applies more broadly to general permutation-based MMD testing, and includes the use of deep kernels with features learnt using unsupervised models such as auto-encoders.\nWe highlight the applicability of our MMD-Fuse tests on both synthetic low-dimensional and real-world high-dimensional data, and compare its performance in terms of power against current state-of-the-art kernel tests.'}",https://openreview.net{'value': '/pdf/bae8c384e04844e2c6dcdbf7e92fed8b2628058e.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=JIKM2vS8XU,{'value': 'DatasetDM: Synthesizing Data with Perception Annotations Using Diffusion Models'},Weijia Wu; Yuzhong Zhao; Hao Chen; Yuchao Gu; Rui Zhao; Yefei He; Hong Zhou; Mike Zheng Shou; Chunhua Shen,~Weijia_Wu2; ~Yuzhong_Zhao1; ~Hao_Chen17; ~Yuchao_Gu1; ~Rui_Zhao12; ~Yefei_He1; ~Hong_Zhou3; ~Mike_Zheng_Shou1; ~Chunhua_Shen2,{'value': ['Diffusion Model; Text-guided dataset generation']},"{'value': 'Current deep networks are very data-hungry and benefit from training on large-scale datasets, which are often time-consuming to collect and annotate. By contrast, synthetic data can be generated infinitely using generative models such as DALL-E and diffusion models, with minimal effort and cost. In this paper, we present DatasetDM, a generic dataset generation model that can produce diverse synthetic\nimages and the corresponding high-quality perception annotations (e.g., segmentation masks, and depth). Our method builds upon the pre-trained diffusion model and extends text-guided image synthesis to perception data generation. We show that the rich latent code of the diffusion model can be effectively decoded as accurate perception annotations using a decoder module. Training the decoder only needs less than 1% (around 100 images) of manually labeled images, enabling the generation of an infinitely large annotated dataset. Then these synthetic data can be used for training various perception models on downstream tasks. To showcase the power of the proposed approach, we generate datasets with rich dense pixel-wise labels for a wide range of downstream tasks, including semantic15\nsegmentation, instance segmentation, and depth estimation. Notably, it achieves 1) state-of-the-art results on semantic segmentation and instance segmentation; 2) significantly more efficient and robust in domain generalization than the real data; 3) state-of-the-art results in zero-shot segmentation setting; and 4) flexibility for efficient application and novel task composition (e.g., image editing)'}",https://openreview.net{'value': '/pdf/6fdc2c2bc7e310efef7751115ab7eda60d662769.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=JDw50IX4TY,{'value': 'Partial Multi-Label Learning with Probabilistic Graphical Disambiguation'},Jun-Yi Hang; Min-Ling Zhang,~Jun-Yi_Hang1; ~Min-Ling_Zhang2,"{'value': ['Machine learning', 'multi-label learning', 'partial multi-label learning', 'label disambiguation']}","{'value': 'In partial multi-label learning (PML), each training example is associated with a set of candidate labels, among which only some labels are valid. As a common strategy to tackle PML problem, disambiguation aims to recover the ground-truth labeling information from such inaccurate annotations. However, existing approaches mainly rely on heuristics or ad-hoc rules to disambiguate candidate labels, which may not be universal enough in complicated real-world scenarios. To provide a principled way for disambiguation, we make a first attempt to explore the probabilistic graphical model for PML problem, where a directed graph is tailored to infer latent ground-truth labeling information from the generative process of partial multi-label data. Under the framework of stochastic gradient variational Bayes, a unified variational lower bound is derived for this graphical model, which is further relaxed probabilistically so that the desired prediction model can be induced with simultaneously identified ground-truth labeling information. Comprehensive experiments on multiple synthetic and real-world data sets show that our approach outperforms the state-of-the-art counterparts.'}",https://openreview.net{'value': '/pdf/bf43e43bfb70cd65392b4bd1434310c02670f4e2.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=JCN9YsZiwB,{'value': 'Deep Non-line-of-sight Imaging from Under-scanning Measurements'},Yue Li; Yueyi Zhang; Juntian Ye; Feihu Xu; Zhiwei Xiong,~Yue_Li11; ~Yueyi_Zhang2; ~Juntian_Ye1; ~Feihu_Xu1; ~Zhiwei_Xiong1,"{'value': ['Non-line-of-sight imaging', 'Transient Recovery', 'Volume Reconstruction']}","{'value': 'Active confocal non-line-of-sight (NLOS) imaging has successfully enabled seeing around corners relying on high-quality transient measurements. However, acquiring spatial-dense transient measurement is time-consuming, raising the question of how to reconstruct satisfactory results from under-scanning measurements (USM). The existing solutions, involving the traditional algorithms, however, are hindered by unsatisfactory results or long computing times. To this end, we propose the first deep-learning-based approach to NLOS imaging from USM. Our proposed end-to-end network is composed of two main components: the transient recovery network (TRN) and the volume reconstruction network (VRN). Specifically, TRN takes the under-scanning measurements as input, utilizes a multiple kernel feature extraction module and a multiple feature fusion module, and outputs sufficient-scanning measurements at the high-spatial resolution. Afterwards, VRN incorporates the linear physics prior of the light-path transport model and reconstructs the hidden volume representation. Besides, we introduce regularized constraints that enhance the perception of more local details while suppressing smoothing effects. The proposed method achieves superior performance on both synthetic data and public real-world data, as demonstrated by extensive experimental results with different under-scanning grids. Moreover, the proposed method delivers impressive robustness at an extremely low scanning grid (i.e., 8$\\times$8) and offers high-speed inference (i.e., 50 times faster than the existing iterative solution).'}",https://openreview.net{'value': '/pdf/8ca21f507a11f8e3a82499ac31767e5f730c18e5.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=JCCi58IUsh,{'value': 'Grounded Decoding: Guiding Text Generation with Grounded Models for Embodied Agents'},Wenlong Huang; Fei Xia; Dhruv Shah; Danny Driess; Andy Zeng; Yao Lu; Pete Florence; Igor Mordatch; Sergey Levine; Karol Hausman; brian ichter,~Wenlong_Huang1; ~Fei_Xia1; ~Dhruv_Shah1; ~Danny_Driess1; ~Andy_Zeng3; ~Yao_Lu13; ~Pete_Florence1; ~Igor_Mordatch5; ~Sergey_Levine1; ~Karol_Hausman2; ~brian_ichter1,"{'value': ['robotics', 'language models', 'embodied agents']}","{'value': 'Recent progress in large language models (LLMs) has demonstrated the ability to learn and leverage Internet-scale knowledge through pre-training with autoregressive models. Unfortunately, applying such models to settings with embodied agents, such as robots, is challenging due to their lack of experience with the physical world, inability to parse non-language observations, and ignorance of rewards or safety constraints that robots may require. On the other hand, language-conditioned robotic policies that learn from interaction data can provide the necessary grounding that allows the agent to be correctly situated in the real world, but such policies are limited by the lack of high-level semantic understanding due to the limited breadth of the interaction data available for training them. Thus, if we want to make use of the semantic knowledge in a language model while still situating it in an embodied setting, we must construct an action sequence that is both likely according to the language model and also realizable according to grounded models of the environment. We frame this as a problem similar to probabilistic filtering: decode a sequence that both has high probability under the language model and high probability under a set of grounded model objectives. We demonstrate how such grounded models can be obtained across three simulation and real-world domains, and that the proposed decoding strategy is able to solve complex, long-horizon embodiment tasks in a robotic setting by leveraging the knowledge of both models.'}",https://openreview.net{'value': '/pdf/7dc83574bcaf3b1245b01026782fe6b45e8c3b23.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=J1gBijopla,{'value': 'Quantifying & Modeling Multimodal Interactions: An Information Decomposition Framework'},Paul Pu Liang; Yun Cheng; Xiang Fan; Chun Kai Ling; Suzanne Nie; Richard J. Chen; Zihao Deng; Nicholas Allen; Randy Auerbach; Faisal Mahmood; Ruslan Salakhutdinov; Louis-Philippe Morency,~Paul_Pu_Liang1; ~Yun_Cheng2; ~Xiang_Fan1; ~Chun_Kai_Ling2; ~Suzanne_Nie1; ~Richard_J._Chen1; ~Zihao_Deng2; ~Nicholas_Allen1; ~Randy_Auerbach1; ~Faisal_Mahmood1; ~Ruslan_Salakhutdinov1; ~Louis-Philippe_Morency1,"{'value': ['multimodal learning', 'feature interactions', 'partial information decomposition', 'information theory', 'quantification', 'model selection']}","{'value': 'The recent explosion of interest in multimodal applications has resulted in a wide selection of datasets and methods for representing and integrating information from different modalities. Despite these empirical advances, there remain fundamental research questions: How can we quantify the interactions that are necessary to solve a multimodal task? Subsequently, what are the most suitable multimodal models to capture these interactions? To answer these questions, we propose an information-theoretic approach to quantify the degree of redundancy, uniqueness, and synergy relating input modalities with an output task. We term these three measures as the PID statistics of a multimodal distribution (or PID for short), and introduce two new estimators for these PID statistics that scale to high-dimensional distributions. To validate PID estimation, we conduct extensive experiments on both synthetic datasets where the PID is known and on large-scale multimodal benchmarks where PID estimations are compared with human annotations. Finally, we demonstrate their usefulness in (1) quantifying interactions within multimodal datasets, (2) quantifying interactions captured by multimodal models, (3) principled approaches for model selection, and (4) three real-world case studies engaging with domain experts in pathology, mood prediction, and robotic perception where our framework helps to recommend strong multimodal models for each application.'}",https://openreview.net{'value': '/pdf/b13b51ca6ddc73b2e8a80fefc4d109e2e25f9933.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=IrEYkhuxup,{'value': 'Why Did This Model Forecast This Future? Information-Theoretic Saliency for Counterfactual Explanations of Probabilistic Regression Models'},Chirag Raman; Alec Nonnemaker; Amelia Villegas-Morcillo; Hayley Hung; Marco Loog,~Chirag_Raman2; ~Alec_Nonnemaker1; ~Amelia_Villegas-Morcillo1; ~Hayley_Hung2; ~Marco_Loog1,"{'value': ['Probabilistic Forecasting', 'Saliency', 'Explainability', 'XAI', 'Probabilistic Regression']}","{'value': ""We propose a post hoc saliency-based explanation framework for counterfactual reasoning in probabilistic multivariate time-series forecasting (regression) settings. Building upon Miller's framework of explanations derived from research in multiple social science disciplines, we establish a conceptual link between counterfactual reasoning and saliency-based explanation techniques. To address the lack of a principled notion of saliency, we leverage a unifying definition of information-theoretic saliency grounded in preattentive human visual cognition and extend it to forecasting settings. Specifically, we obtain a closed-form expression for commonly used density functions to identify which observed timesteps appear salient to an underlying model in making its probabilistic forecasts. We empirically validate our framework in a principled manner using synthetic data to establish ground-truth saliency that is unavailable for real-world data. Finally, using real-world data and forecasting models, we demonstrate how our framework can assist domain experts in forming new data-driven hypotheses about the causal relationships between features in the wild.""}",https://openreview.net{'value': '/pdf/3538b72ded7628ddb32e8ccced061f9e4dad003f.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=IoizwO1NLf,{'value': 'Skill-it! A data-driven skills framework for understanding and training language models'},Mayee F Chen; Nicholas Roberts; Kush Bhatia; Jue WANG; Ce Zhang; Frederic Sala; Christopher Re,~Mayee_F_Chen1; ~Nicholas_Roberts2; ~Kush_Bhatia3; ~Jue_WANG1; ~Ce_Zhang1; ~Frederic_Sala1; ~Christopher_Re1,"{'value': ['language models', 'data selection']}","{'value': 'The quality of training data impacts the performance of pre-trained large language models (LMs). Given a fixed budget of tokens, we study how to best select data that leads to good downstream model performance across tasks. We develop a new framework based on a simple hypothesis: just as humans acquire interdependent skills in a deliberate order, language models also follow a natural order when learning a set of skills from their training data. If such an order exists, it can be utilized for improved understanding of LMs and for data-efficient training. Using this intuition, our framework formalizes the notion of a skill and of an ordered set of skills in terms of the associated data. First, using both synthetic and real data, we demonstrate that these ordered skill sets exist, and that their existence enables more advanced skills to be learned with less data when we train on their prerequisite skills. Second, using our proposed framework, we introduce an online data sampling algorithm, Skill-It, over mixtures of skills for both continual pre-training and fine-tuning regimes, where the objective is to efficiently learn multiple skills in the former and an individual skill in the latter. On the LEGO synthetic in the continual pre-training setting, Skill-It obtains 37.5 points higher accuracy than random sampling. On the Natural Instructions dataset in the fine-tuning setting, Skill-It reduces the validation loss on the target skill by 13.6% versus training on data associated with the target skill itself. \nWe apply our skills framework on the RedPajama dataset to continually pre-train a 3B-parameter LM, achieving higher accuracy on the LM Evaluation Harness with 1B tokens than the baseline approach of sampling uniformly over data sources with 3B tokens.'}",https://openreview.net{'value': '/pdf/2747b41210c890e7d3d00094c8fe2cc353658f22.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=IdF7VT6eEs,{'value': 'Online Performative Gradient Descent for Learning Nash Equilibria in Decision-Dependent Games'},Zihan Zhu; Ethan X Fang; Zhuoran Yang,~Zihan_Zhu2; ~Ethan_X_Fang1; ~Zhuoran_Yang1,"{'value': ['Performative Prediction', 'Nash Equilibrium', 'Reproducing Kernel Hilbert Space', 'Online Learning', 'Stochastic Gradient Methods']}","{'value': 'We study the multi-agent game within the innovative framework of decision-dependent games, which establishes a feedback mechanism that population data reacts to agents’ actions and further characterizes the strategic interactions between agents. We focus on finding the Nash equilibrium of decision-dependent games in the bandit feedback setting. However, since agents are strategically coupled, traditional gradient-based methods are infeasible without the gradient oracle. To overcome this challenge, we model the strategic interactions by a general parametric model and propose a novel online algorithm, Online Performative Gradient Descent (OPGD), which leverages the ideas of online stochastic approximation and projected gradient descent to learn the Nash equilibrium in the context of function approximation for the unknown gradient. In particular, under mild assumptions on the function classes defined in the parametric model, we prove that OPGD can find the Nash equilibrium efficiently for strongly monotone decision-dependent games. Synthetic numerical experiments validate our theory.'}",https://openreview.net{'value': '/pdf/d2bee81432baefe074b0f842aff2433e4d62772a.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Ia4dmqst0Z,{'value': 'ResoNet: Noise-Trained Physics-Informed MRI Off-Resonance Correction'},Alfredo De Goyeneche; Shreya Ramachandran; Ke Wang; Ekin Karasan; Joseph Yitan Cheng; Stella X. Yu; Michael Lustig,~Alfredo_De_Goyeneche1; ~Shreya_Ramachandran1; ~Ke_Wang8; ~Ekin_Karasan1; ~Joseph_Yitan_Cheng1; ~Stella_X._Yu2; ~Michael_Lustig2,"{'value': ['Inverse problem', 'MRI', 'Medical Imaging', 'Computational Imaging', 'Deep Learning', 'Off-Resonance']}","{'value': 'Magnetic Resonance Imaging (MRI) is a powerful medical imaging modality that offers diagnostic information without harmful ionizing radiation. Unlike optical imaging, MRI sequentially samples the spatial Fourier domain (k-space) of the image. \nMeasurements are collected in multiple shots, or readouts, and in each shot, data along a smooth trajectory is sampled.\nConventional MRI data acquisition relies on sampling k-space row-by-row in short intervals, which is slow and inefficient. More efficient, non-Cartesian sampling trajectories (e.g., Spirals) use longer data readout intervals, but are more susceptible to magnetic field inhomogeneities, leading to off-resonance artifacts. Spiral trajectories cause off-resonance blurring in the image, and the mathematics of this blurring resembles that of optical blurring, where magnetic field variation corresponds to depth and readout duration to aperture size. Off-resonance blurring is a system issue with a physics-based, accurate forward model. We present a physics-informed deep learning framework for off-resonance correction in MRI, which is trained exclusively on synthetic, noise-like data with representative marginal statistics. Our approach allows for fat/water separation and is compatible with parallel imaging acceleration. Through end-to-end training using synthetic randomized data (i.e., noise-like images, coil sensitivities, field maps), we train the network to reverse off-resonance effects across diverse anatomies and contrasts without retraining. We demonstrate the effectiveness of our approach through results on phantom and in-vivo data. This work has the potential to facilitate the clinical adoption of non-Cartesian sampling trajectories, enabling efficient, rapid, and motion-robust MRI scans. Code is publicly available at: https://github.com/mikgroup/ResoNet.'}",https://openreview.net{'value': '/pdf/f827572ebe7ad355680c0e8109e7a7c96f9e4971.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=IQRc3FrYOG,{'value': 'Mutual-Information Regularized Multi-Agent Policy Iteration'},Jiangxing Wang; Deheng Ye; Zongqing Lu,~Jiangxing_Wang2; ~Deheng_Ye1; ~Zongqing_Lu2,{'value': ['Multi-Agent Reinforcement Learning']},"{'value': 'Despite the success of cooperative multi-agent reinforcement learning algorithms, most of them focus on a single team composition, which prevents them from being used in more realistic scenarios where dynamic team composition is possible. While some studies attempt to solve this problem via multi-task learning in a fixed set of team compositions, there is still a risk of overfitting to the training set, which may lead to catastrophic performance when facing dramatically varying team compositions during execution. To address this problem, we propose to use mutual information (MI) as an augmented reward to prevent individual policies from relying too much on team-related information and encourage agents to learn policies that are robust in different team compositions. Optimizing this MI-augmented objective in an off-policy manner can be intractable due to the existence of dynamic marginal distribution. To alleviate this problem, we first propose a multi-agent policy iteration algorithm with a fixed marginal distribution and prove its convergence and optimality. Then, we propose to employ the Blahut–Arimoto algorithm and an imaginary team composition distribution for optimization with approximate marginal distribution as the practical implementation. Empirically, our method demonstrates strong zero-shot generalization to dynamic team compositions in complex cooperative tasks.'}",https://openreview.net{'value': '/pdf/7b3b9cbba45a5608bea1b8e0f7e6b50c7a11f6e5.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=IMiGRqltQQ,{'value': '“Why Not Looking backward?” A Robust Two-Step Method to Automatically Terminate Bayesian Optimization'},Shuang Li; Ke Li; Wei Li,~Shuang_Li12; ~Ke_Li5; ~Wei_Li72,"{'value': ['Bayesian Optimization', 'Termination Criterion', 'Looking Backward']}","{'value': 'Bayesian Optimization (BO) is a powerful method for tackling expensive black-box optimization problems. As a sequential model-based optimization strategy, BO iteratively explores promising solutions until a predetermined budget, either iterations or time, is exhausted. The decision on when to terminate BO significantly influences both the quality of solutions and its computational efficiency. In this paper, we propose a simple, yet theoretically grounded, two-step method for automatically terminating BO. Our core concept is to proactively identify if the search is within a convex region by examining previously observed samples. BO is halted once the local regret within this convex region falls below a predetermined threshold. To enhance numerical stability, we propose an approximation method for calculating the termination indicator by solving a bilevel optimization problem. We conduct extensive empirical studies on diverse benchmark problems, including synthetic functions, reinforcement learning, and hyperparameter optimization. Experimental results demonstrate that our proposed method saves up to $\\approx 80\\%$ computational budget yet is with an order of magnitude smaller performance degradation, comparing against the other peer methods. In addition, our proposed termination method is robust in terms of the setting of its termination criterion.'}",https://openreview.net{'value': '/pdf/c40e4eb712eb2a8ff0a5f9b560f27b3162bfa2a2.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=IJblKO45YU,{'value': 'Goal-Conditioned Predictive Coding for Offline Reinforcement Learning'},Zilai Zeng; Ce Zhang; Shijie Wang; Chen Sun,~Zilai_Zeng1; ~Ce_Zhang7; ~Shijie_Wang2; ~Chen_Sun1,"{'value': ['reinforcement learning', 'offline RL', 'self-supervised learning']}","{'value': 'Recent work has demonstrated the effectiveness of formulating decision making as supervised learning on offline-collected trajectories. Powerful sequence models, such as GPT or BERT, are often employed to encode the trajectories. However, the benefits of performing sequence modeling on trajectory data remain unclear. In this work, we investigate whether sequence modeling has the ability to condense trajectories into useful representations that enhance policy learning. We adopt a two-stage framework that first leverages sequence models to encode trajectory-level representations, and then learns a goal-conditioned policy employing the encoded representations as its input. This formulation allows us to consider many existing supervised offline RL methods as specific instances of our framework. Within this framework, we introduce Goal-Conditioned Predictive Coding (GCPC), a sequence modeling objective that yields powerful trajectory representations and leads to performant policies. Through extensive empirical evaluations on AntMaze, FrankaKitchen and Locomotion environments, we observe that sequence modeling can have a significant impact on challenging decision making tasks. Furthermore, we demonstrate that GCPC learns a goal-conditioned latent representation encoding the future trajectory, which enables competitive performance on all three benchmarks.'}",https://openreview.net{'value': '/pdf/66ff9d643d53377df4ee9d7714864183574a7cf2.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=IHR83ufYPy,{'value': 'Leveraging sparse and shared feature activations for disentangled representation learning'},Marco Fumero; Florian Wenzel; Luca Zancato; Alessandro Achille; Emanuele Rodolà; Stefano Soatto; Bernhard Schölkopf; Francesco Locatello,~Marco_Fumero1; ~Florian_Wenzel1; ~Luca_Zancato1; ~Alessandro_Achille1; ~Emanuele_Rodolà1; ~Stefano_Soatto3; ~Bernhard_Schölkopf1; ~Francesco_Locatello1,"{'value': ['disentanglement', 'OOD generalization', 'multitask learning']}","{'value': 'Recovering the latent factors of variation of high dimensional data has so far focused on simple synthetic settings. Mostly building on unsupervised and weakly-supervised objectives, prior work missed out on the positive implications for representation learning on real world data. In this work, we propose to leverage knowledge extracted from a diversified set of supervised tasks to learn a common disentangled representation. Assuming each supervised task only depends on an unknown subset of the factors of variation, we disentangle the feature space of a supervised multi-task model, with features activating sparsely across different tasks and information being shared as appropriate. Importantly, we never directly observe the factors of variations but establish that access to multiple tasks is sufficient for identifiability under sufficiency and minimality assumptions.\nWe validate our approach on six real world distribution shift benchmarks, and different data modalities (images, text), demonstrating how disentangled representations can be transferred to real settings.'}",https://openreview.net{'value': '/pdf/a4d438d017564bfbabefcfc12facd422953e9222.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=IEMLNF4gK4,{'value': 'SHAP-IQ: Unified Approximation of any-order Shapley Interactions'},Fabian Fumagalli; Maximilian Muschalik; Patrick Kolpaczki; Eyke Hüllermeier; Barbara Hammer,~Fabian_Fumagalli1; ~Maximilian_Muschalik1; ~Patrick_Kolpaczki1; ~Eyke_Hüllermeier1; ~Barbara_Hammer4,"{'value': ['Explainable Artificial Intelligence', 'Feature Interaction', 'Shapley Interaction', 'Shapley Value']}","{'value': 'Predominately in explainable artificial intelligence (XAI) research, the Shapley value (SV) is applied to determine feature attributions for any black box model. Shapley interaction indices extend the SV to define any-order feature interactions. Defining a unique Shapley interaction index is an open research question and, so far, three definitions have been proposed, which differ by their choice of axioms. Moreover, each definition requires a specific approximation technique. Here, we propose SHAPley Interaction Quantification (SHAP-IQ), an efficient sampling-based approximator to compute Shapley interactions for arbitrary cardinal interaction indices (CII), i.e. interaction indices that satisfy the linearity, symmetry and dummy axiom. SHAP-IQ is based on a novel representation and, in contrast to existing methods, we provide theoretical guarantees for its approximation quality, as well as estimates for the variance of the point estimates. For the special case of SV, our approach reveals a novel representation of the SV and corresponds to Unbiased KernelSHAP with a greatly simplified calculation. We illustrate the computational efficiency and effectiveness by explaining language, image classification and high-dimensional synthetic models.'}",https://openreview.net{'value': '/pdf/ad9dd10721dfdc7aec1878ddd33f899345abc62d.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=I9GNrInbdf,{'value': 'Formulating Discrete Probability Flow Through Optimal Transport'},Pengze Zhang; Hubery Yin; Chen Li; Xiaohua Xie,~Pengze_Zhang1; ~Hubery_Yin1; ~Chen_Li11; ~Xiaohua_Xie1,"{'value': ['Discrete Probability Flow', 'Optimal Transport']}","{'value': 'Continuous diffusion models are commonly acknowledged to display a deterministic probability flow, whereas discrete diffusion models do not. In this paper, we aim to establish the fundamental theory for the probability flow of discrete diffusion models. Specifically, we first prove that the continuous probability flow is the Monge optimal transport map under certain conditions, and also present an equivalent evidence for discrete cases.  In view of these findings, we are then able to define the discrete probability flow in line with the principles of optimal transport. Finally, drawing upon our newly established definitions, we propose a novel sampling method that surpasses previous discrete diffusion models in its ability to generate more certain outcomes. Extensive experiments on the synthetic toy dataset and the CIFAR-10 dataset have validated the effectiveness of our proposed discrete probability flow. Code is released at: https://github.com/PangzeCheung/Discrete-Probability-Flow.'}",https://openreview.net{'value': '/pdf/4b0b62652c3a51071d52c54921c52cf9a39c590c.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=HvhagNdf5z,{'value': 'Synthetic-to-Real Pose Estimation with Geometric Reconstruction'},Qiuxia Lin; Kerui Gu; Linlin Yang; Angela Yao,~Qiuxia_Lin1; ~Kerui_Gu1; ~Linlin_Yang1; ~Angela_Yao1,"{'value': ['pose estimation', 'domain adaptation']}","{'value': 'Pose estimation is remarkably successful under supervised learning, but obtaining annotations, especially for new deployments, is costly and time-consuming. This work tackles adapting models trained on synthetic data to real-world target domains with only unlabelled data. A common approach is model fine-tuning with pseudo-labels from the target domain; yet many pseudo-labelling strategies cannot provide sufficient high-quality pose labels. This work proposes a reconstruction-based strategy as a complement to pseudo-labelling for synthetic-to-real domain adaptation. We generate the driving image by geometrically transforming a base image according to the predicted keypoints and enforce a reconstruction loss to refine the predictions. It provides a novel solution to effectively correct confident yet inaccurate keypoint locations through image reconstruction in domain adaptation. Our approach outperforms the previous state-of-the-arts by 8% for PCK on four large-scale hand and human real-world datasets. In particular, we excel on endpoints such as fingertips and head, with 7.2% and 29.9% improvements in PCK.'}",https://openreview.net{'value': '/pdf/bffd733896d24f662ad7f1840da7bcbce7839bc9.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Ht79ZTVMsn,{'value': 'Addressing the speed-accuracy simulation trade-off for adaptive spiking neurons'},Luke Taylor; Andrew J King; Nicol Spencer Harper,~Luke_Taylor1; ~Andrew_J_King1; ~Nicol_Spencer_Harper1,"{'value': ['spiking neural network', 'surrogate gradient descent', 'adaptive leaky integrate and fire neuron', 'speed-accuracy trade-off', 'electrophysiological recordings']}","{'value': 'The adaptive leaky integrate-and-fire (ALIF) model is fundamental within computational neuroscience and has been instrumental in studying our brains $\\textit{in silico}$. Due to the sequential nature of simulating these neural models, a commonly faced issue is the speed-accuracy trade-off: either accurately simulate a neuron using a small discretisation time-step (DT), which is slow, or more quickly simulate a neuron using a larger DT and incur a loss in simulation accuracy. Here we provide a solution to this dilemma, by algorithmically reinterpreting the ALIF model, reducing the sequential simulation complexity and permitting a more efficient parallelisation on GPUs. We computationally validate our implementation to obtain over a $50\\times$ training speedup using small DTs on synthetic benchmarks. We also obtained a comparable performance to the standard ALIF implementation on different supervised classification tasks - yet in a fraction of the training time. Lastly, we showcase how our model makes it possible to quickly and accurately fit real electrophysiological recordings of cortical neurons, where very fine sub-millisecond DTs are crucial for capturing exact spike timing.'}",https://openreview.net{'value': '/pdf/e7f24d624356157f86080372611572dd115346c7.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=HszLRiHyfO,{'value': 'Causal Component Analysis'},Wendong Liang; Armin Kekić; Julius von Kügelgen; Simon Buchholz; Michel Besserve; Luigi Gresele; Bernhard Schölkopf,~Wendong_Liang1; ~Armin_Kekić1; ~Julius_von_Kügelgen2; ~Simon_Buchholz1; ~Michel_Besserve1; ~Luigi_Gresele1; ~Bernhard_Schölkopf1,"{'value': ['Causality', 'independent component analysis', 'causal inference', 'interventions', 'latent variable models', 'identifiability']}","{'value': 'Independent Component Analysis (ICA) aims to recover independent latent variables from observed mixtures thereof. Causal Representation Learning (CRL) aims instead to infer causally related (thus often statistically _dependent_) latent variables, together with the unknown graph encoding their causal relationships. We introduce an intermediate problem termed _Causal Component Analysis (CauCA)_. CauCA can be viewed as a generalization of ICA, modelling the causal dependence among the latent components, and as a special case of CRL. In contrast to CRL, it presupposes knowledge of the causal graph, focusing solely on learning the unmixing function and the causal mechanisms. Any impossibility results regarding the recovery of the ground truth in CauCA also apply for CRL, while possibility results may serve as a stepping stone for extensions to CRL. We characterize CauCA identifiability from multiple datasets generated through different types of interventions on the latent causal variables. As a corollary, this interventional perspective also leads to new identifiability results for nonlinear ICA—a special case of CauCA with an empty graph—requiring strictly fewer datasets than previous results. We introduce a likelihood-based approach using normalizing flows to estimate both the unmixing function and the causal mechanisms, and demonstrate its effectiveness through extensive synthetic experiments in the CauCA and ICA setting.'}",https://openreview.net{'value': '/pdf/d77866239c5cd0912f3815941a80e70b73d03c71.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=HUuEMMM8Ik,{'value': 'Detecting hidden confounding in observational data using multiple environments'},Rickard Karlsson; JH Krijthe,~Rickard_Karlsson1; ~JH_Krijthe1,"{'value': ['causal inference', 'hidden confounding', 'multiple environments', 'independent causal mechansisms', 'independence testing']}","{'value': 'A common assumption in causal inference from observational data is that there is no hidden confounding. Yet it is, in general, impossible to verify the presence of hidden confounding factors from a single dataset. Under the assumption of independent causal mechanisms underlying the data-generating process, we demonstrate a way to detect unobserved confounders when having multiple observational datasets coming from different environments. We present a theory for testable conditional independencies that are only absent when there is hidden confounding and examine cases where we violate its assumptions: degenerate & dependent mechanisms, and faithfulness violations. Additionally, we propose a procedure to test these independencies and study its empirical finite-sample behavior using simulation studies and semi-synthetic data based on a real-world dataset. In most cases, the proposed procedure correctly predicts the presence of hidden confounding, particularly when the confounding bias is large.'}",https://openreview.net{'value': '/pdf/e4c64183a6e812c986319a1e63c604d0dc7523d1.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=GxL6PrmEUw,{'value': 'Distributional Learning of Variational AutoEncoder: Application to Synthetic Data Generation'},Seunghwan An; Jong-June Jeon,~Seunghwan_An2; ~Jong-June_Jeon1,"{'value': ['Variational AutoEncoder', 'distributional learning', 'synthetic data generation', 'CRPS', 'asymmetric Laplace distribution']}","{'value': ""The Gaussianity assumption has been consistently criticized as a main limitation of the Variational Autoencoder (VAE) despite its efficiency in computational modeling. In this paper, we propose a new approach that expands the model capacity (i.e., expressive power of distributional family) without sacrificing the computational advantages of the VAE framework. Our VAE model's decoder is composed of an infinite mixture of asymmetric Laplace distribution, which possesses general distribution fitting capabilities for continuous variables. Our model is represented by a special form of a nonparametric M-estimator for estimating general quantile functions, and we theoretically establish the relevance between the proposed model and quantile estimation. We apply the proposed model to synthetic data generation, and particularly, our model demonstrates superiority in easily adjusting the level of data privacy.""}",https://openreview.net{'value': '/pdf/b4dfb0d75b227381d2742fee2a9220e899687d9c.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Gtse4R6iS4,{'value': 'Robustifying Generalizable Implicit Shape Networks with a Tunable Non-Parametric Model'},Amine Ouasfi; Adnane Boukhayma,~Amine_Ouasfi1; ~Adnane_Boukhayma2,"{'value': ['implicit neural representations', '3D reconstruction from unoriented point could', 'kernel ridge regression']}","{'value': 'Feedforward generalizable models for implicit shape reconstruction from unoriented point cloud present multiple advantages, including high performance and inference speed. However, they still suffer from generalization issues, ranging from underfitting the input point cloud, to misrepresenting samples outside of the training data distribution, or with toplogies unseen at training.  We propose here an efficient mechanism to remedy some of these limitations at test time. We combine the inter-shape data prior of the network with an intra-shape regularization prior of a Nyström Kernel Ridge Regression, that we further adapt by fitting its hyperprameters to the current shape. The resulting shape function defined in a shape specific Reproducing Kernel Hilbert Space benefits from desirable stability and efficiency properties and grants a shape adaptive expressiveness-robustness trade-off. We demonstrate the improvement obtained through our method  with respect to baselines and the state-of-the-art using synthetic and real data.'}",https://openreview.net{'value': '/pdf/9c3f0b9ccd2dfe797ba09091407ea8011896a02f.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=GjJRbEZ1dc,{'value': 'Multitask Learning with No Regret: from Improved Confidence Bounds to Active Learning'},Pier Giuseppe Sessa; Pierre Laforgue; Nicolò Cesa-Bianchi; Andreas Krause,~Pier_Giuseppe_Sessa1; ~Pierre_Laforgue1; ~Nicolò_Cesa-Bianchi1; ~Andreas_Krause1,"{'value': ['multitask learning', 'confidence intervals', 'online learning theory', 'active learning', 'regret']}","{'value': ""Multitask learning is a powerful framework that enables one to simultaneously learn multiple related tasks by sharing information between them. Quantifying uncertainty in the estimated tasks is of pivotal importance for many downstream applications, such as online or active learning. In this work, we provide novel confidence intervals for multitask regression in the challenging agnostic setting, i.e., when neither the similarity between tasks nor the tasks' features are available to the learner. The obtained intervals do not require i.i.d. data and can be directly applied to bound the regret in online learning. Through a refined analysis of the multitask information gain, we obtain new regret guarantees that, depending on a task similarity parameter, can significantly improve over treating tasks independently. We further propose a novel online learning algorithm that achieves such improved regret without knowing this parameter in advance, i.e., automatically adapting to task similarity. As a second key application of our results, we introduce a novel multitask active learning setup where several tasks must be simultaneously optimized, but only one of them can be queried for feedback by the learner at each round. For this problem, we design a no-regret algorithm that uses our confidence intervals to decide which task should be queried. Finally, we empirically validate our bounds and algorithms on synthetic and real-world (drug discovery) data.""}",https://openreview.net{'value': '/pdf/3218199bdb9adece68c3672cf898cd8d98dbece6.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Gij638d76O,{'value': 'Neural Latent Geometry Search: Product Manifold Inference via Gromov-Hausdorff-Informed Bayesian Optimization'},Haitz Sáez de Ocáriz Borde; Alvaro Arroyo; Ismael Morales López; Ingmar Posner; Xiaowen Dong,~Haitz_Sáez_de_Ocáriz_Borde1; ~Alvaro_Arroyo1; ismael.morales@hertford.ox.ac.uk; ~Ingmar_Posner1; ~Xiaowen_Dong1,"{'value': ['Representation Learning', 'Product Manifolds', 'Bayesian Optimization', 'Gromov-Hausdorff Distance']}","{'value': 'Recent research indicates that the performance of machine learning models can be improved by aligning the geometry of the latent space with the underlying data structure. Rather than relying solely on Euclidean space, researchers have proposed using hyperbolic and spherical spaces with constant curvature, or combinations thereof, to better model the latent space and enhance model performance. However, little attention has been given to the problem of automatically identifying the optimal latent geometry for the downstream task. We mathematically define this novel formulation and coin it as neural latent geometry search (NLGS). More specifically, we introduce an initial attempt to search for a latent geometry composed of a product of constant curvature model spaces with a small number of query evaluations, under some simplifying assumptions. To accomplish this, we propose a novel notion of distance between candidate latent geometries based on the Gromov-Hausdorff distance from metric geometry. In order to compute the Gromov-Hausdorff distance, we introduce a mapping function that enables the comparison of different manifolds by embedding them in a common high-dimensional ambient space. We then design a graph search space based on the notion of smoothness between latent geometries and employ the calculated distances as an additional inductive bias. Finally, we use Bayesian optimization to search for the optimal latent geometry in a query-efficient manner. This is a general method which can be applied to search for the optimal latent geometry for a variety of models and downstream tasks. We perform experiments on synthetic and real-world datasets to identify the optimal latent geometry for multiple machine learning problems.'}",https://openreview.net{'value': '/pdf/ecac30b142818450cdd50b8a94f6d321cc1be1f4.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=GiUe0ZFiVe,{'value': 'Bi-Level Offline Policy Optimization with Limited Exploration'},Wenzhuo Zhou,~Wenzhuo_Zhou1,"{'value': ['Offline Reinforcement Learning', 'Sample Efficiency', 'Regret Bound', 'Data Coverage']}","{'value': ""We study offline reinforcement learning (RL) which seeks to learn a good policy based on a fixed, pre-collected dataset. A fundamental challenge behind this task is the distributional shift due to the dataset lacking sufficient exploration, especially under function approximation. To tackle this issue, we propose a bi-level structured policy optimization algorithm that models a hierarchical interaction between the policy (upper-level) and the value function (lower-level). The lower level focuses on constructing a confidence set of value estimates that maintain sufficiently small weighted average Bellman errors, while controlling uncertainty arising from distribution mismatch. Subsequently, at the upper level, the policy aims to maximize a conservative value estimate from the confidence set formed at the lower level. This novel formulation preserves the maximum flexibility of the implicitly induced exploratory data distribution, enabling the power of model extrapolation. In practice, it can be solved through a computationally efficient, penalized adversarial estimation procedure. Our theoretical regret guarantees do not rely on any data-coverage and completeness-type assumptions, only requiring realizability. These guarantees also demonstrate that the learned policy represents the ``best effort'' among all policies, as no other policies can outperform it. We evaluate our model using a blend of synthetic, benchmark, and real-world datasets for offline RL, showing that it performs competitively with state-of-the-art methods.""}",https://openreview.net{'value': '/pdf/0b203af29f5b3c9dde37eeaa91e21bf316700021.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Gh67ZZ6zkS,{'value': 'PreDiff: Precipitation Nowcasting with Latent Diffusion Models'},Zhihan Gao; Xingjian Shi; Boran Han; Hao Wang; Xiaoyong Jin; Danielle C. Maddix; Yi Zhu; Mu Li; Bernie Wang,~Zhihan_Gao1; ~Xingjian_Shi1; ~Boran_Han1; ~Hao_Wang3; ~Xiaoyong_Jin1; ~Danielle_C._Maddix1; ~Yi_Zhu1; ~Mu_Li4; ~Bernie_Wang1,"{'value': ['Machine Learning for Earth Science', 'Spatiotemporal Forecasting', 'Generative Models', 'Diffusion Models']}","{'value': 'Earth system forecasting has traditionally relied on complex physical models that are computationally expensive and require significant domain expertise.\nIn the past decade, the unprecedented increase in spatiotemporal Earth observation data has enabled data-driven forecasting models using deep learning techniques.\nThese models have shown promise for diverse Earth system forecasting tasks but either struggle with handling uncertainty or neglect domain-specific prior knowledge, resulting in averaging possible futures to blurred forecasts or generating physically implausible predictions.\nTo address these limitations, we propose a two-stage pipeline for probabilistic spatiotemporal forecasting: 1) We develop *PreDiff*, a conditional latent diffusion model capable of probabilistic forecasts. 2) We incorporate an explicit knowledge alignment mechanism to align forecasts with domain-specific physical constraints. \nThis is achieved by estimating the deviation from imposed constraints at each denoising step and adjusting the transition distribution accordingly.\nWe conduct empirical studies on two datasets: N-body MNIST, a synthetic dataset with chaotic behavior, and SEVIR, a real-world precipitation nowcasting dataset. \nSpecifically, we impose the law of conservation of energy in N-body MNIST and anticipated precipitation intensity in SEVIR. \nExperiments demonstrate the effectiveness of PreDiff in handling uncertainty, incorporating domain-specific prior knowledge, and generating forecasts that exhibit high operational utility.'}",https://openreview.net{'value': '/pdf/f59de76b3a7e0e1f83153cb78506f89dbcf015c8.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=GJtP1ZEzua,{'value': 'D4Explainer: In-distribution Explanations of Graph Neural Network via Discrete Denoising Diffusion'},Jialin Chen; Shirley Wu; Abhijit Gupta; Zhitao Ying,~Jialin_Chen2; ~Shirley_Wu1; ~Abhijit_Gupta1; ~Zhitao_Ying1,"{'value': ['Explainability', 'Graph Neural Network', 'Diffusion Model']}","{'value': 'The widespread deployment of Graph Neural Networks (GNNs) sparks significant interest in their explainability, which plays a vital role in model auditing and ensuring trustworthy graph learning. The objective of GNN explainability is to discern the underlying graph structures that have the most significant impact on model predictions. Ensuring that explanations generated are reliable necessitates consideration of the in-distribution property, particularly due to the vulnerability of GNNs to out-of-distribution data. Unfortunately, prevailing explainability methods tend to constrain the generated explanations to the structure of the original graph, thereby downplaying the significance of the in-distribution property and resulting in explanations that lack reliability.\nTo address these challenges, we propose D4Explainer, a novel approach that provides in-distribution GNN explanations for both counterfactual and model-level explanation scenarios. The proposed D4Explainer incorporates generative graph distribution learning into the optimization objective, which accomplishes two goals: 1) generate a collection of diverse counterfactual graphs that conform to the in-distribution property for a given instance, and 2) identify the most discriminative graph patterns that contribute to a specific class prediction, thus serving as model-level explanations. It is worth mentioning that D4Explainer is the first unified framework that combines both counterfactual and model-level explanations.\nEmpirical evaluations conducted on synthetic and real-world datasets provide compelling evidence of the state-of-the-art performance achieved by D4Explainer in terms of explanation accuracy, faithfulness, diversity, and robustness.'}",https://openreview.net{'value': '/pdf/8ba69e911039af2e1511df3de684d821ea40942b.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=GItLpB1vhK,{'value': 'Estimating Koopman operators with sketching to provably learn large scale dynamical systems'},Giacomo Meanti; Antoine Chatalic; Vladimir R Kostic; Pietro Novelli; Massimiliano Pontil; Lorenzo Rosasco,~Giacomo_Meanti1; ~Antoine_Chatalic1; ~Vladimir_R_Kostic1; ~Pietro_Novelli1; ~Massimiliano_Pontil4; ~Lorenzo_Rosasco1,"{'value': ['dynamical systems', 'kernel methods', 'koopman operator', 'sketching', 'molecular dynamics', 'efficient machine learning']}","{'value': ""The theory of Koopman operators allows to deploy non-parametric machine learning algorithms to predict and analyze complex dynamical systems.\nEstimators such as principal component regression (PCR) or reduced rank regression (RRR) in kernel spaces can be shown to provably learn Koopman operators from finite empirical observations of the system's time evolution. \nScaling these approaches to very long trajectories is a challenge and requires introducing suitable approximations to make computations feasible. \nIn this paper, we boost the efficiency of \ndifferent kernel-based Koopman operator estimators using random projections (sketching).\nWe derive, implement and test the new ``sketched'' estimators with extensive experiments on synthetic and large-scale molecular dynamics datasets. \nFurther, we establish non asymptotic error bounds giving a sharp characterization of the trade-offs between statistical learning rates and computational efficiency.\nOur empirical and theoretical analysis shows that the proposed estimators provide a sound and efficient way to learn large scale dynamical systems.\nIn particular our experiments indicate that the proposed estimators retain the same accuracy of PCR or RRR, while being much faster.""}",https://openreview.net{'value': '/pdf/c1b736e72959b41fb100dafcb870a51da9629c9c.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=GEtXhqKW6X,{'value': 'iSCAN: Identifying Causal Mechanism Shifts among Nonlinear Additive Noise Models'},Tianyu Chen; Kevin Bello; Bryon Aragam; Pradeep Kumar Ravikumar,tianyuchen@uchicago.edu; ~Kevin_Bello1; ~Bryon_Aragam1; ~Pradeep_Kumar_Ravikumar1,"{'value': ['distribution shifts', 'heterogeneous data', 'feature-shift', 'structural causal models', 'additive noise models', 'causality', 'root-cause analysis']}","{'value': 'Structural causal models (SCMs) are widely used in various disciplines to represent causal relationships among variables in complex systems.\nUnfortunately, the underlying causal structure is often unknown, and estimating it from data remains a challenging task. \nIn many situations, however, the end goal is to localize the changes (shifts) in the causal mechanisms between related datasets instead of learning the full causal structure of the individual datasets. \nSome applications include root cause analysis, analyzing gene regulatory network structure changes between healthy and cancerous individuals, or explaining distribution shifts. \nThis paper focuses on identifying the causal mechanism shifts in two or more related datasets over the same set of variables---*without estimating the entire DAG structure of each SCM*.\nPrior work under this setting assumed linear models with Gaussian noises; instead, in this work we assume that each SCM belongs to the more general class of *nonlinear* additive noise models (ANMs).\nA key technical contribution of this work is to show that the Jacobian of the score function for the *mixture distribution* allows for the identification of shifts under general non-parametric functional mechanisms.\nOnce the shifted variables are identified, we leverage recent work to estimate the structural differences, if any, for the shifted variables.\nExperiments on synthetic and real-world data are provided to showcase the applicability of this approach.\nCode implementing the proposed method is open-source and publicly available at  https://github.com/kevinsbello/iSCAN.'}",https://openreview.net{'value': '/pdf/7c90d0db006cc54e295a515facab929854ccd995.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=G8nal7MpIQ,{'value': 'Guide Your Agent with Adaptive Multimodal Rewards'},Changyeon Kim; Younggyo Seo; Hao Liu; Lisa Lee; Jinwoo Shin; Honglak Lee; Kimin Lee,~Changyeon_Kim1; ~Younggyo_Seo1; ~Hao_Liu1; ~Lisa_Lee1; ~Jinwoo_Shin1; ~Honglak_Lee2; ~Kimin_Lee1,"{'value': ['Reinforcement Learning', 'Multimodal Representation', 'Imitation Learning']}","{'value': ""Developing an agent capable of adapting to unseen environments remains a difficult challenge in imitation learning. This work presents Adaptive Return-conditioned Policy (ARP), an efficient framework designed to enhance the agent's generalization ability using natural language task descriptions and pre-trained multimodal encoders. Our key idea is to calculate a similarity between visual observations and natural language instructions in the pre-trained multimodal embedding space (such as CLIP) and use it as a reward signal. We then train a return-conditioned policy using expert demonstrations labeled with multimodal rewards. Because the multimodal rewards provide adaptive signals at each timestep, our ARP effectively mitigates the goal misgeneralization. This results in superior generalization performances even when faced with unseen text instructions, compared to existing text-conditioned policies. To improve the quality of rewards, we also introduce a fine-tuning method for pre-trained multimodal encoders, further enhancing the performance. Video demonstrations and source code are available on the project website: \\url{https://sites.google.com/view/2023arp}.""}",https://openreview.net{'value': '/pdf/7b5068134f25b8c88db8899c8f7e18072b72f7d8.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=G560qr59Gi,{'value': 'Implicit Bias of Gradient Descent for Two-layer ReLU and Leaky ReLU Networks on Nearly-orthogonal Data'},Yiwen Kou; Zixiang Chen; Quanquan Gu,~Yiwen_Kou1; ~Zixiang_Chen1; ~Quanquan_Gu1,"{'value': ['ReLU Neural Networks', 'Implicit Bias', 'Deep Learning Theory']}","{'value': 'The implicit bias towards solutions with favorable properties is believed to be a key reason why neural networks trained by gradient-based optimization can generalize well. While the implicit bias of gradient flow has been widely studied for homogeneous neural networks (including ReLU and leaky ReLU networks), the implicit bias of gradient descent is currently only understood for smooth neural networks. Therefore, implicit bias in non-smooth neural networks trained by gradient descent remains an open question. In this paper, we aim to answer this question by studying the implicit bias of gradient descent for training two-layer fully connected (leaky) ReLU neural networks. We showed that when the training data are nearly-orthogonal, for leaky ReLU activation function, gradient descent will find a network with a stable rank that converges to $1$, whereas for ReLU activation function, gradient descent will find a neural network with a stable rank that is upper bounded by a constant. Additionally, we show that gradient descent will find a neural network such that all the training data points have the same normalized margin asymptotically. Experiments on both synthetic and real data backup our theoretical findings.'}",https://openreview.net{'value': '/pdf/ab6b7def82367ec50b43c91fafc7fc8dfb91384b.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=FskZtRvMJI,{'value': 'RiskQ: Risk-sensitive Multi-Agent Reinforcement Learning Value Factorization'},Siqi Shen; Chennan Ma; Chao Li; Weiquan Liu; Yongquan Fu; Songzhu Mei; Xinwang Liu; Cheng Wang,~Siqi_Shen5; ~Chennan_Ma1; ~Chao_Li29; ~Weiquan_Liu1; ~Yongquan_Fu2; ~Songzhu_Mei1; ~Xinwang_Liu1; ~Cheng_Wang2,"{'value': ['multi-agent reinforcement learning', 'value factorization', 'individual global max', 'risk-sensitive']}","{'value': 'Multi-agent systems are characterized by environmental uncertainty, varying policies of agents, and partial observability, which result in significant risks. In the context of Multi-Agent Reinforcement Learning (MARL), learning coordinated and decentralized policies that are sensitive to risk is challenging. To formulate the coordination requirements in risk-sensitive MARL, we introduce the Risk-sensitive Individual-Global-Max (RIGM) principle as a generalization of the Individual-Global-Max (IGM) and Distributional IGM (DIGM) principles. This principle requires that the collection of risk-sensitive action selections of each agent should be equivalent to the risk-sensitive action selection of the central policy. Current MARL value factorization methods do not satisfy the RIGM principle for common risk metrics such as the Value at Risk (VaR) metric or distorted risk measurements. Therefore, we propose RiskQ to address this limitation, which models the joint return distribution by modeling quantiles of it as weighted quantile mixtures of per-agent return distribution utilities. RiskQ satisfies the RIGM principle for the VaR and distorted risk metrics. We show that RiskQ can obtain promising performance through extensive experiments. The source code of RiskQ is available in https://github.com/xmu-rl-3dv/RiskQ.'}",https://openreview.net{'value': '/pdf/304803860d3360243875995a5251d8a5474d612d.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Fp5uC6YHwe,{'value': '3D-IntPhys: Towards More Generalized 3D-grounded Visual Intuitive Physics under Challenging Scenes'},Haotian Xue; Antonio Torralba; Joshua B. Tenenbaum; Daniel LK Yamins; Yunzhu Li; Hsiao-Yu Tung,~Haotian_Xue1; ~Antonio_Torralba1; ~Joshua_B._Tenenbaum1; ~Daniel_LK_Yamins1; ~Yunzhu_Li1; ~Hsiao-Yu_Tung1,"{'value': ['Intuitive Physics', 'Computer Vision']}","{'value': 'Given a visual scene, humans have strong intuitions about how a scene can evolve over time under given actions. The intuition, often termed visual intuitive physics, is a critical ability that allows us to make effective plans to manipulate the scene to achieve desired outcomes without relying on extensive trial and error. In this paper, we present a framework capable of learning 3D-grounded visual intuitive physics models from videos of complex scenes with fluids. Our method is composed of a conditional Neural Radiance Field (NeRF)-style visual frontend and a 3D point-based dynamics prediction backend, using which we can impose strong relational and structural inductive bias to capture the structure of the underlying environment. Unlike existing intuitive point-based dynamics works that rely on the supervision of dense point trajectory from simulators, we relax the requirements and only assume access to multi-view RGB images and (imperfect) instance masks acquired using color prior. This enables the proposed model to handle scenarios where accurate point estimation and tracking are hard or impossible. We generate datasets including three challenging scenarios involving fluid, granular materials, and rigid objects in the simulation. The datasets do not include any dense particle information so most previous 3D-based intuitive physics pipelines can barely deal with that. We show our model can make long-horizon future predictions by learning from raw images and significantly outperforms models that do not employ an explicit 3D representation space. We also show that once trained, our model can achieve strong generalization in complex scenarios under extrapolate settings.'}",https://openreview.net{'value': '/pdf/739e599bd87f8fd4fcb09b78dd8827c81af83052.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=FmZVRe0gn8,{'value': 'Robust Multi-Agent Reinforcement Learning via Adversarial Regularization: Theoretical Foundation and Stable Algorithms'},Alexander Bukharin; Yan Li; Yue Yu; Qingru Zhang; Zhehui Chen; Simiao Zuo; Chao Zhang; Songan Zhang; Tuo Zhao,~Alexander_Bukharin1; ~Yan_Li9; ~Yue_Yu2; ~Qingru_Zhang2; ~Zhehui_Chen1; ~Simiao_Zuo1; ~Chao_Zhang15; ~Songan_Zhang1; ~Tuo_Zhao1,"{'value': ['Multi-Agent Reinforcement Learning', 'Theory of Robust Reinforcement Learning', 'Adversarial Regularization']}","{'value': 'Multi-Agent Reinforcement Learning (MARL) has shown promising results across several domains. Despite this promise, MARL policies often lack robustness and are therefore sensitive to small changes in their environment. This presents a serious concern for the real world deployment of MARL algorithms, where the testing environment may slightly differ from the training environment. In this work we show that we can gain robustness by controlling a policy’s Lipschitz constant, and under mild conditions, establish the existence of a Lipschitz and close-to-optimal policy. Motivated by these insights, we propose a new robust MARL framework, ERNIE, that promotes the Lipschitz continuity of the policies with respect to the state observations and actions by adversarial regularization. The ERNIE framework provides robustness against noisy observations, changing transition dynamics, and malicious actions of agents. However, ERNIE’s adversarial regularization may introduce some training instability. To reduce this instability, we reformulate adversarial regularization as a Stackelberg game. We demonstrate the effectiveness of the proposed framework with extensive experiments in traffic light control and particle environments. In addition, we extend ERNIE to mean-field MARL with a formulation based on distributionally robust optimization that outperforms its non-robust counterpart and is of independent interest. Our code is available at https://github.com/abukharin3/ERNIE.'}",https://openreview.net{'value': '/pdf/e66b05e7e10a71b29848af8febe181910a745dd5.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=FiClXlUqA7,{'value': 'A Unified Approach to Domain Incremental Learning with Memory: Theory and Algorithm'},Haizhou Shi; Hao Wang,~Haizhou_Shi1; ~Hao_Wang3,"{'value': ['Domain Incremental Learning', 'Continual Learning', 'Theory']}","{'value': 'Domain incremental learning aims to adapt to a sequence of domains with access to only a small subset of data (i.e., memory) from previous domains. Various methods have been proposed for this problem, but it is still unclear how they are related and when practitioners should choose one method over another. In response, we propose a unified framework, dubbed Unified Domain Incremental Learning (UDIL), for domain incremental learning with memory. Our UDIL **unifies** various existing methods, and our theoretical analysis shows that UDIL always achieves a tighter generalization error bound compared to these methods. The key insight is that different existing methods correspond to our bound with different **fixed** coefficients; based on insights from this unification, our UDIL allows **adaptive** coefficients during training, thereby always achieving the tightest bound. Empirical results show that our UDIL outperforms the state-of-the-art domain incremental learning methods on both synthetic and real-world datasets. Code will be available at https://github.com/Wang-ML-Lab/unified-continual-learning.'}",https://openreview.net{'value': '/pdf/6da832130b1985d5bdc64ae1dcf66dcd077c5cba.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=FgakGFpll1,{'value': 'A Metadata-Driven Approach to Understand Graph Neural Networks'},Ting Wei Li; Qiaozhu Mei; Jiaqi Ma,~Ting_Wei_Li1; ~Qiaozhu_Mei1; ~Jiaqi_Ma1,"{'value': ['Graph Neural Networks', 'Metadata-Driven Analysis', 'Gini Coefficient of Degree Distribution']}","{'value': 'Graph Neural Networks (GNNs) have achieved remarkable success in various applications, but their performance can be sensitive to specific data properties of the graph datasets they operate on. Current literature on understanding the limitations of GNNs has primarily employed a \\emph{model-driven} approach that leverage heuristics and domain knowledge from network science or graph theory to model the GNN behaviors, which is time-consuming and highly subjective. In this work, we propose a \\emph{metadata-driven} approach to analyze the sensitivity of GNNs to graph data properties, motivated by the increasing availability of graph learning benchmarks. We perform a multivariate sparse regression analysis on the metadata derived from benchmarking GNN performance across diverse datasets, yielding a set of salient data properties. To validate the effectiveness of our data-driven approach, we focus on one identified data property, the degree distribution, and investigate how this property influences GNN performance through theoretical analysis and controlled experiments. Our theoretical findings reveal that datasets with more balanced degree distribution exhibit better linear separability of node representations, thus leading to better GNN performance. We also conduct controlled experiments using synthetic datasets with varying degree distributions, and the results align well with our theoretical findings. Collectively, both the theoretical analysis and controlled experiments verify that the proposed metadata-driven approach is effective in identifying critical data properties for GNNs.'}",https://openreview.net{'value': '/pdf/fae8b8759c4cb4b431479a2f1ff5ed2b478ce9dd.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=FOFJmR1oxt,{'value': 'BCDiff: Bidirectional Consistent Diffusion for Instantaneous Trajectory Prediction'},Rongqing Li; Changsheng Li; Dongchun Ren; Guangyi Chen; Ye Yuan; Guoren Wang,~Rongqing_Li1; ~Changsheng_Li4; ~Dongchun_Ren2; ~Guangyi_Chen1; ~Ye_Yuan15; ~Guoren_Wang2,"{'value': ['Trajectory prediction', 'instantaneous observation']}","{'value': 'The objective of pedestrian trajectory prediction is to estimate the future paths of pedestrians by leveraging historical observations, which plays a vital role in ensuring the safety of self-driving vehicles and navigation robots. Previous works usually rely on a sufficient amount of observation time to accurately predict future trajectories. However, there are many real-world situations where the model lacks sufficient time to observe, such as when pedestrians abruptly emerge from blind spots, resulting in inaccurate predictions and even safety risks. Therefore, it is necessary to perform trajectory prediction based on instantaneous observations, which has rarely been studied before. In this paper, we propose a Bi-directional Consistent Diffusion framework tailored for instantaneous trajectory prediction, named BCDiff. At its heart, we develop two coupled diffusion models by designing a mutual guidance mechanism which can bidirectionally and consistently generate unobserved historical trajectories and future trajectories step-by-step,  to utilize the complementary information between them. Specifically, at each step, the predicted unobserved historical trajectories and limited observed trajectories guide one diffusion model to generate future trajectories, while the predicted future trajectories and observed trajectories guide the other diffusion model to predict unobserved historical trajectories. Given the presence of relatively high noise in the generated trajectories during the initial steps, we introduce a gating mechanism to learn the weights between the predicted trajectories and the limited observed trajectories for automatically balancing their contributions. By means of this iterative and mutually guided generation process, both the future and unobserved historical trajectories undergo continuous refinement, ultimately leading to accurate predictions. Essentially, BCDiff is an encoder-free framework that can be compatible with existing trajectory prediction models in principle. Experiments show that our proposed BCDiff significantly improves the accuracy of instantaneous trajectory prediction on the ETH/UCY and Stanford Drone datasets, compared to related approaches.'}",https://openreview.net{'value': '/pdf/8557f9cb53bd4a2e8cffc0b9e2752e6b94be8002.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=FFOYWUpBca,{'value': 'C-Disentanglement: Discovering Causally-Independent Generative Factors under  an Inductive Bias of Confounder'},Xiaoyu Liu; Jiaxin Yuan; Bang An; Yuancheng Xu; Yifan Yang; Furong Huang,~Xiaoyu_Liu3; ~Jiaxin_Yuan1; ~Bang_An1; ~Yuancheng_Xu1; ~Yifan_Yang5; ~Furong_Huang1,"{'value': ['causal disentanglement', 'causal generative process', 'generative factors', 'confounder', 'inductive bias', 'disentanglement', 'causal inference']}","{'value': 'Representation learning assumes that real-world data is generated by a few semantically meaningful generative factors (i.e., sources of variation) and aims to discover them in the latent space. These factors are expected to be causally disentangled, meaning that distinct factors are encoded into separate latent variables, and changes in one factor will not affect the values of the others. Compared to statistical independence, causal disentanglement allows more controllable data generation, improved robustness, and better generalization. However, most existing work assumes unconfoundedness in the discovery process, that there are no common causes to the generative factors and thus obtain only statistical independence. In this paper, we recognize the importance of modeling confounders in discovering causal generative factors. Unfortunately, such factors are not identifiable without proper inductive bias. We fill the gap by introducing a framework entitled Confounded-Disentanglement (C-Disentanglement), the first framework that explicitly introduces the inductive bias of confounder via labels from domain expertise. In addition, we accordingly propose an approach to sufficiently identify the causally-disentangled factors under any inductive bias of the confounder.  We conduct extensive experiments on both synthetic and real-world datasets. Our method demonstrates competitive results compared to various SOTA baselines in obtaining causally disentangled features and downstream tasks under domain shifts.'}",https://openreview.net{'value': '/pdf/7b59a50805387dae0ef70761a265781504977751.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=F5FVsfCxt8,{'value': 'Decision Tree for Locally Private Estimation with Public Data'},Yuheng Ma; Han Zhang; Yuchao Cai; Hanfang Yang,~Yuheng_Ma1; ~Han_Zhang21; ~Yuchao_Cai1; ~Hanfang_Yang2,"{'value': ['Local differential privacy', 'non-parametric regression', 'decision tree', 'public data']}","{'value': 'We propose conducting locally differentially private (LDP) estimation with the aid of a small amount of public data to enhance the performance of private estimation. Specifically, we introduce an efficient algorithm called Locally differentially Private Decision Tree (LPDT) for LDP regression. We first use the public data to grow a decision tree partition and then fit an estimator according to the partition privately.  From a theoretical perspective, we show that LPDT is $\\varepsilon$-LDP and has a mini-max optimal convergence rate under a mild assumption of similarity between public and private data, whereas the lower bound of the convergence rate of LPDT without public data is strictly slower, which implies that the public data helps to improve the convergence rates of LDP estimation. We conduct experiments on both synthetic and real-world data to demonstrate the superior performance of LPDT compared with other state-of-the-art LDP regression methods. Moreover, we show that LPDT remains effective despite considerable disparities between public and private data.'}",https://openreview.net{'value': '/pdf/0ddc4c586332d39ef78317002064a301774d2e94.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=F1mv2L7Rkb,{'value': 'Invariant Anomaly Detection under Distribution Shifts: A Causal Perspective'},João B. S. Carvalho; Mengtao Zhang; Robin Geyer; Carlos Cotrini; Joachim M. Buhmann,~João_B._S._Carvalho1; ~Mengtao_Zhang1; ~Robin_Geyer1; ~Carlos_Cotrini1; ~Joachim_M._Buhmann1,"{'value': ['anomaly detection', 'causal inference', 'distribution shifts']}","{'value': 'Anomaly detection (AD) is the machine learning task of identifying highly discrepant abnormal samples by solely relying on the consistency of the normal training samples. Under the constraints of a distribution shift, the assumption that training samples and test samples are drawn from the same distribution breaks down. In this work, by leveraging tools from causal inference we attempt to increase the resilience of anomaly detection models to different kinds of distribution shifts. We begin by elucidating a simple yet necessary statistical property that ensures invariant representations, which is critical for robust AD under both domain and covariate shifts. From this property, we derive a regularization term which, when minimized, leads to partial distribution invariance across environments. \nThrough extensive experimental evaluation on both synthetic and real-world tasks, covering a range of six different AD methods, we demonstrated significant improvements in out-of-distribution performance. Under both covariate and domain shift, models regularized with our proposed term showed marked increased robustness. Code is available at: https://github.com/JoaoCarv/invariant-anomaly-detection'}",https://openreview.net{'value': '/pdf/e37ca6c259978c18c72e0fb2974931c2e256b275.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Eysb8t3MJ5,{'value': 'GlucoSynth: Generating Differentially-Private Synthetic Glucose Traces'},Josephine Lamp; Mark Derdzinski; Christopher Hannemann; Joost Van der Linden; Lu Feng; Tianhao Wang; David Evans,~Josephine_Lamp1; ~Mark_Derdzinski1; ~Christopher_Hannemann1; ~Joost_Van_der_Linden1; ~Lu_Feng4; ~Tianhao_Wang3; ~David_Evans1,"{'value': ['Synthetic Data', 'Time Series', 'Generative Adversarial Networks', 'Differential Privacy', 'Glucose', 'Diabetes']}","{'value': 'We focus on the problem of generating high-quality, private synthetic glucose traces, a task generalizable to many other time series sources. Existing methods for time series data synthesis, such as those using Generative Adversarial Networks (GANs), are not able to capture the innate characteristics of glucose data and cannot provide any formal privacy guarantees without severely degrading the utility of the synthetic data. In this paper we present GlucoSynth, a novel privacy-preserving GAN framework to generate synthetic glucose traces. The core intuition behind our approach is to conserve relationships amongst motifs (glucose events) within the traces, in addition to temporal dynamics. Our framework incorporates differential privacy mechanisms to provide strong formal privacy guarantees. We provide a comprehensive evaluation on the real-world utility of the data using 1.2 million glucose traces; GlucoSynth outperforms all previous methods in its ability to generate high-quality synthetic glucose traces with strong privacy guarantees.'}",https://openreview.net{'value': '/pdf/bd9e53790e27750dfee5e323173ce828207ac0b4.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Eq9AFZlAjt,{'value': 'Unbounded Differentially Private Quantile and Maximum Estimation'},David Durfee,~David_Durfee1,"{'value': ['Differential privacy', 'Theory', 'Spars Vector Technique', 'Quantile']}","{'value': 'In this work we consider the problem of differentially private computation of\nquantiles for the data, especially the highest quantiles such as maximum, but\nwith an unbounded range for the dataset. We show that this can be done\nefficiently through a simple invocation of $\\texttt{AboveThreshold}$, a\nsubroutine that is iteratively called in the fundamental Sparse Vector\nTechnique, even when there is no upper bound on the data. In particular, we\nshow that this procedure can give more accurate and robust estimates on the\nhighest quantiles with applications towards clipping that is essential for\ndifferentially private sum and mean estimation. In addition, we show how two\ninvocations can handle the fully unbounded data setting. Within our study, we\nshow that an improved analysis of $\\texttt{AboveThreshold}$ can improve the\nprivacy guarantees for the widely used Sparse Vector Technique that is of\nindependent interest. We give a more general characterization of privacy loss\nfor $\\texttt{AboveThreshold}$ which we immediately apply to our method for\nimproved privacy guarantees. Our algorithm only requires one $O(n)$ pass\nthrough the data, which can be unsorted, and each subsequent query takes $O(1)$\ntime. We empirically compare our unbounded algorithm with the state-of-the-art\nalgorithms in the bounded setting. For inner quantiles, we find that our method\noften performs better on non-synthetic datasets. For the maximal quantiles,\nwhich we apply to differentially private sum computation, we find that our\nmethod performs significantly better.'}",https://openreview.net{'value': '/pdf/c96f3eec153b1b399f515431d364c1b408c77271.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=EGfYnTyEGv,{'value': 'A Long $N$-step Surrogate Stage Reward for Deep Reinforcement Learning'},Junmin Zhong; Ruofan Wu; Jennie Si,~Junmin_Zhong1; ~Ruofan_Wu3; ~Jennie_Si1,"{'value': ['Deep reinforcement learning', 'Reward Estimation']}","{'value': 'We introduce a new stage reward estimator  named the long $N$-step surrogate stage (LNSS) reward for deep reinforcement learning (RL). It aims at mitigating the high variance problem, which has shown impeding successful convergence of learning, hurting task performance, and hindering applications of deep RL in continuous control problems. In this paper we show that LNSS, which utilizes a long reward trajectory of  rewards of future steps, provides consistent performance improvement measured by average reward, convergence speed, learning success rate,and variance reduction in $Q$ values and rewards.  Our evaluations are based on a variety of environments in DeepMind Control Suite and OpenAI Gym  by using  LNSS in baseline deep RL algorithms such as DDPG, D4PG, and TD3. We show  that LNSS reward has enabled good results that have been challenging to obtain by deep RL previously. Our analysis also shows that  LNSS exponentially reduces the upper bound on the variances of $Q$ values from respective single-step methods.'}",https://openreview.net{'value': '/pdf/0aebd89db1d578e90ec4158426291802ee6d6e19.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=E3ZUEaeFYS,{'value': 'Strategic Distribution Shift of Interacting Agents via Coupled Gradient Flows'},Lauren E Conger; Franca Hoffman; Eric Mazumdar; Lillian J Ratliff,~Lauren_E_Conger1; franca.hoffmann@caltech.edu; ~Eric_Mazumdar1; ~Lillian_J_Ratliff1,"{'value': ['distribution shift', 'partial differential equations']}","{'value': 'We propose a novel framework for analyzing the dynamics of distribution shift in real-world systems that captures the feedback loop between learning algorithms and the distributions on which they are deployed. Prior work largely models feedback-induced distribution shift as adversarial or via an overly simplistic distribution-shift structure. In contrast, we propose a coupled partial differential equation model that captures fine-grained changes in the distribution over time by accounting for complex dynamics that arise due to strategic responses to algorithmic decision-making, non-local endogenous population interactions, and other exogenous sources of distribution shift. We consider two common settings in machine learning: cooperative settings with information asymmetries, and competitive settings where a learner faces strategic users. For both of these settings, when the algorithm retrains via gradient descent, we prove asymptotic convergence of the retraining procedure to a steady-state, both in finite and in infinite dimensions, obtaining explicit rates in terms of the model parameters. To do so we derive new results on the convergence of coupled PDEs that extends what is known on multi-species systems. Empirically, we show that our approach captures well-documented forms of distribution shifts like polarization and disparate impacts that simpler models cannot capture.'}",https://openreview.net{'value': '/pdf/d8b21f397109ee8ecb2da3cd833c35d27b603db7.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=E2zoGTkTbW,{'value': 'Reward Imputation with Sketching for Contextual Batched Bandits'},Xiao Zhang; Ninglu Shao; Zihua Si; Jun Xu; Wenhan Wang; Hanjing Su; Ji-Rong Wen,~Xiao_Zhang7; ~Ninglu_Shao1; ~Zihua_Si1; ~Jun_Xu1; ~Wenhan_Wang3; ~Hanjing_Su2; ~Ji-Rong_Wen1,"{'value': ['batched bandit', 'sketching', 'reward imputation', 'regret bound', 'ridge regression']}","{'value': 'Contextual batched bandit (CBB) is a setting where a batch of rewards is observed from the environment at the end of each episode, but the rewards of the non-executed actions are unobserved, resulting in partial-information feedback. Existing approaches for CBB often ignore the rewards of the non-executed actions, leading to underutilization of feedback information. In this paper, we propose an efficient approach called Sketched Policy Updating with Imputed Rewards (SPUIR) that completes the unobserved rewards using sketching, which approximates the full-information feedbacks. We formulate reward imputation as an imputation regularized ridge regression problem that captures the feedback mechanisms of both executed and non-executed actions. To reduce time complexity, we solve the regression problem using randomized sketching. We prove that our approach achieves an instantaneous regret with controllable bias and smaller variance than approaches without reward imputation. Furthermore, our approach enjoys a sublinear regret bound against the optimal policy. We also present two extensions, a rate-scheduled version and a version for nonlinear rewards, making our approach more practical. Experimental results show that SPUIR outperforms state-of-the-art baselines on synthetic, public benchmark, and real-world datasets.'}",https://openreview.net{'value': '/pdf/56f77e16ec737b93d54c689d992803405f29cb6e.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=DpuphOgJqh,{'value': 'Selectively Sharing Experiences Improves Multi-Agent Reinforcement Learning'},Matthias Gerstgrasser; Tom Danino; Sarah Keren,~Matthias_Gerstgrasser1; ~Tom_Danino1; ~Sarah_Keren1,"{'value': ['multi-agent reinforcement learning', 'reinforcement learning', 'deep q learning', 'cooperative ai']}","{'value': 'We present a novel multi-agent RL approach, Selective Multi-Agent Prioritized Experience Relay, in which agents share with other agents a limited number of transitions they observe during training. The intuition behind this is that even a small number of relevant experiences from other agents could help each agent learn. Unlike many other multi-agent RL algorithms, this approach allows for largely decentralized training, requiring only a limited communication channel between agents. We show that our approach outperforms baseline no-sharing decentralized training and state-of-the art multi-agent RL algorithms. Further, sharing only a small number of highly relevant experiences outperforms sharing all experiences between agents, and the performance uplift from selective experience sharing is robust across a range of hyperparameters and DQN variants.'}",https://openreview.net{'value': '/pdf/ea8e2f6e47715bbf8846ac24f2da9d20cab0e397.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Deb1yP1zMN,{'value': 'Automatic Integration for Spatiotemporal Neural Point Processes'},Zihao Zhou; Rose Yu,~Zihao_Zhou1; ~Rose_Yu1,"{'value': ['spatiotemporal modeling', 'neural point processes', 'integration method']}","{'value': 'Learning continuous-time point processes is essential to many discrete event forecasting tasks. However, integration poses a major challenge, particularly for spatiotemporal point processes (STPPs), as it involves calculating the likelihood through triple integrals over space and time. Existing methods for integrating STPP either assume a parametric form of the intensity function, which lacks flexibility; or approximating the intensity with Monte Carlo sampling, which introduces numerical errors. Recent work by Omi et al. proposes a dual network approach for efficient integration of flexible intensity function. However, their method only focuses on the 1D temporal point process. In this paper, we introduce a novel paradigm: `Auto-STPP` (Automatic Integration for Spatiotemporal Neural Point Processes) that extends the dual network approach to 3D STPP. While previous work provides a foundation, its direct extension overly restricts the intensity function and leads to computational challenges. In response, we introduce a decomposable parametrization for the integral network using ProdNet. This approach, leveraging the product of simplified univariate graphs, effectively sidesteps the computational complexities inherent in multivariate computational graphs. We prove the consistency of `Auto-STPP` and validate it on synthetic data and benchmark real-world datasets. `Auto-STPP` shows a significant advantage in recovering complex intensity functions from irregular spatiotemporal events, particularly when the intensity is sharply localized. Our code is open-source at https://github.com/Rose-STL-Lab/AutoSTPP.'}",https://openreview.net{'value': '/pdf/bef569982e1f76af2946dc7765375af2b5001812.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Dbaxm9ujq6,{'value': 'How2comm: Communication-Efficient and Collaboration-Pragmatic Multi-Agent Perception'},Dingkang Yang; Kun Yang; Yuzheng Wang; Jing Liu; Zhi Xu; Rongbin Yin; Peng Zhai; Lihua Zhang,~Dingkang_Yang1; ~Kun_Yang5; ~Yuzheng_Wang1; ~Jing_Liu14; ~Zhi_Xu3; ~Rongbin_Yin1; ~Peng_Zhai1; ~Lihua_Zhang1,"{'value': ['Collaborative perception', 'multi-agent communication']}","{'value': 'Multi-agent collaborative perception has recently received widespread attention as an emerging application in driving scenarios. Despite the advancements in previous efforts, challenges remain due to various noises in the perception procedure, including communication redundancy, transmission delay, and collaboration heterogeneity. To tackle these issues, we propose \\textit{How2comm}, a collaborative perception framework that seeks a trade-off between perception performance and communication bandwidth. Our novelties lie in three aspects. First, we devise a mutual information-aware communication mechanism to maximally sustain the informative features shared by collaborators. The spatial-channel filtering is adopted to perform effective feature sparsification for efficient communication. Second, we present a flow-guided delay compensation strategy to predict future characteristics from collaborators and eliminate feature misalignment due to temporal asynchrony. Ultimately, a pragmatic collaboration transformer is introduced to integrate holistic spatial semantics and temporal context clues among agents. Our framework is thoroughly evaluated on several LiDAR-based collaborative detection datasets in real-world and simulated scenarios. Comprehensive experiments demonstrate the superiority of How2comm and the effectiveness of all its vital components. The code will be released at https://github.com/ydk122024/How2comm.'}",https://openreview.net{'value': '/pdf/7b21bfe4e91fae6f28ee7da63566386896847687.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=DVjyq5eCAD,{'value': 'Chasing Fairness Under Distribution Shift: A Model Weight Perturbation Approach'},Zhimeng Jiang; Xiaotian Han; Hongye Jin; Guanchu Wang; Rui Chen; Na Zou; Xia Hu,~Zhimeng_Jiang1; ~Xiaotian_Han1; ~Hongye_Jin1; ~Guanchu_Wang1; ~Rui_Chen4; ~Na_Zou2; ~Xia_Hu4,"{'value': ['Model Weight Perturbation', 'fairness', 'distribution shift']}","{'value': 'Fairness in machine learning has attracted increasing attention in recent years. The fairness methods improving algorithmic fairness for in-distribution data may not perform well under distribution shifts. In this paper, we first theoretically demonstrate the inherent connection between distribution shift,  data perturbation, and model weight perturbation.\nSubsequently, we analyze the sufficient conditions to guarantee fairness (i.e., low demographic parity) for the target dataset, including fairness for the source dataset, and low prediction difference between the source and target datasets for each sensitive attribute group. Motivated by these sufficient conditions, we propose robust fairness regularization (RFR) by considering the worst case within the model weight perturbation ball for each sensitive attribute group. We evaluate the effectiveness of our proposed RFR algorithm on synthetic and real distribution shifts across various datasets. Experimental results demonstrate that RFR achieves better fairness-accuracy trade-off performance compared with several baselines. The source code is available at \\url{https://github.com/zhimengj0326/RFR_NeurIPS23}.'}",https://openreview.net{'value': '/pdf/3dcae620954418c5fb70f4599f677e1a1d66d77c.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=DP2lioYIYl,{'value': 'A Theory of Unsupervised Translation Motivated by Understanding Animal Communication'},Shafi Goldwasser; David Gruber; Adam Tauman Kalai; Orr Paradise,~Shafi_Goldwasser2; ~David_Gruber1; ~Adam_Tauman_Kalai1; ~Orr_Paradise1,"{'value': ['Theory', 'Unsupervised Machine Translation']}","{'value': 'Neural networks are capable of translating between languages—in some cases even between two languages where there is little or no access to parallel translations, in what is known as Unsupervised Machine Translation (UMT). Given this progress, it is intriguing to ask whether machine learning tools can ultimately enable understanding animal communication, particularly that of highly intelligent\nanimals. We propose a theoretical framework for analyzing UMT when no parallel translations are available and when it cannot be assumed that the source and target corpora address related subject domains or posses similar linguistic structure. We\nexemplify this theory with two stylized models of language, for which our framework provides bounds on necessary sample complexity; the bounds are formally proven and experimentally verified on synthetic data. These bounds show that the error rates are inversely related to the language complexity and amount of common ground. This suggests that unsupervised translation of animal communication may be feasible if the communication system is sufficiently complex.'}",https://openreview.net{'value': '/pdf/fb6a03e50308a9fd851987952a9fd33fe73956f2.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=DNHGKeOhLl,{'value': 'On the Stability-Plasticity Dilemma in Continual Meta-Learning: Theory and Algorithm'},Qi CHEN; Changjian Shui; Ligong Han; Mario Marchand,~Qi_CHEN6; ~Changjian_Shui2; ~Ligong_Han1; ~Mario_Marchand1,{'value': ['continual meta-learning; transfer learning; stability-plasticity dilemma;']},"{'value': 'We focus on Continual Meta-Learning (CML), which targets accumulating and exploiting meta-knowledge on a sequence of non-i.i.d. tasks. The primary challenge is to strike a balance between stability and plasticity, where a model should be stable to avoid catastrophic forgetting in previous tasks and plastic to learn generalizable concepts from new tasks. To address this, we formulate the CML objective as controlling the average excess risk upper bound of the task sequence, which reflects the trade-off between forgetting and generalization. Based on the objective, we introduce a unified theoretical framework for CML in both static and shifting environments, providing guarantees for various task-specific learning algorithms. Moreover, we first present a rigorous analysis of a bi-level trade-off in shifting environments. To approach the optimal trade-off, we propose a novel algorithm that dynamically adjusts the meta-parameter and its learning rate w.r.t environment change. Empirical evaluations on synthetic and real datasets illustrate the effectiveness of the proposed theory and algorithm.'}",https://openreview.net{'value': '/pdf/0ee9a8d9cb4e5d5580b8cb655f610575ec1f7e7e.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=DEiNSfh1k7,{'value': 'DreamSim: Learning New Dimensions of Human Visual Similarity using Synthetic Data'},Stephanie Fu; Netanel Yakir Tamir; Shobhita Sundaram; Lucy Chai; Richard Zhang; Tali Dekel; Phillip Isola,~Stephanie_Fu1; ~Netanel_Yakir_Tamir1; ~Shobhita_Sundaram1; ~Lucy_Chai1; ~Richard_Zhang1; ~Tali_Dekel1; ~Phillip_Isola1,"{'value': ['perceptual similarity', 'foundation model', 'perception', 'computer vision', 'image metric']}","{'value': 'Current perceptual similarity metrics operate at the level of pixels and patches. These metrics compare images in terms of their low-level colors and textures, but fail to capture mid-level similarities and differences in image layout, object pose, and semantic content. In this paper, we develop a perceptual metric that assesses images holistically. Our first step is to collect a new dataset of human similarity judgments over image pairs that are alike in diverse ways. Critical to this dataset is that judgments are nearly automatic and shared by all observers. To achieve this we use recent text-to-image models to create synthetic pairs that are perturbed along various dimensions. We observe that popular perceptual metrics fall short of explaining our new data, and we introduce a new metric, DreamSim, tuned to better align with human perception. We analyze how our metric is affected by different visual attributes, and find that it focuses heavily on foreground objects and semantic content while also being sensitive to color and layout. Notably, despite being trained on synthetic data, our metric generalizes to real images, giving strong results on retrieval and reconstruction tasks. Furthermore, our metric outperforms both prior learned metrics and recent large vision models on these tasks. Our project page: https://dreamsim-nights.github.io/'}",https://openreview.net{'value': '/pdf/fb6714a8a4a6c793c072c37b2991b8f8b983fd3e.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=DEC7NxDJLh,{'value': 'Coupled Reconstruction of Cortical Surfaces by Diffeomorphic Mesh Deformation'},Hao Zheng; Hongming Li; Yong Fan,~Hao_Zheng1; ~Hongming_Li1; yong.fan@pennmedicine.upenn.edu,"{'value': ['Brain MRIs', 'cortical surface reconstruction', 'deep learning']}","{'value': ""Accurate reconstruction of cortical surfaces from brain magnetic resonance images (MRIs) remains a challenging task due to the notorious partial volume effect in brain MRIs and the cerebral cortex's thin and highly folded patterns. Although many promising deep learning-based cortical surface reconstruction methods have been developed, they typically fail to model the interdependence between inner (white matter) and outer (pial) cortical surfaces, which can help generate cortical surfaces with spherical topology. To robustly reconstruct the cortical surfaces with topological correctness, we develop a new deep learning framework to jointly reconstruct the inner, outer, and their in-between (midthickness) surfaces and estimate cortical thickness directly from 3D MRIs. Our method first estimates the midthickness surface and then learns three diffeomorphic flows jointly to optimize the midthickness surface and deform it inward and outward to the inner and outer cortical surfaces respectively, regularized by topological correctness. Our method also outputs a cortex thickness value for each surface vertex, estimated from its diffeomorphic deformation trajectory. Our method has been evaluated on two large-scale neuroimaging datasets, including ADNI and OASIS, achieving state-of-the-art cortical surface reconstruction performance in terms of accuracy, surface regularity, and computation efficiency.""}",https://openreview.net{'value': '/pdf/3276a92606efb35455dd1359ba3dff704fe85325.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=D9CMRR5Lof,{'value': 'MGDD: A Meta Generator for Fast Dataset Distillation'},Songhua Liu; Xinchao Wang,~Songhua_Liu2; ~Xinchao_Wang1,"{'value': ['Dataset Distillation', 'Dataset Condensation', 'Efficient Learning', 'Conditional Generation', 'Meta Learning']}","{'value': 'Existing dataset distillation (DD) techniques typically rely on iterative strategies to synthesize condensed datasets, where datasets before and after distillation are forward and backward through neural networks a massive number of times. Despite the promising results achieved, the time efficiency of prior approaches is still far from satisfactory. Moreover, when different sizes of synthetic datasets are required, they have to repeat the iterative training procedures, which is highly cumbersome and lacks flexibility. In this paper, different from the time-consuming forward-backward passes, we introduce a generative fashion for dataset distillation with significantly improved efficiency. Specifically, synthetic samples are produced by a generator network conditioned on the initialization of DD, while synthetic labels are obtained by solving a least-squares problem in a feature space. Our theoretical analysis reveals that the errors of synthetic datasets solved in the original space and then processed by any conditional generators are upper-bounded. To find a satisfactory generator efficiently, we propose a meta-learning algorithm, where a meta generator is trained on a large dataset so that only a few steps are required to adapt to a target dataset. The meta generator is termed as MGDD in our approach. Once adapted, it can handle arbitrary sizes of synthetic datasets, even for those unseen during adaptation. Experiments demonstrate that the generator adapted with only a limited number of steps performs on par with those state-of-the-art DD methods and yields $22\\times$ acceleration.'}",https://openreview.net{'value': '/pdf/849d39ff55c93d69c6d22cec9029c711811ac957.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=CtXXOaxDw7,{'value': 'V-InFoR: A Robust Graph Neural Networks Explainer for Structurally Corrupted Graphs'},Senzhang Wang; Jun Yin; Chaozhuo Li; Xing Xie; Jianxin Wang,~Senzhang_Wang2; ~Jun_Yin11; ~Chaozhuo_Li1; ~Xing_Xie3; ~Jianxin_Wang1,"{'value': ['Explainable AI', 'Graph Neural Networks', 'Machine Learning']}","{'value': 'GNN explanation method aims to identify an explanatory subgraph which contains the most informative components of the full graph. However, a major limitation of existing GNN explainers is that they are not robust to the structurally corrupted graphs, e.g., graphs with noisy or adversarial edges. On the one hand, existing GNN explainers mostly explore explanations based on either the raw graph features or the learned latent representations, both of which can be easily corrupted. On the other hand, the corruptions in graphs are irregular in terms of the structural properties, e.g., the size or connectivity of graphs, which makes the rigorous constraints used by previous GNN explainers unfeasible. To address these issues, we propose a robust GNN explainer called V-InfoR. Specifically, a robust graph representation extractor, which takes insights of variational inference, is proposed to infer the latent distribution of graph representations. Instead of directly using the corrupted raw features or representations of each single graph, we sample the graph representations from the inferred distribution for the downstream explanation generator, which can effectively eliminate the minor corruption. We next formulate the explanation exploration as a graph information bottleneck (GIB) optimization problem. As a more general method that does not need any rigorous structural constraints, our GIB-based method can adaptively capture both the regularity and irregularity of the severely corrupted graphs for explanation. Extensive evaluations on both synthetic and real-world datasets indicate that V-InfoR significantly improves the GNN explanation performance for the structurally corrupted graphs. Code and dataset are available at https://anonymous.4open.science/r/V-InfoR-EF88'}",https://openreview.net{'value': '/pdf/6cb765be7bec62e9561b541650364dbb097f074d.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=CruxS0C0LS,{'value': 'Finding Local Minima Efficiently in Decentralized Optimization'},Wenhan Xian; Heng Huang,~Wenhan_Xian1; ~Heng_Huang1,"{'value': ['second-order optimality', 'decentralized optimization']}","{'value': 'In this paper we study the second-order optimality of decentralized stochastic algorithm that escapes saddle point efficiently for nonconvex optimization problems. We propose a new pure gradient-based decentralized stochastic algorithm PEDESTAL with a novel convergence analysis framework to address the technical challenges unique to the decentralized stochastic setting. Our method is the first decentralized stochastic algorithm to achieve second-order optimality with non-asymptotic analysis. We provide theoretical guarantees with the gradient complexity of $\\tilde{O} (\\epsilon^{-3})$ to find $O(\\epsilon, \\sqrt{\\epsilon})$-second-order stationary point, which matches state-of-the-art results of centralized counterparts or decentralized methods to find first-order stationary point. We also conduct two decentralized tasks in our experiments, a matrix sensing task with synthetic data and a matrix factorization task with a real-world dataset to validate the performance of our method.'}",https://openreview.net{'value': '/pdf/1ef9c73f0938c60e940df2c61901d2e3c4f77878.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=CniUitfEY3,{'value': 'Reusable Slotwise Mechanisms'},Trang Nguyen; Amin Mansouri; Kanika Madan; Nguyen Duy Khuong; Kartik Ahuja; Dianbo Liu; Yoshua Bengio,~Trang_Nguyen1; ~Amin_Mansouri1; ~Kanika_Madan3; ~Nguyen_Duy_Khuong1; ~Kartik_Ahuja1; ~Dianbo_Liu2; ~Yoshua_Bengio1,"{'value': ['Out-of-Distribution Generalization', 'Slotwise', 'Visual Reasoning', 'Video Prediction', 'Reusable Mechanism', 'Dynamics modeling']}","{'value': 'Agents with the ability to comprehend and reason about the dynamics of objects would be expected to exhibit improved robustness and generalization in novel scenarios. However, achieving this capability necessitates not only an effective scene representation but also an understanding of the mechanisms governing interactions among object subsets. Recent studies have made significant progress in representing scenes using object slots. In this work, we introduce Reusable Slotwise Mechanisms, or RSM, a framework that models object dynamics by leveraging communication among slots along with a modular architecture capable of dynamically selecting reusable mechanisms for predicting the future states of each object slot. Crucially, RSM leverages the Central Contextual Information (CCI), enabling selected mechanisms to access the remaining slots through a bottleneck, effectively allowing for modeling of higher order and complex interactions that might require a sparse subset of objects. Experimental results demonstrate the superior performance of RSM compared to state-of-the-art methods across various future prediction and related downstream tasks, including Visual Question Answering and action planning. Furthermore, we showcase RSM’s Out-of-Distribution generalization ability to handle scenes in intricate scenarios.'}",https://openreview.net{'value': '/pdf/1b2980d66ac506d8fa9ca1ccbc3906979e450f09.pdf'},{'abstract_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=Cc2fjBBlBD,{'value': 'Spuriosity Didn’t Kill the Classifier: Using Invariant Predictions to Harness Spurious Features'},Cian Eastwood; Shashank Singh; Andrei Liviu Nicolicioiu; Marin Vlastelica; Julius von Kügelgen; Bernhard Schölkopf,~Cian_Eastwood1; ~Shashank_Singh1; ~Andrei_Liviu_Nicolicioiu1; ~Marin_Vlastelica1; ~Julius_von_Kügelgen2; ~Bernhard_Schölkopf1,"{'value': ['invariant prediction', 'spurious correlations', 'out-of-distribution generalization', 'domain generalization', 'domain adaptation', 'test-time domain adaptation']}","{'value': 'To avoid failures on out-of-distribution data, recent works have sought to extract features that have an invariant or stable relationship with the label across domains, discarding ""spurious"" or unstable features whose relationship with the label changes across domains. However, unstable features often carry complementary information that could boost performance if used correctly in the test domain. In this work, we show how this can be done without test-domain labels. In particular, we prove that pseudo-labels based on stable features provide sufficient guidance for doing so, provided that stable and unstable features are conditionally independent given the label. Based on this theoretical insight, we propose Stable Feature Boosting (SFB), an algorithm for: (i) learning a predictor that separates stable and conditionally-independent unstable features; and (ii) using the stable-feature predictions to adapt the unstable-feature predictions in the test domain. Theoretically, we prove that SFB can learn an asymptotically-optimal predictor without test-domain labels. Empirically, we demonstrate the effectiveness of SFB on real and synthetic data.'}",https://openreview.net{'value': '/pdf/2e9da61f3c6b4f8ccc80f819ffe98b4098c1049f.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=CYCzfXn6cZ,{'value': 'Survival Permanental Processes for Survival Analysis with Time-Varying Covariates'},Hideaki Kim,~Hideaki_Kim1,"{'value': ['survival analysis', 'temporal point process', 'Bayesian estimation', 'permanental process', 'representer theorem', 'kernel method']}","{'value': 'Survival or time-to-event data with time-varying covariates are common in practice, and exploring the non-stationarity in covariates is essential to accurately analyzing the nonlinear dependence of time-to-event outcomes on covariates. Traditional survival analysis methods such as Cox proportional hazards model have been extended to address the time-varying covariates through a counting process formulation, although sophisticated machine learning methods that can accommodate time-varying covariates have been limited. In this paper, we propose a non-parametric Bayesian survival model to analyze the nonlinear dependence of time-to-event outcomes on time-varying covariates. We focus on a computationally feasible Cox process called permanental process, which assumes the square root of hazard function to be generated from a Gaussian process, and tailor it for survival data with time-varying covariates. We verify that the proposed model holds with the representer theorem, a beneficial property for functional analysis, which offers us a fast Bayesian estimation algorithm that scales linearly with the number of observed events without relying on Markov Chain Monte Carlo computation. We evaluate our algorithm on synthetic and real-world data, and show that it achieves comparable predictive accuracy while being tens to hundreds of times faster than state-of-the-art methods.'}",https://openreview.net{'value': '/pdf/c2708659783388032de7ea87f606ffa08262f280.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=CQuRzAgjg9,{'value': 'Online Clustering of Bandits with Misspecified User Models'},Zhiyong Wang; Jize Xie; Xutong Liu; Shuai Li; John C.S. Lui,~Zhiyong_Wang9; ~Jize_Xie1; ~Xutong_Liu1; ~Shuai_Li3; ~John_C.S._Lui2,{'value': ['online clustering of bandits']},"{'value': 'The contextual linear bandit is an important online learning problem where given arm features, a learning agent selects an arm at each round to maximize the cumulative rewards in the long run. A line of works, called the clustering of bandits (CB), utilize the collaborative effect over user preferences and have shown significant improvements over classic linear bandit algorithms. However, existing CB algorithms require well-specified linear user models and can fail when this critical assumption does not hold. Whether robust CB algorithms can be designed for more practical scenarios with misspecified user models remains an open problem. In this paper, we are the first to present the important problem of clustering of bandits with misspecified user models (CBMUM), where the expected rewards in user models can be perturbed away from perfect linear models. We devise two robust CB algorithms, RCLUMB and RSCLUMB (representing the learned clustering structure with dynamic graph and sets, respectively), that can accommodate the inaccurate user preference estimations and erroneous clustering caused by model misspecifications. We prove regret upper bounds of $O(\\epsilon_*T\\sqrt{md\\log T}  + d\\sqrt{mT}\\log T)$ for our algorithms under milder assumptions than previous CB works, which match the lower bound asymptotically in $T$ up to logarithmic factors, and also match the state-of-the-art results in several degenerate cases. Our regret analysis is novel and different from the typical proof flow of previous CB works. The techniques in proving the regret caused by misclustering users are quite general and may be of independent interest. Experiments on both synthetic and real-world data show our outperformance over previous algorithms.'}",https://openreview.net{'value': '/pdf/88b50fc1b7f51999a78150d0d40d1e3587c2bcf0.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=CGj72TyGJy,{'value': 'Automatic Grouping for Efficient Cooperative Multi-Agent Reinforcement Learning'},Yifan Zang; Jinmin He; Kai Li; Haobo Fu; QIANG FU; Junliang Xing; Jian Cheng,~Yifan_Zang1; ~Jinmin_He1; ~Kai_Li2; ~Haobo_Fu2; ~QIANG_FU8; ~Junliang_Xing1; ~Jian_Cheng7,"{'value': ['MARL', 'Cooperative Multi-Agent Reinforcement Learning', 'Coordination and Cooperation', 'Automatic Grouping', 'Group-Wise Learning']}","{'value': ""Grouping is ubiquitous in natural systems and is essential for promoting efficiency in team coordination. This paper proposes a novel formulation of Group-oriented Multi-Agent Reinforcement Learning (GoMARL), which learns automatic grouping without domain knowledge for efficient cooperation. In contrast to existing approaches that attempt to directly learn the complex relationship between the joint action-values and individual utilities, we empower subgroups as a bridge to model the connection between small sets of agents and encourage cooperation among them, thereby improving the learning efficiency of the whole team. In particular, we factorize the joint action-values as a combination of group-wise values, which guide agents to improve their policies in a fine-grained fashion. We present an automatic grouping mechanism to generate dynamic groups and group action-values. We further introduce a hierarchical control for policy learning that drives the agents in the same group to specialize in similar policies and possess diverse strategies for various groups. Experiments on the StarCraft II micromanagement tasks and Google Research Football scenarios verify our method's effectiveness. Extensive component studies show how grouping works and enhances performance.""}",https://openreview.net{'value': '/pdf/b8a6bee77fa99b8947f0961b591c27abd6b6bb1c.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=C9cgwmJ8Pt,{'value': 'Fast Projected Newton-like Method for Precision Matrix Estimation under Total Positivity'},Jian-Feng CAI; José Vinícius De Miranda Cardoso; Daniel P. Palomar; Jiaxi Ying,~Jian-Feng_CAI1; ~José_Vinícius_De_Miranda_Cardoso1; ~Daniel_P._Palomar1; ~Jiaxi_Ying1,"{'value': ['MTP2', 'Total Positivity', 'Generalized graph Laplacian', 'Precision matrix estimation', 'Nonnegative partial correlations']}","{'value': 'We study the problem of estimating precision matrices in Gaussian distributions that are multivariate totally positive of order two ($\\mathrm{MTP}_2$). The precision matrix in such a distribution is an M-matrix. This problem can be formulated as a sign-constrained log-determinant program. Current algorithms are designed using the block coordinate descent method or the proximal point algorithm, which becomes computationally challenging in high-dimensional cases due to the requirement to solve numerous nonnegative quadratic programs or large-scale linear systems. To address this issue, we propose a novel algorithm based on the two-metric projection method, incorporating a carefully designed search direction and variable partitioning scheme. Our algorithm substantially reduces computational complexity, and its theoretical convergence is established. Experimental results on synthetic and real-world datasets demonstrate that our proposed algorithm provides a significant improvement in computational efficiency compared to the state-of-the-art methods.'}",https://openreview.net{'value': '/pdf/6845ab79f422b338aacde388c2d0eb106633f1d6.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=C8pvL8Qbfa,{'value': 'Conservative Offline Policy Adaptation in Multi-Agent Games'},Chengjie Wu; Pingzhong Tang; Jun Yang; Yujing Hu; Tangjie Lv; Changjie Fan; Chongjie Zhang,~Chengjie_Wu1; ~Pingzhong_Tang1; ~Jun_Yang6; ~Yujing_Hu2; ~Tangjie_Lv1; ~Changjie_Fan1; ~Chongjie_Zhang1,"{'value': ['reinforcement learning', 'opponent exploitation', 'multi-agent']}","{'value': 'Prior research on policy adaptation in multi-agent games has often relied on online interaction with the target agent in training, which can be expensive and impractical in real-world scenarios. Inspired by recent progress in offline reinforcement learn- ing, this paper studies offline policy adaptation, which aims to utilize the target agent’s behavior data to exploit its weakness or enable effective cooperation. We investigate its distinct challenges of distributional shift and risk-free deviation, and propose a novel learning objective, conservative offline adaptation, that optimizes the worst-case performance against any dataset consistent proxy models. We pro- pose an efficient algorithm called Constrained Self-Play (CSP) that incorporates dataset information into regularized policy learning. We prove that CSP learns a near-optimal risk-free offline adaptation policy upon convergence. Empirical results demonstrate that CSP outperforms non-conservative baselines in various environments, including Maze, predator-prey, MuJoCo, and Google Football.'}",https://openreview.net{'value': '/pdf/b7f33f5b4e401a1e19d7abd347b3d83b37583edc.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=BdvCo8RVlx,{'value': 'The Contextual Lasso: Sparse Linear Models via Deep Neural Networks'},Ryan Thompson; Amir Dezfouli; Robert Kohn,~Ryan_Thompson1; ~Amir_Dezfouli2; ~Robert_Kohn1,"{'value': ['feature selection', 'sparsity', 'sparse regression', 'varying coefficients', 'deep learning']}","{'value': ""Sparse linear models are one of several core tools for interpretable machine learning, a field of emerging importance as predictive models permeate decision-making in many domains. Unfortunately, sparse linear models are far less flexible as functions of their input features than black-box models like deep neural networks. With this capability gap in mind, we study a not-uncommon situation where the input features dichotomize into two groups: explanatory features, which are candidates for inclusion as variables in an interpretable model, and contextual features, which select from the candidate variables and determine their effects. This dichotomy leads us to the contextual lasso, a new statistical estimator that fits a sparse linear model to the explanatory features such that the sparsity pattern and coefficients vary as a function of the contextual features. The fitting process learns this function nonparametrically via a deep neural network. To attain sparse coefficients, we train the network with a novel lasso regularizer in the form of a projection layer that maps the network's output onto the space of $\\ell_1$-constrained linear models. An extensive suite of experiments on real and synthetic data suggests that the learned models, which remain highly transparent, can be sparser than the regular lasso without sacrificing the predictive power of a standard deep neural network.""}",https://openreview.net{'value': '/pdf/84de3974738264bc47f2eeca4ca075518d4bbe10.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=BXQtgwA2n0,{'value': 'Offline Multi-Agent Reinforcement Learning with Implicit Global-to-Local Value Regularization'},Xiangsen Wang; Haoran Xu; Yinan Zheng; Xianyuan Zhan,~Xiangsen_Wang1; ~Haoran_Xu4; ~Yinan_Zheng1; ~Xianyuan_Zhan1,{'value': ['Offline reinforcement learning; multi-agent reinforcement learning; multi-agent cooperation']},"{'value': 'Offline reinforcement learning (RL) has received considerable attention in recent years due to its attractive capability of learning policies from offline datasets without environmental interactions. Despite some success in the single-agent setting, offline multi-agent RL (MARL) remains to be a challenge. The large joint state-action space and the coupled multi-agent behaviors pose extra complexities for offline policy optimization. Most existing offline MARL studies simply apply offline data-related regularizations on individual agents, without fully considering the multi-agent system at the global level. In this work, we present OMIGA, a new offline multi-agent RL algorithm with implicit global-to-local value regularization. OMIGA provides a principled framework to convert global-level value regularization into equivalent implicit local value regularizations and simultaneously enables in-sample learning, thus elegantly bridging multi-agent value decomposition and policy learning with offline regularizations. Based on comprehensive experiments on the offline multi-agent MuJoCo and StarCraft II micro-management tasks, we show that OMIGA achieves superior performance over the state-of-the-art offline MARL methods in almost all tasks.'}",https://openreview.net{'value': '/pdf/3dd2ab8d5f8e3728056cfa396f22b3c975c7ca75.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=BRqlkTDvvm,{'value': 'BQ-NCO: Bisimulation Quotienting for Efficient Neural Combinatorial Optimization'},Darko Drakulic; Sofia Michel; Florian Mai; Arnaud Sors; Jean-Marc Andreoli,~Darko_Drakulic1; ~Sofia_Michel1; ~Florian_Mai1; ~Arnaud_Sors1; ~Jean-Marc_Andreoli2,"{'value': ['Combinatorial Optimization', 'Markov Decision Processes', 'Bisimulation', 'Policy Learning', 'Out-of-Distribution Generalization', 'Routing Problems', 'TSP', 'CVRP', 'KP.']}","{'value': 'Despite the success of neural-based combinatorial optimization methods for end-to-end heuristic learning, out-of-distribution generalization remains a challenge. In this paper, we present a novel formulation of Combinatorial Optimization Problems (COPs) as Markov Decision Processes (MDPs) that effectively leverages common symmetries of COPs to improve out-of-distribution robustness. Starting from a direct MDP formulation of a constructive method, we introduce a generic way to reduce the state space, based on Bisimulation Quotienting (BQ) in MDPs. Then, for COPs with a recursive nature, we specialize the bisimulation and show how the reduced state exploits the symmetries of these problems and facilitates MDP solving. Our approach is principled and we prove that an optimal policy for the proposed BQ-MDP actually solves the associated COPs. We illustrate our approach on five classical problems: the Euclidean and Asymmetric Traveling Salesman, Capacitated Vehicle Routing, Orienteering and Knapsack Problems. Furthermore, for each problem, we introduce a simple attention-based policy network for the BQ-MDPs, which we train by imitation of (near) optimal solutions of small instances from a single distribution. We obtain new state-of-the-art results for the five COPs on both synthetic and realistic benchmarks. Notably, in contrast to most existing neural approaches, our learned policies show excellent generalization performance to much larger instances than seen during training, without any additional search procedure. Our code is available at: [link](https://github.com/naver/bq-nco).'}",https://openreview.net{'value': '/pdf/045708a8ecde38df0562afd292b1fe3ec94019f4.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=BHHrX3CRE1,{'value': 'Regularity as Intrinsic Reward for Free Play'},Cansu Sancaktar; Justus Piater; Georg Martius,~Cansu_Sancaktar1; ~Justus_Piater1; ~Georg_Martius1,"{'value': ['Intrinsic Motivation', 'Reinforcement Learning', 'Model-based Planning', 'Regularity', 'Manipulation', 'Zero-shot Generalization', 'Unsupervised Exploration']}","{'value': 'We propose regularity as a novel reward signal for intrinsically-motivated reinforcement learning. Taking inspiration from child development, we postulate that striving for structure and order helps guide exploration towards a subspace of tasks that are not favored by naive uncertainty-based intrinsic rewards. Our generalized formulation of Regularity as Intrinsic Reward (RaIR) allows us to operationalize it within model-based reinforcement learning. In a synthetic environment, we showcase the plethora of structured patterns that can emerge from pursuing this regularity objective. We also demonstrate the strength of our method in a multi-object robotic manipulation environment. We incorporate RaIR into free play and use it to complement the model’s epistemic uncertainty as an intrinsic reward. Doing so, we witness the autonomous construction of towers and other regular structures during free play, which leads to a substantial improvement in zero-shot downstream task performance on assembly tasks.'}",https://openreview.net{'value': '/pdf/6d14c7affdc950661caf850922e76e6575fcf49b.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=AuXd54odxm,{'value': 'Extraction and Recovery of Spatio-Temporal Structure in Latent Dynamics Alignment with Diffusion Models'},Yule Wang; Zijing Wu; Chengrui Li; Anqi Wu,~Yule_Wang1; ~Zijing_Wu1; ~Chengrui_Li1; ~Anqi_Wu4,"{'value': ['Neural distribution alignment', 'Diffusion model', 'Neuroscience', 'Neural decoding']}","{'value': ""In the field of behavior-related brain computation, it is necessary to align raw neural signals against the drastic domain shift among them. A foundational framework within neuroscience research posits that trial-based neural population activities rely on low-dimensional latent dynamics, thus focusing on the latter greatly facilitates the alignment procedure. Despite this field's progress, existing methods ignore the intrinsic spatio-temporal structure during the alignment phase. Hence, their solutions usually lead to poor quality in latent dynamics structures and overall performance. To tackle this problem, we propose an alignment method ERDiff, which leverages the expressivity of the diffusion model to preserve the spatio-temporal structure of latent dynamics. Specifically, the latent dynamics structures of the source domain are first extracted by a diffusion model. Then, under the guidance of this diffusion model, such structures are well-recovered through a maximum likelihood alignment procedure in the target domain. We first demonstrate the effectiveness of our proposed method on a synthetic dataset. Then, when applied to neural recordings from the non-human primate motor cortex, under both cross-day and inter-subject settings, our method consistently manifests its capability of preserving the spatio-temporal structure of latent dynamics and outperforms existing approaches in alignment goodness-of-fit and neural decoding performance.""}",https://openreview.net{'value': '/pdf/e37f3ea604d1ec090a44790a994d1c32a75a5799.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=AtHJ7TLheF,{'value': 'Calibrate and Boost Logical Expressiveness of GNN Over Multi-Relational and Temporal Graphs'},Dingmin Wang; Yeyuan Chen,~Dingmin_Wang1; ~Yeyuan_Chen1,"{'value': ['Knowledge Graphs', 'First-Order Logic', 'Temporal Knowledge Graph', 'Graph Neural Networks']}","{'value': 'As a powerful framework for graph representation learning, Graph Neural Networks (GNNs) have garnered significant attention in recent years. However, to the best of our knowledge, there has been no formal analysis of the logical expressiveness of GNNs as Boolean node classifiers over multi-relational graphs, where each edge carries a specific relation type. In this paper, we investigate $\\mathcal{FOC}_2$, a fragment of first-order logic with two variables and counting quantifiers. On the negative side, we demonstrate that the R$^2$-GNN architecture, which extends the local message passing GNN by incorporating global readout, fails to capture $\\mathcal{FOC}_2$ classifiers in the general case. Nevertheless, on the positive side, we establish that R$^2$-GNNs models are equivalent to $\\mathcal{FOC}_2$ classifiers under certain restricted yet reasonable scenarios. To address the limitations of R$^2$-GNNs regarding expressiveness, we propose a simple graph transformation technique, akin to a preprocessing step, which can be executed in linear time. This transformation enables R$^2$-GNNs to effectively capture any $\\mathcal{FOC}_2$ classifiers when applied to the ""transformed"" input graph. Moreover, we extend our analysis of expressiveness and graph transformation to temporal graphs, exploring several temporal GNN architectures and providing an expressiveness hierarchy for them. To validate our findings, we implement R$^2$-GNNs and the graph transformation technique and conduct empirical tests in node classification tasks against various well-known GNN architectures that support multi-relational or temporal graphs. Our experimental results consistently demonstrate that R$^2$-GNN with the graph transformation outperforms the baseline methods on both synthetic and real-world datasets'}",https://openreview.net{'value': '/pdf/a315bb296babc05ae062e895f00aa7a9bb49905b.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=AiEipk1X0c,{'value': 'A Deep Instance Generative Framework for MILP Solvers Under Limited Data Availability'},Zijie Geng; Xijun Li; Jie Wang; Xiao Li; Yongdong Zhang; Feng Wu,~Zijie_Geng1; ~Xijun_Li1; ~Jie_Wang1; ~Xiao_Li19; ~Yongdong_Zhang2; ~Feng_Wu1,"{'value': ['Learning to Optimize', 'Machine Learning for Combinatorial Optimization', 'Mixed-Integer Linear Programming', 'Graph Generation']}","{'value': 'In the past few years, there has been an explosive surge in the use of machine learning (ML) techniques to address combinatorial optimization (CO) problems, especially mixed-integer linear programs (MILPs). Despite the achievements, the limited availability of real-world instances often leads to sub-optimal decisions and biased solver assessments, which motivates a suite of synthetic MILP instance generation techniques. However, existing methods either rely heavily on expert-designed formulations or struggle to capture the rich features of real-world instances. To tackle this problem, we propose G2MILP, *the first* deep generative framework for MILP instances. Specifically, G2MILP represents MILP instances as bipartite graphs, and applies a masked variational autoencoder to iteratively corrupt and replace parts of the original graphs to generate new ones. The appealing feature of G2MILP is that it can learn to generate novel and realistic MILP instances without prior expert-designed formulations, while preserving the structures and computational hardness of real-world datasets, simultaneously. Thus the generated instances can facilitate downstream tasks for enhancing MILP solvers under limited data availability. We design a suite of benchmarks to evaluate the quality of the generated MILP instances. Experiments demonstrate that our method can produce instances that closely resemble real-world datasets in terms of both structures and computational hardness. The deliverables are released at [https://miralab-ustc.github.io/L2O-G2MILP](https://miralab-ustc.github.io/L2O-G2MILP).'}",https://openreview.net{'value': '/pdf/f8e13c7bc3b63456194664bbb7c8513b4af9f460.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=AYLlZMmUbo,{'value': 'Two Heads are Better Than One: A Simple Exploration Framework for Efficient Multi-Agent Reinforcement Learning'},Jiahui Li; Kun Kuang; Baoxiang Wang; Xingchen Li; Fei Wu; Jun Xiao; Long Chen,~Jiahui_Li2; ~Kun_Kuang1; ~Baoxiang_Wang1; ~Xingchen_Li1; ~Fei_Wu2; ~Jun_Xiao1; ~Long_Chen8,"{'value': ['multi-agent reinforcement learning', 'influence-based exploration']}","{'value': 'Exploration strategy plays an important role in reinforcement learning, especially in sparse-reward tasks. In cooperative multi-agent reinforcement learning~(MARL), designing a suitable exploration strategy is much more challenging due to the large state space and the complex interaction among agents. Currently, mainstream exploration methods in MARL either contribute to exploring the unfamiliar states which are large and sparse, or measuring the interaction among agents with high computational costs. We found an interesting phenomenon that different kinds of exploration plays a different role in different MARL scenarios, and choosing a suitable one is often more effective than designing an exquisite algorithm. In this paper, we propose a exploration method that incorporate the \\underline{C}uri\\underline{O}sity-based and \\underline{IN}fluence-based exploration~(COIN) which is simple but effective in various situations. First, COIN measures the influence of each agent on the other agents based on mutual information theory and designs it as intrinsic rewards which are applied to each individual value function. Moreover, COIN computes the curiosity-based intrinsic rewards via prediction errors which are added to the extrinsic reward. For integrating the two kinds of intrinsic rewards, COIN utilizes a novel framework in which they complement each other and lead to a sufficient and effective exploration on cooperative MARL tasks. We perform extensive experiments on different challenging benchmarks, and results across different scenarios show the superiority of our method.'}",https://openreview.net{'value': '/pdf/6854c6c89e85c2e9d9f19ca18bbbe7bb269c8719.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=AG9A7Ae9r3,{'value': 'DIFFER:Decomposing Individual Reward for Fair Experience Replay in Multi-Agent Reinforcement Learning'},Xunhan Hu; Jian Zhao; Wengang Zhou; Ruili Feng; Houqiang Li,~Xunhan_Hu1; ~Jian_Zhao7; ~Wengang_Zhou1; ~Ruili_Feng1; ~Houqiang_Li1,{'value': ['Experience Replay; Reinforcement Learning; Multi-Agent System']},"{'value': 'Cooperative multi-agent reinforcement learning (MARL) is a challenging task, as agents must learn complex and diverse individual strategies from a shared team reward. However, existing methods struggle to distinguish and exploit important individual experiences, as they lack an effective way to decompose the team reward into individual rewards. To address this challenge, we propose DIFFER, a powerful theoretical framework for decomposing individual rewards to enable fair experience replay in MARL.\nBy enforcing the invariance of network gradients, we establish a partial differential equation whose solution yields the underlying individual reward function. The individual TD-error can then be computed from the solved closed-form individual rewards, indicating the importance of each piece of experience in the learning task and guiding the training process. Our method elegantly achieves an equivalence to the original learning framework when individual experiences are homogeneous, while also adapting to achieve more muscular efficiency and fairness when diversity is observed.\nOur extensive experiments on popular benchmarks validate the effectiveness of our theory and method, demonstrating significant improvements in learning efficiency and fairness. \nCode is available in supplement material.'}",https://openreview.net{'value': '/pdf/6d50d5c9ddb64383ad69f661c93f96c602a7027e.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=A6X9y8n4sT,{'value': 'One-2-3-45: Any Single Image to 3D Mesh in 45 Seconds without Per-Shape Optimization'},Minghua Liu; Chao Xu; Haian Jin; Linghao Chen; Mukund Varma T; Zexiang Xu; Hao Su,~Minghua_Liu1; ~Chao_Xu6; ~Haian_Jin1; ~Linghao_Chen2; ~Mukund_Varma_T1; ~Zexiang_Xu1; ~Hao_Su1,"{'value': ['single image reconstruction', '3d generation', 'mesh reconstruction', 'diffusion models']}","{'value': 'Single image 3D reconstruction is an important but challenging task that requires extensive knowledge of our natural world. Many existing methods solve this problem by optimizing a neural radiance field under the guidance of 2D diffusion models but suffer from lengthy optimization time, 3D inconsistency results, and poor geometry. In this work, we propose a novel method that takes a single image of any object as input and generates a full 360-degree 3D textured mesh in a single feed-forward pass. Given a single image, we first use a view-conditioned 2D diffusion model, Zero123, to generate multi-view images for the input view, and then aim to lift them up to 3D space. Since traditional reconstruction methods struggle with inconsistent multi-view predictions, we build our 3D reconstruction module upon an SDF-based generalizable neural surface reconstruction method and propose several critical training strategies to enable the reconstruction of 360-degree meshes. Without costly optimizations, our method reconstructs 3D shapes in significantly less time than existing methods. Moreover, our method favors better geometry, generates more 3D consistent results, and adheres more closely to the input image. We evaluate our approach on both synthetic data and in-the-wild images and demonstrate its superiority in terms of both mesh quality and runtime. In addition, our approach can seamlessly support the text-to-3D task by integrating with off-the-shelf text-to-image diffusion models.'}",https://openreview.net{'value': '/pdf/2e70089a720284724521cbc786ab46b09f2f8fa5.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=A6JDQDv7Nt,{'value': 'Keep Various Trajectories: Promoting Exploration of Ensemble Policies in Continuous Control'},Chao Li; Chen GONG; Qiang He; Xinwen Hou,~Chao_Li28; ~Chen_GONG8; ~Qiang_He1; ~Xinwen_Hou2,"{'value': ['Reinforcement Learning', 'Ensemble Exploration', 'Control Tasks']}","{'value': 'The combination of deep reinforcement learning (DRL) with ensemble methods has been proved to be highly effective in addressing complex sequential decision-making problems. This success can be primarily attributed to the utilization of multiple models, which enhances both the robustness of the policy and the accuracy of value function estimation. However, there has been limited analysis of the empirical success of current ensemble RL methods thus far. Our new analysis reveals that the sample efficiency of previous ensemble DRL algorithms may be limited by sub-policies that are not as diverse as they could be. Motivated by these findings, our study introduces a new ensemble RL algorithm, termed \\textbf{T}rajectories-awar\\textbf{E} \\textbf{E}nsemble exploratio\\textbf{N} (TEEN). The primary goal of TEEN is to  maximize the expected return while promoting more diverse trajectories. Through extensive experiments, we demonstrate that TEEN not only enhances the sample diversity of the ensemble policy compared to using sub-policies alone but also improves the performance over ensemble RL algorithms. On average, TEEN outperforms the baseline ensemble DRL algorithms by 41\\% in performance on the tested representative environments.'}",https://openreview.net{'value': '/pdf/a0b9adf4a30b63bad5dc1e530e3228d2997f4ba0.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=A5yMv7XPuA,{'value': 'Combinatorial Group Testing with Selfish Agents'},Giorgos Chionas; Dariusz Rafal Kowalski; Piotr Krysta,g.chionas@liverpool.ac.uk; ~Dariusz_Rafal_Kowalski1; ~Piotr_Krysta1,"{'value': ['Combinatorial Group Testing', 'Adversarial Equilibrium', 'Contention Resolution', 'selfish agents', 'learning time', 'adaptive learning algorithms']}","{'value': ""We study the Combinatorial Group Testing (CGT) problem in a novel game-theoretic framework, with a solution concept of Adversarial Equilibrium (AE). In this new framework, we have $n$ selfish agents corresponding to the elements of the universe $[n] =\\{0,1,\\ldots,n-1\\}$ and a hidden set $K \\subseteq [n]$ of active agents of size $|K| = k \\ll n$. In each round of the game, each active agent decides if it is present in a query $Q \\subseteq [n]$, and all agents receive feedback on $Q \\cap K$. The goal of each active agent is to assure that its id could be learned from the feedback as early as possible. \n\nWe present a comprehensive set of results in this new game, where we design and analyze adaptive algorithmic strategies of agents which are AE's. In particular, if $k$ is known to the agents, then we design adaptive AE strategies with provably near optimal learning time of $O(k \\log(n/k))$. In the case of unknown $k$, we design an adaptive AE strategies with learning time of order $n^k$, and we prove a lower bound of $\\Omega(n)$ on the learning time of any such algorithmic strategies. This shows a strong separations between the two models of known and unknown $k$, as well as between the classic CGT, i.e., without selfish agents, and our game theoretic CGT model.""}",https://openreview.net{'value': '/pdf/a422817c9921f7ca9764eb064a8d4e10e66aff62.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=9i8MD9btc8,{'value': '(Almost) Provable Error Bounds Under Distribution Shift via Disagreement Discrepancy'},Elan Rosenfeld; Saurabh Garg,~Elan_Rosenfeld1; ~Saurabh_Garg3,"{'value': ['accuracy estimation', 'error bounds', 'distribution shift', 'unsupervised domain adaptation']}","{'value': 'We derive a new, (almost) guaranteed upper bound on the error of deep neural networks under distribution shift using unlabeled test data. Prior methods are either vacuous in practice or accurate on average but heavily underestimate error for a sizeable fraction of shifts. In particular, the latter only give guarantees based on complex continuous measures such as test calibration, which cannot be identified without labels, and are therefore unreliable. Instead, our bound requires a simple, intuitive condition which is well justified by prior empirical works and holds in practice effectively 100\\% of the time. The bound is inspired by $\\mathcal{H}\\Delta\\mathcal{H}$-divergence but is easier to evaluate and substantially tighter, consistently providing non-vacuous test error upper bounds. Estimating the bound requires optimizing one multiclass classifier to disagree with another, for which some prior works have used sub-optimal proxy losses; we devise a ""disagreement loss"" which is theoretically justified and performs better in practice. We expect this loss can serve as a drop-in replacement for future methods which require maximizing multiclass disagreement. Across a wide range of natural and synthetic distribution shift benchmarks, our method gives valid error bounds while achieving average accuracy comparable to—though not better than—competitive estimation baselines.'}",https://openreview.net{'value': '/pdf/202205a6734e166164d8f4a2f8cbd19ddeba00fa.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=9cQzO3rXgR,{'value': 'Diffusion Representation for Asymmetric Kernels via Magnetic Transform'},Mingzhen He; FAN He; Ruikai Yang; Xiaolin Huang,~Mingzhen_He1; ~FAN_He1; ruikai.yang@sjtu.edu.cn; ~Xiaolin_Huang1,"{'value': ['Asymmetric kernels', 'diffusion maps', 'magnetic transform', 'dimension reduction']}","{'value': 'As a nonlinear dimension reduction technique, the diffusion map (DM) has been widely used. \nIn DM, kernels play an important role for capturing the nonlinear relationship of data. However, only symmetric kernels can be used now, which prevents the use of DM in directed graphs, trophic networks, and other real-world scenarios where the intrinsic and extrinsic geometries in data are asymmetric. A promising technique is the magnetic transform which  converts an asymmetric matrix to a Hermitian one. However, we are facing essential problems, including how diffusion distance could be preserved and how divergence could be avoided during diffusion process. Via theoretical proof, we successfully establish a diffusion representation framework with the magnetic transform, named MagDM. The effectiveness and robustness for dealing data endowed with asymmetric proximity are demonstrated on three synthetic datasets and two trophic networks.'}",https://openreview.net{'value': '/pdf/cd6896954605535d320234c4ce876981201a7322.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=9cF6RUwMe7,{'value': 'Learning Space-Time Continuous Latent Neural PDEs from Partially Observed States'},Valerii Iakovlev; Markus Heinonen; Harri Lähdesmäki,~Valerii_Iakovlev1; ~Markus_Heinonen1; ~Harri_Lähdesmäki1,"{'value': ['neural', 'PDEs', 'neural PDEs', 'partial observations', 'space time continuous']}","{'value': 'We introduce a novel grid-independent model for learning partial differential equations (PDEs) from noisy and partial observations on irregular spatiotemporal grids. We propose a space-time continuous latent neural PDE model with an efficient probabilistic framework and a novel encoder design for improved data efficiency and grid independence. The latent state dynamics are governed by a PDE model that combines the collocation method and the method of lines. We employ amortized variational inference for approximate posterior estimation and utilize a multiple shooting technique for enhanced training speed and stability. Our model demonstrates state-of-the-art performance on complex synthetic and real-world datasets, overcoming limitations of previous approaches and effectively handling partially-observed data. The proposed model outperforms recent methods, showing its potential to advance data-driven PDE modeling and enabling robust, grid-independent modeling of complex partially-observed dynamic processes across various domains.'}",https://openreview.net{'value': '/pdf/39f06a9ef80aed1de24764f262e57c284d0f90d7.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=9S8oVumknA,{'value': 'Intervention Generalization: A View from Factor Graph Models'},Gecia Bravo-Hermsdorff; David Watson; Jialin Yu; Jakob Zeitler; Ricardo Silva,~Gecia_Bravo-Hermsdorff1; ~David_Watson2; ~Jialin_Yu2; ~Jakob_Zeitler1; ~Ricardo_Silva1,"{'value': ['Causality', 'experimental design']}","{'value': 'One of the goals of causal inference is to generalize from past experiments and observational data to novel conditions. While it is in principle possible to eventually learn a mapping from a novel experimental condition to an outcome of interest, provided a sufficient variety of experiments is available in the training data, coping with a large combinatorial space of possible interventions is hard. Under a typical sparse experimental design, this mapping is ill-posed without relying on heavy regularization or prior distributions. Such assumptions may or may not be reliable, and can be hard to defend or test. In this paper, we take a close look at how to warrant a leap from past experiments to novel conditions based on minimal assumptions about the factorization of the distribution of the manipulated system, communicated in the well-understood language of factor graph models. A postulated interventional factor model (IFM) may not always be informative, but it conveniently abstracts away a need for explicitly modeling unmeasured confounding and feedback mechanisms, leading to directly testable claims. Given an IFM and datasets from a collection of experimental regimes, we derive conditions for identifiability of the expected outcomes of new regimes never observed in these training data. We implement our framework using several efficient algorithms, and apply them on a range of semi-synthetic experiments.'}",https://openreview.net{'value': '/pdf/e442d024f583bc23ca5d76b42fcac5ae9bcb7958.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=9QEVJ9qm46,{'value': 'Robust Learning with Progressive Data Expansion Against Spurious Correlation'},Yihe Deng; Yu Yang; Baharan Mirzasoleiman; Quanquan Gu,~Yihe_Deng1; ~Yu_Yang4; ~Baharan_Mirzasoleiman1; ~Quanquan_Gu1,"{'value': ['spurious correlation', 'robustness', 'robust learning']}","{'value': ""While deep learning models have shown remarkable performance in various tasks, they are susceptible to learning non-generalizable _spurious features_ rather than the core features that are genuinely correlated to the true label. In this paper, beyond existing analyses of linear models, we theoretically examine the learning process of a two-layer nonlinear convolutional neural network in the presence of spurious features. Our analysis suggests that imbalanced data groups and easily learnable spurious features can lead to the dominance of spurious features during the learning process. In light of this, we propose a new training algorithm called **PDE** that efficiently enhances the model's robustness for a better worst-group performance. PDE begins with a group-balanced subset of training data and progressively expands it to facilitate the learning of the core features. Experiments on synthetic and real-world benchmark datasets confirm the superior performance of our method on models such as ResNets and Transformers. On average, our method achieves a $2.8$ \\% improvement in worst-group accuracy compared with the state-of-the-art method, while enjoying up to $10\\times$ faster training efficiency.""}",https://openreview.net{'value': '/pdf/88df7e8e1efe1bc5ecb4377d9237cd5b22b6cf10.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=9B9J8X23LK,{'value': 'Accelerating Motion Planning via Optimal Transport'},An Thai Le; Georgia Chalvatzaki; Armin Biess; Jan Peters,~An_Thai_Le1; ~Georgia_Chalvatzaki1; ~Armin_Biess1; ~Jan_Peters3,"{'value': ['Motion Planning', 'Trajectory Optimization', 'Optimal Transport']}","{'value': ""Motion planning is still an open problem for many disciplines, e.g., robotics, autonomous driving, due to their need for high computational resources that hinder real-time, efficient decision-making. A class of methods striving to provide smooth solutions is gradient-based trajectory optimization. However, those methods usually suffer from bad local minima, while for many settings, they may be inapplicable due to the absence of easy-to-access gradients of the optimization objectives. In response to these issues, we introduce Motion Planning via Optimal Transport (MPOT)---a \\textit{gradient-free} method that optimizes a batch of smooth trajectories over highly nonlinear costs, even for high-dimensional tasks, while imposing smoothness through a Gaussian Process dynamics prior via the planning-as-inference perspective. To facilitate batch trajectory optimization, we introduce an original zero-order and highly-parallelizable update rule----the Sinkhorn Step, which uses the regular polytope family for its search directions. Each regular polytope, centered on trajectory waypoints, serves as a local cost-probing neighborhood, acting as a \\textit{trust region} where the Sinkhorn Step ``transports'' local waypoints toward low-cost regions. We theoretically show that Sinkhorn Step guides the optimizing parameters toward local minima regions of non-convex objective functions. We then show the efficiency of MPOT in a range of problems from low-dimensional point-mass navigation to high-dimensional whole-body robot motion planning, evincing its superiority compared to popular motion planners, paving the way for new applications of optimal transport in motion planning.""}",https://openreview.net{'value': '/pdf/d5b6cbf0c010ea92b372c87eba1a7206ef0fb145.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=99MHSB98yZ,{'value': 'Scenario Diffusion: Controllable Driving Scenario Generation With Diffusion'},Ethan Pronovost; Meghana Reddy Ganesina; Noureldin Hendy; Zeyu Wang; Andres Morales; Kai Wang; Nicholas Roy,~Ethan_Pronovost1; ~Meghana_Reddy_Ganesina1; ~Noureldin_Hendy1; ~Zeyu_Wang13; ~Andres_Morales1; kai@zoox.com; ~Nicholas_Roy1,"{'value': ['Deep Learning', '(Other) Applications', '(Other) Machine Learning Topics']}","{'value': 'Automated creation of synthetic traffic scenarios is a key part of scaling the safety validation of autonomous vehicles (AVs). In this paper, we propose Scenario Diffusion, a novel diffusion-based architecture for generating traffic scenarios that enables controllable scenario generation. We combine latent diffusion, object detection and trajectory regression to generate distributions of synthetic agent poses, orientations and trajectories simultaneously. This distribution is conditioned on the map and sets of tokens describing the desired scenario to provide additional control over the generated scenario. We show that our approach has sufficient expressive capacity to model diverse traffic patterns and generalizes to different geographical regions.'}",https://openreview.net{'value': '/pdf/7cea04c54184d6fcc4beb1aa2e633e70478c877a.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=966yOmwk6d,{'value': 'Towards Data-Algorithm Dependent Generalization: a Case Study on Overparameterized Linear Regression'},Jing Xu; Jiaye Teng; Yang Yuan; Andrew C Yao,~Jing_Xu4; ~Jiaye_Teng2; ~Yang_Yuan4; ~Andrew_C_Yao1,"{'value': ['data-algorithm dependent generalization analysis', 'overparameterized linear regression']}","{'value': 'One of the major open problems in machine learning is to characterize generalization in the overparameterized regime, where most traditional generalization bounds become inconsistent even for overparameterized linear regression. In many scenarios, this failure can be attributed to obscuring the crucial interplay between the training algorithm and the underlying data distribution. This paper demonstrate that the generalization behavior of overparameterized model should be analyzed in a both data-relevant and algorithm-relevant manner. To make a formal characterization, We introduce a notion called data-algorithm compatibility, which considers the generalization behavior of the entire data-dependent training trajectory, instead of traditional last-iterate analysis.  We validate our claim by studying the setting of solving overparameterized linear regression with gradient descent. Specifically, we perform a data-dependent trajectory analysis and derive a sufficient condition for compatibility in such a setting. Our theoretical results demonstrate that if we take early stopping iterates into consideration, generalization can hold with significantly weaker restrictions on the problem instance than the previous last-iterate analysis.'}",https://openreview.net{'value': '/pdf/277fbfbb800e3cf082d96404b63a0c76e66deafa.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=94rKFkcm56,{'value': 'Distance-Restricted Folklore Weisfeiler-Leman GNNs with Provable Cycle Counting Power'},Junru Zhou; Jiarui Feng; Xiyuan Wang; Muhan Zhang,~Junru_Zhou1; ~Jiarui_Feng1; ~Xiyuan_Wang1; ~Muhan_Zhang1,"{'value': ['Cycle counting', 'graph neural networks']}","{'value': 'The ability of graph neural networks (GNNs) to count certain graph substructures, especially cycles, is important for the success of GNNs on a wide range of tasks. It has been recently used as a popular metric for evaluating the expressive power of GNNs. Many of the proposed GNN models with provable cycle counting power are based on subgraph GNNs, i.e., extracting a bag of subgraphs from the input graph, generating representations for each subgraph, and using them to augment the representation of the input graph. However, those methods require heavy preprocessing, and suffer from high time and memory costs. In this paper, we overcome the aforementioned limitations of subgraph GNNs by proposing a novel class of GNNs---$d$-Distance-Restricted FWL(2) GNNs, or $d$-DRFWL(2) GNNs, based on the well-known FWL(2) algorithm. As a heuristic method for graph isomorphism testing, FWL(2) colors all node pairs in a graph and performs message passing among those node pairs. In order to balance the expressive power and complexity, $d$-DRFWL(2) GNNs simplify FWL(2) by restricting the range of message passing to node pairs whose mutual distances are at most $d$. This way, $d$-DRFWL(2) GNNs exploit graph sparsity while avoiding the expensive subgraph extraction operations in subgraph GNNs, making both the time and space complexity lower. We theoretically investigate both the discriminative power and the cycle counting power of $d$-DRFWL(2) GNNs. Our most important finding is that $d$-DRFWL(2) GNNs have provably strong cycle counting power even with $d=2$: they can count all 3, 4, 5, 6-cycles. Since 6-cycles (e.g., benzene rings) are ubiquitous in organic molecules, being able to detect and count them is crucial for achieving robust and generalizable performance on molecular tasks. Experiments on both synthetic datasets and molecular datasets verify our theory. To the best of our knowledge, 2-DRFWL(2) GNN is the most efficient GNN model to date (both theoretically and empirically) that can count up to 6-cycles.'}",https://openreview.net{'value': '/pdf/9353fb302ef17d6e38c2f57b613e7111fe1c8a18.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=919tWtJPXe,{'value': 'Self-supervised Object-Centric Learning for Videos'},Görkay Aydemir; Weidi Xie; Fatma Guney,~Görkay_Aydemir1; ~Weidi_Xie3; ~Fatma_Guney1,"{'value': ['Unsupervised Object Discovery', 'Unsupervised Video Object Segmentation', 'Object-Centric Learning', 'Unsupervised Video Multi Object Segmentation']}","{'value': 'Unsupervised multi-object segmentation has shown impressive results on images by utilizing powerful semantics learned from self-supervised pretraining. An additional modality such as depth or motion is often used to facilitate the segmentation in video sequences. However, the performance improvements observed in synthetic sequences, which rely on the robustness of an additional cue, do not translate to more challenging real-world scenarios. In this paper, we propose the first fully unsupervised method for segmenting multiple objects in real-world sequences. Our object-centric learning framework spatially binds objects to slots on each frame and then relates these slots across frames. From these temporally-aware slots, the training objective is to reconstruct the middle frame in a high-level semantic feature space. We propose a masking strategy by dropping a significant portion of tokens in the feature space for efficiency and regularization. Additionally, we address over-clustering by merging slots based on similarity. Our method can successfully segment multiple instances of complex and high-variety classes in YouTube videos.'}",https://openreview.net{'value': '/pdf/56923a879f1c35e105843cc792fbd1a87f08c247.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=90O5cvFZkZ,{'value': 'GUST: Combinatorial Generalization by Unsupervised Grouping with Neuronal Coherence'},Hao Zheng; Hui Lin; Rong Zhao,~Hao_Zheng2; ~Hui_Lin5; ~Rong_Zhao3,"{'value': ['neuronal coherence', 'combinatorial generalization', 'perceptual grouping', 'unsupervised learning']}","{'value': 'Dynamically grouping sensory information into structured entities is essential for understanding the world of combinatorial nature. However, the grouping ability and therefore combinatorial generalization are still challenging artificial neural networks. Inspired by the evidence that successful grouping is indicated by neuronal coherence in the human brain, we introduce GUST (Grouping Unsupervisely by Spike Timing network), an iterative network architecture with biological constraints to bias the network towards a dynamical state of neuronal coherence that softly reflects the grouping information in the temporal structure of its spiking activity. We evaluate and analyze the model on synthetic datasets. Interestingly, the segregation ability is directly learned from superimposed stimuli with a succinct unsupervised objective. Two learning stages are present, from coarsely perceiving global features to additionally capturing local features. Further, the learned symbol-like building blocks can be systematically composed to represent novel scenes in a bio-plausible manner.'}",https://openreview.net{'value': '/pdf/37587afc6ee47f8e58e6fef17daddffc6e2587b3.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=8xx0pyMOW1,{'value': 'Training neural operators to preserve invariant measures of chaotic attractors'},Ruoxi Jiang; Peter Y. Lu; Elena Orlova; Rebecca Willett,~Ruoxi_Jiang1; ~Peter_Y._Lu1; ~Elena_Orlova1; ~Rebecca_Willett1,"{'value': ['Neural operators', 'contrastive learning', 'optimal transport', 'chaotic attractors', 'invariant measures']}","{'value': 'Chaotic systems make long-horizon forecasts difficult because small perturbations in initial conditions cause trajectories to diverge at an exponential rate. In this setting, neural operators trained to minimize squared error losses, while capable of accurate short-term forecasts, often fail to reproduce statistical or structural properties of the dynamics over longer time horizons and can yield degenerate results. In this paper, we propose an alternative framework designed to preserve invariant measures of chaotic attractors that characterize the time-invariant statistical properties of the dynamics. Specifically, in the multi-environment setting (where each sample trajectory is governed by slightly different dynamics),  we consider two novel approaches to training with noisy data. First, we propose a loss based on the optimal transport distance between the observed dynamics and the neural operator outputs. This approach requires expert knowledge of the underlying physics to determine what statistical features should be included in the optimal transport loss. Second, we show that a  contrastive learning framework, which does not require any specialized prior knowledge, can preserve statistical properties of the dynamics nearly as well as the optimal transport approach. On a variety of chaotic systems, our method is shown empirically to preserve invariant measures of chaotic attractors.'}",https://openreview.net{'value': '/pdf/b14a5dfa81903acdb97fbc7b18430ff742f2e28f.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=8aunGrXdkl,{'value': 'Convex and Non-convex Optimization Under Generalized Smoothness'},Haochuan Li; Jian Qian; Yi Tian; Alexander Rakhlin; Ali Jadbabaie,~Haochuan_Li2; ~Jian_Qian2; ~Yi_Tian1; ~Alexander_Rakhlin1; ~Ali_Jadbabaie1,"{'value': ['Optimization', 'Convergence', 'Generalized smoothness']}","{'value': ""Classical analysis of convex and non-convex optimization methods often requires the Lipschitz continuity of the gradient, which limits the analysis to functions bounded by quadratics. Recent work relaxed this requirement to a non-uniform smoothness condition with the Hessian norm  bounded by an affine function of the gradient norm, and proved convergence in the non-convex setting via gradient clipping, assuming bounded noise. In this paper, we further generalize this non-uniform smoothness condition and develop a simple, yet powerful analysis technique that bounds the gradients along the trajectory, thereby leading to  stronger results for both convex and non-convex optimization problems. In particular, we obtain the classical convergence rates for (stochastic) gradient descent and Nesterov's accelerated gradient method in the convex and/or non-convex setting under this general smoothness condition. The new analysis approach does not require gradient clipping and allows heavy-tailed noise with bounded variance in the stochastic setting.""}",https://openreview.net{'value': '/pdf/8155b31c9cecd6c6119f248dbdcd5dcc083336ea.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=8Oukmqfek2,{'value': 'Rethinking Gauss-Newton for learning over-parameterized models'},Michael Arbel; Romain Menegaux; Pierre Wolinski,~Michael_Arbel1; ~Romain_Menegaux1; ~Pierre_Wolinski1,"{'value': ['implicit bias', 'gauss newton']}","{'value': ""This work studies the global convergence and implicit bias of Gauss Newton's (GN) when optimizing over-parameterized one-hidden layer networks in the mean-field regime. \nWe first establish a global convergence result for GN in the continuous-time limit exhibiting a faster convergence rate compared to GD due to improved conditioning. \nWe then perform an empirical study on a synthetic regression task to investigate the implicit bias of GN's method.\nWhile GN is consistently faster than GD in finding a global optimum, the learned model generalizes well on test data when starting from random initial weights with a small variance and using a small step size to slow down convergence. \nSpecifically, our study shows that such a setting results in a hidden learning phenomenon, where the dynamics are able to recover features with good generalization properties despite the model having sub-optimal training and test performances due to an under-optimized linear layer. This study exhibits a trade-off between the convergence speed of GN and the generalization ability of the learned solution.""}",https://openreview.net{'value': '/pdf/7f16160de5a9cae07795ae31b8b7c20181c3af3d.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=898RcRYWCg,{'value': 'Tame a Wild Camera: In-the-Wild Monocular Camera Calibration'},Shengjie Zhu; Abhinav Kumar; Masa Hu; Xiaoming Liu,~Shengjie_Zhu1; ~Abhinav_Kumar1; ~Masa_Hu1; ~Xiaoming_Liu2,{'value': ['Monocular Camera Calibration; Camera Pose Estimation; Image Editing']},"{'value': '3D sensing for monocular in-the-wild images, e.g., depth estimation and 3D object detection, has become increasingly important.\nHowever, the unknown intrinsic parameter hinders their development and deployment.\nPrevious methods for the monocular camera calibration rely on specific 3D objects or strong geometry prior, such as using a checkerboard or imposing a Manhattan World assumption.\nThis work instead calibrates intrinsic via exploiting the monocular 3D prior.\nGiven an undistorted image as input, our method calibrates the complete 4 Degree-of-Freedom (DoF) intrinsic parameters.\nFirst, we show intrinsic is determined by the two well-studied monocular priors: monocular depthmap and surface normal map.\nHowever, this solution necessitates a low-bias and low-variance depth estimation.\nAlternatively, we introduce the incidence field, defined as the incidence rays between points in 3D space and pixels in the 2D imaging plane.\nWe show that: 1) The incidence field is a pixel-wise parametrization of the intrinsic invariant to image cropping and resizing.\n2) The incidence field is a learnable monocular 3D prior, determined pixel-wisely by up-to-sacle monocular depthmap and surface normal.\nWith the estimated incidence field, a robust RANSAC algorithm recovers intrinsic.\nWe show the effectiveness of our method through superior performance on synthetic and zero-shot testing datasets.\nBeyond calibration, we demonstrate downstream applications in image manipulation detection \\& restoration, uncalibrated two-view pose estimation, and 3D sensing.'}",https://openreview.net{'value': '/pdf/72e46f248ef210c03cbdacbf2c0a1044fad61fb7.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=805CW5w2CY,{'value': 'A Simple Solution for Offline Imitation from Observations and Examples with Possibly Incomplete Trajectories'},Kai Yan; Alex Schwing; Yu-Xiong Wang,~Kai_Yan1; ~Alex_Schwing1; ~Yu-Xiong_Wang1,"{'value': ['offline Imitation learning', 'learning from observations', 'positive-unlabeled learning']}","{'value': 'Offline imitation from observations aims to solve MDPs where only task-specific expert states and task-agnostic non-expert state-action pairs are available. Offline imitation is useful in real-world scenarios where arbitrary interactions are costly and expert actions are unavailable. The state-of-the-art ‘DIstribution Correction Estimation’ (DICE) methods minimize divergence of state occupancy between expert and learner policies and retrieve a policy with weighted behavior cloning; however, their results are unstable when learning from incomplete trajectories, due to a non-robust optimization in the dual domain. To address the issue, in this paper, we propose Trajectory-Aware Imitation Learning from Observations (TAILO). TAILO uses a discounted sum along the future trajectory as the weight for weighted behavior cloning. The terms for the sum are scaled by the output of a discriminator, which aims to identify expert states. Despite simplicity, TAILO works well if there exist trajectories or segments of expert behavior in the task-agnostic data, a common assumption in prior work. In experiments across multiple testbeds, we find TAILO to be more robust and effective, particularly with incomplete trajectories.'}",https://openreview.net{'value': '/pdf/968da9db0b0d808d6b1a43b7e9e24756264a3339.pdf'},{'title_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=7rm3OcASkg,{'value': 'DP-Mix: Mixup-based Data Augmentation for Differentially Private Learning'},Wenxuan Bao; Francesco Pittaluga; Vijay Kumar b g; Vincent Bindschaedler,~Wenxuan_Bao2; ~Francesco_Pittaluga2; ~Vijay_Kumar_b_g1; ~Vincent_Bindschaedler1,"{'value': ['differential privacy', 'deep learning', 'data augmentation']}","{'value': 'Data augmentation techniques, such as image transformations and combinations, are highly effective at improving the generalization of computer vision models, especially when training data is limited. However, such techniques are fundamentally incompatible with differentially private learning approaches, due to the latter’s built-in assumption that each training image’s contribution to the learned model is bounded. In this paper, we investigate why naive applications of multi-sample data augmentation techniques, such as mixup, fail to achieve good performance and propose two novel data augmentation techniques specifically designed for the constraints of differentially private learning. Our first technique, DP-Mix_Self, achieves SoTA classification performance across a range of datasets and settings by performing mixup on self-augmented data. Our second technique, DP-Mix_Diff, further improves performance by incorporating synthetic data from a pre-trained diffusion model into the mixup process. We open-source the code at https://github.com/wenxuan-Bao/DP-Mix.'}",https://openreview.net{'value': '/pdf/d0c62cf22805eb821a0426c933a76facb868fa15.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=7qfkImn0dL,{'value': 'ExPT: Synthetic Pretraining for Few-Shot Experimental Design'},Tung Nguyen; Sudhanshu Agrawal; Aditya Grover,~Tung_Nguyen2; sudhanshuagr27@g.ucla.edu; ~Aditya_Grover1,"{'value': ['experimental design', 'few-shot', 'black-box optimization', 'synthetic pretraining', 'in-context learning', 'transformer']}","{'value': 'Experimental design is a fundamental problem in many science and engineering fields. In this problem, sample efficiency is crucial due to the time, money, and safety costs of real-world design evaluations. Existing approaches either rely on active data collection or access to large, labeled datasets of past experiments, making them impractical in many real-world scenarios. In this work, we address the more challenging yet realistic setting of few-shot experimental design, where only a few labeled data points of input designs and their corresponding values are available. We approach this problem as a conditional generation task, where a model conditions on a few labeled examples and the desired output to generate an optimal input design. To this end, we introduce Experiment Pretrained Transformers (ExPT), a foundation model for few-shot experimental design that employs a novel combination of synthetic pretraining with in-context learning. In ExPT, we only assume knowledge of a finite collection of unlabelled data points from the input domain and pretrain a transformer neural network to optimize diverse synthetic functions defined over this domain. Unsupervised pretraining allows ExPT to adapt to any design task at test time in an in-context fashion by conditioning on a few labeled data points from the target task and generating the candidate optima. We evaluate ExPT on few-shot experimental design in challenging domains and demonstrate its superior generality and performance compared to existing methods. The source code is available at https://github.com/tung-nd/ExPT.git.'}",https://openreview.net{'value': '/pdf/421efd46edd799c06357032c33b619d238c97873.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=7ntySBR3Ey,{'value': 'Energy-Efficient Scheduling with Predictions'},Eric Balkanski; Noemie Perivier; Clifford Stein; Hao-Ting Wei,~Eric_Balkanski2; ~Noemie_Perivier1; ~Clifford_Stein1; ~Hao-Ting_Wei1,"{'value': ['Scheduling', 'algorithms with predictions', 'speed scaling', 'energy minimization']}","{'value': ""An  important goal of modern scheduling systems is to efficiently manage power usage. In energy-efficient scheduling,   the operating system controls the speed at which a machine is processing jobs  with the dual objective of  minimizing energy consumption and optimizing the quality of service cost of the resulting schedule. Since  machine-learned predictions  about future  requests can often be learned from historical data, a recent line of work  on learning-augmented algorithms aims to achieve improved performance guarantees by leveraging predictions.   In particular, for energy-efficient scheduling, Bamas et. al. [NeurIPS '20] and Antoniadis et. al. [SWAT '22]\n  designed algorithms with predictions for the  energy minimization with deadlines problem and achieved an improved competitive ratio when the prediction error is small while also maintaining  worst-case bounds even when the prediction error is arbitrarily large.\n\nIn this paper, we consider a general setting for energy-efficient scheduling and provide a flexible learning-augmented algorithmic framework that takes as input an offline and an online algorithm for the desired energy-efficient scheduling problem. We show that, when the prediction error is small, this framework gives improved competitive ratios for many different energy-efficient scheduling problems, including  energy minimization with deadlines, while also maintaining a bounded competitive ratio regardless of the prediction error. Finally, we empirically demonstrate that this framework achieves an improved performance on real and synthetic datasets.""}",https://openreview.net{'value': '/pdf/c8299d546b7e8e900c4906a806403f185a6f8b09.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=7ntI4kcoqG,"{'value': 'AMAG: Additive, Multiplicative and Adaptive Graph Neural Network For Forecasting Neuron Activity'}",Jingyuan Li; Leo Scholl; Trung Le; Pavithra Rajeswaran; Amy L Orsborn; Eli Shlizerman,~Jingyuan_Li3; lscholl@uw.edu; ~Trung_Le4; ~Pavithra_Rajeswaran1; ~Amy_L_Orsborn1; ~Eli_Shlizerman1,"{'value': ['Neuroscience and Cognitive Science', 'Neural Activity Forecasting', 'Graph Neural Network']}","{'value': 'Latent Variable Models (LVMs) propose to model the dynamics of neural populations by capturing low-dimensional structures that represent features involved in neural activity. Recent LVMs are based on deep learning methodology where a deep neural network is trained to reconstruct the same neural activity given as input and as a result to build the latent representation. Without taking past or future activity into account such a task is non-causal. In contrast, the task of forecasting neural activity based on given input extends the reconstruction task. LVMs that are trained on such a task could potentially capture temporal causality constraints within its latent representation. Forecasting has received less attention than reconstruction due to recording challenges such as limited neural measurements and trials. In this work, we address modeling neural population dynamics via the forecasting task and improve forecasting performance by including a prior, which consists of pairwise neural unit interaction as a multivariate dynamic system. Our proposed model---Additive, Multiplicative, and Adaptive Graph Neural Network (AMAG)---leverages additive and multiplicative message-passing operations analogous to the interactions in neuronal systems and adaptively learns the interaction among neural units to forecast their future activity. We demonstrate the advantage of AMAG compared to non-GNN based methods on synthetic data and multiple modalities of neural recordings (field potentials from penetrating electrodes or surface-level micro-electrocorticography) from four rhesus macaques. Our results show the ability of AMAG to recover ground truth spatial interactions and yield estimation for future dynamics of the neural population.'}",https://openreview.net{'value': '/pdf/83f412912e9f581fab6d83d5f10fc657585fd321.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=7nXaoclHed,{'value': 'A Sublinear-Time Spectral Clustering Oracle with Improved Preprocessing Time'},Ranran Shen; Pan Peng,~Ranran_Shen1; ~Pan_Peng1,"{'value': ['Sublinear-time algorithms', 'Spectral Clustering', 'Graph Clustering', 'Random Walks']}","{'value': 'We address the problem of designing a sublinear-time spectral clustering oracle for graphs that exhibit strong clusterability. Such graphs contain $k$ latent clusters, each characterized by a large inner conductance (at least $\\varphi$) and a small outer conductance (at most $\\varepsilon$). Our aim is to preprocess the graph to enable clustering membership queries, with the key requirement that both preprocessing and query answering should be performed in sublinear time, and the resulting partition should be consistent with a $k$-partition that is close to the ground-truth clustering. Previous oracles have relied on either a $\\textrm{poly}(k)\\log n$ gap between inner and outer conductances or exponential (in $k/\\varepsilon$) preprocessing time. Our algorithm relaxes these assumptions, albeit at the cost of a slightly higher misclassification ratio. We also show that our clustering oracle is robust against a few random edge deletions. To validate our theoretical bounds, we conducted experiments on synthetic networks.'}",https://openreview.net{'value': '/pdf/60fb80ab34e772b1720f56bc3d6304f3bfdfe094.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=7gbjsgcN5p,{'value': 'Unsupervised Optical Flow Estimation with Dynamic Timing Representation for Spike Camera'},Lujie Xia; Ziluo Ding; Rui Zhao; Jiyuan Zhang; Lei Ma; Zhaofei Yu; Tiejun Huang; Ruiqin Xiong,~Lujie_Xia1; ~Ziluo_Ding1; ~Rui_Zhao11; ~Jiyuan_Zhang3; ~Lei_Ma3; ~Zhaofei_Yu1; ~Tiejun_Huang1; ~Ruiqin_Xiong1,"{'value': ['Optical flow', 'unsupervised learning', 'spike camera']}","{'value': 'Efficiently selecting an appropriate spike stream data length to extract precise information is the key to the spike vision tasks. To address this issue, we propose a dynamic timing representation for spike streams. Based on multi-layers architecture, it applies dilated convolutions on temporal dimension to extract features on multi-temporal scales with few parameters. And we design layer attention to dynamically fuse these features. Moreover, we propose an unsupervised learning method for optical flow estimation in a spike-based manner to break the dependence on labeled data. In addition, to verify the robustness, we also build a spike-based synthetic validation dataset for extreme scenarios in autonomous driving, denoted as SSES dataset. It consists of various corner cases. Experiments show that our method can predict optical flow from spike streams in different high-speed scenes, including real scenes. For instance, our method achieves $15\\%$ and $19\\%$ error reduction on PHM dataset compared to the best spike-based work, SCFlow, in $\\Delta t=10$ and $\\Delta t=20$ respectively, using the same settings as in previous works. The source code and dataset are available at \\href{https://github.com/Bosserhead/USFlow}{https://github.com/Bosserhead/USFlow}.'}",https://openreview.net{'value': '/pdf/77d7daeb405589da0329562487cb7baa96d21c5e.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=7f6vH3mmhr,{'value': 'Multi-Agent Learning with Heterogeneous Linear Contextual Bandits'},Anh Do; Thanh Nguyen-Tang; Raman Arora,~Anh_Do2; ~Thanh_Nguyen-Tang1; ~Raman_Arora1,"{'value': ['Multi-agent', 'Bandits', 'Cooperative']}","{'value': 'As trained intelligent systems become increasingly pervasive, multiagent learning has emerged as a popular framework for studying complex interactions between autonomous agents. Yet, a formal understanding of how and when learners in heterogeneous environments benefit from sharing their respective experiences is far from complete. In this paper, we seek answers to these questions in the context of linear contextual bandits. We present a novel distributed learning algorithm based on the upper confidence bound (UCB) algorithm, which we refer to as H-LINUCB, wherein agents cooperatively minimize the group regret under the coordination of a central server. In the setting where the level of heterogeneity or dissimilarity across the environments is known to the agents, we show that H-LINUCB is provably optimal in regimes where the tasks are highly similar or highly dissimilar.'}",https://openreview.net{'value': '/pdf/a517b945e594d2b03a665195e8e4ef92dca1a30c.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=7R8noSP4vL,{'value': 'Tempo Adaptation in Non-stationary Reinforcement Learning'},Hyunin Lee; Yuhao Ding; Jongmin Lee; Ming Jin; Javad Lavaei; Somayeh Sojoudi,~Hyunin_Lee1; ~Yuhao_Ding2; ~Jongmin_Lee1; ~Ming_Jin2; ~Javad_Lavaei1; ~Somayeh_Sojoudi1,"{'value': ['Non-stationary RL', 'Reinforcement Learning']}","{'value': ""We first raise and tackle a ``time synchronization'' issue between the agent and the environment in non-stationary reinforcement learning (RL), a crucial factor hindering its real-world applications. In reality, environmental changes occur over wall-clock time ($t$) rather than episode progress ($k$), where wall-clock time signifies the actual elapsed time within the fixed duration $t \\in [0, T]$. In existing works, at episode $k$, the agent rolls a trajectory and trains a policy before transitioning to episode $k+1$. In the context of the time-desynchronized environment, however, the agent at time $t_{k}$ allocates $\\Delta t$ for trajectory generation and training, subsequently moves to the next episode at $t_{k+1}=t_{k}+\\Delta t$. Despite a fixed total number of episodes ($K$), the agent accumulates different trajectories influenced by the choice of interaction times ($t_1,t_2,...,t_K$), significantly impacting the suboptimality gap of the policy. We propose a Proactively Synchronizing Tempo ($\\texttt{ProST}$) framework that computes a suboptimal sequence {$t_1,t_2,...,t_K$} (= { $t_{1:K}$}) by minimizing an upper bound on its performance measure, i.e., the dynamic regret. Our main contribution is that we show that a suboptimal {$t_{1:K}$} trades-off between the policy training time (agent tempo) and how fast the environment changes (environment tempo). Theoretically, this work develops a suboptimal {$t_{1:K}$} as a function of the degree of the environment's non-stationarity while also achieving a sublinear dynamic regret. Our experimental evaluation on various high-dimensional non-stationary environments shows that the $\\texttt{ProST}$ framework achieves a higher online return at suboptimal {$t_{1:K}$} than the existing methods.""}",https://openreview.net{'value': '/pdf/8db7f228453b28a79a307de32e9dcf101d3ef52c.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=7PJ6LaIOO4,{'value': 'Statistical and Computational Trade-off in Multi-Agent Multi-Armed Bandits'},Filippo Vannella; Alexandre Proutiere; Jaeseong Jeong,~Filippo_Vannella1; ~Alexandre_Proutiere1; ~Jaeseong_Jeong1,"{'value': ['Multi-Agent Multi-Armed Bandits', 'Multi-Armed Bandits', 'Regret Minimization']}","{'value': 'We study the problem of regret minimization in Multi-Agent Multi-Armed Bandits (MAMABs) where the rewards are defined through a factor graph. We derive an instance-specific regret lower bound and characterize the minimal expected number of times each global action should be explored. Unfortunately, this bound and the corresponding optimal exploration process are obtained by solving a combinatorial optimization problem with a set of variables and constraints exponentially growing with the number of agents. We approximate the regret lower bound problem via Mean Field techniques to reduce the number of variables and constraints. By tuning the latter, we explore the trade-off between achievable regret and complexity. We devise Efficient Sampling for MAMAB (ESM), an algorithm whose regret asymptotically matches the corresponding approximated lower bound. We assess the regret and computational complexity of ESM numerically, using both synthetic and real-world experiments in radio communications networks.'}",https://openreview.net{'value': '/pdf/21b4afefd53ae63864d2338899e3d4f31edf395d.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=7EMphtUgCI,{'value': 'AVIS: Autonomous Visual Information Seeking with Large Language Model Agent'},Ziniu Hu; Ahmet Iscen; Chen Sun; Kai-Wei Chang; Yizhou Sun; David A Ross; Cordelia Schmid; Alireza Fathi,~Ziniu_Hu1; ~Ahmet_Iscen3; ~Chen_Sun1; ~Kai-Wei_Chang1; ~Yizhou_Sun1; ~David_A_Ross1; ~Cordelia_Schmid1; ~Alireza_Fathi1,"{'value': ['large language model', 'visual question answering', 'dynamic decision making', 'Tool augmented LLM']}","{'value': 'In this paper, we propose an autonomous information seeking visual question answering framework, AVIS. Our method leverages a Large Language Model (LLM) to dynamically strategize the utilization of external tools and to investigate their outputs via tree search, thereby acquiring the indispensable knowledge needed to provide answers to the posed questions. Responding to visual questions that necessitate external knowledge, such as ""What event is commemorated by the building depicted in this image?"", is a complex task. This task presents a combinatorial search space that demands a sequence of actions, including invoking APIs, analyzing their responses, and making informed decisions. We conduct a user study to collect a variety of instances of human decision-making when faced with this task. This data is then used to design a system comprised of three components: an LLM-powered planner that dynamically determines which tool to use next, an LLM-powered reasoner that analyzes and extracts key information from the tool outputs, and a working memory component that retains the acquired information throughout the process. The collected user behavior serves as a guide for our system in two key ways. First, we create a transition graph by analyzing the sequence of decisions made by users. This graph delineates distinct states and confines the set of actions available at each state. Second, we use examples of user decision-making to provide our LLM-powered planner and reasoner with relevant contextual instances, enhancing their capacity to make informed decisions. We show that AVIS achieves state-of-the-art results on knowledge-based visual question answering benchmarks such as Infoseek and OK-VQA.'}",https://openreview.net{'value': '/pdf/fdde686d726cd8f20ae3773fe15894af0a9fd043.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=77i6itptQW,{'value': 'IDEA: An Invariant Perspective for Efficient Domain Adaptive Image Retrieval'},Haixin Wang; Hao Wu; Jinan Sun; Shikun Zhang; Chong Chen; Xian-Sheng Hua; Xiao Luo,~Haixin_Wang3; ~Hao_Wu39; ~Jinan_Sun1; ~Shikun_Zhang2; ~Chong_Chen2; ~Xian-Sheng_Hua1; ~Xiao_Luo3,"{'value': ['domain adaption', 'binary descriptor', 'causal inference']}","{'value': 'In this paper, we investigate the problem of unsupervised domain adaptive hashing, which leverage knowledge from a label-rich source domain to expedite learning to hash on a label-scarce target domain. Although numerous existing approaches attempt to incorporate transfer learning techniques into deep hashing frameworks, they often neglect the essential invariance for adequate alignment between these two domains. Worse yet, these methods fail to distinguish between causal and non-causal effects embedded in images, rendering cross-domain retrieval ineffective. To address these challenges, we propose an Invariance-acquired Domain AdaptivE HAshing (IDEA) model. Our IDEA first decomposes each image into a causal feature representing label information, and a non-causal feature indicating domain information. Subsequently, we generate discriminative hash codes using causal features with consistency learning on both source and target domains. More importantly, we employ a generative model for synthetic samples to simulate the intervention of various non-causal effects, ultimately minimizing their impact on hash codes for domain invariance. Comprehensive experiments conducted on benchmark datasets validate the superior performance of our IDEA compared to a variety of competitive baselines.'}",https://openreview.net{'value': '/pdf/77d7e8bb1e9e32ff56fc4c7712f8cc1e15f9aaa2.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=6jNQ1AY1Uf,{'value': 'Synthetic Experience Replay'},Cong Lu; Philip J. Ball; Yee Whye Teh; Jack Parker-Holder,~Cong_Lu1; ~Philip_J._Ball2; ~Yee_Whye_Teh2; ~Jack_Parker-Holder1,"{'value': ['Reinforcement Learning', 'Diffusion Models', 'Synthetic Data', 'Sample-Efficient RL']}","{'value': ""A key theme in the past decade has been that when large neural networks and large datasets combine they can produce remarkable results. In deep reinforcement learning (RL), this paradigm is commonly made possible through experience replay, whereby a dataset of past experiences is used to train a policy or value function. However, unlike in supervised or self-supervised learning, an RL agent has to collect its own data, which is often limited. Thus, it is challenging to reap the benefits of deep learning, and even small neural networks can overfit at the start of training. In this work, we leverage the tremendous recent progress in generative modeling and propose Synthetic Experience Replay (SynthER), a diffusion-based approach to flexibly upsample an agent's collected experience. We show that SynthER is an effective method for training RL agents across offline and online settings, in both proprioceptive and pixel-based environments. In offline settings, we observe drastic improvements when upsampling small offline datasets and see that additional synthetic data also allows us to effectively train larger networks. Furthermore, SynthER enables online agents to train with a much higher update-to-data ratio than before, leading to a significant increase in sample efficiency, without any algorithmic changes. We believe that synthetic training data could open the door to realizing the full potential of deep learning for replay-based RL algorithms from limited data. Finally, we open-source our code at https://github.com/conglu1997/SynthER.""}",https://openreview.net{'value': '/pdf/270fbf4148b7e8037943bf5d486912098f23addf.pdf'},{'title_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=6XC5iKqRVm,{'value': 'DELTA: Diverse Client Sampling for Fasting Federated Learning'},Lin Wang; Yongxin Guo; Tao Lin; Xiaoying Tang,~Lin_Wang14; ~Yongxin_Guo1; ~Tao_Lin1; ~Xiaoying_Tang2,"{'value': ['federated learning', 'client sampling']}","{'value': ""Partial client participation has been widely adopted in Federated Learning (FL) to reduce the communication burden efficiently. However, an inadequate client sampling scheme can lead to the selection of unrepresentative subsets, resulting in significant variance in model updates and slowed convergence. Existing sampling methods are either biased or can be further optimized for faster convergence.\nIn this paper, we present DELTA, an unbiased sampling scheme designed to alleviate these issues. DELTA characterizes the effects of client diversity and local variance, and samples representative clients with valuable information for global model updates. In addition, DELTA is a proven optimal unbiased sampling scheme that minimizes variance caused by partial client participation and outperforms other unbiased sampling schemes in terms of convergence.  Furthermore, to address full-client gradient dependence, we provide a practical version of DELTA depending on the available clients' information, and also analyze its convergence. Our results are validated through experiments on both synthetic and real-world datasets.""}",https://openreview.net{'value': '/pdf/cf6e8c9825a76b364f078e3a3a31bfcfa3e34332.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=6JJq5TW9Mc,{'value': 'Learning World Models with Identifiable Factorization'},Yu-Ren Liu; Biwei Huang; Zhengmao Zhu; Honglong Tian; Mingming Gong; Yang Yu; Kun Zhang,~Yu-Ren_Liu1; ~Biwei_Huang1; ~Zhengmao_Zhu1; ~Honglong_Tian1; ~Mingming_Gong1; ~Yang_Yu5; ~Kun_Zhang1,{'value': ['Model-based Reinforcement Learning; Causal Representation Learning;']},"{'value': 'Extracting a stable and compact representation of the environment is crucial for efficient reinforcement learning in high-dimensional, noisy, and non-stationary environments.  Different categories of information coexist in such environments -- how to effectively extract and disentangle the information remains a challenging problem. In this paper, we propose IFactor, a general framework to model four distinct categories of latent state variables that capture various aspects of information within the RL system, based on their interactions with actions and rewards. Our analysis establishes block-wise identifiability of these latent variables, which not only provides a stable and compact representation but also discloses that all reward-relevant factors are significant for policy learning. We further present a practical approach to learning the world model with identifiable blocks, ensuring the removal of redundancies but retaining minimal and sufficient information for policy optimization. Experiments in synthetic worlds demonstrate that our method accurately identifies the ground-truth latent variables, substantiating our theoretical findings. Moreover, experiments in variants of the DeepMind Control Suite and RoboDesk showcase the superior performance of our approach over baselines.'}",https://openreview.net{'value': '/pdf/f42fb8e08a233349840c6912f967116ddf1f645a.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=6EaLIw3W7c,{'value': 'LinkerNet: Fragment Poses and Linker Co-Design with 3D Equivariant Diffusion'},Jiaqi Guan; Xingang Peng; PeiQi Jiang; Yunan Luo; Jian Peng; Jianzhu Ma,~Jiaqi_Guan1; ~Xingang_Peng1; ~PeiQi_Jiang2; ~Yunan_Luo1; ~Jian_Peng1; ~Jianzhu_Ma2,"{'value': ['Linker design', 'generative models']}","{'value': 'Targeted protein degradation techniques, such as PROteolysis TArgeting Chimeras (PROTACs), have emerged as powerful tools for selectively removing disease-causing proteins. One challenging problem in this field is designing a linker to connect different molecular fragments to form a stable drug-candidate molecule. Existing models for linker design assume that the relative positions of the fragments are known, which may not be the case in real scenarios. In this work, we address a more general problem where the poses of the fragments are *unknown* in 3D space. We develop a 3D equivariant diffusion model that jointly learns the generative process of both fragment poses and the 3D structure of the linker. By viewing fragments as rigid bodies, we design a fragment pose prediction module inspired by the Newton-Euler equations in rigid body mechanics. Empirical studies on ZINC and PROTAC-DB datasets demonstrate that our model can generate chemically valid, synthetically-accessible,  and low-energy molecules under both unconstrained and constrained generation settings.'}",https://openreview.net{'value': '/pdf/18c4ca5ade0f47732cd4a81cb37e997773ca7d85.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=6EDHfVHicP,{'value': 'DDF-HO: Hand-Held Object Reconstruction via Conditional Directed Distance Field'},Chenyangguang Zhang; Yan Di; Ruida Zhang; Guangyao Zhai; Fabian Manhardt; Federico Tombari; Xiangyang Ji,~Chenyangguang_Zhang1; ~Yan_Di2; ~Ruida_Zhang1; ~Guangyao_Zhai1; ~Fabian_Manhardt1; ~Federico_Tombari1; ~Xiangyang_Ji1,"{'value': ['hand-held object reconstruction', 'directed distance field', 'human-object interaction']}","{'value': 'Reconstructing hand-held objects from a single RGB image is an important and challenging problem. Existing works utilizing Signed Distance Fields (SDF) reveal limitations in comprehensively capturing the complex hand-object interactions, since SDF is  only reliable within the proximity of the target, and hence, infeasible to simultaneously encode local hand and object cues. To address this issue, we propose DDF-HO, a novel approach leveraging Directed Distance Field (DDF) as the shape representation. Unlike SDF, DDF maps a ray in 3D space, consisting of an origin and a direction, to corresponding DDF values, including a binary visibility signal determining whether the ray intersects the objects and a distance value measuring the distance from origin to target in the given direction. We randomly sample multiple rays and collect local to global geometric features for them by introducing a novel 2D ray-based feature aggregation scheme and a 3D intersection-aware hand pose embedding, combining 2D-3D features to model hand-object interactions. Extensive experiments on synthetic and real-world datasets demonstrate that DDF-HO consistently outperforms all baseline methods by a large margin, especially under Chamfer Distance, with about 80% leap forward. Codes are available at https://github.com/ZhangCYG/DDFHO.'}",https://openreview.net{'value': '/pdf/fdc3731967822bde8f03229836d4f516c1f9fb23.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=5ytypAqAsR,{'value': 'No Representation Rules Them All in Category Discovery'},Sagar Vaze; Andrea Vedaldi; Andrew Zisserman,~Sagar_Vaze1; ~Andrea_Vedaldi1; ~Andrew_Zisserman1,"{'value': ['Category discovery', 'semi-supervised learning', 'self-supervised learning', 'classification']}","{'value': ""In this paper we tackle the problem of Generalized Category Discovery (GCD). Specifically, given a dataset with labelled and unlabelled images, the task is to cluster all images in the unlabelled subset, whether or not they belong to the labelled categories. Our first contribution is to recognise that most existing GCD benchmarks only contain labels for a single clustering of the data, making it difficult to ascertain whether models are leveraging the available labels to solve the GCD task, or simply solving an unsupervised clustering problem. As such, we present a synthetic dataset, named 'Clevr-4', for category discovery. Clevr-4 contains four equally valid partitions of the data, i.e based on object 'shape', 'texture' or 'color' or 'count'. To solve the task, models are required to extrapolate the taxonomy specified by labelled set, rather than simply latch onto a single natural grouping of the data. We use this dataset to demonstrate the limitations of unsupervised clustering in the GCD setting, showing that even very strong unsupervised models fail on Clevr-4. We further use Clevr-4 to examine the weaknesses of existing GCD algorithms, and propose a new method which addresses these shortcomings, leveraging consistent findings from the representation learning literature to do so. Our simple solution, which is based on `Mean Teachers' and termed $\\mu$GCD, substantially outperforms implemented baselines on Clevr-4. Finally, when we transfer these findings to real data on the challenging Semantic Shift Benchmark suite, we find that $\\mu$GCD outperforms all prior work, setting a new state-of-the-art.""}",https://openreview.net{'value': '/pdf/ac51480cf4816f6e9e753fbcc38d308d0a4a9a11.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=5gz7npbQ6Z,{'value': 'A Cross-Moment Approach for Causal Effect Estimation'},Yaroslav Kivva; Saber Salehkaleybar; Negar Kiyavash,~Yaroslav_Kivva1; ~Saber_Salehkaleybar1; ~Negar_Kiyavash1,"{'value': ['Causal inference', 'Difference-in-Difference', 'Structural causal models', 'Potential outcome', 'Proxy learning']}","{'value': 'We consider the problem of estimating the causal effect of a treatment on an outcome in  linear structural causal models (SCM) with latent confounders when we have access to a single proxy variable.\nSeveral methods (such as difference-in-difference (DiD) estimator or negative outcome control) have been proposed in this setting in the literature. However, these approaches require either restrictive assumptions on the data generating model or having access to at least two proxy variables.\nWe propose a method to estimate the causal effect using cross moments between the treatment, the outcome, and the proxy variable. In particular, we show that the causal effect can be identified with simple arithmetic operations on the cross moments if the latent confounder in linear SCM is non-Gaussian.\nIn this setting, DiD estimator provides an unbiased estimate only in the special case where the latent confounder has exactly the same direct causal effects on the outcomes in the pre-treatment and post-treatment phases. This translates to the common trend assumption in DiD, which we effectively relax.\nAdditionally, we provide an impossibility result that shows the causal effect cannot be identified if the observational distribution over the treatment, the outcome, and the proxy is jointly Gaussian.\n Our experiments on both synthetic and real-world datasets showcase the effectiveness\nof the proposed approach in estimating the causal effect.'}",https://openreview.net{'value': '/pdf/c88e92ff5e34aa709d95f42e8941fe0b60e87415.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=5VQFAvUHcd,{'value': 'Replicable Clustering'},Hossein Esfandiari; Amin Karbasi; Vahab Mirrokni; Grigoris Velegkas; Felix Zhou,~Hossein_Esfandiari1; ~Amin_Karbasi3; ~Vahab_Mirrokni2; ~Grigoris_Velegkas1; ~Felix_Zhou1,"{'value': ['Theory', 'Clustering Theory', 'Statistical Learning Theory', 'Reproducibility', 'Replicability']}","{'value': 'We design replicable algorithms in the context of statistical clustering under the recently introduced notion of replicability from Impagliazzo et al. [2022]. According to this definition, a clustering algorithm is replicable if, with high probability, its output induces the exact same partition of the sample space after two executions on different inputs drawn from the same distribution, when its internal randomness is shared across the executions. We propose such algorithms for the statistical $k$-medians, statistical $k$-means, and statistical $k$-centers problems by utilizing approximation routines for their combinatorial counterparts in a black-box manner. In particular, we demonstrate a replicable $O(1)$-approximation algorithm for statistical Euclidean $k$-medians ($k$-means) with $\\operatorname{poly}(d)$ sample complexity. We also describe an $O(1)$-approximation algorithm with an additional $O(1)$-additive error for statistical Euclidean $k$-centers, albeit with $\\exp(d)$ sample complexity. In addition, we provide experiments on synthetic distributions in 2D using the $k$-means++ implementation from sklearn as a black-box that validate our theoretical results.'}",https://openreview.net{'value': '/pdf/ff1a592c05f6bb2acb93f5b61494e1744ce625f2.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=5Fgdk3hZpb,"{'value': 'Squeeze, Recover and Relabel: Dataset Condensation at ImageNet Scale From A New Perspective'}",Zeyuan Yin; Eric Xing; Zhiqiang Shen,~Zeyuan_Yin1; ~Eric_Xing1; ~Zhiqiang_Shen1,"{'value': ['Dataset Condensation and Distillation', 'ImageNet Scale']}","{'value': 'We present a new dataset condensation framework termed Squeeze, Recover and Relabel (SRe$^2$L) that decouples the bilevel optimization of model and synthetic data during training, to handle varying scales of datasets, model architectures and image resolutions for efficient dataset condensation. The proposed method demonstrates flexibility across diverse dataset scales and exhibits multiple advantages in terms of arbitrary resolutions of synthesized images, low training cost and memory consumption with high-resolution synthesis, and the ability to scale up to arbitrary evaluation network architectures. Extensive experiments are conducted on Tiny-ImageNet and full ImageNet-1K datasets. Under 50 IPC, our approach achieves the highest 42.5\\% and 60.8\\% validation accuracy on Tiny-ImageNet and ImageNet-1K, outperforming all previous state-of-the-art methods by margins of 14.5\\% and 32.9\\%, respectively. Our approach also surpasses MTT in terms of speed by approximately 52$\\times$ (ConvNet-4) and 16$\\times$ (ResNet-18) faster with less memory consumption of 11.6$\\times$ and 6.4$\\times$ during data synthesis. Our code and condensed datasets of 50, 200 IPC with 4K recovery budget are available at https://github.com/VILA-Lab/SRe2L.'}",https://openreview.net{'value': '/pdf/9bd0f7a26ba0c2916d8fc71375b5a81ec2d390fc.pdf'},{'abstract_filter': 'Data Synthesis'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=4L2OlXhiTM,{'value': 'FIRAL: An Active Learning Algorithm for Multinomial Logistic Regression'},Youguang Chen; George Biros,~Youguang_Chen1; ~George_Biros3,"{'value': ['statistical learning', 'active learning', 'logistic regression', 'regret minimization']}","{'value': 'We investigate theory and algorithms for pool-based active learning for multiclass classification using multinomial logistic regression.  Using finite sample analysis, we prove that the Fisher Information Ratio (FIR)  lower and upper bounds  the excess risk. Based on our theoretical analysis, we propose an active learning algorithm that  employs regret minimization to minimize the FIR. To verify our derived excess risk bounds, we conduct experiments on synthetic datasets. Furthermore, we compare FIRAL with five other methods and found that our scheme  outperforms them: it consistently produces the smallest classification error in the multiclass logistic regression setting, as demonstrated through experiments on MNIST, CIFAR-10, and 50-class ImageNet.'}",https://openreview.net{'value': '/pdf/bb906bcfe26114d51ccdb14b0576212dcd3341d2.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=40L3viVWQN,{'value': 'The Pick-to-Learn Algorithm: Empowering Compression for Tight Generalization Bounds and Improved Post-training Performance'},Dario Paccagnan; Marco Campi; Simone Garatti,~Dario_Paccagnan1; ~Marco_Campi1; ~Simone_Garatti1,"{'value': ['Statistical learning theory', 'Compression theory', 'Generalization bounds']}","{'value': 'Generalization bounds are valuable both for theory and applications. On the one hand, they shed light on the mechanisms that underpin the learning processes; on the other, they certify how well a learned model performs against unseen inputs.  In this work we build upon a recent breakthrough in compression theory to develop a new framework yielding tight generalization bounds of wide practical applicability.  The core idea is to embed any given learning algorithm into a suitably-constructed meta-algorithm (here called Pick-to-Learn, P2L) in order to instill desirable compression properties. When applied to the MNIST classification dataset and to a synthetic regression problem, P2L not only attains generalization bounds that compare favorably with the state of the art (test-set and PAC-Bayes bounds), but it also learns models with better post-training performance.'}",https://openreview.net{'value': '/pdf/596f6209168ad423054afb49c46f556626cb7fa5.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=3ofe0lpwQP,{'value': 'DisDiff: Unsupervised Disentanglement of Diffusion Probabilistic Models'},Tao Yang; Yuwang Wang; Yan Lu; Nanning Zheng,~Tao_Yang9; ~Yuwang_Wang3; ~Yan_Lu7; ~Nanning_Zheng1,"{'value': ['Diffusion Probabilistic Model', 'Disentangled representation']}","{'value': 'Targeting to understand the underlying explainable factors behind observations and modeling the conditional generation process on these factors, we connect disentangled representation learning to diffusion probabilistic models (DPMs) to take advantage of the remarkable modeling ability of DPMs. We propose a new task, disentanglement of (DPMs): given a pre-trained DPM, without any annotations of the factors, the task is to automatically discover the inherent factors behind the observations and disentangle the gradient fields of DPM into sub-gradient fields, each conditioned on the representation of each discovered factor. With disentangled DPMs, those inherent factors can be automatically discovered, explicitly represented and clearly injected into the diffusion process via the sub-gradient fields. To tackle this task, we devise an unsupervised approach, named DisDiff, and for the first time achieving disentangled representation learning in the framework of DPMs. Extensive experiments on synthetic and real-world datasets demonstrate the effectiveness of DisDiff.'}",https://openreview.net{'value': '/pdf/683e70172dd9704b718e53396ddefd2b1961f139.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=3aVZhMfsyz,{'value': 'Volume Feature Rendering for Fast Neural Radiance Field Reconstruction'},Kang Han; Wei Xiang; Lu Yu,~Kang_Han1; ~Wei_Xiang3; ~Lu_Yu8,"{'value': ['neural rendering', 'volume rendering', 'view synthesis', '3D reconstruction']}","{'value': ""Neural radiance fields (NeRFs) are able to synthesize realistic novel views from multi-view images captured from distinct positions and perspectives. In NeRF's rendering pipeline, neural networks are used to represent a scene independently or transform queried learnable feature vector of a point to the expected color or density. With the aid of geometry guides either in the form of occupancy grids or proposal networks, the number of color neural network evaluations can be reduced from hundreds to dozens in the standard volume rendering framework. However, many evaluations of the color neural network are still a bottleneck for fast NeRF reconstruction. This paper revisits volume feature rendering (VFR) for the purpose of fast NeRF reconstruction. The VFR integrates the queried feature vectors of a ray into one feature vector, which is then transformed to the final pixel color by a color neural network. This fundamental change to the standard volume rendering framework requires only one single color neural network evaluation to render a pixel, which substantially lowers the high computational complexity of the rendering framework attributed to a large number of color neural network evaluations. Consequently, we can use a comparably larger color neural network to achieve a better rendering quality while maintaining the same training and rendering time costs. This approach achieves the state-of-the-art rendering quality on both synthetic and real-world datasets while requiring less training time compared with existing methods.""}",https://openreview.net{'value': '/pdf/65167de68d479f9dcdf6649dfce464afa6e3dd01.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=3X2EbBLNsk,{'value': 'Birth of a Transformer: A Memory Viewpoint'},Alberto Bietti; Vivien Cabannes; Diane Bouchacourt; Herve Jegou; Leon Bottou,~Alberto_Bietti1; ~Vivien_Cabannes1; ~Diane_Bouchacourt3; ~Herve_Jegou1; ~Leon_Bottou1,"{'value': ['transformers', 'language models', 'deep learning theory', 'interpretability']}","{'value': 'Large language models based on transformers have achieved great empirical successes. However, as they are deployed more widely, there is a growing need to better understand their internal mechanisms in order to make them more reliable. These models appear to store vast amounts of knowledge from their training data, and to adapt quickly to new information provided in their context or prompt. We study how transformers balance these two types of knowledge by considering a synthetic setup where tokens are generated from either global or context-specific bigram distributions. By a careful empirical analysis of the training process on a simplified two-layer transformer, we illustrate the fast learning of global bigrams and the slower development of an ""induction head"" mechanism for the in-context bigrams. We highlight the role of weight matrices as associative memories, provide theoretical insights on how gradients enable their learning during training, and study the role of data-distributional properties.'}",https://openreview.net{'value': '/pdf/18f0a07370deb3c1db84a94f1c73ee9d3a2bd72c.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=3WAnGWLpSQ,{'value': 'Why Does Sharpness-Aware Minimization Generalize Better Than SGD?'},Zixiang Chen; Junkai Zhang; Yiwen Kou; Xiangning Chen; Cho-Jui Hsieh; Quanquan Gu,~Zixiang_Chen1; ~Junkai_Zhang2; ~Yiwen_Kou1; ~Xiangning_Chen1; ~Cho-Jui_Hsieh1; ~Quanquan_Gu1,"{'value': ['Sharpness Aware Algorithm', 'Deep Learning Theory']}","{'value': 'The challenge of overfitting, in which the model memorizes the training data and fails to generalize to test data, has become increasingly significant in the training of large neural networks. To tackle this challenge, Sharpness-Aware Minimization (SAM) has emerged as a promising training method, which can improve the generalization of neural networks even in the presence of label noise. However, a deep understanding of how SAM works, especially in the setting of nonlinear neural networks and classification tasks, remains largely missing. This paper fills this gap by demonstrating why SAM generalizes better than Stochastic Gradient Descent (SGD) for a certain data model and two-layer convolutional ReLU networks. The loss landscape of our studied problem is nonsmooth, thus current explanations for the success of SAM based on the Hessian information are insufficient. Our result explains the benefits of SAM, particularly its ability to prevent noise learning in the early stages, thereby facilitating more effective learning of features. Experiments on both synthetic and real data corroborate our theory.'}",https://openreview.net{'value': '/pdf/e01bc91c4b9c7d10e417e796d3e9a604a98bac39.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=3NWWgB2SuF,{'value': 'Undirected Probabilistic Model for Tensor Decomposition'},Zerui Tao; Toshihisa Tanaka; Qibin Zhao,~Zerui_Tao1; tanakat@cc.tuat.ac.jp; ~Qibin_Zhao1,"{'value': ['Tensor decomposition', 'tensor completion', 'probabilistic methods']}","{'value': 'Tensor decompositions (TDs) serve as a powerful tool for analyzing multiway data. Traditional TDs incorporate prior knowledge about the data into the model, such as a directed generative process from latent factors to observations. In practice, selecting proper structural or distributional assumptions beforehand is crucial for obtaining a promising TD representation. However, since such prior knowledge is typically unavailable in real-world applications, choosing an appropriate TD model can be challenging. This paper aims to address this issue by introducing a flexible TD framework that discards the structural and distributional assumptions, in order to learn as much information from the data. Specifically, we construct a TD model that captures the joint probability of the data and latent tensor factors through a deep energy-based model (EBM). Neural networks are then employed to parameterize the joint energy function of tensor factors and tensor entries. The flexibility of EBM and neural networks enables the learning of underlying structures and distributions. In addition, by designing the energy function, our model unifies the learning process of different types of tensors, such as static tensors and dynamic tensors with time stamps. The resulting model presents a doubly intractable nature due to the presence of latent tensor factors and the unnormalized probability function. To efficiently train the model, we derive a variational upper bound of the conditional noise-contrastive estimation objective that learns the unnormalized joint probability by distinguishing data from conditional noises. We show advantages of our model on both synthetic and several real-world datasets.'}",https://openreview.net{'value': '/pdf/88817bcc103246e157e373b2236a5a0f38cbd643.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=3IyL2XWDkG,"{'value': 'CAMEL: Communicative Agents for ""Mind"" Exploration of Large Language Model Society'}",Guohao Li; Hasan Abed Al Kader Hammoud; Hani Itani; Dmitrii Khizbullin; Bernard Ghanem,~Guohao_Li1; ~Hasan_Abed_Al_Kader_Hammoud1; ~Hani_Itani1; ~Dmitrii_Khizbullin2; ~Bernard_Ghanem1,"{'value': ['Communicative Agents', 'Large Language Models', 'AI Society', 'Role-Playing', 'Society of Mind']}","{'value': 'The rapid advancement of chat-based language models has led to remarkable progress in complex task-solving. However, their success heavily relies on human input to guide the conversation, which can be challenging and time-consuming. This paper explores the potential of building scalable techniques to facilitate autonomous cooperation among communicative agents, and provides insight into their “cognitive” processes. To address the challenges of achieving autonomous cooperation, we propose a novel communicative agent framework named role-playing . Our approach involves using inception prompting to guide chat agents toward task completion while maintaining consistency with human intentions. We showcase how role-playing can be used to generate conversational data for studying the behaviors and capabilities of a society of agents, providing a valuable resource for investigating conversational language models. In particular, we conduct comprehensive studies on instruction-following cooperation in multi-agent settings. Our contributions include introducing a novel communicative agent framework, offering a scalable approach for studying the cooperative behaviors and capabilities of multi-agent systems, and open-sourcing our library to support research on communicative agents and beyond: https://github.com/camel-ai/camel.'}",https://openreview.net{'value': '/pdf/c3b30e69a77284c793251816c4fb2ce742d1696a.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=3Fc9gnR0fa,{'value': 'Neural Frailty Machine: Beyond proportional hazard assumption in neural survival regressions'},Ruofan Wu; Jiawei Qiao; Mingzhe Wu; Wen Yu; Ming Zheng; Tengfei LIU; Tianyi Zhang; Weiqiang Wang,~Ruofan_Wu1; ~Jiawei_Qiao1; ~Mingzhe_Wu1; ~Wen_Yu1; ~Ming_Zheng1; ~Tengfei_LIU2; ~Tianyi_Zhang5; ~Weiqiang_Wang4,"{'value': ['Survival Analysis', 'Theory', 'Semiparametric statistics']}","{'value': 'We present neural frailty machine (NFM), a powerful and flexible neural modeling framework for survival regressions. The NFM framework utilizes the classical idea of multiplicative frailty in survival analysis as a principled way of extending the proportional hazard assumption, at the same time being able to leverage the strong approximation power of neural architectures for handling nonlinear covariate dependence. Two concrete models are derived under the framework that extends neural proportional hazard models and nonparametric hazard regression models. Both models allow efficient training under the likelihood objective. Theoretically, for both proposed models, we establish statistical guarantees of neural function approximation with respect to nonparametric components via characterizing their rate of convergence. Empirically, we provide synthetic experiments that verify our theoretical statements. We also conduct experimental evaluations over $6$ benchmark datasets of different scales, showing that the proposed NFM models achieve predictive performance comparable to or sometimes surpassing state-of-the-art survival models. Our code is publicly availabel at https://github.com/Rorschach1989/nfm'}",https://openreview.net{'value': '/pdf/5d098edfd61024018a098101da38a620aba04480.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=35nFSbEBks,{'value': 'Equivariant Spatio-Temporal Attentive Graph Networks to Simulate Physical Dynamics'},Liming Wu; Zhichao Hou; Jirui Yuan; Yu Rong; Wenbing Huang,~Liming_Wu1; ~Zhichao_Hou1; ~Jirui_Yuan1; ~Yu_Rong1; ~Wenbing_Huang1,"{'value': ['Equivariance', 'Spatio-Temporal GNNs', 'Physical Dynamics']}","{'value': 'Learning to represent and simulate the dynamics of physical systems is a crucial yet challenging task. Existing equivariant Graph Neural Network (GNN) based methods have encapsulated the symmetry of physics, \\emph{e.g.}, translations, rotations, etc, leading to better generalization ability. Nevertheless, their frame-to-frame formulation of the task overlooks the non-Markov property mainly incurred by unobserved dynamics in the environment. In this paper, we reformulate dynamics simulation as a spatio-temporal prediction task, by employing the trajectory in the past period to recover the Non-Markovian interactions. We propose Equivariant Spatio-Temporal Attentive Graph Networks (ESTAG), an equivariant version of spatio-temporal GNNs, to fulfil our purpose. At its core, we design a novel Equivariant Discrete Fourier Transform (EDFT) to extract periodic patterns from the history frames, and then construct an Equivariant Spatial Module (ESM) to accomplish spatial message passing, and an Equivariant Temporal Module (ETM) with the forward attention and equivariant pooling mechanisms to aggregate temporal message. We evaluate our model on three real datasets corresponding to the molecular-, protein- and macro-level. Experimental results verify the effectiveness of ESTAG compared to typical spatio-temporal GNNs and equivariant GNNs.'}",https://openreview.net{'value': '/pdf/9a43ee0555ced98934e7749112b46dcdb684cbe5.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=2yXExAl0FW,{'value': 'A Diffusion-Model of Joint Interactive Navigation'},Matthew Niedoba; Jonathan Wilder Lavington; Yunpeng Liu; Vasileios Lioutas; Justice Sefas; Xiaoxuan Liang; Dylan Green; Setareh Dabiri; Berend Zwartsenberg; Adam Scibior; Frank Wood,~Matthew_Niedoba2; ~Jonathan_Wilder_Lavington1; ~Yunpeng_Liu1; ~Vasileios_Lioutas1; ~Justice_Sefas1; liang51@cs.ubc.ca; ~Dylan_Green1; ~Setareh_Dabiri1; ~Berend_Zwartsenberg1; ~Adam_Scibior1; ~Frank_Wood2,"{'value': ['Diffusion Models', 'Trajecotry Forecasting', 'Autonomous Vehicles', 'Motion Forecasting', 'Simulation']}","{'value': 'Simulation of autonomous vehicle systems requires that simulated traffic participants exhibit diverse and realistic behaviors. The use of prerecorded real-world traffic scenarios in simulation ensures realism but the rarity of safety critical events makes large scale collection of driving scenarios expensive. In this paper, we present DJINN -- a diffusion based method of generating traffic scenarios. Our approach jointly diffuses the trajectories of all agents, conditioned on a flexible set of state observations from the past, present, or future. On popular trajectory forecasting datasets, we report state of the art performance on joint trajectory metrics. In addition, we demonstrate how DJINN flexibly enables direct test-time sampling from a variety of valuable conditional distributions including goal-based sampling, behavior-class sampling, and scenario editing.'}",https://openreview.net{'value': '/pdf/ea1047dd7c9afc76331d002472119d941a5b8596.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=2URr3mkagy,{'value': 'Revisiting Implicit Differentiation for Learning Problems in Optimal Control'},Ming Xu; Timothy L Molloy; Stephen Gould,~Ming_Xu5; ~Timothy_L_Molloy1; ~Stephen_Gould1,"{'value': ['implicit differentiation', 'bi-level optimization; constrained learning and control; safe learning for control']}","{'value': 'This paper proposes a new method for differentiating through optimal trajectories arising from non-convex, constrained discrete-time optimal control (COC) problems using the implicit function theorem (IFT). Previous works solve a differential Karush-Kuhn-Tucker (KKT) system for the trajectory derivative, and achieve this efficiently by solving an auxiliary Linear Quadratic Regulator (LQR) problem. In contrast, we directly evaluate the matrix equations which arise from applying variable elimination on the Lagrange multiplier terms in the (differential) KKT system. By appropriately accounting for the structure of the terms within the resulting equations, we show that the trajectory derivatives scale linearly with the number of timesteps. Furthermore, our approach allows for easy parallelization, significantly improved scalability with model size, direct computation of vector-Jacobian products and improved numerical stability compared to prior works. As an additional contribution, we unify prior works, addressing claims that computing trajectory derivatives using IFT scales quadratically with the number of timesteps. We evaluate our method on a both synthetic benchmark and four challenging, learning from demonstration benchmarks including a 6-DoF maneuvering quadrotor and 6-DoF rocket powered landing.'}",https://openreview.net{'value': '/pdf/310ce30d729c0581af8e3d1a38f83fa7a92ad789.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=2SScUiWUbn,{'value': 'On the Connection between Pre-training Data Diversity and Fine-tuning Robustness'},Vivek Ramanujan; Thao Nguyen; Sewoong Oh; Ali Farhadi; Ludwig Schmidt,~Vivek_Ramanujan1; ~Thao_Nguyen3; ~Sewoong_Oh1; ~Ali_Farhadi3; ~Ludwig_Schmidt1,"{'value': ['robustness', 'out-of-distribution shifts', 'finetuning', 'pretraining']}","{'value': 'Pre-training has been widely adopted in deep learning to improve model performance, especially when the training data for a target task is limited. In our work, we seek to understand the implications of this training strategy on the generalization properties of downstream models. More specifically, we ask the following question: how do properties of the pre-training distribution affect the robustness of a fine-tuned model? The properties we explore include the label space, label semantics, image diversity, data domains, and data quantity of the pre-training distribution. We find that the primary factor influencing downstream effective robustness (Taori et al., 2020) is data quantity, while other factors have limited significance. For example, reducing the number of ImageNet pre-training classes by 4x while increasing the number of images per class by 4x (that is, keeping total data quantity fixed) does not impact the robustness of fine-tuned models. We demonstrate our findings on pre-training distributions drawn from various natural and synthetic data sources, primarily using the iWildCam-WILDS distribution shift as a test for robustness.'}",https://openreview.net{'value': '/pdf/c7cf28bbf8c9a2d7186940e7790123eb7e5ddb5b.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=2OcNWFHFpk,{'value': 'Group Robust Classification Without Any Group Information'},Christos Tsirigotis; Joao Monteiro; Pau Rodriguez; David Vazquez; Aaron Courville,~Christos_Tsirigotis1; ~Joao_Monteiro1; ~Pau_Rodriguez2; ~David_Vazquez1; ~Aaron_Courville3,"{'value': ['out-of-distribution generalization', 'robustness', 'fairness', 'spurious correlations', 'systematic generalization', 'model selection']}","{'value': 'Empirical risk minimization (ERM) is sensitive to spurious correlations present in training data, which poses a significant risk when deploying systems trained under this paradigm in high-stake applications. While the existing literature focuses on maximizing group-balanced or worst-group accuracy, estimating these quantities is hindered by costly bias annotations. This study contends that current bias-unsupervised approaches to group robustness continue to rely on group information to achieve optimal performance. Firstly, these methods implicitly assume that all group combinations are represented during training. To illustrate this, we introduce a systematic generalization task on the MPI3D dataset and discover that current algorithms fail to improve the ERM baseline when combinations of observed attribute values are missing. Secondly, bias labels are still crucial for effective model selection, restricting the practicality of these methods in real-world scenarios. To address these limitations, we propose a revised methodology for training and validating debiased models in an entirely bias-unsupervised manner. We achieve this by employing pretrained self-supervised models to reliably extract bias information, which enables the integration of a logit adjustment training loss with our validation criterion. Our empirical analysis on synthetic and real-world tasks provides evidence that our approach overcomes the identified challenges and consistently enhances robust accuracy, attaining performance which is competitive with or outperforms that of state-of-the-art methods, which, conversely, rely on bias labels for validation.'}",https://openreview.net{'value': '/pdf/fe4ca36a8baa8d188cd36e368aff44610b1fd98e.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=2BpoGPSDCR,{'value': 'Solving Inverse Physics Problems with Score Matching'},Benjamin Holzschuh; Simona Vegetti; Nils Thuerey,~Benjamin_Holzschuh1; ~Simona_Vegetti1; ~Nils_Thuerey1,"{'value': ['inverse problems', 'diffusion models', 'learned corrections', 'score matching']}","{'value': ""We propose to solve inverse problems involving the temporal evolution of physics systems by leveraging recent advances from diffusion models. \nOur method moves the system's current state backward in time step by step by combining an approximate inverse physics simulator and a learned correction function. \nA central insight of our work is that training the learned correction with a single-step loss is equivalent to a score matching objective, while recursively predicting longer parts of the trajectory during training relates to maximum likelihood training of a corresponding probability flow.\nWe highlight the advantages of our algorithm compared to standard denoising score matching and implicit score matching, as well as fully learned baselines for a wide range of inverse physics problems. The resulting inverse solver has excellent accuracy and temporal stability and, in contrast to other learned inverse solvers, allows for sampling the posterior of the solutions. Code and experiments are available at https://github.com/tum-pbs/SMDP.""}",https://openreview.net{'value': '/pdf/e14d868c93d4bb63690c02fd9c5fcb4f28eed65c.pdf'},{'abstract_filter': 'Trajectory'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=1wOkHN9JK8,{'value': 'Hierarchical VAEs provide a normative account of motion processing in the primate brain'},Hadi Vafaii; Jacob L. Yates; Daniel A. Butts,~Hadi_Vafaii1; ~Jacob_L._Yates1; ~Daniel_A._Butts1,"{'value': ['NeuroAI', 'VAE', 'Dorsal stream', 'Hierarchical Bayesian Inference']}","{'value': ""The relationship between perception and inference, as postulated by Helmholtz in the 19th century, is paralleled in modern machine learning by generative models like Variational Autoencoders (VAEs) and their hierarchical variants. Here, we evaluate the role of hierarchical inference and its alignment with brain function in the domain of motion perception. We first introduce a novel synthetic data framework, Retinal Optic Flow Learning (ROFL), which enables control over motion statistics and their causes. We then present a new hierarchical VAE and test it against alternative models on two downstream tasks: (i) predicting ground truth causes of retinal optic flow (e.g., self-motion); and (ii) predicting the responses of neurons in the motion processing pathway of primates. We manipulate the model architectures (hierarchical versus non-hierarchical), loss functions, and the causal structure of the motion stimuli. We find that hierarchical latent structure in the model leads to several improvements. First, it improves the linear decodability of ground truth variables and does so in a sparse and disentangled manner. Second, our hierarchical VAE outperforms previous state-of-the-art models in predicting neuronal responses and exhibits sparse latent-to-neuron relationships. These results depend on the causal structure of the world, indicating that alignment between brains and artificial neural networks depends not only on architecture but also on matching ecologically relevant stimulus statistics. Taken together, our results suggest that hierarchical Bayesian inference underlines the brain's understanding of the world, and hierarchical VAEs can effectively model this understanding.""}",https://openreview.net{'value': '/pdf/d86d8927876b4a47e56df68b2796a5fbc2f191c7.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=1pWNhmbllE,{'value': 'Uncertainty-Aware Instance Reweighting for Off-Policy Learning'},Xiaoying Zhang; Junpu Chen; Hongning Wang; Hong Xie; Yang Liu; John C.S. Lui; Hang Li,~Xiaoying_Zhang3; ~Junpu_Chen1; ~Hongning_Wang1; ~Hong_Xie2; ~Yang_Liu3; ~John_C.S._Lui2; ~Hang_Li4,"{'value': ['off-policy learning', 'uncertainty']}","{'value': 'Off-policy learning, referring to the procedure of policy optimization with access only to logged feedback data, has shown importance in various important real-world applications, such as search engines and recommender systems. While the ground-truth logging policy is usually unknown, previous work simply takes its estimated value for the off-policy learning, ignoring the negative impact from both high bias and high variance resulted from such an estimator. And these impact is often magnified on samples with small and inaccurately estimated logging probabilities. The contribution of this work is to explicitly model the uncertainty in the estimated logging policy, and propose an Uncertainty-aware Inverse Propensity Score estimator (UIPS) for improved off-policy learning, with a theoretical convergence guarantee. Experiment results on the synthetic and real-world recommendation datasets demonstrate that UIPS significantly improves the quality of the discovered policy, when compared against an extensive list of state-of-the-art baselines.'}",https://openreview.net{'value': '/pdf/8210f388161a56af7a203e3c3524972a1dd46490.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=1aQivXgZKj,{'value': 'Incentivized Communication for Federated Bandits'},Zhepei Wei; Chuanhao Li; Haifeng Xu; Hongning Wang,~Zhepei_Wei1; ~Chuanhao_Li1; ~Haifeng_Xu1; ~Hongning_Wang1,"{'value': ['contextual bandit', 'federated learning', 'incentive mechanism']}","{'value': 'Most existing works on federated bandits take it for granted that all clients are altruistic about sharing their data with the server for the collective good whenever needed. Despite their compelling theoretical guarantee on performance and communication efficiency, this assumption is overly idealistic and oftentimes violated in practice, especially when the algorithm is operated over self-interested clients, who are reluctant to share data without explicit benefits. Negligence of such self-interested behaviors can significantly affect the learning efficiency and even the practical operability of federated bandit learning. In light of this, we aim to spark new insights into this under-explored research area by formally introducing an incentivized communication problem for federated bandits, where the server shall motivate clients to share data by providing incentives. Without loss of generality, we instantiate this bandit problem with the contextual linear setting and propose the first incentivized communication protocol, namely, Inc-FedUCB, that achieves near-optimal regret with provable communication and incentive cost guarantees. Extensive empirical experiments on both synthetic and real-world datasets further validate the effectiveness of the proposed method across various environments.'}",https://openreview.net{'value': '/pdf/c0c3b8608c65cee25d021fea25e4461833b0b7b0.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=1B6YKnHYBb,{'value': 'De novo Drug Design using Reinforcement Learning with Multiple GPT Agents'},Xiuyuan Hu; Guoqing Liu; Yang Zhao; Hao Zhang,~Xiuyuan_Hu1; ~Guoqing_Liu3; ~Yang_Zhao11; ~Hao_Zhang37,"{'value': ['De novo drug design', 'Molecular generation', 'Multi-agent reinforcement learning', 'GPT']}","{'value': '*De novo* drug design is a pivotal issue in pharmacology and a new area of focus in AI for science research. A central challenge in this field is to generate molecules with specific properties while also producing a wide range of diverse candidates. Although advanced technologies such as transformer models and reinforcement learning have been applied in drug design, their potential has not been fully realized. Therefore, we propose MolRL-MGPT, a reinforcement learning algorithm with multiple GPT agents for drug molecular generation. To promote molecular diversity, we encourage the agents to collaborate in searching for desirable molecules in diverse directions. Our algorithm has shown promising results on the GuacaMol benchmark and exhibits efficacy in designing inhibitors against SARS-CoV-2 protein targets. The codes are available at: https://github.com/HXYfighter/MolRL-MGPT.'}",https://openreview.net{'value': '/pdf/3cf70b69e2cd6d8f3c8af683c2c8d837a2cab930.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=19AgWnmyoV,{'value': 'Instructing Goal-Conditioned Reinforcement Learning Agents with Temporal Logic Objectives'},Wenjie Qiu; Wensen Mao; He Zhu,~Wenjie_Qiu1; wm300@cs.rutgers.edu; ~He_Zhu4,"{'value': ['Goal-Conditioned Reinforcement Learning', 'Linear Temporal Logic']}","{'value': 'Goal-conditioned reinforcement learning (RL) is a powerful approach for learning general-purpose skills by reaching diverse goals. However, it has limitations when it comes to task-conditioned policies, where goals are specified by temporally extended instructions written in the Linear Temporal Logic (LTL) formal language. Existing approaches for finding LTL-satisfying policies rely on sampling a large set of LTL instructions during training to adapt to unseen tasks at inference time. However, these approaches do not guarantee generalization to out-of-distribution LTL objectives, which may have increased complexity. In this paper, we propose a novel approach to address this challenge. We show that simple goal-conditioned RL agents can be instructed to follow arbitrary LTL specifications without additional training over the LTL task space. Unlike existing approaches that focus on LTL specifications expressible as regular expressions, our technique is unrestricted and generalizes to $\\omega$-regular expressions. Experiment results demonstrate the effectiveness of our approach in adapting goal-conditioned RL agents to satisfy complex temporal logic task specifications zero-shot.'}",https://openreview.net{'value': '/pdf/acf92fe710e42dab207c1c717abf1ebcdef65091.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=0rVXQEeFEL,{'value': 'Transformer-based Planning for Symbolic Regression'},Parshin Shojaee; Kazem Meidani; Amir Barati Farimani; Chandan K. Reddy,~Parshin_Shojaee1; ~Kazem_Meidani1; ~Amir_Barati_Farimani2; ~Chandan_K._Reddy1,"{'value': ['Symbolic Regression', 'Transformers', 'Planning', 'Deep Learning']}","{'value': ""Symbolic regression (SR) is a challenging task in machine learning that involves finding a mathematical expression for a function based on its values. Recent advancements in SR have demonstrated the effectiveness of pre-trained transformer models in generating equations as sequences, leveraging large-scale pre-training on synthetic datasets and offering notable advantages in terms of inference time over classical Genetic Programming (GP) methods. However, these models primarily rely on supervised pre-training objectives borrowed from text generation and overlook equation discovery goals like accuracy and complexity. To address this, we propose TPSR, a Transformer-based Planning strategy for Symbolic Regression that incorporates Monte Carlo Tree Search planning algorithm into the transformer decoding process. Unlike conventional decoding strategies, TPSR enables the integration of non-differentiable equation verification feedback, such as fitting accuracy and complexity, as external sources of knowledge into the transformer equation generation process. Extensive experiments on various datasets show that our approach outperforms state-of-the-art methods, enhancing the model's fitting-complexity trade-off, extrapolation abilities, and robustness to noise.""}",https://openreview.net{'value': '/pdf/758ab88ee6b6c59b9c8f107773d07abacb03fec5.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=0OImBCFsdf,{'value': 'SaVeNet: A Scalable Vector Network for Enhanced Molecular Representation Learning'},Sarp Aykent; Tian Xia,~Sarp_Aykent1; ~Tian_Xia10,"{'value': ['geometric deep learning', 'molecule property prediction', 'geometric representation learning']}","{'value': ""Geometric representation learning of molecules is challenging yet essential for applications in multiple domains. Despite the impressive breakthroughs made by geometric deep learning in various molecular representation learning tasks, effectively capturing complicated geometric features across spatial dimensions is still underexplored due to the significant difficulties in modeling efficient geometric representations and learning the inherent correlation in 3D structural modeling. These include computational inefficiency, underutilization of vectorial embeddings, and limited generalizability to integrate various geometric properties. To address the raised concerns, we introduce an efficient and effective framework, Scalable Vector Network (SaVeNet), designed to accommodate a range of geometric requirements without depending on costly embeddings. In addition, the proposed framework scales effectively with introduced direction noise. Theoretically, we analyze the desired properties (i.e., invariance and equivariant) and framework efficiency of the SaVeNet. Empirically, we conduct a comprehensive series of experiments to evaluate the efficiency and expressiveness of the proposed model. Our efficiency-focused experiments underscore the model's empirical superiority over existing methods. Experimental results on synthetic and real-world datasets demonstrate the expressiveness of our model, which achieves state-of-the-art performance across various tasks within molecular representation learning.""}",https://openreview.net{'value': '/pdf/e1fe16876b7b9e591d904ef1f22f8e134a707b44.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=0Iw2dLh8uq,{'value': 'Multi-Agent Meta-Reinforcement Learning: Sharper Convergence Rates with Task Similarity'},Weichao Mao; Haoran Qiu; Chen Wang; Hubertus Franke; Zbigniew Kalbarczyk; Ravi Iyer; Tamer Basar,~Weichao_Mao1; ~Haoran_Qiu1; ~Chen_Wang17; ~Hubertus_Franke1; ~Zbigniew_Kalbarczyk1; ~Ravi_Iyer1; ~Tamer_Basar1,"{'value': ['Reinforcement learning', 'game theory', 'multi-agent systems', 'meta-learning']}","{'value': 'Multi-agent reinforcement learning (MARL) has primarily focused on solving a single task in isolation, while in practice the environment is often evolving, leaving many related tasks to be solved. In this paper, we investigate the benefits of meta-learning in solving multiple MARL tasks collectively. We establish the first line of theoretical results for meta-learning in a wide range of fundamental MARL settings, including learning Nash equilibria in two-player zero-sum Markov games and Markov potential games, as well as learning coarse correlated equilibria in general-sum Markov games. Under natural notions of task similarity, we show that meta-learning achieves provable sharper convergence to various game-theoretical solution concepts than learning each task separately. As an important intermediate step, we develop multiple MARL algorithms with initialization-dependent convergence guarantees. Such algorithms integrate optimistic policy mirror descents with stage-based value updates, and their refined convergence guarantees (nearly) recover the best known results even when a good initialization is unknown. To our best knowledge, such results are also new and might be of independent interest. We further provide numerical simulations to corroborate our theoretical findings.'}",https://openreview.net{'value': '/pdf/04e42cc67993cd613b562cae3dd21418ffcad371.pdf'},{'title_filter': 'Agent'},NeurIPS.cc,2023,Conference
https://openreview.net/forum?id=0BwB03qA5T,{'value': 'Gaussian Process Probes (GPP) for Uncertainty-Aware Probing'},Zi Wang; Alexander Ku; Jason Michael Baldridge; Thomas L. Griffiths; Been Kim,~Zi_Wang1; ~Alexander_Ku1; ~Jason_Michael_Baldridge1; ~Thomas_L._Griffiths1; ~Been_Kim1,"{'value': ['Interpretability', 'probing', 'Bayesian', 'Gaussian process', 'transparency']}","{'value': ""Understanding which concepts models can and cannot represent has been fundamental to many tasks: from effective and responsible use of models to detecting out of distribution data. We introduce Gaussian process probes (GPP), a unified and simple framework for probing and measuring uncertainty about concepts represented by models. As a Bayesian extension of linear probing methods, GPP asks what kind of distribution over classifiers (of concepts) is induced by the model. This distribution can be used to measure both what the model represents and how confident the probe is about what the model represents.  GPP can be applied to any pre-trained  model with vector representations of inputs (e.g., activations). It does not require access to training data, gradients, or the architecture. We validate GPP on datasets containing both synthetic and real images. Our experiments show it can (1) probe a model's representations of concepts even with a very small number of examples, (2) accurately measure both epistemic uncertainty (how confident the probe is) and aleatory uncertainty (how fuzzy the concepts are to the model), and (3) detect out of distribution data using those uncertainty measures as well as classic methods do. By using Gaussian processes to expand what probing can offer, GPP provides a data-efficient, versatile and uncertainty-aware tool for understanding and evaluating the capabilities of machine learning models.""}",https://openreview.net{'value': '/pdf/cd744f7de4b5c6cbb69d1de38aaaa494e02fd70c.pdf'},{'abstract_filter': 'Synthetic'},NeurIPS.cc,2023,Conference
