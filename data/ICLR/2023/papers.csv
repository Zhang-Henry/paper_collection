forum,title,authors,authorids,keywords,abstract,pdf,match,venue,year,type
https://openreview.net/forum?id=zzL_5WoI3I,An Adaptive Entropy-Regularization Framework for Multi-Agent Reinforcement Learning,"['Woojun Kim', 'Youngchul Sung']","['~Woojun_Kim1', '~Youngchul_Sung1']","['Multi-Agent Reinforcement Learning', 'Entropy Regularization', 'Exploration-Exploitation Tradeoff']","In this paper, we propose an adaptive entropy-regularization framework (ADER) for multi-agent reinforcement learning (RL) to learn the adequate amount of exploration for each agent based on the degree of required exploration. In order to handle instability arising from updating multiple entropy temperature parameters for multiple agents, we disentangle the soft value function into two types: one for pure reward and the other for entropy. By applying multi-agent value factorization to the disentangled value function of pure reward, we obtain a relevant metric to assess the necessary degree of exploration for each agent. Based on this metric, we propose the ADER algorithm based on maximum entropy RL, which controls the necessary level of exploration across agents over time by learning the proper target entropy for each agent. Experimental results show that the proposed scheme significantly outperforms current state-of-the-art multi-agent RL algorithms. ",https://openreview.net/pdf/326b9e492a2f9b8c9c6b57df0cc2821d16942084.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=ztgT8Iok130,Sample-efficient multi-objective molecular optimization with GFlowNets,"['Yiheng Zhu', 'Jialu Wu', 'Chaowen Hu', 'Jiahuan Yan', 'Chang-Yu Hsieh', 'Tingjun Hou', 'Jian Wu']","['~Yiheng_Zhu3', '~Jialu_Wu1', '~Chaowen_Hu1', '~Jiahuan_Yan1', '~Chang-Yu_Hsieh1', '~Tingjun_Hou1', '~Jian_Wu6']","['multi-objective molecular optimization', 'Bayesian optimization', 'generative flow networks']","Many crucial scientific problems involve designing novel molecules with desired properties, which can be formulated as an expensive black-box optimization problem over the discrete chemical space. Computational methods have achieved initial success but still struggle with simultaneously optimizing multiple competing properties in a sample-efficient manner. In this work, we propose a multi-objective Bayesian optimization (MOBO) algorithm leveraging the hypernetwork-based GFlowNets (HN-GFN) as an acquisition function optimizer, with the purpose of sampling a diverse batch of candidate molecular graphs from an approximate Pareto front. Using a single preference-conditioned hypernetwork, HN-GFN learns to explore various trade-offs between objectives. Inspired by reinforcement learning, we further propose a hindsight-like off-policy strategy to share high-performing molecules among different preferences in order to speed up learning for HN-GFN. Through synthetic experiments, we illustrate that HN-GFN has adequate capacity to generalize over preferences. Extensive experiments show that our framework outperforms the best baselines by a large margin in terms of hypervolume in various real-world MOBO settings.",https://openreview.net/pdf/e071eb49a79f32cd751f8aa514e16320a17f8442.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=znLlSgN-4S0,"More Centralized Training, Still Decentralized Execution: Multi-Agent Conditional Policy Factorization","['Jiangxing Wang', 'Deheng Ye', 'Zongqing Lu']","['~Jiangxing_Wang2', '~Deheng_Ye1', '~Zongqing_Lu2']",['Multi-Agent Reinforcement Learning'],"In cooperative multi-agent reinforcement learning (MARL), combining value decomposition with actor-critic enables agents to learn stochastic policies, which are more suitable for the partially observable environment. Given the goal of learning local policies that enable decentralized execution, agents are commonly assumed to be independent of each other, even in centralized training. However, such an assumption may prohibit agents from learning the optimal joint policy. To address this problem, we explicitly take the dependency among agents into centralized training. Although this leads to the optimal joint policy, it may not be factorized for decentralized execution. Nevertheless, we theoretically show that from such a joint policy, we can always derive another joint policy that achieves the same optimality but can be factorized for decentralized execution. To this end, we propose multi-agent conditional policy factorization (MACPF), which takes more centralized training but still enables decentralized execution. We empirically verify MACPF in various cooperative MARL tasks and demonstrate that MACPF achieves better performance or faster convergence than baselines. Our code is available at https://github.com/PKU-RL/FOP-DMAC-MACPF.",https://openreview.net/pdf/8258fe1c50fe61494176aa41b2c207716e3d556b.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=zZXztocaN9,BO-Muse: A Human expert and AI teaming framework for accelerated experimental design ,"['Sunil Gupta', 'Alistair Shilton', 'Shannon Ryan', 'Arun Kumar Anjanapura Venkatesh', 'Majid Abdolshah', 'Hung Le', 'Santu Rana', 'Julian Berk', 'Mahad Rashid', 'Svetha Venkatesh']","['~Sunil_Gupta2', '~Alistair_Shilton1', '~Shannon_Ryan1', '~Arun_Kumar_Anjanapura_Venkatesh1', '~Majid_Abdolshah1', '~Hung_Le1', '~Santu_Rana1', '~Julian_Berk1', '~Mahad_Rashid1', '~Svetha_Venkatesh1']","['Experimental Design', 'Machine learning', 'Optimisation', 'Bayesian optimisation', 'Human-AI Teaming']","In this paper we introduce BO-Muse, a new approach to human-AI teaming for the optimisation of expensive blackbox functions. Inspired by the intrinsic difficulty of extracting expert knowledge and distilling it back into AI models and by observations of human behaviour in real-world experimental design, our algorithm lets the human expert take the lead in the experimental process. The human expert can use their domain expertise to its full potential, while the AI plays the role of a muse, injecting novelty and searching for areas of weakness to break the human out of over-exploitation induced by cognitive entrenchment. With mild assumptions, we show that our algorithm converges sub-linearly, at a rate faster than the AI or human alone. We validate our algorithm using synthetic data and with human experts performing real-world experiments.",https://openreview.net/pdf/692b01680e7fd5f063d8b26e23d90632c95bfe54.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=zWwrB9wenY1U,Soundness and Completeness: An Algorithmic Perspective on Evaluation of Feature Attribution,"['Yawei Li', 'Yang Zhang', 'Bernd Bischl', 'Mina Rezaei']","['~Yawei_Li3', '~Yang_Zhang22', '~Bernd_Bischl1', '~Mina_Rezaei1']","['explainable AI', 'explainability', 'feature attribution']","Feature attribution is a fundamental approach to explaining neural networks by quantifying the importance of input features for a model's prediction. Although a variety of feature attribution methods have been proposed, there is little consensus on the assessment of attribution methods. In this study, we empirically show the limitations of \emph{order-based} and \emph{model-retraining} metrics. To overcome the limitations and enable evaluation with higher granularity, we propose a novel method to evaluate the \emph{completeness} and \emph{soundness} of feature attribution methods. Our proposed evaluation metrics are mathematically grounded on algorithm theory and require no knowledge of ""ground truth"" informative features. We validate our proposed metrics by conducting experiments on synthetic and real-world datasets. Lastly, we use the proposed metrics to benchmark a wide range of feature attribution methods. Our evaluation results provide an innovative perspective on comparing feature attribution methods. Code is in the supplementary material. ",https://openreview.net/pdf/3965624d91f69d61d00ec23383b65212b1c7305b.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=zT5T9gHpGI,Adversarial Counterfactual Environment Model Learning,"['Xiong-Hui Chen', 'Yang Yu', 'Zhengmao Zhu', 'ZhiHua Yu', 'Chen Zhenjun', 'Chenghe Wang', 'Yinan Wu', 'Hongqiu Wu', 'Rong-Jun Qin', 'Ruijin Ding', 'Huang Fangsheng']","['~Xiong-Hui_Chen1', '~Yang_Yu5', '~Zhengmao_Zhu1', '~ZhiHua_Yu2', '~Chen_Zhenjun1', '~Chenghe_Wang1', '~Yinan_Wu2', '~Hongqiu_Wu2', '~Rong-Jun_Qin1', '~Ruijin_Ding1', '~Huang_Fangsheng1']","['offline environment model learning', 'reinforcement learning', 'causal inference']","A good model for action-effect prediction, i.e., the environment model, is essential for sample-efficient policy learning, in which the agent can take numerous free trials to find good policies. Currently, the model is commonly learned by fitting historical transition data through empirical risk minimization (ERM). However, we discover that simple data fitting can lead to a model that will be totally wrong in guiding policy learning due to the selection bias in offline dataset collection. In this work, we introduce weighted empirical risk minimization (WERM) to handle this problem in model learning.  A typical WERM method utilizes inverse propensity scores to re-weight the training data to approximate the target distribution. However, during the policy training, the data distributions of the candidate policies can be various and unknown. Thus, we propose an adversarial weighted empirical risk minimization (AWRM) objective that learns the model with respect to the worst case of the target distributions. We implement AWRM in a sequential decision structure, resulting in the GALILEO model learning algorithm. We also discover that GALILEO is closely related to adversarial model learning, explaining the empirical effectiveness of the latter. We apply GALILEO in synthetic tasks and verify that GALILEO makes accurate predictions on counterfactual data. We finally applied GALILEO in real-world offline policy learning tasks and found that GALILEO significantly improves policy performance in real-world testing.",https://openreview.net/pdf/61ab5d197c127522a0ca862d515a2ea1973016ea.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=zH9GcZ3ZGXu,Feature Reconstruction From Outputs Can Mitigate Simplicity Bias in Neural Networks,"['Sravanti Addepalli', 'Anshul Nasery', 'Venkatesh Babu Radhakrishnan', 'Praneeth Netrapalli', 'Prateek Jain']","['~Sravanti_Addepalli1', '~Anshul_Nasery2', '~Venkatesh_Babu_Radhakrishnan2', '~Praneeth_Netrapalli1', '~Prateek_Jain1']","['Simplicity Bias', 'Out-of-distribution robustness', 'OOD Generalization', 'Deep Learning']","Deep Neural Networks are known to be brittle to even minor distribution shifts compared to the training distribution. While one line of work has demonstrated that \emph{Simplicity Bias} (SB) of DNNs -- bias towards learning only the simplest features -- is a key reason for this brittleness, another recent line of work has surprisingly found that diverse/ complex features are indeed learned by the backbone, and their brittleness is due to the linear classification head relying primarily on the simplest features. To bridge the gap between these two lines of work, we first hypothesize and verify that while SB may not altogether preclude learning complex features, it amplifies simpler features over complex ones. Namely, simple features are replicated several times in the learned representations while complex features might not be replicated. This phenomenon, we term \emph{Feature  Replication  Hypothesis}, coupled with the \emph{Implicit Bias} of SGD to converge to maximum margin solutions in the feature space, leads the models to rely mostly on the simple features for classification. To mitigate this bias, we propose \emph{Feature Reconstruction Regularizer (FRR)} to ensure that the learned features can be reconstructed back from the logits. The use of \emph{FRR} in linear layer training (\emph{FRR-L}) encourages the use of more diverse features for classification. We further propose to finetune the full network by freezing the weights of the linear layer trained using \emph{FRR-L}, to refine the learned features, making them more suitable for classification. Using this simple solution, we demonstrate up to 15\% gains in OOD accuracy on the recently introduced semi-synthetic datasets with extreme distribution shifts. Moreover, we demonstrate noteworthy gains over existing SOTA methods on the standard OOD benchmark DomainBed as well.",https://openreview.net/pdf/d04b89a2199e2c436eabe69c7d7b984b0f21db55.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=ynD_LAMwar2,Reinforcement Logic Rule Learning for Temporal Point Processes ,"['Chao Yang', 'Lu Wang', 'Kun Gao', 'Shuang Li']","['~Chao_Yang9', '~Lu_Wang11', '~Kun_Gao1', '~Shuang_Li3']","['temporal point processes', 'explainable models', 'rule learning']","We aim to learn a set of temporal logic rules to explain the occurrence of temporal events. Leveraging the temporal point process modeling and learning framework, the rule content and rule weights are jointly learned by maximizing the likelihood of the observed noisy event sequences. The proposed algorithm alternates between a master problem, where the rule weights are updated, and a subproblem, where a new rule is searched and included. The formulated master problem is convex and relatively easy to solve, whereas the subproblem requires searching the huge combinatorial rule predicate and relationship space. To tackle this challenge, we propose a neural search policy to learn to generate the new rule content as a sequence of actions. The policy parameters will be trained end-to-end using the reinforcement learning framework, where the reward signals can be efficiently queried by evaluating the subproblem objective. The trained policy can be used to generate new rules, and moreover, the well-trained policies can be directly transferred to other tasks to speed up the rule searching procedure in the new task. We evaluate our methods on both synthetic and real-world datasets, obtaining promising results.",https://openreview.net/pdf/6dc861c4da6b6dd8d33c05f7362d16a9cafd6ed6.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=yFQjggu62T,Scalable and Privacy-enhanced Graph Generative Model for Graph Neural Networks,"['Minji Yoon', 'Yue Wu', 'John Palowitch', 'Bryan Perozzi', 'Russ Salakhutdinov']","['~Minji_Yoon1', '~Yue_Wu17', '~John_Palowitch1', '~Bryan_Perozzi1', '~Russ_Salakhutdinov1']","['graph generative model', 'graph neural networks', 'graph convolutional networks', 'benchmark graph generation']","As the field of Graph Neural Networks (GNN) continues to grow, it experiences a corresponding increase in the need for large, real-world datasets to train and test new GNN models on challenging, realistic problems. Unfortunately, such graph datasets are often generated from online, highly privacy-restricted ecosystems, which makes research and development on these datasets hard, if not impossible. This greatly reduces the amount of benchmark graphs available to researchers, causing the field to rely only on a handful of publicly-available datasets. To address this dilemma, we introduce a novel graph generative model, Computation Graph Transformer (CGT) that can learn and reproduce the distribution of real-world graphs in a privacy-enhanced way. Our proposed model (1) generates effective benchmark graphs on which GNNs show similar task performance as on the source graphs, (2) scales to process large-scale real-world graphs, (3) guarantees privacy for end-users. Extensive experiments across a vast body of graph generative models show that only our model can successfully generate privacy-controlled, synthetic substitutes of large-scale real-world graphs that can be effectively used to evaluate GNN models.",https://openreview.net/pdf/0bcbfa22875adf615372a04dc0242e01763e53ab.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=yAYHho4fATa,CFlowNets: Continuous Control with Generative Flow Networks,"['Yinchuan Li', 'Shuang Luo', 'Haozhi Wang', 'Jianye HAO']","['~Yinchuan_Li1', '~Shuang_Luo1', '~Haozhi_Wang1', '~Jianye_HAO1']","['Continuous control tasks', 'Generative flow networks']","Generative flow networks (GFlowNets), as an emerging technique, can be used as an alternative to reinforcement learning for exploratory control tasks. GFlowNets aims to sample actions with a probability proportional to the reward, similar to sampling different candidates in an active learning fashion. However, existing GFlowNets cannot adapt to continuous control tasks because GFlowNets need to form a DAG and compute the flow matching loss by traversing the inflows and outflows of each node in the trajectory. In this paper, we propose generative continuous flow networks (CFlowNets) that can be applied to continuous control tasks. First, we present the theoretical formulation of CFlowNets. Then, a training framework for CFlowNets is proposed, including the action selection process, the flow approximation algorithm, and the continuous flow matching loss function. Afterward, we theoretically prove the error bound of the flow approximation. The error decreases rapidly as the number of flow samples increases. Finally, experimental results on continuous control tasks demonstrate the performance advantages of CFlowNets compared to many reinforcement learning methods, especially regarding exploration ability.",https://openreview.net/pdf/d04aea952ea57b0759baa3d16e05576bc4d9fd2b.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=xgFfr5IIuXP,Clustering and Ordering Variable-Sized Sets: The Catalog Problem,"['Mateusz Maria Jurewicz', 'Graham W. Taylor', 'Leon Derczynski']","['~Mateusz_Maria_Jurewicz1', '~Graham_W._Taylor1', '~Leon_Derczynski1']","['neural clustering', 'set-to-sequence', 'supervised clustering', 'structure prediction', 'set representation', 'learning to order']","Prediction of a varying number of ordered clusters from sets of any cardinality is a challenging task for neural networks, combining elements of set representation, clustering and learning to order. This task arises in many diverse areas, ranging from medical triage, through multi-channel signal analysis for petroleum exploration to product catalog structure prediction. This paper focuses on the latter, which exemplifies a number of challenges inherent to adaptive ordered clustering, referred to further as the eponymous Catalog Problem. These include learning variable cluster constraints, exhibiting relational reasoning and managing combinatorial complexity. Despite progress in both neural clustering and set-to-sequence methods, no joint, fully differentiable model exists to-date. We develop such a modular architecture, referred to further as Neural Ordered Clusters (NOC), enhance it with a specific mechanism for learning cluster-level cardinality constraints, and provide a robust comparison of its performance in relation to alternative models. We test our method on three datasets, including synthetic catalog structures and PROCAT, a dataset of real-world catalogs consisting of over 1.5M products, achieving state-of-the-art results on a new, more challenging formulation of the underlying problem, which has not been addressed before. Additionally, we examine the network's ability to learn higher-order interactions and investigate its capacity to learn both compositional and structural rulesets.",https://openreview.net/pdf/33dbec164decabd10f2ecd63e1fc9c52adb04912.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=xeg2fW5E2l3,Set-Level Self-Supervised Learning from Noisily-Labeled Data,"['Chia-Ching Lin', 'Shang-Fu Chen', 'Fu-En Yang', 'Yu-Chiang Frank Wang', 'Chin-Laung Lei']","['~Chia-Ching_Lin1', '~Shang-Fu_Chen2', '~Fu-En_Yang1', '~Yu-Chiang_Frank_Wang2', '~Chin-Laung_Lei1']","['Self-supervised learning', 'Noisy label learning', 'Meta-learning', 'EM algorithm']","Noisy labels are inevitably presented in real-world datasets due to labeling error or visual content ambiguity. Existing methods generally approach the task of noisy label learning (NLL) by either properly regularizing the model, or reweighting clean/noisy labeled samples. While self-supervised learning (SSL) has been applied to pre-train deep neural networks without label supervision, downstream tasks like image classification still require clean labeled data. And, most SSL strategies are performed at the instance level, regardless of the correctness of its label. In this paper, we propose set-level self-supervised learning (SLSSL), which performs SSL at mini-batch levels with observed noisy labels. By corrupting the labels of each training mini-batch, our SLSSL enforces the model to exhibit sufficient robustness. Moreover, the proposed SLSSL can also be utilized for sample reweighting technique. As a result, the proposed learning scheme can be applied as an expectation-maximization (EM) algorithm during model training. Extensive experiments on synthetic and real-world noisy label data confirm the effectiveness of our framework.",https://openreview.net/pdf/2216db2b926f80ad83932fad5ebbd912d8d3c584.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=xYlJRpzZtsY,ROSCOE: A Suite of Metrics for Scoring Step-by-Step Reasoning,"['Olga Golovneva', 'Moya Peng Chen', 'Spencer Poff', 'Martin Corredor', 'Luke Zettlemoyer', 'Maryam Fazel-Zarandi', 'Asli Celikyilmaz']","['~Olga_Golovneva1', '~Moya_Peng_Chen1', '~Spencer_Poff1', '~Martin_Corredor1', '~Luke_Zettlemoyer1', '~Maryam_Fazel-Zarandi1', '~Asli_Celikyilmaz1']","['step-by-step reasoning', 'evaluation']","Large language models show improved downstream task performance when prompted to generate step-by-step reasoning to justify their final answers. These reasoning steps greatly improve model interpretability and verification, but objectively studying their correctness (independent of the final answer) is difficult without reliable methods for automatic evaluation. We simply do not know how often the stated reasoning steps actually support the final end task predictions. In this work, we present ROSCOE, a suite of interpretable, unsupervised automatic scores that improve and extend previous text generation evaluation metrics. To evaluate ROSCOE against baseline metrics, we design a typology of reasoning errors and collect synthetic and human evaluation scores on commonly used reasoning datasets. In contrast with existing metrics, ROSCOE can measure semantic consistency, logicality, informativeness, fluency, and factuality — among other traits — by leveraging properties of step-by-step rationales. We empirically verify the strength of our metrics on five human annotated and six programmatically perturbed diagnostics datasets - covering a diverse set of tasks that require reasoning skills and show that ROSCOE can consistently outperform baseline metrics.",https://openreview.net/pdf/3f6164615b8f835462171508e65f188740d76ee8.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=xTWoeTdHgH-,Evaluating Unsupervised Denoising Requires Unsupervised Metrics,"['Adria Marcos Morales', 'Matan Leibovich', 'Sreyas Mohan', 'Joshua Lawrence Vincent', 'Piyush Haluai', 'MAI TAN', 'Peter Crozier', 'Carlos Fernandez-Granda']","['~Adria_Marcos_Morales1', '~Matan_Leibovich1', '~Sreyas_Mohan1', '~Joshua_Lawrence_Vincent1', '~Piyush_Haluai1', '~MAI_TAN1', '~Peter_Crozier1', '~Carlos_Fernandez-Granda1']","['Denoising', 'Unsupervised Learning', 'Evaluation Metrics', 'Statistical Estimation', 'Imaging', 'Electron Microscopy']","Unsupervised denoising is a crucial challenge in real-world imaging applications. Unsupervised deep-learning methods have demonstrated impressive performance on benchmarks based on synthetic noise. However, no metrics are available to evaluate these methods in an unsupervised fashion. This is highly problematic for the many practical applications where ground-truth clean images are not available. In this work, we propose two novel metrics: the unsupervised mean squared error (MSE) and the unsupervised peak signal-to-noise ratio (PSNR), which are computed using only noisy data. We provide a theoretical analysis of these metrics, showing that they are asymptotically consistent estimators of the supervised MSE and PSNR. Controlled numerical experiments with synthetic noise confirm that they provide accurate approximations in practice. We validate our approach on real-world data from two imaging modalities:  videos in raw format and transmission electron microscopy. Our results demonstrate that the proposed metrics enable unsupervised evaluation of denoising methods based exclusively on noisy data.",https://openreview.net/pdf/099f905ccf6961644075ea89e9bfdf0986eab786.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=wkg_b4-IwTZ,A Closer Look at Model Adaptation using Feature Distortion and Simplicity Bias,"['Puja Trivedi', 'Danai Koutra', 'Jayaraman J. Thiagarajan']","['~Puja_Trivedi1', '~Danai_Koutra1', '~Jayaraman_J._Thiagarajan3']","['Transfer Learning', 'Robustness', 'Adaptation', 'Data Augmentation']","Advances in the expressivity of pretrained models have increased interest in the design of adaptation protocols which enable safe and effective transfer learning. Going beyond conventional linear probing (LP) and fine tuning (FT) strategies, protocols that can effectively control feature distortion, i.e., the failure to update features orthogonal to the in-distribution, have been found to achieve improved out-of-distribution generalization (OOD). In order to limit this distortion, the LP+FT protocol, which first learns a linear probe and then uses this initialization for subsequent FT, was proposed. However, in this paper, we find when adaptation protocols (LP, FT, LP+FT) are also evaluated on a variety of safety objectives (e.g., calibration, robustness, etc.), a complementary perspective to feature distortion is helpful to explain protocol behavior. To this end, we study the susceptibility of protocols to simplicity bias (SB), i.e. the well-known propensity of deep neural networks to rely upon simple features, as SB has recently been shown to underlie several problems in robust generalization. Using a synthetic dataset, we demonstrate the susceptibility of existing protocols to SB. Given the strong effectiveness of LP+FT, we then propose modified linear probes that help mitigate SB, and lead to better initializations for subsequent FT. We verify the effectiveness of the proposed LP+FT variants for decreasing SB in a controlled setting, and their ability to improve OOD generalization and safety on three adaptation datasets.",https://openreview.net/pdf/a96c8869749346661838b9c685006ca0e44e9011.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=wPVw218szF,Near Optimal Private and Robust Linear Regression,"['Xiyang Liu', 'Prateek Jain', 'Weihao Kong', 'Sewoong Oh', 'Arun Suggala']","['~Xiyang_Liu1', '~Prateek_Jain1', '~Weihao_Kong1', '~Sewoong_Oh1', '~Arun_Suggala1']","['differential privacy', 'private estimation', 'linear regression', 'label corruption']","We study the canonical statistical estimation problem of linear regression from $n$ i.i.d. examples under $(\varepsilon,\delta)$-differential privacy when a fraction of response variables are adversarially corrupted.   We propose a variant of the popular differentially private stochastic gradient descent (DP-SGD) algorithm with two innovations: a full-batch gradient descent to improve sample complexity and a novel adaptive clipping to guarantee robustness. When there is no adversarial corruption, this algorithm improves upon the existing state-of-the-art approach and achieves near optimal sample complexity. Under label-corruption, this is the first efficient linear regression algorithm to provably guarantee both $(\epsilon,\delta)$-DP and robustness. Synthetic experiments confirm the superiority of our approach. ",https://openreview.net/pdf/a1a787bd958b8f381601462126fd3b05687b3b53.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=w9WUQkBvpI,Subsampling in Large Graphs Using Ricci Curvature,"['Shushan Wu', 'Huimin Cheng', 'Jiazhang Cai', 'Ping Ma', 'Wenxuan Zhong']","['~Shushan_Wu1', '~Huimin_Cheng1', '~Jiazhang_Cai1', '~Ping_Ma1', '~Wenxuan_Zhong1']","['Graph subsampling', 'Ricci curvature']","In the past decades, many large graphs with millions of nodes have been collected/constructed. The high computational cost and significant visualization difficulty hinder the analysis of large graphs. To overcome the difficulties, researchers have developed many graph subsampling approaches to provide a rough sketch that preserves global properties. By selecting representative nodes, these graph subsampling methods can help researchers estimate the graph statistics, e.g., the number of communities, of the large graph from the subsample. However, the available subsampling methods, e.g., degree node sampler and random walk sampler, tend to leave out minority communities because nodes with high degrees are more likely to be sampled. To overcome the shortcomings of the existing methods, we are motivated to apply the community information hidden in the graph to the subsampling method. Though the community structure is unavailable, community structure information can be obtained by applying geometric methods to a graph. An analog of Ricci curvature in the manifold is defined for the graph, i.e., Ollivier Ricci curvature. Based on the asymptotic results about the within-community edge and between-community edge's OR curvature, we propose a subsampling algorithm based on our theoretical results, the Ollivier-Ricci curvature Gradient-based subsampling (ORG-sub) algorithm. The proposed ORG-sub algorithm has two main contributions: First, ORG-sub provides a rigorous theoretical guarantee that the probability of ORG-sub taking all communities into the final subgraph converges to one. Second, extensive experiments on synthetic and benchmark datasets demonstrate the advantages of our algorithm.",https://openreview.net/pdf/028be470cd7466da953f6e016e46cf5dfb5947b5.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=w2mDq-p9EEf,Learning Latent Structural Causal Models,"['Jithendaraa Subramanian', 'Yashas Annadani', 'Ivaxi Sheth', 'Nan Rosemary Ke', 'Tristan Deleu', 'Stefan Bauer', 'Derek Nowrouzezahrai', 'Samira Ebrahimi Kahou']","['~Jithendaraa_Subramanian1', '~Yashas_Annadani1', '~Ivaxi_Sheth1', '~Nan_Rosemary_Ke1', '~Tristan_Deleu1', '~Stefan_Bauer1', '~Derek_Nowrouzezahrai1', '~Samira_Ebrahimi_Kahou1']","['Causal discovery', 'Bayesian inference']","Causal learning has long concerned itself with the accurate recovery of underlying causal mechanisms. Such causal modelling enables better explanations of out-of-distribution data. Prior works on causal learning assume that the high-level causal variables are given. However, in machine learning tasks, one often operates on low-level data like image pixels or high-dimensional vectors. In such settings, the entire Structural Causal Model (SCM) -- structure, parameters, \textit{and} high-level causal variables -- is unobserved and needs to be learnt from low-level data. We treat this problem as Bayesian inference of the latent SCM, given low-level data. For linear Gaussian additive noise SCMs, we present a tractable approximate inference method which performs joint inference over the causal variables, structure and parameters of the latent SCM from random, known interventions. Experiments are performed on synthetic datasets and a causally generated image dataset to demonstrate the efficacy of our approach. We also perform image generation from unseen interventions, thereby verifying out of distribution generalization for the proposed causal model.",https://openreview.net/pdf/63a5676e151b88e25ccf790f232ac1921e110b1b.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=vxln_lFKkfc,Untangling Effect and Side Effect: Consistent Causal Inference in Non-Targeted Trials,"['Georgios Mavroudeas', 'Malik Magdon-Ismail', 'Kristin Bennett', 'Jason Kuruzovich']","['~Georgios_Mavroudeas1', '~Malik_Magdon-Ismail1', '~Kristin_Bennett1', '~Jason_Kuruzovich1']","['Causal Inference', 'Non Targeted Trials', 'Machine Learning', 'Heterogeneous Treatment Effects']","A treatment is usually appropriate for some group (the ``sick"" group) on whom it has an effect, but it can also have a side-effect when given to subjects from another group (the ``healthy"" group). In a non-targeted trial both sick and healthy subjects may be treated, producing
heterogeneous effects within the treated group. Inferring the correct treatment effect on the sick population is then 
difficult, because the effect and side-effect are tangled. We propose an efficient nonparametric approach to untangling the effect and side-effect, called  PCM (pre-cluster and merge). We prove its asymptotic consistency in a general setting and
show, on synthetic data, 
more than a 10x improvement in accuracy over existing state-of-the-art.
",https://openreview.net/pdf/56cdd812acaceee6a2b77038f8b66c792ecc1a64.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=vmFwJeiSx4X,Multi-Layered 3D Garments Animation,"['Yidi Shao', 'Chen Change Loy', 'Bo Dai']","['~Yidi_Shao1', '~Chen_Change_Loy2', '~Bo_Dai2']",[],"Most existing 3D garment animation datasets are restricted to human bodies with single-layered garments. Even though cases with upper shirts and lower pants are included, only a few overlap areas among such garment combinations exist. Moreover, they often regard human body movement as the only driving factor that causes garment animation. Approaches developed on top of these datasets thus tend to model garments as functions of human body parameters such as body shape and pose. While such treatment leads to promising performance on existing datasets, it leaves a gap between experimental environments and real scenarios, where a body can wear multiple layered garments and the corresponding garment dynamics can be affected by environmental factors and garment attributes. Consequently, existing approaches often struggle to generalize to multi-layered garments and realistic scenarios. To facilitate the advance of 3D garment animation toward handling more challenging cases, this paper presents a new large-scale synthetic dataset called LAYERS, covering 4,900 different combinations of multi-layered garments with 700k frames in total. The animation of these multi-layered garments follows the laws of physics and is affected by not only human body movements but also random environmental wind and garment attributes. To demonstrate the quality of LAYERS, we further propose a novel method, LayersNet, for 3D garment animation, which represents garments as unions of particles and subsequently adopts a neural network to animate garments via particle-based simulation. In this way, the interactions between different parts of one garment, different garments on the same body, and garments against various driving factors, can be naturally and uniformly handled via the interactions of particles. Through comprehensive experiments, LayersNet demonstrates superior performance in terms of animation accuracy and generality over baselines. The proposed dataset, LAYERS, as well as the proposed method, LayersNet, will be publicly available.",https://openreview.net/pdf/5bf39d3e86e854d81de7ff1abf2c1aa05a2d6380.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=vjSKpocWeGf,Lipschitz regularized gradient flows and latent generative particles,"['Hyemin Gu', 'Panagiota Birmpa', 'Yannis Pantazis', 'Markos Katsoulakis', 'Luc Rey-Bellet']","['~Hyemin_Gu1', '~Panagiota_Birmpa1', '~Yannis_Pantazis1', '~Markos_Katsoulakis1', '~Luc_Rey-Bellet1']","['probability divergences', 'generative models', 'Lipschitz regularization', 'gradient flows', 'autoencoders', 'particle algorithms']","Lipschitz regularized $f$-divergences are constructed by imposing a bound on the Lipschitz constant of the discriminator in the variational representation. These divergences interpolate between the Wasserstein metric and $f$-divergences and provide a flexible family of loss functions for non-absolutely continuous (e.g. empirical) distributions, possibly with heavy tails. We first construct Lipschitz regularized gradient flows on the space of probability measures based on these divergences. Examples of such gradient flows are Lipschitz regularized Fokker-Planck and porous medium partial differential equations (PDEs) for the Kullback-Leibler and $\alpha$-divergences, respectively. The regularization corresponds to imposing a Courant–Friedrichs–Lewy numerical stability condition on the PDEs. For empirical measures, the Lipschitz regularization on gradient flows induces a numerically stable transporter/discriminator particle algorithm, where the generative particles are transported along the gradient of the discriminator. The gradient structure leads to a regularized Fisher information which is the total kinetic energy of the particles and can be used to track the convergence of the algorithm. The Lipschitz regularized discriminator can be implemented via neural network spectral normalization and the particle algorithm generates approximate samples from possibly high-dimensional distributions known only from data. Notably, our particle algorithm can generate synthetic data even in small sample size regimes. A new data processing inequality for the regularized divergence allows us to combine our particle algorithm with representation learning, e.g. autoencoder architectures. The resulting particle algorithm in latent space yields markedly improved generative properties in terms of efficiency and quality of the synthetic samples. From a statistical mechanics perspective the encoding can be interpreted dynamically as learning a better mobility for the generative particles. ",https://openreview.net/pdf/f95b8bee808d335bb430ec2c78a939cb49d8409e.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=vaf8KQ8bhS,RbX: Region-based explanations of prediction models,"['Ismael Lemhadri', 'Harrison H Li', 'Trevor Hastie']","['~Ismael_Lemhadri1', '~Harrison_H_Li1', '~Trevor_Hastie1']",[],"We introduce region-based explanations (RbX), a novel, model-agnostic method to generate local explanations of scalar outputs from a black-box prediction model using only query access. RbX is based on a greedy algorithm for building a convex polytope that approximates a region of feature space where model predictions are close to the prediction at some target point. This region is fully specified by the user on the scale of the predictions, rather than on the scale of the features. The geometry of this polytope - specifically the change in each coordinate necessary to escape the polytope - quantifies the local sensitivity of the predictions to each of the features. These “escape distances” can then be standardized to rank the features by local importance. RbX is guaranteed to satisfy a “sparsity” axiom, which requires that features which do not enter into the prediction model are assigned zero importance. At the same time, real data examples and synthetic experiments show how RbX can more readily detect all locally relevant features than existing methods.",https://openreview.net/pdf/c54650701a3023e84ebf4ae863c2ccf168538608.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=v61jhmI2zz,Discovering Bugs in Vision Models using Off-the-shelf Image Generation and Captioning,"['Olivia Wiles', 'Isabela Albuquerque', 'Sven Gowal']","['~Olivia_Wiles1', '~Isabela_Albuquerque1', '~Sven_Gowal2']","['robustness', 'failure discovery']","Automatically discovering failures in vision models under real-world settings remains an open challenge. This work shows how off-the-shelf, large-scale, image-to-text and text-to-image models, trained on vast amounts of data, can be leveraged to automatically find such failures. In essence, a conditional text-to-image generative model is used to generate large amounts of synthetic, yet realistic, inputs given a ground-truth label. A captioning model is used to describe misclassified inputs. Descriptions are used in turn to generate more inputs, thereby assessing whether specific descriptions induce more failures than expected. As failures are grounded to natural language, we automatically obtain a high-level, human-interpretable explanation of each failure. We use this pipeline to demonstrate that we can effectively interrogate classifiers trained on ImageNet to find specific failure cases and discover spurious correlations. We also show that we can scale the approach to generate adversarial datasets targeting specific classifier architectures. This work demonstrates the utility of large-scale generative models to automatically discover bugs in vision models in an open-ended manner. We also describe a number of limitations and pitfalls related to this approach.",https://openreview.net/pdf/3c3da633058982171bc01205d90d6dbeea96b163.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=v3y68gz-WEz,Riemannian Metric Learning via Optimal Transport,"['Christopher Scarvelis', 'Justin Solomon']","['~Christopher_Scarvelis1', '~Justin_Solomon1']","['optimal transport', 'riemannian geometry', 'manifold learning', 'time series']","We introduce an optimal transport-based model for learning a metric tensor from cross-sectional samples of evolving probability measures on a common Riemannian manifold. We neurally parametrize the metric as a spatially-varying matrix field and efficiently optimize our model's objective using a simple alternating scheme. Using this learned metric, we can non-linearly interpolate between probability measures and compute geodesics on the manifold. We show that metrics learned using our method improve the quality of trajectory inference on scRNA and bird migration data at the cost of little additional cross-sectional data.",https://openreview.net/pdf/ef540eb6d8d75498298baa5bf7417a3542a7b4e8.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=v-3dUexkNn,Towards predicting dynamic stability of power grids with Graph Neural Networks,"['Christian Nauck', 'Michael Lindner', 'Konstantin Schürholt', 'Frank Hellmann']","['~Christian_Nauck1', '~Michael_Lindner1', '~Konstantin_Schürholt1', '~Frank_Hellmann1']","['Power grids', 'dynamic stability', 'Graph Neural Networks']","To mitigate climate change, the share of renewable energies in power production needs to be increased. Renewables introduce new challenges to power grids regarding the dynamic stability due to decentralization, reduced inertia and volatility in production. However, dynamic stability simulations are intractable and exceedingly expensive for large grids. Graph Neural Networks (GNNs) are a promising method to reduce the computational effort of analyzing dynamic stability of power grids. We provide new datasets of dynamic stability of synthetic power grids and find that GNNs are surprisingly effective at predicting highly non-linear targets from topological information only. We show that large GNNs outperform GNNs from previous work as well as as handcrafted graph features and semi-analytic approximations. Further, we demonstrate GNNs can accurately identify \emph{trouble maker}-nodes in the power grids. Lastly, we show that GNNs trained on small grids can perform accurately on a large synthetic Texan power grid model, which illustrates the potential of our approach.",https://openreview.net/pdf/07bb7e3741389dfb3cbe989b8389443c5dc4e089.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=uyqks-LILZX,Modeling the Data-Generating Process is Necessary for Out-of-Distribution Generalization,"['Jivat Neet Kaur', 'Emre Kiciman', 'Amit Sharma']","['~Jivat_Neet_Kaur1', '~Emre_Kiciman1', '~Amit_Sharma3']",[],"Recent empirical studies on domain generalization (DG) have shown that DG algorithms that perform well on some distribution shifts fail on others, and no state-of-the-art DG algorithm performs consistently well on all shifts. Moreover, real-world data often has multiple distribution shifts over different attributes; hence we introduce multi-attribute distribution shift datasets and find that the accuracy of existing DG algorithms falls even further. To explain these results, we provide a formal characterization of generalization under multi-attribute shifts using a canonical causal graph. Based on the relationship between spurious attributes and the classification label, we obtain realizations of the canonical causal graph that characterize common distribution shifts and show that each shift entails different independence constraints over observed variables. As a result, we prove that any algorithm based on a single, fixed constraint cannot work well across all shifts, providing theoretical evidence for mixed empirical results on DG algorithms. Based on this insight, we develop Causally Adaptive Constraint Minimization (CACM), an algorithm that uses knowledge about the data-generating process to adaptively identify and apply the correct independence constraints for regularization. Results on fully synthetic, MNIST, small NORB, and Waterbirds datasets, covering binary and multi-valued attributes and labels, show that adaptive dataset-dependent constraints lead to the highest accuracy on unseen domains whereas incorrect constraints fail to do so. Our results demonstrate the importance of modeling the causal relationships inherent in the data-generating process.",https://openreview.net/pdf/4048ed797cd1ecee3eb0807128459f763f1cd777.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=ufCQZeAMZzf,Low-Rank Graph Neural Networks Inspired by the Weak-balance Theory in Social Networks,"['Langzhang Liang', 'Xiangjing Hu', 'Zenglin Xu', 'Zixing Song', 'Irwin King']","['~Langzhang_Liang1', '~Xiangjing_Hu1', '~Zenglin_Xu1', '~Zixing_Song1', '~Irwin_King1']","['graph neural networks', 'heterophily', 'social theory', 'low rank']","Graph Neural Networks (GNNs) have achieved state-of-the-art performance on node classification tasks by exploiting both the graph structures and node features. Generally, most existing GNNs depend on the implicit homophily assumption that nodes belonging to the same class are more likely to be connected. However, GNNs may fail to model heterophilious graphs where nodes with different labels tend to be linked, as shown in recent studies.  To address this issue, we propose a generic GNN applicable to both homophilious and heterophilious graphs, namely Low-Rank Graph Neural Network (LRGNN). In detail, we aim at computing a coefficient matrix such that the sign of each coefficient reveals whether the corresponding two nodes belong to the same class, which is similar to the sign inference problem. In Signed Social Networks (SSNs), the sign inference problem can be modeled as a low-rank matrix factorization (LRMF) problem due to the global low-rank structure described by the weak balance theory. In this paper, we show that signed graphs are naturally generalized weakly-balanced when considering node classification tasks. Motivated by this observation, we propose to leverage LRMF to recover a coefficient matrix from a partially observed signed adjacency matrix. To effectively capture the node similarity, we further incorporate the low-rank representation (LRR) method. Our theoretical result shows that under our update rule of node representations, LRR obtained by solving a subspace clustering problem can recover the subspace structure of node representations. To solve the corresponding optimization problem, we utilize an iterative optimization algorithm with a convergence guarantee and develop a neural-style initialization manner that enables fast convergence. Finally, extensive experimental evaluation on both real-world and synthetic graphs has validated the superior performance of LRGNN over various state-of-the-art GNNs. In particular, LRGNN can offer clear performance gains in a scenario when the node features are not informative enough.",https://openreview.net/pdf/5f8a49029fefca9e88dcd4273d9cfa7c7e447a59.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=uKmuzIuVl8z,Structure-based Drug Design with Equivariant Diffusion Models,"['Arne Schneuing', 'Yuanqi Du', 'Charles Harris', 'Arian Rokkum Jamasb', 'Ilia Igashov', 'weitao Du', 'Tom Leon Blundell', 'Pietro Lio', 'Carla P Gomes', 'Max Welling', 'Michael M. Bronstein', 'Bruno Correia']","['~Arne_Schneuing1', '~Yuanqi_Du1', '~Charles_Harris2', '~Arian_Rokkum_Jamasb1', '~Ilia_Igashov1', '~weitao_Du1', '~Tom_Leon_Blundell1', '~Pietro_Lio1', '~Carla_P_Gomes1', '~Max_Welling1', '~Michael_M._Bronstein1', '~Bruno_Correia1']","['Diffusion Models', 'Equivariant Neural Networks', 'Structure-based Drug Design', 'Molecule Generation', 'Conditional Generation']","Structure-based drug design (SBDD) aims to design small-molecule ligands that bind with high affinity and specificity to pre-determined protein targets. Traditional SBDD pipelines start with large-scale docking of compound libraries from public databases, thus limiting the exploration of chemical space to existent previously studied regions.
Recent machine learning methods approached this problem using an atom-by-atom generation approach, which is computationally expensive. 
In this paper, we formulate SBDD as a 3D-conditional generation problem and present DiffSBDD, an E(3)-equivariant 3D-conditional diffusion model that generates novel ligands conditioned on protein pockets. 
Furthermore, we curate a new dataset of experimentally determined binding complex data from Binding MOAD to provide realistic binding scenario rather than the synthetic CrossDocked dataset. Comprehensive in silico experiments demonstrate the efficiency of DiffSBDD in generating novel and diverse drug-like ligands that engage protein pockets with high binding energies as predicted by in silico docking.",https://openreview.net/pdf/534070e1a8092ce852688c63211857cb33856123.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=u9hnCwX99I1,Centralized Training with Hybrid Execution in Multi-Agent Reinforcement Learning,"['Pedro Pinto Santos', 'Diogo S. Carvalho', 'Miguel Vasco', 'Francisco S. Melo', 'Alberto Sardinha', 'Pedro A. Santos', 'Ana Paiva']","['~Pedro_Pinto_Santos1', '~Diogo_S._Carvalho1', '~Miguel_Vasco1', '~Francisco_S._Melo1', '~Alberto_Sardinha1', '~Pedro_A._Santos1', '~Ana_Paiva2']",['Multi-Agent Reinforcement Learning'],"We introduce hybrid execution in multi-agent reinforcement learning (MARL), a new paradigm in which agents aim to successfully perform cooperative tasks with any communication level at execution time by taking advantage of information-sharing among the agents. Under hybrid execution, the communication level can range from a setting in which no communication is allowed between agents (fully decentralized), to a setting featuring full communication (fully centralized). To formalize our setting, we define a new class of multi-agent partially observable Markov decision processes (POMDPs) that we name hybrid-POMDPs, which explicitly models a communication process between the agents. We contribute MARO, an approach that combines an autoregressive predictive model to estimate missing agents' observations, and a dropout-based RL training scheme that simulates different communication levels during the centralized training phase. We evaluate MARO on standard scenarios and extensions of previous benchmarks tailored to emphasize the negative impact of partial observability in MARL. Experimental results show that our method consistently outperforms baselines, allowing agents to act with faulty communication while successfully exploiting shared information.",https://openreview.net/pdf/1e453f0df117752fa75e7810ace4310c4099f97c.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=u0aNcjqhEJ,Consciousness-Aware Multi-Agent Reinforcement Learning,"['Jianzhun Shao', 'Hongchang Zhang', 'Yun Qu', 'Chang Liu', 'Shuncheng He', 'Yuhang Jiang', 'Xiangyang Ji']","['~Jianzhun_Shao1', '~Hongchang_Zhang1', '~Yun_Qu2', '~Chang_Liu9', '~Shuncheng_He1', '~Yuhang_Jiang3', '~Xiangyang_Ji1']",['multi-agent reinforcement learning'],"In cooperative multi-agent reinforcement learning, centralized training with decentralized execution (CTDE) shows great promise for a trade-off between independent Q-learning and joint action learning. However, vanilla CTDE methods assumed a fixed number of agents could hardly adapt to real-world scenarios where dynamic team compositions typically suffer from the dilemma of dramatic partial observability variance. Specifically, agents with extensive sight ranges are prone to be affected by trivial environmental substrates, dubbed the “attention distraction” issue; ones with limited observability can hardly sense their teammates, hindering the quality of cooperation. In this paper, we propose a Consciousness-Aware Multi-Agent reinforcement learning (CAMA) approach, which roots in a divide-and-conquer strategy to facilitate stable and sustainable teamwork. Concretely, CAMA targets dividing the input entities with controlled observability masks by an Entity Dividing Module (EDM) according to their execution relevance for consciousness learning. To tackle the attention distraction issue, the highly related entities are fed to a Consciousness Enhancement Module (CEM) for consciousness-aware representation extraction via action prediction with an inverse model. For better out-of-sight-range cooperation, the lowly related ones are compressed to brief messages by a Consciousness Replenishment Module (CRM) with a conditional mutual information estimator. Our CAMA outperforms the SOTA methods significantly on the challenging StarCraftII, MPE, and Traffic Junction benchmarks.",https://openreview.net/pdf/997d626ea381b73966bba7980d7607707ea0a50d.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=ttnf-Wibn2R,An Analytic Framework for Robust Training of Differentiable Hypothesis,"['Ramin Barati', 'Reza Safabakhsh', 'Mohammad Rahmati']","['~Ramin_Barati1', '~Reza_Safabakhsh1', '~Mohammad_Rahmati1']",[],"The reliability of a learning model is key to the successful deployment of machine learning in various industries. Creating a robust model, particularly one unaffected by adversarial attacks, requires a comprehensive understanding of the adversarial examples phenomenon. However, it is difficult to describe the phenomenon due to the complicated nature of the problems in machine learning. Consequently, many studies investigate the phenomenon by proposing a simplified model of how adversarial examples occur and validate it by predicting some aspect of the phenomenon. While these studies cover many different characteristics of the adversarial examples, they have not reached a holistic approach to the geometric and analytic modeling of the phenomenon. We observe the phenomenon in many applications of machine learning, and its effects seems to be independent of the choice of the hypothesis class. In this paper, we propose a formalization of robustness in learning theoretic terms and give a geometrical description of the phenomenon in analytic classifiers. We then utilize the proposal to devise a robust classification learning rule for differentiable hypothesis classes and showcase our framework on synthetic and real-world data.",https://openreview.net/pdf/21d61c913c546d572488600f61aeaeb4ae075dec.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=tsPXEkMzPjB,Learning to Decouple Complex System for Sequential Data,"['Zihan Zhou', 'Minxin Ao', 'Tianshu Yu']","['zihanzhou1@link.cuhk.edu.cn', '121050006@link.cuhk.edu.cn', '~Tianshu_Yu2']","['neural differential equation', 'sequential learning', 'decoupling complex system']","A complex system with cluttered observations may be a coupled mixture of multiple simple sub-systems corresponding to \emph{latent entities}. Such sub-systems may hold distinct dynamics in the continuous-time domain, therein complicated interactions between sub-systems also evolve over time.  This setting is fairly common in the real world, but has been less considered. In this paper, we propose a sequential learning approach under this setting by decoupling a complex system for handling irregularly sampled and cluttered sequential observations. Such decoupling brings about not only subsystems describing the dynamics of each latent entity, but also a meta-system capturing the interaction between entities over time. Specifically, we argue that the meta-system of interactions is governed by a smoothed version of \emph{projected differential equations}. Experimental results on synthetic and real-world datasets show the advantages of our approach when facing complex and cluttered sequential data compared to the state-of-the-art.",https://openreview.net/pdf/cda7ea238c2f1abf3dbc2a930938d6eb3f6eba78.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=tlhsswFz9x,Learning Graph Neural Network Topologies,"['Avishkar Saha', 'Oscar Mendez Maldonado', 'Chris Russell', 'Richard Bowden']","['~Avishkar_Saha1', '~Oscar_Mendez_Maldonado1', '~Chris_Russell3', '~Richard_Bowden1']",[],"Graph convolutional networks (GCNs) enable end-to-end learning on graph structured data. However, many works begin by assuming a given graph structure. As the ideal graph structure is often unknown, this limits applicability. To address this, we present a novel end-to-end differentiable graph-generator which builds the graph topology on the fly. Our module can be readily integrated into existing pipelines involving graph convolution operations, replacing the predetermined or existing adjacency matrix with one that is learned, and optimised, as part of the general objective. As such it is applicable to any GCN. We show that integrating our module into both node classification and trajectory prediction pipelines improves accuracy across a range of datasets and backbones.",https://openreview.net/pdf/48868383be4fb6c14a1396585baddcc526fb4ed0.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=tPrRs6YB2P,Scenario-based Question Answering with Interacting Contextual Properties,"['Haitian Sun', 'William W. Cohen', 'Ruslan Salakhutdinov']","['~Haitian_Sun2', '~William_W._Cohen2', '~Ruslan_Salakhutdinov1']",['Question Answering'],"In the scenario-based Question Answering (QA) task, models are asked to find answers that are appropriate to the user scenarios associated with the question and identify information that is missing from the scenarios but is necessary for the answers to hold. Scenarios commonly include multiple properties of users, such as age, employment status, and income level for the question “How much can I claim from this benefit”. The properties relevant to a potential answer are given in a document, which will state conditions necessary for the answer to hold. Documents also may specify how conditions interact with each other, e.g. with text like “one of the conditions below must apply”. Although understanding the relationship between conditions is crucial for solving this challenging QA task, limited work has been done so far in modeling this. In this paper, we propose the T-Reasoner model, which solves this problem with three jointly learned modules: an entailment module which checks whether a condition has been satisfied by the scenario, a decoding module which locates eligible answers from documents, and a reasoning module which infers the relationship between conditions and performs a reasoning step to determine the logically consistent answers and identify missing conditions. T-Reasoner outperforms strong baselines on a synthetic scenario-based QA dataset and achieves a new state-of-the-art on two scenario-based QA benchmarks, outperforming the prior best models by 3-10 points.",https://openreview.net/pdf/3fd9ea33c70845a298ecbb8cf8b7cdb1cb25c4c1.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=tKMLGb7MWC,A Reinforcement Learning Approach to Estimating Long-term Treatment Effects,"['Ziyang Tang', 'Yiheng Duan', 'Stephanie Zhang', 'Lihong Li']","['~Ziyang_Tang1', 'yiheng@amazon.com', 'stepzhan@amazon.com', '~Lihong_Li1']","['reinforcement learning', 'off-policy evaluation', 'A/B testing']","Randomized experiments (a.k.a. A/B tests) are a powerful tool for estimating treatment effects, to inform decisions making in business, healthcare and other applications. In many problems, the treatment has a lasting effect that evolves over time. A limitation with randomized experiments is that they do not easily extend to measure long-term effects, since running long experiments is time-consuming and expensive. In this paper, we take a reinforcement learning (RL) approach that estimates the average reward in a Markov process. Motivated by real-world scenarios where the observed state transition is nonstationary, we develop a new algorithm for a class of nonstationary problems, and demonstrate promising results in two synthetic datasets and one online store dataset.",https://openreview.net/pdf/693e8525df90817f1b0757b468adabfbceec5b7d.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=tHsu1olr9ZcQ,Variational Reparametrized Policy Learning with Differentiable Physics,"['Zhiao Huang', 'Litian Liang', 'Zhan Ling', 'Xuanlin Li', 'Chuang Gan', 'Hao Su']","['~Zhiao_Huang1', '~Litian_Liang1', '~Zhan_Ling2', '~Xuanlin_Li1', '~Chuang_Gan1', '~Hao_Su1']",['Differentiable Physics Reinforcement Learning'],"We study the problem of policy parameterization for reinforcement learning (RL) with high-dimensional continuous action space. Our goal is to find a good way to parameterize the policy of continuous RL as a multi-modality distribution. To this end, we propose to treat the continuous RL policy as a generative model over the distribution of optimal trajectories. We use a diffusion process-like strategy to model the policy and derive a novel variational bound which is the optimization objective to learn the policy. To maximize the objective by gradient descent, we introduce the Reparameterized Policy Gradient Theorem. This theorem elegantly connects classical method REINFORCE and trajectory return optimization for computing the gradient of a policy. Moreover, our method enjoys strong exploration ability due to the multi-modality policy parameterization; notably, when a strong differentiable world model presents, our method also enjoys the fast convergence speed of trajectory optimization. We evaluate our method on numerical problems and manipulation tasks within a differentiable simulator. Qualitative results show its ability to capture the multi-modality distribution of optimal trajectories, and quantitative results show that it can avoid local optima and outperforms baseline approaches.",https://openreview.net/pdf/4bb6ca9d02ccb14c66ebf2c868d1edfdf199b98b.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=swEskiem99,Feature selection and low test error in shallow low-rotation ReLU networks,['Matus Telgarsky'],['~Matus_Telgarsky1'],"['gradient descent', 'gradient flow', 'margin maximization', 'test error', 'neural collapse', 'generalization']","This work establishes low test error of gradient flow (GF) and stochastic gradient descent (SGD) on two-layer ReLU networks with standard initialization scale, in three regimes where key sets of weights rotate little (either naturally due to GF and SGD, or due to an artificial constraint), and making use of margins as the core analysis technique. The first regime is near initialization, specifically until the weights have moved by $\mathcal{O}(\sqrt m)$, where $m$ denotes the network width, which is in sharp contrast to the $\mathcal{O}(1)$ weight motion allowed by the Neural Tangent Kernel (NTK); here it is shown that GF and SGD only need a network width and number of samples inversely proportional to the NTK margin, and moreover that GF attains at least the NTK margin itself and in particular escapes bad KKT points of the margin objective, whereas prior work could only establish nondecreasing but arbitrarily small margins. The second regime is the Neural Collapse (NC) setting, where data lies in well-separated groups, and the sample complexity scales with the number of groups; here the contribution over prior work is an analysis of the entire GF trajectory from initialization. Lastly, if the inner layer weights are constrained to change in norm only and can not rotate, then GF with large widths achieves globally maximal margins, and its sample complexity scales with their inverse; this is in contrast to prior work, which required infinite width and a tricky dual convergence assumption.
",https://openreview.net/pdf/fcbfd7f8d46076e87300ed63c39d60a6e8c11a7e.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=shzu8d6_YAR,FaiREE: fair classification with finite-sample and distribution-free guarantee,"['Puheng Li', 'James Zou', 'Linjun Zhang']","['~Puheng_Li1', '~James_Zou1', '~Linjun_Zhang1']","['algorithmic fairness', 'distribution-free', 'finite-sample', 'classification']","Algorithmic fairness plays an increasingly critical role in machine learning research. Several group fairness notions and algorithms have been proposed. However, the fairness guarantee of existing fair classification methods mainly depend on specific data distributional assumptions, often requiring large sample sizes, and fairness could be violated when there is a modest number of samples, which is often the case in practice. In this paper, we propose FaiREE, a fair classification algorithm which can satisfy group fairness constraints with finite-sample and distribution-free theoretical guarantees. FaiREE can be adapted to satisfying various group fairness notions (e.g., Equality of Opportunity, Equalized Odds, Demographic Parity, etc.) and achieve the optimal accuracy. These theoretical guarantees are further supported by experiments on both synthetic and real data. FaiREE is shown to have favorable performance over state-of-the-art algorithms.",https://openreview.net/pdf/0ef42c8eae510f399cb004342de52a2a9b3005e3.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=sPCKNl5qDps,Ollivier-Ricci Curvature for Hypergraphs: A Unified Framework,"['Corinna Coupette', 'Sebastian Dalleiger', 'Bastian Rieck']","['~Corinna_Coupette1', '~Sebastian_Dalleiger1', '~Bastian_Rieck1']","['curvature', 'hypergraphs', 'graphs', 'Wasserstein distance', 'topological data analysis', 'random walks', 'probability measure']","Bridging geometry and topology, curvature is a powerful and expressive invariant. While the utility of curvature has been theoretically and empirically confirmed in the context of manifolds and graphs, its generalization to the emerging domain of hypergraphs has remained largely unexplored. On graphs, the Ollivier-Ricci curvature measures differences between random walks via Wasserstein distances, thus grounding a geometric concept in ideas from probability theory and optimal transport. We develop Orchid, a flexible framework generalizing Ollivier-Ricci curvature to hypergraphs, and prove that the resulting curvatures have favorable theoretical properties. Through extensive experiments on synthetic and real-world hypergraphs from different domains, we demonstrate that Orchid curvatures are both scalable and useful to perform a variety of hypergraph tasks in practice.",https://openreview.net/pdf/cf1554077cc4c42ade51993934dbe9c8c16d4ef0.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=sMsShmoszg,Mind the Privacy Budget: How Generative Models Spend their Privacy Budgets,"['Georgi Ganev', 'Kai Xu', 'Emiliano De Cristofaro']","['~Georgi_Ganev1', '~Kai_Xu4', '~Emiliano_De_Cristofaro1']","['synthetic data', 'differential privacy', 'generative models', 'graphical models', 'GANs']","Numerous Differentially Private (DP) generative models have been presented that aim to produce synthetic data while minimizing privacy risks.
As there is no single model that works well in all settings, empirical analysis is needed to establish and optimize trade-offs vis-\`a-vis the intended use of the synthetic data.
In this paper, we identify and address several challenges in the empirical evaluation of such models.
First, we analyze the steps in which different algorithms ``spend'' their privacy budget.
We evaluate the effects on the performance of downstream tasks to identify problem settings they are most likely to be successful at.
Then, we experiment with increasingly wider and taller training sets with various features, decreasing privacy budgets, and different DP mechanisms and generative models.

Our empirical evaluation, performed on both graphical and deep generative models, sheds light on the distinctive features of different models/mechanisms that make them well-suited for different settings and tasks.
Graphical models distribute the privacy budget horizontally and cannot handle relatively wide datasets, while the performance on the task they were optimized for monotonically increases with more data.
Deep generative models spend their budget per iteration, and their behavior is less predictable with varying dataset dimensions, but could perform better if trained on more features.
Also, low levels of privacy ($\epsilon\geq100$) could help some models generalize, achieving better results than without applying DP.",https://openreview.net/pdf/daaecd76c5fd7ec4ba7da0be8aa9e5cccaa35aa4.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=sKWlRDzPfd7,MAESTRO: Open-Ended Environment Design for Multi-Agent Reinforcement Learning,"['Mikayel Samvelyan', 'Akbir Khan', 'Michael D Dennis', 'Minqi Jiang', 'Jack Parker-Holder', 'Jakob Nicolaus Foerster', 'Roberta Raileanu', 'Tim Rocktäschel']","['~Mikayel_Samvelyan1', '~Akbir_Khan1', '~Michael_D_Dennis1', '~Minqi_Jiang1', '~Jack_Parker-Holder1', '~Jakob_Nicolaus_Foerster1', '~Roberta_Raileanu2', '~Tim_Rocktäschel1']","['reinforcement learning', 'multi-agent learning', 'unsupervised environment design']","Open-ended learning methods that automatically generate a curriculum of increasingly challenging tasks serve as a promising avenue toward generally capable reinforcement learning agents. Existing methods adapt curricula independently over either environment parameters (in single-agent settings) or co-player policies (in multi-agent settings). However, the strengths and weaknesses of co-players can manifest themselves differently depending on environmental features. It is thus crucial to consider the dependency between the environment and co-player when shaping a curriculum in multi-agent domains. In this work, we use this insight and extend Unsupervised Environment Design (UED) to multi-agent environments. We then introduce Multi-Agent Environment Design Strategist for Open-Ended Learning (MAESTRO), the first multi-agent UED approach for two-player zero-sum settings. MAESTRO efficiently produces adversarial, joint curricula over both environments and co-players and attains minimax-regret guarantees at Nash equilibrium. Our experiments show that MAESTRO outperforms a number of strong baselines on competitive two-player games, spanning discrete and continuous control settings.",https://openreview.net/pdf/e65b3ee9b4e5db11d48c773dc4e02702868ef8e6.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=sKDtBKYOdIP,Beam Tree Recursive Cells,"['Jishnu Ray Chowdhury', 'Cornelia Caragea']","['~Jishnu_Ray_Chowdhury2', '~Cornelia_Caragea2']","['Recursive Neural Networks', 'RvNNs', 'length generalization', 'systematicity']","Recursive Neural Networks (RvNNs) generalize Recurrent Neural Networks (RNNs) by allowing sequential composition in a more flexible order, typically, based on some tree structure. While initially user-annotated tree structures were used, in due time, several approaches were proposed to automatically induce tree-structures from raw text to guide the recursive compositions in RvNNs. In this paper, we present an approach called Beam Tree Recursive Cell (or BT-Cell) based on a simple yet overlooked backpropagation-friendly framework. BT-Cell applies beam search on easy-first parsing for simulating RvNNs with automatic structure-induction. Our results show that BT-Cell achieves near-perfect performance on several aspects of challenging structure-sensitive synthetic tasks like ListOps and also comparable performance in realistic data to other RvNN-based models. We further introduce and analyze several extensions of BT-Cell based on relaxations of the hard top-k operators in beam search. We evaluate the models in different out of distribution splits in both synthetic and realistic data. Additionally, we identify a previously unknown failure case for neural models in generalization to unseen number of arguments in ListOps. We will release our code.",https://openreview.net/pdf/aa2e1e69e8e0fe1ed5ec53bac9e9268a7b9c2336.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=rde9B5ue32F,Compressed Predictive Information Coding,"['Rui Meng', 'Tianyi Luo', 'Kristofer Bouchard']","['~Rui_Meng3', '~Tianyi_Luo2', '~Kristofer_Bouchard1']","['Predictive information', 'time series', 'variational inference']","Unsupervised learning plays an important role in many fields, such as machine learning, data compression, and neuroscience. Compared to static data, methods for extracting low-dimensional structure for dynamic data are lagging. We developed a novel information-theoretic framework, Compressed Predictive Information Coding (CPIC), to extract predictive latent representations from dynamic data. Predictive information quantifies the ability to predict the future of a time series from its past. CPIC selectively projects the past (input) into a low dimensional space that is predictive about the compressed data projected from the future (output). The key insight of our framework is to learn representations by balancing the minimization of compression complexity with maximization of the predictive information in the latent space. We derive tractable variational bounds of the CPIC loss by leveraging bounds on mutual information. The CPIC loss induces the latent space to capture information that is maximally predictive of the future of the data from the past. We demonstrate that introducing stochasticity in the encoder and maximizing the predictive information in latent space contributes to learning more robust latent representations. Furthermore, our variational approaches perform better in mutual information estimation compared with estimates under the Gaussian assumption commonly used. We show numerically in synthetic data that CPIC can recover dynamical systems embedded in noisy observation data with low signal-to-noise ratio. Finally, we demonstrate that CPIC extracts features more predictive of forecasting exogenous variables as well as auto-forecasting in various real datasets compared with other state-of-the-art representation learning models. Together, these results indicate that CPIC will be broadly useful for extracting low-dimensional dynamic structure from high-dimensional, noisy time-series data.",https://openreview.net/pdf/e31289b8891e15176d39fb5f99092ca98df29324.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=raU07GpP0P,Improving Deep Regression with Ordinal Entropy,"['Shihao Zhang', 'Linlin Yang', 'Michael Bi Mi', 'Xiaoxu Zheng', 'Angela Yao']","['~Shihao_Zhang1', '~Linlin_Yang1', '~Michael_Bi_Mi1', '~Xiaoxu_Zheng1', '~Angela_Yao1']","['regression', 'classification', 'entropy', 'depth estimation', 'counting', 'age estimation']","In computer vision, it is often observed that formulating regression problems as a classification task yields better performance. We investigate this curious phenomenon and provide a derivation to show that classification, with the cross-entropy loss, outperforms regression with a mean squared error loss in its ability to learn high-entropy feature representations. Based on the analysis, we propose an ordinal entropy loss to encourage higher-entropy feature spaces while maintaining ordinal relationships to improve the performance of regression tasks. Experiments on synthetic and real-world regression tasks demonstrate the importance and benefits of increasing entropy for regression.",https://openreview.net/pdf/3fa28db76e89d4a3ce4e48a57a415e706ad74b51.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=r9hNv76KoT3,Rethinking the Expressive Power of GNNs via Graph Biconnectivity,"['Bohang Zhang', 'Shengjie Luo', 'Liwei Wang', 'Di He']","['~Bohang_Zhang1', '~Shengjie_Luo1', '~Liwei_Wang1', '~Di_He1']","['Graph Neural Networks', 'Expressive Power', 'Weisfeiler-Lehman test', 'Graph Transformer', 'Biconnectivity']","Designing expressive Graph Neural Networks (GNNs) is a central topic in learning graph-structured data. While numerous approaches have been proposed to improve GNNs with respect to the Weisfeiler-Lehman (WL) test, for most of them, there is still a lack of deep understanding of what additional power they can systematically and provably gain. In this paper, we take a fundamentally different perspective to study the expressive power of GNNs beyond the WL test. Specifically, we introduce a novel class of expressivity metrics via graph biconnectivity and highlight their importance in both theory and practice. As biconnectivity can be easily calculated using simple algorithms that have linear computational costs, it is natural to expect that popular GNNs can learn it easily as well. However, after a thorough review of prior GNN architectures, we surprisingly find that most of them are not expressive for any of these metrics. The only exception is the ESAN framework (Bevilacqua et al., 2022), for which we give a theoretical justification of its power. We proceed to introduce a principled and more efficient approach, called the Generalized Distance Weisfeiler-Lehman (GD-WL), which is provably expressive for all biconnectivity metrics. Practically, we show GD-WL can be implemented by a Transformer-like architecture that preserves expressiveness and enjoys full parallelizability. A set of experiments on both synthetic and real datasets demonstrates that our approach can consistently outperform prior GNN architectures.",https://openreview.net/pdf/be0ebeff1b3c008481709874f052f374a1d68dec.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=r0xte-t40I,Learning Human-Compatible Representations for Case-Based Decision Support,"['Han Liu', 'Yizhou Tian', 'Chacha Chen', 'Shi Feng', 'Yuxin Chen', 'Chenhao Tan']","['~Han_Liu12', '~Yizhou_Tian1', '~Chacha_Chen1', '~Shi_Feng1', '~Yuxin_Chen1', '~Chenhao_Tan1']","['human-compatible representation learning', 'human triplet judgments']","Algorithmic case-based decision support provides examples to help human make sense of predicted labels and aid human in decision-making tasks. Despite the promising performance of supervised learning, representations learned by supervised models may not align well with human intuitions: what models consider as similar examples can be perceived as distinct by humans. As a result, they have limited effectiveness in case-based decision support. In this work, we incorporate ideas from metric learning with supervised learning to examine the importance of alignment for effective decision support. In addition to instance-level labels, we use human-provided triplet judgments to learn human-compatible decision-focused representations. Using both synthetic data and human subject experiments in multiple classification tasks, we demonstrate that such representation is better aligned with human perception than representation solely optimized for classification. Human-compatible representations identify nearest neighbors that are perceived as more similar by humans and allow humans to make more accurate predictions, leading to substantial improvements in human decision accuracies (17.8% in butterfly vs. moth classification and 13.2% in pneumonia classification).",https://openreview.net/pdf/8a16439b8778f846cdadf78cfd6ce542a48cbfbe.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=quCOIL8JQnp,Improving Adversarial Robustness by Contrastive Guided Diffusion Process,"['Yidong Ouyang', 'Liyan Xie', 'Guang Cheng']","['~Yidong_Ouyang1', '~Liyan_Xie2', '~Guang_Cheng1']",[],"Synthetic data generation has become an emerging tool to help improve the adversarial robustness in classification tasks since robust learning requires a significantly larger amount of training samples compared with standard classification tasks. Among various deep generative models, the diffusion model has been shown to produce high-quality synthetic images and has achieved good performance in improving the adversarial robustness. However, diffusion-type methods are typically slow in data generation as compared with other generative models. Although different acceleration techniques have been proposed recently, it is also of great importance to study how to improve the sample efficiency of generated data for the downstream task. In this paper, we first analyze the optimality condition of synthetic distribution for achieving non-trivial robust accuracy. We show that enhancing the distinguishability among the generated data is critical for improving adversarial robustness. Thus, we propose the Contrastive-Guided Diffusion Process (Contrastive-DP), which adopts the contrastive loss to guide the diffusion model in data generation. We verify our theoretical results using simulations and demonstrate the good performance of Contrastive-DP on image datasets.",https://openreview.net/pdf/df68fb33d3112faeae607e91d4d1dcd318d633a3.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=qihMOPw4Sf_,Valid P-Value for Deep Learning-driven Salient Region,"['Miwa Daiki', 'Vo Nguyen Le Duy', 'Ichiro Takeuchi']","['miwa.daiki.mllab.nit@gmail.com', '~Vo_Nguyen_Le_Duy1', '~Ichiro_Takeuchi1']","['Saliency Map', 'Attention', 'Selective Inference', 'Uncertainty Quantification', 'P-value', 'Statistical Hypothesis Testing']","Various saliency map methods have been proposed to interpret and explain predictions of deep learning models. Saliency maps allow us to interpret which parts of the input signals have a strong influence on the prediction results. However, since a saliency map is obtained by complex computations in deep learning models, it is often difficult to know how reliable the saliency map itself is. In this study, we propose a method to quantify the reliability of a saliency region in the form of p-values. Our idea is to consider a saliency map as a selected hypothesis by the trained deep learning model and employ the selective inference framework. The proposed method provably provides a valid p-value for the detected salient region, i.e., we can provably control the false positive rate of the detected salient region. We demonstrate the validity of the proposed method through numerical examples in synthetic and real datasets. Furthermore, we develop a Keras-based framework for conducting the proposed selective inference for a wide class of CNNs without additional implementation cost.",https://openreview.net/pdf/4648f8cd96b71924f57fd9418c3d9e7fe45ce8c8.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=qU6NIcpaSi-,Learning Heterogeneous Interaction Strengths by Trajectory Prediction with Graph Neural Network,"['Seungwoong Ha', 'Hawoong Jeong']","['~Seungwoong_Ha1', 'hjeong@kaist.edu']","['relational learning', 'complex systems', 'dynamic systems', 'graph learning']","Dynamical systems with interacting agents are universal in nature, commonly modeled by a graph of relationships between their constituents. Recently, various works have been presented to tackle the problem of inferring those relationships from the system trajectories via deep neural networks, but most of the studies assume binary or discrete types of interactions for simplicity. In the real world, the interaction kernels often involve continuous interaction strengths, which cannot be accurately approximated by discrete relations. In this work, we propose the relational attentive inference network (RAIN) to infer continuously weighted interaction graphs without any ground-truth interaction strengths. Our model employs a novel pairwise attention (PA) mechanism to refine the trajectory representations and a graph transformer to extract heterogeneous interaction weights for each pair of agents. We show that our RAIN model with the PA mechanism accurately infers continuous interaction strengths for simulated physical systems in an unsupervised manner. Further, RAIN with PA successfully predicts trajectories from motion capture data with an interpretable interaction graph, demonstrating the virtue of modeling unknown dynamics with continuous weights.",https://openreview.net/pdf/d2a42a569af4609051ef2c5ee6d8844663d49142.pdf,{'title_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=qLKammDlpF,Fusion over the Grassmann Manifold for Incomplete-Data Clustering,"['Jeremy Scott Johnson', 'Huanran Li', 'Chun Gan', 'Zheng Lu', 'Matthew Malloy', 'Daniel L. Pimentel-Alarcón']","['~Jeremy_Scott_Johnson1', '~Huanran_Li1', '~Chun_Gan1', '~Zheng_Lu5', '~Matthew_Malloy1', '~Daniel_L._Pimentel-Alarcón1']","['high-rank matrix completion', 'subspace clustering', 'manifold learning']","This paper presents a new paradigm to cluster incomplete vectors using subspaces as proxies to exploit the geometry of the Grassmannian. We leverage this new perspective to develop an algorithm to cluster and complete data in a union of subspaces via a fusion penalty formulation. Our approach does not require prior knowledge of the number of subspaces, is naturally suited to handle noise, and only requires an upper bound on the subspaces’ dimensions. In developing our model, we present local convergence guarantees. We describe clustering, completion, model selection, and sketching techniques that can be used in practice, and complement our analysis with synthetic and real-data experiments.",https://openreview.net/pdf/fb8cb9c0430aa29664c0a8339ed19eaa2ab5d855.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=qFVVBzXxR2V,Language Models Are Greedy Reasoners: A Systematic Formal Analysis of Chain-of-Thought,"['Abulhair Saparov', 'He He']","['~Abulhair_Saparov1', '~He_He2']","['large language models', 'reasoning', 'question answering', 'chain-of-thought', 'in-context learning']","Large language models (LLMs) have shown remarkable reasoning capabilities given chain-of-thought prompts (examples with intermediate reasoning steps). Existing benchmarks measure reasoning ability indirectly, by evaluating accuracy on downstream tasks such as mathematical reasoning. However, it is unclear how these models obtain the answers and whether they rely on simple heuristics rather than the generated chain-of-thought. To enable systematic exploration of the reasoning ability of LLMs, we present a new synthetic question-answering dataset called PrOntoQA, where each example is generated from a synthetic world model represented in first-order logic. This allows us to parse the generated chain-of-thought into symbolic proofs for formal analysis. Our analysis on InstructGPT and GPT-3 shows that LLMs are quite capable of making correct individual deduction steps, and so are generally capable of reasoning, even in fictional contexts. However, they have difficulty with proof planning: When multiple valid deduction steps are available, they are not able to systematically explore the different options.",https://openreview.net/pdf/e73172f359a19430928855ff049b5dd1e7a4d987.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=q4qocCgE3uM,MARLlib: Extending RLlib for Multi-agent Reinforcement Learning,"['Siyi Hu', 'Yifan Zhong', 'Minquan Gao', 'Weixun Wang', 'Hao Dong', 'Zhihui Li', 'Xiaodan Liang', 'Yaodong Yang', 'Xiaojun Chang']","['~Siyi_Hu1', '~Yifan_Zhong2', '~Minquan_Gao1', '~Weixun_Wang1', '~Hao_Dong3', '~Zhihui_Li1', '~Xiaodan_Liang2', '~Yaodong_Yang1', '~Xiaojun_Chang1']",['MARL'],"Despite the fast development of multi-agent reinforcement learning (MARL) methods, there is a lack of commonly-acknowledged baseline implementation and evaluation platforms. As a result, an urgent need for MARL researchers is to develop an integrated library suite, similar to the role of RLlib in single-agent RL, that delivers reliable MARL implementation and replicable evaluation in various bechmarks. To fill such a research gap, in this paper, we propose Multi-Agent RLlib (MARLlib), a comprehensive MARL algorithm library that facilitates RLlib for solving multi-agent problems. With a novel design of agent-level distributed dataflow, MARLlib manages to unify tens of algorithms, including different types of independent learning, centralized critic, and value decomposition methods; this leads to a highly composable integration of MARL algorithms that are not possible to unify before. Furthermore, MARLlib goes beyond current work by integrating diverse environment interfaces and providing flexible parameter sharing strategies; this allows to create versatile solutions to  cooperative, competitive, and mixed tasks with minimal code modifications for end users. A plethora of experiments  are conducted to substantiate the correctness of our implementation, based on which we further derive new insights on the relationship between the  performance and the design of algorithmic components. With MARLlib, we expect researchers to be able to tackle broader real-world multi-agent problems with trustworthy solutions. Our code\footnote{\url{https://github.com/ICLR2023Paper4242/MARLlib}} and documentation\footnote{\url{https://iclr2023marllib.readthedocs.io/}} are released for reference.",https://openreview.net/pdf/04ba705e659133d6bcc9f84de40160913411a7f5.pdf,{'abstract_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=q3F0UBAruO,Towards Effective and Interpretable Human-Agent Collaboration in MOBA Games: A Communication Perspective,"['Yiming Gao', 'Feiyu Liu', 'Liang Wang', 'Zhenjie Lian', 'Weixuan Wang', 'Siqin Li', 'Xianliang Wang', 'Xianhan Zeng', 'Rundong Wang', 'jiawei wang', 'QIANG FU', 'Yang Wei', 'Lanxiao Huang', 'Wei Liu']","['~Yiming_Gao4', '~Feiyu_Liu1', '~Liang_Wang10', '~Zhenjie_Lian1', '~Weixuan_Wang1', '~Siqin_Li1', '~Xianliang_Wang1', '~Xianhan_Zeng1', '~Rundong_Wang1', '~jiawei_wang2', '~QIANG_FU8', '~Yang_Wei2', '~Lanxiao_Huang1', '~Wei_Liu3']","['game playing', 'multi-agent', 'human-ai communication', 'human-ai collaboration', 'deep reinforcement learning']","MOBA games, e.g., Dota2 and Honor of Kings, have been actively used as the testbed for the recent AI research on games, and various AI systems have been developed at the human level so far. However, these AI systems mainly focus on how to compete with humans, less on exploring how to collaborate with humans. To this end, this paper makes the first attempt to investigate human-agent collaboration in MOBA games. In this paper, we propose to enable humans and agents to collaborate through explicit communication by designing an efficient and interpretable Meta-Command Communication-based framework, dubbed MCC, for accomplishing effective human-agent collaboration in MOBA games. The MCC framework consists of two pivotal modules: 1) an interpretable communication protocol, i.e., the Meta-Command, to bridge the communication gap between humans and agents; 2) a meta-command value estimator, i.e., the Meta-Command Selector, to select a valuable meta-command for each agent to achieve effective human-agent collaboration. Experimental results in Honor of Kings demonstrate that MCC agents can collaborate reasonably well with human teammates and even generalize to collaborate with different levels and numbers of human teammates. Videos are available at https://sites.google.com/view/mcc-demo.",https://openreview.net/pdf/05be94f6c3da0d1f97a06aaecf42515ddc07d159.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=q2vsXnsjNB_,ConserWeightive Behavioral Cloning for Reliable Offline Reinforcement Learning,"['Tung Nguyen', 'Qinqing Zheng', 'Aditya Grover']","['~Tung_Nguyen2', '~Qinqing_Zheng1', '~Aditya_Grover1']","['offline RL', 'behavioral cloning', 'conservatism']","The goal of offline reinforcement learning (RL) is to learn near-optimal policies from static logged datasets, thus sidestepping expensive online interactions. Behavioral cloning (BC) provides a straightforward solution to offline RL by mimicking offline trajectories via supervised learning. Recent advances~\cite{chen2021decision, janner2021offline, emmons2021rvs} have shown that by conditioning on desired future returns, BC can perform competitively to their value-based counterparts, while enjoying much more simplicity and training stability. However, the distribution of returns in the offline dataset can be arbitrarily skewed and suboptimal, which poses a unique challenge for conditioning BC on expert returns at test-time. We propose ConserWeightive Behavioral Cloning (\name), a simple and effective method for improving the performance of conditional BC for offline RL with two key components: trajectory weighting and conservative regularization. Trajectory weighting addresses the bias-variance tradeoff in conditional BC and provides a principled mechanism to learn from both low return trajectories (typically plentiful) and high return trajectories (typically few). Further, we analyze the notion of conservatism in existing BC methods, and propose a novel conservative regularizer that explicitly encourages the policy to stay close to the data distribution. The regularizer helps achieve more reliable performance, and removes the need for ad-hoc tuning of the conditioning value during evaluation. We instantiate \name{} in the context of Reinforcement Learning via Supervised Learning (RvS)~\cite{emmons2021rvs} and Decision Transformer (DT)~\citep{chen2021decision}, and empirically show that it significantly boosts the performance and stability of prior methods on various offline RL benchmarks.",https://openreview.net/pdf/e96627d536d6dc8b87a9863dee93c760d899ad2e.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=q-PbpHD3EOk,Learning Fast and Slow for Online Time Series Forecasting,"['Quang Pham', 'Chenghao Liu', 'Doyen Sahoo', 'Steven Hoi']","['~Quang_Pham1', '~Chenghao_Liu1', '~Doyen_Sahoo1', '~Steven_Hoi2']","['online time series forecasting', 'continual learning']","Despite the recent success of deep learning for time series forecasting, these methods are not scalable for many real-world applications where data arrives sequentially. Training deep neural forecasters on the fly is notoriously challenging because of their limited ability to adapt to non-stationary environments and remember old knowledge. We argue that the fast adaptation capability of deep neural networks is critical and successful solutions require handling changes to both new and recurring patterns effectively. In this work, inspired by the Complementary Learning Systems (CLS) theory, we propose Fast and Slow learning Network (FSNet) as a novel framework to address the challenges of online forecasting. Particularly, FSNet improves the slowly-learned backbone by dynamically balancing fast adaptation to recent changes and retrieving similar old knowledge. FSNet achieves this mechanism via an interaction between two novel complementary components: (i) a per-layer adapter to support fast learning from individual layers, and (ii) an associative memory to support remembering, updating, and recalling repeating events. Extensive experiments on real and synthetic datasets validate FSNet's efficacy and robustness to both new and recurring patterns. Our code is publicly available at: \url{https://github.com/salesforce/fsnet/}.",https://openreview.net/pdf/44160e05022c0f1eeba06011cd69f40c1abe57b3.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=pxStyaf2oJ5,Domain-Indexing Variational Bayes: Interpretable Domain Index for Domain Adaptation,"['Zihao Xu', 'Guang-Yuan Hao', 'Hao He', 'Hao Wang']","['~Zihao_Xu2', '~Guang-Yuan_Hao1', '~Hao_He1', '~Hao_Wang3']",[],"Previous studies have shown that leveraging ""domain index"" can significantly boost domain adaptation performance (Wang et al., 2020; Xu et al., 2022). However, such domain indices are not always available. To address this challenge, we first provide a formal definition of domain index from the probabilistic perspective, and then propose an adversarial variational Bayesian framework that infers domain indices from multi-domain data, thereby providing additional insight on domain relations and improving domain adaptation performance. Our theoretical analysis shows that our adversarial variational Bayesian framework finds the optimal domain index at equilibrium. Empirical results on both synthetic and real data verify that our model can produce interpretable domain indices which enable us to achieve superior performance compared to state-of-the-art domain adaptation methods. Code is available at https://github.com/Wang-ML-Lab/VDI.",https://openreview.net/pdf/4340ecd2eb1d6cddf23d0257a4ab36cd01fba41e.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=pm7O7gJObtk,NIERT: Accurate Numerical Interpolation through Unifying Scattered Data Representations using Transformer Encoder,"['Shizhe Ding', 'Dongbo Bu']","['~Shizhe_Ding2', '~Dongbo_Bu1']","['numerical interpolation', 'transformer encoder', 'mask mechanism', 'pre-training model']","Numerical interpolation for scattered data, i.e., estimating values for target points based on those of some observed points, is widely used in  computational science and engineering. The existing approaches either require explicitly pre-defined basis functions, which makes them inflexible and limits their performance in practical scenarios, or train neural networks as interpolators, which still have limited interpolation accuracy as they treat observed and target points separately and cannot effectively exploit the correlations among data points. Here, we present a learning-based approach to numerical interpolation for scattered data using encoder representation of Transformers (called NIERT). Unlike the recent learning-based approaches, NIERT treats observed and target points in a unified fashion through embedding them into the same representation space, thus gaining the advantage of  effectively exploiting the correlations among them. The specially-designed partial self-attention mechanism used by NIERT makes it escape from the unexpected interference of target points on observed points. We further show that the partial self-attention is essentially a learnable interpolation module combining multiple neural basis functions, which provides interpretability of NIERT. Through pre-training on large-scale synthetic datasets,  NIERT achieves considerable improvement in interpolation accuracy for practical tasks. On both synthetic and real-world datasets, NIERT  outperforms the existing approaches, e.g., on the TFRD-ADlet dataset for temperature field reconstruction, NIERT achieves an MAE of $1.897\times 10^{-3}$, substantially better than the state-of-the-art  approach (MAE: $27.074\times 10^{-3}$).  The source code of NIERT is available at  https://anonymous.4open.science/r/NIERT-2BCF.",https://openreview.net/pdf/a0f6d830ec74e59d52bccf2cb4e3736bdd6ab295.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=pgJp7rDc_hk,Coreset for Rational Functions,"['David Denisov', 'Ibrahim Jubran', 'Dan Feldman']","['~David_Denisov1', '~Ibrahim_Jubran1', '~Dan_Feldman1']","['Coreset', 'Auto-regression', 'rational functions', 'non-convex optimization']","We consider the problem of fitting a rational function $f:\mathbb{R}\to\mathbb{R}$ to a time-series $g:\{1,\cdots,n\}\to\mathbb{R}$. This is by minimizing the sum of distances (loss function) $\ell(f):=\sum_{i=1}^n |f(i)-g(i)|$, possibly with additional constraints and regularization terms that may depend on $f$. Our main motivation is to approximate such a time-series by a recursive sequence model $F_n=\sum_{i=1}^k \theta_i F_{n-i}$, e.g. a Fibonacci sequence, where $\theta\in \mathbb{R}^k$ are the model parameters, and $k\geq1$ is constant.
For $\varepsilon\in(0,1)$, an $\varepsilon$-coreset for this problem is a small data structure that approximates $\ell(g)$ up to $1\pm\varepsilon$ multiplicative factor, for every rational function $g$ of constant degree.
We prove that every signal has an $\varepsilon$-coreset of size $O(n^{0.001}/\varepsilon^2)$, and provide a construction algorithm that computes it in $O(n^{1.001})$ time.
Open source code is provided, as well as extensive experimental results, on both real and synthetic datasets, which compare our method to existing solvers from Scipy.",https://openreview.net/pdf/1f70add33d89167e0abad3640d14807aa9595389.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=pX21pH4CsNB,Differentially Private Diffusion Models,"['Tim Dockhorn', 'Tianshi Cao', 'Arash Vahdat', 'Karsten Kreis']","['~Tim_Dockhorn1', '~Tianshi_Cao1', '~Arash_Vahdat3', '~Karsten_Kreis1']","['Diffusion models', 'Differential Privacy', 'Generative Modeling']","While modern machine learning models rely on increasingly large training datasets, data is often limited in privacy-sensitive domains. Generative models trained with differential privacy (DP) on sensitive data can sidestep this challenge, providing access to synthetic data instead. However, training DP generative models is highly challenging due to the noise injected into training to enforce DP. We propose to leverage diffusion models (DMs), an emerging class of deep generative models, and introduce Differentially Private Diffusion Models (DPDMs), which enforce privacy using differentially private stochastic gradient descent (DP-SGD). We motivate why DP-SGD is well suited for training DPDMs, and thoroughly investigate the DM parameterization and the sampling algorithm, which turn out to be crucial ingredients in DPDMs. Furthermore, we propose noise multiplicity, a simple yet powerful modification of the DM training objective tailored to the DP setting to boost performance. We validate our novel DPDMs on widely-used image generation benchmarks and achieve state-of-the-art (SOTA) performance by large margins. For example, on MNIST we improve the SOTA FID from 48.4 to 5.01 and downstream classification accuracy from 83.2% to 98.1% for the privacy setting DP-$(\varepsilon=10, \delta=10^{-5})$. Moreover, on standard benchmarks, classifiers trained on DPDM-generated synthetic data perform on par with task-specific DP-SGD-trained classifiers, which has not been demonstrated before for DP generative models.",https://openreview.net/pdf/80b3c1437da640596290ef697263339b9b5b129a.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=p4bZLgHUB6L,Learn Low-dimensional Shortest-path Representation of Large-scale and Complex Graphs,"['Haoyu Wang', 'Chun Yuan', 'Lei Li', 'Jiahui Jin']","['~Haoyu_Wang1', '~Chun_Yuan1', '~Lei_Li12', '~Jiahui_Jin1']","['shortest-path distance', 'graph representation learning', 'random walk']","Estimation of shortest-path (SP) distance lies at the heart of network analysis tasks. Along with the rapid emergence of large-scale and complex graphs, approximate SP-representing algorithms that transform a graph into compact and low-dimensional representations are critical for fast and scalable online analysis. Among different approaches, learning-based representation methods have made a breakthrough both in response time and accuracy. Several competitive works in learning-based methods heuristically leverage truncated random walk and optimization on the arbitrary linkage for SP representation learning. However, they have limitations on both exploration range and distance preservation. We propose in this paper an efficient and interpretable SP representation method called Betweenness Centrality-based Distance Resampling (BCDR). First, we prove that betweenness centrality-based random walk can occupy a wider exploration range of distance due to its awareness of high-order path structures. Second, we leverage distance resampling to simulate random shortest paths from original paths and prove that the optimization on such shortest paths preserves distance relations via implicitly decomposing SP distance-based similarity matrix. BCDR yields an average improvement of 25% accuracy and 25-30% query speed, compared to all existing approximate methods when evaluated on a broad class of real-world and synthetic graphs with diverse sizes and structures.",https://openreview.net/pdf/cda4b61f3b2e14b9a6b37a3241b06325fecf5fdd.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=p0MBhpO5wQ,Rethinking the Explanation of Graph Neural Network via Non-parametric Subgraph Matching,"['Fang Wu', 'Lirong Wu', 'Siyuan Li', 'Dragomir Radev', 'Wenbing Huang']","['~Fang_Wu1', '~Lirong_Wu1', '~Siyuan_Li6', '~Dragomir_Radev2', '~Wenbing_Huang1']","['Graph Neural Networks', 'Graph Matching', 'Explanation']","The great success in graph neural networks (GNNs) provokes the question about explainability: ``Which fraction of the input graph is the most determinant to the prediction?'' However, current approaches usually resort to a black-box to decipher another black-box (i.e., GNN), making it difficult to understand how the explanation is made. Based on the observation that graphs typically share some joint motif patterns, we propose a novel subgraph matching framework named MatchExplainer to explore explanatory subgraphs. 
It couples the target graph with other counterpart instances and identifies the most crucial joint substructure by minimizing the node corresponding-based distance between them. After that, an external graph ranking is followed to select the most informative substructure from all subgraph candidates. Thus, MatchExplainer is entirely non-parametric. 
Moreover, present graph sampling or node dropping methods usually suffer from the false positive sampling problem. To ameliorate that issue, we take advantage of MatchExplainer to fix the most informative portion of the graph and merely operate graph augmentations on the rest less informative part, which is dubbed as MatchDrop. 
We conduct extensive experiments on both synthetic and real-world datasets, showing the effectiveness of our MatchExplainer by outperforming all parametric baselines with large margins. Additional results also demonstrate that our MatchDrop is a general paradigm to be equipped with GNNs for enhanced performance.",https://openreview.net/pdf/9d53b55fbc0dadcccdcb198a65f156a5b7d0ca03.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=oo-X0K4XAn,Neural Constraint Inference: Inferring Energy Constraints in Interacting Systems,"['Armand Comas', 'Yilun Du', 'Sandesh Ghimire', 'Christian Fernandez Lopez', 'Mario Sznaier', 'Joshua B. Tenenbaum', 'Octavia Camps']","['~Armand_Comas1', '~Yilun_Du1', '~Sandesh_Ghimire2', '~Christian_Fernandez_Lopez1', '~Mario_Sznaier1', '~Joshua_B._Tenenbaum1', '~Octavia_Camps1']","['relational inference', 'energy-based models', 'energy constraints', 'trajectory prediction', 'graph neural networks']","Systems consisting of interacting agents are prevalent in the world, ranging from dynamical systems in physics to complex biological networks. To build systems which can interact robustly in the real world, it is thus important to be able to infer the precise interactions governing such systems.  Existing approaches typically discover such interactions by explicitly modeling the feedforward dynamics of the trajectories. In this work, we propose Neural Constraint Inference (NCI) model as an alternative approach to discover such interactions: it discovers a set of relational constraints, represented as energy functions, which when optimized reconstruct the original trajectory. We illustrate how NCI can faithfully predict future trajectory dynamics, achieving  more consistent long-rollouts than existing approaches. We show that the constraints discovered by NCI are disentangled and may be intermixed with constraints from other trajectories. Finally, we illustrate how those constraints enable the incorporation of external test-time constraints.",https://openreview.net/pdf/30028c09947aab35f10c7eb0d1e277a9caecb8a7.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=ohQPU2G3r3C,Faster Hyperparameter Search for GNNs via Calibrated Dataset Condensation,"['Mucong Ding', 'Xiaoyu Liu', 'Tahseen Rabbani', 'Teresa Ranadive', 'Tai-Ching Tuan', 'Furong Huang']","['~Mucong_Ding1', '~Xiaoyu_Liu3', '~Tahseen_Rabbani1', 'tranadive@lps.umd.edu', 'tctuan@lps.umd.edu', '~Furong_Huang1']","['Graph Condensation', 'Dataset Condensation', 'Hyperparameter Optimization', 'Graph Neural Networks', 'Graph Compression']","Dataset condensation aims to reduce the computational cost of training multiple models on a large dataset by condensing the training dataset into a small synthetic set. State-of-the-art approaches rely on matching the model gradients for the real and synthetic data and have recently been applied to condense large-scale graphs for node classification tasks. Although dataset condensation may be efficient when training multiple models for hyperparameter optimization, there is no theoretical guarantee on the generalizability of the condensed data: data condensation often generalizes poorly across hyperparameters/architectures in practice, while we find and prove this overfitting is much more severe on graphs. In this paper, we consider a different condensation objective specifically geared towards hyperparameter search. We aim to generate the synthetic dataset so that the validation-performance rankings of the models, with different hyperparameters, on the condensed and original datasets are comparable. We propose a novel hyperparameter-calibrated dataset condensation algorithm, which obtains the synthetic validation data by matching the hyperparameter gradients computed via implicit differentiation and efficient inverse Hessian approximation. HCDC employs a supernet with differentiable hyperparameters, making it suitable for modeling GNNs with widely different convolution filters. Experiments demonstrate that the proposed framework effectively maintains the validation-performance rankings of GNNs and speeds up hyperparameter/architecture search on graphs.",https://openreview.net/pdf/ffb89454a92c83824e2754db20f608d907ce4731.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=oap4aDN9yS2,Bi-Level Dynamic Parameter Sharing among Individuals and Teams for Promoting Collaborations in Multi-Agent Reinforcement Learning,"['Yan Liu', 'Ying Tiffany He', 'Fei Yu', 'Zhong Ming']","['~Yan_Liu17', '~Ying_Tiffany_He1', '~Fei_Yu13', '~Zhong_Ming1']","['Multi-Agent Reinforcement Learning', 'Reinforcement Learning']","Parameter sharing has greatly contributed to the success of multi-agent reinforcement learning in recent years. However, most existing parameter sharing mechanisms are static, and parameters are indiscriminately shared among individuals, ignoring the dynamic environments and different roles of multiple agents. In addition, although a single-level selective parameter sharing mechanism can promote the diversity of strategies, it is hard to establish complementary and cooperative relationships between agents. To address these issues, we propose a bi-level dynamic parameter sharing mechanism among individuals and teams for promoting effective collaborations (BDPS). Specifically, at the individual level, we define virtual dynamic roles based on the long-term cumulative advantages of agents and share parameters among agents in the same role. At the team level, we combine agents of different virtual roles and share parameters of agents in the same group. Through the joint efforts of these two levels, we achieve a dynamic balance between the individuality and commonality of agents, enabling agents to learn more complex and complementary collaborative relationships. We evaluate BDPS on a challenging set of StarCraft II micromanagement tasks. The experimental results show that our method outperforms the current state-of-the-art baselines, and we demonstrate the reliability of our proposed structure through ablation experiments.",https://openreview.net/pdf/a5306aac11abd8d0df98e4099859e8b005f6ef17.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=nhKHA59gXz,Self-Stabilization: The Implicit Bias of Gradient Descent at the Edge of Stability,"['Alex Damian', 'Eshaan Nichani', 'Jason D. Lee']","['~Alex_Damian1', '~Eshaan_Nichani1', '~Jason_D._Lee1']","['gradient descent', 'optimization', 'edge of stability', 'implicit regularization', 'implicit bias']","Traditional analyses of gradient descent show that when the largest eigenvalue of the Hessian, also known as the sharpness $S(\theta)$, is bounded by $2/\eta$, training is ""stable"" and the training loss decreases monotonically. Recent works, however, have observed that this assumption does not hold when training modern neural networks with full batch or large batch gradient descent. Most recently, Cohen at al. (2021) detailed two important phenomena. The first, dubbed \emph{progressive sharpening}, is that the sharpness steadily increases throughout training until it reaches the instability cutoff $2/\eta$. The second, dubbed \emph{edge of stability}, is that the sharpness hovers at $2/\eta$ for the remainder of training while the loss continues decreasing, albeit non-monotonically. We demonstrate that, far from being chaotic, the dynamics of gradient descent at the edge of stability can be captured by a cubic Taylor expansion: as the iterates diverge in direction of the top eigenvector of the Hessian due to instability, the cubic term in the local Taylor expansion of the loss function causes the curvature to decrease until stability is restored. This property, which we call \emph{self-stabilization}, is a general property of gradient descent and explains its behavior at the edge of stability. A key consequence of self-stabilization is that gradient descent at the edge of stability implicitly follows \emph{projected} gradient descent (PGD) under the constraint $S(\theta) \le 2/\eta$. Our analysis provides precise predictions for the loss, sharpness, and deviation from the PGD trajectory throughout training, which we verify both empirically in a number of standard settings and theoretically under mild conditions. Our analysis uncovers the mechanism for gradient descent's implicit bias towards stability.",https://openreview.net/pdf/5ce767b4f951bb7db5b2c04af424d1c59c1e9387.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=nYWqxUwFc3x,Learning Vortex Dynamics for Fluid Inference and Prediction,"['Yitong Deng', 'Hong-Xing Yu', 'Jiajun Wu', 'Bo Zhu']","['~Yitong_Deng1', '~Hong-Xing_Yu1', '~Jiajun_Wu1', '~Bo_Zhu2']",[],"We propose a novel differentiable vortex particle (DVP) method to infer and predict fluid dynamics from a single video. Lying at its core is a particle-based latent space to encapsulate the hidden, Lagrangian vortical evolution underpinning the observable, Eulerian flow phenomena. Our differentiable vortex particles are coupled with a learnable, vortex-to-velocity dynamics mapping to effectively capture the complex flow features in a physically-constrained, low-dimensional space. This representation facilitates the learning of a fluid simulator tailored to the input video that can deliver robust, long-term future predictions. The value of our method is twofold: first, our learned simulator enables the inference of hidden physics quantities (e.g., velocity field) purely from visual observation; secondly, it also supports future prediction, constructing the input video's sequel along with its future dynamics evolution. We compare our method with a range of existing methods on both synthetic and real-world videos, demonstrating improved reconstruction quality, visual plausibility, and physical integrity.",https://openreview.net/pdf/2027a65f6a0320b8b07a33d5d3ff6b1cb6a0580a.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=nUmCcZ5RKF,IS SYNTHETIC DATA FROM GENERATIVE MODELS READY FOR IMAGE RECOGNITION?,"['Ruifei He', 'Shuyang Sun', 'Xin Yu', 'Chuhui Xue', 'Wenqing Zhang', 'Philip Torr', 'Song Bai', 'XIAOJUAN QI']","['~Ruifei_He1', '~Shuyang_Sun1', '~Xin_Yu6', '~Chuhui_Xue2', '~Wenqing_Zhang1', '~Philip_Torr1', '~Song_Bai3', '~XIAOJUAN_QI2']","['data generation', 'image recognition', 'text-to-image synthesis']","Recent text-to-image generation models have shown promising results in generating high-fidelity photo-realistic images. Though the results are astonishing to human eyes, how applicable these generated images are for recognition tasks remains under-explored. In this work, we extensively study whether and how synthetic images generated from state-of-the-art text-to-image generation models can be used for image recognition tasks, and focus on two perspectives: synthetic data for improving classification models in the data-scare settings (i.e. zero-shot and few-shot), and synthetic data for large-scale model pre-training for transfer learning. We showcase the powerfulness and shortcomings of synthetic data from existing generative models, and propose strategies for better applying synthetic data for recognition tasks. Code: https://github.com/CVMI-Lab/SyntheticData. ",https://openreview.net/pdf/530478d6bc03dbd80ae4d0e00c93647edd522adc.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=nIGza1_wxk,Model Transferability with Responsive Decision Subjects ,"['Yang Liu', 'Yatong Chen', 'Zeyu Tang', 'Kun Zhang']","['~Yang_Liu3', '~Yatong_Chen1', '~Zeyu_Tang1', '~Kun_Zhang1']","['transferability', 'responsive decision subjects', 'induced distribution shift', 'human-ML interaction', 'performance bound']","This paper studies model transferability when human decision subjects respond to a deployed machine learning model. In our setting, an agent or a user corresponds to a sample $(X,Y)$ drawn from a distribution $\mathcal{D}$ and will face a model $h$ and its classification result $h(X)$. Agents can modify $X$ to adapt to $h$, which will incur a distribution shift on $(X,Y)$. Therefore, when training $h$, the learner will need to consider the subsequently ``induced"" distribution when the output model is deployed. Our formulation is motivated by applications where the deployed machine learning models interact with human agents, and will ultimately face \emph{responsive} and interactive data distributions. We formalize the discussions of the transferability of a model by studying how the model trained on the available source distribution (data) would translate to the performance on the induced domain. We provide both upper bounds for the performance gap due to the induced domain shift, as well as lower bound for the trade-offs that a classifier has to suffer on either the source training distribution or the induced target distribution. We provide further instantiated analysis for two popular domain adaptation settings with covariate shift and target shift.",https://openreview.net/pdf/9f8fc08ed653c3511babee63e9f40cb240dab2f0.pdf,{'abstract_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=n1bLgxHW6jW,Zeroth-Order Optimization with Trajectory-Informed Derivative Estimation,"['Yao Shu', 'Zhongxiang Dai', 'Weicong Sng', 'Arun Verma', 'Patrick Jaillet', 'Bryan Kian Hsiang Low']","['~Yao_Shu1', '~Zhongxiang_Dai1', '~Weicong_Sng1', '~Arun_Verma1', '~Patrick_Jaillet1', '~Bryan_Kian_Hsiang_Low1']","['zeroth-order optimization', 'derivative estimation', 'finite difference']","Zeroth-order (ZO) optimization, in which the derivative is unavailable, has recently succeeded in many important machine learning applications. Existing algorithms rely on finite difference (FD) methods for derivative estimation and gradient descent (GD)-based approaches for optimization. However, these algorithms suffer from query inefficiency because many additional function queries are required for derivative estimation in their every GD update, which typically hinders their deployment in real-world applications where every function query is expensive. To this end, we propose a trajectory-informed derivative estimation method which only employs the optimization trajectory (i.e., the history of function queries during optimization) and hence can eliminate the need for additional function queries to estimate a derivative. Moreover, based on our derivative estimation, we propose the technique of dynamic virtual updates, which allows us to reliably perform multiple steps of GD updates without reapplying derivative estimation. Based on these two contributions, we introduce the zeroth-order optimization with trajectory-informed derivative estimation (ZoRD) algorithm for query-efficient ZO optimization. We theoretically demonstrate that our trajectory-informed derivative estimation and our ZoRD algorithm improve over existing approaches, which is then supported by our real-world experiments such as black-box adversarial attack, non-differentiable metric optimization, and derivative-free reinforcement learning.",https://openreview.net/pdf/83be469cfb05989fdaa09e9ae079b8dd86eecccc.pdf,{'title_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=moIlFZfj_1b,Latent Neural ODEs with Sparse Bayesian Multiple Shooting,"['Valerii Iakovlev', 'Cagatay Yildiz', 'Markus Heinonen', 'Harri Lähdesmäki']","['~Valerii_Iakovlev1', '~Cagatay_Yildiz1', '~Markus_Heinonen1', '~Harri_Lähdesmäki1']",[],"Training dynamic models, such as neural ODEs, on long trajectories is a hard problem that requires using various tricks, such as trajectory splitting, to make model training work in practice. These methods are often heuristics with poor theoretical justifications, and require iterative manual tuning. We propose a principled multiple shooting technique for neural ODEs that splits the trajectories into manageable short segments, which are optimized in parallel, while ensuring probabilistic control on continuity over consecutive segments. We derive variational inference for our shooting-based latent neural ODE models and propose amortized encodings of irregularly sampled trajectories with a transformer-based recognition network with temporal attention and relative positional encoding. We demonstrate efficient and stable training, and state-of-the-art performance on multiple large-scale benchmark datasets.",https://openreview.net/pdf/071adbc58872effe03fcbbb9ee55c07fab778bd9.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=mfIX4QpsARJ,EAGLE: Large-scale Learning of Turbulent Fluid Dynamics with Mesh Transformers,"['Steeven JANNY', 'Aurélien Bénéteau', 'Madiha Nadri', 'Julie Digne', 'Nicolas THOME', 'Christian Wolf']","['~Steeven_JANNY2', '~Aurélien_Bénéteau1', '~Madiha_Nadri1', '~Julie_Digne1', '~Nicolas_THOME2', '~Christian_Wolf5']","['Learning Fluid Mechanics', 'Simulation', 'Graph networks']","Estimating fluid dynamics is classically done through the simulation and integration of numerical models solving the Navier-Stokes equations, which is computationally complex and time-consuming even on high-end hardware. This is a notoriously hard problem to solve, which has recently been addressed with machine learning, in particular graph neural networks (GNN) and variants trained and evaluated on datasets of static objects in static scenes with fixed geometry. We attempt to go beyond existing work in complexity and introduce a new model, method and benchmark. We propose EAGLE: a large-scale dataset of ∼1.1 million 2D meshes resulting from simulations of unsteady fluid dynamics caused by a moving flow source interacting with nonlinear scene structure of varying geometries, with 600 different scenes of three different types in total. To perform future forecasting of pressure and velocity on the challenging EAGLE dataset, we introduce a new mesh transformer. It leverages node clustering, graph pooling and global attention to learn long-range dependencies between spatially distant data points without needing a large number of iterations, as existing GNN methods do. We show that our transformer outperforms state-of-the-art performance on, both, existing synthetic and real datasets and on EAGLE. Finally, we highlight that our approach learns to attend to airflow, integrating complex information in a single iteration.",https://openreview.net/pdf/09aee140cdc4dcf6fcc6f93e1be103f7e4d37584.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=me09xlTmm8,Transport with Support: Data-Conditional Diffusion Bridges,"['Ella Tamir', 'Martin Trapp', 'Arno Solin']","['~Ella_Tamir1', '~Martin_Trapp2', '~Arno_Solin1']","['diffusion models', 'optimal transport', 'particle filtering', 'stochastic control', 'sequential Monte Carlo']","The dynamic Schrödinger bridge problem provides an appealing setting for posing optimal transport problems as learning non-linear diffusion processes and enables efficient iterative solvers. Recent works have demonstrated state-of-the-art results (eg, in modelling single-cell embryo RNA sequences or sampling from complex posteriors) but are typically limited to learning bridges with only initial and terminal constraints. Our work extends this paradigm by proposing the Iterative Smoothing Bridge (ISB). We combine learning diffusion models with Bayesian filtering and optimal control, allowing for constrained stochastic processes governed by sparse observations at intermediate stages and terminal constraints. We assess the effectiveness of our method on synthetic and real-world data and show that the ISB generalises well to high-dimensional data, is computationally efficient, and provides accurate estimates of the marginals at intermediate and terminal times. ",https://openreview.net/pdf/da8b6fd7f6b624d5851c386395325541be03d90e.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=mduJQSy7KE,Meta-Weighted Language Model Tuning for Augmentation-Enhanced Few-Shot Learning,"['Yu Meng', 'Martin Michalski', 'Jiaxin Huang', 'Yu Zhang', 'Tarek Abdelzaher', 'Jiawei Han']","['~Yu_Meng1', '~Martin_Michalski1', '~Jiaxin_Huang1', '~Yu_Zhang26', '~Tarek_Abdelzaher1', '~Jiawei_Han1']","['Few-Shot Learning', 'Natural Language Understanding']","Recent studies have revealed the intriguing few-shot learning ability of pretrained language models (PLMs): They can quickly adapt to a new task when fine-tuned on a small amount of labeled data formulated as prompts, without requiring abundant task-specific annotations. Despite their promising performance, most existing few-shot approaches that only learn from the small training set still underperform fully supervised training by nontrivial margins. In this work, we study few-shot learning with PLMs from a different perspective: We first tune an autoregressive PLM on the few-shot samples and then use it as a generator to synthesize a large amount of novel training samples which augment the original training set. To encourage the generator to produce label-discriminative samples, we train it via weighted maximum likelihood where the weight of each token is automatically adjusted based on a discriminative meta-learning objective. A classification PLM can then be fine-tuned on both the few-shot and the synthetic samples with regularization for better generalization and stability. Our approach FewGen achieves an overall better result across seven classification tasks of the GLUE benchmark than existing few-shot learning methods.",https://openreview.net/pdf/50d66620b5f01201047a2cf8af74c89a53ba89eb.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=mcJvCys7DX7,Counterfactual Generation Under Confounding,"['Abbavaram Gowtham Reddy', 'Saloni Dash', 'Amit Sharma', 'Vineeth N. Balasubramanian']","['~Abbavaram_Gowtham_Reddy1', 'salonidash77@gmail.com', '~Amit_Sharma3', '~Vineeth_N._Balasubramanian2']","['counterfactual', 'confounding', 'cycleGAN', 'classification']","A machine learning model, under the influence of observed or unobserved confounders in the training data, can learn spurious correlations and fail to generalize when deployed. For image classifiers, augmenting a training dataset using counterfactual examples has been empirically shown to break spurious correlations.  However, the counterfactual generation task itself becomes more difficult as the level of confounding increases. Existing methods for counterfactual generation under confounding consider a fixed set of interventions (e.g., texture, rotation) and are not flexible enough to capture diverse data-generating processes. Given a causal generative process, we formally characterize the adverse effects of confounding on any downstream tasks and show that the correlation between generative factors (attributes) can be used to quantitatively measure confounding between generative factors. To minimize such correlation, we propose a counterfactual generation method that learns to modify the value of any attribute in an image and generate new images given a set of observed attributes, even when the dataset is highly confounded. These counterfactual images are then used to regularize the downstream classifier such that the learned representations are the same across various generative factors conditioned on the class label. Our method is computationally efficient, simple to implement, and works well for any number of generative factors and confounding variables. Our experimental results on both synthetic (MNIST variants) and real-world (CelebA) datasets show the usefulness of our approach.",https://openreview.net/pdf/e7eee5a5d5e72e5ad1a1d0f15e71d12b1b497f42.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=mb7PtrUbHa,Skill Decision Transformer,"['Shyam Sudhakaran', 'Sebastian Risi']","['~Shyam_Sudhakaran1', '~Sebastian_Risi1']","['Transformer', 'Offline Reinforcement Learning']","Recent work has shown that Large Language Models (LLMs) can be incredibly effective for offline reinforcement learning (RL) by representing the traditional RL problem as a sequence modelling problem. However many of these methods only optimize for high returns, and may not extract much information from a diverse dataset of trajectories. Generalized Decision Transformers (GDTs)  have shown that by utilizing future trajectory information, in the form of information statistics, can help extract more information from offline trajectory data. Building upon this, we propose Skill Decision Transformer (Skill DT). Skill DT draws inspiration from hindsight relabelling and skill discovery methods to discover a diverse set of \emph{primitive behaviors}, or skills. We show that Skill DT can not only perform offline state-marginal matching (SMM), but can discovery descriptive behaviors that can be easily sampled. Furthermore, we show that through purely reward-free optimization, Skill DT is still competitive with supervised offline RL approaches on the D4RL benchmark.",https://openreview.net/pdf/4346de4e9114548caf57d3cabb1d218902d9bb95.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=mX56bKDybu5,Neural Radiance Field Codebooks,"['Matthew Wallingford', 'Aditya Kusupati', 'Alex Fang', 'Vivek Ramanujan', 'Aniruddha Kembhavi', 'Roozbeh Mottaghi', 'Ali Farhadi']","['~Matthew_Wallingford1', '~Aditya_Kusupati1', '~Alex_Fang1', '~Vivek_Ramanujan1', '~Aniruddha_Kembhavi1', '~Roozbeh_Mottaghi1', '~Ali_Farhadi3']","['Object-Centric Representation Learning', 'Representation Learning', 'Neural Radiance Fields']","Compositional representations of the world are a promising step towards enabling high-level scene understanding and efficient transfer to downstream tasks. Learning such representations for complex scenes and tasks remains an open challenge. Towards this goal, we introduce Neural Radiance Field Codebooks (NRC), a scalable method for learning object-centric representations through novel view reconstruction. NRC learns to reconstruct scenes from novel views using a dictionary of object codes which are decoded through a volumetric renderer. This enables the discovery of reoccurring visual and geometric patterns across scenes which are transferable to downstream tasks. We show that NRC representations transfer well to object navigation in THOR, outperforming 2D and 3D representation learning methods by 3.1\% success rate. We demonstrate that our approach is able to perform unsupervised segmentation for more complex synthetic (THOR) and real scenes (NYU Depth) better than prior methods (.101 ARI). Finally, we show that NRC improves on the task of depth ordering by 5.5% accuracy in THOR.",https://openreview.net/pdf/b938c8f0acccd59571a25bc4c07a69bf24a26be3.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=mVn2JGzlET,Partial transportability for domain generalization,"['Alexis Bellot', 'Elias Bareinboim']","['~Alexis_Bellot1', '~Elias_Bareinboim2']","['Causality', 'domain generalization']","Learning prediction models that generalize to related domains is one of the most fundamental challenges in artificial intelligence. There exists a growing literature that argues for learning invariant associations using data from multiple source domains. However, whether invariant predictors generalize to a given target domain depends crucially on the assumed structural changes between domains. Using the perspective of transportability theory, we show that invariance learning, and the settings in which invariant predictors are optimal in terms of worst-case losses, is a special case of a more general partial transportability task. Specifically, the partial transportability task seeks to identify / bound a conditional expectation $\mathbb E_{P_{\pi^*}}[y\mid\mathbf x]$ in an unseen domain $\pi^*$ using knowledge of qualitative changes across domains in the form of causal graphs and data from source domains $\pi^1,\dots,\pi^k$. We show that solutions to this problem have a much wider generalization guarantee that subsumes those of invariance learning and other robust optimization methods that are inspired by causality. For computations in practice, we develop an algorithm that provably provides tight bounds asymptotically in the number of data samples from source domains for any partial transportability problem with discrete observables and illustrate its use on synthetic datasets. ",https://openreview.net/pdf/269b72af4fe951aceb0ae0c226bec28f0e2c77d4.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=mBkUeW8rpD6,DiscoBAX - Discovery of optimal intervention sets in genomic experiment design,"['Clare Lyle', 'Arash Mehrjou', 'Pascal Notin', 'Andrew Jesson', 'Stefan Bauer', 'Yarin Gal', 'Patrick Schwab']","['~Clare_Lyle1', '~Arash_Mehrjou1', '~Pascal_Notin1', '~Andrew_Jesson1', '~Stefan_Bauer1', '~Yarin_Gal1', '~Patrick_Schwab1']","['Optimal experiment design', 'Bayesian Algorithm Execution', 'Active learning', 'Genetic intervention', 'Drug design']","The discovery of novel therapeutics to cure genetic pathologies relies on the identification of the different genes involved in the underlying disease mechanism. With billions of potential hypotheses to test, an exhaustive  exploration of the entire space of potential interventions is impossible in practice. Sample-efficient methods based on active learning or bayesian optimization bear the promise of identifying interesting targets using the least experiments possible. However, genomic perturbation experiments typically rely on proxy outcomes measured in biological model systems that may not completely correlate with the outcome of interventions in humans. In practical experiment design, one aims to find a set of interventions which maximally move a target phenotype via a diverse set of mechanisms in order to reduce the risk of failure in future stages of trials. To that end, we introduce DiscoBAX — a sample-efficient algorithm for the discovery of genetic interventions that maximize the movement of a phenotype in a direction of interest while covering a diverse set of underlying mechanisms. We provide theoretical guarantees on the optimality of the approach under standard assumptions, conduct extensive experiments in synthetic and real-world settings relevant to genomic discovery and demonstrate that DiscoBAX outperforms state-of-the-art active learning and Bayesian optimization methods in this task. Better methods for selecting effective and diverse perturbations in biological systems could enable researchers to potentially discover novel therapeutics for a range of genetically-driven diseases.",https://openreview.net/pdf/51adb7bf889afdfb6e66bf261d3a9ad9fc7a6e03.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=lXMlDL78Alx,Causal Attention to Exploit Transient Emergence of Causal Effect,"['Xiaolei Ru', 'Xin-Ya Zhang', 'Jack Murdoch Moore', 'Gang Yan']","['~Xiaolei_Ru1', '~Xin-Ya_Zhang1', '~Jack_Murdoch_Moore1', '~Gang_Yan2']","['causal attention mechanism', 'coupling-drive', 'sparse causal effect', 'neural dynamics', 'causal network reconstruction']","We propose a causal reasoning mechanism called $\textit{causal attention}$ that can improve performance of machine learning models on a class of causal inference tasks by revealing the generation process behind the observed data. We consider the problem of reconstructing causal networks (e.g., biological neural networks) connecting large numbers of variables (e.g., nerve cells), of which evolution is governed by nonlinear dynamics consisting of weak coupling-drive (i.e., causal effect) and strong self-drive (dominants the evolution). The core difficulty is sparseness of causal effect that emerges (the coupling force is significant) only momentarily and otherwise remains dormant in the neural activity sequence. $\textit{Causal attention}$ is designed to guide the model to make inference focusing on the critical regions of time series data where causality may manifest. Specifically, attention coefficients are assigned autonomously by a neural network trained to maximise the Attention-extended Transfer Entropy, which is a novel generalization of the iconic transfer entropy metric. Our results show that, without any prior knowledge of dynamics, $\textit{causal attention}$ explicitly identifies areas where the strength of coupling-drive is distinctly greater than zero. This innovation substantially improves reconstruction performance for both synthetic and real causal networks using data generated by neuronal models widely used in neuroscience.",https://openreview.net/pdf/1b78da17b9da4589e4845f01df383929a8ec92dc.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=lTt4KjHSsyl,Emergence of Maps in the Memories of Blind Navigation Agents,"['Erik Wijmans', 'Manolis Savva', 'Irfan Essa', 'Stefan Lee', 'Ari S. Morcos', 'Dhruv Batra']","['~Erik_Wijmans1', '~Manolis_Savva1', '~Irfan_Essa1', '~Stefan_Lee1', '~Ari_S._Morcos1', '~Dhruv_Batra1']","['embodied AI', 'navigation', 'characterizing representations']","Animal navigation research posits that organisms build and maintain internal spa- tial representations, or maps, of their environment. We ask if machines – specifically, artificial intelligence (AI) navigation agents – also build implicit (or ‘mental’) maps. A positive answer to this question would (a) explain the surprising phenomenon in recent literature of ostensibly map-free neural-networks achieving strong performance, and (b) strengthen the evidence of mapping as a fundamental mechanism for navigation by intelligent embodied agents, whether they be biological or artificial. Unlike animal navigation, we can judiciously design the agent’s perceptual system and control the learning paradigm to nullify alternative navigation mechanisms. Specifically, we train ‘blind’ agents – with sensing limited to only egomotion and no other sensing of any kind – to perform PointGoal navigation (‘go to $\Delta$x, $\Delta$y’) via reinforcement learning. Our agents are composed of navigation-agnostic components (fully-connected and recurrent neural networks), and our experimental setup provides no inductive bias towards mapping. Despite these harsh conditions, we find that blind agents are (1) surprisingly effective navigators in new environments (∼95% success); (2) they utilize memory over long horizons (remembering ∼1,000 steps of past experience in an episode); (3) this memory enables them to exhibit intelligent behavior (following walls, detecting collisions, taking shortcuts); (4) there is emergence of maps and collision detection neurons in the representations of the environment built by a blind agent as it navigates; and (5) the emergent maps are selective and task dependent (e.g. the agent ‘forgets’ exploratory detours). Overall, this paper presents no new techniques for the AI audience, but a surprising finding, an insight, and an explanation.",https://openreview.net/pdf/6aff51942ab3664378283e5da2b36db1cd04db62.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=lGz9u1ubUXE,Relative Behavioral Attributes: Filling the Gap between Symbolic Goal Specification and Reward Learning from Human Preferences,"['Lin Guan', 'Karthik Valmeekam', 'Subbarao Kambhampati']","['~Lin_Guan1', '~Karthik_Valmeekam1', '~Subbarao_Kambhampati1']","['Neuro-Symbolic', 'Human-AI Interaction']","Generating complex behaviors that satisfy the preferences of non-expert users is a crucial requirement for AI agents. Interactive reward learning from trajectory comparisons (a.k.a. RLHF) is one way to allow non-expert users to convey complex objectives by expressing preferences over short clips of agent behaviors. Even though this parametric method can encode complex tacit knowledge present in the underlying tasks, it implicitly assumes that the human is unable to provide richer feedback than binary preference labels, leading to intolerably high feedback complexity and poor user experience. While providing a detailed symbolic closed-form specification of the objectives might be tempting, it is not always feasible even for an expert user. However, in most cases, humans are aware of how the agent should change its behavior along meaningful axes to fulfill their underlying purpose, even if they are not able to fully specify task objectives symbolically. Using this as motivation, we introduce the notion of Relative Behavioral Attributes, which allows the users to tweak the agent behavior through symbolic concepts (e.g., increasing the softness or speed of agents' movement). We propose two practical methods that can learn to model any kind of behavioral attributes from ordered behavior clips. We demonstrate the effectiveness of our methods on four tasks with nine different behavioral attributes, showing that once the attributes are learned, end users can produce desirable agent behaviors relatively effortlessly, by providing feedback just around ten times. This is over an order of magnitude less than that required by the popular learning-from-human-preferences baselines. The supplementary video and source code are available at: https://guansuns.github.io/pages/rba.",https://openreview.net/pdf/8ddd06f0bef80e495ca1650eb74874f576793c38.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=lEkl0jdSb7B,Any-scale Balanced Samplers for Discrete Space,"['Haoran Sun', 'Bo Dai', 'Charles Sutton', 'Dale Schuurmans', 'Hanjun Dai']","['~Haoran_Sun2', '~Bo_Dai1', '~Charles_Sutton1', '~Dale_Schuurmans1', '~Hanjun_Dai1']","['MCMC', 'Discrete Space Sampling', 'Locally Balanced Proposal']","The locally balanced informed proposal has proved to be highly effective for sampling from discrete spaces. However, its success relies on the ""local'' factor, which ensures that whenever the proposal distribution is restricted to be near the current state, the locally balanced weight functions are asymptotically optimal and the gradient approximations are accurate.  In seeking a more efficient sampling algorithm, many recent works have considered increasing the scale of the proposal distributions, but this causes the ""local'' factor to no longer hold. Instead, we propose any-scale balanced samplers to repair the gap in non-local proposals. In particular, we substitute the locally balanced function with an any-scale balanced function that can self-adjust to achieve better efficiency for proposal distributions at any scale. We also use quadratic approximations to capture curvature of the target distribution and reduce the error in the gradient approximation, while employing a Gaussian integral trick with a special estimated diagonal to efficiently sample from the quadratic proposal distribution. On various synthetic and real distributions, the proposed sampler substantially outperforms existing approaches.",https://openreview.net/pdf/52af7225d7de609b61840c7cb0d899b963a2013e.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=kvAQEZZ_BI1,Learning from conflicting data with hidden contexts,"['Tianren Zhang', 'Yizhou Jiang', 'Xin Su', 'Shangqi Guo', 'Chongkai Gao', 'Feng Chen']","['~Tianren_Zhang1', '~Yizhou_Jiang1', '~Xin_Su1', '~Shangqi_Guo2', '~Chongkai_Gao1', '~Feng_Chen1']","['Conflicting data', 'hidden contexts', 'subjective learning', 'multi-domain learning']","Classical supervised learning assumes a stable relation between inputs and outputs. However, this assumption is often invalid in real-world scenarios where the input-output relation in the data depends on some hidden contexts. We formulate a more general setting where the training data is sampled from multiple unobservable domains, while different domains may possess semantically distinct input-output maps. Training data exhibits inherent conflict in this setting, rendering vanilla empirical risk minimization problematic. We propose to tackle this problem by introducing an allocation function that learns to allocate conflicting data to different prediction models, resulting in an algorithm that we term LEAF. We draw an intriguing connection between our approach and a variant of the Expectation-Maximization algorithm. We provide theoretical justifications for LEAF on its identifiability, learnability, and generalization error. Empirical results demonstrate the efficacy and potential applications of LEAF in a range of regression and classification tasks on both synthetic data and real-world datasets.",https://openreview.net/pdf/e89c7abcdab7060e9736517761458c562edd25a2.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=krFbWKl3Sz,Achieving Communication-Efficient Policy Evaluation for Multi-Agent Reinforcement Learning: Local TD-Steps or Batching?,"['FNU Hairi', 'Zifan Zhang', 'Jia Liu']","['~FNU_Hairi1', 'zhang.9256@osu.edu', '~Jia_Liu1']",[],"In many consensus-based actor-critic multi-agent reinforcement learning (MARL) strategies, one of the key components is the MARL policy evaluation (PE) problem, where a set of $N$ agents work cooperatively to evaluate the value function of the global states under a given policy only through communicating with their neighbors.
In MARL-PE, a critical challenge is how to lower the communication complexity, which is defined as the rounds of communication between neighboring nodes in order to converge to some $\epsilon$-stationary point.
To lower communication complexity in MARL-PE, there exist two ``natural'' ideas: i) using batching to reduce the variance of TD (temporal difference) errors, which in turn improves the convergence rate of MARL-PE; and ii) performing multiple local TD update steps between each consecutive rounds of communication, so as to reduce the communication frequency.
While the effectiveness of the batching approach has been verified and relatively well-understood, the validity of the local TD-steps approach remains unclear due to the potential ``agent-drift'' phenomenon resulted from various heterogeneity factors across agents.
This leads to an interesting open question in MARL-PE: *Does the local TD-steps approach really work and how does it perform in comparison to the batching approach?*
In this paper, we take the first attempt to answer this interesting and fundamental question.
Our theoretical analysis and experimental results confirm that allowing multiple local TD steps is indeed a valid approach in lowering the communication complexity of MARL-PE compared to vanilla consensus-based MARL-PE algorithms.
Specifically, the local TD steps between two consecutive communication rounds can be as large as 
$\mathcal{O}(\sqrt{1/\epsilon}\log{(1/\epsilon)})$ in order to converge to an $\epsilon$-stationary point of MARL-PE. 
Theoretically, we show that in order to reach the optimal sample complexity up to a log factor, the communication complexity is $\mathcal{O}(\sqrt{1/\epsilon}\log{(1/\epsilon)})$, which is *considerably worse* than TD learning with batching, whose communication complexity is $\mathcal{O}(\log (1/\epsilon))$. However, the experimental results show that the allowing multiple steps can be as good as the batch approach. ",https://openreview.net/pdf/6c86aac15ef0304fc0b8012a40dbf8eee3c6ada2.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=khF4d1SRrGH,COFS: COntrollable Furniture layout Synthesis,"['Wamiq Reyaz Para', 'Paul Guerrero', 'Niloy Mitra', 'Peter Wonka']","['~Wamiq_Reyaz_Para1', '~Paul_Guerrero1', '~Niloy_Mitra1', '~Peter_Wonka1']","['generative modelling', 'conditional generation', 'layouts', 'transformers']","Realistic, scalable, and controllable generation of furniture layouts is essential for many applications in virtual reality, augmented reality, game development and synthetic data generation. The most successful current methods tackle this problem as a sequence generation problem which imposes a specific ordering on the elements of the layout, making it hard to exert fine-grained control over the attributes of a generated scene. Existing methods provide control through object-level conditioning, or scene completion, where generation can be conditioned on an arbitrary subset of furniture objects. However, attribute-level conditioning, where generation can be conditioned on an arbitrary subset of object attributes, is not supported. We propose COFS, a method to generate furniture layouts that enables fine-grained control through attribute-level conditioning. For example, COFS allows specifying only the scale and type of objects that should be placed in the scene and the generator chooses their positions and orientations; or the position that should be occupied by objects can be specified and the generator chooses their type, scale, orientation, etc. Our results show both qualitatively and quantitatively that we significantly outperform existing methods on attribute-level conditioning.",https://openreview.net/pdf/fc91c5266695fec4a2e41f98930228517f9faa06.pdf,{'title_filter': 'Data Synthesis'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=kcemndN1Tw,Deep Generative Model based Rate-Distortion for Image Downscaling Assessment,"['Yuanbang Liang', 'Bhavesh Garg', 'Paul L Rosin', 'Yipeng Qin']","['~Yuanbang_Liang1', 'bh05avesh@gmail.com', '~Paul_L_Rosin1', '~Yipeng_Qin1']",[],"In this paper, we propose a novel measure, namely Image Downscaling Assessment by Rate-Distortion (IDA-RD), to quantitatively evaluate image downscaling algorithms. In contrast to image-based methods that measure the quality of downscaled images, ours is process-based that draws ideas from the rate-distortion theory to measure the distortion incurred during downscaling. Our main idea is that downscaling and super-resolution (SR) can be viewed as the encoding and decoding processes in the rate-distortion model, respectively, and that a downscaling algorithm that preserves more details in the resulting low-resolution (LR) images should lead to less distorted high-resolution (HR) images in SR. In other words, the distortion should increase as the downscaling algorithm deteriorates. However, it is non-trivial to measure this distortion as it requires the SR algorithm to be blind and stochastic. Our key insight is that such requirements can be met by recent SR algorithms based on deep generative models that can find all matching HR images for a given LR image on their learned image manifolds. Empirically, we first validate our IDA-RD measure with synthetic downscaling algorithms which simulate distortions by adding various types and levels of degradations to the downscaled images. We then test our measure on traditional downscaling algorithms such as bicubic, bilinear, nearest neighbor interpolation as well as state-of-the-art downscaling algorithms such as DPID, L0-regularized downscaling, and Perceptual downscaling. Experimental results show the effectiveness of our IDA-RD in evaluating image downscaling algorithms.",https://openreview.net/pdf/bd1bd4cde5a7030a3caf47dd561d77d09137fb45.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=kL67fyKb6A,Online black-box adaptation to label-shift in the presence of conditional-shift,"['Faruk Ahmed', 'Aaron Courville']","['~Faruk_Ahmed1', '~Aaron_Courville3']","['label-shift', 'online', 'black-box', 'adaptation', 'Bayesian']","We consider an out-of-distribution setting where trained predictive models are deployed online in new locations (inducing conditional-shift), such that these locations are also associated with differently skewed target distributions (label-shift). While approaches for online adaptation to label-shift have recently been discussed by Wu et al. (2021), the potential presence of concurrent conditional-shift has not been considered in the literature, although one might anticipate such distributional shifts in realistic deployments. In this paper, we empirically explore the effectiveness of online adaptation methods in such situations on three synthetic and two realistic datasets, comprising both classification and regression problems. We show that it is possible to improve performance in these settings by learning additional hyper-parameters to account for the presence of conditional-shift by using appropriate validation sets. ",https://openreview.net/pdf/f6144c522d2971b6cfec7b624115016202bb2dd8.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=k-JvYGkA9o,How Normalization and Weight Decay Can Affect SGD? Insights from a Simple Normalized Model,"['Ruosi Wan', 'Qiaosen Wang', 'Xiangyu Zhang', 'Yu-Wing Tai', 'Jian Sun', 'Chi-Keung Tang']","['~Ruosi_Wan4', '~Qiaosen_Wang1', '~Xiangyu_Zhang1', '~Yu-Wing_Tai2', '~Jian_Sun4', '~Chi-Keung_Tang1']","['normalization', 'stochastic gradient descent', 'optimization']","Recent works(Li et al., 2020, Wan et al., 2021) characterize an important mechanism of normalized model trained with SGD and WD (Weight Decay), called Spherical Motion Dynamics (SMD), confirming its widespread effects in practice. However, no theoretical study is available on the influence of SMD on the training process of normalized models in literature. In this work, we seek to understand the effect of SMD by theoretically analyzing a simple normalized model, named as Noisy Rayleigh Quotient (NRQ). On NRQ, We theoretically prove SMD can dominate the whole training process via controlling the evolution of angular update (AU), an essential feature of SMD. Specifically, we show: 1) within equilibrium state of SMD, the convergence rate and limiting risk of NRQ are mainly determined by the theoretical value of AU; and 2) beyond equilibrium state, the evolution of AU can interfere the optimization trajectory, causing odd phenomena such as ``escape'' behavior. We further show the insights drawn from NRQ is consistent with empirical observations in experiments on real datasets. We believe our theoretical results shed new light on the role of normalization techniques during the training of modern deep learning models.",https://openreview.net/pdf/7ab1a96d414b7a98c0e7f7c134209d0ceacf31a3.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=jyHAGzMu-1Q,Learning to Communicate using Contrastive Learning ,"['Yat Long Lo', 'Biswa Sengupta', 'Jakob Nicolaus Foerster', 'Michael Noukhovitch']","['~Yat_Long_Lo1', '~Biswa_Sengupta5', '~Jakob_Nicolaus_Foerster1', '~Michael_Noukhovitch1']","['Reinforcement Learning', 'Multi-Agent Reinforcement Learning', 'Multi-Agent Communication']","Communication is a powerful tool for coordination in multi-agent RL.  Inducing an effective, common language has been a difficult challenge, particularly in the decentralized setting. In this work, we introduce an alternative perspective where communicative messages sent between agents are considered as different incomplete views of the environment state. Based on this perspective, we propose to learn to communicate using contrastive learning by maximizing the mutual information between messages of a given trajectory. In communication-essential environments, our method outperforms previous work in both performance and learning speed. Using qualitative metrics and representation probing, we show that our method induces more symmetric communication and captures task-relevant information from the environment. Finally, we demonstrate promising results on zero-shot communication, a first for MARL. Overall, we show the power of contrastive learning, and self-supervised learning in general, as a method for learning to communicate.",https://openreview.net/pdf/e901a42f1e5f6d94ecc4d7d03e3d6fcda30dfd85.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=jny79Mfgkno,Dealing with missing data using attention and latent space regularization,"['Jahan Che Penny-Dimri', 'Christoph Bergmeir', 'Julian Smith']","['~Jahan_Che_Penny-Dimri1', '~Christoph_Bergmeir1', 'julian.smith@monash.edu']","['missing data', 'missingness', 'latent space regularization', 'measure theory']","Most practical data science problems encounter missing data. A wide variety of solutions exist, each with strengths and weaknesses that depend upon the missingness-generating process. Here we develop a theoretical framework for training and inference using only observed variables enabling modeling of incomplete datasets without imputation. Using an information and measure-theoretic argument we construct models with latent space representations that regularize against the potential bias introduced by missing data. The theoretical properties of this approach are demonstrated empirically using a synthetic dataset. The performance of this approach is tested on 11 benchmarking datasets with missingness and 18 datasets corrupted across three missingness patterns with comparison against a state-of-the-art model and industry-standard imputation. We show that our proposed method outperforms common imputation methods and the current state-of-the-art with statistical significance.
",https://openreview.net/pdf/e7ab604c4a951e5e1412f357c07d4f1e98851318.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=jgmuRzM-sb6,DAG Matters! GFlowNets Enhanced Explainer for Graph Neural Networks,"['Wenqian Li', 'Yinchuan Li', 'Zhigang Li', 'Jianye HAO', 'Yan Pang']","['~Wenqian_Li1', '~Yinchuan_Li1', '~Zhigang_Li7', '~Jianye_HAO1', '~Yan_Pang1']","['GNN', 'Interpretability']","Uncovering rationales behind predictions of graph neural networks (GNNs) has received increasing attention over the years. Existing literature mainly focus on selecting a subgraph, through combinatorial optimization, to provide faithful explanations. However, the exponential size of candidate subgraphs limits the applicability of state-of-the-art methods to large-scale GNNs. We enhance on this through a different approach: by proposing a generative structure – GFlowNets-based GNN Explainer (GFlowExplainer), we turn the optimization problem into a step-by-step generative problem. Our GFlowExplainer aims to learn a policy that generates a distribution of subgraphs for which the probability of a subgraph is proportional to its’ reward. The proposed approach eliminates the influence of node sequence and thus does not need any pre-training strategies. We also propose a new cut vertex matrix to efficiently explore parent states for GFlowNets structure, thus making our approach applicable in a large-scale setting. We conduct extensive experiments on both synthetic and real datasets, and both qualitative and quantitative results show the superiority of our GFlowExplainer.",https://openreview.net/pdf/8a760853df1498c71ec2c328ac4842a2fcba52ee.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=jdEXFqGjdh,CI-VAE: a Class-Informed Deep Variational Autoencoder for Enhanced Class-Specific Data Interpolation,"['Mohsen Nabian', 'Zahra Eftekhari', 'Alec Wong']","['~Mohsen_Nabian1', 'zeftekhari@coh.org', 'alecwong@coh.org']","['Variational Auto Encoder', 'Supervised', 'Latent Space Traversal', 'Data Interpolation', 'Discriminator']","We proposed Class-Informed Variational Autoencoder (CI-VAE) to enable interpolation between arbitrary pairs of observations of the same class. CI-VAE combines the general VAE architecture with a linear discriminator layer on the latent space to enforce the construction of a latent space such that observations from different classes are linearly separable. In conventional VAEs, class overlapping on the latent space usually occurs. However, in CI-VAE, the enforced linear separability of classes on the latent space allows for robust latent-space linear traversal and data generation between two arbitrary observations of the same class. Class-specific data interpolation has extensive potential applications in science, particularly in biology, such as uncovering the biological trajectory of diseases or cancer. We used the MNIST dataset of handwritten digits as a case study to compare the performance of CI-VAE and VAE in class-specific data augmentation. We showed that CI-VAE significantly improved class-specific linear traversal and data augmentation compared with VAE while maintaining comparable reconstruction error. In a study of Colon cancer genomics data, we showed that the interpolation between normal cells and tumor cells using CI-VAE may enhance our understanding of cancer development. ",https://openreview.net/pdf/624f471b9f14ecb2d4fa00ab4342ef9a3d520854.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=jK02XX9ZpJkt,CAMA: A New Framework for Safe Multi-Agent Reinforcement Learning  Using Constraint Augmentation,"['Ziyan Wang', 'Yali Du', 'Aivar Sootla', 'Haitham Bou Ammar', 'Jun Wang']","['~Ziyan_Wang3', '~Yali_Du1', '~Aivar_Sootla1', '~Haitham_Bou_Ammar1', '~Jun_Wang2']","['Safe', 'Multi-agent Reinforcement Learning', 'Augmentation']","With the widespread application of multi-agent reinforcement learning (MARL) in real-life settings, the ability to meet safety constraints has become an urgent problem to solve. For example, it is necessary to avoid collisions to reach a common goal in controlling multiple drones. We address this problem by introducing the Constraint Augmented Multi-Agent framework --- CAMA. CAMA can serve as a plug-and-play module to the popular MARL algorithms, including centralized training, decentralized execution and independent learning frameworks. In our approach, we represent the safety constraint as the sum of discounted safety costs bounded by the predefined value, which we call the safety budget. Experiments demonstrate that CAMA can converge quickly to a high degree of constraint satisfaction and surpasses other state-of-the-art safety counterpart algorithms in both cooperative and competitive settings. ",https://openreview.net/pdf/8b89e7d633833aae6b6595c02ad7370b9c920784.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=jHc8dCx6DDr,Memory Gym: Partially Observable Challenges to Memory-Based Agents,"['Marco Pleines', 'Matthias Pallasch', 'Frank Zimmer', 'Mike Preuss']","['~Marco_Pleines1', 'matthias.pallasch@udo.edu', 'frank.zimmer@hochschule-rhein-waal.de', '~Mike_Preuss1']","['Deep Reinforcement Learning', 'Memory', 'Benchmark', 'Proximal Policy Optimization', 'Gated Recurrent Unit', 'HELM']","Memory Gym is a novel benchmark for challenging Deep Reinforcement Learning agents to memorize events across long sequences, be robust to noise, and generalize. It consists of the partially observable 2D and discrete control environments Mortar Mayhem, Mystery Path, and Searing Spotlights. These environments are believed to be unsolvable by memory-less agents because they feature strong dependencies on memory and frequent agent-memory interactions. Empirical results based on Proximal Policy Optimization (PPO) and Gated Recurrent Unit (GRU) underline the strong memory dependency of the contributed environments. The hardness of these environments can be smoothly scaled, while different levels of difficulty (some of them unsolved yet) emerge for Mortar Mayhem and Mystery Path. Surprisingly, Searing Spotlights poses a tremendous challenge to GRU-PPO, which remains an open puzzle. Even though the
randomly moving spotlights reveal parts of the environment’s ground truth, environmental ablations hint that these pose a severe perturbation to agents that leverage recurrent model architectures as their memory. 
Source Code: https://github.com/MarcoMeter/drl-memory-gym/",https://openreview.net/pdf/311f37d9f91d2b654e7ef5b66aab43a60b5f0e8b.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=jHA-yCyBGb,DIFFUSION GENERATIVE MODELS ON SO(3),"['Yesukhei Jagvaral', 'Francois Lanusse', 'Rachel Mandelbaum']","['~Yesukhei_Jagvaral1', '~Francois_Lanusse2', '~Rachel_Mandelbaum1']","['Deep Generative Models', 'Manifold Learning', 'SO(3)', 'Denoising Diffusion', 'Score-based models']","Diffusion-based generative models represent the current state-of-the-art for image generation. However, standard diffusion models are based on Euclidean geometry and do not translate directly to manifold-valued data. In this work, we develop extensions of both score-based generative models (SGMs) and Denoising Diffusion Probabilistic Models (DDPMs) to the Lie group of 3D rotations, SO(3). SO(3) is of particular interest in many disciplines such as robotics, biochemistry and astronomy/planetary science. Contrary to more general Riemannian manifolds, SO(3) admits a tractable solution to heat diffusion, and allows us to implement efficient training of Diffusion models. We apply both SO(3) DDPMs and SGMs to synthetic densities on SO(3) and demonstrate state-of-the-art results.",https://openreview.net/pdf/f1c2d0eb57fd34923011bf3c763b6e8cca56abfa.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=jClGv3Qjhb,"A Theoretical Understanding of Shallow Vision Transformers: Learning, Generalization, and Sample Complexity","['Hongkang Li', 'Meng Wang', 'Sijia Liu', 'Pin-Yu Chen']","['~Hongkang_Li1', '~Meng_Wang4', '~Sijia_Liu1', '~Pin-Yu_Chen1']","['Vision transformer', 'Learning', 'Generalization', 'Sample comeplxity', 'Token sparsification', 'Theory']","Vision Transformers (ViTs) with self-attention modules have recently achieved great empirical success in many vision tasks. Due to non-convex interactions across layers, however, the theoretical learning and generalization analysis is mostly elusive. Based on a data model characterizing both label-relevant and label-irrelevant tokens, this paper provides the first theoretical analysis of training a three-layer ViT, i.e., one self-attention layer followed by a two-layer perceptron, for a classification task. We characterize the sample complexity to achieve a zero generalization error. Our sample complexity bound is positively correlated with the inverse of the fraction of label-relevant tokens, the token noise level, and the initial model error. We also prove that a training process using stochastic gradient descent (SGD) leads to a sparse attention map, which is a formal verification of the general intuition about the success of attention. Moreover,  this paper indicates that a proper token sparsification can improve the test performance by removing label-irrelevant and/or noisy tokens, including spurious correlations. Empirical experiments on synthetic data and CIFAR-10 dataset justify our theoretical results and generalize to deeper ViTs. ",https://openreview.net/pdf/31d1481db9db8d93532ef30aa9a64f3a33b188b1.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=jCdoLxMZxf,Copula Conformal Prediction for Multi-step Time Series Forecasting,"['Sophia Huiwen Sun', 'Rose Yu']","['~Sophia_Huiwen_Sun1', '~Rose_Yu1']","['Conformal Prediction', 'time series', 'uncertainty quantification', 'calibration', 'RNN']","Accurate uncertainty measurement is a key step to building robust and reliable machine learning systems. Conformal prediction is a distribution-free uncertainty quantification algorithm popular for its ease of implementation, statistical coverage guarantees, and versatility for underlying forecasters. However, existing conformal prediction algorithms for time series are limited to single-step prediction without considering the temporal dependency. In this paper we propose a Copula-based Conformal Prediction algorithm for multivariate, multi-step Time Series forecasting, CopulaCPTS. On several synthetic and real-world multivariate time series datasets, we show that CopulaCPTS produces more calibrated and sharp confidence intervals for multi-step prediction tasks than existing techniques.",https://openreview.net/pdf/a357c2785026e23479c5fab30ac3cfbe3b3cd378.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=ipflrGaf7ry,Can Agents Run Relay Race with Strangers? Generalization of RL to Out-of-Distribution Trajectories,"['Li-Cheng Lan', 'Huan Zhang', 'Cho-Jui Hsieh']","['~Li-Cheng_Lan1', '~Huan_Zhang1', '~Cho-Jui_Hsieh1']","['Genralization', 'Reinforcement Learning']","In this paper, we evaluate and improve the generalization performance for reinforcement learning (RL) agents on the set of ``controllable'' states, where good policies exist on these states to achieve the goal. An RL agent that generally masters a task should reach its goal starting from any controllable state of the environment instead of memorizing a small set of trajectories. To practically evaluate this type of generalization, we propose relay evaluation, which starts the test agent from the middle of other independently well-trained stranger agents' trajectories. With extensive experimental evaluation, we show the prevalence of generalization failure on controllable states from stranger agents. For example, in the Humanoid environment, we observed that a well-trained Proximal Policy Optimization (PPO) agent, with only 3.9\% failure rate during regular testing, failed on 81.6\% of the states generated by well-trained stranger PPO agents. To improve ""relay generalization,"" we propose a novel method called Self-Trajectory Augmentation (STA), which will reset the environment to the agent's old states according to the Q function during training. After applying STA to the Soft Actor Critic's (SAC) training procedure, we reduced the failure rate of SAC under relay-evaluation by more than three times in most settings without impacting agent performance and increasing the needed number of environment interactions. Our code is available at https://github.com/lan-lc/STA.",https://openreview.net/pdf/80245884d3c21d7b21166281784b35962b9f3e1f.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=ig4E0Y11pX,Theoretical  Characterization of Neural Network Generalization with Group Imbalance,"['Hongkang Li', 'Shuai Zhang', 'Meng Wang', 'Yihua Zhang', 'Pin-Yu Chen', 'Sijia Liu']","['~Hongkang_Li1', '~Shuai_Zhang6', '~Meng_Wang4', '~Yihua_Zhang1', '~Pin-Yu_Chen1', '~Sijia_Liu1']","['Group imbalance', 'Sample complexity', 'Generelization analysis', 'Gaussian mixture model', 'Empirical risk minimization']","Group imbalance has been a known problem in empirical risk minimization (ERM), where the achieved high \textit{average} accuracy could be accompanied by low accuracy in a \textit{minority} group. Despite various algorithmic efforts to improve the minority group accuracy, a theoretical study of the generalization performance of ERM on individual groups remains elusive. By formulating the group imbalance problem with the Gaussian Mixture Model, this paper quantifies the impact of individual groups on the sample complexity, the convergence rate, and the average and group-level testing performance. Although our theoretical framework is centered on binary classification using a one-hidden-layer neural network, to the best of our knowledge, we provide the first theoretical analysis of the group-level generalization of ERM in addition to the commonly studied average generalization performance. Sample insights of our theoretical results include that when all group-level co-variance is in the medium regime and all mean are close to zero,  the learning performance is most desirable in the sense of a small sample complexity, a fast training rate, and a high average and group-level testing accuracy. Moreover, we show that increasing the fraction of the minority group in the training data does not necessarily improve the generalization performance of the minority group.  Our theoretical results are validated on both synthetic and empirical datasets such as CelebA and CIFAR-10 in image classification.",https://openreview.net/pdf/916bd547510f5d8e329f209f7ed060d4d92b45ee.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=icmTV7mhxuQ,Entity Divider with Language Grounding in Multi-Agent Reinforcement Learning,"['Ziluo Ding', 'Wanpeng Zhang', 'Junpeng Yue', 'Xiangjun Wang', 'Tiejun Huang', 'Zongqing Lu']","['~Ziluo_Ding1', '~Wanpeng_Zhang1', '~Junpeng_Yue1', '~Xiangjun_Wang1', '~Tiejun_Huang1', '~Zongqing_Lu2']","['language-based reinforcement learning', 'multi-agent reinforcement learning']","We investigate the use of natural language to drive the generalization of policies in multi-agent settings. Unlike single-agent settings, the generalization of policies should also consider the influence of other agents. Besides, with the increasing number of entities in multi-agent settings, more agent-entity interactions are needed for language grounding, and the enormous search space could impede the learning process. Moreover, given a simple general instruction, e.g., beating all enemies, agents are required to decompose it into multiple subgoals and figure out the right one to focus on. Inspired by previous work, we try to address these issues at the entity level and propose a novel framework for language grounding in multi-agent reinforcement learning, entity divider (EnDi). EnDi enables agents to independently learn subgoal division at the entity level and act in the environment based on the associated entities. The subgoal division is regularized by opponent modeling to avoid subgoal conflicts and promote coordinated strategies. Empirically, EnDi demonstrates the strong generalization ability to unseen games with new dynamics and expresses the superiority over existing methods. ",https://openreview.net/pdf/9aa7ecfdc42fe3363be61a38c480260d8c08f4e0.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=iaYcJKpY2B_,CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis,"['Erik Nijkamp', 'Bo Pang', 'Hiroaki Hayashi', 'Lifu Tu', 'Huan Wang', 'Yingbo Zhou', 'Silvio Savarese', 'Caiming Xiong']","['~Erik_Nijkamp2', '~Bo_Pang4', '~Hiroaki_Hayashi1', '~Lifu_Tu1', '~Huan_Wang1', '~Yingbo_Zhou1', '~Silvio_Savarese1', '~Caiming_Xiong1']","['Program synthesis', 'multi-turn generation', 'code generation', 'large language models', 'generative models']","Program synthesis strives to generate a computer program as a solution to a given problem specification, expressed with input-output examples or natural language descriptions. The prevalence of large language models advances the state-of-the-art for program synthesis, though limited training resources and data impede open access to such models. To democratize this, we train and release a family of large language models up to 16.1B parameters, called CODEGEN, on natural language and programming language data, and open source the training library JAXFORMER. We show the utility of the trained model by demonstrating that it is competitive with the previous state-of-the-art on zero-shot Python code generation on HumanEval. We further investigate the multi-step paradigm for program synthesis, where a single program is factorized into multiple prompts specifying subproblems. To this end, we construct an open benchmark, Multi-Turn Programming Benchmark (MTPB), consisting of 115 diverse problem sets that are factorized into multi-turn prompts. Our analysis on MTPB shows that the same intent provided to CODEGEN in multi-turn fashion significantly improves program synthesis over that provided as a single turn. We make the training library JAXFORMER and model checkpoints available as open source contribution: https://github.com/salesforce/CodeGen.",https://openreview.net/pdf/003bbce081e6ee9edeead69fcdba6fbe3882de42.pdf,{'title_filter': 'Data Synthesis'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=i_1rbq8yFWC,Rhino: Deep Causal Temporal Relationship Learning with History-dependent Noise,"['Wenbo Gong', 'Joel Jennings', 'Cheng Zhang', 'Nick Pawlowski']","['~Wenbo_Gong1', 'joeljennings@microsoft.com', '~Cheng_Zhang1', '~Nick_Pawlowski2']","['Structure learning', 'Causal discovery', 'Time series', 'Structure equation model', 'deep generative model']","Discovering causal relationships between different variables from time series data has been a long-standing challenge for many domains. For example, in stock markets, the announcement of acquisitions from leading companies may have immediate effects on stock prices and increase the uncertainty of the future market due to this past action. To discover causal relations in such case, the model needs to consider non-linear relations between variables, instantaneous effect and the change of noise distribution due to past actions. We name the latter as history-dependent noise. However, previous works do not offer a solution addressing all these problems together. In this paper, we propose a structural equation model, called Rhino, which combines vector auto-regression, deep learning and variational inference to model non-linear relationships with instantaneous effects while allowing the noise distribution to be modulated by history observations. Theoretically, we prove the structural identifiability of Rhino. Our empirical results from extensive synthetic experiments and two real-world benchmarks demonstrate better discovery performance compared to relevant baselines, with ablation studies revealing its robustness under model misspecification.",https://openreview.net/pdf/fbac1494936fa6cf98eb5c4fb5a71e68dee7d101.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=iYvbPx8GTta,SeedGNN: Graph Neural Network for Supervised Seeded Graph Matching,"['Liren Yu', 'Jiaming Xu', 'Xiaojun Lin']","['~Liren_Yu1', '~Jiaming_Xu4', '~Xiaojun_Lin1']","['seeded graph matching', 'Graph Neural Network (GNN)', 'percolation', 'multi-hop witnesses']","There have been significant interests in designing Graph Neural Networks (GNNs) for seeded graph matching, which aims to match two (unlabeled) graphs using only topological information and a small set of seeds. However, most previous GNNs for seeded graph matching employ a semi-supervised approach, which requires a large number of seeds and can not learn knowledge transferable to unseen graphs. In contrast, this paper proposes a new supervised approach that can learn from a training set how to match unseen graphs with only a few seeds. At the core of our SeedGNN architecture are two novel modules: 1) a convolution module that can easily learn the capability of counting and using witnesses of different hops; 2) a percolation module that can use easily-matched pairs as new seeds to percolate and match other nodes. We evaluate SeedGNN on both synthetic and real graphs, and demonstrate significant performance improvement over both non-learning and learning algorithms in the existing literature. Further, our experiments confirm that the knowledge learned by SeedGNN from training graphs can be generalized to test graphs with different sizes and categories. ",https://openreview.net/pdf/84b1b802a22de7a01efc3bf0304a21ed09271265.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=iI8zWfCyCIQ,Graph Backup: Data Efficient Backup Exploiting Markovian Transitions,"['zhengyao jiang', 'Tianjun Zhang', 'Robert Kirk', 'Tim Rocktäschel', 'Edward Grefenstette']","['~zhengyao_jiang2', '~Tianjun_Zhang1', '~Robert_Kirk1', '~Tim_Rocktäschel1', '~Edward_Grefenstette1']","['reinforcement learning', 'graph structure', 'neuro-symbolic methods', 'data efficient reinforcement learning']","The successes of deep Reinforcement Learning (RL) are limited to settings where we have a large stream of online experiences, but applying RL in the data-efficient setting with limited access to online interactions is still challenging. A key to data-efficient RL is good value estimation, but current methods in this space fail to fully utilise the structure of the trajectory data gathered from the environment. In this paper, we treat the transition data of the MDP as a graph, and define a novel backup operator, Graph Backup, which exploits this graph structure for better value estimation. Compared to multi-step backup methods such as $n$-step $Q$-Learning and TD($\lambda$), Graph Backup can perform counterfactual credit assignment and gives stable value estimates for a state regardless of which trajectory the state is sampled from. Our method, when combined with popular off-policy value-based methods, provides improved performance over one-step and multi-step methods on a suite of data-efficient RL benchmarks including MiniGrid, Minatar and Atari100K. We further analyse the reasons for this performance boost through a novel visualisation of the transition graphs of Atari games.",https://openreview.net/pdf/ddcfee6e9d1aa340c21f833a02b68179af160b7a.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=iF0B-U0J5fG,Teach me how to Interpolate a Myriad of Embeddings,"['Shashanka Venkataramanan', 'Ewa Kijak', 'laurent amsaleg', 'Yannis Avrithis']","['~Shashanka_Venkataramanan2', '~Ewa_Kijak1', '~laurent_amsaleg1', '~Yannis_Avrithis2']",[],"Mixup refers to interpolation-based data augmentation, originally motivated as a way to go beyond empirical risk minimization (ERM). Yet, its extensions focus on the definition of interpolation and the space where it takes place, while the augmentation itself is less studied: For a mini-batch of size $m$, most methods interpolate between $m$ pairs with a single scalar interpolation factor $\lambda$.

In this work, we make progress in this direction by introducing MultiMix, which interpolates an arbitrary number $n$ of tuples, each of length $m$, with one vector $\lambda$ per tuple. On sequence data, we further extend to dense interpolation and loss computation over all spatial positions. Overall, we increase the number of tuples per mini-batch by orders of magnitude at little additional cost. This is possible by interpolating at the very last layer before the classifier. Finally, to address inconsistencies due to linear target interpolation, we introduce a self-distillation approach to generate and interpolate synthetic targets.

We empirically show that our contributions result in significant improvement over state-of-the-art mixup methods on four benchmarks. By analyzing the embedding space, we observe that the classes are more tightly clustered and uniformly spread over the embedding space, thereby explaining the improved behavior.",https://openreview.net/pdf/bfaeb93f7410c4bb27a84e52f66fa239d797365c.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=iAPs7yMjjyQ,Evaluating Counterfactual Explainers,"['Diego Velazquez', 'Pau Rodriguez', 'Alexandre Lacoste', 'Issam H. Laradji', 'Xavier Roca', 'Jordi Gonzàlez']","['~Diego_Velazquez1', '~Pau_Rodriguez2', '~Alexandre_Lacoste1', '~Issam_H._Laradji1', 'xavier.roca@uab.cat', '~Jordi_Gonzàlez3']","['Explainability', 'Counterfactuals', 'XAI']","Explainability methods have been widely used to provide insight into the decisions made by statistical models, thus facilitating their adoption in various domains within the industry. Counterfactual explanation methods aim to improve our understanding of a model by perturbing samples in a way that would alter its response in an unexpected manner. This information is helpful for users and for machine learning practitioners to understand and improve their models. Given the value provided by counterfactual explanations, there is a growing interest in the research community to investigate and propose new methods. However, we identify two issues that could hinder the progress in this field. (1) Existing metrics do not accurately reflect the value of an explainability method for the users. (2) Comparisons between methods are usually performed with datasets like CelebA, where images are annotated with attributes that do not fully describe them and with subjective attributes such as ``Attractive''. In this work, we address these problems by proposing an evaluation method with a principled metric to evaluate and compare different counterfactual explanation methods. The evaluation method is based on a synthetic dataset where images are fully described by their annotated attributes. As a result, we are able to perform a fair comparison of multiple explainability methods in the recent literature, obtaining insights about their performance. We make the code public for the benefit of the research community.",https://openreview.net/pdf/c8f0e18f77fe43fa9c5165846d4b0af760612bf4.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=i8AnfJYMvz,Beyond Reward: Offline Preference-guided Policy Optimization,"['Yachen Kang', 'Diyuan Shi', 'Jinxin Liu', 'Li He', 'Donglin Wang']","['~Yachen_Kang1', '~Diyuan_Shi1', '~Jinxin_Liu1', '~Li_He3', '~Donglin_Wang1']","['offline reinforcement learning', 'preference-based reinforcement learning', 'hindsight information matching', 'preference-guided policy optimization']","In this work, we study offline preference-based reinforcement learning (PbRL), which relaxes the two fundamental supervisory signals in standard reinforcement learning (online accessible transition dynamics and rewards). In other words, the agent is provided with fixed offline trajectory transitions and human preferences between pairs of trajectories. Due to the orthogonality property of rewards and dynamics, one common practice is combining prior PbRL-based reward learning objectives with off-the-shelf offline RL algorithms to bridge preference modeling and offline learning. However, such two isolated optimizations require learning a separate reward function and thus place an information bottleneck on reward learning (the bridge). As an alternative, we propose offline preference-guided policy optimization (OPPO), an end-to-end offline PbRL formulation, which jointly learns to model the preference (for finding the optimal task policy) and the offline data (for eliminating OOD). In particular, OPPO introduces an offline hindsight information matching objective and a preference modeling objective. Then, iterating the two objectives over, we can directly extract a well-performing decision policy, avoiding a separate reward learning. We empirically show that OPPO can effectively model the offline preference and outperform prior competing baselines (including the offline RL algorithms performed over the true reward function).",https://openreview.net/pdf/08ca314c182c5472b446bcfed456750a6514c5eb.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=hxUwnEGxW87,Statistical Theory of Differentially Private Marginal-based Data Synthesis Algorithms,"['Ximing Li', 'Chendi Wang', 'Guang Cheng']","['~Ximing_Li2', '~Chendi_Wang2', '~Guang_Cheng1']","['Synthetic data', 'differential privacy', 'marginal-based method', 'Bayesian network', 'learning theory']"," Marginal-based methods achieve promising performance in the synthetic data competition hosted by the National Institute of Standards and Technology (NIST).
 To deal with high-dimensional data, the distribution of synthetic data is represented by a probabilistic graphical model (e.g., a Bayesian network), while the raw data distribution is approximated by a collection of low-dimensional marginals.
 Differential privacy (DP) is guaranteed by introducing random noise to each low-dimensional marginal distribution.
 Despite its promising performance in practice, the statistical properties of marginal-based methods are rarely studied in the literature.
 In this paper, we study DP data synthesis algorithms based on Bayesian networks (BN) from a statistical perspective. We establish a rigorous accuracy guarantee for BN-based algorithms, where the errors are measured by the total variation (TV) distance or the $L^2$ distance. 
 Related to downstream machine learning tasks, an upper bound for the utility error of the DP synthetic data is also derived. To complete the picture, we establish a lower bound for TV accuracy that holds for every $\epsilon$-DP synthetic data generator.",https://openreview.net/pdf/3058893e9f851ac461611b0b24f93d716651a067.pdf,{'title_filter': 'Data Synthesis'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=hp_RwhKDJ5,Learning to Induce Causal Structure ,"['Nan Rosemary Ke', 'Silvia Chiappa', 'Jane X Wang', 'Jorg Bornschein', 'Anirudh Goyal', 'Melanie Rey', 'Theophane Weber', 'Matthew Botvinick', 'Michael Curtis Mozer', 'Danilo Jimenez Rezende']","['~Nan_Rosemary_Ke1', '~Silvia_Chiappa1', '~Jane_X_Wang1', '~Jorg_Bornschein1', '~Anirudh_Goyal1', '~Melanie_Rey1', '~Theophane_Weber1', '~Matthew_Botvinick1', '~Michael_Curtis_Mozer1', '~Danilo_Jimenez_Rezende2']","['causality', 'deep learning']","The fundamental challenge in causal induction is to infer the underlying graph structure given observational and/or interventional data. Most existing causal induction algorithms operate by generating candidate graphs and evaluating them using either score-based methods (including continuous optimization) or independence tests. In our work, we instead treat the inference process as a black box and design a neural network architecture that learns the mapping from both observational and interventional data to graph structures via supervised training on synthetic graphs. The learned model generalizes to new synthetic graphs, is robust to train-test distribution shifts, and achieves state-of-the-art performance on naturalistic graphs for low sample complexity.",https://openreview.net/pdf/643ee1c6aa6829fd0ace9b8add8fa3bf34b9861f.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=hhvkdRdWt1F,Dual Algorithmic Reasoning,"['Danilo Numeroso', 'Davide Bacciu', 'Petar Veličković']","['~Danilo_Numeroso1', '~Davide_Bacciu1', '~Petar_Veličković1']","['Algorithmic Reasoning', 'Deep Learning for Graphs']","Neural Algorithmic Reasoning is an emerging area of machine learning which seeks to infuse algorithmic computation in neural networks, typically by training neural models to approximate steps of classical algorithms. In this context, much of the current work has focused on learning reachability and shortest path graph algorithms, showing that joint learning on similar algorithms is beneficial for generalisation. However, when targeting more complex problems, such ""similar"" algorithms become more difficult to find. Here, we propose to learn algorithms by exploiting duality of the underlying algorithmic problem. Many algorithms solve optimisation problems. We demonstrate that simultaneously learning the dual definition of these optimisation problems in algorithmic learning allows for better learning and qualitatively better solutions. Specifically, we exploit the max-flow min-cut theorem to simultaneously learn these two algorithms over synthetically generated graphs, demonstrating the effectiveness of the proposed approach. We then validate the real-world utility of our dual algorithmic reasoner by deploying it on a challenging brain vessel classification task, which likely depends on the vessels’ flow properties. We demonstrate a clear performance gain when using our model within such a context, and empirically show that learning the max-flow and min-cut algorithms together is critical for achieving such a result.",https://openreview.net/pdf/68736260b81982cea120df8994f055abbfe1ec5c.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=hfaNXjEQB47,Dissecting adaptive methods in GANs,"['Samy Jelassi', 'David Dobre', 'Arthur Mensch', 'Yuanzhi Li', 'Gauthier Gidel']","['~Samy_Jelassi1', '~David_Dobre1', '~Arthur_Mensch1', '~Yuanzhi_Li1', '~Gauthier_Gidel1']","['deep learning theory', 'generative adversarial networks', 'adaptive methods']","Adaptive methods are a crucial component widely used for training generative adversarial networks (GANs). While there has been some work to pinpoint the “marginal value of adaptive methods” in standard tasks, it remains unclear why they are still critical for GAN training. In this paper, we formally study how adaptive methods help train GANs; inspired by the grafting method proposed in (Agarwal et al. 2021), we separate the magnitude and direction components of the Adam updates, and graft them to the direction and magnitude of SGDA updates respectively. By considering an update rule with the magnitude of the Adam update and the normalized direction of SGD, we empirically show that the adaptive magnitude of Adam is key for GAN training. This motivates us to have a closer look at the class of normalized stochastic gradient descent ascent (nSGDA) methods in the context of GAN training. We propose a synthetic theoretical framework to compare the performance of nSGDA and SGDA for GAN training with neural networks. We prove that in that setting, GANs trained with nSGDA recover all the modes of the true distribution, whereas the same networks trained with SGDA (and any learning rate configuration) suffer from mode collapse. The critical insight in our analysis is that normalizing the gradients forces the discriminator and generator to be updated at the same pace. We also experimentally show that for several datasets, Adam's performance can be recovered with nSGDA methods.",https://openreview.net/pdf/0967253aa888b77695501305aff4af8a65f886f4.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=hFUlfiyf1oQ,Rethinking Uniformity in Self-Supervised Representation Learning,"['Xianghong Fang', 'Jian Li', 'Xiangchu Feng', 'Benyou Wang']","['~Xianghong_Fang1', '~Jian_Li17', '~Xiangchu_Feng1', '~Benyou_Wang2']","['Collapse Analysis', 'Wasserstein Distance', 'Self-Supervised Representation Learning']","Self-supervised representation learning has achieved great success in many machine learning tasks. While many research efforts focus on learning better representations by preventing the model from the \emph{collapse} problem, less attention has been drawn to analyzing the collapse degrees of representations. In this paper, we present a formal study of collapse analysis via the \emph{uniformity} metric, which measures how uniformly learned representations distribute on the surface of the unit hypersphere. We fundamentally find that \textit{representation that obeys zero-mean isotropic Gaussian distribution is with the ideal uniformity} since its $l_2$-normalized form uniformly distributes on the surface of the unit hypersphere. Therefore, we propose to use the Wasserstein distance between the distribution of learned representations and the ideal distribution as a quantifiable metric of \emph{uniformity}. Moreover, we design five desirable constraints for ideal uniformity metrics, based on which we find that the proposed uniformity metric satisfies all constraints while the existing one does not. Synthetic experiments also demonstrate the proposed uniformity metric is capable to deal with the dimensional collapse while the existing one is insensitive. Furthermore, we impose the proposed \emph{uniformity} metric as an auxiliary loss term for various existing self-supervised methods, which consistently improves the downstream performance. ",https://openreview.net/pdf/6f6c5196ecf1b5bb0559799cdaaff7e163ae3320.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=hF1WEiIYPNb,Query The Agent: Improving Sample Efficiency Through Epistemic Uncertainty Estimation,"['Julian Alverio', 'Boris Katz', 'Andrei Barbu']","['~Julian_Alverio1', '~Boris_Katz1', '~Andrei_Barbu3']","['goal-conditioned reinforcement learning', 'reinforcement learning', 'goal-conditioned', 'goal', 'model-free', 'sample efficiency', 'deep reinforcement learning']","Curricula for goal-conditioned reinforcement learning agents typically rely on poor estimates of the agent's epistemic uncertainty or fail to consider the agents' epistemic uncertainty altogether, resulting in poor sample efficiency. We propose a novel algorithm, Query The Agent (QTA), which significantly improves sample efficiency by estimating the agent's epistemic uncertainty throughout the state space and setting goals in highly uncertain areas. Encouraging the agent to collect data in highly uncertain states allows the agent to improve its estimation of the value function rapidly. QTA utilizes a novel technique for estimating epistemic uncertainty, Predictive Uncertainty Networks (PUN), to allow QTA to assess the agent's uncertainty in all previously observed states. We demonstrate that QTA offers decisive sample efficiency improvements over preexisting methods.",https://openreview.net/pdf/bc691e68c2328c093a66a9df67d7f41932321395.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=h5z_RaWLdG1,How Does Adaptive Optimization Impact Local Neural Network Geometry?,"['Kaiqi Jiang', 'Dhruv Malik', 'Yuanzhi Li']","['~Kaiqi_Jiang2', '~Dhruv_Malik1', '~Yuanzhi_Li1']","['optimization', 'adaptive algorithms', 'neural networks']","Adaptive optimization methods are well known to achieve superior convergence relative to vanilla gradient methods. The traditional viewpoint in optimization, particularly in convex optimization, explains this improved performance by arguing that, unlike vanilla gradient schemes, adaptive algorithms mimic the behavior of a second-order method by adapting to the global geometry of the loss function. We argue that in the context of neural network optimization, this traditional viewpoint is insufficient. Instead, we advocate for a local trajectory analysis. For iterate trajectories produced by running a generic optimization algorithm OPT, we introduce $R^{\text{OPT}}_{\text{med}}$, a statistic that is analogous to the condition number of the loss Hessian evaluated at the iterates. Through extensive experiments, we show that adaptive methods such as Adam bias the trajectories towards regions where $R^{\text{Adam}}_{\text{med}}$ is small, where one might expect faster convergence. By contrast, vanilla gradient methods like SGD bias the trajectories towards regions where $R^{\text{SGD}}_{\text{med}}$ is comparatively large. We complement these empirical observations with a theoretical result that provably demonstrates this phenomenon in the simplified setting of a two-layer linear network. We view our findings as evidence for the need of a new explanation of the success of adaptive methods, one that is different than the conventional wisdom.",https://openreview.net/pdf/d0db70ed12b5ea04b5fa438347082a94d7c797b7.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=h5OpjGd_lo6,Self-Guided Noise-Free Data Generation for Efficient Zero-Shot Learning,"['Jiahui Gao', 'Renjie Pi', 'LIN Yong', 'Hang Xu', 'Jiacheng Ye', 'Zhiyong Wu', 'WEIZHONG ZHANG', 'Xiaodan Liang', 'Zhenguo Li', 'Lingpeng Kong']","['~Jiahui_Gao2', '~Renjie_Pi1', '~LIN_Yong1', '~Hang_Xu1', '~Jiacheng_Ye2', '~Zhiyong_Wu3', '~WEIZHONG_ZHANG2', '~Xiaodan_Liang2', '~Zhenguo_Li1', '~Lingpeng_Kong1']","['Pre-Trained Language Model', 'Prompt-Based Learning', 'Efficient Zero-Shot Learning']","There is a rising interest in further exploring the zero-shot learning potential of large pre-trained language models (PLMs). A new paradigm called data-generation-based zero-shot learning has achieved impressive success. In this paradigm, the synthesized data from the PLM acts as the carrier of knowledge, which is used to train a task-specific model with orders of magnitude fewer parameters than the PLM, achieving both higher performance and efficiency than prompt-based zero-shot learning methods on PLMs. The main hurdle of this approach is that the synthesized data from PLM usually contains a significant portion of low-quality samples. Fitting on such data will greatly hamper the performance of the task-specific model, making it unreliable for deployment. Previous methods remedy this issue mainly by filtering synthetic data using heuristic metrics(e.g., output confidence), or refining the data with the help of a human expert, which comes with excessive manual tuning or expensive costs. In this paper, we propose a novel noise-robust re-weighting framework SunGen to automatically construct high-quality data for zero-shot classification problems. Our framework features the ability to learn the sample weights indicating data quality without requiring any human annotation. We theoretically and empirically verify the ability of our method to help construct good-quality synthetic datasets. Notably, SunGen-LSTM yields a 9.8% relative improvement than the baseline on average accuracy across eight different established text classification tasks.",https://openreview.net/pdf/82812310fbf1dff5ce1f72fe99e2d46523ca8d5a.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=h3vfP9ASoXEK,Recovering Top-Two Answers and Confusion Probability in Multi-Choice Crowdsourcing,"['Hyeonsu Jeong', 'Hye Won Chung']","['~Hyeonsu_Jeong1', '~Hye_Won_Chung2']","['Crowdsourcing', 'multiple choice', 'detecting confusion', 'task difficulty', 'two-stage inference algorithm', 'minimax optimal convergence rate']","We consider multi-choice crowdsourced labeling with the goal of recovering not only the ground truth but also the most confusing answer and the confusion probability. The most confusing answer provides useful information about the task by revealing the most plausible answer other than the ground truth and how plausible it is. To theoretically analyze such scenarios, we propose a model where there are top-two plausible answers for each task, distinguished from the rest of choices. Task difficulty is quantified by the confusion probability between the top two, and worker reliability is quantified by the probability of giving an answer among the top two. Under this model, we propose a two-stage inference algorithm to infer the top-two answers, where the first stage uses the spectral method to obtain an initial estimate for the top two, and the second stage uses the result of the first stage to refine the estimates based on the maximum likelihood estimator (MLE). We show that our algorithm achieves the minimax optimal convergence rate. We conduct both synthetic and real-data experiments and demonstrate that our algorithm achieves the performance near the optimal MLE for synthetic datasets and the best performance for real datasets compared to other recent algorithms. This shows that our model explains well the real datasets with heterogeneous task difficulties due to confusion between plausible answers. 
",https://openreview.net/pdf/833b7e5cc8f70abc63cf95cd1670323b855b4fce.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=h21yJhdzbwz,Towards One-shot Neural Combinatorial Solvers: Theoretical and Empirical Notes on the Cardinality-Constrained Case,"['Runzhong Wang', 'Li Shen', 'Yiting Chen', 'Xiaokang Yang', 'Dacheng Tao', 'Junchi Yan']","['~Runzhong_Wang1', '~Li_Shen1', '~Yiting_Chen1', '~Xiaokang_Yang1', '~Dacheng_Tao1', '~Junchi_Yan2']","['deep learning', 'combinatorial optimization', 'facility location problem', 'max coverage problem', 'portfolio optimization']","One-shot non-autoregressive neural networks, different from RL-based ones, have been actively adopted for solving combinatorial optimization (CO) problems, which can be trained by the objective score in a self-supervised manner. Such methods have shown their superiority in efficiency (e.g. by parallelization) and potential for tackling predictive CO problems for decision-making under uncertainty. While the discrete constraints often become a bottleneck for gradient-based neural solvers, as currently handled in three typical ways: 1) adding a soft penalty in the objective, where a bounded violation of the constraints cannot be guaranteed, being critical to many constraint-sensitive scenarios; 2) perturbing the input to generate an approximate gradient in a black-box manner, though the constraints are exactly obeyed while the approximate gradients can hurt the performance on the objective score; 3) a compromise by developing soft algorithms whereby the output of neural networks obeys a relaxed constraint, and there can still occur an arbitrary degree of constraint-violation. Towards the ultimate goal of establishing a general framework for neural CO solver with the ability to control an arbitrary-small degree of constraint violation, in this paper, we focus on a more achievable and common setting: the cardinality constraints, which in fact can be readily encoded by a differentiable optimal transport (OT) layer. Based on this observation, we propose OT-based cardinality constraint encoding for end-to-end CO problem learning with two variants: Sinkhorn and Gumbel-Sinkhorn, whereby their violation of the constraints can be exactly characterized and bounded by our theoretical results. On synthetic and real-world CO problem instances, our methods surpass the state-of-the-art CO network and are comparable to (if not superior to) the commercial solver Gurobi. In particular, we further showcase a case study of applying our approach to the predictive portfolio optimization task on real-world asset price data, improving the Sharpe ratio from 1.1 to 2.0 of a strong LSTM+Gurobi baseline under the classic predict-then-optimize paradigm.",https://openreview.net/pdf/47ff06773ffd6757c65cd362fde9c7bfd3176168.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=gvMAooaEi3,Revisiting Higher-Order Gradient Methods for Multi-Agent Reinforcement Learning,"['Ariyan Bighashdel', 'Daan De Geus', 'Pavol Jancura', 'Gijs Dubbelman']","['~Ariyan_Bighashdel1', '~Daan_De_Geus1', '~Pavol_Jancura1', '~Gijs_Dubbelman1']","['Multi-agent reinforcement learning', 'Higher-order gradient-based optimization']","This paper revisits Higher-Order Gradient (HOG) methods for Multi-Agent Reinforcement Learning (MARL). HOG methods are algorithms in which agents use higher-order gradient information to account for other agents' anticipated learning, and are shown to improve coordination in games with self-interested agents. So far, however, HOG methods are only applied to games with low-dimensional state spaces due to inefficient computation and preservation of higher-order gradient information. In this work, we solve these limitations and propose a HOG framework that can be applied to games with higher-dimensional state spaces. Moreover, we show that current HOG methods, when applied to games with common-interested agents, i.e., team games, can lead to miscoordination between the agents. To solve this, we propose Hierarchical Reasoning (HR) to improve coordination in team games, and we experimentally show that our proposed HR significantly outperforms state-of-the-art methods in standard multi-agent games. With our contributions, we greatly improve the applicability of HOG methods for MARL. For reproducibility, the code used for our work will be shared after the reviewing process.",https://openreview.net/pdf/f643b474fdd5fd715a0190110804c1a9d1281f0d.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=gmufyyjyjnN,Semi-supervised consistency regularization for accurate cell type fraction and gene expression estimation,"['Robin Khatri', 'Pierre Machart', 'Stefan Bonn']","['~Robin_Khatri1', '~Pierre_Machart1', '~Stefan_Bonn1']","['Cell deconvolution', 'consistency regularization']","Cell deconvolution is the estimation of cell type fractions and cell type-specific gene expression from mixed data with unknown composition. In biomedical research, cell deconvolution, which is a source separation task, is used to obtain mechanistic and diagnostic insights into human diseases. An unmet challenge in cell deconvolution, however, is the scarcity of realistic training data and the strong domain shift observed in synthetic training data that is used in contemporary methods. Here, we hypothesize that simultaneous consistency regularization of the target and training domains will improve deconvolution performance. By adding this biologically motivated consistency loss to two novel deep learning-based deconvolution algorithms, we achieve state-of-the-art performance on both cell fraction and gene expression estimation. Our method, DISSECT, outperforms competing algorithms across several biomedical gene expression datasets and can be easily adapted to deconvolve other biomedical data types, as exemplified by our spatial expression deconvolution experiments.",https://openreview.net/pdf/370db8f62798093a50ef3191900279fc242ac6f5.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=gmL46YMpu2J,Promptagator: Few-shot Dense Retrieval From 8 Examples,"['Zhuyun Dai', 'Vincent Y Zhao', 'Ji Ma', 'Yi Luan', 'Jianmo Ni', 'Jing Lu', 'Anton Bakalov', 'Kelvin Guu', 'Keith Hall', 'Ming-Wei Chang']","['~Zhuyun_Dai1', '~Vincent_Y_Zhao1', '~Ji_Ma3', '~Yi_Luan1', '~Jianmo_Ni2', '~Jing_Lu4', 'abakalov@google.com', '~Kelvin_Guu1', '~Keith_Hall2', '~Ming-Wei_Chang3']","['large language model', 'few-shot prompting', 'information retrieval']","Much recent research on information retrieval has focused on how to transfer from one task (typically with abundant supervised data) to various other retrieval tasks where supervision is limited, with the implicit assumption that it is possible to generalize from one task to all the rest. However, this overlooks the fact that there are many diverse and unique retrieval problems, each targeting different search intents, queries, and search domains. In this paper, we suggest to work on Few-shot Dense Retrieval, a setting where each task comes with a short description and a few examples. To address this, we introduce Prompt-based Query Generation forRetrieval (Promptagator): for each task, we feed the few-shot examples to a large language model (LLM) and prompt it to behave as a task-specific query generator. Using this, we can synthetically generate a large number of relevant queries for any document, yielding abundant data for training task-specific retrievers --- with no reliance on traditional resources such as Natural Questions (Kwiatkowskiet al., 2019) or MS MARCO (Nguyen et al., 2016). Surprisingly, Promptagator with only 8 annotated examples enables efficient dual encoder retrievers to outperform computationally more expensive models trained on MS MARCO such as ColBERT v2 (Santhanam et al., 2022) by more than 1.2 points nDCG@10 on average on 11 retrieval sets. Further training standard-size re-rankers using the same generated data yields another 5.0 points nDCG@10 improvement. Our studies show that synthetic query generation can be far more effective than previously observed, especially when a small amount of task-specific knowledge is given.",https://openreview.net/pdf/79a0f9b78ef87a8465c2f60eac8f96b996c84b38.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=gfHLOC35Zh,Modality Complementariness: Towards Understanding Multi-modal Robustness,"['Siting Li', 'Chenzhuang Du', 'Yu Huang', 'Longbo Huang', 'Hang Zhao']","['~Siting_Li1', '~Chenzhuang_Du1', '~Yu_Huang3', '~Longbo_Huang2', '~Hang_Zhao1']",['multimodal robustness theory'],"Along with the success of multi-modal learning, the robustness of multi-modal learning is receiving attention due to real-world safety concerns. Multi-modal models are anticipated to be more robust due to the possible redundancy between modalities. However, some empirical results have offered contradictory conclusions. In this paper, we point out an essential factor that causes this discrepancy: The difference in the amount of modality-wise complementary information. We provide an information-theoretical analysis of how the modality complementariness affects the multi-modal robustness. Based on the analysis, we design a metric for quantifying how complementary the modalities are to others and propose an effective pipeline to calculate our metric. Experiments on carefully-designed synthetic data verify our theory. Further, we apply our metric to real-world multi-modal datasets and reveal their property. To our best knowledge, we are the first to identify modality complementariness as an important factor affecting multi-modal robustness.",https://openreview.net/pdf/0384c775320ecca7718d0862f61eefd5cb6de26a.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=gVSJ83n47IT,Imposing conservation properties in deep dynamics modeling via contrastive learning,"['Wang Zhang', 'Subhro Das', 'Tsui-Wei Weng', 'Alexandre Megretski', 'Luca Daniel', 'Lam M. Nguyen']","['~Wang_Zhang2', '~Subhro_Das1', '~Tsui-Wei_Weng1', '~Alexandre_Megretski1', '~Luca_Daniel1', '~Lam_M._Nguyen1']","['dynamical system modeling', 'contrastive learning', 'learning conservation property']","Deep neural networks (DNN) has shown great capacity of modeling a dynamical system, but these DNN-based dynamical models usually do not obey conservation laws. To impose the learned DNN dynamical models with key physical properties such as conservation laws, this paper proposes a two-step approach to endow the invariant priors into the simulations. We first establish a contrastive learning framework to capture the system invariants along the trajectory observations. During the dynamics modeling, we design a projection layer of DNNs to preserve the system invariance. Through experiments, we show our method consistently outperforms the baseline in both coordinate error and conservation metrics and can be further extended to complex and large dynamics by leveraging autoencoder. Notably, a byproduct of our framework is the automated conservation law discovery for dynamical systems with single conservation property. ",https://openreview.net/pdf/803eab6ff008ea0fe1d46dcbe8960ae8ad77319d.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=gULfK60oYr1,Never Revisit: Continuous Exploration in Multi-Agent Reinforcement Learning,"['Chenghao Li', 'Tonghan Wang', 'Xiaoran Wu', 'Jun Yang', 'Qianchuan Zhao', 'Chongjie Zhang']","['~Chenghao_Li1', '~Tonghan_Wang1', '~Xiaoran_Wu1', '~Jun_Yang6', '~Qianchuan_Zhao1', '~Chongjie_Zhang1']",[],"Recently, intrinsic motivations are wildly used for exploration in multi-agent reinforcement learning. We discover that coming with intrinsic rewards is the issue of revisitation -- the relative values of intrinsic rewards fluctuate, causing a sub-space visited before becomes attractive after a period of exploration to other areas. Consequently, agents risk exploring some sub-spaces repeatedly. In this paper, we formally define the concept of revisitation, based on which we propose an observation-distribution matching approach to detect the appearance of revisitation. To avoid it, we add branches to agents' local Q-networks and the mixing network to separate sub-spaces which have already been revisited. Furthermore, to prevent adding branches excessively, we design intrinsic rewards to reduce the probability of and penalize the occurrence of revisitation. By virtue of these advances, our method achieves superior performance on three challenging Google Research Football (GRF) scenarios with sparse rewards. ",https://openreview.net/pdf/9890e1758fb80f530d2e5f85da06beca6c1d1de8.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=gOZ_pKANaPW,Unsupervised Model Selection for Time Series Anomaly Detection,"['Mononito Goswami', 'Cristian Ignacio Challu', 'Laurent Callot', 'Lenon Minorics', 'Andrey Kan']","['~Mononito_Goswami1', '~Cristian_Ignacio_Challu1', '~Laurent_Callot1', '~Lenon_Minorics1', '~Andrey_Kan1']","['Time Series', 'Anomaly Detection', 'Model Selection', 'Unsupervised Learning', 'Rank Aggregation']","Anomaly detection in time-series has a wide range of practical applications. While numerous anomaly detection methods have been proposed in the literature, a recent survey concluded that no single method is the most accurate across various datasets. To make matters worse, anomaly labels are scarce and rarely available in practice. The practical problem of selecting the most accurate model for a given dataset without labels has received little attention in the literature. This paper answers this question \textit{i.e.} Given an unlabeled dataset and a set of candidate anomaly detectors, how can we select the most accurate model? To this end, we identify three classes of surrogate (unsupervised) metrics, namely, \textit{prediction error}, \textit{model centrality}, and \textit{performance on injected synthetic anomalies}, and show that some metrics are highly correlated with standard supervised anomaly detection performance metrics such as the $F_1$ score, but to varying degrees. We formulate metric combination with multiple imperfect surrogate metrics as a robust rank aggregation problem. We then provide theoretical justification behind the proposed approach. Large-scale experiments on multiple real-world datasets demonstrate that our proposed unsupervised approach is as effective as selecting the most accurate model based on partially labeled data.",https://openreview.net/pdf/b9338f8e0cd4d78c188aa60e26ced6737232b2a8.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=gLl0fZQo6Vu,Agent-Controller Representations: Principled Offline RL with Rich Exogenous Information,"['Riashat Islam', 'Manan Tomar', 'Alex Lamb', 'Hongyu Zang', 'Yonathan Efroni', 'Dipendra Misra', 'Xin Li', 'Harm van Seijen', 'Remi Tachet des Combes', 'John Langford']","['~Riashat_Islam1', '~Manan_Tomar1', '~Alex_Lamb1', '~Hongyu_Zang1', '~Yonathan_Efroni2', '~Dipendra_Misra1', '~Xin_Li31', '~Harm_van_Seijen1', '~Remi_Tachet_des_Combes1', '~John_Langford1']","['offline RL', 'exogenous information', 'representation learning', 'latent state recovery', 'robustness']","Learning to control an agent from data collected offline in a rich pixel-based visual observation space is vital for real-world applications of reinforcement learning (RL). A major challenge in this setting is the presence of input information that is hard to model and irrelevant to controlling the agent. This problem has been approached by the theoretical RL community through the lens of exogenous information, i.e, any control-irrelevant information contained in observations. For example, a robot navigating in busy streets needs to ignore irrelevant information, such as other people walking in the background, textures of objects, or birds in the sky. In this paper, we focus on the setting with visually detailed exogenous information, and introduce new offline RL benchmarks offering the ability to study this problem. We find that contemporary representation learning techniques can fail on datasets where the noise is a complex and time dependent process, which is prevalent in practical applications. To address these, we propose to use multi-step inverse models, which have seen a great deal of interest in the RL theory community, to learn Agent-Controller Representations for Offline-RL (ACRO). Despite being simple and requiring no reward, we show theoretically and empirically that the representation created by this objective greatly outperforms baselines.  ",https://openreview.net/pdf/ade16b484acbf893d68b474e358135e8d62075bc.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=gL68u5UuWa,Maximum Likelihood Learning of Energy-Based Models for Simulation-Based Inference,"['Pierre Glaser', 'Michael Arbel', 'Arnaud Doucet', 'Arthur Gretton']","['~Pierre_Glaser1', '~Michael_Arbel1', '~Arnaud_Doucet2', '~Arthur_Gretton1']","['Simulation Based Inference', 'Energy Based Models', 'Maximum Likelihood']","We introduce two Synthetic Likelihood methods for Simulation-Based Inference (SBI), to conduct either amortized or targeted inference from experimental observations when a high-fidelity simulator is available. Both methods learn a Conditional Energy-Based Model (EBM) of the likelihood using synthetic data generated by the simulator, conditioned on parameters drawn from a proposal distribution. The learned likelihood can then be combined with any prior to obtain a posterior estimate, from which samples can be drawn using MCMC. 
Our methods uniquely combine a flexible Energy-Based Model and the minimization of a KL loss: this is in contrast to other synthetic likelihood methods, which either rely on normalizing flows, or minimize score-based objectives; choices that come with known pitfalls. Our first method, Amortized Unnormalized Neural Likelihood Estimation (AUNLE), introduces a tilting trick during training that allows to perform inference using efficient MCMC techniques. Our second method, Sequential UNLE (SUNLE), employs a doubly intractable approach in order to re-use simulation data and improve posterior accuracy for a specific observation. 
We demonstrate the properties of both methods on a range of synthetic datasets, and apply it to a neuroscience model of the pyloric network in the crab, matching the performance of other synthetic likelihood methods at a fraction of the simulation budget.",https://openreview.net/pdf/6971b4f3894d344b153122e3bbefca375a68ea31.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=fxkACnJZmy_,Monotonicity and Double Descent in Uncertainty Estimation with Gaussian Processes,"['Liam Hodgkinson', 'Chris van der Heide', 'Fred Roosta', 'Michael W. Mahoney']","['~Liam_Hodgkinson1', '~Chris_van_der_Heide1', '~Fred_Roosta1', '~Michael_W._Mahoney1']","['double descent', 'Gaussian processes', 'Bayesian statistics']","The quality of many modern machine learning models improves as model complexity increases, an effect that has been quantified—for predictive performance—with the non-monotonic double descent learning curve. Here, we address the overarching question: is there an analogous theory of double descent for models which estimate uncertainty? We provide a partially affirmative and partially negative answer in the setting of Gaussian processes (GP). Under standard assumptions, we prove that higher model quality for optimally-tuned GPs (including uncertainty prediction) under marginal likelihood is realized for larger input dimensions, and therefore exhibits a monotone learning curve. After showing that marginal likelihood does not naturally exhibit double descent in the input dimension, we highlight related forms of posterior predictive loss that do. Finally, we verify empirically that our results hold for real data, beyond our considered assumptions, and explore unusual consequences involving synthetic covariates.",https://openreview.net/pdf/54418a897b8bb492061140d4dee332ff00966ccb.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=fwP9Bc4E71,Learning to Take a Break: Sustainable Optimization of Long-Term User Engagement,"['Eden Saig', 'Nir Rosenfeld']","['~Eden_Saig1', '~Nir_Rosenfeld2']","['Lotka-Volterra dynamics', 'breaking policies', 'digital well-being', 'feed-based recommendation']","Optimizing user engagement is a key goal for modern recommendation systems, but blindly pushing users towards increased consumption risks burn-out, churn, or even addictive habits. To promote digital well-being, most platforms now offer a service that periodically prompts users to take a break. These, however, must be set up manually, and so may be suboptimal for both users and the system.
In this paper, we propose a framework for optimizing long-term engagement by learning individualized breaking policies. Using Lotka-Volterra dynamics, we model users as acting based on two balancing latent states: drive, and interest---which must be conserved. We then give an efficient learning algorithm, provide theoretical guarantees, and empirically evaluate its performance on semi-synthetic data.",https://openreview.net/pdf/5129aa55cfb729f7a9771384175ef0ddeec72c5b.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=fvvcpsEl3Z6,Taming the Long Tail of Deep Probabilistic Forecasting,"['Mayank Sharan', 'Jedrzej Kozerawski', 'Rose Yu']","['~Mayank_Sharan1', '~Jedrzej_Kozerawski1', '~Rose_Yu1']","['Deep probabilistic forecasting', 'Long tail error', 'Time Series forecasting', 'Trajectory forecasting']","Deep probabilistic forecasting is gaining attention in numerous applications from weather prognosis, through electricity consumption estimation, to autonomous vehicle trajectory prediction. However, existing approaches focus on improvements on average metrics without addressing the long tailed distribution of errors. In this work, we observe long tail behavior in the error distribution of state-of-the-art deep learning methods for probabilistic forecasting. We present two loss augmentation methods to reduce tailedness: Pareto Loss and Kurtosis Loss. Both methods are related to the concept of moments, which measures the shape of a distribution. Kurtosis Loss is based on a symmetric measure, the fourth moment. Pareto Loss is based on an asymmetric measure of right tailedness and models loss using a Generalized Pareto Distribution (GPD). We demonstrate the performance of our methods on several real-world datasets, including time series and spatiotemporal trajectories, achieving significant improvements on tail error metrics, while maintaining and even improving upon average error metrics.",https://openreview.net/pdf/8cf58e1f717e40027965dd695157091b07324600.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=fsa9jrF73fo,Learning Reduced Fluid Dynamics,"['zherong pan', 'Xifeng Gao', 'Kui Wu']","['~zherong_pan1', '~Xifeng_Gao1', '~Kui_Wu2']","['Fluid Dynamics', 'Model Reduction']","Predicting the state evolution of ultra high-dimensional, time-reversible fluid dynamic system is a crucial but computationally expensive task. Model-reduction has been proven to be an effective method to reduce the computational cost by learning a low-dimensional state embedding. However, existing reduced models are irrespective of either the time reversible property or the nonlinear dynamics, leading to sub-optimal performance. We propose a model-based approach to identify locally optimal, model-reduced, time reversible, nonlinear fluid dynamic systems. Our main idea is to use stochastic Riemann optimization to obtain a high-quality a reduced fluid model by minimizing the expected trajectory-wise model-reduction error over a given distribution of initial conditions. To this end, our method formulates the reduced fluid dynamics as an invertible state transfer function parameterized by the reduced subspace. We further show that the reduced trajectories are differentiable with respect to the subspace bases over the entire Grassmannian manifold, under proper choices of timestep sizes and numerical integrators. Finally, we propose a loss function measuring the trajectory-wise discrepancy between the original and reduced models. By tensor precomputation, we show that gradient information of such loss functions can be evaluated efficiently over a long trajectory without time-integrating the high-dimensional dynamic system. Through evaluations on a row of simulation benchmarks, we show that our method lower the discrepancy by 45%-97% over conventional reduced models.",https://openreview.net/pdf/f0beb980578e017d4225abbcc4d300ea41bf4f7c.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=fkNZtv_-BeW,Backdoors Stuck At The Frontdoor: Multi-Agent Backdoor Attacks That Backfire,"['Siddhartha Datta', 'Nigel Shadbolt']","['~Siddhartha_Datta1', '~Nigel_Shadbolt1']",[],"Malicious agents in collaborative learning and outsourced data collection threaten the training of clean models. Backdoor attacks, where an attacker poisons a model during training to successfully achieve targeted misclassification, are a major concern to train-time robustness. In this paper, we investigate a multi-agent backdoor attack scenario, where multiple attackers attempt to backdoor a victim model simultaneously. A consistent backfiring phenomenon is observed across a wide range of games, where agents suffer from a low collective attack success rate. We examine different modes of backdoor attack configurations, non-cooperation / cooperation, joint distribution shifts, and game setups to return an equilibrium attack success rate at the lower bound. The results motivate the re-evaluation of backdoor defense research for practical environments.",https://openreview.net/pdf/150b65c5f31f62a36049393cda88c5406f3043e2.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=fWWFv--P0xP,On the Importance and Applicability of Pre-Training for Federated Learning,"['Hong-You Chen', 'Cheng-Hao Tu', 'Ziwei Li', 'Han Wei Shen', 'Wei-Lun Chao']","['~Hong-You_Chen1', '~Cheng-Hao_Tu1', '~Ziwei_Li3', '~Han_Wei_Shen1', '~Wei-Lun_Chao1']","['federated learning', 'pre-training']","Pre-training is prevalent in nowadays deep learning to improve the learned model's performance. However, in the literature on federated learning (FL), neural networks are mostly initialized with random weights. These attract our interest in conducting a systematic study to explore pre-training for FL. Across multiple visual recognition benchmarks, we found that pre-training can not only improve FL, but also close its accuracy gap to the counterpart centralized learning, especially in the challenging cases of non-IID clients' data. To make our findings applicable to situations where pre-trained models are not directly available, we explore pre-training with synthetic data or even with clients' data in a decentralized manner, and found that they can already improve FL notably. Interestingly, many of the techniques we explore are complementary to each other to further boost the performance, and we view this as a critical result toward scaling up deep FL for real-world applications. We conclude our paper with an attempt to understand the effect of pre-training on FL. We found that pre-training enables the learned global models under different clients' data conditions to converge to the same loss basin, and makes global aggregation in FL more stable. Nevertheless, pre-training seems to not alleviate local model drifting, a fundamental problem in FL under non-IID data.",https://openreview.net/pdf/d1a6a32bc6d3abc4be477317cdca0f63fe17a19b.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=fSa5IjNMmmi,Multi-objective optimization via equivariant deep hypervolume approximation,"['Jim Boelrijk', 'Bernd Ensing', 'Patrick Forré']","['~Jim_Boelrijk1', '~Bernd_Ensing1', '~Patrick_Forré1']","['Multi-objective optimization', 'Hypervolume approximation', 'Geometric deep learning', 'Bayesian optimization', 'Evolutionary algorithms']","Optimizing multiple competing objectives is a common problem across science and industry. The inherent inextricable trade-off between those objectives leads one to the task of exploring their Pareto front. A meaningful quantity for the purpose of the latter is the hypervolume indicator, which is used in Bayesian Optimization (BO) and Evolutionary Algorithms (EAs). However, the computational complexity for the calculation of the hypervolume scales unfavorably with increasing number of objectives and data points, which restricts its use in those common multi-objective optimization frameworks. 
To overcome these restrictions, previous work has focused on approximating the hypervolume using deep learning. In this work, we propose a novel deep learning architecture to approximate the hypervolume function, which we call DeepHV. For better sample efficiency and generalization, we exploit the fact that the hypervolume is scale equivariant in each of the objectives as well as permutation invariant w.r.t. both the objectives and the samples, by using a deep neural network that is equivariant w.r.t. the combined group of scalings and permutations. We show through an ablation study that including these symmetries leads to significantly improved model accuracy. 
We evaluate our method against exact, and approximate hypervolume methods in terms of accuracy, computation time, and generalization. We also apply and compare our methods to state-of-the-art multi-objective BO methods and EAs on a range of synthetic and real-world benchmark test cases. The results show that our methods are promising for such multi-objective optimization tasks.",https://openreview.net/pdf/a46f7e06fdd5abd79f16e1e24307e1e051bf3f9e.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=fPVRcJqspu,GOGGLE: Generative Modelling for Tabular Data by Learning Relational Structure,"['Tennison Liu', 'Zhaozhi Qian', 'Jeroen Berrevoets', 'Mihaela van der Schaar']","['~Tennison_Liu1', '~Zhaozhi_Qian1', '~Jeroen_Berrevoets1', '~Mihaela_van_der_Schaar2']","['tabular data', 'synthetic data', 'generative model']","Deep generative models learn highly complex and non-linear representations to generate realistic synthetic data. While they have achieved notable success in computer vision and natural language processing, similar advances have been less demonstrable in the tabular domain. This is partially because generative modelling of tabular data entails a particular set of challenges, including heterogeneous relationships, limited number of samples, and difficulties in incorporating prior knowledge. Additionally, unlike their counterparts in image and sequence domain, deep generative models for tabular data almost exclusively employ fully-connected layers, which encode weak inductive biases about relationships between inputs. Real-world data generating processes can often be represented using relational structures, which encode sparse, heterogeneous relationships between variables. In this work, we learn and exploit relational structure underlying tabular data to better model variable dependence, and as a natural means to introduce regularization on relationships and include prior knowledge. Specifically, we introduce GOGGLE, an end-to-end message passing scheme that jointly learns the relational structure and corresponding functional relationships as the basis of generating synthetic samples. Using real-world datasets, we provide empirical evidence that the proposed method is effective in generating realistic synthetic data and exploiting domain knowledge for downstream tasks. ",https://openreview.net/pdf/7589a804d2686c2acfc5aa8c679329619789df08.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=f3dqV4KLZV1,Adaptive Client Sampling in Federated Learning via Online Learning with Bandit Feedback,"['Boxin Zhao', 'Ziqi Liu', 'Chaochao Chen', 'mladen kolar', 'Zhiqiang Zhang', 'JUN ZHOU']","['~Boxin_Zhao1', '~Ziqi_Liu2', '~Chaochao_Chen3', '~mladen_kolar1', '~Zhiqiang_Zhang4', '~JUN_ZHOU6']","['Federated Learning', 'Client Sampling', 'Optimization']","Due to the high cost of communication, federated learning (FL) systems need to sample a subset of clients that are involved in each round of training. As a result, client sampling plays an important role in FL systems as it affects the convergence rate of optimization algorithms used to train machine learning models. Despite its importance, there is limited work on how to sample clients effectively. In this paper, we cast client sampling as an online learning task with bandit feedback, which we solve with an online stochastic mirror descent (OSMD) algorithm designed to minimize the sampling variance. We then theoretically show how our sampling method can improve the convergence speed of optimization algorithms. To handle the tuning parameters in OSMD that depend on the unknown problem parameters, we use the online ensemble method and doubling trick. We prove a dynamic regret bound relative to any sampling sequence. The regret bound depends on the total variation of the comparator sequence, which naturally captures the intrinsic difficulty of the problem. To the best of our knowledge, these theoretical contributions are new and the proof technique is of independent interest. Through both synthetic and real data experiments, we illustrate advantages of the proposed client sampling algorithm over the widely used uniform sampling and existing online learning based sampling strategies. The proposed adaptive sampling procedure is applicable beyond the FL problem studied here and can be used to improve the performance of stochastic optimization procedures such as stochastic gradient descent and stochastic coordinate descent.",https://openreview.net/pdf/6bd69a4ef1e97f9382a07ee51b7286352318d746.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=esRySujigfO,CLIP-FLOW: CONTRASTIVE LEARNING WITH ITERATIVE PSEUDO LABELING FOR OPTICAL FLOW,"['Zhiqi Zhang', 'Nitin Bansal', 'Changjiang Cai', 'Pan Ji', 'Qingan Yan', 'Xiangyu Xu', 'Yi Xu']","['~Zhiqi_Zhang1', '~Nitin_Bansal1', '~Changjiang_Cai1', '~Pan_Ji2', '~Qingan_Yan2', '~Xiangyu_Xu4', '~Yi_Xu7']","['Optical Flow', 'Contrastvie Learning', 'Semi-supervised Learning']","Synthetic datasets are often used to pretrain end-to-end optical flow networks, due to the lack of a large amount of labeled, real scene data. But major drops in accuracy occur when moving from synthetic to real scenes. How do we better transfer the knowledge learned from synthetic to real domains? To this end, we propose CLIP-Flow, a semi-supervised iterative pseudo labeling framework to transfer the pretraining knowledge to the target real domain. We leverage large-scale, unlabeled real data to facilitate transfer learning with the supervision of iteratively updated pseudo ground truth labels, bridging the domain gap between the synthetic and the real. In addition, we propose a contrastive flow loss on reference features and the warped features by pseudo ground truth flows, to further boost the accurate matching and dampen the mismatching due to motion, occlusion, or noisy pseudo labels. We adopt RAFT as the backbone and obtain an F1-all error of 4.11%, i.e., a 19% error reduction from RAFT (5.10%) and ranking 2nd place at submission on KITTI 2015 benchmark. Our framework can also be extended to other models, e.g., CRAFT, reducing the F1-all error from 4.79% to 4.66% on KITTI 2015 benchmark.  ",https://openreview.net/pdf/011943cd7aa6977f8665225f7ab2a14651b9928d.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=eExA3Mk0Dxp,Robust Multi-Agent Reinforcement Learning against Adversaries on Observation,"['Chenghe Wang', 'Yuhang Ran', 'Lei Yuan', 'Yang Yu', 'Zongzhang Zhang']","['~Chenghe_Wang1', '~Yuhang_Ran1', '~Lei_Yuan2', '~Yang_Yu5', '~Zongzhang_Zhang1']","['multi-agent reinforcement learning', 'robust reinforcement learning', 'cooperative multi-agent systems', 'adversarial training']","With the broad applications of deep learning, such as image classification, it is becoming increasingly essential to tackle the vulnerability of neural networks when facing adversarial attacks, which have been widely studied recently. In the cooperative multi-agent reinforcement learning field, which has also shown potential in real-life domains, little work focuses on the problem of adversarial attacks. However, adversarial attacks on observations that can undermine the coordination among agents are likely to occur in actual deployment. This paper proposes a training framework that progressively generates adversarial attacks on agents' observations to help agents learn a robust cooperative policy. One attacker makes decisions on a hybrid action space that it first chooses an agent to attack and then outputs the perturbation vector. The victim policy is then trained against the attackers. Experimental results show that our generated adversarial attacks are diverse enough to improve the agents' robustness against possible disturbances. ",https://openreview.net/pdf/0a82f38bab922a92e0d32ed7ef3897fae15382b7.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=eDLwjKmtYFt,EquiMod: An Equivariance Module to Improve Visual Instance Discrimination,"['Alexandre DEVILLERS', 'Mathieu Lefort']","['~Alexandre_DEVILLERS1', '~Mathieu_Lefort1']","['Representation learning', 'Self-supervised learning', 'Contrastive learning', 'Equivariance']","Recent self-supervised visual representation methods are closing the gap with supervised learning performance. Most of these successful methods rely on maximizing the similarity between embeddings of related synthetic inputs created through data augmentations. This can be seen as a task that encourages embeddings to leave out factors modified by these augmentations, i.e. to be invariant to them. However, this only considers one side of the trade-off in the choice of the augmentations: they need to strongly modify the images to avoid simple solution shortcut learning (e.g. using only color histograms), but on the other hand, augmentations-related information may be lacking in the representations for some downstream tasks (e.g. literature shows that color is important for bird and flower classification). Few recent works proposed to mitigate this problem of using only an invariance task by exploring some form of equivariance to augmentations. This has been performed by learning additional embeddings space(s), where some augmentation(s) cause embeddings to differ, yet in a non-controlled way. In this work, we introduce EquiMod a generic equivariance module that structures the learned latent space, in the sense that our module learns to predict the displacement in the embedding space caused by the augmentations. We show that applying that module to state-of-the-art invariance models, such as BYOL and SimCLR, increases the performances on the usual CIFAR10 and ImageNet datasets. Moreover, while our model could collapse to a trivial equivariance, i.e. invariance, we observe that it instead automatically learns to keep some augmentations-related information beneficial to the representations. ",https://openreview.net/pdf/86ebacd324e18555c29ba7483c276055948f3c1c.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=dz8i-yzXeVg,Elicitation Inference Optimization for Multi-Principal-Agent Alignment,"['Andrew Konya', 'Yeping Lina Qiu', 'Michael P Varga', 'Aviv Ovadya']","['~Andrew_Konya1', '~Yeping_Lina_Qiu1', '~Michael_P_Varga1', '~Aviv_Ovadya1']","['alignment', 'large language models', 'LLMs', 'NLP', 'transfer learning', 'human-centered AI', 'LLMs', 'preference modeling']","In multi-principal-agent alignment scenarios spanning governance, markets, diplomacy, and AI, it is infeasible to elicit every principal's view on all perspectives relevant to agent decisions. Elicitation inference optimization (EIO) aims to minimize the $n$ elicitations needed to approximate $N$ principal's views across $K$ perspectives. In this work, we demonstrate an EIO approach where data efficiency ($NK/n$) increases with scale. We introduce STUMP: an elicitation inference model which integrates an LLM with a latent factor model to enable learning transfer across samples, contexts, and languages.  Then, we characterize STUMP's performance on a set of elicitation primitives from which scalable elicitation (sampling) protocols can be constructed. Building from these results, we design and demonstrate two scalable elicitation protocols for STUMP where data efficiency grows boundlessly, scaling like $O(n)$ in the number of elicitations $n$. This makes it possible to obtain complex, high-dimensional preference signals spanning principal populations at any scale.",https://openreview.net/pdf/46746608209d3fc39afecb2a59bf74dfec6c57ef.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=dqZ_GFn7Nuh,AUTOMATIC CURRICULUM FOR UNSUPERVISED REIN- FORCEMENT LEARNING,"['Yucheng Yang', 'Tianyi Zhou', 'Tianhong Dai', 'Meng Fang', 'Mykola Pechenizkiy']","['~Yucheng_Yang2', '~Tianyi_Zhou1', '~Tianhong_Dai1', '~Meng_Fang1', '~Mykola_Pechenizkiy1']",[],"Recent unsupervised reinforcement learning (URL) can learn meaningful skills without task rewards by carefully designed training objectives. However, most existing works lack quantitative evaluation metrics for URL but mainly rely on visualizations of trajectories to compare the performance. Moreover, each URL method only focuses on a single training objective, which can hinder further learning progress and the development of new skills. To bridge these gaps, we first propose multiple evaluation metrics for URL that can cover different preferred properties. We show that balancing these metrics leads to what a “good” trajectory visualization embodies. Next, we use these metrics to develop an automatic curriculum that can change the URL objective across different learning stages in order to improve and balance all metrics. Specifically, we apply a non-stationary multi-armed bandit algorithm to select an existing URL objective for each episode according to the metrics evaluated in previous episodes. Extensive experiments indifferent environments demonstrate the advantages of our method on achieving promising and balanced performance over all URL metrics.",https://openreview.net/pdf/93251ac00b1df67d7f89c189341931d918b25907.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=dmWMfJeZMM,uGLAD: A deep learning model to recover conditional independence graphs,"['Harsh Shrivastava', 'Urszula Chajewska', 'Robin Abraham', 'Xinshi Chen']","['~Harsh_Shrivastava1', '~Urszula_Chajewska1', '~Robin_Abraham1', '~Xinshi_Chen1']","['Graphical Lasso', 'Deep Learning', 'Unrolled Algorithms', 'Conditional Independence graphs', 'Sparse graphs']","Probabilistic Graphical Models are generative models of complex systems. They rely on conditional independence assumptions between variables to learn sparse representations which can be visualized in a form of a graph. Such models are used for domain exploration and structure discovery in poorly understood domains. This work introduces a novel technique to perform sparse graph recovery by optimizing deep unrolled networks. Assuming that the input data $X\in\mathbb{R}^{M\times D}$ comes from an underlying multivariate Gaussian distribution, we apply a deep model on $X$ that outputs the precision matrix $\Theta$. Then, the partial correlation matrix \mathrm{P} is calculated which can also be interpreted as providing a list of conditional independence assertions holding in the input distribution. Our model, \texttt{uGLAD}, builds upon and extends the state-of-the-art model \texttt{GLAD} to the unsupervised setting. The key benefits of our model are (1) \texttt{uGLAD} automatically optimizes sparsity-related regularization parameters leading to better performance than existing algorithms. (2) We introduce multi-task learning based `consensus' strategy for robust handling of missing data in an unsupervised setting. We evaluate performance on synthetic Gaussian, non-Gaussian data generated from Gene Regulatory Networks, and present case studies in anaerobic digestion and infant mortality.",https://openreview.net/pdf/bc80a9227fea49be8184c7c7b8337a59e740d921.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=dhYUMMy0_Eg,Equal Improvability: A New Fairness Notion Considering the Long-term Impact,"['Ozgur Guldogan', 'Yuchen Zeng', 'Jy-yong Sohn', 'Ramtin Pedarsani', 'Kangwook Lee']","['~Ozgur_Guldogan1', '~Yuchen_Zeng1', '~Jy-yong_Sohn1', '~Ramtin_Pedarsani1', '~Kangwook_Lee1']","['Fairness and Bias in Artificial Intelligence', 'Machine Learning']","Devising a fair classifier that does not discriminate against different groups is an important problem in machine learning. Although researchers have proposed various ways of defining group fairness, most of them only focused on the immediate fairness, ignoring the long-term impact of a fair classifier under the dynamic scenario where each individual can improve its feature over time. Such dynamic scenarios happen in real world, e.g., college admission and credit loaning, where each rejected sample makes effort to change its features to get accepted afterwards. In this dynamic setting, the long-term fairness should equalize the samples’ feature distribution across different groups after the rejected samples make some effort to improve. In order to promote long-term fairness, we propose a new fairness notion called Equal Improvability (EI), which equalizes the potential acceptance rate of the rejected samples across different groups assuming a bounded level of effort will be spent by each rejected sample. We analyze the properties of EI and its connections with existing fairness notions. To find a classifier that satisfies the EI requirement, we propose and study three different approaches that solve EI regularized optimization problems. Through experiments on both synthetic and real datasets, we demonstrate that the proposed EI-regularized algorithms encourage us to find a fair classifier in terms of EI. Finally, we provide experimental results on dynamic scenarios which highlight the advantages of our EI metric in achieving the long-term fairness. Codes are available in anonymous GitHub repository.",https://openreview.net/pdf/97ea07ad031609a62cd7a8f682fec684434f45cf.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=dcN0CaXQhT,Causal Reasoning in the Presence of Latent Confounders via Neural ADMG Learning,"['Matthew Ashman', 'Chao Ma', 'Agrin Hilmkil', 'Joel Jennings', 'Cheng Zhang']","['~Matthew_Ashman1', '~Chao_Ma2', '~Agrin_Hilmkil1', '~Joel_Jennings1', '~Cheng_Zhang1']","['causality', 'causal discovery', 'causal inference', 'structural equation model', 'latent confounders', 'variational inference']","Latent confounding has been a long-standing obstacle for causal reasoning from observational data. One popular approach is to model the data using acyclic directed mixed graphs (ADMGs), which describe ancestral relations between variables using directed and bidirected edges. However, existing methods using ADMGs are based on either linear functional assumptions or a discrete search that is complicated to use and lacks computational tractability for large datasets. In this work, we further extend the existing body of work and develop a novel gradient-based approach to learning an ADMG with nonlinear functional relations from observational data. We first show that the presence of latent confounding is identifiable under the assumptions of bow-free ADMGs with nonlinear additive noise models. With this insight, we propose a novel neural causal model based on autoregressive flows. This not only enables us to model complex causal relationships behind the data, but also estimate their functional relationships (hence treatment effects) simultaneously. We further validate our approach via experiments on both synthetic and real-world datasets, and demonstrate the competitive performance against relevant baselines.",https://openreview.net/pdf/149ce81bce210b81430db7d28cdb51750814141c.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=dPOLZ2u4SKV,Expected Probabilistic Hierarchies,"['Marcel Kollovieh', 'Bertrand Charpentier', 'Daniel Zügner', 'Stephan Günnemann']","['~Marcel_Kollovieh1', '~Bertrand_Charpentier2', '~Daniel_Zügner1', '~Stephan_Günnemann1']","['Hierarchical Clustering', 'Graph Clustering', 'Clustering', 'Probabilistic Models']","Hierarchical clustering has usually been addressed by discrete optimization using heuristics or continuous optimization of relaxed scores for hierarchies. In this work, we propose to optimize expected scores under a probabilistic model over hierarchies. (1) We show theoretically that the global optimum of the expected Dasgupta cost and Tree-Sampling divergence (TSD), two unsupervised metrics for hierarchical clustering scores, are equal to the optimum of their discrete counterparts contrary to some relaxed scores. (2) We propose Expected Probabilistic Hierarchies (EPH), a probabilistic model to learn hierarchies in data by optimizing expected scores. EPH uses differentiable hierarchy sampling enabling end-to-end gradient-descent based optimizations, and an unbiased subgraph sampling approach to scale to large datasets. (3) We evaluate EPH on synthetic and real-world datasets including vector and graph datasets. EPH outperforms all other approaches on quantitative results and provides meaningful hierarchies in qualitative evaluations.",https://openreview.net/pdf/6a7f462685c75c4f84a25bad4bb5cf8722ed9bd2.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=dO4aZ9-CsTn,Hierarchical Prototypes for  Unsupervised Dynamics Generalization in Model-Based Reinforcement Learning,"['Jiaxian Guo', 'Mingming Gong', 'Yali Du', 'Zhen Wang', 'Dacheng Tao']","['~Jiaxian_Guo2', '~Mingming_Gong1', '~Yali_Du1', '~Zhen_Wang9', '~Dacheng_Tao1']","['Unsupervised Dynamics Generalization', 'Model-Based Reinforcement Learning']","By incorporating the environment-specific factor into the dynamics prediction, model-based reinforcement learning (MBRL) is able to generalise to environments with diverse dynamics.In the majority of real-world scenarios, the environment-specific factor is not observable, so existing methods attempt to estimate it from historical transition segments. Nevertheless,earlier research was unable to identify distinct clusters for environment-specific factors learned from different environments, resulting in poor performance.
To address this issue,
We introduce a set of environmental prototypes to represent the environmental-specified representation for each environment. By encouraging learned environment-specific factors to resemble their assigned environmental prototypes more closely, the discrimination between factors estimated from distinct environments will be enhanced. To learn such prototypes, we first construct prototypes for each sampled trajectory and then hierarchically combine trajectory prototypes with similar semantics into one environmental prototype. Experiments demonstrate that environment-specific factors estimated by our method have superior clustering performance and can consistently improve MBRL's generalisation performance in six environments consistently.",https://openreview.net/pdf/20e881856fbf47168891abe80e2abf024ecf7b50.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=dCwBpTXbfIq,Identifying Weight-Variant Latent Causal Models,"['Yuhang Liu', 'Zhen Zhang', 'Dong Gong', 'Mingming Gong', 'Biwei Huang', 'Anton van den Hengel', 'Kun Zhang', 'Javen Qinfeng Shi']","['~Yuhang_Liu1', '~Zhen_Zhang2', '~Dong_Gong1', '~Mingming_Gong1', '~Biwei_Huang1', '~Anton_van_den_Hengel1', '~Kun_Zhang1', '~Javen_Qinfeng_Shi1']",[],"The task of causal representation learning aims to uncover latent higher-level causal representations that affect lower-level observations. Identifying true latent causal representations from observed data, while allowing instantaneous causal relations among latent variables,  remains a challenge, however. To this end, we start from the analysis of three intrinsic properties in identifying latent space from observations: transitivity, permutation indeterminacy, and scaling indeterminacy. We find that transitivity acts as a key role in impeding the identifiability of latent causal representations. To address the unidentifiable issue due to transitivity, we introduce a novel identifiability condition where the underlying latent causal model satisfies a linear-Gaussian model, in which the causal coefficients and the distribution of Gaussian noise are modulated by an additional observed variable. Under some mild assumptions, we can show that the latent causal representations can be identified up to trivial permutation and scaling. Furthermore, based on this theoretical result, we propose a novel method, termed Structural caUsAl Variational autoEncoder, which directly learns latent causal representations and causal relationships among them, together with the mapping from the latent causal variables to the observed ones. We show that the proposed method learns the true parameters asymptotically. Experimental results on synthetic and real data demonstrate the identifiability and consistency results and the efficacy of the proposed method in learning latent causal representations.",https://openreview.net/pdf/e1cc392b92d7216219e68b06cb14a851814bee68.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=dCOL0inGl3e,Certifiably Robust Policy Learning against Adversarial Multi-Agent Communication,"['Yanchao Sun', 'Ruijie Zheng', 'Parisa Hassanzadeh', 'Yongyuan Liang', 'Soheil Feizi', 'Sumitra Ganesh', 'Furong Huang']","['~Yanchao_Sun1', '~Ruijie_Zheng1', '~Parisa_Hassanzadeh1', '~Yongyuan_Liang1', '~Soheil_Feizi2', '~Sumitra_Ganesh1', '~Furong_Huang1']","['certifiable robustness', 'reinforcement learning', 'multi-agent system', 'adversarial communication', 'adversarial attack']","Communication is important in many multi-agent reinforcement learning (MARL) problems for agents to share information and make good decisions. However, when deploying trained communicative agents in a real-world application where noise and potential attackers exist, the safety of communication-based policies becomes a severe issue that is underexplored. Specifically, if communication messages are manipulated by malicious attackers, agents relying on untrustworthy communication may take unsafe actions that lead to catastrophic consequences. Therefore, it is crucial to ensure that agents will not be misled by corrupted communication, while still benefiting from benign communication. In this work, we consider an environment with $N$ agents, where the attacker may arbitrarily change the communication from any $C<\frac{N-1}{2}$ agents to a victim agent. For this strong threat model, we propose a certifiable defense by constructing a message-ensemble policy that aggregates multiple randomly ablated message sets. Theoretical analysis shows that this message-ensemble policy can utilize benign communication while being certifiably robust to adversarial communication, regardless of the attacking algorithm. Experiments in multiple environments verify that our defense significantly improves the robustness of trained policies against various types of attacks.",https://openreview.net/pdf/f1c6ea43513dada0ace7e97e3a9c8f26b83250a8.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=d8tJcOxnzF9,Learning Multiobjective Program Through Online Learning,"['Chaosheng Dong', 'Yijia Wang', 'Bo Zeng']","['~Chaosheng_Dong1', 'yiw94@pitt.edu', '~Bo_Zeng1']","['Learning Multiobjective Program', 'Multiobjective Optimization']","We investigate the problem of learning the parameters (i.e., objective functions or constraints) of a multiobjective decision making model, based on a set of sequentially arrived decisions. In particular, these decisions might not be exact and possibly carry measurement noise or are generated with the bounded rationality of decision makers. In this paper, we propose a general online learning framework to deal with this learning problem using inverse multiobjective optimization, and prove that this framework converges at a rate of $\mathcal{O}(1/\sqrt{T})$ under certain regularity conditions. More precisely, we develop two online learning algorithms with implicit update rules which can handle noisy data. Numerical results with both synthetic and real world datasets show that both algorithms can learn the parameters of a multiobjective program with great accuracy and are robust to noise.",https://openreview.net/pdf/5f53b3e7d9b8ec6ab6b6356217048e4e5dec2c67.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=d7Q0vVfJ0wO,Implicit Regularization for Group Sparsity,"['Jiangyuan Li', 'Thanh V Nguyen', 'Chinmay Hegde', 'Raymond K. W. Wong']","['~Jiangyuan_Li1', '~Thanh_V_Nguyen1', '~Chinmay_Hegde1', '~Raymond_K._W._Wong1']","['gradient descent', 'implicit regularization', 'structured/group sparsity', 'linear neural network']","We study the implicit regularization of gradient descent towards structured sparsity via a novel neural reparameterization, which we call a diagonally grouped linear neural network. We show the following intriguing property of our reparameterization: gradient descent over the squared regression loss, without any explicit regularization, biases towards solutions with a group sparsity structure. In contrast to many existing works in understanding implicit regularization, we prove that our training trajectory cannot be simulated by mirror descent. We analyze the gradient dynamics of the corresponding regression problem in the general noise setting and obtain minimax-optimal error rates. Compared to existing bounds for implicit sparse regularization using diagonal linear networks, our analysis with the new reparameterization shows improved sample complexity. In the degenerate case of size-one groups, our approach gives rise to a new algorithm for sparse linear regression. Finally, we demonstrate the efficacy of our approach with several numerical experiments.",https://openreview.net/pdf/efa20f315f25148216c11b749723e1e6e8fac117.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=d3QNWD_pcFv,"Neural Lagrangian Schr\""{o}dinger Bridge: Diffusion Modeling for Population Dynamics","['Takeshi Koshizuka', 'Issei Sato']","['~Takeshi_Koshizuka1', 'isseis@gmail.com']","['Population Dynamics', 'Trajectory Inference', 'Neural SDEs', 'Stochastic Optimal Transport', 'Schrödinger Bridge']","Population dynamics is the study of temporal and spatial variation in the size of populations of organisms and is a major part of population ecology. One of the main difficulties in analyzing population dynamics is that we can only obtain observation data with coarse time intervals from fixed-point observations due to experimental costs or measurement constraints. Recently, modeling population dynamics by using continuous normalizing flows (CNFs) and dynamic optimal transport has been proposed to infer the sample trajectories from a fixed-point observed population. While the sample behavior in CNFs is deterministic, the actual sample in biological systems moves in an essentially random yet directional manner. Moreover, when a sample moves from point A to point B in dynamical systems, its trajectory typically follows the principle of least action in which the corresponding action has the smallest possible value. To satisfy these requirements of the sample trajectories, we formulate the Lagrangian Schrödinger bridge (LSB) problem and propose to solve it approximately by modeling the advection-diffusion process with regularized neural SDE. We also develop a model architecture that enables faster computation of the loss function. Experimental results show that the proposed method can efficiently approximate the population-level dynamics even for high-dimensional data and that using the prior knowledge introduced by the Lagrangian enables us to estimate the sample-level dynamics with stochastic behavior.",https://openreview.net/pdf/4f5dfd7d5e9825029e736d0ace01eda002efdcb8.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=cytNlkyjWOq,Multi-Agent Multi-Game Entity Transformer,"['Rundong Wang', 'Weixuan Wang', 'Xianhan Zeng', 'Liang Wang', 'Zhenjie Lian', 'Yiming Gao', 'Feiyu Liu', 'Siqin Li', 'Xianliang Wang', 'QIANG FU', 'Yang Wei', 'Lanxiao Huang', 'Longtao Zheng', 'Zinovi Rabinovich', 'Bo An']","['~Rundong_Wang1', '~Weixuan_Wang1', '~Xianhan_Zeng1', '~Liang_Wang10', '~Zhenjie_Lian1', '~Yiming_Gao4', '~Feiyu_Liu1', '~Siqin_Li1', '~Xianliang_Wang1', '~QIANG_FU8', '~Yang_Wei2', '~Lanxiao_Huang1', '~Longtao_Zheng1', '~Zinovi_Rabinovich1', '~Bo_An2']","['reinforcement learning', 'multi-agent reinforcement learing', 'transformer', 'pretrained model']","Building large-scale generalist pre-trained models for many tasks is becoming an emerging and potential direction in reinforcement learning (RL). Research such as Gato and Multi-Game Decision Transformer have displayed outstanding performance and generalization capabilities on many games and domains. However, there exists a research blank about developing highly capable and generalist models in multi-agent RL (MARL), which can substantially accelerate progress towards general AI. To fill this gap, we propose Multi-Agent multi-Game ENtity TrAnsformer (MAGENTA) from the entity perspective as an orthogonal research to previous time-sequential modeling. Specifically, to deal with different state/observation spaces in different games, we analogize games as languages, thus training different ""tokenizers"" for various games. The feature inputs are split according to different entities and tokenized in the same continuous space. Then, two types of transformer-based model are proposed as permutation-invariant architectures to deal with various numbers of entities and capture the attention over different entities. MAGENTA is trained on Honor of Kings, Starcraft II micromanagement, and Neural MMO with a single set of transformer weights. Extensive experiments show that MAGENTA can play games across various categories with arbitrary numbers of agents and increase the efficiency of fine-tuning in new games and scenarios by 50\%-100\%. See our project page at \url{https://sites.google.com/view/rl-magenta}.",https://openreview.net/pdf/d62239eae00ca98ce343574d3709068d2631674b.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=cp5PvcI6w8_,TabPFN: A Transformer That Solves Small Tabular Classification Problems in a Second,"['Noah Hollmann', 'Samuel Müller', 'Katharina Eggensperger', 'Frank Hutter']","['~Noah_Hollmann1', '~Samuel_Müller1', '~Katharina_Eggensperger1', '~Frank_Hutter1']","['Tabular Data', 'AutoML', 'Green AI', 'Bayesian prediction', 'Causal Reasoning', 'Real-time Machine Learning']","We present TabPFN, a trained Transformer that can do supervised classification for small tabular datasets in less than a second, needs no hyperparameter tuning and is competitive with state-of-the-art classification methods.
TabPFN is fully entailed in the weights of our network, which accepts training and test samples as a set-valued input and yields predictions for the entire test set in a single forward pass.
TabPFN is a Prior-Data Fitted Network (PFN) and is trained offline once, to approximate Bayesian inference on synthetic datasets drawn from our prior.
This prior incorporates ideas from causal reasoning: It entails a large space of structural causal models with a preference for simple structures.
On the $18$ datasets in the OpenML-CC18 suite that contain up to 1000 training data points, up to 100 purely numerical features without missing values, and up to 10 classes, we show that our method clearly outperforms boosted trees and performs on par with complex state-of-the-art AutoML systems with up to $230\times$ speedup.
This increases to a $5\,700\times$ speedup when using a GPU. We also validate these results on an additional 67 small numerical datasets from OpenML.
We provide all our code, the trained TabPFN, an interactive browser demo and a Colab notebook at https://github.com/automl/TabPFN.",https://openreview.net/pdf/a14bada70718d8e2f05879f7f5dd162a0adbe28c.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=cnsHSSLnHVV,Equivariant 3D-Conditional Diffusion Models for Molecular Linker Design,"['Ilia Igashov', 'Hannes Stärk', 'Clement Vignac', 'Victor Garcia Satorras', 'Pascal Frossard', 'Max Welling', 'Michael M. Bronstein', 'Bruno Correia']","['~Ilia_Igashov1', '~Hannes_Stärk1', '~Clement_Vignac1', '~Victor_Garcia_Satorras2', '~Pascal_Frossard1', '~Max_Welling1', '~Michael_M._Bronstein1', '~Bruno_Correia1']","['Molecules', 'Drug Discovery', 'Molecular Linker Design', 'Equivariant', 'Diffusion Models']","Fragment-based drug discovery has been an effective paradigm in early-stage drug development. An open challenge in this area is designing linkers between disconnected molecular fragments of interest to obtain chemically-relevant candidate drug molecules. In this work, we propose DiffLinker, an E(3)-equivariant 3D-conditional diffusion model for molecular linker design. Given a set of disconnected fragments, our model places missing atoms in between and designs a molecule incorporating all the initial fragments. Unlike previous approaches that are only able to connect pairs of molecular fragments, our method can link an arbitrary number of fragments. Additionally, the model automatically determines the number of atoms in the linker and its attachment points to the input fragments. We demonstrate that DiffLinker outperforms other methods on the standard datasets generating more diverse and synthetically-accessible molecules. Besides, we experimentally test our method in real-world applications, showing that it can successfully generate valid linkers conditioned on target protein pockets.",https://openreview.net/pdf/b751e84e6906e915b3a30a97f53604c591114635.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=cddbeL1HWaD,Cheap Talk Discovery and Utilization in Multi-Agent Reinforcement Learning,"['Yat Long Lo', 'Christian Schroeder de Witt', 'Samuel Sokota', 'Jakob Nicolaus Foerster', 'Shimon Whiteson']","['~Yat_Long_Lo1', '~Christian_Schroeder_de_Witt1', '~Samuel_Sokota1', '~Jakob_Nicolaus_Foerster1', '~Shimon_Whiteson1']","['Reinforcement Learning', 'Multi-Agent Reinforcement Learning']","By enabling agents to communicate, recent cooperative multi-agent reinforcement learning (MARL) methods have demonstrated better task performance and more coordinated behavior. Most existing approaches facilitate inter-agent communication by allowing agents to send messages to each other through free communication channels, i.e., \emph{cheap talk channels}. Current methods require these channels to be constantly accessible and known to the agents a priori. In this work, we lift these requirements such that the agents must discover the cheap talk channels and learn how to use them. Hence, the problem has two main parts: \emph{cheap talk discovery} (CTD) and \emph{cheap talk utilization} (CTU). We introduce a novel conceptual framework for both parts and develop a new algorithm based on mutual information maximization that outperforms existing algorithms in CTD/CTU settings. We also release a novel benchmark suite to stimulate future research in CTD/CTU.",https://openreview.net/pdf/efb6725925bb04b66d9a794a929e5ed57ea8ef69.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=cZM4iZmxzR7,Simple Spectral Graph Convolution from an Optimization Perspective,"['Hao Zhu', 'Piotr Koniusz']","['~Hao_Zhu2', '~Piotr_Koniusz1']","['Graph Convolution', 'Graph Fourier Transformation', 'Unsupervised Learning']","Recent studies on SGC, PageRank and S\textsuperscript{2}GC have demonstrated that several graph diffusion techniques are straightforward, quick, and effective for tasks in the graph domain like node classification. Even though these techniques do not even need labels, they can nevertheless produce more discriminating features than raw attributes for downstream tasks with different classifiers. These methods are data-independent and thus primarily rely on some empirical parameters on polynomial bases (e.g., Monomial and Chebyshev), which ignore the homophily of graphs and the attribute distribution. They are more insensitive to heterophilous graphs due to the low-pass filtering. Although there are many approaches focusing on GNNs based on heterophilous graphs, these approaches are dependent on label information to learn model parameters. In this paper, we study the question: are labels a necessity for GNNs with heterophilous graphs? Based on this question, we propose a framework of self-representation on graphs related to the Least Squares problem. Specifically, we use Generalized Minimum RESidual (GMRES) method, which finds the least squares solution over Krylov subspaces. In theoretical analysis, without label information, we enjoy better features with graph convolution. 
The proposed method, like previous data-independent methods, is not a deep model and is, therefore, quick, scalable, and simple. We  also show performance guarantees for models on real and synthetic data. On a benchmark of real-world datasets, empirically, our method is competitive with existing deep models for node classification.",https://openreview.net/pdf/4dfec7b41fd7e6502bbccc24b2cb1a405d85029f.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=cYZupNY8DS4,Online Policy Optimization for Robust MDP,"['Jing Dong', 'Jingwei Li', 'Baoxiang Wang', 'Jingzhao Zhang']","['~Jing_Dong3', '~Jingwei_Li2', '~Baoxiang_Wang1', '~Jingzhao_Zhang2']",[],"Reinforcement learning (RL) has exceeded human performance in many synthetic settings such as video games and Go. However, real-world deployment of end-to-end RL models is rare, as RL models can be very sensitive to slight perturbation of the environment. The robust Markov decision process (MDP) framework---in which the transition probabilities belong to an uncertainty set around a nominal model---provides one way to develop robust models. While previous analysis shows RL algorithms are effective assuming access to a generative model, it remains unclear whether RL can be efficient under a more realistic online setting, which requires carefully balancing exploration and exploitation. In this work, we consider online robust MDP by interacting with an unknown nominal system. We propose a robust optimistic policy optimization algorithm that is provably efficient. To address the additional uncertainty caused by an adversarial environment, our model features a new optimistic update rule derived via Fenchel conjugates. Our analysis establishes the first regret upper bound for online robust MDPs. ",https://openreview.net/pdf/e03cc06b2f45de1a09d00394817980d9798ee452.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=cVFD6qE8gnY,Planning with Sequence Models through Iterative Energy Minimization,"['Hongyi Chen', 'Yilun Du', 'Yiye Chen', 'Joshua B. Tenenbaum', 'Patricio A. Vela']","['~Hongyi_Chen2', '~Yilun_Du1', '~Yiye_Chen1', '~Joshua_B._Tenenbaum1', '~Patricio_A._Vela1']","['Reinforcement Learning', 'Planning', 'Language Model', 'Decision Transformer']","Recent works have shown that language modeling can be effectively used to train reinforcement learning (RL) policies. However, the success of applying existing language models to planning, in which we wish to obtain a trajectory of actions to reach some goal, is less straightforward. The typical autoregressive generation procedures of language models preclude sequential refinement of earlier steps, which limits the effectiveness of a predicted plan. In this paper, we suggest an approach towards integrating planning with language models based on the idea of iterative energy minimization, and illustrate how such a procedure leads to improved RL performance across different tasks. We train a masked language model to capture an implicit energy function over trajectories of actions, and formulate planning as finding a trajectory of actions with minimum energy. We illustrate how this procedure enables improved performance over recent approaches across BabyAI and Atari environments. We further demonstrate unique benefits of our iterative optimization procedure, involving new task generalization, test-time constraints adaptation, and the ability to compose plans together. Project webpage: https://hychen-naza.github.io/projects/LEAP/index.html",https://openreview.net/pdf/b6ee4b3ab28ce8f9c2f94ec81b64cf338bfdfafe.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=cH4MVZsScm,OoD-Control: Out-of-Distribution Generalization for Adaptive UAV Flight Control,"['Yuxiao Duan', 'Jundong Zhou', 'Zhaoyu Zeng', 'Haoqi Zeng', 'Nanyang Ye']","['~Yuxiao_Duan1', 'zhoujundong@sjtu.edu.cn', '~Zhaoyu_Zeng1', 'zeng-hq@sjtu.edu.cn', '~Nanyang_Ye1']",[],"Data-driven control methods have demonstrated precise and agile control of Unmanned Aerial Vehicles (UAVs) over turbulence environments. However, they are relatively weak at taming the out-of-distribution (OoD) data, i.e., encountering the generalization problem when faced with unknown environments with different data distributions from the training set. Many studies have designed algorithms to reduce the impact of the OoD problem, a common but tricky problem in machine learning. To tackle the OoD generalization problem in control, we propose a theoretically guaranteed approach: OoD-Control. We provide proof that for any perturbation within some range on the states, the control error can be upper bounded by a constant. In this paper, we present our OoD-Control generalization algorithm for online adaptive flight control and execute it on two instances. Experiments show that systems trained by the proposed OoD-Control algorithm perform better in quite different environments from training. And the control method is extensible and pervasively applicable and can be applied to different dynamical models. OoD-Control is validated on UAV dynamic models, and we find it performs state-of-the-art in positioning stability and trajectory tracking problems.",https://openreview.net/pdf/94b6438d7340dda1dffb706c2eefa825fbdd2541.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=cEygmQNOeI,Language Models are Realistic Tabular Data Generators,"['Vadim Borisov', 'Kathrin Sessler', 'Tobias Leemann', 'Martin Pawelczyk', 'Gjergji Kasneci']","['~Vadim_Borisov1', '~Kathrin_Sessler1', '~Tobias_Leemann1', '~Martin_Pawelczyk1', '~Gjergji_Kasneci2']","['tabular data', 'tabular data generation', 'large language models', 'transformers', 'probabilistic modeling', 'deep neural networks']","Tabular data is among the oldest and most ubiquitous forms of data. However, the generation of synthetic samples with the original data’s characteristics remains a significant challenge for tabular data. While many generative models from the computer vision domain, such as variational autoencoders or generative adversarial networks, have been adapted for tabular data generation, less research has been directed towards recent transformer-based large language models (LLMs), which are also generative in nature. To this end, we propose GReaT (Generation of Realistic Tabular data), which exploits an auto-regressive generative LLM to sample synthetic and yet highly realistic tabular data. Furthermore, GReaT can model tabular data distributions by conditioning on any subset of features; the remaining features are sampled without additional overhead. We demonstrate the effectiveness of the proposed approach in a series of experiments that quantify the validity and quality of the produced data samples from multiple angles. We find that GReaT maintains state-of-the-art performance across numerous real-world and synthetic data sets with heterogeneous feature types coming in various sizes.",https://openreview.net/pdf/93e938176cd4da2511c79883813c6bb7781f9804.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=cDVL245jZa,GAPS: Few-Shot Incremental Semantic Segmentation via Guided Copy-Paste Synthesis,"['Ri-Zhao Qiu', 'Peiyi Chen', 'Wangzhe Sun', 'Yu-Xiong Wang', 'Kris Hauser']","['~Ri-Zhao_Qiu1', 'peiyic2@illinois.edu', 'wangzhe.sun@vanderbilt.edu', '~Yu-Xiong_Wang1', '~Kris_Hauser2']","['continual learning', 'incremental learning', 'incremental segmentation', 'few-shot learning']","Few-shot incremental segmentation is the task of updating a segmentation model, as novel classes are introduced online overtime with a small number of training images. Although incremental segmentation methods exist in the literature, they tend to fall short in the few-shot regime and when given partially-annotated training images, where only the novel class is segmented. This paper proposes a data synthesizer, Guided copy-And-Paste Synthesis (GAPS), that improves the performance of few-shot incremental segmentation in a model-agnostic fashion. Despite the great success of copy-paste synthesis in the conventional offline visual recognition, we demonstrate substantially degraded performance of its naive extension in our online scenario, due to newly encountered challenges. To this end, GAPS (i) addresses the partial-annotation problem by leveraging copy-paste to generate fully-labeled data for training, (ii) helps augment the few images of novel objects by introducing a guided sampling process, and (iii) mitigates catastrophic forgetting by employing a diverse memory-replay buffer. Compared to existing state-of-the-art methods, GAPS dramatically boosts the novel IoU of baseline methods on established few-shot incremental segmentation benchmarks by up to 80%. More notably, GAPS maintains good performance in even more impoverished annotation settings, where only single instances of novel objects are annotated.",https://openreview.net/pdf/35e0d095a41834d2bdd84e60fb8229c67a3aab46.pdf,{'title_filter': 'Data Synthesis'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=cA77NrVEuqn,Efficient Planning in a Compact Latent Action Space,"['zhengyao jiang', 'Tianjun Zhang', 'Michael Janner', 'Yueying Li', 'Tim Rocktäschel', 'Edward Grefenstette', 'Yuandong Tian']","['~zhengyao_jiang2', '~Tianjun_Zhang1', '~Michael_Janner1', '~Yueying_Li1', '~Tim_Rocktäschel1', '~Edward_Grefenstette1', '~Yuandong_Tian1']","['Model-based RL', 'Planning', 'Sequence Modelling RL', 'Generative Model', 'Offline Reinforcement Learning']","Planning-based reinforcement learning has shown strong performance in tasks in discrete and low-dimensional continuous action spaces. However, planning usually brings significant computational overhead for decision making, so scaling such methods to high-dimensional action spaces remains challenging. To advance efficient planning for high-dimensional continuous control, we propose Trajectory Autoencoding Planner (TAP), which learns low-dimensional latent action codes with a state-conditional VQ-VAE. The decoder of the VQ-VAE thus serves as a novel dynamics model that takes latent actions and current state as input and reconstructs long-horizon trajectories. During inference time, given a starting state, TAP searches over discrete latent actions to find trajectories that have both high probability under the training distribution and high predicted cumulative reward. Empirical evaluation in the offline RL setting demonstrates low decision latency which is indifferent to the growing raw action dimensionality. For Adroit robotic hand manipulation tasks with high-dimensional continuous action space, TAP surpasses existing model-based methods by a large margin and also beats strong model-free actor-critic baselines.",https://openreview.net/pdf/18c1efd356786f3071db813b03dac9cd5621a032.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=c5-qKzTbP2O,Interpretable (meta)factorization of clinical questionnaires to identify general dimensions of psychopathology,"['Ka Chun Lam', 'Bridget W Mahony', 'Armin Raznahan', 'Francisco Pereira']","['~Ka_Chun_Lam1', 'bridgetwmahony@gmail.com', 'raznahana@mail.nih.gov', '~Francisco_Pereira1']","['Factor analysis', 'matrix factorization', 'meta-factors', 'latent constructs', 'Healthy Brain Network Study']","Psychiatry research aims at understanding manifestations of psychopathology in behavior, in terms of a small number of latent constructs. These are usually inferred from questionnaire data using factor analysis. The resulting factors and relationship to the original questions are not necessarily interpretable. Furthermore, this approach does not provide a way to separate the effect of confounds from those of constructs, and requires explicit imputation for missing data. Finally, there is no clear way to integrate multiple sets of constructs estimated from different questionnaires. An important question is whether there is a universal, compact set of constructs that would span all the psychopathology issues listed across those questionnaires.  We propose a new matrix factorization method designed for questionnaires aimed at promoting interpretability, through bound and sparsity constraints. We provide an optimization procedure with theoretical convergence guarantees, and validate automated methods to detect latent dimensionality on synthetic data. We first demonstrate the method on a commonly used general-purpose questionnaire. We then show it can be used to extract a broad set of 15 psychopathology factors spanning 21 questionnaires from the Healthy Brain Network study. We show that our method preserves diagnostic information against competing methods, even as it imposes more constraints. Finally, we demonstrate that it can be used for defining a short, general questionnaire that allows recovery of those 15 meta-factors, using data more efficiently than other methods.",https://openreview.net/pdf/10045f2f053bc0ee378cc946cf2413ef2d945f1f.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=bzaPGEllsjE,"A view of mini-batch SGD via generating functions: conditions of convergence, phase transitions,  benefit from negative momenta.","['Maksim Velikanov', 'Denis Kuznedelev', 'Dmitry Yarotsky']","['~Maksim_Velikanov1', '~Denis_Kuznedelev1', '~Dmitry_Yarotsky1']","['SGD', 'linear models', 'optimization', 'analytic framework', 'NTK']","Mini-batch SGD with momentum is a fundamental algorithm for learning large predictive models. In this paper we develop a new analytic framework to analyze noise-averaged properties of mini-batch SGD for linear models at constant learning rates, momenta and sizes of batches. Our key idea is to consider the dynamics of the second moments of model parameters for a special family of ""Spectrally Expressible"" approximations. This allows to obtain an explicit expression for the generating function of the sequence of loss values. By analyzing this generating function, we find, in particular, that 1) the SGD dynamics exhibits several convergent and divergent regimes depending on the spectral distributions of the problem; 2) the convergent regimes admit explicit stability conditions, and explicit loss asymptotics in the case of power-law spectral distributions; 3) the optimal convergence rate can be achieved at negative momenta. We verify our theoretical predictions by extensive experiments with MNIST and synthetic problems, and find a good quantitative agreement.",https://openreview.net/pdf/90d22c6df28d1d2983dce952bd3a17a819ab5b3b.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=bRwBpKrNzF7,Faster Last-iterate Convergence of Policy Optimization in Zero-Sum Markov Games,"['Shicong Cen', 'Yuejie Chi', 'Simon Shaolei Du', 'Lin Xiao']","['~Shicong_Cen1', '~Yuejie_Chi1', '~Simon_Shaolei_Du1', '~Lin_Xiao1']","['zero-sum Markov game', 'entropy regularization', 'policy optimization', 'global convergence', 'multiplicative updates']","Multi-Agent Reinforcement Learning (MARL)---where multiple agents learn to interact in a shared dynamic environment---permeates across a wide range of critical applications. While there has been substantial progress on understanding the global convergence of policy optimization methods in single-agent RL, designing and analysis of efficient policy optimization algorithms in the MARL setting present significant challenges and new desiderata, which unfortunately, remain highly inadequately addressed by existing theory. In this paper, we focus on the most basic setting of competitive multi-agent RL, namely two-player zero-sum Markov games, and study equilibrium finding algorithms in both the infinite-horizon discounted setting and the finite-horizon episodic setting. We propose a single-loop policy optimization method with symmetric updates from both agents, where the policy is updated via the entropy-regularized optimistic multiplicative weights update (OMWU) method and the value is updated on a slower timescale. We show that, in the full-information tabular setting, the proposed method achieves a finite-time last-iterate linear convergence to the quantal response equilibrium of the regularized problem, which translates to a sublinear convergence to the Nash equilibrium by controlling the amount of regularization. Our convergence results improve upon the best known iteration complexities, and lead to a better understanding of policy optimization in competitive Markov games.",https://openreview.net/pdf/d08b35cf66974eeaf9743746b69c38f772753301.pdf,{'abstract_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=bLmSMXbqXr,Quality-Similar Diversity via Population Based Reinforcement Learning,"['Shuang Wu', 'Jian Yao', 'Haobo Fu', 'Ye Tian', 'Chao Qian', 'Yaodong Yang', 'QIANG FU', 'Yang Wei']","['~Shuang_Wu3', '~Jian_Yao7', '~Haobo_Fu2', '~Ye_Tian1', '~Chao_Qian1', '~Yaodong_Yang1', '~QIANG_FU8', '~Yang_Wei2']","['quality diversity', 'reinforcement learning', 'user-defined', 'population']","Diversity is a growing research topic in Reinforcement Learning (RL). Previous research on diversity has mainly focused on promoting diversity to encourage exploration and thereby improve quality (the cumulative reward), maximizing diversity subject to quality constraints, or jointly maximizing quality and diversity, known as the quality-diversity problem. In this work, we present the quality-similar diversity problem that features diversity among policies of similar qualities. In contrast to task-agnostic diversity, we focus on task-specific diversity defined by a set of user-specified Behavior Descriptors (BDs). A BD is a scalar function of a trajectory (e.g., the fire action rate for an Atari game), which delivers the type of diversity the user prefers. To derive the gradient of the user-specified diversity with respect to a policy, which is not trivially available, we introduce a set of BD estimators and connect it with the classical policy gradient theorem. Based on the diversity gradient, we develop a population-based RL algorithm to adaptively and efficiently optimize the population diversity at multiple quality levels throughout training. Extensive results on MuJoCo and Atari demonstrate that our algorithm significantly outperforms previous methods in terms of generating user-specified diverse policies across different quality levels.",https://openreview.net/pdf/d8f5cd723fc580efed10ef08df13eda8c3ad877f.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=bHpOeIXvSX2,On the Interplay Between Misspecification and Sub-optimality Gap: From Linear Contextual Bandits to Linear MDPs,"['Weitong Zhang', 'Jiafan He', 'Zhiyuan Fan', 'Quanquan Gu']","['~Weitong_Zhang2', '~Jiafan_He1', '~Zhiyuan_Fan1', '~Quanquan_Gu1']",[],"We study linear contextual bandits in the misspecified setting, where the expected reward function can be approximated by a linear function class up to a bounded misspecification level $\zeta>0$. We propose an algorithm based on a novel data selection scheme, which only selects the contextual vectors with large uncertainty for online regression. We show that, when the misspecification level $\zeta$ is dominated by $\tilde O(\Delta / \sqrt{d})$ with $\Delta$ being the minimal sub-optimality gap and $d$ being the dimension of the contextual vectors, our algorithm enjoys the same gap-dependent regret bound $\tilde O ({d^2} /{\Delta})$ as in the well-specified setting up to logarithmic factors. Together with a lower bound adapted from Du et al. (2019); Lattimore et al.(2020), our result suggests an interplay between misspecification level and the sub-optimality gap: (1) the linear contextual bandit model is efficiently learnable when $\zeta \leq \tilde O({\Delta} / \sqrt{d})$; and (2) it is not efficiently learnable when $\zeta \geq \tilde \Omega({\Delta} / {\sqrt{d}})$. We also extend our algorithm to reinforcement learning with linear Markov decision processes (linear MDPs), and obtain a parallel result of gap-dependent regret. Experiments on both synthetic and real-world datasets corroborate our theoretical results.",https://openreview.net/pdf/630e09ff71ed6b7b040ca735961cb4f96d47dd32.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=aKcS3xojnwY,GEASS: Neural causal feature selection for high-dimensional biological data,"['Mingze Dong', 'Yuval Kluger']","['~Mingze_Dong1', '~Yuval_Kluger1']","['Granger causality', 'feature selection', 'neural networks', 'single-cell genomics', 'spatial transcriptomics']","Identifying nonlinear causal relationships in high-dimensional biological data is an important task. However, current neural network based causality detection approaches for such data suffer from poor interpretability and cannot scale well to the high dimensional regime. Here we present GEASS (Granger fEAture Selection of Spatiotemporal data), which identifies sparse Granger causality mechanisms of high dimensional spatiotemporal data by a single neural network. GEASS maximizes sparsity-regularized modified transfer entropy with a theoretical guarantee of recovering features with spatial/temporal Granger causal relationships. The sparsity regularization is achieved by a novel combinatorial stochastic gate layer to select sparse non-overlapping feature subsets. We demonstrate the efficacy of GEASS in several synthetic datasets and real biological data from single-cell RNA sequencing and spatial transcriptomics.",https://openreview.net/pdf/cae8ae2947fab56338cdfefd11f686b7a431f9f7.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=aCQt_BrkSjC,Learning Hyper Label Model for Programmatic Weak Supervision,"['Renzhi Wu', 'Shen-En Chen', 'Jieyu Zhang', 'Xu Chu']","['~Renzhi_Wu1', '~Shen-En_Chen2', '~Jieyu_Zhang1', '~Xu_Chu2']","['Programmatic Weak Supervision', 'Data Programming', 'Label Model']","To reduce the human annotation efforts, the programmatic weak supervision (PWS) paradigm abstracts weak supervision sources as labeling functions (LFs) and involves a label model to aggregate the output of multiple LFs to produce training labels. Most existing label models require a parameter learning step for each dataset. In this work, we present a hyper label model that (once learned) infers the ground-truth labels for each dataset in a single forward pass without dataset-specific parameter learning. The hyper label model approximates an optimal analytical (yet computationally intractable) solution of the ground-truth labels. We train the model on synthetic data generated in the way that ensures the model approximates the analytical optimal solution, and build the model upon Graph Neural Network (GNN) to ensure the model prediction being invariant (or equivariant) to the permutation of LFs (or data points). On 14 real-world datasets, our hyper label model outperforms the best existing methods in both accuracy (by 1.4 points on average) and efficiency (by six times on average). Our code is available at https://github.com/wurenzhi/hyper_label_model",https://openreview.net/pdf/1d4db3190f142ad660f267b6ac768334b52564af.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=_tIZQEMcWyv,Adaptive Gradient Methods with Local Guarantees,"['Zhou Lu', 'Wenhan Xia', 'Sanjeev Arora', 'Elad Hazan']","['~Zhou_Lu1', '~Wenhan_Xia1', '~Sanjeev_Arora1', '~Elad_Hazan1']",[],"Adaptive gradient methods are the method of choice for optimization in machine learning and used to train the largest deep models. In this paper we study the problem of learning a local preconditioner, that can change as the data is changing along the optimization trajectory. We propose an adaptive gradient method that has provable adaptive regret guarantees vs. the best local preconditioner. To derive this guarantee, we prove a new adaptive regret bound in online learning that improves upon previous adaptive online learning methods. 
We demonstrate the robustness of our method in automatically choosing the optimal learning rate schedule for popular benchmarking tasks in vision and language domains. Without the need to manually tune a learning rate schedule, our method can, in a single run, achieve comparable and stable task accuracy as a fine-tuned optimizer.",https://openreview.net/pdf/f5305a9cb2bcd3cd13cfc6e43cc7ef0ce185d9c2.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=_qVhsWyWB9,"Deep Learning From Crowdsourced Labels: Coupled Cross-Entropy Minimization, Identifiability, and Regularization","['Shahana Ibrahim', 'Tri Nguyen', 'Xiao Fu']","['~Shahana_Ibrahim1', '~Tri_Nguyen2', '~Xiao_Fu1']","['deep learning', 'learning under noisy labels', 'neural classifier', 'end-to-end learning', 'crowdsourcing']","Using noisy crowdsourced labels from multiple annotators, a deep learning-based end-to-end (E2E) system aims to learn the label correction mechanism and the neural classifier simultaneously. To this end, many E2E systems concatenate the neural classifier with multiple annotator-specific label confusion layers and co-train the two parts in a parameter-coupled manner. The formulated coupled cross-entropy minimization (CCEM)-type criteria are intuitive and work well in practice. Nonetheless, theoretical understanding of the CCEM criterion has been limited. The contribution of this work is twofold: First, performance guarantees of the CCEM criterion are presented. Our analysis reveals for the first time that the CCEM can indeed correctly identify the annotators' confusion characteristics and the desired ``ground-truth'' neural classifier under realistic conditions, e.g., when only incomplete annotator labeling and finite samples are available. Second, based on the insights learned from our analysis, two regularized variants of the CCEM are proposed.  The regularization terms provably enhance the identifiability of the target model parameters in various more challenging cases. A series of synthetic and real data experiments are presented to showcase the effectiveness of our approach.",https://openreview.net/pdf/49ef61c9a86ec546eaf7789c562a056aff1ad491.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=_lPNXhQ4uvS,Atomized Deep Learning Models,"['Yi-Lin Tuan', 'Zih-Yun Chiu', 'William Yang Wang']","['~Yi-Lin_Tuan1', '~Zih-Yun_Chiu1', '~William_Yang_Wang2']",[],"Deep learning models often tackle the intra-sample structure, such as the order of words in a sentence and pixels in an image, but have not pay much attention to the inter-sample relationship. In this paper, we show that explicitly modeling the inter-sample structure to be more discretized can potentially help model's expressivity. We propose a novel method, Atom Modeling, that can discretize a continuous latent space by drawing an analogy between a data point and an {\it atom}, which is naturally spaced away from other atoms with distances depending on their intra structures. Specifically, we model each data point as an atom composed of electrons, protons, and neutrons and minimize the potential energy caused by the interatomic force among data points. Through experiments with qualitative analysis in our proposed Atom Modeling on synthetic and real datasets, we find that Atom Modeling can improve the performance by maintaining the inter-sample relation and can capture an interpretable intra-sample relation by mapping each component in a data point to electron/proton/neutron.",https://openreview.net/pdf/52c1437e83cf3f24210904f85b1db2d185c2ea4c.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=_j4ZUpoNO1e,NEW TRAINING FRAMEWORK FOR SPEECH ENHANCEMENT USING REAL NOISY SPEECH,"['Szu-Wei Fu', 'Cheng Yu', 'Yu Tsao', 'Vishak Gopal', 'Jayant Gupchup', 'Ross Cutler']","['~Szu-Wei_Fu1', '~Cheng_Yu3', '~Yu_Tsao1', 'vishak.gopal@microsoft.com', '~Jayant_Gupchup1', '~Ross_Cutler1']","['Speech enhancement', 'Quality prediction', 'Semi-supervised learning', 'Adversarially robust']","Recently, deep learning-based speech enhancement (SE) models have gained
significant improvements. However, the success is mainly based on using synthetic
training data created by adding clean speech with noise. On the other hand, in spite
of its large amount, real noisy speech is hard to be applied for SE model training
because of lack of its clean reference. In this paper, we propose a novel method
to utilize real noisy speech for SE model training based on a non-intrusive speech
quality prediction model. The SE model is trained through the guide of the quality
prediction model. We also find that a speech quality predictor with better accuracy
may not necessarily be an appropriate teacher to guide the SE model. In addition,
we show that if the quality prediction model is adversarially robust, then the
prediction model itself can also be served as a SE model by modifying the input
noisy speech through gradient backpropagation. Objective experiment results show
that, under the same SE model structure, the proposed new training method trained
on a large amount of real noisy speech can outperform the conventional supervised
model trained on synthetic noisy speech. Lastly, the two training methods can be
combined to utilize both benefits of synthetic noisy speech (easy to learn) and real
noisy speech (large amount) to form semi-supervised learning which can further
boost the performance both objectively and subjectively. The code will be released
after publication.",https://openreview.net/pdf/ae110c0ecbfaa6ca123e7bbd77465d98bd280e95.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=_d2f3hRn0hT,Single-level Adversarial Data Synthesis based on Neural Tangent Kernels,"['Yu-Rong Zhang', 'Reddy Su', 'Sheng-Yen Chou', 'Shan-Hung Wu']","['~Yu-Rong_Zhang1', '~Reddy_Su1', '~Sheng-Yen_Chou1', '~Shan-Hung_Wu1']","['Adversarial', 'Data Synthesis', 'Neural Tangent Kernels']","Generative adversarial networks (GANs) have achieved impressive performance in data synthesis and have driven the development of many applications. How- ever, GANs are known to be hard to train due to their bilevel objective, which leads to the problems of convergence, mode collapse, and gradient vanishing. In this paper, we propose a new generative model called the generative adversarial NTK (GA-NTK) that has a single-level objective. The GA-NTK keeps the spirit of adversarial learning (which helps generate plausible data) while avoiding the training difficulties of GANs. This is done by modeling the discriminator as a Gaussian process with a neural tangent kernel (NTK-GP) whose training dynam- ics can be completely described by a closed-form formula. We analyze the conver- gence behavior of GA-NTK trained by gradient descent and give some sufficient conditions for convergence. We also conduct extensive experiments to study the advantages and limitations of GA-NTK and propose some techniques that make GA-NTK more practical.",https://openreview.net/pdf/1bff923193249d356324a448be8c46945ace0df0.pdf,{'title_filter': 'Data Synthesis'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=_-FN9mJsgg,Improving Object-centric Learning with Query Optimization,"['Baoxiong Jia', 'Yu Liu', 'Siyuan Huang']","['~Baoxiong_Jia1', '~Yu_Liu26', '~Siyuan_Huang2']",['unsupervised object-centric learning'],"The ability to decompose complex natural scenes into meaningful object-centric abstractions lies at the core of human perception and reasoning. In the recent culmination of unsupervised object-centric learning, the Slot-Attention module has played an important role with its simple yet effective design and fostered many powerful variants. These methods, however, have been exceedingly difficult to train
without supervision and are ambiguous in the notion of object, especially for complex natural scenes. In this paper, we propose to address these issues by investigating the potential of learnable queries as initializations for Slot-Attention learning, uniting it with efforts from existing attempts on improving Slot-Attention learning with bi-level optimization. With simple code adjustments on Slot-Attention, our model, Bi-level Optimized Query Slot Attention, achieves state-of-the-art results on 3 challenging synthetic and 7 complex real-world datasets in unsupervised image segmentation and reconstruction, outperforming previous baselines by a large margin. We provide thorough ablative studies to validate the necessity and effectiveness of our design. Additionally, our model exhibits great potential for concept binding and zero-shot learning. Our work is made publicly available at https://bo-qsa.github.io.",https://openreview.net/pdf/d5ec9ca4a9c3d9b9a0b66373194a2f787d2e515c.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=ZzdBhtEH9yB,Implicit regularization in Heavy-ball momentum accelerated stochastic gradient descent,"['Avrajit Ghosh', 'He Lyu', 'Xitong Zhang', 'Rongrong Wang']","['~Avrajit_Ghosh1', '~He_Lyu1', '~Xitong_Zhang1', '~Rongrong_Wang1']",[],"It is well known that the finite step-size ($h$) in Gradient descent (GD) implicitly regularizes solutions to flatter minimas. A natural question to ask is \textit{Does the momentum parameter $\beta$ (say) play a role in implicit regularization in Heavy-ball (H.B) momentum accelerated gradient descent (GD+M)?}. To answer this question, first, we show that  the trajectory traced by discrete H.B momentum update (GD+M) is $O(h^2)$ close to a continuous trajectory induced by a modified loss, which consists of an original loss and an implicit regularizer. This implicit regularizer for (GD+M) is indeed stronger than that of (GD) by factor of $(\frac{1+\beta}{1-\beta})$, thus explaining why (GD+M) shows better generalization performance and higher test accuracy than (GD). Furthermore, we extend our analysis to stochastic version of gradient descent with momentum (SGD+M) and propose a deterministic continuous trajectory that is $O(h^2)$ close to the discrete update of (SGD+M) in a strong approximation sense. We explore the implicit regularization in (SGD+M) and (GD+M) through a series of experiments validating our theory. ",https://openreview.net/pdf/dbc1161118a53cfa8a20ab379843b210af71728b.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=ZrEbzL9eQ3W,Scaling Laws for a Multi-Agent Reinforcement Learning Model,"['Oren Neumann', 'Claudius Gros']","['~Oren_Neumann1', 'gros@itp.uni-frankfurt.de']","['Neural scaling laws', 'Multi-agent reinforcement learning', 'AlphaZero']","The recent observation of neural power-law scaling relations has made a significant impact in the field of deep learning. A substantial amount of attention has been dedicated as a consequence to the description of scaling laws, although mostly for supervised learning and only to a reduced extent for reinforcement learning frameworks. In this paper we present an extensive study of performance scaling for a cornerstone reinforcement learning algorithm, AlphaZero. On the basis of a relationship between Elo rating, playing strength and power-law scaling, we train AlphaZero agents on the games Connect Four and Pentago and analyze their performance. We find that player strength scales as a power law in neural network parameter count when not bottlenecked by available compute, and as a power of compute when training optimally sized agents. We observe nearly identical scaling exponents for both games. Combining the two observed scaling laws we obtain a power law relating optimal size to compute similar to the ones observed for language models. We find that the predicted scaling of optimal neural network size fits our data for both games. This scaling law implies that previously published state-of-the-art game-playing models are significantly smaller than their optimal size, given the respective compute budgets. We also show that large AlphaZero models are more sample efficient, performing better than smaller models with the same amount of training data.",https://openreview.net/pdf/f98ab0085243b503d56efc920c90c19b95dc7ec8.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Zob4P9bRNcK,Learning Cut Selection for Mixed-Integer Linear Programming via Hierarchical Sequence Model,"['Zhihai Wang', 'Xijun Li', 'Jie Wang', 'Yufei Kuang', 'Mingxuan Yuan', 'Jia Zeng', 'Yongdong Zhang', 'Feng Wu']","['~Zhihai_Wang1', '~Xijun_Li1', '~Jie_Wang1', '~Yufei_Kuang1', '~Mingxuan_Yuan1', '~Jia_Zeng1', '~Yongdong_Zhang2', '~Feng_Wu1']","['mixed-integer linear programming', 'cut selection', 'deep reinforcement learning', 'sequence to sequence learning']","Cutting planes (cuts) are important for solving mixed-integer linear programs (MILPs), which formulate a wide range of important real-world applications. Cut selection---which aims to select a proper subset of the candidate cuts to improve the efficiency of solving MILPs---heavily depends on (P1) which cuts should be preferred, and (P2) how many cuts should be selected. Although many modern MILP solvers tackle (P1)-(P2) by manually designed heuristics, machine learning offers a promising approach to learn more effective heuristics from MILPs collected from specific applications. However, many existing learning-based methods focus on learning which cuts should be preferred, neglecting the importance of learning the number of cuts that should be selected. Moreover, we observe from extensive empirical results that (P3) what order of selected cuts should be preferred has a significant impact on the efficiency of solving MILPs as well. To address this challenge, we propose a novel hierarchical sequence model (HEM) to learn cut selection policies via reinforcement learning. Specifically, HEM consists of a two-level model: (1) a higher-level model to learn the number of cuts that should be selected, (2) and a lower-level model---that formulates the cut selection task as a sequence to sequence learning problem---to learn policies selecting an ordered subset with the size determined by the higher-level model. To the best of our knowledge, HEM is the first method that can tackle (P1)-(P3) in cut selection simultaneously from a data-driven perspective. Experiments show that HEM significantly improves the efficiency of solving MILPs compared to human-designed and learning-based baselines on both synthetic and large-scale real-world MILPs, including MIPLIB 2017. Moreover, experiments demonstrate that HEM well generalizes to MILPs that are significantly larger than those seen during training.",https://openreview.net/pdf/6885b5f02c9a39764dee43349192398b48a69fd5.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=ZZCJv2biATn,Target Conditioned Representation Independence (TCRI); from Domain-Invariant to Domain-General Representations,"['Olawale Elijah Salaudeen', 'Oluwasanmi O Koyejo']","['~Olawale_Elijah_Salaudeen1', '~Oluwasanmi_O_Koyejo1']","['Domain Generalization', 'Out-of-distribution Generalization', 'Transfer Learning', 'Distribution Shift', 'Covariate Shift']","We propose a Target Conditioned Representation Independence (TCRI) objective for domain generalization. TCRI addresses the limitations of existing domain generalization methods due to incomplete constraints. Specifically, TCRI implements regularizers motivated by conditional independence constraints that are sufficient to strictly learn complete sets of invariant mechanisms, which we show are necessary and sufficient for domain generalization. Empirically, we show that TCRI is effective on both synthetic and real-world data. TCRI is competitive with baselines in average accuracy while outperforming them in worst-domain accuracy, indicating desired cross-domain stability.",https://openreview.net/pdf/c42fd0b1a918283db9e8ad1e5441d9efd2339543.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=ZS8L3Fbv-L,The Value of Out-of-distribution Data,"['Ashwin De Silva', 'Rahul Ramesh', 'Carey Priebe', 'Pratik Chaudhari', 'Joshua T Vogelstein']","['~Ashwin_De_Silva1', '~Rahul_Ramesh2', '~Carey_Priebe1', '~Pratik_Chaudhari1', '~Joshua_T_Vogelstein1']","['Distribution Shift', 'Learning Theory']","More data is expected to help us generalize to a task. But real datasets can contain out-of-distribution (OOD) data; this can come in the form of heterogeneity such as intra-class variability but also in the form of temporal shifts or concept drifts. We demonstrate a counter-intuitive phenomenon for such problems: generalization error of the task can be a non-monotonic function of the number of OOD samples; a small number of OOD samples can improve generalization but if the number of OOD samples is beyond a threshold, then the generalization error can deteriorate. We also show that if we know which samples are OOD, then using a weighted objective between the target and OOD samples ensures that the generalization error decreases monotonically. We demonstrate and analyze this phenomenon using linear classifiers on synthetic datasets and medium-sized neural networks on vision benchmarks such as MNIST, CIFAR-10, CINIC-10, PACS, and DomainNet, and observe the effect data augmentation, hyperparameter optimization, and pre-training have on this behavior. ",https://openreview.net/pdf/2a040acaed5593c005905e432e20f78733547ae3.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=ZBUthI6wK9h,Robust Scheduling with GFlowNets,"['David W Zhang', 'Corrado Rainone', 'Markus Peschl', 'Roberto Bondesan']","['~David_W_Zhang1', '~Corrado_Rainone1', 'mpeschl@qti.qualcomm.com', '~Roberto_Bondesan1']","['Scheduling', 'GFlowNets', 'Combinatorial Optimization']","Finding the best way to schedule operations in a computation graph is a classical NP-hard problem which is central to compiler optimization. However, evaluating the goodness of a schedule on the target hardware can be very time-consuming. Traditional approaches as well as previous machine learning ones typically optimize proxy metrics, which are fast to evaluate but can lead to bad schedules when tested on the target hardware. In this work, we propose a new approach to scheduling by sampling proportionally to the proxy metric using a novel GFlowNet method. We introduce a technique to control the trade-off between diversity and goodness of the proposed schedules at inference time and demonstrate empirically that the pure optimization baselines can lead to subpar performance with respect to our approach when tested on a target model. Furthermore, we show that conditioning the GFlowNet on the computation graph enables generalization to unseen scheduling problems for both synthetic and real-world compiler datasets.",https://openreview.net/pdf/194aa63ea4f72f9cbdb927436fcd60b93e807444.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Z4lOwCEJQ8Z,Training Normalizing Flows from Dependent Data,"['Matthias Kirchler', 'Christoph Lippert', 'Marius Kloft']","['~Matthias_Kirchler1', '~Christoph_Lippert1', '~Marius_Kloft1']",['Normalizing Flows'],"Normalizing flows are powerful non-parametric statistical models that function as a hybrid between density estimators and generative models. Current learning algorithms for normalizing flows assume that data points are sampled independently, an assumption that is frequently violated in practice, which may lead to erroneous density estimation and data generation. We propose a likelihood objective of normalizing flows incorporating dependencies between the data points, for which we derive a flexible and efficient learning algorithm suitable for different dependency structures. We show that respecting dependencies between observations can improve empirical results on both synthetic and real-world data.

",https://openreview.net/pdf/6a6216ea87352439b3c7c6325a6497e22a690f6e.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=YfUICnZMwk7,Weighted Clock Logic Point Process,"['Ruixuan Yan', 'Yunshi Wen', 'Debarun Bhattacharjya', 'Ronny Luss', 'Tengfei Ma', 'Achille Fokoue', 'Anak Agung Julius']","['~Ruixuan_Yan1', 'weny2@rpi.edu', '~Debarun_Bhattacharjya1', '~Ronny_Luss1', '~Tengfei_Ma1', '~Achille_Fokoue1', '~Anak_Agung_Julius1']","['Multivariate event data', 'Neuro-symbolic models', 'Temporal point process', 'Propositional logic']","Datasets involving multivariate event streams are prevalent in numerous applications. We present a novel framework for modeling temporal point processes called clock logic neural networks (CLNN) which learn weighted clock logic (wCL) formulas as interpretable temporal rules by which some events promote or inhibit other events. Specifically, CLNN models temporal relations between events using conditional intensity rates informed by a set of wCL formulas, which are more expressive than related prior work. Unlike conventional approaches of searching for generative rules through expensive combinatorial optimization, we design smooth activation functions for components of wCL formulas that enable a continuous relaxation of the discrete search space and efficient learning of wCL formulas using gradient-based methods. Experiments on synthetic datasets manifest our model's ability to recover the ground-truth rules and improve computational efficiency. In addition, experiments on real-world datasets show that our models perform competitively when compared with state-of-the-art models. ",https://openreview.net/pdf/eb9a99d990427c8b4ac5187f36e3bf4c618b20bf.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=YdFkY-QHkPl,Provably Learning Diverse Features in Multi-View Data with Midpoint Mixup,"['Muthu Chidambaram', 'Xiang Wang', 'Chenwei Wu', 'Rong Ge']","['~Muthu_Chidambaram1', '~Xiang_Wang1', '~Chenwei_Wu1', '~Rong_Ge1']","['mixup', 'data augmentation', 'theory', 'optimization', 'multi-view', 'feature learning', 'generalization', 'deep learning']","Mixup is a data augmentation technique that relies on training using random convex combinations of data points and their labels. In recent years, Mixup has become a standard primitive used in the training of state-of-the-art image classification models due to its demonstrated benefits over empirical risk minimization with regards to generalization and robustness. In this work, we try to explain some of this success from a feature learning perspective. We focus our attention on classification problems in which each class may have multiple associated features (or views) that can be used to predict the class correctly. Our main theoretical results demonstrate that, for a non-trivial class of data distributions with two features per class, training a 2-layer convolutional network using empirical risk minimization can lead to learning only one feature for almost all classes while training with a specific instantiation of Mixup succeeds in learning both features for every class. We also show empirically that these theoretical insights extend to the practical settings of image benchmarks modified to have additional synthetic features.",https://openreview.net/pdf/9df8ff47ef9647935015f25d7345b30473336380.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Whf5OGxibGR,Causal discovery from conditionally stationary time series,"['Carles Balsells Rodas', 'Ruibo Tu', 'Hedvig Kjellstrom', 'Yingzhen Li']","['~Carles_Balsells_Rodas1', '~Ruibo_Tu1', '~Hedvig_Kjellstrom1', '~Yingzhen_Li1']","['causal discovery', 'temporal data', 'graph neural network', 'time series', 'non-stationary', 'probabilistic modelling']","Causal discovery, i.e., inferring underlying causal relationships from observational data, has been shown to be highly challenging for AI systems. In time series modeling context, traditional causal discovery methods mainly consider constrained scenarios with fully observed variables and/or data from stationary time-series. We develop a causal discovery approach to handle a wide class of non-stationary time-series that are conditionally stationary, where the non-stationary behaviour is modeled as stationarity conditioned on a set of (possibly hidden) state variables. Named state-dependent causal inference (SDCI), our approach is able to recover the underlying causal dependencies, provably with fully-observed states and empirically with hidden states. The latter is confirmed by experiments on synthetic linear system and nonlinear particle interaction data, where SDCI achieves superior performance over baseline causal discovery methods. Improved results over non-causal RNNs on modeling NBA player movements demonstrate the potential of our method and motivate the use causality-driven methods for forecasting.",https://openreview.net/pdf/46b3e389e9891387fa794849be72a7ac46cec7ac.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=WbyWDWoXD3,Feint in Multi-Player Games,"['Junyu Liu', 'Wangkai Jin', 'Xiangjun Peng']","['~Junyu_Liu5', '~Wangkai_Jin1', '~Xiangjun_Peng1']","['Feint', 'Multi-Player Games']","This paper introduces the first formalization, implementation and quantitative evaluation of \feint in Multi-Player Games. Our work first formalizes \feint from the perspective of Multi-Player Games, in terms of the temporal, spatial and their collective impacts. The formalization is built upon \textit{Non-transitive Active Markov Game Model}, where \feint can have a considerable amount of impacts. Then, our work considers practical implementation details of \feint in Multi-Player Games, under the state-of-the-art progress of multi-agent modeling to date (namely Multi-Agent Reinforcement Learning). Finally, our work quantitatively examines the effectiveness of our design, and the results show that our design of Feint can (1) greatly improve the reward gains from the game; (2) significantly improve the diversity of Multi-Player Games; and (3) only incur negligible overheads in terms of time consumption. We conclude that our design of Feint is effective and practical, to make Multi-Player Games more interesting.",https://openreview.net/pdf/8f3d206a3499ff07ce036109c750a257444d22a8.pdf,{'abstract_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=WOquZTLCBO1,VIPeR: Provably Efficient Algorithm for Offline RL with Neural Function Approximation,"['Thanh Nguyen-Tang', 'Raman Arora']","['~Thanh_Nguyen-Tang1', '~Raman_Arora1']","['Offline Reinforcement Learning', 'Neural Networks']","We propose a novel algorithm for offline reinforcement learning called Value Iteration with Perturbed Rewards (VIPeR), which amalgamates the pessimism principle with random perturbations of the value function. Most current offline RL algorithms explicitly construct statistical confidence regions to obtain pessimism via lower confidence bounds (LCB), which cannot easily scale to complex problems where a neural network is used to estimate the value functions. Instead, VIPeR implicitly obtains pessimism by simply perturbing the offline data multiple times with carefully-designed i.i.d. Gaussian noises to learn an ensemble of estimated state-action {value functions} and acting greedily with respect to the minimum of the ensemble. The estimated state-action values are obtained by fitting a parametric model (e.g., neural networks) to the perturbed datasets using gradient descent. As a result, VIPeR only needs $\mathcal{O}(1)$ time complexity for action selection, while LCB-based algorithms require at least $\Omega(K^2)$, where $K$ is the total number of trajectories in the offline data. We also propose a novel data-splitting technique that helps remove a factor involving the log of the covering number in our bound. We prove that VIPeR yields a provable uncertainty quantifier with overparameterized neural networks and enjoys a bound on sub-optimality of $\tilde{\mathcal{O}}(  { \kappa H^{5/2}  \tilde{d} }/{\sqrt{K}})$, where $\tilde{d}$ is the effective dimension, $H$ is the horizon length and $\kappa$ measures the distributional shift. We corroborate the statistical and computational efficiency of VIPeR with an empirical evaluation on a wide set of synthetic and real-world datasets. To the best of our knowledge, VIPeR is the first algorithm for offline RL that is provably efficient for general Markov decision processes (MDPs) with neural network function approximation. ",https://openreview.net/pdf/9a8eb48070ffcd0332fa35d7aaa9229cea1438c4.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=WL8FlAugqQ,Neural DAG Scheduling via One-Shot Priority Sampling,"['Wonseok Jeon', 'Mukul Gagrani', 'Burak Bartan', 'Weiliang Will Zeng', 'Harris Teague', 'Piero Zappi', 'Christopher Lott']","['~Wonseok_Jeon1', '~Mukul_Gagrani2', '~Burak_Bartan1', '~Weiliang_Will_Zeng1', '~Harris_Teague1', 'pzappi@qti.qualcomm.com', '~Christopher_Lott1']","['Combinatorial Optimization', 'Directed Acyclic Graph', 'Scheduling', 'Graph Neural Network', 'Reinforcement Learning']","We consider the problem of scheduling operations/nodes, the dependency among which is characterized by a Directed Acyclic Graph (DAG). Due to its NP-hard nature, heuristic algorithms were traditionally used to acquire reasonably good solutions, and more recent works have proposed Machine Learning (ML) heuristics that can generalize to unseen graphs and outperform the non-ML heuristics. However, it is computationally costly to generate solutions using existing ML schedulers since they adopt the episodic reinforcement learning framework that necessitates multi-round neural network processing. We propose a novel ML scheduler that uses a one-shot neural network encoder to sample node priorities which are converted by list scheduling to the final schedules. Since the one-shot encoder can efficiently sample the priorities in parallel, our algorithm runs significantly faster than existing ML baselines and has comparable run time with the fast traditional heuristics. We empirically show that our algorithm generates better schedules than both non-neural and neural baselines across various real-world and synthetic scheduling tasks.",https://openreview.net/pdf/20210ea69d6b5ccead90b146eeb53cf34ed79f34.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=WF7dU23lRCo,A $2$-parameter Persistence Layer for Learning,"['Cheng Xin', 'Soham Mukherjee', 'Shreyas N. Samaga', 'Tamal K. Dey']","['~Cheng_Xin2', '~Soham_Mukherjee1', '~Shreyas_N._Samaga1', '~Tamal_K._Dey1']","['topological data analysis', 'graph representation', 'persistent homology', '2-parameter persistence', 'graph neural network']","$1$-parameter persistent homology, a cornerstone in Topological Data Analysis (TDA), studies the evolution of topological features such as cycle basis hidden in data. It has found its application in strengthening the representation power of deep learning models like Graph Neural Networks (GNN). To enrich the representations of topological features,  here we propose to study $2$-parameter persistence modules induced by bi-filtration functions. In order to incorporate these representations into machine learning models, we introduce a novel vectorization on $2$-parameter persistence modules called Generalized Rank Invariant Landscape {\textsc{Gril}}. We show that this vector representation is stable and differentiable with respect to underlying filtration functions and can be easily integrated into machine learning models to augment encoding topological features. We present an algorithm to compute the vectorization and its gradients. We also test our methods on synthetic graph datasets and compare the results with some popular graph neural networks.",https://openreview.net/pdf/46ed6a698d545f9875361a36b2245291559665d4.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=WA35e2vPlFT,Neural Implicit Manifold Learning for Topology-Aware Generative Modelling,"['Brendan Leigh Ross', 'Gabriel Loaiza-Ganem', 'Anthony L. Caterini', 'Jesse C Cresswell']","['~Brendan_Leigh_Ross1', '~Gabriel_Loaiza-Ganem1', '~Anthony_L._Caterini1', '~Jesse_C_Cresswell1']","['Manifold Learning', 'Unsupervised Learning', 'Density Estimation', 'Topology', 'Differential Geometry', 'Generative Modelling']","Natural data observed in $\mathbb{R}^n$ is often constrained to an $m$-dimensional manifold $\mathcal{M}$, where $m < n$. Current probabilistic models represent this manifold by mapping an $m$-dimensional latent variable through a neural network $f_\theta: \mathbb{R}^m \to \mathbb{R}^n$. Such procedures, which we call pushforward models, incur a straightforward limitation: manifolds cannot in general be represented with a single parameterization, meaning that attempts to do so will incur either computational instability or the inability to learn probability densities within the manifold. To remedy this problem, we propose to model $\mathcal{M}$ as a neural implicit manifold: the set of zeros of a neural network. To learn the data distribution within $\mathcal{M}$, we introduce constrained energy-based models, which use a constrained variant of Langevin dynamics to train and sample within a learned manifold. The resulting model can be manipulated with an arithmetic of manifolds, which allows practitioners to take unions and intersections of model manifolds. In experiments on synthetic and natural data, we show that constrained EBMs can learn manifold-supported distributions with complex topologies more accurately than pushforward models.",https://openreview.net/pdf/24f8008772887d2a345bebc8b5a675d77f5b064a.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Vo1MVffQED,Oracles and Followers: Stackelberg Equilibria in Deep Multi-Agent Reinforcement Learning,"['Matthias Gerstgrasser', 'David C. Parkes']","['~Matthias_Gerstgrasser1', '~David_C._Parkes1']","['Multi-Agent Reinforcement Learning', 'Game Theory', 'Security Games', 'Mechanism Design', 'Stackelberg Equilibrium', 'Indirect Mechanism Design']","Stackelberg equilibria arise naturally in a range of popular learning problems, such as in security games or indirect mechanism design, and have received in- creasing attention in the reinforcement learning literature. We present a general framework for implementing Stackelberg equilibria search as a multi-agent RL problem, allowing a wide range of algorithmic design choices. We discuss how previous approaches can be seen as specific instantiations of this framework. As a key insight, we note that the design space allows for approaches not previously seen in the literature, for instance by leveraging multitask and meta-RL techniques for follower convergence. We propose one such approach using contextual poli- cies and evaluate it experimentally on standard benchmark domains. Finally, we illustrate the effect of adopting designs outside the borders of our framework in controlled experiments.",https://openreview.net/pdf/13cece9567e53f9dfc4afb43faab46f604980177.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Vf6WcUDnY7c,Optimizing Spca-based Continual Learning: A Theoretical Approach,"['Chunchun Yang', 'Malik Tiomoko', 'Zengfu Wang']","['~Chunchun_Yang1', '~Malik_Tiomoko1', 'zfwang@ustc.edu.cn']","['continual learning', 'high dimensional statistics', 'machine learning theory']","Catastrophic forgetting and the stability-plasticity dilemma are two major obstacles to continual learning. In this paper we first propose a theoretical analysis of a SPCA-based continual learning algorithm using high dimensional statistics. Second, we design OSCL  (Optimized Spca-based Continual Learning) which builds on a flexible task optimization based on the theory. By optimizing a single task, catastrophic forgetting can be prevented theoretically. While optimizing multi-tasks, the trade-off between integrating knowledge from the new task and retaining previous knowledge of the old task can be achieved by assigning appropriate weights to corresponding tasks in compliance with the objectives. Experimental results confirm that the various theoretical conclusions are robust to a wide range of data distributions. Besides, several applications on synthetic and real data show that the proposed method while being computationally efficient, achieves comparable results with some state of the art.",https://openreview.net/pdf/a20ec8899b62b37efc84fd55afa5fc1c384cbb3a.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Vf2DK1Ol0ed,A Benchmark Dataset for Learning from Label Proportions,"['Anand Paresh Brahmbhatt', 'Mohith Pokala', 'Rishi Saket', 'Aravindan Raghuveer']","['~Anand_Paresh_Brahmbhatt1', '~Mohith_Pokala1', '~Rishi_Saket1', '~Aravindan_Raghuveer1']","['Learning from Label Proportions', 'Benchmark Dataset', 'LLP']","Learning from label proportions (LLP) has recently emerged as an important technique of weakly supervised learning on aggregated labels. In LLP, a model is trained on groups (a.k.a bags) of feature-vectors and their corresponding label proportions to predict labels for individual feature-vectors. While previous works have developed a variety of techniques for LLP, including novel loss functions, model architectures and their optimization, they typically evaluated their methods on pseudo-synthetically generated LLP training data using common small scale supervised learning datasets by randomly sampling or partitioning their instances into bags.  Despite growing interest in this important task there are no large scale open source LLP benchmarks to compare various approaches. Construction of such a benchmark is hurdled by two challenges a) lack of natural large scale LLP like data, b) large number of mostly artificial methods of forming bags from instance level datasets. 
In this paper we propose LLP-Bench: a large scale LLP benchmark constructed from   the Criteo Kaggle CTR dataset. We do an in-depth, systematic study of the Criteo dataset and propose a methodology to create a  benchmark as a collection of diverse and large scale LLP datasets. We choose the Criteo dataset since it admits multiple natural collections of bags formed by grouping  subsets of its 26 categorical features. We analyze all bag collections obtained through grouping by one or two categorical features, in terms of their bag-level statistics as well as embedding based distance metrics quantifying the geometric separation of bags. We then propose to include in LLP-Bench a few groupings to fairly represent real world bag distributions.
We also measure the performance of state of the art models, loss functions (adapted to LLP) and optimizers on LLP-Bench. We perform a series of ablations and explain the performance of various techniques  on LLP-Bench. To the best of our knowledge LLP-Bench is the first open source benchmark for the LLP task. We hope that the proposed benchmark and the evaluation methodology will be used by ML researchers and practitioners to better understand and hence devise state of art LLP algorithms. ",https://openreview.net/pdf/091a6ae3959a706a0135d23c9032fbae501e415d.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=VYaTFO2Myi5,Towards Controllable Policy through Goal-Masked Transformers,"['Xinyao Niu', 'Tong Sang', 'Yuchen Sun', 'Xiangjun Wang']","['~Xinyao_Niu1', '~Tong_Sang1', '~Yuchen_Sun1', '~Xiangjun_Wang1']",[],"Offline goal-conditioned supervised learning (GCSL) can learn to achieve various goals from purely offline datasets without reward information, enhancing control over the policy. However, we argue that learning a composite policy switchable among different goals seamlessly should be an essential task for obtaining a controllable policy. This feature should be learnable if the dataset contains enough data about such switches. Unfortunately, most existing datasets either partially or entirely lack such switching demonstrations. Current GCSL approaches that use hindsight information concentrate primarily on reachability at the state or return level. They might not work as expected when the goal is changed within an episode. To this end, we present Goal-Masked Transformers (GMT), an efficient GCSL algorithm based on transformers with goal masking. GMT makes use of trajectory-level hindsight information, which is automatically gathered and can be adjusted for various statistics of interest. Due to the autoregressive nature of GMT, we can change the goal and control the policy at any time. We empirically evaluate GMT on MuJoCo continuous control benchmarks and Atari discrete control games with image states to compare GMT against baselines. We illustrate that GMT can infer the missing switching processes from the given dataset and thus switch smoothly among different goals. As a result, GMT demonstrates its ability to control policy and succeeds on all the tasks with low variance, while existing GCSL works can hardly succeed in goal-switching.",https://openreview.net/pdf/b4514e1359fdafebf8abe27cda428e460f2a3cf6.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=VIwEYmMID9R,DPMAC: Differentially Private Communication for Cooperative Multi-Agent Reinforcement Learning,"['Canzhe Zhao', 'Yanjie Ze', 'Jing Dong', 'Baoxiang Wang', 'Shuai Li']","['~Canzhe_Zhao1', '~Yanjie_Ze1', '~Jing_Dong3', '~Baoxiang_Wang1', '~Shuai_Li3']","['Communication in deep multi-agent reinforcement learning', 'Deep multi-agent reinforcement learning', 'Differential privacy', 'Game theory']","Communication lays the foundation for cooperation in human society and in multi-agent reinforcement learning (MARL). Humans also desire to maintain their privacy when communicating with others, yet such privacy concern has not been considered in existing works in MARL. We propose the \textit{differentially private multi-agent communication} (DPMAC) algorithm, which protects the sensitive information of individual agents by equipping each agent with a local message sender with rigorous $(\epsilon, \delta)$-differential privacy (DP) guarantee. In contrast to directly perturbing the messages with predefined DP noise as commonly done in privacy-preserving scenarios, we adopt a stochastic message sender for each agent respectively and incorporate the DP requirement into the sender, which automatically adjusts the learned message distribution to alleviate the instability caused by DP noise. Further, we prove the existence of a Nash equilibrium in cooperative MARL with privacy-preserving communication, which suggests that this problem is game-theoretically learnable. Extensive experiments demonstrate a clear advantage of DPMAC over baseline methods in privacy-preserving scenarios.",https://openreview.net/pdf/9daeb42348ce59d12ca4cf4989941cbfffedcfcc.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=VILHmvACcR,Learning to perceive objects by prediction,"['Tushar Arora', 'JOHN DAY', 'Li Erran Li', 'Ming Bo Cai']","['~Tushar_Arora1', '~JOHN_DAY1', '~Li_Erran_Li1', '~Ming_Bo_Cai1']","['self supervised learning', 'predictive learning', 'object-centric representation', '3D perception', 'sensory grounding']","The representation of objects is the building block of higher-level concepts. Infants develop the notion of objects without supervision, for which the prediction error of future sensory input is likely a major teaching signal. We assume that the goal of representing objects distinctly is to allow the prediction of the coherent motion of all parts of an object independently from the background while keeping track of relatively fewer parameters of the object's motion. To realize this, we propose a framework to extract object-centric representations from single 2D images by learning to predict future scenes containing moving objects. The model learns to explicitly infer objects' locations in a 3D environment, generate 2D segmentation masks of objects, and perceive depth. Importantly, the model requires no supervision or pre-training but assumes rigid-body motion and only needs the observer's self-motion at training time. Further, by evaluating on a new synthetic dataset with more complex textures of objects and background, we found our model overcomes the reliance on clustering colors for segmenting objects, which is a limitation for previous models not using motion information. Our work demonstrates a new approach to learning symbolic representation grounded in sensation and action.",https://openreview.net/pdf/07bf7a9bb819a7e18997f00a905fdde03f665130.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=VE1s3e5xriA,Dual Student Networks for Data-Free Model Stealing,"['James Beetham', 'Navid Kardan', 'Ajmal Saeed Mian', 'Mubarak Shah']","['~James_Beetham1', '~Navid_Kardan1', '~Ajmal_Saeed_Mian1', '~Mubarak_Shah3']",[],"Data-free model stealing aims to replicate a target model without direct access to either the training data or the target model. To accomplish this, existing methods use a generator to produce samples in order to train a student model to match the target model outputs. To this end, the two main challenges are estimating gradients of the target model without access to its parameters, and generating a diverse set of training samples that thoroughly explores the input space. We propose a Dual Student method where two students are symmetrically trained in order to provide the generator a criterion to generate samples that the two students disagree on. On one hand, disagreement on a sample implies at least one student has classified the sample incorrectly when compared to the target model. This incentive towards disagreement implicitly encourages the generator to explore more diverse regions of the input space. On the other hand, our method utilizes gradients of student models to indirectly estimate gradients of the target model. We show that this novel training objective for the generator network is equivalent to optimizing a lower bound on the generator's loss if we had access to the target model gradients. In other words, our method alters the standard data-free model stealing paradigm by substituting the target model with a separate student model, thereby creating a lower bound which can be directly optimized without additional target model queries or separate synthetic datasets. We show that our new optimization framework provides more accurate gradient estimation of the target model and better accuracies on benchmark classification datasets. Additionally, our approach balances improved query efficiency with training computation cost. Finally, we demonstrate that our method serves as a better proxy model for transfer-based adversarial attacks than existing data-free model stealing methods.",https://openreview.net/pdf/41d38335bded64c06dfd2672ead107cdf3b3e2d9.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=V2BQvSIWnYD,Learning Arborescence with An Efficient Inference Algorithm,"['Nan Jiang', 'Maxwell J Jacobson', 'Yexiang Xue']","['~Nan_Jiang7', '~Maxwell_J_Jacobson1', '~Yexiang_Xue1']","['minimum weight arborescence', 'arborescence Learning']","We consider a class of structured learning problems on arborescence (i.e., the directed spanning tree) from the input graph. The key step involved in this problem is predicting the minimal weight arborescence (MWA) from the learned model. In literature, there are two lines of research for predicting MWA: the Chu-Liu Edmonds (CLE) and the Lovasz methods.  The CLE method is easy to implement while it takes $\mathcal{O}(n)$ cycle contractions. Here $n$ is the graph size.  The Lovasz method reduces to the multi-pair shortest path (MPSP) problem and takes only $\mathcal{O}(\log n)$ contractions. Nevertheless, in the CPU setting, MPSP has the same time complexity as finding MWA. The Lovasz method only attains time efficiency under a sufficient GPU setting. Both the aforementioned methods are painfully slow for large-scale learning tasks.  In this research, we find the general MPSP problem can be simplified when working with machine learning models. This is because the learning model predicts edge weights for all pairs of vertices and the graph we process is always complete.  Therefore, we only need to handle those paths that directly enter every weakly connected component (WCC) while the classic Lovasz method needs to handle all possible paths. This allows us to propose LAzy LoVAz (Lava) method that enjoys $\mathcal{O}(\log n)$ contractions as well as efficient performance in both CPU and GPU settings. In experiments, we consider synthetic datasets and two real-world learning tasks, i.e., graph-based dependency parsing and unsupervised parsing on ListOps.  The empirical results exhibit important gains of our Lava method to the classic CLE and Lovasz methods, that Lava boosts the training time for arborescence learning tasks.",https://openreview.net/pdf/bc40b11773f87e44c9cbaad664670bd51ad5bf49.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Uzgfy7_v7BH,Causal Mean Field Multi-Agent Reinforcement Learning,"['Hao Ma', 'Zhiqiang Pu', 'Yi Pan', 'Boyin Liu', 'Min Chen', 'Shijie Wang']","['~Hao_Ma5', '~Zhiqiang_Pu1', 'yi.pan@ia.ac.cn', '~Boyin_Liu2', 'chenmin161@mails.ucas.ac.cn', 'shijie.wang2022@outlook.com']","['multi-agent reinforcement mearning', 'causal inference']","Scalability remains a challenge in multi-agent reinforcement learning and is currently under active research. However, existing works lack the ability to identify the essential interaction under the non-stationary environment. We propose causal mean field Q-learning (CMFQ) to address this problem. It has the advantage of MFQ, which can compress the space size dramatically. Besides, it is ever more robust toward the non-stationary caused by increasing agents. We enable agents to identify which ally or opponent is more crucial by asking ""what if"" with the help of the structural causal model (SCM), then pay more attention to more crucial ones. We test CMFQ in mixed cooperative-competitive and cooperative games, which verify our method's scalability performance.",https://openreview.net/pdf/f63600d93314ac2fbf21e84d755a6a063521277e.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=UrzBg1Zz7ob,Towards a More Rigorous Science of Blindspot Discovery in Image Models,"['Gregory Plumb', 'Nari Johnson', 'Angel Cabrera', 'Ameet Talwalkar']","['~Gregory_Plumb2', '~Nari_Johnson1', '~Angel_Cabrera1', '~Ameet_Talwalkar1']",[],"A growing body of work studies Blindspot Discovery Methods (BDMs): methods for finding semantically meaningful subsets of the data where an image classifier performs significantly worse, without making strong assumptions. Motivated by observed gaps in prior work, we introduce a new framework for evaluating BDMs, SpotCheck, that uses synthetic image datasets to train models with known blindspots and a new BDM, PlaneSpot, that uses a 2D image representation. We use SpotCheck to run controlled experiments that identify factors that influence BDM performance (e.g., the number of blindspot in a model) and show that PlaneSpot outperforms existing BDMs. Importantly, we validate these findings using real data. Overall, we hope that the methodology and analyses presented in this work will serve as a guide for future work on blindspot discovery.",https://openreview.net/pdf/51d998560ec0d5bb53370e7bc09f768675b6001b.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=UmU9mydWRV3,Neural DAEs: Constrained neural networks,"['Tue Boesen', 'Eldad Haber', 'Uri M. Ascher']","['~Tue_Boesen1', '~Eldad_Haber3', 'ascher@cs.ubc.ca']","['neural networks', 'differential algebraic equations', 'constraints']","In this article we investigate the effect of explicitly adding auxiliary trajectory information to neural networks for dynamical systems. We draw inspiration from the field of differential-algebraic equations and differential equations on manifolds and implement similar methods in residual neural networks. We discuss constraints through stabilization as well as projection methods, and show when to use which method based on experiments involving simulations of multi-body pendulums and molecular dynamics scenarios. Several of our methods are easy to implement in existing code and have limited impact on performance while giving significant boosts in terms of inference.",https://openreview.net/pdf/31a8d71c7983fafb342736a1828d1de79007f0f0.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=UkU05GOH7_6,Generating Diverse Cooperative Agents by Learning Incompatible Policies,"['Rujikorn Charakorn', 'Poramate Manoonpong', 'Nat Dilokthanakul']","['~Rujikorn_Charakorn1', '~Poramate_Manoonpong1', '~Nat_Dilokthanakul1']","['multi-agent systems', 'cooperation', 'collaboration', 'reinforcement learning', 'diversity', 'robustness']","Training a robust cooperative agent requires diverse partner agents. However, obtaining those agents is difficult. Previous works aim to learn diverse behaviors by changing the state-action distribution of agents. But, without information about the task's goal, the diversified agents are not guided to find other important, albeit sub-optimal, solutions: the agents might learn only variations of the same solution. In this work, we propose to learn diverse behaviors via policy compatibility. Conceptually, policy compatibility measures whether policies of interest can coordinate effectively. We theoretically show that incompatible policies are not similar. Thus, policy compatibility—which has been used exclusively as a measure of robustness—can be used as a proxy for learning diverse behaviors. Then, we incorporate the proposed objective into a population-based training scheme to allow concurrent training of multiple agents. Additionally, we use state-action information to induce local variations of each policy. Empirically, the proposed method consistently discovers more solutions than baseline methods across various multi-goal cooperative environments. Finally, in multi-recipe Overcooked, we show that our method produces populations of behaviorally diverse agents, which enables generalist agents trained with such a population to be more robust.

See our project page at https://bit.ly/marl-lipo
",https://openreview.net/pdf/ac9e4f47a8a7afc2d31fe69575bb97700dd88071.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=UYS38ssi1M,Learning GFlowNets from partial episodes for improved convergence and stability,"['Kanika Madan', 'Jarrid Rector-Brooks', 'Maksym Korablyov', 'Emmanuel Bengio', 'Moksh Jain', 'Andrei Cristian Nica', 'Tom Bosc', 'Yoshua Bengio', 'Nikolay Malkin']","['~Kanika_Madan3', '~Jarrid_Rector-Brooks2', '~Maksym_Korablyov1', '~Emmanuel_Bengio1', '~Moksh_Jain1', '~Andrei_Cristian_Nica1', '~Tom_Bosc1', '~Yoshua_Bengio1', '~Nikolay_Malkin1']","['GFlowNets', 'probabilistic modeling', 'reinforcement learning']","Generative flow networks (GFlowNets) are a family of algorithms for training a sequential sampler of discrete objects under an unnormalized target density and have been successfully used for various probabilistic modeling tasks. Existing training objectives for GFlowNets are either local to states or transitions, or propagate a reward signal over an entire sampling trajectory. We argue that these alternatives represent opposite ends of a gradient bias-variance tradeoff and propose a way to exploit this tradeoff to mitigate its harmful effects. Inspired by the TD($\lambda$) algorithm in reinforcement learning, we introduce subtrajectory balance or SubTB($\lambda$), a GFlowNet training objective that can learn from partial action subsequences of varying lengths. We show that SubTB($\lambda$) accelerates sampler convergence in previously studied and new environments and enables training GFlowNets in environments with longer action sequences and sparser reward landscapes than what was possible before. We also perform a comparative analysis of stochastic gradient dynamics, shedding light on the bias-variance tradeoff in GFlowNet training and the advantages of subtrajectory balance.",https://openreview.net/pdf/8bdb6b759d5bda81ec90b669c7cbec534c1db61d.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=UP_GHHPw7rP,Nearly Minimax Optimal Offline Reinforcement Learning with Linear Function Approximation: Single-Agent MDP and Markov Game,"['Wei Xiong', 'Han Zhong', 'Chengshuai Shi', 'Cong Shen', 'Liwei Wang', 'Tong Zhang']","['~Wei_Xiong9', '~Han_Zhong1', '~Chengshuai_Shi1', '~Cong_Shen1', '~Liwei_Wang1', '~Tong_Zhang2']",['RL theory'],"Offline reinforcement learning (RL) aims at learning an optimal strategy using a pre-collected dataset without further interactions with the environment. While various algorithms have been proposed for offline RL in the previous literature, the minimax optimality has only been (nearly) established for tabular Markov decision processes (MDPs). In this paper, we focus on offline RL with linear function approximation and propose a new pessimism-based algorithm for offline linear MDP. At the core of our algorithm is the uncertainty decomposition via a reference function, which is new in the literature of offline RL under linear function approximation. Theoretical analysis demonstrates that our algorithm can match the performance lower bound up to logarithmic factors. We also extend our techniques to the two-player zero-sum Markov games (MGs), and establish a new performance lower bound for MGs, which tightens the existing result, and verifies the nearly minimax optimality of the proposed algorithm. To the best of our knowledge, these are the first computationally efficient and nearly minimax optimal algorithms for offline single-agent MDPs and MGs with linear function approximation.",https://openreview.net/pdf/4ec7b1dd165364db85e719d8b2232962869eb44d.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=UJ4nGMHZYI,Factor Learning Portfolio Optimization Informed by Continuous-Time Finance Models,"['Sinong Geng', 'houssam nassif', 'Zhaobin Kuang', 'Anders Max Reppen', 'K. Ronnie Sircar']","['~Sinong_Geng1', '~houssam_nassif1', '~Zhaobin_Kuang1', '~Anders_Max_Reppen1', '~K._Ronnie_Sircar1']",[],"We study financial portfolio optimization in the presence of unknown and uncontrolled system variables referred to as stochastic factors. Existing work falls into two distinct categories: (i) reinforcement learning employs end-to-end policy learning with flexible factor representation, but does not precisely model the dynamics of asset prices or factors; (ii) continuous-time finance methods, in contrast, take advantage of explicitly modeled dynamics but pre-specify, rather than learn, factor representation. We propose FaLPO (factor learning portfolio optimization), a framework that interpolates between these two approaches. Specifically, FaLPO hinges on deep policy gradient to learn a performant investment policy that takes advantage of flexible representation for stochastic factors. Meanwhile, FaLPO also incorporates continuous-time finance models when modeling the dynamics. It uses the optimal policy functional form derived from such models and optimizes an objective that combines policy learning and model calibration. We prove the convergence of FaLPO, and provide performance guarantees via a finite-sample bound. On both synthetic and real-world portfolio optimization tasks, we observe that FaLPO outperforms five leading methods. Finally, we show that FaLPO can be extended to other decision-making problems with stochastic factors.",https://openreview.net/pdf/92cd77cc4d9da949c287fa768b8ff1f8c1df33cf.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=U0jfsqmoV-4,Instruction-Following Agents with Jointly Pre-Trained Vision-Language Models,"['Hao Liu', 'Lisa Lee', 'Kimin Lee', 'Pieter Abbeel']","['~Hao_Liu1', '~Lisa_Lee1', '~Kimin_Lee1', '~Pieter_Abbeel2']","['reinforcement learning', 'pre-training', 'multimodal representation', 'representation learning', 'transformer']","Humans are excellent at understanding language and vision to accomplish a wide range of tasks. In contrast, creating general instruction-following embodied agents remains a difficult challenge. Prior work that uses pure language-only models lack visual grounding, making it difficult to connect language instructions with visual observations. On the other hand, methods that use pre-trained vision-language models typically come with divided language and visual representations, requiring designing specialized network architecture to fuse them together. We propose a simple yet effective model for robots to solve instruction-following tasks in vision-based environments. Our InstructRL method consists of a multimodal transformer that encodes visual observations and language instructions, and a policy transformer that predicts actions based on encoded representations. The multimodal transformer is pre-trained on millions of image-text pairs and natural language text, thereby producing generic cross-modal representations of observations and instructions. The policy transformer keeps track of the full history of observations and actions, and predicts actions autoregressively. We show that this unified transformer model outperforms all state-of-the-art pre-trained or trained-from-scratch methods in both single-task and multi-task settings. Our model also shows better model scalability and generalization ability than prior work.",https://openreview.net/pdf/ccaa63e0939bc0518db8c562fc78c1f7787d73e6.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=TnzdAU7c8WM,Learning Visual Representation with Synthetic Images and Topologically-defined Labels,"['Shizuo Kaji', 'Yohsuke Watanabe']","['~Shizuo_Kaji1', '~Yohsuke_Watanabe1']","['topology', 'persistent homology', 'self-supervised learning', 'synthetic image']","We propose a scheme for neural networks to learn visual representation with synthetic images and mathematically-defined labels that capture topological information. To verify that the model acquires a different visual representation than with the usual supervised learning with manually-defined labels, we show that the models pretrained with our scheme can be finetuned for image classification tasks to achieve an improved convergence compared to those trained from scratch. 
Convolutional neural networks, built upon iterative local operations, are good at learning local features of the image, such as texture, whereas they tend to pay less attention to larger structures. Our method provides a simple way to encourage the model to learn global features through a specifically designed task based on topology. Furthermore, our method requires no real images nor manual labels; hence it sheds light on some of the lately concerned topics in computer vision, such as the cost and the fairness in data collection and annotation.",https://openreview.net/pdf/eca47190f4243002b44c64fadae87121aa45e4fa.pdf,{'title_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Th98b8dH4yr,Tangential Wasserstein Projections,"['Florian Gunsilius', 'Meng Hsuan Hsieh', 'Myung Jin Lee']","['~Florian_Gunsilius1', '~Meng_Hsuan_Hsieh1', '~Myung_Jin_Lee1']","['Optimal Transport', 'Wasserstein', 'Generalized geodesics', 'Projection', 'Tangent Cone', 'Causal Inference']","We develop a notion of projections between sets of probability measures using the geometric properties of the $2$-Wasserstein space. It is designed for general multivariate probability measures, is computationally efficient to implement, and provides a unique solution in regular settings. The idea is to work on regular tangent cones of the Wasserstein space using generalized geodesics. Its structure and computational properties make the method applicable in a variety of settings, from causal inference to the analysis of object data. An application to estimating causal effects yields a generalization of the notion of synthetic controls for systems with general heterogeneity described via multivariate probability measures, as well as a way to estimate optimal weights jointly over all time periods.",https://openreview.net/pdf/e5532e5044e7064cdd070609e8d691381bc88c09.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=TdTGGj7fYYJ,Unsupervised Meta-learning via Few-shot Pseudo-supervised Contrastive Learning,"['Huiwon Jang', 'Hankook Lee', 'Jinwoo Shin']","['~Huiwon_Jang1', '~Hankook_Lee1', '~Jinwoo_Shin1']","['unsupervised meta-learning', 'supervised contrastive learning', 'self-supervised learning']","Unsupervised meta-learning aims to learn generalizable knowledge across a distribution of tasks constructed from unlabeled data. Here, the main challenge is how to construct diverse tasks for meta-learning without label information; recent works have proposed to create, e.g., pseudo-labeling via pretrained representations or creating synthetic samples via generative models. However, such a task construction strategy is fundamentally limited due to heavy reliance on the immutable pseudo-labels during meta-learning and the quality of the representations or the generated samples. To overcome the limitations, we propose a simple yet effective unsupervised meta-learning framework, coined Pseudo-supervised Contrast (PsCo), for few-shot classification. We are inspired by the recent self-supervised learning literature; PsCo utilizes a momentum network and a queue of previous batches to improve pseudo-labeling and construct diverse tasks in a progressive manner. Our extensive experiments demonstrate that PsCo outperforms existing unsupervised meta-learning methods under various in-domain and cross-domain few-shot classification benchmarks. We also validate that PsCo is easily scalable to a large-scale benchmark, while recent prior-art meta-schemes are not.",https://openreview.net/pdf/65c63b72201856c7d08ce81fba8f12b50947aa77.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Tb3ZJBDF7aA,Pre-training Protein Structure Encoder via Siamese Diffusion Trajectory Prediction,"['Zuobai Zhang', 'Minghao Xu', 'Aurelie Lozano', 'Vijil Chenthamarakshan', 'Payel Das', 'Jian Tang']","['~Zuobai_Zhang1', '~Minghao_Xu1', '~Aurelie_Lozano1', '~Vijil_Chenthamarakshan1', '~Payel_Das1', '~Jian_Tang1']","['Protein representation learning', 'diffusion models', 'self-supervised learning']","Due to the determining role of protein structures on diverse protein functions, pre-training representations of proteins on massive unlabeled protein structures has attracted rising research interests. Among recent efforts on this direction, mutual information (MI) maximization based methods have gained the superiority on various downstream benchmark tasks. The core of these methods is to design correlated views that share common information about a protein. Previous view designs focus on capturing structural motif co-occurrence on the same protein structure, while they cannot capture detailed atom/residue interactions. To address this limitation, we propose the Siamese Diffusion Trajectory Prediction (SiamDiff) method. SiamDiff builds a view as the trajectory that gradually approaches protein native structure from scratch, which facilitates the modeling of atom/residue interactions underlying the protein structural dynamics. Specifically, we employ the multimodal diffusion process as a faithful simulation of the structure-sequence co-diffusion trajectory, where rich patterns of protein structural changes are embedded. On such basis, we design a principled theoretical framework to maximize the MI between correlated multimodal diffusion trajectories. We study the effectiveness of SiamDiff on both residue-level and atom-level structures. On the EC and ATOM3D benchmarks, we extensively compare our method with previous protein structure pre-training approaches. The experimental results verify the consistently superior or competitive performance of SiamDiff on all benchmark tasks compared to existing baselines. The source code will be made public upon acceptance.",https://openreview.net/pdf/1c7b861dfae0a1beada9e33038d8d6adb117d5c4.pdf,{'title_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=TPiwkItUSu,Behind the Scenes of Gradient Descent: A Trajectory Analysis via Basis Function Decomposition,"['Jianhao Ma', 'Lingjun Guo', 'Salar Fattahi']","['~Jianhao_Ma1', '~Lingjun_Guo1', '~Salar_Fattahi2']","['nonconvex optimization', 'trajectory analysis', 'neural network optimization']","This work analyzes the solution trajectory of gradient-based algorithms via a novel basis function decomposition. We show that, although solution trajectories of gradient-based algorithms may vary depending on the learning task, they behave almost monotonically when projected onto an appropriate orthonormal function basis. Such projection gives rise to a basis function decomposition of the solution trajectory. Theoretically, we use our proposed basis function decomposition to establish the convergence of gradient descent (GD) on several representative learning tasks. In particular, we improve the convergence of GD on symmetric matrix factorization and provide a completely new convergence result for the orthogonal symmetric tensor decomposition. Empirically, we illustrate the promise of our proposed framework on realistic deep neural networks (DNNs) across different architectures, gradient-based solvers, and datasets. Our key finding is that gradient-based algorithms monotonically learn the coefficients of a particular orthonormal function basis of DNNs defined as the eigenvectors of the conjugate kernel after training.",https://openreview.net/pdf/ca6112e62d0190aca22c33e237c6215e3ad9962e.pdf,{'title_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=TMYzh1hsHd,MA2QL: A Minimalist Approach to Fully Decentralized Multi-Agent Reinforcement Learning,"['Kefan Su', 'Siyuan Zhou', 'Chuang Gan', 'Xiangjun Wang', 'Zongqing Lu']","['~Kefan_Su1', '~Siyuan_Zhou2', '~Chuang_Gan1', '~Xiangjun_Wang1', '~Zongqing_Lu2']",['multi-agent reinforcement learning'],"Decentralized learning has shown great promise for cooperative multi-agent reinforcement learning (MARL). However, non-stationarity remains a significant challenge in fully decentralized learning. In the paper, we tackle the non-stationarity problem in the simplest and fundamental way and propose multi-agent alternate Q-learning (MA2QL), where agents take turns to update their Q-functions by Q-learning. MA2QL is a minimalist approach to fully decentralized cooperative MARL but is theoretically grounded. We prove that when each agent guarantees $\varepsilon$-convergence at each turn, their joint policy converges to a Nash equilibrium. In practice, MA2QL only requires minimal changes to independent Q-learning (IQL). We empirically evaluate MA2QL on a variety of cooperative multi-agent tasks. Results show MA2QL consistently outperforms IQL, which verifies the effectiveness of MA2QL, despite such minimal changes.",https://openreview.net/pdf/64d8a2ca3d5acc89e42a1e5fbd1436913b71078b.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=TLx9diIRJVj,SynBench: Task-Agnostic Benchmarking of Pretrained Representations using Synthetic Data,"['Ching-Yun Ko', 'Pin-Yu Chen', 'Jeet Mohapatra', 'Payel Das', 'Luca Daniel']","['~Ching-Yun_Ko1', '~Pin-Yu_Chen1', '~Jeet_Mohapatra1', '~Payel_Das1', '~Luca_Daniel1']",[],"Recent success in fine-tuning large models, that are pretrained on broad data at scale, on downstream tasks has led to a significant paradigm shift in deep learning, from task-centric model design to task-agnostic representation learning and task-specific fine-tuning. As the representations of pretrained models are used as a foundation for different downstream tasks, this paper proposes a new task-agnostic framework, \textit{SynBench}, to measure the quality of pretrained representations using synthetic data. We set up a reference by a theoretically-derived robustness-accuracy tradeoff of the class conditional Gaussian mixture. Given a pretrained model, the representations of data synthesized from the Gaussian mixture are used to compare with our reference to infer the quality. By comparing the ratio of area-under-curve between the raw data and their representations, SynBench offers a quantifiable score for robustness-accuracy performance benchmarking. Our framework applies to a wide range of pretrained models taking continuous data inputs and is independent of the downstream tasks and datasets. Evaluated with several pretrained vision transformer models, the experimental results show that our SynBench score well matches the actual linear probing performance of the pre-trained model when fine-tuned on downstream tasks. Moreover, our framework can be used to inform the design of robust linear probing on pretrained representations to mitigate the robustness-accuracy tradeoff in downstream tasks.",https://openreview.net/pdf/7d4c6af5e3f9c83b39cd7960f76b0f8500ab585b.pdf,{'title_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=TJPmwnQIMmw,Adversarial Causal Augmentation for Graph Covariate Shift,"['Yongduo Sui', 'Xiang Wang', 'Jiancan Wu', 'An Zhang', 'Xiangnan He', 'Tat-Seng Chua']","['~Yongduo_Sui1', '~Xiang_Wang6', '~Jiancan_Wu1', '~An_Zhang2', '~Xiangnan_He1', '~Tat-Seng_Chua2']","['Graph Data Augmentation', 'Graph Neural Networks', 'Covariate Shift', 'OOD Generalization']","Out-of-distribution (OOD) generalization on graphs is drawing widespread attention. However, existing efforts mainly focus on the OOD issue of correlation shift. While another type, covariate shift, remains largely unexplored but is the focus of this work. From a data generation view, causal features are stable substructures in data, which play key roles in OOD generalization. While their complementary parts, environments, are unstable features that often lead to various distribution shifts. Correlation shift establishes spurious statistical correlations between environments and labels. In contrast, covariate shift means that there exist unseen environmental features in test data. Existing strategies of graph invariant learning and data augmentation suffer from limited environments or unstable causal features, which greatly limits their generalization ability on covariate shift. In view of that, we propose a novel graph augmentation strategy: Adversarial Causal Augmentation (AdvCA), to alleviate the covariate shift. Specifically, it adversarially augments the data to explore diverse distributions of the environments. Meanwhile, it keeps the causal features invariant across diverse environments. It maintains the environmental diversity while ensuring the invariance of the causal features, thereby effectively alleviating the covariate shift. Extensive experimental results with in-depth analyses demonstrate that AdvCA can outperform 14 baselines on synthetic and real-world datasets with various covariate shifts.",https://openreview.net/pdf/7d9688e93892271720938ff6bfa929724e3f6a56.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=TBOFHtBariC,On discrete symmetries of robotics systems: A group-theoretic and data-driven analysis,"['Daniel Ordonez-Apraez', 'Mario Martin', 'Antonio Agudo', 'Francesc Moreno-Noguer']","['~Daniel_Ordonez-Apraez1', '~Mario_Martin2', '~Antonio_Agudo3', '~Francesc_Moreno-Noguer1']","['Morphological Symmetries', 'Discrete Symmetries of Dynamical Systems', 'Equivariant Dynamics', 'Equivariant Function Approximators', 'Geometric Deep Learning']","In this work, we study the Morphological Symmetries of dynamical systems with one or more planes of symmetry, a predominant feature in animal biology and robotic systems, characterized by the duplication and balanced distribution of body parts. These morphological symmetries imply that the system's dynamics are symmetric (or approximately symmetric), which in turn imprints symmetries in optimal control policies and in all proprioceptive and exteroceptive measurements related to the evolution of the system's dynamics. For data-driven methods, symmetry represents an inductive bias that justifies data augmentation and the construction of symmetric function approximators. To this end, we use Group Theory to present a theoretical and practical framework allowing for (1) the identification of the system's morphological symmetry Group $\G$, (2) the characterization of how the group acts upon the system state variables and any relevant measurement living in the Euclidean space, and (3) the exploitation of data symmetries through the use of $\G$-equivariant/$\G$-invariant Neural Networks, for which we present experimental results on synthetic and real-world applications, demonstrating how symmetry constraints lead to better sample efficiency and generalization while reducing the number of trainable parameters.",https://openreview.net/pdf/f79b3ac494d465f44557e3e5b9f6d460668b91fc.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=T6HPzkhaKeS,Action Matching: A Variational Method for Learning Stochastic Dynamics from Samples,"['Kirill Neklyudov', 'Daniel Severo', 'Alireza Makhzani']","['~Kirill_Neklyudov1', '~Daniel_Severo1', '~Alireza_Makhzani1']",[],"Stochastic dynamics are ubiquitous in many fields of science, from the evolution of quantum systems in physics to diffusion-based models in machine learning. Existing methods such as score matching can be used to simulate these physical processes by assuming that the dynamics is a diffusion, which is not always the case. In this work, we propose a method called ""Action Matching"" that enables us to learn a much broader family of stochastic dynamics. Our method requires access only to samples from different time-steps, makes no explicit assumptions about the underlying dynamics, and can be applied even when samples are uncorrelated (i.e., are not part of a trajectory). Action Matching directly learns an underlying mechanism to move samples in time without modeling the distributions at each time-step. In this work, we showcase how Action Matching can be used for several computer vision tasks such as generative modeling, super-resolution, colorization, and inpainting; and further discuss potential applications in other areas of science.",https://openreview.net/pdf/be11a3215548703bc487696afb43b9cd7a63f81d.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=SxO-qoAwVM,Understanding Hindsight Goal Relabeling Requires Rethinking Divergence Minimization,"['Lunjun Zhang', 'Bradly C. Stadie']","['~Lunjun_Zhang1', '~Bradly_C._Stadie1']","['reinforcement learning', 'multi-goal reinforcement learning', 'imitation learning']","Hindsight goal relabeling has become a foundational technique for multi-goal reinforcement learning (RL). The idea is quite simple: any arbitrary trajectory can be seen as an expert demonstration for reaching the trajectory's end state. Intuitively, this procedure trains a goal-conditioned policy to imitate a sub-optimal expert. However, this connection between imitation and hindsight relabeling is not well understood. Modern imitation learning algorithms are described in the language of divergence minimization, and yet it remains an open problem how to recast hindsight goal relabeling into that framework. In this work, we develop a unified objective for goal-reaching that explains such a connection, from which we can derive goal-conditioned supervised learning (GCSL) and the reward function in hindsight experience replay (HER) from first principles. Experimentally, we find that despite recent advances in goal-conditioned behaviour cloning (BC), multi-goal Q-learning can still outperform BC-like methods; moreover, a vanilla combination of both actually hurts model performance. Under our framework, we study when BC is expected to help, and empirically validate our findings. Our work further bridges goal-reaching and generative modeling, illustrating the nuances and new pathways of extending the success of generative models to RL.",https://openreview.net/pdf/916bf81972cae1705a77d99a562a532a60fa090c.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=SaRj2ka1XZ3,Language Models Can Teach Themselves to Program Better,"['Patrick Haluptzok', 'Matthew Bowers', 'Adam Tauman Kalai']","['~Patrick_Haluptzok1', '~Matthew_Bowers1', '~Adam_Tauman_Kalai1']","['deep learning', 'natural language processing', 'program synthesis', 'large language models']","Recent Language Models (LMs) achieve breakthrough performance in code generation when trained on human-authored problems, even solving some competitive-programming problems. Self-play has proven useful in games such as Go, and thus it is natural to ask whether LMs can generate their own instructive programming problems to improve their performance. We show that it is possible for an LM to synthesize programming problems and solutions, which are filtered for correctness by a Python interpreter. The LM’s performance is then seen to improve when it is fine-tuned on its own synthetic problems and verified solutions; thus the model “improves itself” using the Python interpreter. Problems are specified formally as programming puzzles [Schuster et al. , 2021], a code-based problem format where solutions can easily be verified for correctness by execution. In experiments on publicly-available LMs, test accuracy more than doubles. This work demonstrates the potential for code LMs, with an interpreter, to generate instructive problems and improve their own performance.",https://openreview.net/pdf/70f1e70fce89088da12b7493b7d1a8d444a2acec.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=S9GpoS2TmN,Abstract-to-Executable Trajectory Translation for One-Shot Task Generalization,"['Stone Tao', 'Xiaochen Li', 'Tongzhou Mu', 'Zhiao Huang', 'Yuzhe Qin', 'Hao Su']","['~Stone_Tao1', '~Xiaochen_Li1', '~Tongzhou_Mu1', '~Zhiao_Huang1', '~Yuzhe_Qin1', '~Hao_Su1']","['Trajectory Translation', 'One-Shot Generalization', 'Long-Horizon Task', 'Reinforcement Learning']","Training long-horizon robotic policies in complex physical environments is essential for many applications, such as robotic manipulation. However, learning a policy that can generalize to unseen tasks is challenging. In this work, we propose to achieve one-shot task generalization by decoupling plan generation and plan execution. Specifically, our method solves complex long-horizon tasks in three steps: build a paired abstract environment by simplifying geometry and physics, generate abstract trajectories, and solve the original task by an abstract-to-executable trajectory translator. In the abstract environment, complex dynamics such as physical manipulation are removed, making abstract trajectories easier to generate. However, this introduces a large domain gap between abstract trajectories and the actual executed trajectories as abstract trajectories lack low-level details and aren’t aligned frame-to-frame with the executed trajectory. In a manner reminiscent of language translation, our approach leverages a seq-to-seq model to overcome the large domain gap between the abstract and executable trajectories, enabling the low-level policy to follow the abstract trajectory. Experimental results on various unseen long-horizon tasks with different robot embodiments demonstrate the practicability of our methods to achieve one-shot task generalization. Videos and more details can be found in the supplementary materials and project page: https://sites.google.com/view/abstract-to-executable-iclr23/",https://openreview.net/pdf/8cbd0d88c301cc75e09f0b4d0bd54348b35ff3a9.pdf,{'title_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=S80ioOGLpD9,Joint-Predictive Representations for Multi-Agent Reinforcement Learning,"['Mingxiao Feng', 'Wengang Zhou', 'Yaodong Yang', 'Houqiang Li']","['~Mingxiao_Feng1', '~Wengang_Zhou1', '~Yaodong_Yang1', '~Houqiang_Li1']",[],"The recent advances in reinforcement learning have demonstrated the effectiveness of vision-based self-supervised learning (SSL). However, the main efforts on this direction have been paid on single-agent setting, making multi-agent reinforcement learning~(MARL) lags thus far. There are two significant obstacles that prevent applying off-the-shelf SSL approaches with MARL on a partially observable multi-agent system : (a) each agent only gets a partial observation, and (b) previous SSL approaches only take consistent temporal representations into account, while ignoring the characterization that captures the interaction and fusion among agents. In this paper, we propose \textbf{M}ulti-\textbf{A}gent  \textbf{Jo}int-Predictive \textbf{R}epresentations~(MAJOR), a novel framework to explore self-supervised learning on cooperative MARL. Specifically, we treat the latent representations of local observations of all agents as the sequence of masked contexts of the global state, and we then learn effective representations by predicting the future latent representations for each agent with the help of the agent-level information interactions in a joint transition model. We have conducted extensive experiments on wide-range MARL environments, including both vision-based and state-based scenarios, and show that our proposed MAJOR achieves superior asymptotic performance and sample efficiency against other state-of-the-art methods.",https://openreview.net/pdf/75a8a39509ea0cb056d3a45d1a5d964aaa0d9d12.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Rywi6F_HVCO,Augmentative Topology Agents For Open-Ended Learning,"['Muhammad Umair Nasir', 'Michael Beukman', 'Steven James', 'Christopher Wesley Cleghorn']","['~Muhammad_Umair_Nasir1', '~Michael_Beukman1', '~Steven_James1', '~Christopher_Wesley_Cleghorn1']","['Open-Ended Learning', 'NeuroEvolution']","In this work, we tackle the problem of Open-Ended Learning by a method that simultaneously evolves agents and increasingly challenging environments. Unlike previous open-ended approaches that optimize agents using a fixed neural network topology, we hypothesize that generalization can be improved by allowing agents' controllers to become more complex as they encounter more difficult environments.  Our method, Augmentative Topology EPOET (ATEP), extends the Enhanced Paired Open-Ended Trailblazer (EPOET) algorithm by allowing agents to evolve their own neural network structures over time, adding complexity and capacity as necessary. Empirical results demonstrate that ATEP results in general agents capable of solving more environments than a fixed-topology baseline. We also investigate mechanisms for transferring agents between environments and find that a species-based approach further improves the performance and generalization of agents.",https://openreview.net/pdf/9ea7a6b152b9c122bca52e8aefeccb287c6a4c7f.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=RvV2xvoML7G,Treatment Effect Estimation with Collider Bias and Confounding Bias,"['Baohong Li', 'Kun Kuang', 'Ruoxuan Xiong', 'Fei Wu']","['~Baohong_Li1', '~Kun_Kuang1', '~Ruoxuan_Xiong1', '~Fei_Wu1']",[],"To answer causal questions from observational data, it is important to consider the mechanisms that determine which data values are observed and which are missing. Prior work has considered the treatment assignment mechanism and proposed methods to remove the confounding bias from the common causes of treatment and outcome. However, there are other issues in sample selection, commonly overlooked in prior work, that can bias the treatment effect estimation, such as the issue of censored outcome as a form of collider bias. In this paper, we propose the novel Selection Controlled CounterFactual Regression (SC-CFR) to simultaneously address confounding and collider bias. Specifically, we first calculate the magnitude of the collider bias of different instances by estimating the selection model and then add a control term to remove the collider bias while learning a balanced representation to remove the confounding bias when estimating the outcome model. Our method is shown to provide unbiased treatment effect estimates from observational data with confounding and collider bias. Extensive empirical results on both synthetic and real-world datasets show that our method consistently outperforms benchmarks when both types of biases exist.",https://openreview.net/pdf/151198ad73360596d2db0ab55778eea91986fa19.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Rl4ihTreFnV,Robust Multi-Agent Reinforcement Learning with State Uncertainties,"['Sihong He', 'Songyang Han', 'Sanbao Su', 'Shuo Han', 'Shaofeng Zou', 'Fei Miao']","['~Sihong_He1', '~Songyang_Han1', '~Sanbao_Su1', '~Shuo_Han3', '~Shaofeng_Zou1', '~Fei_Miao1']","['multi-agent reinforcement learning', 'robust reinforcement learning']","In real-world multi-agent reinforcement learning (MARL) applications, agents may not have perfect state information (e.g., due to inaccurate measurement or malicious attacks), which challenges the robustness of agents' policies. Though robustness is getting important in MARL deployment, little prior work has studied state uncertainties in MARL, neither in problem formulation nor algorithm design. Motivated by this robustness issue, we study the problem of MARL with state uncertainty in this work. We provide the first attempt to the theoretical and empirical analysis of this challenging problem. We first model the problem as a Markov Game with state perturbation adversaries (MG-SPA), and introduce Robust Equilibrium as the solution concept. We conduct fundamental analysis regarding MG-SPA and give conditions under which such an equilibrium exists. Then we propose a robust multi-agent Q-learning (RMAQ) algorithm to find such an equilibrium, with convergence guarantees. To handle high-dimensional state-action space, we design a robust multi-agent actor-critic (RMAAC) algorithm based on an analytical expression of the policy gradient derived in the paper. Our experiments show that the proposed RMAQ algorithm converges to the optimal value function; our RMAAC algorithm outperforms several MARL methods that do not consider the state uncertainty in several multi-agent environments.",https://openreview.net/pdf/b8fe6046a426a2e16266d9d47f18306135307820.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=RIJM-pJF_3K,Causally Constrained Data Synthesis For Private Data Release,"['Varun Chandrasekaran', 'Darren Edge', 'Somesh Jha', 'Lukas Wutschitz', 'Amit Sharma', 'Cheng Zhang', 'Shruti Tople']","['~Varun_Chandrasekaran1', 'darren.edge@microsoft.com', '~Somesh_Jha1', '~Lukas_Wutschitz1', '~Amit_Sharma3', '~Cheng_Zhang1', '~Shruti_Tople2']",[],"Data privacy is critical in many decision-making contexts, such as healthcare and finance. A common mechanism is to create differentially private synthetic data using generative models. Such data generation reflects certain statistical properties of the original data, but often has an unacceptable privacy vs. utility trade-off. Since natural data inherently exhibits causal structure, we propose incorporating \emph{causal information} into the training process to favorably navigate the aforementioned trade-off. Under certain assumptions for linear gaussian models and a broader class of models, we theoretically prove that causally informed generative models provide better differential privacy guarantees than their non-causal counterparts. We evaluate our proposal using variational autoencoders, and demonstrate that the trade-off is mitigated through better utility for comparable privacy.",https://openreview.net/pdf/accaf0a0c437aa4aa099c6d5ada1e2c443734628.pdf,{'title_filter': 'Data Synthesis'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Qi4oCA89CmO,Why Did This Model Forecast This Future? Information-Theoretic Temporal Saliency for Counterfactual Explanations of Probabilistic Forecasts,"['Chirag Raman', 'Hayley Hung', 'Marco Loog']","['~Chirag_Raman2', '~Hayley_Hung2', '~Marco_Loog1']","['probabilistic forecasting', 'saliency', 'explainability']","Probabilistic forecasting of multivariate time series is significant to several research domains where multiple futures exist for a single observed sequence. Identifying the observations on which a well-performing model bases its forecasts can enable domain experts to form data-driven hypotheses about the causal relationships between features. Consequently, we begin by revisiting the question: what constitutes a causal explanation? One hurdle in the landscape of explainable artificial intelligence is that what constitutes an explanation is not well-grounded. We build upon Miller's framework of explanations derived from research in multiple social science disciplines, and establish a conceptual link between counterfactual reasoning and saliency-based explanation techniques. However, the complication is a lack of a consistent and principled notion of saliency. Also, commonly derived saliency maps may be inconsistent with the data generation process and the underlying model. We therefore leverage a unifying definition of information-theoretic saliency grounded in preattentive human visual cognition and extend it to forecasting settings. In contrast to existing methods that require either explicit training of the saliency mechanism or access to the internal parameters of the underlying model, we obtain a closed-form solution for the resulting saliency map for commonly used density functions in probabilistic forecasting. To empirically evaluate our explainability framework in a principled manner, we construct a synthetic dataset of conversation dynamics and demonstrate that our method recovers the true salient timesteps for a forecast given a well-performing underlying model.",https://openreview.net/pdf/eea73f7fc60694325dc6eb8762ebf6bc3bffcf2a.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Qc_OopMEBnC,Learning to Segment from Noisy Annotations: A Spatial Correction Approach,"['Jiachen Yao', 'Yikai Zhang', 'Songzhu Zheng', 'Mayank Goswami', 'Prateek Prasanna', 'Chao Chen']","['~Jiachen_Yao1', '~Yikai_Zhang1', '~Songzhu_Zheng1', '~Mayank_Goswami1', '~Prateek_Prasanna3', '~Chao_Chen1']",[],"Noisy labels can significantly affect the performance of deep neural networks (DNNs). In medical image segmentation tasks, annotations are error-prone due to the high demand in annotation time and in the annotators' expertise. Existing methods mostly tackle label noise in classification tasks. Their independent-noise assumptions do not fit label noise in segmentation task. In this paper, we propose a novel noise model for segmentation problems that encodes spatial correlation and bias, which are prominent in segmentation annotations. Further, to mitigate such label noise, we propose a label correction method to recover true label progressively. We provide theoretical guarantees of the correctness of the proposed method. Experiments show that our approach outperforms current state-of-the-art methods on both synthetic and real-world noisy annotations.",https://openreview.net/pdf/3a19f70c903f3d5336ce11a5aa6ac1f5f12152af.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Qamz7Q_Ta1k,Direct Embedding of Temporal Network Edges via Time-Decayed Line Graphs,"['Sudhanshu Chanpuriya', 'Ryan A. Rossi', 'Sungchul Kim', 'Tong Yu', 'Jane Hoffswell', 'Nedim Lipka', 'Shunan Guo', 'Cameron N Musco']","['~Sudhanshu_Chanpuriya1', '~Ryan_A._Rossi2', '~Sungchul_Kim1', '~Tong_Yu3', 'jhoffs@adobe.com', '~Nedim_Lipka1', 'sguo@adobe.com', '~Cameron_N_Musco1']","['temporal', 'networks', 'graphs', 'embedding']","Temporal networks model a variety of important phenomena involving timed interactions between entities. Existing methods for machine learning on temporal networks generally exhibit at least one of two limitations. First, many methods assume time to be discretized, so if the time data is continuous, the user must determine the discretization and discard precise time information. Second, edge representations can only be calculated indirectly from the nodes, which may be suboptimal for tasks like edge classification. We present a simple method that avoids both shortcomings: construct the line graph of the network, which includes a node for each interaction, and weigh the edges of this graph based on the difference in time between interactions. From this derived graph, edge representations for the original network can be computed with efficient classical methods. The simplicity of this approach facilitates explicit theoretical analysis: we can constructively show the effectiveness of our method's representations for a natural synthetic model of temporal networks. Empirical results on real-world networks demonstrate our method's efficacy and efficiency on both link classification and prediction.",https://openreview.net/pdf/90f557dbe9c9290881d4da0fddf557a84bd2da96.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=QWQM0ZwZdRS,Fake It Until You Make It : Towards Accurate Near-Distribution Novelty Detection,"['Hossein Mirzaei', 'Mohammadreza Salehi', 'Sajjad Shahabi', 'Efstratios Gavves', 'Cees G. M. Snoek', 'Mohammad Sabokrou', 'Mohammad Hossein Rohban']","['~Hossein_Mirzaei1', '~Mohammadreza_Salehi2', '~Sajjad_Shahabi1', '~Efstratios_Gavves1', '~Cees_G._M._Snoek1', '~Mohammad_Sabokrou1', '~Mohammad_Hossein_Rohban1']",[],"We aim for image-based novelty detection. Despite considerable progress, existing models either fail or face dramatic drop under the so-called ``near-distribution"" setup, where the differences between normal and anomalous samples are subtle. We first demonstrate existing methods could experience up to 20\% decrease in their AUCs in the near-distribution setting. Next, we propose to exploit a score-based generative model to produce synthetic near-distribution anomalous data. Our model is then fine-tuned to distinguish such data from the normal samples. We make quantitative as well as qualitative evaluation of this strategy, and compare the results with a variety of GAN-based models.  Effectiveness of our method for both near-distribution and standard novelty detection is assessed through extensive experiments on datasets in diverse applications such as medical images, object classification, and quality control. This reveals that our method significantly improves upon existing models, and consistently decreases the gap between the near-distribution and standard novelty detection AUCs by a considerable amount.",https://openreview.net/pdf/adb38cfa18f4064baa8532ba96fd48c4ad2cf87a.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=QTXKTXJKIh,Achieving Near-Optimal Individual Regret & Low Communications in Multi-Agent Bandits,"['Xuchuang Wang', 'Lin Yang', 'Yu-Zhen Janice Chen', 'Xutong Liu', 'Mohammad Hajiesmaili', 'Don Towsley', 'John C.S. Lui']","['~Xuchuang_Wang1', 'linyang@nju.edu.cn', '~Yu-Zhen_Janice_Chen1', '~Xutong_Liu1', '~Mohammad_Hajiesmaili1', '~Don_Towsley1', '~John_C.S._Lui2']","['Multi-agent multi-armed bandits', 'individual regret', 'communication']","Cooperative multi-agent multi-armed bandits (CM2AB) study how distributed agents cooperatively play the same multi-armed bandit game. Most existing CM2AB works focused on maximizing the group performance of all agents---the accumulation of all agents' individual performance (i.e., individual reward). However, in many applications, the performance of the system is more sensitive to the ``bad'' agent---the agent with the worst individual performance. For example, in a drone swarm, a ``bad'' agent may crash into other drones and severely degrade the system performance. In that case, the key of the learning algorithm design is to coordinate computational and communicational resources among agents so to optimize the individual learning performance of the ``bad'' agent. In CM2AB, maximizing the group performance is equivalent to minimizing the group regret of all agents, and minimizing the individual performance can be measured by minimizing the maximum (worst) individual regret among agents. Minimizing the maximum individual regret was largely ignored in prior literature, and currently, there is little work on how to minimize this objective with a low communication overhead. In this paper, we propose a near-optimal algorithm on both individual and group regrets, in addition,  we also propose a novel communication module in the algorithm, which only needs \(O(\log (\log T))\) communication times where \(T\) is the number of decision rounds. We also conduct simulations to illustrate the advantage of our algorithm by comparing it to other known baselines.",https://openreview.net/pdf/04213bd9368859af7649a1f1b85b691f3a583f8b.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Q120_4COf-K,Synthetic Data Generation of Many-to-Many Datasets via Random Graph Generation,"['Kai Xu', 'Georgi Ganev', 'Emile Joubert', 'Rees Davison', 'Olivier Van Acker', 'Luke Robinson']","['~Kai_Xu4', '~Georgi_Ganev1', '~Emile_Joubert1', '~Rees_Davison1', '~Olivier_Van_Acker1', '~Luke_Robinson1']","['synthetic data generation', 'random graph generation', 'differential privacy']","Synthetic data generation (SDG) has become a popular approach to release private datasets.
In SDG, a generative model is fitted on the private real data, and samples drawn from the model are released as the protected synthetic data.
While real-world datasets usually consist of multiple tables with potential \emph{many-to-many} relationships (i.e.~\emph{many-to-many datasets}), recent research in SDG mostly focuses on modeling tables \emph{independently} or only considers generating datasets with special cases of many-to-many relationships such as \emph{one-to-many}.
In this paper, we first study challenges of building faithful generative models for many-to-many datasets, identifying limitations of existing methods.
We then present a novel factorization for many-to-many generative models,  which leads to a scalable generation framework by combining recent results from random graph theory and representation learning.
Finally, we extend the framework to establish the notion of $(\epsilon,\delta)$-differential privacy.
Through a real-world dataset, we demonstrate that our method can generate synthetic datasets while preserving information within and across tables better than its closest competitor.",https://openreview.net/pdf/be7956b2e543e1b8e0ec80abee0a911606aee3cb.pdf,{'title_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Q-neeWNVv1,Order Matters: Agent-by-agent Policy Optimization,"['Xihuai Wang', 'Zheng Tian', 'Ziyu Wan', 'Ying Wen', 'Jun Wang', 'Weinan Zhang']","['~Xihuai_Wang1', '~Zheng_Tian1', '~Ziyu_Wan2', '~Ying_Wen1', '~Jun_Wang2', '~Weinan_Zhang1']",['Multi-agent Reinforcement Learning'],"While multi-agent trust region algorithms have achieved great success empirically in solving coordination tasks, most of them,  however, suffer from a non-stationarity problem since agents update their policies simultaneously. In contrast, a sequential scheme that updates policies agent-by-agent provides another perspective and shows strong performance. However, sample inefficiency and lack of monotonic improvement guarantees for each agent are still the two significant challenges for the sequential scheme. In this paper, we propose the \textbf{A}gent-by-\textbf{a}gent \textbf{P}olicy \textbf{O}ptimization (A2PO) algorithm to improve the sample efficiency and retain the guarantees of monotonic improvement for each agent during training. We justify the tightness of the monotonic improvement bound compared with other trust region algorithms. From the perspective of sequentially updating agents, we further consider the effect of agent updating order and extend the theory of non-stationarity into the sequential update scheme. To evaluate A2PO, we conduct a comprehensive empirical study on four benchmarks: StarCraftII, Multi-agent MuJoCo, Multi-agent Particle Environment, and Google Research Football full game scenarios. A2PO consistently outperforms strong baselines.",https://openreview.net/pdf/b7c35e63818d65e4523a6ae4314674a0eeb7bb36.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=PxohstFQm9q,Simplicity bias in $1$-hidden layer neural networks,"['Depen Morwani', 'Praneeth Netrapalli', 'jatin batra', 'Karthikeyan Shanmugam', 'Prateek Jain']","['~Depen_Morwani1', '~Praneeth_Netrapalli1', '~jatin_batra1', '~Karthikeyan_Shanmugam1', '~Prateek_Jain1']","['Simplicity Bias', 'Neural Network', 'Gradient Descent']","Recent works \citep{shah2020pitfalls,chen2021intriguing} have demonstrated that neural networks exhibit extreme \emph{simplicity bias} (SB). That is,  they learn \emph{only the simplest} features  to solve a task at hand, even in the presence of other, more robust but more complex features. Due to lack of a general and rigorous definition of \emph{features}, these works showcase SB on \emph{semi-synthetic} datasets such as Color-MNIST, MNIST-CIFAR where defining features is relatively easier. 

In this work, we rigorously define as well as thoroughly establish SB for \emph{one hidden layer} neural networks. More concretely, (i) we define SB as the network essentially being a function of a low dimensional projection of the inputs (ii) theoretically, we show that when the data is linearly separable, the network primarily depends on only the linearly separable ($1$-dimensional) subspace even in the presence of an arbitrarily large number of other, more complex features which could have led to a significantly more robust classifier,  (iii) empirically, we show that models trained on \emph{real} datasets such as Imagenette and Waterbirds-Landbirds indeed depend on a low dimensional projection of the inputs, thereby demonstrating SB on these datasets, iv) finally, we present a natural ensemble approach that encourages diversity in  models by training successive models on features not used by earlier models, and demonstrate that it yields models that are significantly more robust to Gaussian noise.",https://openreview.net/pdf/6c2a71a1119e9c2f644c96629d1ffc4c00bd7512.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=PfPrnKDtvIG,Multi-Agent Reinforcement Learning with Shared Resources for Inventory Management,"['Yuandong Ding', 'Mingxiao Feng', 'Guozi Liu', 'Wei Jiang', 'Chuheng Zhang', 'Li Zhao', 'Lei Song', 'Houqiang Li', 'Yan Jin', 'Jiang Bian']","['~Yuandong_Ding1', '~Mingxiao_Feng1', '~Guozi_Liu1', 'weij4@illinois.edu', '~Chuheng_Zhang1', '~Li_Zhao1', '~Lei_Song3', '~Houqiang_Li1', '~Yan_Jin3', '~Jiang_Bian1']","['Multi-Agent Reinforcement Learning', 'Inventory Mangement']","In this paper, we consider the inventory management (IM) problem where we need to make replenishment decisions for a large number of stock keeping units (SKUs) to balance their supply and demand. In our setting, the constraint on the shared resources (such as the inventory capacity) couples the otherwise independent control for each SKU. We formulate the problem with this structure as Shared-Resource Stochastic Game (SRSG) and propose an efficient algorithm called Context-aware Decentralized PPO (CD-PPO). Through extensive experiments, we demonstrate that CD-PPO can accelerate the learning procedure compared with standard MARL algorithms.",https://openreview.net/pdf/a057d061dce08b6196f98519eeb910da2526caad.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Peot1SFDX0,Preference Transformer: Modeling Human Preferences using Transformers for RL,"['Changyeon Kim', 'Jongjin Park', 'Jinwoo Shin', 'Honglak Lee', 'Pieter Abbeel', 'Kimin Lee']","['~Changyeon_Kim1', '~Jongjin_Park1', '~Jinwoo_Shin1', '~Honglak_Lee2', '~Pieter_Abbeel2', '~Kimin_Lee1']","['preference-based reinforcement learning', 'human-in-the-loop reinforcement learning', 'deep reinforcement learning']","Preference-based reinforcement learning (RL) provides a framework to train agents using human preferences between two behaviors. However, preference-based RL has been challenging to scale since it requires a large amount of human feedback to learn a reward function aligned with human intent. In this paper, we present Preference Transformer, a neural architecture that models human preferences using transformers. Unlike prior approaches assuming human judgment is based on the Markovian rewards which contribute to the decision equally, we introduce a new preference model based on the weighted sum of non-Markovian rewards. We then design the proposed preference model using a transformer architecture that stacks causal and bidirectional self-attention layers. We demonstrate that Preference Transformer can solve a variety of control tasks using real human preferences, while prior approaches fail to work. We also show that Preference Transformer can induce a well-specified reward and attend to critical events in the trajectory by automatically capturing the temporal dependencies in human decision-making. Code is available on the project website: https://sites.google.com/view/preference-transformer.",https://openreview.net/pdf/8a47190a33890c3b90463d493dc6f9bb78af91ee.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=PAKkOriJBd,Coordination Scheme Probing for Generalizable Multi-Agent Reinforcement Learning,"['Hao Ding', 'Chengxing Jia', 'Cong Guan', 'Feng Chen', 'Lei Yuan', 'Zongzhang Zhang', 'Yang Yu']","['~Hao_Ding5', '~Chengxing_Jia1', '~Cong_Guan1', '~Feng_Chen12', '~Lei_Yuan2', '~Zongzhang_Zhang1', '~Yang_Yu5']","['reinforcement learning', 'multi-agent reinforcement learning', 'agent modeling']","Coordinating with previously unknown teammates without joint learning is a crucial need for real-world multi-agent applications, such as human-AI interaction. An active research topic on this problem is ad hoc teamwork, which improves agents' coordination ability in zero-shot settings. However, previous works can only solve the problem of a single agent's coordination with different teams, which is not in line with arbitrary group-to-group coordination in complex multi-agent scenarios. Moreover, they commonly suffer from limited adaptation ability within an episode in a zero-shot setting. To address these problems, we introduce the Coordination Scheme Probing (CSP) approach that applies a disentangled scheme probing module to represent and classify the newly arrived teammates beforehand with limited pre-collected episodic data and makes multi-agent control accordingly. To achieve generalization, CSP learns a meta-policy with multiple sub-policies that follow distinguished coordination schemes in an end-to-end fashion and automatically reuses it to coordinate with unseen teammates. Empirically, we show that the proposed method achieves remarkable performance compared to existing ad hoc teamwork and policy generalization methods in various multi-agent cooperative scenarios.",https://openreview.net/pdf/0d0633049838da07b4f5de064de1fbac697d92c3.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=P3PJokAqGW,Learning with Stochastic Orders,"['Carles Domingo-Enrich', 'Yair Schiff', 'Youssef Mroueh']","['~Carles_Domingo-Enrich1', '~Yair_Schiff1', '~Youssef_Mroueh1']","['optimal transport', 'stochastic order', 'Choquet order', 'convex function', 'input convex neural network', 'integral probability metric', 'image generation', 'statistical rates']","Learning high-dimensional distributions is often done with explicit likelihood modeling or implicit modeling via minimizing integral probability metrics (IPMs). In this paper, we expand this learning paradigm to stochastic orders, namely, the convex or Choquet order between probability measures. Towards this end, exploiting the relation between convex orders and optimal transport, we introduce the Choquet-Toland distance between probability measures, that can be used as a drop-in replacement for IPMs. We also introduce the Variational Dominance Criterion (VDC) to learn probability measures with dominance constraints, that encode the desired stochastic order between the learned measure and a known baseline. We analyze both quantities and show that they suffer from the curse of dimensionality and propose surrogates via input convex maxout networks (ICMNs), that enjoy parametric rates. We provide a min-max framework for learning with stochastic orders and validate it experimentally on synthetic and high-dimensional image generation, with promising results. Finally, our ICMNs class of convex functions and its derived Rademacher Complexity are of independent interest beyond their application in convex orders. Code to reproduce experimental results is available at https://github.com/yair-schiff/stochastic-orders-ICMN.",https://openreview.net/pdf/69bf232a5f31365934fcdc570925118eede29e06.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=P1MaSJlwdT4,Go-Explore with a guide: Speeding up search in sparse reward settings with goal-directed intrinsic rewards,"['Chong Min John Tan', 'Mehul Motani']","['~Chong_Min_John_Tan2', '~Mehul_Motani1']","['reinforcement learning', 'intrinsic motivation', 'goal-directed rewards', 'hippocampal replay', 'hard-exploration', 'sparse rewards']","Reinforcement Learning (RL) agents have traditionally been very sample-intensive to train, especially in environments with sparse rewards. Seeking inspiration from neuroscience experiments of rats learning the structure of a maze without needing extrinsic rewards, we seek to incorporate additional intrinsic rewards to guide behavior. We propose a potential-based goal-directed intrinsic reward (GDIR), which provides a reward signal regardless of whether the task is achieved, and ensures that learning can always take place. While GDIR may be similar to approaches such as reward shaping in incorporating goal-based rewards, we highlight that GDIR is innate to the agent and hence applicable across a wide range of environments without needing to rely on a properly shaped environment reward. We also note that GDIR is different from curiosity-based intrinsic motivation, which can diminish over time and lead to inefficient exploration. Go-Explore is a well-known state-of-the-art algorithm for sparse reward domains, and we demonstrate that by incorporating GDIR in the ``Go"" and ``Explore"" phases, we can improve Go-Explore's performance and enable it to learn faster across multiple environments, for both discrete (2D grid maze environments, Towers of Hanoi, Game of Nim) and continuous (Cart Pole and Mountain Car) state spaces. Furthermore, to consolidate learnt trajectories better, our method also incorporates a novel approach of hippocampal replay to update the values of GDIR and reset state visit and selection counts of states along the successful trajectory. As a benchmark, we also show that our proposed approaches learn significantly faster than traditional extrinsic-reward-based RL algorithms such as Proximal Policy Optimization, TD-learning, and Q-learning.",https://openreview.net/pdf/792d0f553c3b9eb4af6aa81dea97790a1288f830.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=P-73JPgRs0R,Effects of Graph Convolutions in Multi-layer Networks,"['Aseem Baranwal', 'Kimon Fountoulakis', 'Aukosh Jagannath']","['~Aseem_Baranwal1', '~Kimon_Fountoulakis1', '~Aukosh_Jagannath1']","['graph neural networks', 'node classification', 'classification threshold', 'contextual stochastic block model']","Graph Convolutional Networks (GCNs) are one of the most popular architectures that are used to solve classification problems accompanied by graphical information. We present a rigorous theoretical understanding of the effects of graph convolutions in multi-layer networks. We study these effects through the node classification problem of a non-linearly separable Gaussian mixture model coupled with a stochastic block model. First, we show that a single graph convolution expands the regime of the distance between the means where multi-layer networks can classify the data by a factor of at least $1/\sqrt[4]{\rm deg}$, where ${\rm deg}$ denotes the expected degree of a node. Second, we show that with a slightly stronger graph density, two graph convolutions improve this factor to at least $1/\sqrt[4]{n}$, where $n$ is the number of nodes in the graph. Finally, we provide both theoretical and empirical insights into the performance of graph convolutions placed in different combinations among the layers of a neural network, concluding that the performance is mutually similar for all combinations of the placement. We present extensive experiments on both synthetic and real-world data that illustrate our results.",https://openreview.net/pdf/d210fced5bf1ca06dc521b5bd8088e97ffbdc31e.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=OxBl7cSgo6_,Heterogeneous-Agent Mirror Learning,"['Jakub Grudzien Kuba', 'Xidong Feng', 'Shiyao Ding', 'Hao Dong', 'Yaodong Yang']","['~Jakub_Grudzien_Kuba1', '~Xidong_Feng1', '~Shiyao_Ding1', '~Hao_Dong2', '~Yaodong_Yang1']","['deep multi-agent reinforcement learning', 'multi-agent reinforcement learning theory']","The necessity for cooperation among intelligent machines has popularised cooperative multi-agent reinforcement learning (MARL) in the artificial intelligence (AI) research community. However, many research endeavours have been focused on developing practical MARL algorithms whose effectiveness has been studied only empirically, thereby lacking theoretical guarantees. As recent studies have revealed, MARL methods often achieve performance that is unstable in terms of reward monotonicity or suboptimal at convergence. To resolve these issues, in this paper, we introduce a novel framework named Heterogeneous-Agent Mirror Learning (HAML) that provides a general template for MARL algorithmic designs. We prove that algorithms derived from the HAML template satisfy the desired properties of the monotonic improvement of the joint reward and the convergence to Nash equilibrium. We verify the practicality of HAML by proving that the current state-of-the-art cooperative MARL algorithms, HATRPO and HAPPO, are in fact HAML instances. Next, as a natural outcome of our theory, we propose HAML extensions of two well-known RL algorithms, HAA2C (for A2C) and HADDPG (for DDPG), and demonstrate their effectiveness against strong baselines on StarCraftII and Multi-Agent MuJoCo tasks.",https://openreview.net/pdf/32ce8ddc549d03e30882ae6ec449f757a2cb36c7.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Or8rcTLo7U,Maximal Correlation-Based Post-Nonlinear Learning for Bivariate Causal Discovery,"['Tianjian Zhang', 'Feng Yin', 'Zhi-Quan Luo']","['~Tianjian_Zhang1', '~Feng_Yin1', '~Zhi-Quan_Luo1']",[],"Bivariate causal discovery aims to determine the causal relationship between two random variables from passive observational data (as intervention is not affordable in many scientific fields), which is considered fundamental and challenging. Designing algorithms based on the post-nonlinear (PNL) model has aroused much attention for its generality. However, the state-of-the-art (SOTA) PNL-based algorithms involve highly non-convex objectives for neural network training, which are time-consuming and unable to produce meaningful solutions with finite samples. In this paper, we propose a novel method that incorporates maximal correlation into the PNL model learning (short as MC-PNL) such that the underlying nonlinearities can be accurately recovered. Owing to the benign structure of our objective function when modeling the nonlinearities with linear combinations of random Fourier features, the target optimization problem can be solved rather efficiently and rapidly via the block coordinate descent. We also compare the MC-PNL with SOTA methods on the downstream synthetic and real causal discovery tasks to show its superiority in time and accuracy. Our code is available at https://anonymous.4open.science/r/MC-PNL-E446/.",https://openreview.net/pdf/05d9675703d87f470fb7035a9985486e4f238476.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=OhUAblg27z,Harnessing Mixed Offline Reinforcement Learning Datasets via Trajectory Weighting,"['Zhang-Wei Hong', 'Pulkit Agrawal', 'Remi Tachet des Combes', 'Romain Laroche']","['~Zhang-Wei_Hong1', '~Pulkit_Agrawal1', '~Remi_Tachet_des_Combes1', '~Romain_Laroche1']","['offline reinforcement learning', 'reinforcement learning', 'sampling', 'experience replay']","Most offline reinforcement learning (RL) algorithms return a target policy maximizing a trade-off between (1) the expected performance gain over the behavior policy that collected the dataset, and (2) the risk stemming from the out-of-distribution-ness of the induced state-action occupancy. It follows that the performance of the target policy is strongly related to the performance of the behavior policy and, thus, the trajectory return distribution of the dataset. We show that in mixed datasets consisting of mostly low-return trajectories and minor high-return trajectories, state-of-the-art offline RL algorithms are overly restrained by low-return trajectories and fail to exploit high-performing trajectories to the fullest. To overcome this issue, we show that, in deterministic MDPs with stochastic initial states, the dataset sampling can be re-weighted to induce an artificial dataset whose behavior policy has a higher return. This re-weighted sampling strategy may be combined with any offline RL algorithm. We further analyze that the opportunity for performance improvement over the behavior policy correlates with the positive-sided variance of the returns of the trajectories in the dataset. We empirically show that while CQL, IQL, and TD3+BC achieve only a part of this potential policy improvement, these same algorithms combined with our reweighted sampling strategy fully exploit the dataset. Furthermore, we empirically demonstrate that, despite its theoretical limitation, the approach may still be efficient in stochastic environments. ",https://openreview.net/pdf/b83963010af384d9aa84006520ff14a6370f893e.pdf,{'title_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=OfaJyiYonBk,Iteratively Learning Novel Strategies with Diversity Measured in State Distances,"['Wei Fu', 'Weihua Du', 'Jingwei Li', 'Sunli Chen', 'Jingzhao Zhang', 'Yi Wu']","['~Wei_Fu1', '~Weihua_Du1', '~Jingwei_Li2', '~Sunli_Chen1', '~Jingzhao_Zhang2', '~Yi_Wu1']","['diverse behavior', 'multi-agent reinforcement learning', 'deep reinforcement learning']","In complex reinforcement learning (RL) problems, policies with similar rewards may have substantially different behaviors. Yet, to not only optimize rewards but also discover as many diverse strategies as possible remains a challenging problem. A natural approach to this task is constrained population-based training (PBT), which simultaneously learns a collection of policies subject to diversity constraints. However, due to the unaffordable computation cost of PBT, we adopt an alternative approach, iterative learning (IL), which repeatedly learns a single novel policy that is sufficiently different from previous ones. We first analyze these two frameworks and prove that, for any policy pool derived by PBT, we can always use IL to obtain another policy pool of the same rewards and competitive diversity scores. In addition, we also present a novel state-based diversity measure with two tractable realizations. Such a metric can impose a stronger and much smoother diversity constraint than existing action-based metrics. Combining IL and the state-based diversity measure, we develop a powerful diversity-driven RL algorithm, State-based Intrinsic-reward Policy Optimization (SIPO), with provable convergence properties. We empirically examine our algorithm in complex multi-agent environments including StarCraft Multi-Agent Challenge and Google Research Football. SIPO is able to consistently derive strategically diverse and human-interpretable policies that cannot be discovered by existing baselines.",https://openreview.net/pdf/8104275e81fb11ab8c218e2b324d5dc7edd8a827.pdf,{'abstract_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=OTbRTIY4YS,Global Explainability of GNNs via Logic Combination of Learned Concepts,"['Steve Azzolin', 'Antonio Longa', 'Pietro Barbiero', 'Pietro Lio', 'Andrea Passerini']","['~Steve_Azzolin2', '~Antonio_Longa1', '~Pietro_Barbiero1', '~Pietro_Lio1', '~Andrea_Passerini2']","['Explainability', 'Graph Neural Networks', 'Concept Learning']","While instance-level explanation of GNN is a well-studied problem with plenty of approaches being developed, providing a global explanation for the behaviour of a GNN is much less explored, despite its potential in interpretability and debugging. Existing solutions either simply list local explanations for a given class, or generate a synthetic prototypical graph with maximal score for a given class, completely missing any combinatorial aspect that the GNN could have learned.
In this work, we propose GLGExplainer (Global Logic-based GNN Explainer), the first Global Explainer capable of generating explanations as arbitrary Boolean combinations of learned graphical concepts. GLGExplainer is a fully differentiable architecture that takes local explanations as inputs and combines them into a logic formula over graphical concepts, represented as clusters of local explanations. 
Contrary to existing solutions, GLGExplainer provides accurate and human-interpretable global explanations that are perfectly aligned with ground-truth explanations (on synthetic data) or match existing domain knowledge (on real-world data). Extracted formulas are faithful to the model predictions, to the point of providing insights into some occasionally incorrect rules learned by the model, making GLGExplainer a promising diagnostic tool for learned GNNs.",https://openreview.net/pdf/4bc7378db838b1014f2e7b981b34a3e0aadaaf09.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=ORp91sAbzI,Leveraging Unlabeled Data to Track Memorization,"['Mahsa Forouzesh', 'Hanie Sedghi', 'Patrick Thiran']","['~Mahsa_Forouzesh2', '~Hanie_Sedghi1', '~Patrick_Thiran1']","['memorization', 'label noise', 'generalization', 'unlabeled data', 'deep learning']","Deep neural networks may easily memorize noisy labels present in real-world data, which degrades their ability to generalize. It is therefore important to track and evaluate the robustness of models against noisy label memorization. We propose a metric, called $\textit{susceptibility}$, to gauge such memorization for neural networks. Susceptibility is simple and easy to compute during training. Moreover, it does not require access to ground-truth labels and it only uses unlabeled data. We empirically show the effectiveness of our metric in tracking memorization on various architectures and datasets and provide theoretical insights into the design of the susceptibility metric. Finally, we show through extensive experiments on datasets with synthetic and real-world label noise that one can utilize susceptibility and the overall training accuracy to distinguish models that maintain a low memorization on the training set and generalize well to unseen clean data. ",https://openreview.net/pdf/fd7c9f38e71ea9b881d14aa1c553aee5ee725757.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=OIcMPYZXFPL,Mastering Spatial Graph Prediction of Road Networks,"['Sotiris Anagnostidis', 'Aurelien Lucchi', 'Thomas Hofmann']","['~Sotiris_Anagnostidis1', '~Aurelien_Lucchi1', '~Thomas_Hofmann1']",[],"Accurately predicting road networks from satellite images requires a global understanding of the network topology. We propose to capture such high-level information by introducing a graph-based framework that simulates the addition of sequences of graph edges using a reinforcement learning (RL) approach. In particular, given a partially generated graph associated with a satellite image, an RL agent nominates modifications that maximize a cumulative reward. As opposed to standard supervised techniques that tend to be more restricted to commonly used surrogate losses, these rewards can be based on various complex, potentially non-continuous, metrics of interest. This yields more power and flexibility to encode problem-dependent knowledge. Empirical results on several benchmark datasets demonstrate enhanced performance and increased high-level reasoning about the graph topology when using a tree-based search. We further highlight the superiority of our approach under substantial occlusions by introducing a new synthetic benchmark dataset for this task.",https://openreview.net/pdf/d57ed684b0a65bd250f36888d7420fbd173e8cad.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=OAsXFPBfTBh,Autoregressive Conditional Neural Processes,"['Wessel Bruinsma', 'Stratis Markou', 'James Requeima', 'Andrew Y. K. Foong', 'Tom Andersson', 'Anna Vaughan', 'Anthony Buonomo', 'Scott Hosking', 'Richard E Turner']","['~Wessel_Bruinsma1', '~Stratis_Markou1', '~James_Requeima1', '~Andrew_Y._K._Foong1', 'tomand@bas.ac.uk', '~Anna_Vaughan1', 'ab2707@cam.ac.uk', 'jask@bas.ac.uk', '~Richard_E_Turner1']",[],"Conditional neural processes (CNPs; Garnelo et al., 2018a) are attractive meta-learning models which produce well-calibrated predictions and are trainable via a simple maximum likelihood procedure. Although CNPs have many advantages, they are unable to model dependencies in their predictions. Various works propose solutions to this, but these come at the cost of either requiring approximate inference or being limited to Gaussian predictions. In this work, we instead propose to change how CNPs are deployed at test time, without any modifications to the model or training procedure. Instead of making predictions independently for every target point, we autoregressively define a joint predictive distribution using the chain rule of probability, taking inspiration from the neural autoregressive density estimator (NADE) literature. We show that this simple procedure allows factorised Gaussian CNPs to model highly dependent, non-Gaussian predictive distributions. Perhaps surprisingly, in an extensive range of tasks with synthetic and real data, we show that CNPs in autoregressive (AR) mode not only significantly outperform non-AR CNPs, but are also competitive with more sophisticated models that are significantly more computationally expensive and challenging to train. This performance is remarkable given that AR CNPs are not trained to model joint dependencies. Our work provides an example of how ideas from neural distribution estimation can benefit neural processes, and motivates research into the AR deployment of other neural process models.",https://openreview.net/pdf/8333abe2794ea3baf2d24fc271dbef749d5a4565.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=O5rKg7IRQIO,Guarded Policy Optimization with Imperfect Online Demonstrations,"['Zhenghai Xue', 'Zhenghao Peng', 'Quanyi Li', 'Zhihan Liu', 'Bolei Zhou']","['~Zhenghai_Xue1', '~Zhenghao_Peng1', '~Quanyi_Li1', '~Zhihan_Liu1', '~Bolei_Zhou5']","['reinforcement learning', 'guarded policy optimization', 'imperfect demonstrations', 'shared control', 'metadrive simulator']","The Teacher-Student Framework (TSF) is a reinforcement learning setting where a teacher agent guards the training of a student agent by intervening and providing online demonstrations. Assuming optimal, the teacher policy has the perfect timing and capability to intervene in the learning process of the student agent, providing safety guarantee and exploration guidance. Nevertheless, in many real-world settings it is expensive or even impossible to obtain a well-performing teacher policy. In this work, we relax the assumption of a well-performing teacher and develop a new method that can incorporate arbitrary teacher policies with modest or inferior performance. We instantiate an Off-Policy Reinforcement Learning algorithm, termed Teacher-Student Shared Control (TS2C), which incorporates teacher intervention based on trajectory-based value estimation. Theoretical analysis validates that the proposed TS2C algorithm attains efficient exploration and substantial safety guarantee without being affected by the teacher's own performance. Experiments on various continuous control tasks show that our method can exploit teacher policies at different performance levels while maintaining a low training cost. Moreover, the student policy surpasses the imperfect teacher policy in terms of higher accumulated reward in held-out testing environments. Code is available at https://metadriverse.github.io/TS2C.",https://openreview.net/pdf/e19dee281e43ab70ef8f8640d6ccb689bed45bd8.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=NnOZT_CR26Z,GoBigger: A Scalable Platform for Cooperative-Competitive Multi-Agent Interactive Simulation,"['Ming Zhang', 'Shenghan Zhang', 'Zhenjie Yang', 'Lekai Chen', 'Jinliang Zheng', 'Chao Yang', 'Chuming Li', 'Hang Zhou', 'Yazhe Niu', 'Yu Liu']","['~Ming_Zhang10', '~Shenghan_Zhang1', '~Zhenjie_Yang1', '~Lekai_Chen1', '~Jinliang_Zheng1', '~Chao_Yang3', '~Chuming_Li1', '~Hang_Zhou9', '~Yazhe_Niu1', '~Yu_Liu2']","['Reinforcement Learning', 'Environment', 'Cooperation', 'Competition', 'Scalable']","The emergence of various multi-agent environments has motivated powerful algorithms to explore agents' cooperation or competition. Even though this has greatly promoted the development of multi-agent reinforcement learning  (MARL), it is still not enough to support further exploration on the behavior of swarm intelligence between multiple teams, and cooperation between multiple agents due to their limited scalability. To alleviate this, we introduce GoBigger, a scalable platform for cooperative-competition multi-agent interactive simulation. GoBigger is an enhanced environment for the Agar-like game, enabling the simulation of multiple scales of agent intra-team cooperation and inter-team competition. Compared with existing multi-agent simulation environments, our platform supports multi-team games with more than two teams simultaneously, which dramatically expands the diversity of agent cooperation and competition, and can more effectively simulate the swarm intelligent agent behavior. Besides, in GoBigger, the cooperation between the agents in a team can lead to much higher performance. We offer a diverse set of challenging scenarios, built-in bots, and visualization tools for best practices in benchmarking. We evaluate several state-of-the-art algorithms on GoBigger and demonstrate the potential of the environment. We believe this platform can inspire various emerging research directions in MARL, swarm intelligence, and large-scale agent interactive learning. Both GoBigger and its related benchmark are open-sourced. More information could be found at https://github.com/opendilab/GoBigger.",https://openreview.net/pdf/a9b5c1cac35cce14dad1036f5b0f324ad899d11f.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=NYtq-CsRP3H,Parameter Averaging for Feature Ranking,"['Talip Ucar', 'Ehsan Hajiramezanali']","['~Talip_Ucar2', '~Ehsan_Hajiramezanali1']","['Parameter averaging', 'feature ranking', 'feature importance', 'robustness', 'interpretability', 'tabular data']","Neural Networks are known to be sensitive to initialisation. The methods that rely on neural networks for feature ranking are not robust since they can have variations in their ranking when the model is initialized and trained with different random seeds. In this work, we introduce a novel method based on parameter averaging to estimate accurate and robust feature importance in tabular data setting, referred as XTab. We first initialize and train multiple instances of a shallow network (referred as local masks) with ""different random seeds"" for a downstream task. We then obtain a global mask model by ""averaging the parameters"" of local masks. We show that although the parameter averaging might result in a global model with higher loss, it still leads to the discovery of the ground-truth feature importance more consistently than an individual model does. We conduct extensive experiments on a variety of synthetic and real-world data, demonstrating that the XTab can be used to obtain the global feature importance that is not sensitive to sub-optimal model initialisation.",https://openreview.net/pdf/e79336859855d12aa07cfc4418982b3c988a4068.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=NTCYXulK9qm,Co-Evolution As More Than a Scalable Alternative for Multi-Agent Reinforcement Learning,['Patrick Grzywok'],['~Patrick_Grzywok1'],"['reinforcement learning', 'multi-agent reinforcement learning', 'policy search', 'co-evolution', 'evolutionary algorithm']","In recent years, gradient based multi-agent reinforcement learning is growing in success. One contributing factor is the use of shared parameters for learning policy networks. While this approach scales well with the number of agents during execution it lacks this ambiguity for training as the number of produced samples grows linearly with the number of agents. For a very large number of agents, this could lead to an inefficient use of the circumstantial amount of produced samples. Moreover in single-agent reinforcement learning policy search with evolutionary algorithms showed viable success when sampling can be parallelized on a larger scale. The here proposed method does not only consider sampling in concurrent environments but further investigates sampling diverse parameters from the population in co-evolution in joint environments during training. This co-evolutionary policy search has shown to be capable of training a large number of agents. Beyond that, it has been shown to produce competitive results in smaller environments in comparison to gradient descent based methods. This surprising result make evolutionary algorithms a promising candidate for further research in the context of multi-agent reinforcement learning.",https://openreview.net/pdf/ef90a358c1b140d624af9e72ce4070931d4ad77a.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=NO0ThzteQdI,NERDS: A General Framework to Train Camera Denoisers from Raw-RGB Noisy Image Pairs,"['Heewon Kim', 'Kyoung Mu Lee']","['~Heewon_Kim2', '~Kyoung_Mu_Lee2']",[],"  We aim to train accurate denoising networks for smartphone/digital cameras from single noisy images. Downscaling is commonly used as a practical denoiser for low-resolution images. Based on this processing, we found that the pixel variance of the natural images is more robust to downscaling than the pixel variance of the camera noises. Intuitively, downscaling easily removes high-frequency noises than natural textures. To utilize this property, we can adopt noisy/clean image synthesis at low-resolution to train camera denoisers. On this basis, we propose a new solution pipeline -- NERDS that estimates camera noises and synthesizes noisy-clean image pairs from only noisy images.  In particular, it first models the noise in raw-sensor images as a Poisson-Gaussian distribution, then estimates the noise parameters using the difference of pixel variances by downscaling. We formulate the noise estimation as a gradient-descent-based optimization problem through a reparametrization trick. We further introduce a new Image Signal Processor (ISP) estimation method that enables denoiser training in a human-readable RGB space by transforming the synthetic raw images to the style of a given RGB noisy image. The noise and ISP estimations utilize rich augmentation to synthesize image pairs for denoiser training. Experiments show that our NERDS can accurately train CNN-based denoisers (e.g., DnCNN, ResNet-style network) outperforming previous noise-synthesis-based and self-supervision-based denoisers in real datasets.",https://openreview.net/pdf/bdebcf036670b6aad12923bc167527b706b42167.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=N4K5ck-BTT,Scaffolding a Student to Instill Knowledge,"['Anil Kag', 'Durmus Alp Emre Acar', 'Aditya Gangrade', 'Venkatesh Saligrama']","['~Anil_Kag1', '~Durmus_Alp_Emre_Acar1', '~Aditya_Gangrade1', '~Venkatesh_Saligrama1']","['knowledge distillation', 'tiny capacity student', 'large capacity teacher', 'budget constrained learning']","We propose a novel knowledge distillation (KD) method to selectively instill teacher knowledge into a student model motivated by situations where the student's capacity is significantly smaller than that of the teachers. In vanilla KD, the teacher primarily sets a predictive target for the student to follow, and we posit that this target is overly optimistic due to the student's lack of capacity. We develop a novel scaffolding scheme where the teacher, in addition to setting a predictive target, also scaffolds the student's prediction by censoring hard-to-learn examples. Scaffolding utilizes the same information as the teacher's soft-max predictions as inputs, and in this sense, our proposal can be viewed as a natural variant of vanilla KD. We show on synthetic examples that censoring hard-examples leads to smoothening the student's loss landscape so that the student encounters fewer local minima. As a result, it has good generalization properties. Against vanilla KD, we achieve improved performance and are comparable to more intrusive techniques that leverage feature matching on benchmark datasets.
",https://openreview.net/pdf/c8a1e11f100899f2bd81fb3442a4721f0872fe17.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Mof47lISH6N,DifFace: Blind Face Restoration with Diffused Error Contraction,"['Zongsheng Yue', 'Chen Change Loy']","['~Zongsheng_Yue1', '~Chen_Change_Loy2']","['Face Restoration', 'Diffusion Model', 'Super-resolution']","While deep learning-based methods for blind face restoration have achieved unprecedented success, they still suffer from two major limitations. First, most of them deteriorate when facing complex degradations out of their training data. Second, these methods require multiple constraints, e.g., fidelity, perceptual, and adversarial losses, which requires laborious hyper-parameters tuning to stabilize and balance their influences. In this work, we propose a novel method named DifFace, being able to cope with unseen and complex degradations more gracefully without complicated loss designs. The key of our method is to establish a posterior distribution from the observed low-quality (LQ) image to its high-quality (HQ) counterpart. In particular, we design a transition distribution from the LQ image to the intermediate state of a pre-trained diffusion model and then gradually transmit from this intermediate state to the HQ target by recursively applying a pre-trained diffusion model. The transition distribution only relies on a restoration backbone that is trained with L2 loss on some synthetic data, which favorably avoids the cumbersome training process in existing methods. Moreover, the transition distribution is capable of contracting the error of the restoration backbone and thus makes our method more robust to unknown degradations. Comprehensive experiments show that DifFace is superior to current state-of-the-art methods, especially in cases with severe degradations. Code and model will be released.",https://openreview.net/pdf/9670b623722d76aa64038405e42aa4d07e8d46ec.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=MhuFzFsrfvH,Optimal Transport for Offline Imitation Learning,"['Yicheng Luo', 'zhengyao jiang', 'Samuel Cohen', 'Edward Grefenstette', 'Marc Peter Deisenroth']","['~Yicheng_Luo1', '~zhengyao_jiang2', '~Samuel_Cohen1', '~Edward_Grefenstette1', '~Marc_Peter_Deisenroth1']","['offline reinforcement learning', 'optimal transport', 'imitation learning']","With the advent of large datasets, offline reinforcement learning is a promising framework for learning good decision-making policies without the need to interact with the real environment.
However, offline RL requires the dataset to be reward-annotated, which presents practical challenges when reward engineering is difficult or when obtaining reward annotations is labor-intensive.
In this paper, we introduce Optimal Transport Relabeling (OTR), an imitation learning algorithm that can automatically relabel offline data of mixed and unknown quality with rewards from a few good demonstrations. OTR's key idea is to use optimal transport to compute an optimal alignment between an unlabeled trajectory in the dataset and an expert demonstration to obtain a similarity measure that can be interpreted as a reward, which can then be used by an offline RL algorithm to learn the policy. OTR is easy to implement and computationally efficient. On D4RL benchmarks, we demonstrate that OTR with a single demonstration can consistently match the performance of offline RL with ground-truth rewards.
",https://openreview.net/pdf/3c2503af4f49d5f2f79a720075d8cfc042c50960.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=MdiVU9lMmVS,Very Large Scale Multi-Agent Reinforcement Learning with Graph Attention Mean Field,['Qianyue Hao'],['~Qianyue_Hao1'],"['Multi-agent reinforcement learning', 'large-scale problems', 'graph attention', 'mean field']","With recent advances in reinforcement learning, we have witnessed countless successes of intelligent agents in various domains. Especially, multi-agent reinforcement learning (MARL) is suitable for many real-world scenarios and has vast potential applications. However, typical MARL methods can only handle tens of agents, leaving scenarios with up to hundreds or even thousands of agents almost unexplored. There exist two key challenges in scaling up the number of agents: (1) agent-agent interactions are critical in multi-agent systems while the number of interactions grows quadratically with the number of agents, causing great computational complexity and difficulty in strategies-learning; (2) the strengths of interactions vary among agents and over time, making it difficult to precisely model such interactions. In this paper, we propose the Graph Attention Mean Field (GAT-MF) method, where we convert agent-agent interactions into interactions between each agent and a weighted mean field, greatly reducing the computational complexity. We mathematically prove the correctness of this conversion. We design a graph attention mechanism to automatically capture the different and time-varying strengths of interactions, ensuring the ability of our method to precisely model interactions among the agents. We conduct extensive experiments in both manual and real-world scenarios with up to more than 3000 agents, demonstrating that comparing existing MARL methods, our method reaches superior performance and 9.4 times computational efficiency.",https://openreview.net/pdf/beb6830c8b16328725a483b96dbef96a1491de65.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=MbWntPvE5Tg,Planning Immediate Landmarks of Targets for Model-Free Skill Transfer across Agents,"['Minghuan Liu', 'Zhengbang Zhu', 'Menghui Zhu', 'Yuzheng Zhuang', 'Weinan Zhang', 'Jianye HAO']","['~Minghuan_Liu1', '~Zhengbang_Zhu1', '~Menghui_Zhu1', '~Yuzheng_Zhuang1', '~Weinan_Zhang1', '~Jianye_HAO1']","['reinforcement learning', 'transfer learning']","In reinforcement learning applications, agents usually need to deal with various input/output features when specified with different state and action spaces by their developers or physical restrictions, indicating re-training from scratch and considerable sample inefficiency, especially when agents follow similar solution steps to achieve tasks.
In this paper, we aim to transfer pre-trained skills to alleviate the above challenge. Specifically, we propose PILoT, i.e., Planning Immediate Landmarks of Targets. PILoT utilizes the universal decoupled policy optimization to learn a goal-conditioned state planner; then, we distill a goal-planner to plan immediate landmarks in a model-free style that can be shared among different agents. In our experiments, we show the power of PILoT on various transferring challenges, including few-shot transferring across action spaces and dynamics, from low-dimensional vector states to image inputs, from simple robot to complicated morphology; and we also illustrate PILoT provides a zero-shot transfer solution from a simple 2D navigation task to the harder Ant-Maze task.",https://openreview.net/pdf/1268f4a67e362911d65e2a20d7838b6c7a80f1fd.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=M_MvkWgQSt,Real-time variational method for learning neural trajectory and its dynamics,"['Matthew Dowling', 'Yuan Zhao', 'Il Memming Park']","['~Matthew_Dowling2', '~Yuan_Zhao1', '~Il_Memming_Park1']","['neural dynamics', 'neural trajectory', 'online variational inference']","Latent variable models have become instrumental in computational neuroscience for reasoning about neural computation.  This has fostered the development of powerful offline algorithms for extracting latent neural trajectories from neural recordings.  However, despite the potential of real-time alternatives to give immediate feedback to experimentalists, and enhance experimental design, they have received markedly less attention.  In this work, we introduce the exponential family variational Kalman filter (eVKF), an online recursive Bayesian method aimed at inferring latent trajectories while simultaneously learning the dynamical system generating them.  eVKF works for arbitrary likelihoods and utilizes the constant base measure exponential family to model the latent state stochasticity. We derive a closed-form variational analog to the predict step of the Kalman filter which leads to a provably tighter bound on the ELBO compared to another online variational method. We validate our method on synthetic and real-world data, and, notably, show that it achieves competitive performance.",https://openreview.net/pdf/f2a3ae5af4f08eb6ca19ee6d8642f0023b244943.pdf,{'title_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=MZFDUB40NJ,Uncertainty-aware off policy learning,"['Xiaoying Zhang', 'Junpu Chen', 'Hongning Wang', 'Hong Xie', 'Hang Li']","['~Xiaoying_Zhang3', '~Junpu_Chen1', '~Hongning_Wang1', '~Hong_Xie2', '~Hang_Li4']","['off-policy learning', 'uncertainty']","Off-policy learning, referring to the procedure of policy optimization with access only to logged feedback data, has shown importance in various real-world applications, such as search engines, recommender systems, etc.  While the ground-truth logging policy, which generates the logged data, is usually unknown, previous work directly takes its estimated value in off-policy learning, resulting in a biased estimator. This estimator has both high bias and variance on samples with small and inaccurate estimated logging probabilities. 
In this work, we explicitly model the uncertainty in the estimated logging policy and propose a novel  \underline{U}ncertainty-aware \underline{I}nverse  \underline{P}ropensity \underline{S}core estimator (UIPS) for improved off-policy learning. Experiment results on synthetic and three real-world  recommendation datasets demonstrate the advantageous sample efficiency of the proposed UIPS estimator.",https://openreview.net/pdf/82abf43a1a49fce58d576fe6273ca74fccae387e.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=LiXDW7CF94J,How robust is unsupervised representation learning to distribution shift?,"['Yuge Shi', 'Imant Daunhawer', 'Julia E Vogt', 'Philip Torr', 'Amartya Sanyal']","['~Yuge_Shi1', '~Imant_Daunhawer2', '~Julia_E_Vogt1', '~Philip_Torr1', '~Amartya_Sanyal1']","['distribution shift', 'OOD generalisation', 'spurious correlation', 'simplicity bias', 'SSL', 'unsupervised learning', 'auto-encoder']","The robustness of machine learning algorithms to distributions shift is primarily discussed in the context of supervised learning (SL). As such, there is a lack of insight on the robustness of the representations learned from unsupervised methods, such as self-supervised learning (SSL) and auto-encoder based algorithms (AE), to distribution shift. We posit that the input-driven objectives of unsupervised algorithms lead to representations that are more robust to distribution shift than the target-driven objective of SL. We verify this by extensively evaluating the performance of SSL and AE on both synthetic and realistic distribution shift datasets. Following observations that the linear layer used for classification itself can be susceptible to spurious correlations, we evaluate the representations using a linear
head trained on a small amount of out-of-distribution (OOD) data, to isolate the robustness of the learned representations from that of the linear head. We also develop “controllable” versions of existing realistic domain generalisation datasets with adjustable degrees of distribution shifts. This allows us to study the robustness of different learning algorithms under versatile yet realistic distribution shift
conditions. Our experiments show that representations learned from unsupervised learning algorithms generalise better than SL under a wide variety of extreme as well as realistic distribution shifts.",https://openreview.net/pdf/4e056f415188ed58053ecc69d8168e2e3af4699f.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=LUql3ZOFwFD,Differentially Private Conditional Text Generation For Synthetic Data Production,"['Pranav Putta', 'Ander Steele', 'Joseph W Ferrara']","['~Pranav_Putta1', '~Ander_Steele1', '~Joseph_W_Ferrara1']","['differential privacy', 'conditional text generation', 'NLP']","Companies have faced increasing pressure in recent years to anonymize user collected data when sharing internally or to third parties. Text data in particular contains copious amounts of personally identifiable information that has proven to be difficult to de-identify while remain useful for the party of interest. Previous works have suggested that synthetic text generation could provide a promising avenue to curate high performant and private datasets. In this paper, we introduce an approach to synthesize high utility text classification datasets by performing conditional generation through a large language model, distilGPT2, while providing measurable guarantees via differential privacy. We show that naive approaches suffer heavily from utility loss by entangling task-relevant factors in the transformer embedding space, making controlled generation more difficult. We analyze how incorporating a secondary learning objective can improve the performance of the generative model, improving utility of the generated data.",https://openreview.net/pdf/da80055e8a1f2af09d27a65feb9e5b15654769cf.pdf,{'title_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=LNpMtk15AS4,Boosting Causal Discovery via Adaptive Sample Reweighting,"['An Zhang', 'Fangfu Liu', 'Wenchang Ma', 'Zhibo Cai', 'Xiang Wang', 'Tat-Seng Chua']","['~An_Zhang2', '~Fangfu_Liu2', '~Wenchang_Ma1', '~Zhibo_Cai1', '~Xiang_Wang6', '~Tat-Seng_Chua2']","['Causal Structure Learning', 'Score-based Causal Discovery', 'Adaptive Sample Reweighting']","Under stringent model type and variable distribution assumptions, score-based causal discovery methods learn the directed acyclic graph (DAG) from observational data by evaluating candidate graphs over an averaged score function. Despite the great success in low-dimensional linear systems, it has been observed that these approaches overly exploits easier-to-fit samples, thus inevitably learning spurious edges. Worse still, the common homogeneity assumption of most causal discovery methods can be easily violated due to the widespread existence of heterogeneous data in the real world, resulting in performance vulnerability when noise distributions vary. We propose a simple yet effective model-agnostic framework to boost causal discovery performance by dynamically learning the adaptive weights for the Reweighted Score function, ReScore for short, where the learned weights tailors quantitatively to the important degree of each samples. Intuitively, we leverage the bilevel optimization scheme to alternatively train a standard DAG learner first, then upweight the samples that the DAG learner fails to fit well and downweight the samples that the DAG learner easily extracts the causation information from. Extensive experiments on both synthetic and real-world datasets are carried out to validate the effectiveness of ReScore. We observe consistent and significant boosts in structure learning performance. We further visualize that ReScore concurrently mitigates the influence of spurious edges and generalizes to heterogeneous data. Finally, we perform theoretical analysis to guarantee the structure identifiability and the weight adaptive properties of ReScore. Our codes are available at https://github.com/anzhang314/ReScore.",https://openreview.net/pdf/490a8e5885f74912244f797f7afd7060d7d2bbe9.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=LIV7-_7pYPl,DexDeform: Dexterous Deformable Object Manipulation with Human Demonstrations and Differentiable Physics,"['Sizhe Li', 'Zhiao Huang', 'Tao Chen', 'Tao Du', 'Hao Su', 'Joshua B. Tenenbaum', 'Chuang Gan']","['~Sizhe_Li1', '~Zhiao_Huang1', '~Tao_Chen1', '~Tao_Du1', '~Hao_Su1', '~Joshua_B._Tenenbaum1', '~Chuang_Gan1']","['Deformable Object Manipulation', 'Dexterous Manipulation', 'Differentiable Physics']","In this work, we aim to learn dexterous manipulation of deformable objects using multi-fingered hands. Reinforcement learning approaches for dexterous rigid object manipulation would struggle in this setting due to the complexity of physics interaction with deformable objects. At the same time, previous trajectory optimization approaches with differentiable physics for deformable manipulation would suffer from local optima caused by the explosion of contact modes from hand-object interactions. To address these challenges, we propose DexDeform, a principled framework that abstracts dexterous manipulation skills from human demonstration, and refines the learned skills with differentiable physics. Concretely, we first collect a small set of human demonstrations using teleoperation. And we then train a skill model using demonstrations for planning over action abstractions in imagination. To explore the goal space, we further apply augmentations to the existing deformable shapes in demonstrations and use a gradient optimizer to refine the actions planned by the skill model. Finally, we adopt the refined trajectories as new demonstrations for finetuning the skill model. To evaluate the effectiveness of our approach, we introduce a suite of six challenging dexterous deformable object manipulation tasks. Compared with baselines, DexDeform is able to better explore and generalize across novel goals unseen in the initial human demonstrations. Additional materials can be found at our project website: https://sites.google.com/view/dexdeform.",https://openreview.net/pdf/40f58e1097499c5bdbba2b9dea60f73decfcf1b9.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=L6CKiPH3hI,Enriching Online Knowledge Distillation with Specialist Ensemble,"['Mincheol Park', 'Woojeong Kim', 'Junsik Bang', 'Won Woo Ro', 'Suhyun Kim']","['~Mincheol_Park1', '~Woojeong_Kim1', '~Junsik_Bang1', '~Won_Woo_Ro1', '~Suhyun_Kim1']","['Online knowledge distillation', 'Label prior shift', 'Ensemble learning']","Online Knowledge Distillation (KD) has an advantage over traditional KD works in that it removes the necessity for a pre-trained teacher. Indeed, an ensemble of small teachers has become typical guidance for a student's learning trajectory. Previous works emphasized diversity to create helpful ensemble knowledge and further argued that the size of diversity should be significant to prevent homogenization. This paper proposes a well-founded online KD framework with naturally derived specialists. In supervised learning, the parameters of a classifier are optimized by stochastic gradient descent based on a training dataset distribution. If the training dataset is shifted, the optimal point and corresponding parameters change accordingly, which is natural and explicit.
We first introduce a label prior shift to induce evident diversity among the same teachers, which assigns a skewed label distribution to each teacher and simultaneously specializes them through importance sampling. Compared to previous works, our specialization achieves the highest level of diversity and maintains it throughout training. Second, we propose a new aggregation that uses post-compensation in specialist outputs and conventional model averaging. The aggregation empirically exhibits the advantage of ensemble calibration even if applied to previous diversity-eliciting methods. Finally, through extensive experiments, we demonstrate the efficacy of our framework on top-1 error rate, negative log-likelihood, and notably expected calibration error.",https://openreview.net/pdf/2ff38143ff2c4a2d71c39020214dc3f2f42ea25d.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=L2MUOUp0beo,CoRTX: Contrastive Framework for Real-time Explanation,"['Yu-Neng Chuang', 'Guanchu Wang', 'Fan Yang', 'Quan Zhou', 'Pushkar Tripathi', 'Xuanting Cai', 'Xia Hu']","['~Yu-Neng_Chuang1', '~Guanchu_Wang1', '~Fan_Yang27', '~Quan_Zhou5', '~Pushkar_Tripathi2', '~Xuanting_Cai1', '~Xia_Hu4']","['Interpretability', 'explainability', 'real-time explanation', 'feature attribution', 'feature importance ranking']","Recent advancements in explainable machine learning provide effective and faithful solutions for interpreting model behaviors. However, many explanation methods encounter efficiency issues, which largely limit their deployments in practical scenarios. Real-time explainer (RTX) frameworks have thus been proposed to accelerate the model explanation process by learning an one-feed-forward explainer. Existing RTX frameworks typically build the explainer under the supervised learning paradigm, which requires large amounts of explanation labels as the ground truth. Considering that accurate explanation labels are usually hard to obtain, due to constrained computational resources and limited human efforts, effective explainer training is still challenging in practice. In this work, we propose a COntrastive Real-Time eXplanation (CoRTX) framework to learn the explanation-oriented representation and relieve the intensive dependence of explainer training on explanation labels. Specifically, we design a synthetic strategy to select positive and negative instances for explanation representation learning. Theoretical analysis show that our selection strategy can benefit the contrastive learning process on explanation tasks. Experimental results on three real-world datasets further demonstrate the efficiency and efficacy of our proposed CoRTX framework.",https://openreview.net/pdf/8e9825a8e9446ab79ae7406ff203d26aef5828ed.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Kn43SKplAn,3D Surface Reconstruction in the Wild by Deforming Shape Priors from Synthetic Data,"['Nicolai Haeni', 'Jun-Jee Chao', 'Volkan Isler']","['~Nicolai_Haeni1', '~Jun-Jee_Chao1', '~Volkan_Isler1']","['3D reconstruction', 'pose estimation', 'shape deformation']","We present a new method for category-specific 3D reconstruction from a single image. A limitation of current color image-based 3D reconstruction models is that they do not generalize across datasets, due to domain shift. In contrast, we show that one can learn to reconstruct objects across datasets by shape priors learned from synthetic 3D data and a point cloud pose canonicalization method. Given a single depth image at test time, we first place this partial point cloud in a canonical pose. Then, we use a neural deformation field in the canonical coordinate frame to reconstruct the 3D surface of the object. Finally, we jointly optimize object pose and 3D shape to fit the partial depth observation. Our approach achieves state-of-the-art reconstruction performance across several real-world datasets, even when trained without ground truth camera poses (which are required by some of the state-of-the-art methods). We further show that our method generalizes to different input modalities, from dense depth images to sparse and noisy LIDAR scans. ",https://openreview.net/pdf/98af33e19325b70a87c0c15d55ea7d44cf48cab7.pdf,{'title_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=KiT3-iN8wHJ,Uncertainty and Traffic Light Aware Pedestrian Crossing Intention Prediction,"['Minali Upreti', 'Jayanth Ramesh', 'Chandan R Kumar', 'Bodhisattwa Chakraborty', 'VIKRAM BALISAVIRA', 'Phillip Czech', 'Vitali Kaiser', 'Markus Roth']","['~Minali_Upreti1', '~Jayanth_Ramesh1', '~Chandan_R_Kumar1', '~Bodhisattwa_Chakraborty1', '~VIKRAM_BALISAVIRA1', '~Phillip_Czech1', '~Vitali_Kaiser1', '~Markus_Roth1']","['deep learning', 'computer vision', 'recurrent neural networks', 'uncertainty estimation', 'intention prediction', 'attention mechanism', 'autonomous driving']","Predicting Vulnerable Road User (VRU) crossing intention is one of the major challenges in automated driving. Crossing intention prediction systems trained only on pedestrian features underperform in situations that are most obvious to humans, as the latter take additional context features into consideration. Moreover, such systems tend to be over-confident for out-of-distribution samples, therefore making them less reliable to be used by downstream tasks like sensor fusion and trajectory planning for automated vehicles. In this work, we demonstrate that the results of crossing intention prediction systems can be improved by incorporating traffic light status as an additional input. Further, we make the model robust and interpretable by estimating uncertainty. Experiments on the PIE dataset show that the F1-score improved from 0.77 to 0.82 and above for three different baseline systems when considering traffic-light context. By adding uncertainty, we show increased uncertainty values for out-of-distribution samples, therefore leading to interpretable and reliable predictions of crossing intention.",https://openreview.net/pdf/569a45050d5aeaea2b37970f9bca09dc84f54b9b.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Ki4ocDm364,Scaling Pareto-Efficient Decision Making via Offline Multi-Objective RL,"['Baiting Zhu', 'Meihua Dang', 'Aditya Grover']","['~Baiting_Zhu1', '~Meihua_Dang1', '~Aditya_Grover1']","['Reinforcement Learning', 'Offline Reinforcement Learning', 'Multi-Objective Reinforcement Learning', 'Decision Transformer', 'Sequential Decision Making']","The goal of multi-objective reinforcement learning (MORL) is to learn policies that simultaneously optimize multiple competing objectives. In practice, an agent's preferences over the objectives may not be known apriori, and hence, we require policies that can generalize to arbitrary preferences at test time. In this work, we propose a new data-driven setup for offline MORL, where we wish to learn a preference-agnostic policy agent using only a finite dataset of offline demonstrations of other agents and their preferences. The key contributions of this work are two-fold. First, we introduce D4MORL, (D)atasets for MORL that are specifically designed for offline settings. It contains 1.8 million annotated demonstrations obtained by rolling out reference policies that optimize for randomly sampled preferences on 6 MuJoCo environments with 2-3 objectives each. Second, we propose Pareto-Efficient Decision Agents (PEDA), a family of offline MORL algorithms that builds and extends Decision Transformers via a novel preference-and-return-conditioned policy. Empirically, we show that PEDA closely approximates the behavioral policy on the D4MORL benchmark and provides an excellent approximation of the Pareto-front with appropriate conditioning, as measured by the hypervolume and sparsity metrics. ",https://openreview.net/pdf/3d73c1e257eb3d1dd034f43fe3b51884a6dfade4.pdf,{'abstract_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=KaeYRGTaODt,Multi-Agent Policy Transfer via Task Relationship Modeling,"['Rong-Jun Qin', 'Feng Chen', 'Tonghan Wang', 'Lei Yuan', 'Xiaoran Wu', 'Yipeng Kang', 'Zongzhang Zhang', 'Chongjie Zhang', 'Yang Yu']","['~Rong-Jun_Qin1', '~Feng_Chen12', '~Tonghan_Wang1', '~Lei_Yuan2', '~Xiaoran_Wu1', '~Yipeng_Kang1', '~Zongzhang_Zhang1', '~Chongjie_Zhang1', '~Yang_Yu5']","['Multi-agent reinforcement learning', 'cooperative transfer learning']","Team adaptation to new cooperative tasks is a hallmark of human intelligence, which has yet to be fully realized in learning agents. Previous works on multi-agent transfer learning accommodate teams of different sizes, but heavily rely on the generalization ability of neural networks for adapting to unseen tasks. We posit that the relationship among tasks provides the key information for policy adaptation. To utilize such relationship for efficient transfer, we try to discover and exploit the knowledge among tasks from different teams, propose to learn effect-based task representations as a common latent space among tasks, and use it to build an alternatively fixed training scheme. We demonstrate that the task representation can capture the relationship among teams and generalize to unseen tasks. As a result, the proposed method can help transfer learned cooperation knowledge to new tasks after training on a few source tasks, and the learned transferred policies can also help solve tasks that are hard to learn from scratch.",https://openreview.net/pdf/fc1720abd9708aa25ab7ce8f93ed89d2794e3e3f.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=K1Z-P0Le0DT,Recurrent Real-valued Neural Autoregressive Density Estimator for Online Density Estimation and Classification of Streaming Data,"['Tianyu Li', 'Bogdan Mazoure', 'Guillaume Rabusseau']","['~Tianyu_Li3', '~Bogdan_Mazoure1', '~Guillaume_Rabusseau1']","['density estimation', 'online learning', 'streaming data', 'classification']","In contrast with the traditional offline learning, where complete data accessibility is assumed, many modern applications involve processing data in a streaming fashion. This online learning setting raises various challenges, including concept drift, hardware memory constraints, etc. In this paper, we propose the Recurrent Real-valued Neural Autoregressive Density Estimator (RRNADE), a flexible density-based model for online classification and density estimation. RRNADE combines a neural Gaussian mixture density module with a recurrent module. This combination allows RRNADE to exploit possible sequential correlations in the streaming task, which are often ignored in the classical streaming setting where each input is assumed to be independent from the previous ones. We showcase the ability of RRNADE to adapt to concept drifts on synthetic density estimation tasks. We also apply RRNADE to online classification tasks on both real world and synthetic datasets and compare it with multiple density based as well as nondensity based online classification methods. In almost all of these tasks, RRNADE outperforms the other methods. Lastly, we conduct an ablation study demonstrating the complementary benefits of the density and the recurrent modules.",https://openreview.net/pdf/21ee454f7a986d75f2e134372e9c2fb5b25a1848.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=K1NKDaNM9i,Counterfactual Vision-Language Data Synthesis with Intra-Sample Contrast Learning,"['Zhecan Wang', 'Yicheng He', 'Wenhao Li', 'Haoxuan You', 'Long Chen', 'Noel C Codella', 'Yulei Niu', 'Kai-Wei Chang', 'Shih-Fu Chang']","['~Zhecan_Wang2', 'yh3330@columbia.edu', 'wl2750@columbia.edu', '~Haoxuan_You1', '~Long_Chen8', '~Noel_C_Codella1', '~Yulei_Niu1', '~Kai-Wei_Chang1', '~Shih-Fu_Chang3']","['counterfactual', 'data augmentation', 'vision language', 'kowledge distillation', 'vcr', 'vqa', 'visual question answering', 'commonsense reasoning', 'multimodal', 'robust', 'domain-shift', 'debiased']","Existing Visual Learning (VL) benchmarks often contain exploitative biases. Most former works only attempted to mitigate biases in semantically low-level and conventional visual-question-answering typed datasets like VQA and GQA. However, these methods cannot generalize to recently emerging highly semantic VL datasets like VCR and are also difficult to scale due to many severe problems like high-cost labors, drastically disrupting the data distribution\textit{, etc.}To resolve those problems and also address other unique biases on VCR-like datasets, we first conduct in-depth analysis and identify important biases in VCR dataset. We further propose a generalized solution that synthesizes counterfactual image and text data based on the original query's semantic focus while producing less distortion to the data distribution. To utilize our synthesized data, we also design an innovative intra-sample contrastive training strategy to assist QA learning in Visual Commonsense Reasoning (VCR). Moreover, our synthesized VL data also serve as a highly-semantic debiased benchmark for evaluating future VL models' robustness. Extensive experiments show that our proposed synthesized data and training strategy improve existing VL models' performances on both the original VCR dataset and our proposed debiased benchmark.",https://openreview.net/pdf/d1b5c296ac9bf1fd5add23936a6a867caf241799.pdf,{'title_filter': 'Data Synthesis'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=JtC6yOHRoJJ,Human-level Atari 200x faster,"['Steven Kapturowski', 'Víctor Campos', 'Ray Jiang', 'Nemanja Rakicevic', 'Hado van Hasselt', 'Charles Blundell', 'Adria Puigdomenech Badia']","['~Steven_Kapturowski1', '~Víctor_Campos1', '~Ray_Jiang1', '~Nemanja_Rakicevic1', '~Hado_van_Hasselt1', '~Charles_Blundell1', '~Adria_Puigdomenech_Badia2']","['Reinforcement Learning', 'Data-efficiency', 'Exploration', 'Off-policy']","The task of building general agents that perform well over a wide range of tasks has been an important goal in reinforcement learning since its inception. The problem has been subject of research of a large body of work, with performance frequently measured by observing scores over the wide range of environments contained in the Atari 57 benchmark. Agent57 was the first agent to surpass the human benchmark on all 57 games, but this came at the cost of poor data-efficiency, requiring nearly 80 billion frames of experience to achieve. Taking Agent57 as a starting point, we employ a diverse set of strategies to achieve a 200-fold reduction of experience needed to outperform the human baseline, within our novel agent MEME. We investigate a range of instabilities and bottlenecks we encountered while reducing the data regime, and propose effective solutions to build a more robust and efficient agent. We also demonstrate competitive performance with high-performing methods such as Muesli and MuZero. Our contributions aim to achieve faster propagation of learning signals related to rare events, stabilize learning under differing value scales, improve the neural network architecture, and make updates more robust under a rapidly-changing policy.",https://openreview.net/pdf/b23bc123e103d66e46f6b7516e3fb6dffd1d2cba.pdf,{'abstract_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=JsrvkgM8gO2,Large Learning Rate Matters for Non-Convex Optimization,"['Amirkeivan Mohtashami', 'Martin Jaggi', 'Sebastian U Stich']","['~Amirkeivan_Mohtashami1', '~Martin_Jaggi1', '~Sebastian_U_Stich1']","['large learning rates', 'GD', 'SGD', 'non-convex optimization']","When training neural networks, it has been widely observed that a large step size is essential in stochastic gradient descent (SGD) for obtaining superior models. However, the effect of large step sizes on the success of SGD is not well understood theoretically. 
Several previous works have attributed this success to the stochastic noise present in SGD.  However, we show through a novel set of experiments that the stochastic noise is not sufficient to explain good non-convex training, and that instead the effect of a large learning rate itself is essential for obtaining best performance.
We demonstrate the same effects also in the noise-less case, i.e. for full-batch GD. We formally prove that GD with large step size---on certain non-convex function classes---follows a different trajectory than GD with a small step size, which can lead to convergence to a global minimum instead of a local one. 
Finally, we also demonstrate the difference in trajectories for small and large learning rates for real neural networks, again observing that large learning rates allow escaping from a local minimum, confirming this behavior is indeed relevant in practice.",https://openreview.net/pdf/dfe38e5de9e409abd5d1ac3a7204d02508e79e62.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=JmkjrlVE-DG,Over-Training with Mixup May Hurt Generalization,"['Zixuan Liu', 'Ziqiao Wang', 'Hongyu Guo', 'Yongyi Mao']","['~Zixuan_Liu3', '~Ziqiao_Wang1', '~Hongyu_Guo1', '~Yongyi_Mao2']","['Mixup', 'Generalization', 'Overfitting', 'Regularization']","Mixup, which creates synthetic training instances by linearly interpolating random sample pairs, is a simple and yet effective regularization technique to boost the performance of deep models trained with SGD. In this work, we report a previously unobserved phenomenon in Mixup raining: on a number of standard datasets, the performance of Mixup-trained models starts to decay after training for a large number of epochs, giving rise to a  U-shaped generalization curve. This behavior is further aggravated when the size of original dataset is reduced. To help understand such a behavior of Mixup, we show theoretically that Mixup training may introduce undesired data-dependent label noises to the synthesized data. Via analyzing a least-square regression problem with a random feature model, we explain why noisy labels may cause the U-shaped curve to occur: Mixup improves generalization through fitting the clean patterns at the early training stage,  but as training progresses, Mixup becomes over-fitting to the noise in the synthetic data. Extensive experiments are performed on a variety of benchmark datasets, validating this explanation.",https://openreview.net/pdf/9b1abc99da7f78ec360a4288ad20cecabb1eed6a.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=JdTnc9gjVfJ,MoDem: Accelerating Visual Model-Based Reinforcement Learning with Demonstrations,"['Nicklas Hansen', 'Yixin Lin', 'Hao Su', 'Xiaolong Wang', 'Vikash Kumar', 'Aravind Rajeswaran']","['~Nicklas_Hansen1', '~Yixin_Lin1', '~Hao_Su1', '~Xiaolong_Wang3', '~Vikash_Kumar2', '~Aravind_Rajeswaran1']","['model-based reinforcement learning', 'visual reinforcement learning', 'learning from demonstrations']","Poor sample efficiency continues to be the primary challenge for deployment of deep Reinforcement Learning (RL) algorithms for real-world applications, and in particular for visuo-motor control. Model-based RL has the potential to be highly sample efficient by concurrently learning a world model and using synthetic rollouts for planning and policy improvement. However, in practice, sample-efficient learning with model-based RL is bottlenecked by the exploration challenge. In this work, we find that leveraging just a handful of demonstrations can dramatically improve the sample-efficiency of model-based RL. Simply appending demonstrations to the interaction dataset, however, does not suffice. We identify key ingredients for leveraging demonstrations in model learning -- policy pretraining, targeted exploration, and oversampling of demonstration data -- which forms the three phases of our model-based RL framework. We empirically study three complex visuo-motor control domains and find that our method is 160%-250% more successful in completing sparse reward tasks compared to prior approaches in the low data regime (100k interaction steps, 5 demonstrations). Code and videos are available at https://nicklashansen.github.io/modemrl.",https://openreview.net/pdf/6a5db4c4bb6e33558fd94164736145a682ec92a3.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=JVlyfHEEm0k,Understanding Train-Validation Split in Meta-Learning with Neural Networks,"['Xinzhe Zuo', 'Zixiang Chen', 'Huaxiu Yao', 'Yuan Cao', 'Quanquan Gu']","['~Xinzhe_Zuo1', '~Zixiang_Chen1', '~Huaxiu_Yao1', '~Yuan_Cao1', '~Quanquan_Gu1']","['meta-learning', 'neural networks', 'deep learning', 'train-validation split', 'convolutional neural network']","The goal of meta-learning is to learn a good prior model from a collection of tasks such that the learned prior is able to adapt quickly to new tasks without accessing many data from the new tasks. A common practice in meta-learning is to perform a train-validation split on each task, where the training set is used for adapting the model parameter to that specific task and the validation set is used for learning a prior model that is shared across all tasks. Despite its success and popularity in multitask learning and few-shot learning, the understanding of the train-validation split is still limited, especially when the neural network models are used. In this paper, we study the benefit of train-validation split for classification problems with neural network models trained by gradient descent. We prove that the train-validation split is necessary to learn a good prior model when the noise in the training sample is large, while the train-train method fails. We validate our theory by conducting experiment on both synthetic and real datasets. To the best of our knowledge, this is the first work towards the theoretical understanding of train-validation split in meta-learning with neural networks.",https://openreview.net/pdf/b36628c00cf099f06c22fb730529a978598fddfa.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=JUNKYmGGuEw,Neural multi-event forecasting on spatio-temporal point processes using probabilistically enriched transformers,"['Negar Erfanian', 'Santiago Segarra', 'Maarten V. de Hoop']","['~Negar_Erfanian1', '~Santiago_Segarra1', '~Maarten_V._de_Hoop2']","['Stochastic Point Processes', 'Multi-event Prediction', 'Transformers', 'Normalizing Flows', 'Hawkes Process', 'Deep Learning', 'Generative Models']","Predicting discrete events in time and space has many scientific applications, such as predicting hazardous earthquakes and outbreaks of infectious diseases. History-dependent spatio-temporal Hawkes processes are often used to mathematically model these point events. However, previous approaches have faced numerous challenges, particularly when attempting to forecast multiple future events. In this work, we propose a new neural architecture for multi-event forecasting of spatio-temporal point processes, utilizing transformers, augmented with normalizing flows and probabilistic layers. Our network makes batched predictions of complex history-dependent spatio-temporal distributions of future discrete events, achieving state-of-the-art performance on a variety of benchmark datasets including the South California Earthquakes, Citibike, Covid19, and Hawkes synthetic Pinwheel datasets. More generally, we illustrate how our network can be applied to any dataset of discrete events with associated markers, even when no underlying physics is known.",https://openreview.net/pdf/886cc923e40101cd74cec91aa5c918686d5a8dc9.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=JOix_wb4AeM,In-distribution and Out-of-distribution Generalization for Graph Neural Networks,"['Emmanuel Sales', 'Renjie Liao', 'Nick Harvey']","['~Emmanuel_Sales1', '~Renjie_Liao1', '~Nick_Harvey1']","['Graph Neural Networks', 'Generalization Bounds', 'Out-of-distribution generalization', 'Learning theory']","Graph neural networks (GNNs) are models that allow learning with structured data of varying size. Despite their popularity, theoretical understanding of the generalization of GNNs is an under-explored topic. In this work, we expand the theoretical understanding of both in-distribution and out-of-distribution generalization of GNNs. Firstly, we improve upon the state-of-the-art PAC-Bayes (in-distribution) generalization bound primarily by reducing an exponential dependency on the node degree to a linear dependency. Secondly, utilizing tools from spectral graph theory, we prove some rigorous guarantees about the out-of-distribution (OOD) size generalization of GNNs, where graphs in the training set have different numbers of nodes and edges from those in the test set. To empirically verify our theoretical findings, we conduct experiments on both synthetic and real-world graph datasets. Our computed generalization gaps for the in-distribution case significantly improve the state-of-the-art PAC-Bayes results. For the OOD case, experiments on community classification tasks in large social networks show that GNNs achieve strong size generalization performance in cases guaranteed by our theory.",https://openreview.net/pdf/fafbe048be3a4216c1eb808b8c7e1ea7512b71e2.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=JDuEddUsSb,Efficient Discovery of Dynamical Laws in Symbolic Form,"['Sören Becker', 'Michal Klein', 'Alexander Neitz', 'Giambattista Parascandolo', 'Niki Kilbertus']","['~Sören_Becker2', '~Michal_Klein1', '~Alexander_Neitz1', '~Giambattista_Parascandolo1', '~Niki_Kilbertus1']","['Symbolic', 'ODE', 'Transformer']","We propose a transformer-based sequence-to-sequence model that recovers scalar ordinary differential equations (ODEs) in symbolic form from time-series data of a single observed solution trajectory of the ODE. Our method is efficiently scalable: after one-time pretraining on a large set of ODEs, we can infer the governing laws of a new observed solution in a few forward passes of the model. First, we generate and make available a large dataset of more than 3M ODEs together with more than 63M numerical solutions for different initial conditions that may serve as a useful benchmark for future work on machine learning for dynamical systems. Then we show that our model performs better or on par with existing methods in various test cases in terms of accurate symbolic recovery of the ODE, especially for more complex expressions. Reliably recovering the symbolic form of dynamical laws is important as it allows for further dissemination of the inferred dynamics as well as meaningful modifications for predictions under interventions.",https://openreview.net/pdf/090b4b0ec856b04f45884d46e851b8ee2a8ee404.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=J7CTp-jNyJ,SYNG4ME: Model Evaluation using Synthetic Test Data,"['Boris van Breugel', 'Nabeel Seedat', 'Fergus Imrie', 'Mihaela van der Schaar']","['~Boris_van_Breugel2', '~Nabeel_Seedat1', '~Fergus_Imrie1', '~Mihaela_van_der_Schaar2']","['Model Evaluation', 'Synthetic data']","Model evaluation is a crucial step in ensuring reliable machine learning systems. Currently, predictive models are evaluated on held-out test data, quantifying aggregate model performance. Limitations of available test data make it challenging to evaluate model performance on small subgroups or when the environment changes. Synthetic test data provides a unique opportunity to address this challenge; instead of evaluating predictive models on real data, we propose to use synthetic data. This brings two advantages. First, supplementing and increasing the amount of evaluation data can lower the variance of model performance estimates compared to evaluation on the original test data. This is especially true for local performance evaluation in low-density regions, e.g. minority or intersectional groups. Second, generative models can be conditioned as to induce a shift in the synthetic data distribution, allowing us to evaluate how supervised models could perform in different target settings. In this work, we propose SYNG4ME: an automated suite of synthetic data generators for model evaluation. By generating smart synthetic data sets, data practitioners have a new tool for exploring how supervised models may perform on subgroups of the data, and how robust methods are to distributional shifts. We show experimentally that SYNG4ME achieves more accurate performance estimates compared to using the test data alone.",https://openreview.net/pdf/07814e3fdf1a092fbe16856bc382b68d8260fb58.pdf,{'title_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=IVESH65r0Ar,A Simple Yet Powerful Deep Active Learning With Snapshots Ensembles,"['Seohyeon Jung', 'Sanghyun Kim', 'Juho Lee']","['~Seohyeon_Jung1', '~Sanghyun_Kim2', '~Juho_Lee2']","['Active learning', 'Snapshot ensemble', 'Uncertainty estimation']","Given an unlabeled pool of data and the experts who can label them, active learning aims to build an agent that can effectively acquire data to be queried to the experts, maximizing the gain in performance when trained with them. While there are several principles for active learning, a prevailing approach is to estimate uncertainties of predictions for unlabeled samples and use them to define acquisition functions. Active learning with the uncertainty principle works well for deep learning, especially for large-scale image classification tasks with deep neural networks. Still, it is often overlooked how the uncertainty of predictions is estimated, despite the common findings on the difficulty of accurately estimating uncertainties of deep neural networks. In this paper, we highlight the effectiveness of snapshot ensembles for deep active learning. Compared to the previous approaches based on Monte-Carlo dropout or deep ensembles, we show that a simple acquisition strategy based on uncertainties estimated from parameter snapshots gathered from a single optimization path significantly improves the quality of the acquired samples. Based on this observation, we further propose an efficient active learning algorithm that maintains a single learning trajectory throughout the entire active learning episodes, unlike the existing algorithms training models from scratch for every active learning episode. Through the extensive empirical comparison, we demonstrate the effectiveness of snapshot ensembles for deep active learning.",https://openreview.net/pdf/4b4df3d988ecc07d73d78a6a4063cc0c3153a2aa.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=HnSceSzlfrY,RPM: Generalizable Multi-Agent Policies for Multi-Agent Reinforcement Learning,"['Wei Qiu', 'Xiao Ma', 'Bo An', 'Svetlana Obraztsova', 'Shuicheng YAN', 'Zhongwen Xu']","['~Wei_Qiu3', '~Xiao_Ma2', '~Bo_An2', '~Svetlana_Obraztsova1', '~Shuicheng_YAN3', '~Zhongwen_Xu1']","['multi-agent system', 'multi-agent reinforcement learning']","Despite the recent advancement in multi-agent reinforcement learning (MARL), the MARL agents easily overfit the training environment and perform poorly in evaluation scenarios where other agents behave differently. Obtaining generalizable policies for MARL agents is thus necessary but challenging mainly due to complex multi-agent interactions. In this work, we model the MARL problem with Markov Games and propose a simple yet effective method, called ranked policy memory (RPM), i.e., to maintain a look-up memory of policies to achieve good generalizability. The main idea of RPM is to train MARL policies via gathering massive multi-agent interaction data. In particular, we first rank each agent’s policies by its training episode return, i.e., the episode return of each agent in the training environment; we then save the ranked policies in the memory; when an episode starts, each agent can randomly select a policy from the RPM as the behavior policy. Each agent uses the behavior policy to gather multi-agent interaction data for MARL training. This innovative self-play framework guarantees the diversity of multi-agent interaction in the training data. Experimental results on Melting Pot demonstrate that RPM enables MARL agents to interact with unseen agents in multi-agent generalization evaluation scenarios and complete given tasks. It significantly boosts the performance up to 818% on average.",https://openreview.net/pdf/e0f67e22108de8d6be84c75330ee0de82ed3ae5a.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Hh0BdBf6Ls,UNREAL: Unlabeled Nodes Retrieval and Labeling for Heavily-imbalanced Node Classification,"['Liang Yan', 'Shengzhong Zhang', 'Bisheng Li', 'min zhou', 'Zengfeng Huang']","['~Liang_Yan5', '~Shengzhong_Zhang1', '~Bisheng_Li1', '~min_zhou1', '~Zengfeng_Huang1']","['Node Classification', 'Heavily-imbalanced Representation Learning', 'Graph Neural Networks']","Extremely skewed label distributions are common in real-world node classification tasks. If not dealt with appropriately, it significantly hurts the performance of GNNs on minority classes. Due to the practical importance, there have been a series of recent researches devoted to this challenge. Existing over-sampling techniques smooth the label distribution by generating ''fake'' minority nodes and synthesize their features and local topology, which largely ignore the rich information of unlabeled nodes on graphs. Recent methods based on loss function modification re-weight different samples or change classification margins, which achieve good performance. However, representative methods need label information to estimate the distance of each node to its class center, which is unavailable on unlabeled nodes.  In this paper, we propose UNREAL, which is an iterative over-sampling method. The first key difference is that we only add unlabeled nodes instead of synthetic nodes, which eliminates the challenge of feature and neighborhood generation. To select which unlabeled nodes to add, we propose geometric ranking, which ranks unlabeled nodes based on unsupervised learning results in the node embedding space. Finally, we identify the issue of geometric imbalance in the embedding space and provide a simple metric to filter out geometrically imbalanced nodes. Extensive experiments on real-world benchmark datasets are conducted, and the empirical results show that our method significantly outperforms current state-of-the-art methods consistent on different datasets with different imbalance ratios.",https://openreview.net/pdf/fbef3bc8c57cb06ba0e6b7d601a18175a2d40e87.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=H8XpqEkbua_,Differentially Private Dataset Condensation,"['Tianhang Zheng', 'Baochun Li']","['~Tianhang_Zheng2', '~Baochun_Li1']",[],"Recent work in ICML'22 builds a theoretical connection between dataset condensation (DC) and differential privacy (DP) and claims that DC can provide privacy protection for free. However, the connection is problematic because of two controversial assumptions. In this paper, we revisit the ICML'22 work and elucidate the issues in the two controversial assumptions. To correctly connect DC and DP, we propose two differentially private dataset condensation (DPDC) algorithms---LDPDC and NDPDC. Through extensive evaluations on multiple datasets, we demonstrate that LDPDC has comparable performance to recent DP generative methods despite its simplicity. NDPDC provides acceptable DP guarantees with a mild utility loss, compared to the state-of-the-art DC method. Additionally, NDPDC allows a flexible trade-off between the synthetic data utility and DP budget.",https://openreview.net/pdf/05f6f7a918ed03b2dcd4f472eee2f4e0f14e67bb.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=H6LVUiHzYDE,MEGAN: Multi Explanation Graph Attention Network,"['Jonas Teufel', 'Luca Torresi', 'Patrick Nicholas Reiser', 'Pascal Friederich']","['~Jonas_Teufel1', '~Luca_Torresi1', '~Patrick_Nicholas_Reiser1', '~Pascal_Friederich1']","['explainable artificial intelligence', 'interpretable machine learning', 'graph neural networks', 'attention network', 'graph regression', 'graph classification']","Explainable artificial intelligence (XAI) methods are expected to improve trust during human-AI interactions, provide tools for model analysis and extend human understanding of complex problems. Attention-based models are an important subclass of XAI methods, partly due to their full differentiability and the potential to improve explanations by means of explanation-supervised training. We propose the novel multi-explanation graph attention network (MEGAN). Our graph regression and classification model features multiple explanation channels, which can be chosen independently of the task specifications. We first validate our model on a synthetic graph regression dataset, where our model produces single-channel explanations with quality similar to GNNExplainer. Furthermore, we demonstrate the advantages of multi-channel explanations on one synthetic and two real-world datasets: The prediction of water solubility of molecular graphs and sentiment classification of movie reviews. We find that our model produces explanations consistent with human intuition, opening the way to learning from our model in less well-understood tasks.",https://openreview.net/pdf/3e9c0a43ac73486c039e8cb907bf13b8b015ca71.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=H0gdPxSwkPb,Diffusion Adversarial Representation Learning for Self-supervised Vessel Segmentation,"['Boah Kim', 'Yujin Oh', 'Jong Chul Ye']","['~Boah_Kim1', '~Yujin_Oh1', '~Jong_Chul_Ye1']","['Diffusion model', 'Adversarial learning', 'Self-supervised learning', 'Vessel segmentation']","Vessel segmentation in medical images is one of the important tasks in the diagnosis of vascular diseases and therapy planning. Although learning-based segmentation approaches have been extensively studied, a large amount of ground-truth labels are required in supervised methods and confusing background structures make neural networks hard to segment vessels in an unsupervised manner. To address this, here we introduce a novel diffusion adversarial representation learning (DARL) model that leverages a denoising diffusion probabilistic model with adversarial learning, and apply it to vessel segmentation. In particular, for self-supervised vessel segmentation, DARL learns the background signal using a diffusion module, which lets a generation module effectively provide vessel representations. Also, by adversarial learning based on the proposed switchable spatially-adaptive denormalization, our model estimates synthetic fake vessel images as well as vessel segmentation masks, which further makes the model capture vessel-relevant semantic information. Once the proposed model is trained, the model generates segmentation masks in a single step and can be applied to general vascular structure segmentation of coronary angiography and retinal images. Experimental results on various datasets show that our method significantly outperforms existing unsupervised and self-supervised vessel segmentation methods.",https://openreview.net/pdf/daadbc20b5665f981c5c27eeb20cb5e9ba6ac96e.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=GvMuB-YsiK6,Explaining Patterns in Data  with  Language Models via Interpretable Autoprompting,"['Chandan Singh', 'John Xavier Morris', 'Jyoti Aneja', 'Alexander M Rush', 'Jianfeng Gao']","['~Chandan_Singh1', '~John_Xavier_Morris1', '~Jyoti_Aneja2', '~Alexander_M_Rush1', '~Jianfeng_Gao1']","['Interpretability', 'explainability', 'XAI', 'AI for science']","Large language models (LLMs) have displayed an impressive ability to harness natural language to perform complex tasks. In this work, we explore whether we can leverage this learned ability to find and explain patterns in data. Specifically, given a pre-trained LLM and data examples, we introduce interpretable autoprompting (iPrompt), an algorithm that generates a natural-language string explaining the data. iPrompt iteratively alternates between generating explanations with an LLM and reranking them based on their performance when used as a prompt. Experiments on a wide range of datasets, from synthetic mathematics to natural-language understanding, show that iPrompt can yield meaningful insights by accurately finding groundtruth dataset descriptions. Moreover, the prompts produced by iPrompt are simultaneously human-interpretable and highly effective for generalization: on real-world sentiment classification datasets, iPrompt produces prompts that match or even improve upon human-written prompts for GPT-3. Finally, experiments with an fMRI dataset show the potential for iPrompt to aid in scientific discovery.",https://openreview.net/pdf/2607a064389bdde9d47bd61f38b952fb58cb49c2.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=GVWySHBD3Cl,Estimating Treatment Effects using Neurosymbolic Program Synthesis,"['Abbavaram Gowtham Reddy', 'Vineeth N. Balasubramanian']","['~Abbavaram_Gowtham_Reddy1', '~Vineeth_N._Balasubramanian2']","['Causal effect', 'treatment effect', 'neurosymbolic programming', 'domain specific language']","Estimating treatment effects from observational data is a central problem in causal inference. Methods to solve this problem exploit inductive biases and heuristics from causal inference to design multi-head neural network architectures and regularizers. In this work, we propose to use neurosymbolic program synthesis, a data-efficient, and interpretable technique, to solve the treatment effect estimation problem. We theoretically show that neurosymbolic programming can solve the treatment effect estimation problem. By designing a Domain Specific Language (DSL) for treatment effect estimation based on the inductive biases used in literature, we argue that neurosymbolic programming is a better alternative to treatment effect estimation than traditional models. Our empirical study reveals that our model, which implicitly encodes inductive biases in a DSL, achieves better performance on benchmark datasets than the state-of-the-art models.",https://openreview.net/pdf/52795a7ad62996e037db584b54e9bcd13a3771ac.pdf,{'title_filter': 'Data Synthesis'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=GUfVNbxIYv,$\Phi$-DVAE: Learning Physically Interpretable Representations with Nonlinear Filtering,"['Alex John Glyn-Davies', 'Connor Duffin', 'Omer Deniz Akyildiz', 'Mark Girolami']","['~Alex_John_Glyn-Davies1', '~Connor_Duffin1', '~Omer_Deniz_Akyildiz1', '~Mark_Girolami2']","['variational autoencoder', 'nonlinear filter', 'physics-informed', 'parameter estimation', 'variational inference', 'Bayesian inverse problems']","Incorporating unstructured data into physical models is a challenging problem that is emerging in data assimilation. Traditional approaches focus on well-defined observation operators whose functional forms are typically assumed to be known. This prevents these methods from achieving a consistent model-data synthesis in configurations where the mapping from data-space to model-space is unknown. To address these shortcomings, in this paper we develop a physics-informed dynamical variational autoencoder ($\Phi$-DVAE) for embedding diverse data streams into time-evolving physical systems described by differential equations. Our approach combines a standard (possibly nonlinear) filter for the latent state-space model and a VAE, to embed the unstructured data stream into the latent dynamical system. A variational Bayesian framework is used for the joint estimation of the embedding, latent states, and unknown system parameters. To demonstrate the method, we look at three examples: video datasets generated by the advection and Korteweg-de Vries partial differential equations, and a velocity field generated by the Lorenz-63 system. Comparisons with relevant baselines show that the $\Phi$-DVAE provides a data efficient dynamics encoding methodology that is competitive with standard approaches, with the added benefit of incorporating a physically interpretable latent space.",https://openreview.net/pdf/35c27b781c88ecab409bb0dacde7e7b97d010388.pdf,{'abstract_filter': 'Data Synthesis'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=GULFHQfgw0g,Neural Agents Struggle to Take Turns in Bidirectional Emergent Communication,"['Valentin Taillandier', 'Dieuwke Hupkes', 'Benoît Sagot', 'Emmanuel Dupoux', 'Paul Michel']","['~Valentin_Taillandier1', '~Dieuwke_Hupkes1', '~Benoît_Sagot1', '~Emmanuel_Dupoux1', '~Paul_Michel1']","['language emergence', 'turn-taking', 'conversation', 'communication', 'neural agents', 'cooperative game', 'reinforcement learning']","The spontaneous exchange of turns is a central aspect of human communication. Although turn-taking conventions come to us naturally, artificial dialogue agents struggle to coordinate, and must rely on hard-coded rules to engage in interactive conversations with human interlocutors. In this paper, we investigate the conditions under which artificial agents may naturally develop turn-taking conventions in a simple language game. We describe a cooperative task where success is contingent on the exchange of information along a shared communication channel where talking over each other hinders communication. Despite these environmental constraints, neural-network based agents trained to solve this task with reinforcement learning do not systematically adopt turn-taking conventions. However, we find that agents that do agree on turn-taking protocols end up performing better. 
Moreover, agents that are forced to perform turn-taking can learn to solve the task more quickly. 
This suggests that turn-taking may help to generate conversations that are easier for speakers to interpret.",https://openreview.net/pdf/f6e0700b1a4de32f13aabefaa7a865a60b7ce2f2.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=GKsNIC_mQRG,Emergence of Exploration in Policy Gradient Reinforcement Learning via Resetting,"['Sotetsu Koyamada', 'Paavo Parmas', 'Tadashi Kozuno', 'Shin Ishii']","['~Sotetsu_Koyamada1', '~Paavo_Parmas1', '~Tadashi_Kozuno1', '~Shin_Ishii1']",[],"In reinforcement learning (RL), many exploration methods explicitly promote stochastic policies, e.g., by adding an entropy bonus. We argue that exploration only matters in RL because the agent repeatedly encounters the same or similar states, so that it is beneficial to gradually improve the performance over the encounters; otherwise, the greedy policy would be optimal. Based on this intuition, we propose ReMax, an objective for RL whereby stochastic exploration arises as an emergent property, without adding any explicit exploration bonus. In ReMax, an episode is modified so that the agent can reset to previous states in the trajectory, and the agent’s goal is to maximize the best return in the trajectory tree. We show that this ReMax objective can be directly optimized with an unbiased policy gradient method. Experiments confirm that ReMax leads to the emergence of a stochastic exploration policy, and improves the performance compared to RL with no exploration bonus.",https://openreview.net/pdf/c06884cb07438f1f31c60d5151e54b39e26d33d4.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=G7E_K3WaLpK,Infusing Lattice Symmetry Priors in Neural Networks Using Soft Attention Masks,"['Mattia Atzeni', 'Mrinmaya Sachan', 'Andreas Loukas']","['~Mattia_Atzeni1', '~Mrinmaya_Sachan3', '~Andreas_Loukas1']",[],"Infusing inductive biases and knowledge priors in artificial neural networks is a promising approach for achieving sample efficiency in current deep learning models. Core knowledge priors of human intelligence have been studied extensively in developmental science and recent work has postulated the idea that research on artificial intelligence should revolve around the same basic priors. As a step towards this direction, in this paper, we introduce LatFormer, a model that incorporates lattice geometry and topology priors in attention masks.
Our study of the properties of these masks motivates a modification to the standard attention mechanism, where attention weights are scaled using soft attention masks generated by a convolutional neural network. Our experiments on ARC and on synthetic visual reasoning tasks show that LatFormer requires 2-orders of magnitude fewer data than standard attention and transformers in these tasks. Moreover, our results on ARC tasks that incorporate geometric priors provide preliminary evidence that deep learning can tackle this complex dataset, which is widely viewed as an important open challenge for AI research.",https://openreview.net/pdf/0c40eeab7a893043ada108b7be6a59b17fb16241.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=F_EhNDSamN,Parametrizing Product Shape Manifolds by Composite Networks,"['Josua Sassen', 'Klaus Hildebrandt', 'Martin Rumpf', 'Benedikt Wirth']","['~Josua_Sassen1', '~Klaus_Hildebrandt1', '~Martin_Rumpf1', '~Benedikt_Wirth1']","['shape spaces', 'product manifolds', 'nonlinear statistics', 'low-dimensional data manifolds']","Parametrizations of data manifolds in shape spaces can be computed using the rich toolbox of Riemannian geometry. This, however, often comes with high computational costs, which raises the question if one can learn an efficient neural network approximation. We show that this is indeed possible for shape spaces with a special product structure, namely those smoothly approximable by a direct sum of low-dimensional manifolds. Our proposed architecture leverages this structure by separately learning approximations for the low-dimensional factors and a subsequent combination. After developing the approach as a general framework, we apply it to a shape space of triangular surfaces. Here, typical examples of data manifolds are given through datasets of articulated models and can be factorized, for example, by a Sparse Principal Geodesic Analysis (SPGA). We demonstrate the effectiveness of our proposed approach with experiments on synthetic data as well as manifolds extracted from data via SPGA.",https://openreview.net/pdf/2832887c23c3957ac23c919a6f7a43abde5a7ef2.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=FJdSi_seSg,Do We Always Need to Penalize Variance of Losses for Learning with Label Noise?,"['Yexiong Lin', 'Yu Yao', 'Yuxuan Du', 'Jun Yu', 'Bo Han', 'Mingming Gong', 'Tongliang Liu']","['~Yexiong_Lin1', '~Yu_Yao3', '~Yuxuan_Du2', '~Jun_Yu3', '~Bo_Han1', '~Mingming_Gong1', '~Tongliang_Liu1']",[],"Algorithms which minimize the averaged loss have been widely designed for dealing with noisy labels. Intuitively, when there is a finite training sample, penalizing the variance of losses will improve the stability and generalization of the algorithms. Interestingly, we found that the variance of losses sometimes needs to be increased for the problem of learning with noisy labels. Specifically, increasing the variance of losses would boost the memorization effect and reduce the harmfulness of incorrect labels. Regularizers can be easily designed to increase the variance of losses and be plugged in many existing algorithms. Empirically, the proposed method by increasing the variance of losses could improve the generalization ability of baselines on both synthetic and real-world datasets.",https://openreview.net/pdf/ea6946cc1e63e2067130c3c79c0b89cdb7dad2a4.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=F5uYcwABMu,"Same Pre-training Loss, Better Downstream: Implicit Bias Matters for Language Models","['Hong Liu', 'Sang Michael Xie', 'Zhiyuan Li', 'Tengyu Ma']","['~Hong_Liu5', '~Sang_Michael_Xie1', '~Zhiyuan_Li2', '~Tengyu_Ma1']","['Language Modeling', 'Implicit Bias']","Language modeling on large-scale datasets leads to impressive performance gains on various downstream language tasks.  The (validation) pre-training loss (or perplexity in autoregressive language modeling) is often used as the evaluation metric when developing language models since the pre-training loss tends to be well-correlated with downstream performance (which is itself difficult to evaluate comprehensively). Contrary to this conventional wisdom, this paper shows that 1) pre-training loss cannot fully explain downstream performance and 2) flatness of the model is well-correlated with downstream performance where pre-training loss is not. On simplified datasets, we identify three ways to produce models with the same (statistically optimal) pre-training loss but different downstream performance: continue pre-training after convergence, increasing the model size, and changing the training algorithm.  These experiments demonstrate the existence of implicit bias of pre-training algorithms/optimizers---among models with the same minimal pre-training loss, they implicitly prefer more transferable ones. Toward understanding this implicit bias, we prove that SGD with standard mini-batch noise implicitly prefers flatter minima in language models, and empirically observe a strong correlation between flatness and downstream performance among models with the same minimal pre-training loss. We also prove in a synthetic language setting that among the models with the minimal pre-training loss, the flattest model transfers to downstream tasks.",https://openreview.net/pdf/7f758bfc0a1a58c52ba31364a2db83a58c023658.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=EpvL_FaLtw,Multi-Treatment Effect Estimation with Proxy: Contrastive Learning and Rank Weighting,"['Minqin Zhu', 'Anpeng Wu', 'Ruoxuan Xiong', 'Kun Kuang']","['~Minqin_Zhu1', '~Anpeng_Wu1', '~Ruoxuan_Xiong1', '~Kun_Kuang1']",[],"We study the treatment effect estimation problem for continuous and multi-dimensional treatments, in the setting with unobserved confounders, but high-dimension proxy variables for unobserved confounders are available. Existing methods either directly adjust the relationship between observed covariates and treatments or recover the hidden confounders by probabilistic models. However, they either rely on a correctly specified treatment assignment model or require strong prior of the unobserved confounder distribution. To relax these requirements, we propose a Contrastive Regularizer (CR) to learn the proxy representation that  contains all the relevant information in unobserved confounders. Based on the CR, we propose a novel ranked weighting method (Rw) to de-bias the treatment assignment. Combining Cr and Rw, we propose a neural network framework named CRNet to estimate the effects of multiple continuous treatments under unobserved confounders, evaluated by the Average Dose-Response Function. Empirically, we demonstrate that CRNet achieves state-of-the-art performance on both synthetic and semi-synthetic datasets.",https://openreview.net/pdf/2407bbda886499fbfc7788ca329d0c2ec027531b.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=ERjQnrmLKH4,Learning Counterfactually Invariant Predictors,"['Francesco Quinzan', 'Cecilia Casolo', 'Krikamol Muandet', 'Niki Kilbertus', 'Yucen Luo']","['~Francesco_Quinzan1', '~Cecilia_Casolo1', '~Krikamol_Muandet1', '~Niki_Kilbertus1', '~Yucen_Luo1']","['causality', 'kernel mean embeddings', 'counterfactual fairness', 'counterfactual invariance']","We propose a method to learn predictors that are invariant under counterfactual changes of certain covariates. This method is useful when the prediction target is causally influenced by covariates that should not affect the predictor output. For instance, this could prevent an object recognition model from being influenced by position, orientation, or scale of the object itself. We propose a model-agnostic regularization term based on conditional kernel mean embeddings to enforce counterfactual invariance during training. We prove the soundness of our method, which can handle mixed categorical and continuous multivariate attributes. Empirical results on synthetic and real-world data demonstrate the efficacy of our method in a variety of settings.",https://openreview.net/pdf/f97ee6813bf33599b18a5255910356dfd0d95830.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=ED2Jjms9A4H,Efficient Exploration via Fragmentation and Recall,"['Jaedong Hwang', 'Zhang-Wei Hong', 'Eric R Chen', 'Akhilan Boopathy', 'Pulkit Agrawal', 'Ila R Fiete']","['~Jaedong_Hwang1', '~Zhang-Wei_Hong1', '~Eric_R_Chen1', '~Akhilan_Boopathy1', '~Pulkit_Agrawal1', '~Ila_R_Fiete1']","['fragmentation', 'recall', 'exploration', 'cognitive science', 'neuroscience', 'curiosity', 'reinforcement learning', 'spatial navigation']","Efficient exploration and model-building are critical for learning in large state- spaces. However, agents typically face problems like getting stuck locally during exploration and catastrophic forgetting in their construction of models when the environments are heterogeneous. Here, we propose and apply the concept of Fragmentation-and-Recall to solve spatial (FarMap) and reinforcement learning problems (FarCuriosity). Agents construct local maps or local models, respectively, which are used to predict the current observation. High surprisal points lead to a fragmentation event. At fracture points, we store the current map or model fragment in a long-term memory (LTM) and initialize a new fragment. On the other hand, Fragments are recalled (and thus reused) from LTM if the observations of their fracture points match the agent’s current observation during exploration. The set of fracture points defines a set of intrinsic potential subgoals. Agents choose their next subgoal from the set of near and far potential subgoals in the current fragment or LTM, respectively. Thus, local maps and model fragments guide exploration locally and avoid catastrophic forgetting in learning heterogeneous environments, while LTM promotes exploration more globally. We evaluate FarMap and FarCuriosity on complex procedurally-generated spatial environments and on reinforcement learning benchmarks and demonstrate that the proposed methods are more efficient at exploration and memory use, and in harvesting extrinsic rewards, respectively.",https://openreview.net/pdf/f07f4d9ba345a1688439bd1531056ed3169d52e2.pdf,{'abstract_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=E8mzu3JbdR,ChordMixer: A Scalable Neural Attention Model for Sequences with Different Length,"['Ruslan Khalitov', 'Tong Yu', 'Lei Cheng', 'Zhirong Yang']","['~Ruslan_Khalitov1', '~Tong_Yu4', '~Lei_Cheng1', '~Zhirong_Yang1']","['Mixer', 'Attention', 'Scalable']","Sequential data naturally have different lengths in many domains, with some very long sequences. As an important modeling tool, neural attention should capture long-range interaction in such sequences. However, most existing neural attention models admit only short sequences, or they have to employ chunking or padding to enforce a constant input length. Here we propose a simple neural network building block called ChordMixer which can model the attention for long sequences with variable lengths. Each ChordMixer block consists of a position-wise rotation layer without learnable parameters and an element-wise MLP layer. Repeatedly applying such blocks forms an effective network backbone that mixes the input signals towards the learning targets. We have tested ChordMixer on the synthetic adding problem, long document classification, and DNA sequence-based taxonomy classification. The experiment results show that our method substantially outperforms other neural attention models.",https://openreview.net/pdf/dbeed2c3d0b79691b83802ee788e14ea278798b1.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=E3ip6qBLF7,Distributionally Robust Recourse Action,"['Duy Nguyen', 'Ngoc Bui', 'Viet Anh Nguyen']","['~Duy_Nguyen2', '~Ngoc_Bui1', '~Viet_Anh_Nguyen2']","['Robust Optimization', 'Explainable AI', 'Algorithmic Recourse']","A recourse action aims to explain a particular algorithmic decision by showing one specific way in which the instance could be modified to receive an alternate outcome. Existing recourse generation methods often assume that the machine learning model does not change over time. However, this assumption does not always hold in practice because of data distribution shifts, and in this case, the recourse action may become invalid. To redress this shortcoming, we propose the Distributionally Robust Recourse Action (DiRRAc) framework, which generates a recourse action that has high probability of being valid under a mixture of model shifts. We first formulate the robustified recourse setup as a min-max optimization problem, where the max problem is specified by Gelbrich distance over an ambiguity set around the distribution of model parameters. Then we suggest a projected gradient descent algorithm to find a robust recourse according to the min-max objective. We also show that our DiRRAc framework can be extended to hedge against the misspecification of the mixture weights. Numerical experiments with both synthetic and three real-world datasets demonstrate the benefits of our proposed framework over the state-of-the-art recourse methods, which generate robust recourses.
",https://openreview.net/pdf/2ba3251326914f789659bf5c76f1bc06b8567cb4.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Do9MOlwWHu0,Learning Sparse Group Models Through Boolean Relaxation,"['Yijie Wang', 'Yuan Zhou', 'Xiaoqing Huang', 'Kun Huang', 'Jie Zhang', 'Jianzhu Ma']","['~Yijie_Wang2', '~Yuan_Zhou1', '~Xiaoqing_Huang1', '~Kun_Huang2', '~Jie_Zhang20', '~Jianzhu_Ma2']","['Structured sparisity', 'Convex relaxation', 'Cardinality-constrained program', 'Small sample size']","We introduce an efficient algorithmic framework for learning sparse group models formulated as the natural convex relaxation of a cardinality-constrained program with Boolean variables. We provide theoretical techniques to characterize the equivalent condition when the relaxation achieves the exact integral optimal solution, as well as a rounding algorithm to produce a feasible integral solution once the optimal relaxation solution is fractional. We demonstrate the power of our equivalent condition by applying it to two ensembles of random problem instances that are challenging and popularly used in literature and prove that our method achieves exactness with overwhelming probability and nearly optimal sample complexity. Empirically, we use synthetic datasets to demonstrate that our proposed method significantly outperforms the state-of-the-art group sparse learning models in terms of individual and group support recovery when the number of samples is small. Furthermore, we show the out-performance of our method in cancer drug response prediction.",https://openreview.net/pdf/0760530295a66fdff783489bb9ee1628a6ed3880.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=DeG07_TcZvT,Emergent World Representations: Exploring a Sequence Model Trained on a Synthetic Task,"['Kenneth Li', 'Aspen K Hopkins', 'David Bau', 'Fernanda Viégas', 'Hanspeter Pfister', 'Martin Wattenberg']","['~Kenneth_Li1', '~Aspen_K_Hopkins1', '~David_Bau1', '~Fernanda_Viégas1', '~Hanspeter_Pfister1', '~Martin_Wattenberg1']","['world representation', 'GPT']","Language models show a surprising range of capabilities, but the source of their apparent competence is unclear. Do these networks just memorize a collection of surface statistics, or do they rely on internal representations of the process that generates the sequences they see? We investigate this question by applying a variant of the GPT model to the task of predicting legal moves in a simple board game, Othello. Although the network has no a priori knowledge of the game or its rules, we uncover evidence of an emergent nonlinear internal representation of the board state. Interventional experiments indicate this representation can be used to control the output of the network and create ""latent saliency maps"" that can help explain predictions in human terms.",https://openreview.net/pdf/70fb51a26cffdf3304e24f4d2e803b729904fe20.pdf,{'title_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=De4FYqjFueZ,Transformers Learn Shortcuts to Automata,"['Bingbin Liu', 'Jordan T. Ash', 'Surbhi Goel', 'Akshay Krishnamurthy', 'Cyril Zhang']","['~Bingbin_Liu1', '~Jordan_T._Ash1', '~Surbhi_Goel1', '~Akshay_Krishnamurthy1', '~Cyril_Zhang1']","['Transformer', 'self-attention', 'group theory', 'semigroup theory', 'algebraic automata theory', 'shortcut learning', 'theory of deep learning']","Algorithmic reasoning requires capabilities which are most naturally understood through recurrent models of computation, like the Turing machine. However, Transformer models, while lacking recurrence, are able to perform such reasoning using far fewer layers than the number of reasoning steps. This raises the question: what solutions are these shallow and non-recurrent models finding? We investigate this question in the setting of learning automata, discrete dynamical systems naturally suited to recurrent modeling and expressing algorithmic tasks. Our theoretical results completely characterize shortcut solutions, whereby a shallow Transformer with only $o(T)$ layers can exactly replicate the computation of an automaton on an input sequence of length $T$. By representing automata using the algebraic structure of their underlying transformation semigroups, we obtain $O(\log T)$-depth simulators for all automata and $O(1)$-depth simulators for all automata whose associated groups are solvable. Empirically, we perform synthetic experiments by training Transformers to simulate a wide variety of automata, and show that shortcut solutions can be learned via standard training. We further investigate the brittleness of these solutions and propose potential mitigations.",https://openreview.net/pdf/6fceba3e100352173ef8f64b4743424fc99f1e8d.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Db_WALIfbdC,Bayesian Optimal Experimental Design for the Survey Bandit Setting,"['Sang T. Truong', 'Willie Neiswanger', 'Susan Athey']","['~Sang_T._Truong1', '~Willie_Neiswanger2', '~Susan_Athey1']","['Bayesian optimal experimental design', 'contextual bandit', 'survey']","The contextual bandit is a classic problem in sequential decision making under uncertainty that finds broad application to tasks in precision medicine, personalized education, and drug discovery. Here, a decision maker repeatedly receives a context, takes an action, and then observes an associated outcome, with the goal of choosing actions that achieve a minimal regret. However, in many settings, the context is not given, and the decision maker must instead collect some information to infer a context before proceeding. For example, when a doctor does not have prior information about a patient, they might ask a sequence of questions before recommending a medical treatment. In this paper, we aim to develop methods for this setting—which we refer to as the \emph{survey bandit}—where the decision maker is not given access to the context but can ask a finite sequence of questions to gain information about the context before taking an action and observing an outcome. Using insights from Bayesian optimal experimental design (BOED) and decision-theoretic information theory, we view the interaction with each user as a BOED task, where the goal is to ask a sequence of questions that elicit the most information about the optimal action for this user. Our procedure is agnostic to the choice of probabilistic model, and we demonstrate its usefulness in a few common classes of distributions. Our algorithm achieves significantly better performance on both synthetic and real data relative to existing baseline methods while remaining statistically efficient, interpretable, and computationally friendly.",https://openreview.net/pdf/7404513cf6a65ffdebcd858cb1aa8056a9935f24.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=DAxQXzdq8SF,SOM-CPC: Unsupervised Contrastive Learning with Self-Organizing Maps for Structured Representations of High-Rate Time Series,"['Iris A.M. Huijben', 'Arthur Andreas Nijdam', 'Sebastiaan Overeem', 'Merel M Van Gilst', 'Ruud Van Sloun']","['~Iris_A.M._Huijben1', '~Arthur_Andreas_Nijdam1', '~Sebastiaan_Overeem1', '~Merel_M_Van_Gilst1', '~Ruud_Van_Sloun1']","['Contrastive Predictive Coding', 'Self-Organizing Maps', 'Time series', 'Dimensionality Reduction']","Continuous monitoring with an ever-increasing number of sensors has become ubiquitous across many application domains. Acquired data are typically high-dimensional and difficult to interpret, but they are also hypothesized to lie on a low-dimensional manifold. Dimensionality reduction techniques have, therefore, been sought for. Popular linear methods like Principle Component Analysis (PCA) have been extended to non-linear techniques such as Self-Organizing Maps (SOMs) or deep learning (DL) models. DL models have the ability to act on raw data, preventing heuristic feature selection, but the resulting latent space is often unstructured and still multi-dimensional. PCA and SOMs, on the other hand, need to be preceded with a feature-extraction step, but can then map high-dimensional features to 2D space. In this work we propose SOM-CPC, a model that jointly optimizes Contrastive Predictive Coding and a SOM to find an organized 2D manifold. We address a largely unexplored and challenging set of scenarios comprising high-rate time series, and show on both synthetic and real-life data (medical sleep data and audio recordings) that SOM-CPC outperforms both DL-based feature extraction, followed by PCA, K-means or a SOM, and strong deep-SOM baselines that jointly optimize a DL model and a SOM. SOM-CPC has great potential to expose latent patterns in high-rate data streams and may therefore contribute to a better understanding of many different processes and systems. ",https://openreview.net/pdf/f85ad885376722f740ab9f661f2599ae480d5a3d.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=CxPw6TeByX4,SoundNeRirF: Receiver-to-Receiver Sound Neural Room Impulse Response Field,"['Yuhang He', 'Jia-Xing Zhong', 'Zhuangzhuang Dai', 'Niki Trigoni', 'Andrew Markham']","['~Yuhang_He3', '~Jia-Xing_Zhong1', '~Zhuangzhuang_Dai1', '~Niki_Trigoni1', '~Andrew_Markham2']","['Sound Neural Rendering Field', 'Sound Prediction', 'Representation Learning', 'Receiver-to-Receiver Modelling']","We present SoundNeRirF, a framework that learns a continuous receiver-to-receiver neural room impulse response field~(r2r-RIR) to help robot efficiently predict the sound to be heard at novel locations. It represents a room acoustic scene as a continuous 6D function, whose input is a reference receiver's 3D position and a target receiver's 3D position, and whose outputs are an inverse room impulse response~(inverse-RIR) and a forward room impulse response~(forward-RIR) that jointly project the sound from the reference position to the target position. SoundNeRirF requires knowledge of neither sound source (e.g. location and number of sound sources) nor room acoustic properties~(e.g. room size, geometry, materials). Instead, it merely depends on a sparse set of sound receivers' positions, as well as the recorded sound at each position. We instantiate the continuous 6D function as multi-layer perceptrons~(MLP), so it is fully differentiable and continuous at any spatial position. SoundNeRirF is encouraged, during the training stage, to implicitly encode the interaction between sound sources, receivers and room acoustic properties by minimizing the discrepancy between the predicted sound and the truly heard sound at the target position. During inference, the sound at a novel position is predicted by giving a reference position and the corresponding reference sound. Extensive experiments on both synthetic and real-world datasets show SoundNeRirF is capable of predicting high-fidelity and audio-realistic sound that fully captures room reverberation characteristics, significantly outperforming existing methods in terms of accuracy and efficiency.",https://openreview.net/pdf/d53f3d8fe3cd72b5ed2fd9bc88252b05e394dabf.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Cx1xYn6vVm2,A Mutual Information Duality Algorithm for Multi-Agent Specialization,"['Stefan Juang', 'Qiyang Cao', 'Yuan Zhou', 'Ruochen Liu', 'Nevin Zhang', 'Elvis S. Liu']","['~Stefan_Juang1', '~Qiyang_Cao1', '~Yuan_Zhou9', '~Ruochen_Liu2', '~Nevin_Zhang1', '~Elvis_S._Liu1']","['Multi-agent', 'Reinforcement Learning', 'Mutual Information', 'Duality', 'Policy Gradient', 'Social Graph']","The social behavior change in a population has long been studied as an essential component of multi-agent learning. The learning of behavioral change not only involves reinforcement learning (RL), but also be measured against the general population with mutual information (MI). The combination of RL and MI led us to derive MI optimizations from policy gradient. With MI as multi-agent's optimization objective, we discover that the dual properties of MI can result in distinctly different population behaviors. From MI maximization that maximizes the stability of a population to MI minimization that enables specialization among the agents, the dual of MI creates a significant change in a population's behavioral properties. In this paper, we propose a minimax formulation of MI (M\&M) that enables agents specialization with stable regularization. Empirically we evaluated M\&M against the prior SOTA MARL framework, and analyze the social behavior change in performance, diversity, and the stability of their social graphs. ",https://openreview.net/pdf/c4b4baec433aaa241d9588a232e85cb024d88c48.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Cp-io_BoFaE,FluidLab: A Differentiable Environment for Benchmarking Complex Fluid Manipulation,"['Zhou Xian', 'Bo Zhu', 'Zhenjia Xu', 'Hsiao-Yu Tung', 'Antonio Torralba', 'Katerina Fragkiadaki', 'Chuang Gan']","['~Zhou_Xian1', '~Bo_Zhu2', '~Zhenjia_Xu1', '~Hsiao-Yu_Tung2', '~Antonio_Torralba1', '~Katerina_Fragkiadaki1', '~Chuang_Gan1']","['Complex Fluid Manipulation', 'Differentiable Physics']","Humans manipulate various kinds of fluids in their everyday life: creating latte art, scooping floating objects from water, rolling an ice cream cone, etc. Using robots to augment or replace human labors in these daily settings remain as a challenging task due to the multifaceted complexities of fluids. Previous research in robotic fluid manipulation mostly consider fluids governed by an ideal, Newtonian model in simple task settings (e.g., pouring water into a container). However, the vast majority of real-world fluid systems manifest their complexities in terms of the fluid’s complex material behaviors (e.g., elastoplastic deformation) and multi-component interactions (e.g. coffee and frothed milk when making latte art), both of which were well beyond the scope of the current literature. To evaluate robot learning algorithms on understanding and interacting with such complex fluid systems, a comprehensive virtual platform with versatile simulation capabilities and well-established tasks is needed. In this work, we introduce FluidLab, a simulation environment with a diverse set of manipulation tasks involving complex fluid dynamics. These tasks address interactions between solid and fluid as well as among multiple fluids. At the heart of our platform is a fully differentiable physics simulator, FluidEngine, providing GPU-accelerated simulations and gradient calculations for various material types and their couplings, extending the scope of the existing differentiable simulation engines. We identify several challenges for fluid manipulation learning by evaluating a set of reinforcement learning and trajectory optimization methods on our platform. To address these challenges, we propose several domain-specific optimization schemes coupled with differentiable physics, which are empirically shown to be effective in tackling optimization problems featured by fluid system’s non-convex and non-smooth properties. Furthermore, we demonstrate reasonable sim-to-real transfer by deploying optimized trajectories in real-world settings. FluidLab is publicly available at: https://fluidlab2023.github.io.",https://openreview.net/pdf/6f396409f5100c7dca4d9a23810e4e4aefb8c5f2.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Cn6JkFnKgPX,Analysis of differentially private synthetic data: a general measurement error approach,"['Yangdi Jiang', 'Yi Liu', 'Xiaodong Yan', 'Anne-Sophie Charest', 'Linglong Kong', 'Bei Jiang']","['~Yangdi_Jiang1', '~Yi_Liu13', '~Xiaodong_Yan1', '~Anne-Sophie_Charest1', '~Linglong_Kong2', '~Bei_Jiang1']","['Measurement Error Model', 'Differential Privacy', 'Regression', 'Statistical Inference']","Differential private (DP) synthetic datasets have been receiving significant attention from academia, industry, and government. However, little is known about how to perform statistical inference using DP synthetic datasets. Naive approaches that do not take into account the induced uncertainty due to DP mechanism will result in biased estimators and invalid inferences. In this paper, we present a general class of bias-corrected DP estimators with valid asymptotic confidence intervals for parameters in regression settings, by establishing the connection between additive DP mechanisms and measurement error models. Our simulation shows that when the sample covariance between DP noises and data is close to zero, our estimator is far superior to the widely used sufficient statistic perturbation algorithm, and the CIs can achieve better coverage when comparing to the naive CIs obtained from ignoring the DP mechanism.",https://openreview.net/pdf/066a8bbdf9a4c5d46cca6f988e4e83de5ee753cf.pdf,{'title_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=CgCmwcfgEdH,PGrad: Learning Principal Gradients For Domain Generalization,"['Zhe Wang', 'Jake Grigsby', 'Yanjun Qi']","['~Zhe_Wang19', '~Jake_Grigsby1', '~Yanjun_Qi1']",[],"Machine learning models fail to perform when facing out-of-distribution (OOD) domains, a challenging task known as domain generalization (DG). In this work, we develop a novel DG training strategy, we call PGrad, to learn a robust gradient direction, improving models' generalization ability on unseen domains.  The proposed gradient aggregates the principal directions of a sampled roll-out optimization trajectory that measures the training dynamics across all training domains. PGrad gradient design forces the DG training to ignore domain-dependent noise signals and updates all training domains with a robust direction covering main components of parameter dynamics.  We further improve PGrad via bijection-based computational refinement and directional plus length-based calibrations. Our theoretical proof connects PGrad to the spectral analysis of Hessian in training neural networks. Experiments on DomainBed and WILDS benchmarks demonstrate that our approach effectively enables robust DG optimization and leads to smoothly decreased loss curves.  Empirically, PGrad achieves competitive results across seven datasets, demonstrating its efficacy across both synthetic and real-world distributional shifts.",https://openreview.net/pdf/3624aed42e1bd899a25cf9a4c59dd981a3281799.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=CcXTudu9bvu,DELTA: Diverse Client Sampling for Fasting Federated Learning,"['Lin Wang', 'Yongxin Guo', 'Tao Lin', 'Xiaoying Tang']","['~Lin_Wang14', '~Yongxin_Guo1', '~Tao_Lin1', '~Xiaoying_Tang2']","['federated learning', 'client sampling']","Partial client participation has been widely adopted in Federated Learning (FL) to efficiently reduce the communication burden. However, an improper client sampling scheme will select unrepresentative subsets, which will cause a large variance in the model update and slows down the convergence. Existing sampling methods are either biased or can be further improved to accelerate the convergence. In this paper, we propose an unbiased sampling scheme, termed DELTA, to alleviate this problem. In particular, DELTA characterizes the impact of client diversity and local variance and samples the representative clients who carry valuable information for global model updates. Moreover, DELTA is a provably optimal unbiased sampling scheme that minimizes the variance caused by partial client participation and achieves better convergence than other unbiased sampling schemes. We corroborate our results with experiments on both synthetic and real data sets.",https://openreview.net/pdf/cd9451c5dbdec976074c7253d011835e70ceec1e.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=COZDy0WYGg,Hungry Hungry Hippos: Towards Language Modeling with State Space Models,"['Daniel Y Fu', 'Tri Dao', 'Khaled Kamal Saab', 'Armin W Thomas', 'Atri Rudra', 'Christopher Re']","['~Daniel_Y_Fu1', '~Tri_Dao1', '~Khaled_Kamal_Saab1', '~Armin_W_Thomas1', '~Atri_Rudra1', '~Christopher_Re1']","['language modeling', 'state space models', 'efficiency']","State space models (SSMs) have demonstrated state-of-the-art sequence modeling performance in some modalities, but underperform attention in language modeling. Moreover, despite scaling nearly linearly in sequence length instead of quadratically, SSMs are still slower than Transformers due to poor hardware utilization. In this paper, we make progress on understanding the expressivity gap between SSMs and attention in language modeling, and on reducing the hardware barrier between SSMs and attention. First, we use synthetic language modeling tasks to understand the gap between SSMs and attention. We find that existing SSMs struggle with two capabilities: recalling earlier tokens in the sequence and comparing tokens across the sequence. To understand the impact on language modeling, we propose a new SSM layer, H3, that is explicitly designed for these abilities. H3 matches attention on the synthetic languages and comes within 0.4 PPL of Transformers on OpenWebText. Furthermore, a hybrid 125M-parameter H3-attention model that retains two attention layers surprisingly outperforms Transformers on OpenWebText by 1.0 PPL. Next, to improve the efficiency of training SSMs on modern hardware, we propose FlashConv. FlashConv uses a fused block FFT algorithm to improve efficiency on sequences up to 8K, and introduces a novel state passing algorithm that exploits the recurrent properties of SSMs to scale to longer sequences. FlashConv yields 2$\times$ speedup on the long-range arena benchmark and allows hybrid language models to generate text 2.4$\times$ faster than Transformers. Using FlashConv, we scale hybrid H3-attention language models up to 2.7B parameters on the Pile and find promising initial results, achieving lower perplexity than Transformers and outperforming Transformers in zero- and few-shot learning on a majority of tasks in the SuperGLUE benchmark.",https://openreview.net/pdf/b3774a7e6b7bda0783528bf1dc8e2600707d797f.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=CJl2S0w1mbq,A UNIFIED VIEW OF FINDING AND TRANSFORMING WINNING LOTTERY TICKETS,"['Kun Wang', 'Yuxuan Liang', 'Pengkun Wang', 'Pengfei Gu', 'Zhengyang Zhou', 'Chao Huang', 'Yang Wang']","['~Kun_Wang15', '~Yuxuan_Liang1', '~Pengkun_Wang1', '~Pengfei_Gu1', '~Zhengyang_Zhou1', '~Chao_Huang7', '~Yang_Wang32']","['Lottery Tickets Hypothesis', 'Dual Lottery Tickets Hypothesis', 'Non-linear increased regularization', 'early stopping']","While over-parameterized deep neural networks obtain prominent results on various machine learning tasks, their superfluous parameters usually make model training and inference notoriously inefficient. Lottery Ticket Hypothesis (LTH) addresses this issue from a novel perspective: it articulates that there always exist sparse and admirable subnetworks in a randomly initialized dense network, which can be realized by an iterative pruning strategy. Dual Lottery Ticket Hypothesis (DLTH) further investigates sparse network training from a complementary view. Concretely, it introduces a gradually increased regularization term to transform a dense network to an ultra-light subnetwork without sacrificing learning capacity. After revisiting the success of LTH and DLTH, we unify these two research lines by coupling the stability of iterative pruning and the excellent performance of increased regularization, resulting in two new algorithms (UniLTH and UniDLTH) for finding and transforming winning tickets, respectively. Unlike either LTH without regularization or DLTH which applies regularization across the training, our methods first train the network without any regularization force until the model reaches a certain point (i.e., the validation loss does not decrease for several epochs), and then employ increased regularization for information extrusion and iteratively perform magnitude pruning till the end. We theoretically prove that the early stopping mechanism acts analogously as regularization and can help the optimization trajectory stop at a particularly better point in space than regularization. This not only prevent the parameters from being excessively skewed to the training distribution (over-fitting), but also better stimulate the network potential to obtain more powerful subnetworks. Extensive experiments are conducted to show the superiority of our methods in terms of accuracy and sparsity. ",https://openreview.net/pdf/bcd1bd832e5b83da08fcab57c4b9be71415ce9ea.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=CGBCTp2M6lA,Leveraging Future Relationship Reasoning for Vehicle Trajectory Prediction,"['Daehee Park', 'Hobin Ryu', 'Yunseo Yang', 'Jegyeong Cho', 'Jiwon Kim', 'Kuk-Jin Yoon']","['~Daehee_Park1', '~Hobin_Ryu2', '~Yunseo_Yang1', '~Jegyeong_Cho1', '~Jiwon_Kim8', '~Kuk-Jin_Yoon1']","['Trajectory prediction', 'Autonomous driving', 'Neural relation inference', 'Stochasticity modeling', 'Multimodal prediction']","Understanding the interaction between multiple agents is crucial for realistic vehicle trajectory prediction. 
Existing methods have attempted to infer the interaction from the observed past trajectories of agents using pooling, attention, or graph-based methods, which rely on a deterministic approach. 
However, these methods can fail under complex road structures, as they cannot predict various interactions that may occur in the future. 
In this paper, we propose a novel approach that uses lane information to predict a stochastic future relationship among agents. 
To obtain a coarse future motion of agents, our method first predicts the probability of lane-level waypoint occupancy of vehicles. 
We then utilize the temporal probability of passing adjacent lanes for each agent pair, assuming that agents passing adjacent lanes will highly interact. 
We also model the interaction using a probabilistic distribution, which allows for multiple possible future interactions. 
The distribution is learned from the posterior distribution of interaction obtained from ground truth future trajectories. 
We validate our method on popular trajectory prediction datasets: nuScenes and Argoverse. 
The results show that the proposed method brings remarkable performance gain in prediction accuracy, and achieves state-of-the-art performance in long-term prediction benchmark dataset.",https://openreview.net/pdf/26afa69e0c70599af069b4e1fd67c5256d02890a.pdf,{'title_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=CBfYffLqWqb,Evolving Populations of Diverse RL Agents with MAP-Elites,"['Thomas PIERROT', 'Arthur Flajolet']","['~Thomas_PIERROT1', '~Arthur_Flajolet2']",[],"Quality Diversity (QD) has emerged as a powerful alternative optimization paradigm that aims at generating large and diverse collections of solutions, notably with its flagship algorithm MAP-ELITES (ME) which evolves solutions through mutations and crossovers. While very effective for some unstructured problems, early ME implementations relied exclusively on random search to evolve the population of solutions, rendering them notoriously sample-inefficient for high-dimensional problems, such as when evolving neural networks. Follow-up works considered exploiting gradient information to guide the search in order to address these shortcomings through techniques borrowed from either Black-Box Optimization (BBO) or Reinforcement Learning (RL). While mixing RL techniques with ME unlocked state-of-the-art performance for robotics control problems that require a good amount of exploration, it also plagued these ME variants with limitations common among RL algorithms that ME was free of, such as hyperparameter sensitivity, high stochasticity as well as training instability, including when the population size increases as some components are shared across the population in recent approaches. Furthermore, existing approaches mixing ME with RL tend to be tied to a specific RL algorithm, which effectively prevents their use on problems where the corresponding RL algorithm fails. To address these shortcomings, we introduce a flexible framework that allows the use of any RL algorithm and alleviates the aforementioned limitations by evolving populations of agents (whose definition include hyperparameters and all learnable parameters) instead of just policies. We demonstrate the benefits brought about by our framework through extensive numerical experiments on a number of robotics control problems, some of which with deceptive rewards, taken from the QD-RL literature. We open source an efficient JAX-based implementation of our algorithm in the QDax library. ",https://openreview.net/pdf/7647093a5e985828f881513eb78bf7d36bde7a04.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=C9uEwyfklBE,Pareto Manifold Learning: Tackling multiple tasks via ensembles of single-task models,"['Nikolaos Dimitriadis', 'Pascal Frossard', 'François Fleuret']","['~Nikolaos_Dimitriadis1', '~Pascal_Frossard1', '~François_Fleuret2']","['Multi-Task Learning', 'multitask learning', 'mode connectivity', 'loss landscape', 'pareto optimal', 'pareto frontier']","In Multi-Task Learning, tasks may compete and limit the performance achieved on each other rather than guiding the optimization trajectory to a common solution, superior to its single-task counterparts. There is often not a single solution that is optimal for all tasks, leading practitioners to balance tradeoffs between tasks' performance, and to resort to optimality in the Pareto sense. Current Multi-Task Learning methodologies either completely neglect this aspect of functional diversity, and produce one solution in the Pareto Front predefined by their optimization schemes, or produce diverse but discrete solutions, each requiring a separate training run. In this paper, we conjecture that there exist Pareto Subspaces, i.e., weight subspaces where multiple optimal functional solutions lie. We propose Pareto Manifold Learning, an ensembling method in weight space that is able to discover such a parameterization and produces a continuous Pareto Front in a single training run, allowing practitioners to modulate the performance on each task during inference on the fly. We validate the proposed method on a diverse set of multi-task learning benchmarks, ranging from image classification to tabular datasets and scene understanding, and show that Pareto Manifold Learning outperforms state-of-the-art algorithms.
",https://openreview.net/pdf/79fc1069d1fe37ce839928e691c8f281db7c7fb9.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=C8by2OoY6Y2,Zero-Shot Retrieval with Search Agents and Hybrid Environments,"['Michelle Chen Huebscher', 'Christian Buck', 'Massimiliano Ciaramita', 'Sascha Rothe']","['~Michelle_Chen_Huebscher1', '~Christian_Buck1', '~Massimiliano_Ciaramita2', '~Sascha_Rothe1']","['learning to search', 'information retrieval', 'document ranking', 'relevance feedback', 'zero shot', 'language models', 'behavioral cloning']","Learning to search is the task of building artificial agents that learn to autonomously use a search box to find information. So far, it has been shown that current language models can learn symbolic query reformulation policies, in combination with traditional term-based retrieval, but fall short of outperforming neural retrievers. We extend the previous learning to search setup to a hybrid environment, which accepts discrete query refinement operations, after a first-pass retrieval step performed by a dual encoder. Experiments on the BEIR task show that search agents, trained via behavioral cloning, outperform the underlying search system based on a combined dual encoder retriever and cross encoder reranker. Furthermore, we find that simple heuristic Hybrid Retrieval Environments (HRE) can improve baseline performance by several nDCG points. The search agent based on the HRE environment (HaRE) produces state-of-the-art performance on both zero-shot and in-domain evaluations. We carry out an extensive qualitative analysis to shed light on the agents policies.",https://openreview.net/pdf/762770bc48f41ed202ffb6be40f0058989516d0f.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=C0q9oBc3n4,Temporal Dependencies in Feature Importance for Time Series Prediction,"['Kin Kwan Leung', 'Clayton Rooke', 'Jonathan Smith', 'Saba Zuberi', 'Maksims Volkovs']","['~Kin_Kwan_Leung1', '~Clayton_Rooke1', '~Jonathan_Smith2', '~Saba_Zuberi1', '~Maksims_Volkovs3']","['time series', 'recurrent', 'explainability']","Time series data introduces two key challenges for explainability methods: firstly, observations of the same feature over subsequent time steps are not independent, and secondly, the same feature can have varying importance to model predictions over time. In this paper, we propose Windowed Feature Importance in Time (WinIT), a feature removal based explainability approach to address these issues. Unlike existing feature removal explanation methods, WinIT explicitly accounts for the temporal dependence between different observations of the same feature in the construction of its importance score. Furthermore, WinIT captures the varying importance of a feature over time, by summarizing its importance over a window of past time steps. We conduct an extensive empirical study on synthetic and real-world data, compare against a wide range of leading explainability methods, and explore the impact of various evaluation strategies. Our results show that WinIT achieves significant gains over existing methods, with more consistent performance across different evaluation metrics.",https://openreview.net/pdf/0f72b3a91d343251112a9846581eefec130b00b6.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=C-xa_D3oTj6,DEP-RL: Embodied Exploration for Reinforcement Learning in Overactuated and Musculoskeletal Systems,"['Pierre Schumacher', 'Daniel Haeufle', 'Dieter Büchler', 'Syn Schmitt', 'Georg Martius']","['~Pierre_Schumacher1', '~Daniel_Haeufle1', '~Dieter_Büchler1', '~Syn_Schmitt1', '~Georg_Martius1']","['reinforcement learning', 'musculoskeletal', 'correlated exploration']","Muscle-actuated organisms are capable of learning an unparalleled diversity of dexterous movements despite their vast amount of muscles. 
Reinforcement learning (RL) on large musculoskeletal models, however, has not been able to show similar performance.  
We conjecture that ineffective exploration in large overactuated action spaces is a key problem.
This is supported by the finding that common exploration noise strategies are inadequate in synthetic examples of overactuated systems. 
We identify differential extrinsic plasticity (DEP), a method from the domain of self-organization, as being able to induce state-space covering exploration within seconds of interaction. 
By integrating DEP into RL, we achieve fast learning of reaching and locomotion in musculoskeletal systems, outperforming current approaches in all considered tasks in sample efficiency and robustness.",https://openreview.net/pdf/e3ebc4afb3c3051ac2670b1f21a54881897fe728.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Bq1-IOPKet,Optimal Transport-Based Supervised Graph Summarization,"['Sepideh Neshatfar', 'Abram Magner', 'Salimeh Yasaei Sekeh']","['~Sepideh_Neshatfar1', '~Abram_Magner1', '~Salimeh_Yasaei_Sekeh1']","['Graph Summarization', 'Optimal Transport', 'Supervised Learning', 'Mutual Information']","Graph summarization is the problem of producing smaller graph representations of an input graph dataset, in such a way that
  the smaller ``compressed'' graphs capture relevant structural information for downstream tasks.  One graph summarization
  method, recently proposed in Garg & Jaakkola (2019), formulates an optimal transport-based framework that allows prior information
  about node, edge, and attribute importance to be incorporated into the graph summarization process. We extend the optimal transport framework to a supervised graph summarization setting, wherein we seek to preserve relevant information about a class label.  We first formulate the problem in terms of maximizing the mutual information between the summarized graph and the class label.  We then propose a method that incorporates mutual information estimates between random variables associated with sample graphs and class labels into
  the optimal transport compression framework from Garg & Jaakkola (2019).  We empirically show performance improvements over the previous work by Garg & Jaakkola (2019), in terms of classification and compression on synthetic and real datasets.  We then theoretically show limitations of the optimal transport approach: e.g., that it fails to satisfy a certain desirable information monotonicity property.  ",https://openreview.net/pdf/c862f73b59ac7901d308f37d0e938a9e4d7ddaf6.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Bo7eeXm6An8,Multi-lingual Evaluation of Code Generation Models,"['Ben Athiwaratkun', 'Sanjay Krishna Gouda', 'Zijian Wang', 'Xiaopeng Li', 'Yuchen Tian', 'Ming Tan', 'Wasi Uddin Ahmad', 'Shiqi Wang', 'Qing Sun', 'Mingyue Shang', 'Sujan Kumar Gonugondla', 'Hantian Ding', 'Varun Kumar', 'Nathan Fulton', 'Arash Farahani', 'Siddhartha Jain', 'Robert Giaquinto', 'Haifeng Qian', 'Murali Krishna Ramanathan', 'Ramesh Nallapati', 'Baishakhi Ray', 'Parminder Bhatia', 'Sudipta Sengupta', 'Dan Roth', 'Bing Xiang']","['~Ben_Athiwaratkun1', '~Sanjay_Krishna_Gouda1', '~Zijian_Wang1', '~Xiaopeng_Li1', 'tiayuche@amazon.com', '~Ming_Tan2', '~Wasi_Uddin_Ahmad1', '~Shiqi_Wang2', '~Qing_Sun2', '~Mingyue_Shang1', '~Sujan_Kumar_Gonugondla1', '~Hantian_Ding1', '~Varun_Kumar3', '~Nathan_Fulton2', '~Arash_Farahani1', '~Siddhartha_Jain1', '~Robert_Giaquinto1', '~Haifeng_Qian1', '~Murali_Krishna_Ramanathan1', '~Ramesh_Nallapati1', '~Baishakhi_Ray2', '~Parminder_Bhatia1', 'sudipta@amazon.com', '~Dan_Roth3', '~Bing_Xiang2']","['code generation', 'execution-based evaluation', 'test-based evaluation', 'language models', 'multi-lingual code generation benchmark', 'code insertion', 'code summarization', 'robustness for code', 'code translation', 'zero-shot code translation', 'multi-lingual', 'mono-lingual', 'language models.']","We present two new benchmarks, MBXP and Multilingual HumanEval, designed to evaluate code completion models in over 10 programming languages. These datasets are generated using a conversion framework that transpiles prompts and test cases from the original MBPP and HumanEval datasets into the corresponding data in the target language. By using these benchmarks, we are able to assess the performance of code generation models in a multi-lingual fashion, and discovered generalization ability of language models on out-of-domain languages, advantages of multi-lingual models over mono-lingual, the ability of  few-shot prompting to teach the model new languages, and zero-shot translation abilities. In addition, we use our code generation model to perform large-scale bootstrapping to obtain synthetic canonical solutions in several languages, which can be used for other code-related evaluations such as code insertion, robustness, or summarization tasks.",https://openreview.net/pdf/c2ba4659e44c45ec67969ec9a74097a37184ad62.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=BgMo9ofIQi6,GENERALIZED MATRIX LOCAL LOW RANK REPRESENTATION BY RANDOM PROJECTION AND SUBMATRIX PROPAGATION,"['Pengtao Dang', 'Wennan Chang', 'Haiqi Zhu', 'Changlin Wan', 'Tong Zhao', 'Tingo Guo', 'Paul Salama', 'Sha Cao', 'Chi Zhang']","['~Pengtao_Dang1', '~Wennan_Chang1', '~Haiqi_Zhu1', '~Changlin_Wan1', '~Tong_Zhao2', 'guoti@iu.edu', '~Paul_Salama1', '~Sha_Cao1', '~Chi_Zhang18']","['Matrix decomposition', 'Local Low Rank matrix detection', 'Representation learning', 'Subspace learning']","Detecting distinct submatrices of low rank property is a highly desirable matrix representation learning technique for the ease of data interpretation, called the matrix local low rank representation (MLLRR). Based on different mathematical assumptions of the local pattern, the MLLRR problem could be categorized into two sub-problems, namely local constant variation (LCV) and local linear low rank (LLR). Existing solutions on MLLRR only focused on the LCV problem, which misses a substantial amount of true and interesting patterns. In this work, we develop a novel matrix computational framework called RPSP (Random Probing based submatrix Propagation) that provides an effective solution for both of the LCV and LLR problems. RPSP detects local low rank patterns that grow from small submatrices of low rank property, which are determined by a random projection approach. RPSP is supported by theories of random projection. Experiments on synthetic data demonstrate that RPSP outperforms all state-of-the-art methods, with the capacity to robustly and correctly identify the low rank matrices under both LCV and LLR settings. On real-world datasets, RPSP also demonstrates its effectiveness in identifying interpretable local low rank matrices.
",https://openreview.net/pdf/b0f398213087ced361c7136cd33800f94b074f47.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=BYWWwSY2G5s,Score-based Continuous-time Discrete Diffusion Models,"['Haoran Sun', 'Lijun Yu', 'Bo Dai', 'Dale Schuurmans', 'Hanjun Dai']","['~Haoran_Sun2', '~Lijun_Yu1', '~Bo_Dai1', '~Dale_Schuurmans1', '~Hanjun_Dai1']","['discrete space diffusion', 'discrete score matching', 'continuous-time diffusion']","Score-based modeling through stochastic differential equations (SDEs) has provided a new perspective on diffusion models, and demonstrated superior performance on continuous data. However, the gradient of the log-likelihood function, \ie, the score function, is not properly defined for discrete spaces. This makes it non-trivial to adapt SDE with score functions to categorical data. In this paper, we extend diffusion models to discrete variables by introducing a stochastic jump process where the reverse process denoises via a continuous-time Markov chain. This formulation admits an analytical simulation during backward sampling. To learn the reverse process, we extend score matching to general categorical data, and show that an unbiased estimator can be obtained via simple matching of the conditional marginal distributions. We demonstrate the effectiveness of the proposed method on a set of synthetic and real-world music and image benchmarks.",https://openreview.net/pdf/d96e90543a3d04a3e6248eacc3088b15b0907078.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=BR_ZhvcYbGJ,Explaining Temporal Graph Models through an Explorer-Navigator Framework,"['Wenwen Xia', 'Mincai Lai', 'Caihua Shan', 'Yao Zhang', 'Xinnan Dai', 'Xiang Li', 'Dongsheng Li']","['~Wenwen_Xia1', '~Mincai_Lai1', '~Caihua_Shan1', '~Yao_Zhang6', '~Xinnan_Dai1', '~Xiang_Li24', '~Dongsheng_Li2']","['graph neural networks', 'gnn explainers', 'temporal graphs']","While GNN explanation has recently received significant attention, existing works are consistently designed for static graphs. Due to the prevalence of temporal graphs, many temporal graph models have been proposed, but explaining their predictions remains to be explored. To bridge the gap, in this paper, we propose T-GNNExplainer for temporal graph model explanation. Specifically, we regard a temporal graph constituted by a sequence of temporal events. Given a target event, our task is to find a subset of previously occurred events that lead to the model's prediction for it. To handle this combinatorial optimization problem, T-GNNExplainer includes an explorer to find the event subsets with Monte Carlo Tree Search (MCTS)  and a navigator that learns the correlations between events and helps reduce the search space. In particular, the navigator is trained in advance and then integrated with the explorer to speed up searching and achieve better results. To the best of our knowledge, T-GNNExplainer is the first explainer tailored for temporal graph models. We conduct extensive experiments to evaluate the performance of T-GNNExplainer. Experimental results on both real-world and synthetic datasets demonstrate that T-GNNExplainer can achieve superior performance with up to about 50% improvement in Area under Fidelity-Sparsity Curve. ",https://openreview.net/pdf/f236c13f60a0bf5c74cb31ee8bd5bf77939d656b.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=BNsuf5g-JRd,Solving Partial Label Learning Problem with Multi-Agent Reinforcement Learning,"['Xinyi Zhang', 'Xingdong Feng', 'Fan Zhou']","['~Xinyi_Zhang5', '~Xingdong_Feng1', '~Fan_Zhou7']",[],"Partial label learning (PLL) deals with classifications when a set of candidate labels instead of the true one is given for each training instance. As a weakly supervised learning problem, the main target of PLL is to discover latent relationships within training samples, and utilize such information to disambiguate noisy labels. Many existing methods choose nearest neighbors of each partially-labeled instance in an unsupervised way such that the obtained instance similarities can be empirically non-optimal and unrelated to the downstream classification task. To address this issue, we propose a novel multi-agent reinforcement learning (MARL) framework which models the connection between each pair of training samples as a reinforcement learning (RL) agent. We use attention-based graph neural network (GNN) to learn the instance similarity, and adaptively refine it using a deterministic policy gradient approach until some pre-defined scoring function is optimized. Different from those two-stage and alternative optimization algorithms whose training procedures are not end-to-end, our RL-based approach directly optimizes the objective function and estimates the instance similarities more precisely. The experimental results show that our method outperforms state-of-the-art competitors with a higher classification accuracy in both synthetic and real examples. ",https://openreview.net/pdf/d7bd458b34d72121a2a6cea8eb5e6af29e8ea8dc.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=BLOkjU9iS24,Constrained Reinforcement Learning for Safety-Critical Tasks via Scenario-Based Programming,"['Davide Corsi', 'Raz Yerushalmi', 'Guy Amir', 'Alessandro Farinelli', 'David Harel', 'Guy Katz']","['~Davide_Corsi1', '~Raz_Yerushalmi1', '~Guy_Amir1', '~Alessandro_Farinelli1', 'david.harel@weizmann.ac.il', '~Guy_Katz1']","['Constrained Reinforcement Learning', 'Scenario Based Programming', 'Safety', 'Robotic Navigation']","Deep reinforcement learning (DRL) has achieved groundbreaking successes in various applications, including robotics. A natural consequence is the adoption of this paradigm for safety-critical tasks, where human safety and expensive hardware can be involved. In this context, it is crucial to optimize the performance of DRL-based agents while providing guarantees about their behavior. This paper presents a novel technique for incorporating domain-expert knowledge into a constrained DRL training loop. Our technique exploits the scenario-based programming paradigm, designed to specify such knowledge in a simple and intuitive way. While our approach can be considered general purpose, we validated our method by performing experiments on a synthetic set of benchmark environments, and the popular robotic mapless navigation problem, in simulation and on the actual platform. Our results demonstrate that using our approach to leverage expert knowledge dramatically improves the safety and performance of the agent.",https://openreview.net/pdf/037db8a93436a735e5b8586baefc2e78a15985e7.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=B4maZQLLW0_,Stateful Active Facilitator: Coordination and Environmental Heterogeneity in Cooperative Multi-Agent Reinforcement Learning,"['Dianbo Liu', 'Vedant Shah', 'Oussama Boussif', 'Cristian Meo', 'Anirudh Goyal', 'Tianmin Shu', 'Michael Curtis Mozer', 'Nicolas Heess', 'Yoshua Bengio']","['~Dianbo_Liu2', '~Vedant_Shah2', '~Oussama_Boussif1', 'c.meo@tudelft.nl', '~Anirudh_Goyal1', '~Tianmin_Shu1', '~Michael_Curtis_Mozer1', '~Nicolas_Heess1', '~Yoshua_Bengio1']",[],"In cooperative multi-agent reinforcement learning, a team of agents works together
to achieve a common goal. Different environments or tasks may require varying
degrees of coordination among agents in order to achieve the goal in an optimal
way. The nature of coordination will depend on properties of the environment—its
spatial layout, distribution of obstacles, dynamics, etc. We term this variation
of properties within an environment as heterogeneity. Existing literature has not
sufficiently addressed the fact that different environments may have different levels
of heterogeneity. We formalize the notions of coordination level and heterogeneity
level of an environment and present HECOGrid, a suite of multi-agent RL
environments that facilitates empirical evaluation of different MARL approaches
across different levels of coordination and environmental heterogeneity by providing
a quantitative control over coordination and heterogeneity levels of the
environment. Further, we propose a Centralized Training Decentralized Execution
learning approach called Stateful Active Facilitator (SAF) that enables agents to
work efficiently in high-coordination and high-heterogeneity environments through
a differentiable and shared knowledge source used during training and dynamic
selection from a shared pool of policies. We evaluate SAF and compare its performance
against baselines IPPO and MAPPO on HECOGrid. Our results show
that SAF consistently outperforms the baselines across different tasks and different
heterogeneity and coordination levels.",https://openreview.net/pdf/e91b82d1a670376c4dd37b3ff6ed712eff719b12.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=B-z41MBL_tH,Causal Imitation Learning via Inverse Reinforcement Learning,"['Kangrui Ruan', 'Junzhe Zhang', 'Xuan Di', 'Elias Bareinboim']","['~Kangrui_Ruan1', '~Junzhe_Zhang3', '~Xuan_Di1', '~Elias_Bareinboim2']","['Causal Inference', 'Graphical Models']","One of the most common ways children learn when unfamiliar with the environment is by mimicking adults. Imitation learning concerns an imitator learning to behave in an unknown environment from an expert's demonstration; reward signals remain latent to the imitator. This paper studies imitation learning through causal lenses and extends the analysis and tools developed for behavior cloning (Zhang, Kumor, Bareinboim, 2020) to inverse reinforcement learning. First, we propose novel graphical conditions that allow the imitator to learn a policy performing as well as the expert's behavior policy, even when the imitator and the expert's state-action space disagree, and unobserved confounders (UCs) are present. When provided with parametric knowledge about the unknown reward function, such a policy may outperform the expert's. Also, our method is easily extensible and allows one to leverage existing IRL algorithms even when UCs are present, including the multiplicative-weights algorithm (MWAL) (Syed & Schapire, 2008) and the generative adversarial imitation learning (GAIL) (Ho & Ermon, 2016). Finally, we validate our framework by simulations using real-world and synthetic data.",https://openreview.net/pdf/2d0bee07a9f373073524d04d2dae5fab301d34be.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=B-dM7df9Axo,Learning PDE Solution Operator for Continuous Modeling of Time-Series,"['Yesom Park', 'Jaemoo Choi', 'Changyeon Yoon', 'Chang hoon Song', 'Myungjoo Kang']","['~Yesom_Park1', '~Jaemoo_Choi1', '~Changyeon_Yoon1', '~Chang_hoon_Song1', '~Myungjoo_Kang1']","['Neural ODEs', 'Partial differential equations', 'Neural operators', 'Time-series']","Learning underlying dynamics from data is important and challenging in many real-world scenarios. Incorporating differential equations (DEs) to design continuous networks has drawn much attention recently, the most prominent of which is Neural ODE. Most prior works make specific assumptions on the type of DEs or restrict them to first or second-order DEs, making the model specialized for certain problems. Furthermore, due to the use of numerical integration, they suffer from computational expensiveness and numerical instability. Building upon recent Fourier neural operator (FNO), this work proposes a partial differential equation (PDE) based framework which improves the dynamics modeling capability and circumvents the need for costly numerical integration. FNO is hard to be directly applied to real applications because it is mainly confined to physical PDE problems. To fill this void, we propose a continuous-in-time FNO to deal with irregularly-sampled time series and provide a theoretical result demonstrating its universality. Moreover, we reveal an intrinsic property of PDEs that increases the stability of the model. Several numerical evidence shows that our method represents a broader range of problems, including synthetic, image classification, and irregular time-series. Our framework opens up a new way for a continuous representation of neural networks that can be readily adopted for real-world applications.",https://openreview.net/pdf/1875ce999b29a2f8ac87318e95b36e4fe1e5a792.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=AuEgNlEAmed,A theoretical study of inductive biases in contrastive learning,"['Jeff Z. HaoChen', 'Tengyu Ma']","['~Jeff_Z._HaoChen1', '~Tengyu_Ma1']","['theory of self-supervised learning', 'theory of contrastive learning']","Understanding self-supervised learning is important but challenging. Previous theoretical works study the role of pretraining losses, and view neural networks as general black boxes. However, the recent work of [Saunshi et al.] argues that the model architecture --- a component largely ignored by previous works --- also has significant influences on the downstream performance of self-supervised learning. In this work, we provide the first theoretical analysis of self-supervised learning that incorporates the effect of inductive biases originating from the model class. In particular, we focus on contrastive learning --- a popular self-supervised learning method that is widely used in the vision domain. We show that when the model has limited capacity, contrastive representations would recover certain special clustering structures that are compatible with the model architecture, but ignore many other clustering structures in the data distribution. As a result, our theory can capture the more realistic setting where contrastive representations have much lower dimensionality than the number of clusters in the data distribution. We instantiate our theory on several synthetic data distributions, and provide empirical evidence to support the theory.",https://openreview.net/pdf/c0e1dd5361d9fbb78aee85364df2ab49854653b4.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=AjC0KBjiMu,Contrastive Learning Can Find An Optimal Basis For Approximately View-Invariant Functions,"['Daniel D. Johnson', 'Ayoub El Hanchi', 'Chris J. Maddison']","['~Daniel_D._Johnson1', '~Ayoub_El_Hanchi1', '~Chris_J._Maddison1']","['contrastive learning', 'self-supervised learning', 'representation learning', 'kernel', 'kernel PCA', 'positive definite', 'eigenfunction', 'spectral clustering', 'invariance', 'Markov chain', 'minimax optimal']","Contrastive learning is a powerful framework for learning self-supervised representations that generalize well to downstream supervised tasks. We show that multiple existing contrastive learning methods can be reinterpeted as learning kernel functions that approximate a fixed *positive-pair kernel*. We then prove that a simple representation obtained by combining this kernel with PCA provably minimizes the worst-case approximation error of linear predictors, under a straightforward assumption that positive pairs have similar labels. Our analysis is based on a decomposition of the target function in terms of the eigenfunctions of a positive-pair Markov chain, and a surprising equivalence between these eigenfunctions and the output of Kernel PCA. We give generalization bounds for downstream linear prediction using our kernel PCA representation, and show empirically on a set of synthetic tasks that applying kernel PCA to contrastive learning models can indeed approximately recover the Markov chain eigenfunctions, although the accuracy depends on the kernel parameterization as well as on the augmentation strength.",https://openreview.net/pdf/470d0d377fbd21359685cd8abe602339d5f71751.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=AP0iZoaRaS,Interactive Portrait Harmonization,"['Jeya Maria Jose Valanarasu', 'HE Zhang', 'Jianming Zhang', 'Yilin Wang', 'Zhe Lin', 'Jose Echevarria', 'Yinglan Ma', 'Zijun Wei', 'Kalyan Sunkavalli', 'Vishal Patel']","['~Jeya_Maria_Jose_Valanarasu1', '~HE_Zhang2', '~Jianming_Zhang1', '~Yilin_Wang4', '~Zhe_Lin1', '~Jose_Echevarria1', 'yingma@adobe.com', '~Zijun_Wei2', '~Kalyan_Sunkavalli1', '~Vishal_Patel2']","['harmonization', 'image editing', 'low-level vision']","Current image harmonization methods consider the entire background as the guidance for harmonization. However, this may limit the capability for user to choose any specific object/person in the background to guide the harmonization. To enable flexible interaction between user and harmonization, we introduce interactive harmonization, a new setting where the harmonization is performed with respect to a selected region in the reference image instead of the entire background. A new flexible framework that allows users to pick certain regions of the background image and use it to guide the harmonization is proposed. Inspired by professional portrait harmonization users, we also introduce a new luminance matching loss to optimally match the color/luminance conditions between the composite foreground and select reference region. This framework provides more control to the image harmonization pipeline achieving visually pleasing portrait edits. Furthermore, we also introduce a new dataset carefully curated for validating portrait harmonization. Extensive experiments on both synthetic and real-world datasets show that the proposed approach is efficient and robust compared to previous harmonization baselines, especially for portraits.",https://openreview.net/pdf/8fecedc380fae9d1025815dc9e8f0bdac4616474.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=AGLG_ncNp0X,Personalized Federated Hypernetworks for Privacy Preservation in Multi-Task Reinforcement Learning,"['Doseok Jang', 'Larry Yan', 'Lucas Spangher', 'Selvaprabu Nadarajah', 'Costas Spanos']","['~Doseok_Jang1', 'yanlarry@berkeley.edu', '~Lucas_Spangher1', '~Selvaprabu_Nadarajah1', '~Costas_Spanos1']","['microgrid clusters', 'energy demand response', 'transactive energy control', 'neural networks', 'multi-agent reinforcement learning', 'reinforcement learning', 'multi-task learning', 'transfer learning', 'hypernetworks', 'federated learning', 'personalized federated learning', 'microgrids']","Multi-Agent Reinforcement Learning currently focuses on implementations where all data and training can be centralized to one machine. But what if local agents are split across multiple tasks, and need to keep data private between each? We develop the first application of Personalized Federated Hypernetworks (PFH) to Reinforcement Learning (RL). We then present a novel application of PFH to few-shot transfer, and demonstrate significant initial increases in learning. PFH has never been demonstrated beyond supervised learning benchmarks, so we apply PFH to an important domain: RL price-setting for energy demand response. We consider a general case across where agents are split across multiple microgrids, wherein energy consumption data must be kept private within each microgrid. Together, our work explores how the fields of personalized federated learning and RL can come together to make learning efficient across multiple tasks while keeping data secure.",https://openreview.net/pdf/4b9fd7dcf31573a4c496b1dca9451051ca9aae7d.pdf,{'abstract_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=A09CypdRq8D,Partial Advantage Estimator for Proximal Policy Optimization,"['Xiulei Song', 'Yizhao Jin', 'Gregory Slabaugh', 'Simon Lucas']","['~Xiulei_Song2', '~Yizhao_Jin1', '~Gregory_Slabaugh2', '~Simon_Lucas1']","['Reinforcement learning', 'value estimator']","Estimation of value in policy gradient methods is a fundamental problem. Generalized Advantage Estimation (GAE) is an exponentially-weighted estimator of an advantage function similar to TD($\lambda$). It substantially reduces the variance of policy gradient estimates at the expense of bias. In practical applications, a truncated GAE is used due to the incompleteness of the trajectory, which results in a large bias during estimation. To address this challenge, instead of using the all truncated GAE, we propose to take a part of the calculated GAE for updates, which significantly reduces the bias due to the incomplete trajectory.  We perform experiments in MuJoCo and $\mu$RTS to investigate the effect of different partial coefficient and sampling lengths. We show that our partial GAE approach yields better empirical results in both environments.",https://openreview.net/pdf/c28b221c8c849bf17d74b8eea6ea662ca5d48596.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=9bVBH1GD5sr,FOCUS: Fairness via Agent-Awareness for Federated Learning on Heterogeneous Data,"['Wenda Chu', 'Chulin Xie', 'Boxin Wang', 'Linyi Li', 'Lang Yin', 'Han Zhao', 'Bo Li']","['~Wenda_Chu1', '~Chulin_Xie1', '~Boxin_Wang1', '~Linyi_Li1', '~Lang_Yin1', '~Han_Zhao1', '~Bo_Li19']","['federated learning', 'fairness', 'data heterogeneity', 'clustering', 'expectation–maximization (EM)']","Federated learning (FL) provides an effective collaborative training paradigm, allowing local agents to train a global model jointly without sharing their local data to protect privacy.
On the other hand, due to the heterogeneous nature of local agents, it is challenging to optimize or even define the fairness for agents, which may discourage valuable participation. For instance, the trained global model may sacrifice the performance of a minority user with high-quality data based on loss optimization over all users.
Existing work usually considers accuracy equity as fairness for different users in FL, which is limited especially under the heterogeneous setting, since it is intuitively ""unfair"" that agents with low-quality data would achieve similar accuracy.
In this work, we aim to address such limitations and propose a formal fairness definition in FL, fairness via agent-awareness (FAA), which takes the heterogeneous data contributions of local agents into account. In addition, we propose a fair FL training algorithm based on agent clustering (FOCUS) to achieve FAA. Theoretically, we prove the convergence and optimality of  FOCUS under mild conditions for linear and general convex loss functions with bounded smoothness. We also prove that FOCUS always achieves higher fairness measured by FAA compared with standard FedAvg protocol under both linear and general convex loss functions. Empirically, we evaluate FOCUS on four datasets, including synthetic data, images, and texts under different settings, and we show that FOCUS achieves significantly higher fairness based on FAA while maintaining similar or even higher prediction accuracy compared with FedAvg and other existing fair FL algorithms.
",https://openreview.net/pdf/efce74618927c1b658562643f202ee2c472d2056.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=9Y0P3YoERSy,The GANfather: Controllable generation of malicious activity to expose detection weaknesses and improve defence systems.,"['Ricardo Ribeiro Pereira', 'Jacopo Bono', 'João Tiago Ascensão', 'David Oliveira Aparicio', 'Pedro Manuel Pinto Ribeiro', 'Pedro Bizarro']","['~Ricardo_Ribeiro_Pereira1', '~Jacopo_Bono1', '~João_Tiago_Ascensão1', '~David_Oliveira_Aparicio1', '~Pedro_Manuel_Pinto_Ribeiro1', '~Pedro_Bizarro1']",[],"Criminal activities are typically adversarial in nature, where an attacker and a defence system are constantly adapting to each other's behaviour. If the defence systems are helped by automated detection methods, then those methods need to be updated frequently. In practice, this means that the defence systems are always one step behind the attackers. For example, in anti-money laundering systems, new labels representing suspicious activity are frequently delayed by weeks or months and some money laundering activity may never be found, leading to detection systems that are inaccurate and resulting in an estimated undetected €0.7-3 trillion being laundered annually.

To tackle the problem of missing or delayed labels in adversarial settings, we propose The GANfather, an adversarial and label-free method to both (1) generate a variety of meaningful attacks, as guided by a custom, user-defined objective function; and (2) train a defence system to detect such attacks. Optionally, we can ensure that the generated attacks escape an existing detection system, revealing current weaknesses which the new defence system actively corrects. Our method is inspired by generative adversarial networks (GANs), but unlike GANs we nudge our generator to produce out-of-distribution data using a loss function that characterises criminal activity. Importantly, our method does not require any labelled examples.

We test our framework in two real-world use-cases, namely injection attacks in recommendation systems and anti-money laundering. In the former, we show how an injection attack with a limited number of generated fake profiles is sufficient to successfully recommend an item to a large number of users. These generated injection attacks are more effective in recommending the target item than naive ‘bombing’ strategies and harder to detect. In the latter, the generated attacks are able to simulate money laundering and move cumulative amounts close to 250 thousand dollars through a network of accounts without being detected by existing systems. We also show how we can train a new defence system that captures all these synthetic attacks, potentially saving millions of dollars in detected criminal activity. Our method is generic and applicable in a variety of adversarial domains, exposing current liabilities with the generated data and strengthening the defence systems against current and future malicious attacks.",https://openreview.net/pdf/42bc64d5cad694bdc4905e3b0483c583e339edab.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=9WdB5yVICCA,CausalAgents: A Robustness Benchmark for Motion Forecasting Using Causal Relationships,"['Rebecca Roelofs', 'Liting Sun', 'Benjamin Caine', 'Khaled S. Refaat', 'Benjamin Sapp', 'Scott Ettinger', 'Wei Chai']","['~Rebecca_Roelofs1', '~Liting_Sun1', '~Benjamin_Caine1', '~Khaled_S._Refaat1', '~Benjamin_Sapp3', '~Scott_Ettinger1', 'chaiwei@google.com']","['robustness', 'motion forecasting', 'self-driving cars']","As machine learning models become increasingly prevalent in motion forecasting systems for autonomous vehicles (AVs), it is critical that we ensure that model predictions are safe and reliable. However, exhaustively collecting and labeling the data necessary to fully test the long tail of rare and challenging scenarios is difficult and expensive. In this work, we construct a new benchmark for evaluating and improving model robustness by applying perturbations to existing data. Specifically, we conduct an extensive labeling effort to identify causal agents, or agents whose presence influences human driver behavior in any way, in the Waymo Open Motion Dataset (WOMD), and we use these labels to perturb the data by deleting non-causal agents from the scene. We then evaluate a diverse set of state-of-the-art deep-learning model architectures on our proposed benchmark and find that all models exhibit large shifts under perturbation. Under non-causal perturbations, we observe a 25-38% relative change in minADE as compared to the original. We then investigate techniques to improve model robustness, including increasing the training dataset size and using targeted data augmentations that drop agents throughout training. We provide the causal agent labels as an additional attribute to WOMD and release the robustness benchmarks to aid the community in building more reliable and safe deep-learning models for motion forecasting. 
",https://openreview.net/pdf/bfb992bb824c13285ca88bca7b97ffe32757c4a3.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=9JjGZsDvHb,Metro: Memory-Enhanced Transformer for Retrosynthetic Planning via Reaction Tree,"['Songtao Liu', 'Zhitao Ying', 'Zuobai Zhang', 'Peilin Zhao', 'Jian Tang', 'Lu Lin', 'Dinghao Wu']","['~Songtao_Liu2', '~Zhitao_Ying1', '~Zuobai_Zhang1', '~Peilin_Zhao2', '~Jian_Tang1', '~Lu_Lin2', '~Dinghao_Wu1']","['Retrosynthetic Planning', 'Transformer', 'Memory Network', 'Reaction Database', 'Reaction tree']","Retrosynthetic planning plays a critical role in drug discovery and organic chemistry. Starting from a target molecule as the root node, it aims to find a complete reaction tree subject to the constraint that all leaf nodes belong to a set of starting materials. The multi-step reactions are crucial because they determine the flow chart in the production of the Organic Chemical Industry. However, existing datasets lack curation of tree-structured multi-step reactions and fail to provide such reaction trees, limiting models' understanding of organic molecule transformations. In this work, we first develop a benchmark curated for the retrosynthetic planning task, which consists of 124,869 reaction trees retrieved from the public USPTO-full dataset. On top of that, we propose Metro: Memory-Enhanced Transformer for RetrOsynthetic planning. Specifically, the dependency among molecules in the reaction tree is captured as context information for multi-step retrosynthesis predictions through transformers with a memory module. Extensive experiments show that Metro dramatically outperforms existing single-step retrosynthesis models by at least 10.7% in top-1 accuracy. The experiments demonstrate the superiority of exploiting context information in the retrosynthetic planning task. Moreover, the proposed model can be directly used for synthetic accessibility analysis, as it is trained on reaction trees with the shortest depths. Our work is the first step towards a brand new formulation for retrosynthetic planning in the aspects of data construction, model design, and evaluation.",https://openreview.net/pdf/ae5a91db6a4c68feea708424f46b7478c93fa89a.pdf,{'title_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=9IlzJa5cAv,DT+GNN: A Fully Explainable Graph Neural Network using Decision Trees,"['Peter Müller', 'Lukas Faber', 'Karolis Martinkus', 'Roger Wattenhofer']","['~Peter_Müller2', '~Lukas_Faber1', '~Karolis_Martinkus1', '~Roger_Wattenhofer1']",[],"We propose a new Decision Tree Graph Neural Network (DT+GNN) architecture for Graph Neural Network (GNN) explanation. Existing post-hoc explanation methods highlight important inputs but fail to reveal how a GNN uses these inputs. In contrast DT+GNN is fully explainable: Humans can inspect and understand the decision making of DT+GNN at every step. DT+GNN internally uses a novel GNN layer that is restricted to categorical state spaces for nodes and messages. After training with gradient descent we can easily distill these layers into decision trees. These trees are further pruned using our newly proposed method to ensure they are small and easy to interpret. DT+GNN can also compute node-level importance scores like the existing explanation methods. We demonstrate on real-world GNN benchmarks that DT+GNN has competitive classification accuracy and computes competitive explanations. Furthermore, we leverage DT+GNN's full explainability to inspect the decision processes in synthetic and real-world datasets with surprising results. We make this inspection accessible through an interactive web tool.",https://openreview.net/pdf/2067637eaa2922f308ff534774c4c36ae465e074.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=9DZKk85Z4zA,Gradient-Guided Importance Sampling for Learning Binary Energy-Based Models,"['Meng Liu', 'Haoran Liu', 'Shuiwang Ji']","['~Meng_Liu3', '~Haoran_Liu1', '~Shuiwang_Ji1']",[],"Learning energy-based models (EBMs) is known to be difficult especially on discrete data where gradient-based learning strategies cannot be applied directly. Although ratio matching is a sound method to learn discrete EBMs, it suffers from expensive computation and excessive memory requirements, thereby resulting in difficulties in learning EBMs on high-dimensional data. Motivated by these limitations, in this study, we propose ratio matching with gradient-guided importance sampling (RMwGGIS). Particularly, we use the gradient of the energy function w.r.t. the discrete data space to approximately construct the provably optimal proposal distribution, which is subsequently used by importance sampling to efficiently estimate the original ratio matching objective. We perform experiments on density modeling over synthetic discrete data, graph generation, and training Ising models to evaluate our proposed method. The experimental results demonstrate that our method can significantly alleviate the limitations of ratio matching, perform more effectively in practice, and scale to high-dimensional problems. Our implementation is available at https://github.com/divelab/RMwGGIS.",https://openreview.net/pdf/5b2f9ad18b0930a16ef891e03d537cc91c0c7e09.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=99RpBVpLiX,Distilling Model Failures as Directions in Latent Space,"['Saachi Jain', 'Hannah Lawrence', 'Ankur Moitra', 'Aleksander Madry']","['~Saachi_Jain1', '~Hannah_Lawrence1', '~Ankur_Moitra1', '~Aleksander_Madry1']","['datasets', 'biases', 'subpopulations']","Existing methods for isolating hard subpopulations and spurious correlations in datasets often require human intervention. This can make these methods labor-intensive and dataset-specific. To address these shortcomings, we present a scalable method for automatically distilling a model's failure modes. Specifically, we harness linear classifiers to identify consistent error patterns, and, in turn, induce a natural representation of these failure modes as directions within the feature space. We demonstrate that this framework allows us to discover and automatically caption challenging subpopulations within the training dataset. Moreover, by combining our framework with off-the-shelf diffusion models, we can generate images that are especially challenging for the analyzed model, and thus can be used to perform synthetic data augmentation that helps remedy the model's failure modes.",https://openreview.net/pdf/c9daa261ea96d95a6dee52da157a59e14333cf07.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=8xuFD1yCoH,TuneUp: A Training Strategy for Improving Generalization of Graph Neural Networks,"['Weihua Hu', 'Kaidi Cao', 'Kexin Huang', 'Edward W Huang', 'Karthik Subbian', 'Jure Leskovec']","['~Weihua_Hu1', '~Kaidi_Cao1', '~Kexin_Huang1', '~Edward_W_Huang1', '~Karthik_Subbian1', '~Jure_Leskovec1']","['Graph Neural Networks', 'Curriculum learning', 'Tail nodes']","Despite many advances in Graph Neural Networks (GNNs), their training strategies simply focus on minimizing a loss over nodes in a graph. However, such simplistic training strategies may be sub-optimal as they neglect that certain nodes are much harder to make accurate predictions on than others. Here we present TuneUp, a curriculum learning strategy for better training GNNs. Crucially, TuneUp trains a GNN in two stages. The first stage aims to produce a strong base GNN. Such base GNNs tend to perform well on head nodes (nodes with large degrees) but less so on tail nodes (nodes with small degrees). So, the second stage of TuneUp specifically focuses on improving prediction on tail nodes. Concretely, TuneUp synthesizes many additional supervised tail node data by dropping edges from head nodes and reusing the supervision on the original head nodes. TuneUp then minimizes the loss over the synthetic tail nodes to finetune the base GNN. TuneUp is a general training strategy that can be used with any GNN architecture and any loss, making TuneUp applicable to a wide range of prediction tasks. Extensive evaluation of TuneUp on two GNN architectures, three types of prediction tasks, and both inductive and transductive settings shows that TuneUp significantly improves the performance of the base GNN on tail nodes, while often even improving the performance on head nodes, which together leads up to 58.5% relative improvement in GNN predictive performance. Moreover, TuneUp significantly outperforms its variants without the two-stage curriculum learning, existing graph data augmentation techniques, as well as other specialized methods for tail nodes.",https://openreview.net/pdf/c1fcb0581242deb2e9ea2725f4b54e66dd444123.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=8sSnD78NqTN,Learning Soft Constraints From Constrained Expert Demonstrations,"['Ashish Gaurav', 'Kasra Rezaee', 'Guiliang Liu', 'Pascal Poupart']","['~Ashish_Gaurav1', '~Kasra_Rezaee1', '~Guiliang_Liu1', '~Pascal_Poupart2']","['inverse reinforcement learning', 'constraint learning']","Inverse reinforcement learning (IRL) methods assume that the expert data is generated by an agent optimizing some reward function. However, in many settings, the agent may optimize a reward function subject to some constraints, where the constraints induce behaviors that may be otherwise difficult to express with just a reward function. We consider the setting where the reward function is given, and the constraints are unknown, and propose a method that is able to recover these constraints satisfactorily from the expert data. While previous work has focused on recovering hard constraints, our method can recover cumulative soft constraints that the agent satisfies on average per episode. In IRL fashion, our method solves this problem by adjusting the constraint function iteratively through a constrained optimization procedure, until the agent behavior matches the expert behavior. We demonstrate our approach on synthetic environments, robotics environments and real world highway driving scenarios.",https://openreview.net/pdf/8fcf77a080574ee36abb6525663524292f7b5217.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=8WTAh0tj2jC,Agent-based Graph Neural Networks,"['Karolis Martinkus', 'Pál András Papp', 'Benedikt Schesch', 'Roger Wattenhofer']","['~Karolis_Martinkus1', '~Pál_András_Papp1', '~Benedikt_Schesch1', '~Roger_Wattenhofer1']","['Graph Neural Networks', 'GNN', 'Graph Classification', 'Expressive Graph Neural Networks', 'Sublinear algorithms']","We present a novel graph neural network we call AgentNet, which is designed specifically for graph-level tasks. AgentNet is inspired by sublinear algorithms, featuring a computational complexity that is independent of the graph size. The architecture of AgentNet differs fundamentally from the architectures of traditional graph neural networks. In AgentNet, some trained \textit{neural agents} intelligently walk the graph, and then collectively decide on the output. We provide an extensive theoretical analysis of AgentNet: We show that the agents can learn to systematically explore their neighborhood and that AgentNet can distinguish some structures that are even indistinguishable by 2-WL. Moreover, AgentNet is able to separate any two graphs which are sufficiently different in terms of subgraphs. We confirm these theoretical results with synthetic experiments on hard-to-distinguish graphs and real-world graph classification tasks. In both cases, we compare favorably not only to standard GNNs but also to computationally more expensive GNN extensions.",https://openreview.net/pdf/a33a54dc51ae12d26281cd196933bb3be33a76f3.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=8U4joMeLRF,Rethinking Self-Supervised Visual Representation Learning in Pre-training for 3D Human Pose and Shape Estimation,"['Hongsuk Choi', 'Hyeongjin Nam', 'Taeryung Lee', 'Gyeongsik Moon', 'Kyoung Mu Lee']","['~Hongsuk_Choi1', 'namhj28@gmail.com', 'trlee94@snu.ac.kr', '~Gyeongsik_Moon1', '~Kyoung_Mu_Lee2']","['pre-training', '3D human pose and shape estimation', 'self-supervised representation learning']","Recently, a few self-supervised representation learning (SSL) methods have outperformed the ImageNet classification pre-training for vision tasks such as object detection. However, its effects on 3D human body pose and shape estimation (3DHPSE) are open to question, whose target is fixed to a unique class, the human, and has an inherent task gap with SSL. We empirically study and analyze the effects of SSL and further compare it with other pre-training alternatives for 3DHPSE. The alternatives are 2D annotation-based pre-training and synthetic data pre-training, which share the motivation of SSL that aims to reduce the labeling cost. They have been widely utilized as a source of weak-supervision or fine-tuning, but have not been remarked as a pre-training source. SSL methods underperform the conventional ImageNet classification pre-training on multiple 3DHPSE benchmarks by 7.7% on average. In contrast, despite a much less amount of pre-training data, the 2D annotation-based pre-training improves accuracy on all benchmarks and shows faster convergence during fine-tuning. Our observations challenge the naive application of the current SSL pre-training to 3DHPSE and relight the value of other data types in the pre-training aspect.",https://openreview.net/pdf/6017994942dfe60d2f4cb69be42afc4cd3675da8.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=8JsaP7j1cL0,Correlative Information Maximization Based Biologically Plausible Neural Networks for Correlated Source Separation,"['Bariscan Bozkurt', 'Ateş İsfendiyaroğlu', 'Cengiz Pehlevan', 'Alper Tunga Erdogan']","['~Bariscan_Bozkurt1', '~Ateş_İsfendiyaroğlu1', '~Cengiz_Pehlevan2', '~Alper_Tunga_Erdogan1']","['Biologically Plausible Neural Networks', 'Blind Correlated Source Separation', 'Correlative Information Maximization']","The brain effortlessly extracts latent causes of stimuli, but how it does this at the network level remains unknown. Most prior attempts at this problem proposed neural networks that implement independent component analysis, which works under the limitation that latent elements are mutually independent. Here, we relax this limitation and propose a biologically plausible neural network that extracts correlated latent sources by exploiting information about their domains. To derive this network, we choose maximum correlative information transfer from inputs to outputs as the separation objective under the constraint that the outputs are restricted to their presumed sets. The online formulation of this optimization problem naturally leads to neural networks with local learning rules. Our framework incorporates infinitely many source domain choices and flexibly models complex latent structures. Choices of simplex or polytopic source domains result in networks with piecewise-linear activation functions. We provide numerical examples to demonstrate the superior correlated source separation capability for both synthetic and natural sources.",https://openreview.net/pdf/ef092df8bb544b27c12e88fa9b2d3dd15abedb01.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=89GT-S49mGd,Function-space regularized Rényi divergences,"['Jeremiah Birrell', 'Yannis Pantazis', 'Paul Dupuis', 'Luc Rey-Bellet', 'Markos Katsoulakis']","['~Jeremiah_Birrell1', '~Yannis_Pantazis1', '~Paul_Dupuis1', '~Luc_Rey-Bellet1', '~Markos_Katsoulakis1']","['Rényi divergence', 'integral probability metrics', 'variational formulas', 'worst-case-regret']","We propose a new family of regularized Rényi divergences parametrized not only by the order $\alpha$ but also by a variational function space. These new objects are defined by taking the infimal convolution of the standard Rényi divergence with the integral probability metric (IPM) associated with the chosen function space. We derive a novel dual variational representation that can be used to construct numerically tractable divergence estimators. This representation avoids risk-sensitive terms and therefore exhibits lower variance, making it well-behaved  when $\alpha>1$; this addresses a notable weakness of prior approaches. We prove several properties of these new divergences, showing that they interpolate between the classical Rényi divergences and IPMs. We also study the $\alpha\to\infty$ limit, which leads to a regularized worst-case-regret and a new variational representation in the classical case. Moreover, we show that the proposed regularized Rényi divergences inherit features from IPMs such as the ability to compare distributions that are not absolutely continuous, e.g., empirical measures and distributions with low-dimensional support. We present numerical results on both synthetic and real datasets, showing the utility of these new divergences in both estimation and GAN training applications; in particular, we demonstrate significantly reduced variance and improved training performance.",https://openreview.net/pdf/2e551aaf5e4f3d5a15272f0f78bcaf860e9cb8bd.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=7tJyBmu9iCj,Neural-based classification rule learning for sequential data,"['Marine Collery', 'Philippe Bonnard', 'François Fages', 'Remy Kusters']","['~Marine_Collery1', 'philippe.bonnard@fr.ibm.com', 'francois.fages@inria.fr', '~Remy_Kusters1']","['classification rule learning', 'binary neural network', 'interpretable AI', 'sequential data']","Discovering interpretable patterns for classification of sequential data is of key importance for a variety of fields, ranging from genomics to fraud detection or more generally interpretable decision-making.
In this paper, we propose a novel differentiable fully interpretable method to discover both local and global patterns (i.e. catching a relative or absolute temporal dependency) for rule-based binary classification.
It consists of a convolutional binary neural network with an interpretable neural filter and a training strategy based on dynamically-enforced sparsity.
We demonstrate the validity and usefulness of the approach on synthetic datasets and on an open-source peptides dataset.
Key to this end-to-end differentiable method is that the expressive patterns used in the rules are learned alongside the rules themselves.",https://openreview.net/pdf/6ccbb01a7fbb6ea6edfc173772ccb005e84f5af1.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=7t3ggLCjl7G,When Do Models Generalize? A Perspective From Data-Algorithm Compatibility,"['Jing Xu', 'Jiaye Teng', 'Yang Yuan', 'Andrew C Yao']","['~Jing_Xu4', '~Jiaye_Teng2', '~Yang_Yuan4', '~Andrew_C_Yao1']","['generalization', 'data-algorithm compatibility', 'early stopping', 'overparameterized linear regression']","One of the major open problems in machine learning is to characterize generalization in the overparameterized regime, where most traditional generalization bounds become inconsistent (Nagarajan and Kolter, 2019). In many scenarios, their failure can be attributed to obscuring the crucial interplay between the training algorithm and the underlying data distribution. To address this issue, we propose a concept named compatibility, which quantitatively characterizes generalization in a both data-relevant and algorithm relevant manner. By considering the entire training trajectory and focusing on early-stopping iterates, compatibility exploits the data and the algorithm information and is therefore a more suitable notion for generalization. We validate this by theoretically studying compatibility under the setting of solving overparameterized linear regression with gradient descent. Specifically, we perform a data-dependent trajectory analysis and derive a sufficient condition for compatibility in such a setting. Our theoretical results demonstrate that in the sense of compatibility, generalization holds with significantly weaker restrictions on the problem instance than the previous last iterate analysis.",https://openreview.net/pdf/c5460ab3b5514c4b20509e754f3bfb2d3effc83f.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=7qyLeRm1e3,Improving Generative Flow Networks with Path Regularization,"['Anh Do', 'Duy Dinh', 'Tan Minh Nguyen', 'Nguyen Duy Khuong', 'Stanley Osher', 'Nhat Ho']","['~Anh_Do1', '~Duy_Dinh1', '~Tan_Minh_Nguyen1', '~Nguyen_Duy_Khuong1', '~Stanley_Osher1', '~Nhat_Ho1']","['generative flow networks', 'path regularization', 'optimal transport']","Generative Flow Networks (GFlowNets) are recently proposed models for learning stochastic policies that generate compositional objects by sequences of actions with the probability proportional to a given reward function. The central problem of GFlowNets is to improve their exploration and generalization. In this work, we propose a novel path regularization method based on optimal transport theory that places prior constraints on the underlying structure of the GFlowNets. The prior is designed to help the GFlowNets better discover the latent structure of the target distribution or enhance its ability to explore the environment in the context of active learning. The path regularization controls the flow in GFlowNets to generate more diverse and novel candidates via maximizing the optimal transport distances between two forward policies or to improve the generalization via minimizing the optimal transport distances. In addition, we derive an efficient implementation of the regularization by finding its closed form solutions in specific cases and a meaningful upper bound that can be used as an approximation to minimize the regularization term. We empirically demonstrate the advantage of our path regularization on a wide range of tasks, including synthetic hypergrid environment modeling, discrete probabilistic modeling, and biological sequence design.",https://openreview.net/pdf/632e0c6b9d8b29dfe716e2e1649b44f639bcefce.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=6jqSG88Mf_D,3D Neural Embedding Likelihood for Robust Sim-to-Real Transfer in Inverse Graphics,"['Guangyao Zhou', 'Nishad Gothoskar', 'Lirui Wang', 'Joshua B. Tenenbaum', 'Dan Gutfreund', 'Miguel Lazaro-Gredilla', 'Dileep George', 'Vikash Mansinghka']","['~Guangyao_Zhou1', '~Nishad_Gothoskar1', '~Lirui_Wang1', '~Joshua_B._Tenenbaum1', '~Dan_Gutfreund1', '~Miguel_Lazaro-Gredilla1', '~Dileep_George1', '~Vikash_Mansinghka1']","['3D inverse graphics', 'probabilistic inference', 'likelihood', 'RGB-D', 'neural embedding', 'object pose estimation']","A central challenge in 3D scene perception via inverse graphics is robustly modeling the gap between 3D graphics and real-world data. We propose a novel 3D Neural Embedding Likelihood (3DNEL) over RGB-D images to address this gap. 3DNEL uses neural embeddings to predict 2D-3D correspondences from RGB and combines this with depth in a principled manner. 3DNEL is trained entirely from synthetic images and generalizes to real-world data. To showcase this capability, we develop a multi-stage inverse graphics pipeline that uses 3DNEL for 6D object pose estimation from real RGB-D images. Our method outperforms the previous state-of-the-art in sim-to-real pose estimation on the YCB-Video dataset, and improves robustness, with significantly fewer large-error predictions. Unlike existing bottom-up, discriminative approaches that are specialized for pose estimation, 3DNEL adopts a probabilistic generative formulation that jointly models multi-object scenes. This generative formulation enables easy extension of 3DNEL to additional tasks like object and camera tracking from video, using principled inference in the same probabilistic model without task specific retraining.",https://openreview.net/pdf/23d64ef5b29f3a75efd042239d0494b351f11ac8.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=6f47WT-HtuH,Unfair geometries: exactly solvable data model with fairness implications,"['Stefano Sarao Mannelli', 'Federica Gerace', 'Negar Rostamzadeh', 'Luca Saglietti']","['~Stefano_Sarao_Mannelli1', '~Federica_Gerace1', '~Negar_Rostamzadeh1', '~Luca_Saglietti1']","['statistical physics', 'statistical mechanics of learning', 'generalization model', 'modelling structured data', 'data imbalance', 'bias', 'fairness', 'bias mitigation']","Machine learning (ML) may be oblivious to human bias but it is not immune to its perpetuation. Marginalisation and iniquitous group representation are often traceable in the very data used for training, and may be reflected or even enhanced by the learning models.
In the present work, we aim at clarifying the role played by data geometry in the emergence of ML bias. We introduce an exactly solvable high-dimensional model of data imbalance, where parametric control over the many bias-inducing factors allows for an extensive exploration of the bias inheritance mechanism.Through the tools of statistical physics, we analytically characterise the typical properties of learning models trained in this synthetic framework and obtain exact predictions for the observables that are commonly employed for fairness assessment.
Despite the simplicity of the data model, we retrace and unpack typical unfairness behaviour observed on real-world datasets. 
We also obtain a detailed analytical characterisation of a class of bias mitigation strategies. We first consider a basic loss-reweighing scheme, which allows for an implicit minimisation of different unfairness metrics, and quantify the incompatibilities between some existing fairness criteria. Then, we consider a novel mitigation strategy based on a matched inference approach, consisting in the introduction of coupled learning models. Our theoretical analysis of this approach shows that the coupled strategy can strike superior fairness-accuracy trade-offs.",https://openreview.net/pdf/85e02011c5684dd0587c387806bb6805d8630cb0.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=6apN9AQ-3fN,Distance VS. Coordinate: Distance Based Embedding Improves Model Generalization for Routing Problems,"['Hongsen Liao', 'Ruiyuan Wu', 'Yuyang Han', 'Yuncong Hu', 'Ke Xing', 'Jinghua Hao', 'Renqing He']","['liaohongsen@meituan.com', 'wuruiyuan@meituan.com', 'hanyuyang02@meituan.com', 'huyuncong03@meituan.com', 'xingke@meituan.com', 'haojinghua@meituan.com', 'herenqing@meituan.com']","['routing problems', 'travelling salesman problem', 'combinatorial optimization', 'pickup and delivery', 'embedding']","Routing problems, such as traveling salesman problem (TSP) and vehicle routing problem, are among the most classic research topics in combinatorial optimization and operations research (OR). In recent years, with the rapid development of online service platforms, there has been renewed interest in applying this study to facilitate emerging industrial applications, such as food delivery and logistics services. While OR methods remain the mainstream technique, increasing efforts have been put into exploiting deep learning (DL) models for tackling routing problems. The existing ML methods often consider the embedding of the route point coordinate as a key model input and are capable of delivering competing performance in synthetic or simplified settings. However, it is empirically noted that this line of work appears to lack robustness and generalization ability that are crucial for real-world applications. In this paper, we demonstrate that the coordinate can unexpectedly lead to these problems. There are two factors that make coordinate rather `poisonous' for DL models: i) the definition of distance between route points is far more complex than what coordinate can depict; ii) the coordinate can hardly be sufficiently `traversed' by the training data. To circumvent these limitations, we propose to abandon the coordinate and instead use the relative distance for route point embedding. We show in both synthetic TSP and real-world food pickup and delivery route prediction problem that our design can significantly improve model's generalization ability, and deliver competitive or better performance with existing models. ",https://openreview.net/pdf/38fe12d316a1646460d951450e7cad85c0cb8a58.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=6ZajpxqTlQ,Generalize Learned Heuristics to Solve Large-scale Vehicle Routing Problems in Real-time,"['Qingchun Hou', 'Jingwei Yang', 'Yiqiang Su', 'Xiaoqing Wang', 'Yuming Deng']","['~Qingchun_Hou1', '~Jingwei_Yang2', 'yiqiang.syq@alibaba-inc.com', '~Xiaoqing_Wang1', '~Yuming_Deng1']","['Learning', 'Vehicle Routing Problem', 'Large-scale Vehicle Routing Problem', 'Generalization', 'Combinatorial Optimization', 'Reinforcement Learning', 'Attention']","Large-scale Vehicle Routing Problems (VRPs) are widely used in logistics, transportation, supply chain, and robotic systems. Recently, data-driven VRP heuristics are proposed to generate real-time VRP solutions with up to 100 nodes. Despite this progress, current heuristics for large-scale VRPs still face three major challenges: 1) Difficulty in generalizing the heuristics learned on small-scale VRPs to large-scale VRPs without retraining; 2) Challenge in generating real-time solutions for large-scale VRPs; 3) Difficulty in embedding global constraints into learned heuristics. We contribute in the three directions: We propose a Two-stage Divide Method (TAM) to generate sub-route sequence rather than node sequence for generalizing the heuristics learned on small-scale VRPs to solve large-scale VRPs in real-time. A  two-step reinforcement learning method with new reward and padding techniques is proposed to train our TAM.  A global mask function is proposed to keep the global constraints satisfied when dividing a large-scale VRP into several small-scale Traveling Salesman Problems (TSPs). As result, we can solve the small-scale TSPs in parallel quickly. The experiments on synthetic and real-world large-scale VRPs show our method could generalize the learned heuristics trained on datasets of VRP 100 to solve VRPs with over 5000 nodes in real-time while keeping the solution quality better than data-driven heuristics and competitive with traditional heuristics.",https://openreview.net/pdf/1360725553e9aebf2b149f234ac6d83c46a077d4.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=6TugHflAGRU,Eigenvalue Initialisation and Regularisation for Koopman Autoencoders,"['Jack William Miller', ""Charles O'Neill"", 'Navid C Constantinou', 'Omri Azencot']","['~Jack_William_Miller1', ""~Charles_O'Neill2"", '~Navid_C_Constantinou1', '~Omri_Azencot1']","['koopman', 'deep learning', 'dynamical systems', 'autoencoders', 'physics-constrained learning', 'neural networks']","Regularising the parameter matrices of neural networks is ubiquitous in training deep models. Typical regularisation approaches suggest initialising weights using small random values, and to penalise weights to promote sparsity. However, these widely used techniques may be less effective in certain scenarios. Here, we study the Koopman autoencoder model which includes an encoder, a Koopman operator layer, and a decoder. These models have been designed and dedicated to tackle physics-related problems with interpretable dynamics and an ability to incorporate physics-related constraints. However, the majority of existing work employs standard regularisation practices. In our work, we take a step toward augmenting Koopman autoencoders with initialisation and penalty schemes tailored for physics-related settings. Specifically, we propose the ""eigeninit"" initialisation scheme that samples initial Koopman operators from specific eigenvalue distributions. In addition, we suggest the ""eigenloss"" penalty scheme that penalises the eigenvalues of the Koopman operator during training. We demonstrate the utility of these schemes on two synthetic data sets: a driven pendulum and flow past a cylinder; and two real-world problems: ocean surface temperatures and cyclone wind fields. We find on these datasets that eigenloss and eigeninit improves the convergence rate by a factor of 2 to 5, and that they reduce the cumulative long-term prediction error by up to a factor of 2.5. Such a finding points to the utility of incorporating similar schemes as an inductive bias in other physics-related deep learning approaches.",https://openreview.net/pdf/3e6cd9e443be11630af76bfecab1d8c524fd459e.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=6P9Y25Pljl6,FedDAR: Federated Domain-Aware Representation Learning,"['Aoxiao Zhong', 'Hao He', 'Zhaolin Ren', 'Na Li', 'Quanzheng Li']","['~Aoxiao_Zhong1', '~Hao_He1', '~Zhaolin_Ren1', '~Na_Li3', '~Quanzheng_Li1']","['federated learning', 'healthcare', 'fairness', 'personalization']","Cross-silo Federated learning (FL) has become a promising tool in machine learning applications for healthcare. It allows hospitals/institutions to train models with sufficient data while the data is kept private. To make sure the FL model is robust when facing heterogeneous data among FL clients, most efforts focus on personalizing models for clients. However, the latent relationships between clients' data are ignored. In this work, we focus on a special non-iid FL problem, called Domain-mixed FL, where each client's data distribution is assumed to be a mixture of several predefined domains.  Recognizing the diversity of domains and the similarity within domains, we propose a novel method, FedDAR, which learns a domain shared representation and domain-wise personalized prediction heads in a decoupled manner. For simplified linear regression settings, we have theoretically proved that FedDAR enjoys a linear convergence rate.  For general settings, we have performed intensive empirical studies on both synthetic and real-world medical datasets which demonstrate its superiority over prior FL methods. Our code is available at https://github.com/zlz0414/FedDAR.     ",https://openreview.net/pdf/665489145995b4ea0d25bd9c551dc68004d604e5.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=6OxI4WqGr6,Semi-Supervised Offline Reinforcement Learning with Action-Free Trajectories,"['Qinqing Zheng', 'Mikael Henaff', 'Brandon Amos', 'Aditya Grover']","['~Qinqing_Zheng1', '~Mikael_Henaff1', '~Brandon_Amos1', '~Aditya_Grover1']",[],"Natural agents can effectively learn from multiple data sources that differ in size, quality, and types of measurements. We study this heterogeneity in the context of offline reinforcement learning (RL) by introducing a new, practically motivated semi-supervised setting. Here, an agent has access to two sets of trajectories: labelled trajectories containing state, action, reward triplets at every timestep, along with unlabelled trajectories that contain only state and reward information.  For this setting, we develop a simple meta-algorithmic pipeline that learns an inverse-dynamics model on the labelled data to obtain proxy-labels for the unlabelled data, followed by the use of any offline RL algorithm on the true and proxy-labelled trajectories. Empirically, we find this simple pipeline to be highly successful --- on several D4RL benchmarks~\cite{fu2020d4rl}, certain offline RL algorithms can match the performance of variants trained on a fully labeled dataset even when we label only 10\% trajectories from the low return regime. Finally, we perform a large-scale controlled empirical study investigating the interplay of data-centric properties of the labelled and unlabelled datasets, with algorithmic design choices (e.g., inverse dynamics, offline RL algorithm) to identify general trends and best practices for training RL agents on semi-supervised offline datasets.",https://openreview.net/pdf/468e24a12a4ceda397ca5c03c35ad253af39b4c3.pdf,{'title_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=6Fq1-57gff,The World is Changing: Improving Fair Training under Correlation Shifts,"['Yuji Roh', 'Kangwook Lee', 'Steven Euijong Whang', 'Changho Suh']","['~Yuji_Roh1', '~Kangwook_Lee1', '~Steven_Euijong_Whang1', '~Changho_Suh1']","['trustworthy AI', 'fairness', 'correlation shifts']","Model fairness is an essential element for Trustworthy AI. While many techniques for model fairness have been proposed, most of them assume that the training and deployment data distributions are identical, which is often not true in practice. In particular, when the bias between labels and sensitive groups changes, the fairness of the trained model is directly influenced and can worsen. We make two contributions for solving this problem. First, we analytically show that existing in-processing fair algorithms have fundamental limits in accuracy and fairness. We introduce the notion of correlation shifts, which can explicitly capture the change of the above bias. Second, we propose a novel pre-processing step that samples the input data to reduce correlation shifts and thus enables the in-processing approaches to overcome their limitations. We formulate an optimization problem for adjusting the data ratio among labels and sensitive groups to reflect the shifted correlation. A key advantage of our approach lies in decoupling the roles of pre-processing and in-processing approaches: correlation adjustment via pre-processing and unfairness mitigation on the processed data via in-processing. Experiments show that our framework effectively improves existing in-processing fair algorithms w.r.t. accuracy and fairness, both on synthetic and real datasets.",https://openreview.net/pdf/d45d1b5f76f00c2730c516502d29dbe70c9b005b.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=5ohslQBnxUw,On the Convergence of Gradient Flow on Multi-layer Linear Models,"['Hancheng Min', 'Rene Vidal', 'Enrique Mallada']","['~Hancheng_Min1', '~Rene_Vidal1', '~Enrique_Mallada1']","['Multi-layer Linear Networks', 'Non-convex optimization', 'Gradient Flow', 'Training invariance']","In this paper, we analyze the convergence of gradient flow on a multi-layer linear model with a loss function of the form $f(W_1W_2\cdots W_L)$. We show that when $f$ satisfies the gradient dominance property, proper weight initialization leads to exponential convergence of the gradient flow to a global minimum of the loss. Moreover, the convergence rate depends on two trajectory-specific quantities that are controlled by the weight initialization: the \emph{imbalance matrices}, which measure the difference between the weights of adjacent layers, and the least singular value of the \emph{weight product} $W=W_1W_2\cdots W_L$. Our analysis provides improved rate bounds for several multi-layer network models studied in the literature, leading to novel characterizations of the effect of weight imbalance on the rate of convergence. Our results apply to most regression losses and extend to classification ones.",https://openreview.net/pdf/9af3591b25e63987502cada12e3331cac6c72277.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=5lgD4vU-l24s,Recursive Time Series Data Augmentation,"['Amine Mohamed Aboussalah', 'Minjae Kwon', 'Raj G Patel', 'Cheng Chi', 'Chi-Guhn Lee']","['~Amine_Mohamed_Aboussalah1', '~Minjae_Kwon1', '~Raj_G_Patel1', '~Cheng_Chi3', '~Chi-Guhn_Lee1']","['Time Series', 'Data augmentation', 'Representation Learning', 'Deep Learning', 'Reinforcement Learning']","Time series observations can be seen as realizations of an underlying dynamical system governed by rules that we typically do not know. For time series learning tasks we create our model using available data. Training on available realizations, where data is limited, often induces severe over-fitting thereby preventing generalization. To address this issue, we introduce a general recursive framework for time series augmentation, which we call the Recursive Interpolation Method (RIM). New augmented time series are generated using a recursive interpolation function from the original time series for use in training. We perform theoretical analysis to characterize the proposed RIM and to guarantee its performance under certain conditions. We apply RIM to diverse synthetic and real-world time series cases to achieve strong performance over non-augmented data on a variety of learning tasks. Our method is also computationally more efficient and leads to better performance when compared to state of the art time series data augmentation.
",https://openreview.net/pdf/59b64e2daa15ab42b1105a5c3ae7a533e5612b26.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=5cAI0qXxyv,$\mathscr{N}$-WL: A New Hierarchy of Expressivity for Graph Neural Networks,"['Qing Wang', 'Dillon Ze Chen', 'Asiri Wijesinghe', 'Shouheng Li', 'Muhammad Farhan']","['~Qing_Wang14', '~Dillon_Ze_Chen1', '~Asiri_Wijesinghe1', '~Shouheng_Li1', 'muhammad.farhan@anu.edu.au']","['Graph neural network', 'Weisfeiler-Lehman algorithm', 'k-WL hierarchy', 'graph classification']","The expressive power of Graph Neural Networks (GNNs) is fundamental for understanding their capabilities and  limitations, i.e., what graph properties can or cannot be learnt by a GNN. Since standard GNNs have been characterised to be upper-bounded by the Weisfeiler-Lehman (1-WL) algorithm, recent attempts concentrated on developing more expressive GNNs in terms of the $k$-WL hierarchy, a well-established framework for graph isormorphism tests. In this work we show that, contrary to the widely accepted view, the $k$-WL hierarchy is not well-suited for measuring expressive GNNs. This is due to limitations that are inherent to high-dimensional WL algorithms such as the lack of a natural interpretation and high computational costs, which makes it difficult to draw any firm conclusions about the expressive power of GNNs beyond 1-WL. Thus, we propose a novel hierarchy of graph isomorphism tests, namely Neighbourhood WL ($\mathscr{N}$-WL), and also establish a new theorem on the equivalence of expressivity between induced connected subgraphs and induced subgraphs within this hierarchy. Further, we design a GNN model upon $\mathscr{N}$-WL, Graph Neighbourhood Neural Network (G3N), and empirically verify its expressive power on synthetic and real-world benchmarks.",https://openreview.net/pdf/a1b6ae5c041645625de45e46ad10cdde373f930c.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=5ZLWi--i57,BQ-NCO: Bisimulation Quotienting for Generalizable Neural Combinatorial Optimization,"['Darko Drakulic', 'Sofia Michel', 'Florian Mai', 'Arnaud Sors', 'Jean-Marc Andreoli']","['~Darko_Drakulic1', '~Sofia_Michel1', '~Florian_Mai1', '~Arnaud_Sors1', '~Jean-Marc_Andreoli2']",[],"Despite the success of Neural Combinatorial Optimization methods for end-to-end heuristic learning, out-of-distribution generalization remains a challenge. 
In this paper, we present a novel formulation of combinatorial optimization (CO) problems as Markov Decision Processes (MDPs) that effectively leverages symmetries of the CO problems to improve out-of-distribution robustness. 
Starting from the standard MDP formulation of constructive heuristics, we introduce a generic transformation based on bisimulation quotienting (BQ) in MDPs. 
This transformation allows to reduce the state space by accounting for the intrinsic symmetries of the CO problem and facilitates the MDP solving.
We illustrate our approach on the Traveling Salesman and Capacitated Vehicle Routing Problems. We present a BQ reformulation of these problems and introduce a simple attention-based policy network that we train by imitation of (near) optimal solutions for small instances from a single distribution. 
We obtain new state-of-the-art generalization results for instances with up to 1000 nodes from synthetic and realistic benchmarks that vary both in size and node distributions.",https://openreview.net/pdf/9e5664814062cee41ae9b1f9912e810124d98970.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=5Z1rblK1Be5,A Risk-Averse Equilibrium for Multi-Agent Systems,"['Oliver Slumbers', 'David Henry Mguni', 'Stephen Marcus McAleer', 'Jun Wang', 'Yaodong Yang']","['~Oliver_Slumbers1', '~David_Henry_Mguni1', '~Stephen_Marcus_McAleer1', '~Jun_Wang2', '~Yaodong_Yang1']","['game theory', 'safe game theory', 'risk averse game theory', 'safe equilibrium', 'population learning', 'game theory equilibrium']","In multi-agent systems, intelligent agents are tasked with making decisions that lead to optimal outcomes when actions of the other agents are as expected, whilst also being prepared for their unexpected behaviour. In this work, we introduce a novel risk-averse solution concept that allows the learner to accommodate low probability actions by finding the strategy with minimum variance, given any level of expected utility. We first prove the existence of such a risk-averse equilibrium, and propose one fictitious-play type learning algorithm for smaller games that enjoys provable convergence guarantees in games classes including zero-sum and potential. Furthermore, we propose an approximation method for larger games based on iterative population-based training that generates a population of risk- averse agents. Empirically, our equilibrium is shown to be able to reduce the utility variance, specifically in the sense that other agents’ low probability behaviour is better accounted for by our equilibrium in comparison to playing other solutions. Importantly, we show that our population of agents that approximate a risk-averse equilibrium is particularly effective against unseen opposing populations, especially in the case of guaranteeing a minimum level of performance, which is critical to safety-aware multi-agent systems.",https://openreview.net/pdf/284654ccfdebb570fb3b07841cb59de942740f1f.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=5R96mIU85IW,Effectively using  public data in privacy preserving Machine learning,"['Milad Nasr', 'Saeed Mahloujifar', 'Xinyu Tang', 'Prateek Mittal', 'Amir Houmansadr']","['~Milad_Nasr2', '~Saeed_Mahloujifar1', '~Xinyu_Tang1', '~Prateek_Mittal1', '~Amir_Houmansadr1']","['Privacy preserving machine learning', 'dp-sgd', 'public data in privacy']","A key challenge towards differentially private machine learning is balancing the trade-off between privacy and utility. 
A recent line of work has demonstrated that leveraging  \emph{public data samples} can enhance the utility of DP-trained models (for the same privacy guarantees). 
In this work, we show that public data can be used to improve utility in DP models significantly more than shown in recent works.  
Towards this end, we introduce a modified DP-SGD algorithm that leverages public data during its training process. 
Our technique uses public data in two complementary ways: (1) it uses generative models trained on public data to produce synthetic data that is effectively embedded in multiple steps of the training pipeline; (2) it uses a new gradient clipping mechanism  (required for achieving differential privacy) which changes the \emph{origin} of gradient vectors using information inferred from available public and synthesized data. 
Our experimental results demonstrate the effectiveness of our approach in improving the state-of-the-art in differentially private machine learning across multiple datasets, network architectures, and application domains. 
Notably, we achieve a $75\%$ accuracy on CIFAR10  when using only $2,000$ public images;  this is \emph{significantly higher} than the  state-of-the-art which is $68\%$  for DP-SGD with the privacy budget of $\varepsilon=2,\delta=10^{-5}$ (given the same number of public data points).",https://openreview.net/pdf/7be872a1a9b55b33468b92dc0615aa3fd4e13f4b.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=5O2uzDusEN5,DFlow: Learning to Synthesize Better Optical Flow Datasets via a Differentiable Pipeline,"['Kwon Byung-Ki', 'Nam Hyeon-Woo', 'Ji-Yun Kim', 'Tae-Hyun Oh']","['~Kwon_Byung-Ki1', '~Nam_Hyeon-Woo1', '~Ji-Yun_Kim1', '~Tae-Hyun_Oh3']","['Synthetic data', 'Optical flow']","Comprehensive studies of synthetic optical flow datasets have attempted to reveal what properties lead to accuracy improvement in learning-based optical flow estimation. However, manually identifying and verifying the properties that contribute to accurate optical flow estimation require large-scale trial-and-error experiments with iteratively generating whole synthetic datasets and training on them, \ie, impractical. To address this challenge, we propose a differentiable optical flow data generation pipeline and a loss function to drive the pipeline, called DFlow. DFlow efficiently synthesizes a dataset effective for a target domain without the need for cumbersome try-and-errors.  This favorable property is achieved by proposing an efficient dataset comparison method that uses neural networks to approximately encode each dataset and compares the proxy networks instead of explicitly comparing datasets in a pairwise way. Our experiments show the competitive performance of our DFlow against the prior arts in pre-training. Furthermore, compared to competing datasets, DFlow achieves the best fine-tuning performance on the Sintel public benchmark with RAFT.",https://openreview.net/pdf/0ef1c24f1cf3ba80131634c7b890f2eb921fef95.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=5Jq1ASp33L,Understanding Incremental Learning of Gradient Descent: A Fine-grained analysis of Matrix Sensing,"['Jikai Jin', 'Zhiyuan Li', 'Kaifeng Lyu', 'Simon Shaolei Du', 'Jason D. Lee']","['~Jikai_Jin1', '~Zhiyuan_Li2', '~Kaifeng_Lyu2', '~Simon_Shaolei_Du1', '~Jason_D._Lee1']","['deep learning theory', 'incremental learning', 'non-convex optimization']","The implicit bias of optimization algorithms such as gradient descent (GD) is believed to play an important role in generalization of modern machine learning methods such as deep learning. This paper provides a fine-grained analysis of the dynamics of GD for the matrix sensing problem, whose goal is to recover a low-rank ground-truth matrix from near-isotropic linear measurements. With small initialization, we that GD behaves similarly to the greedy low-rank learning heuristics~\citep{li2020towards} and follows an incremental learning procedure~\citep{gissin2019implicit}. That is, GD sequentially learns solutions with increasing ranks until it recovers the ground-truth matrix. Compared to existing works which only analyze the first learning phase for rank-1 solutions, our result is stronger because it characterizes the whole learning process. Moreover, our analysis of the incremental learning procedure applies to the
under-parameterized regime as well. As a key ingredient of our analysis, we observe that GD always follows an approximately low-rank trajectory and develops novel landscape properties for matrix sensing with low-rank parameterization. Finally, we conduct numerical experiments which confirm our theoretical findings.",https://openreview.net/pdf/2cce058d1de5c68cf20d3d81301d21dce920e1fc.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=5HLoTvVGDe,Dual Diffusion Implicit Bridges for Image-to-Image Translation,"['Xuan Su', 'Jiaming Song', 'Chenlin Meng', 'Stefano Ermon']","['~Xuan_Su1', '~Jiaming_Song1', '~Chenlin_Meng1', '~Stefano_Ermon1']",[],"Common image-to-image translation methods rely on joint training over data from both source and target domains. The training process requires concurrent access to both datasets, which hinders data separation and privacy protection; and existing models cannot be easily adapted for translation of new domain pairs. We present Dual Diffusion Implicit Bridges (DDIBs), an image translation method based on diffusion models, that circumvents training on domain pairs. Image translation with DDIBs relies on two diffusion models trained independently on each domain, and is a two-step process: DDIBs first obtain latent encodings for source images with the source diffusion model, and then decode such encodings using the target model to construct target images. Both steps are defined via ordinary differential equations (ODEs), thus the process is cycle consistent only up to discretization errors of the ODE solvers. Theoretically, we interpret DDIBs as concatenation of source to latent, and latent to target Schrodinger Bridges, a form of entropy-regularized optimal transport, to explain the efficacy of the method. Experimentally, we apply DDIBs on synthetic and high-resolution image datasets, to demonstrate their utility in a wide variety of translation tasks and their inherent optimal transport properties.",https://openreview.net/pdf/91f1c96de0279c81fb44166262ba54d69daf0fe4.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=5FqeE2SojJi,Proportional Amplitude Spectrum Training Augmentation for Synthetic-to-Real Domain Generalization,"['Prithvijit Chattopadhyay', 'Kartik Sarangmath', 'Vivek Vijaykumar', 'Judy Hoffman']","['~Prithvijit_Chattopadhyay1', '~Kartik_Sarangmath1', '~Vivek_Vijaykumar1', '~Judy_Hoffman1']","['Synthetic-to-Real Generalization', 'Fourier Space Augmentation', 'Single Domain Generalization']","Synthetic data offers the promise of cheap and bountiful training data for settings where lots of labeled real-world data for some task is unavailable. However, models trained on synthetic data significantly underperform on real-world data. In this paper, we propose Proportional Amplitude Spectrum Training Augmentation (PASTA), a simple and effective augmentation strategy to improve out-of-the-box synthetic-to-real (syn-to-real) generalization performance. PASTA involves perturbing the amplitude spectrums of the synthetic images in the Fourier domain to generate augmented views. We design PASTA to perturb the amplitude spectrums in a structured manner such that high-frequency components are perturbed relatively more than the low-frequency ones. For the tasks of semantic segmentation (GTAV→Real), object detection (Sim10K→Real), and object recognition (VisDAC Syn→Real), across a total of 5 syn-to-real shifts, we find that PASTA  either outperforms or is consistently competitive with more complex state-of-the-art methods while being complementary to other generalization approaches.",https://openreview.net/pdf/ea0a4357b3615f0b7f01aadea9d0fcba72677b7e.pdf,{'title_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=5Egggz1q575,Explaining RL Decisions with Trajectories,"['Shripad Vilasrao Deshmukh', 'Arpan Dasgupta', 'Balaji Krishnamurthy', 'Nan Jiang', 'Chirag Agarwal', 'Georgios Theocharous', 'Jayakumar Subramanian']","['~Shripad_Vilasrao_Deshmukh2', 'arpan.dasgupta@research.iiit.ac.in', '~Balaji_Krishnamurthy1', '~Nan_Jiang2', '~Chirag_Agarwal1', '~Georgios_Theocharous1', '~Jayakumar_Subramanian1']","['Explainable RL', 'Explainable AI', 'Offline Reinforcement Learning', 'Trajectory Attribution', 'Decision-Aware AI']","Explanation is a key component for the adoption of reinforcement learning (RL) in many real-world decision-making problems. In the literature,  the explanation is often provided by saliency attribution to the features of the RL agent's state. In this work, we propose a complementary approach to these explanations, particularly for offline RL, where we attribute the policy decisions of a trained RL agent to the trajectories encountered by it during training. To do so, we encode trajectories in offline training data individually as well as collectively (encoding a set of trajectories). We then attribute policy decisions to a set of trajectories in this encoded space by estimating the sensitivity of the decision with respect to that set.  Further, we demonstrate the effectiveness of the proposed approach in terms of quality of attributions as well as practical scalability in diverse environments that involve both discrete and continuous state and action spaces such as grid-worlds, video games (Atari) and continuous control (MuJoCo). We also conduct a human study on a simple navigation task to observe how their understanding of the task compares with data attributed for a trained RL policy.",https://openreview.net/pdf/8c14263279e4c45dd0a74d7e52a0c6d707338882.pdf,{'title_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=54F8woU8vhq,Context and History Aware Other-Shaping,"['Akbir Khan', 'Newton Kwan', 'Timon Willi', 'Chris Lu', 'Andrea Tacchetti', 'Jakob Nicolaus Foerster']","['~Akbir_Khan1', '~Newton_Kwan1', '~Timon_Willi1', '~Chris_Lu1', '~Andrea_Tacchetti1', '~Jakob_Nicolaus_Foerster1']","['Shaping', 'Multi-Agent', 'Reinforcement Learning', 'Meta Reinforcement Learning']","Cooperation failures, in which self-interested agents converge to collectively worst-case outcomes, are a common failure mode of Multi-Agent Reinforcement Learning (MARL) methods. Methods such as Model-Free Opponent Shaping (MFOS) and The Good Shepherd address this issue by shaping their co-player’s learning into mutual cooperation. However, these methods fail to capture important co-player learning dynamics or do not scale to co-players parameterised by deep neural networks. To address these issues, we propose Context and History Aware Other-Shaping (CHAOS). A CHAOS agent is a meta-learner parameterised by a recurrent neural network that learns to shape its co-player over multiple trials. CHAOS considers both the context (inter-episode information), and history (intra-episode information) to shape co-players successfully. CHAOS also successfully scales to shaping co-players parameterised by deep neural networks. In a set of experiments, we show that CHAOS achieves state-of-the-art shaping in matrix games. We provide extensive ablations, motivating the importance of both context and history. CHAOS also successfully shapes on a complex grid-worldbased game, demonstrating CHAOS’s scalability empirically. Finally, we provide empirical evidence that, counterintuitively, the widely-used Coin Game environment does not require history to learn shaping because states are often indicative of past actions. This suggests that the Coin Game is, in contrast to common understanding, unsuitable for investigating shaping in high-dimensional, multi-step environments.",https://openreview.net/pdf/f9eac9c1c3d3e044031b8e259b0aef0f785280e6.pdf,{'abstract_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=53T6FlFulCV,SoundCount: Sound Counting from Raw Audio with Dyadic Decomposition Neural Network,"['Yuhang He', 'Zhuangzhuang Dai', 'Niki Trigoni', 'Andrew Markham']","['~Yuhang_He3', '~Zhuangzhuang_Dai1', '~Niki_Trigoni1', '~Andrew_Markham2']","['Sound Crowd Count', 'Dyadic Decomposition Network', 'Learnable Filters', 'Acoustic Crowd Counting']","In this paper, we study an underexplored, yet important and challenging problem: counting the number of distinct sound events in data characterized by a high degree of polyphonicity and spectral overlap. A key example is counting individual bird calls in bioacoustic data, from which biodiversity can be estimated. We do so by systematically proposing a novel end-to-end trainable neural network, designing new evaluation protocols, quantifying the difficulty of counting depending on sound polyphonicity, and creating a new dataset tailored for concurrent sound event counting. Unlike existing methods that all apply frequency-selective filters on the raw waveform in a one-stage manner, our neural network progressively decomposes the raw waveform dyadically in frequency domain. Taking inspiration from wavelet decomposition, intermediate waveforms convolved by a parent filter are successively processed by a pair of children filters that evenly split the parent filter's carried frequency response. An energy gain normalization module is introduced to normalize received sound events' loudness variance and spectrum overlap. The network is fully convolutional and parameter-frugal so it is light-weight and computationally efficient. We further design a set of polyphony-aware metrics to quantify sound counting difficulty level from different perspectives. To show the efficiency and generalization of our method (we call DyDecNet), we do experiments on both bioacoustic bird sound (both synthetic and real-world sound), telephone-ring sound and music sound data. Comprehensive experiment results show our method outperforms existing sound event detection (SED) methods significantly. The dyadic decomposition front-end network can be used by existing methods to improve their performance accordingly.",https://openreview.net/pdf/0780a4e6c458c1373c635f988f2ca4fc8a91a4ea.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=4vfv4GDG6G,Agent Prioritization with Interpretable Relation for Trajectory Prediction,"['Manh Huynh', 'Hengbo Ma', 'Gita Alaghband', 'Chiho Choi']","['~Manh_Huynh1', '~Hengbo_Ma1', '~Gita_Alaghband1', '~Chiho_Choi2']",[],"In this paper, we present a novel multi-agent trajectory prediction model, which discovers interpretable relations among agents and prioritize agent's motion. Different from existing approaches, our interpretable design is inspired by the fundamental navigation and motion functions of agent movements, which represent 'where' and 'how' the agents move in the scenes. Specifically, it generates the relation matrix, where each element indicates the motion impact from one to another. In addition, in highly interactive scenarios, one agent may implicitly gain higher priority to move, while the motion of other agents may be impacted by the prioritized agents with higher priority (e.g., a vehicle stopping or reducing its speed due to crossing pedestrians). Based on this intuition, we design a novel motion prioritization module to learn the agent motion priorities based on the inferred relation matrix. Then, a decoder is proposed to sequentially predict and iteratively update the future trajectories of each agent based on their priority orders and the learned relation structures. We first demonstrate the effectiveness of our prediction model on simulated Charged Particles dataset. Next, extensive evaluations are performed on commonly-used datasets for robot navigation, human-robot interactions, and autonomous agents: real-world NBA basketball and INTERACTION. Finally, we  show that the proposed model outperforms other state-of-the-art relation based methods, and is capable to infer interpretable, meaningful relations among agents.",https://openreview.net/pdf/6d44363cfb7955228633941af81203887b9786a6.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=4UldFtZ_CVF,Joint Edge-Model Sparse Learning is Provably Efficient for Graph Neural Networks,"['Shuai Zhang', 'Meng Wang', 'Pin-Yu Chen', 'Sijia Liu', 'Songtao Lu', 'Miao Liu']","['~Shuai_Zhang6', '~Meng_Wang4', '~Pin-Yu_Chen1', '~Sijia_Liu1', '~Songtao_Lu1', '~Miao_Liu1']","['Learning theory', 'Graph neural networks', 'Generalization analysis', 'Graph sparisification']","Due to the significant computational challenge of training large-scale graph neural networks (GNNs), various sparse learning techniques have been exploited to reduce memory and storage costs. Examples include graph sparsification that samples a subgraph to reduce the amount of data aggregation and model sparsification that prunes the neural network to reduce the number of trainable weights. Despite the empirical successes in reducing the training cost while maintaining the test accuracy, the theoretical generalization analysis of sparse learning for GNNs remains elusive. To the best of our knowledge, this paper provides the first theoretical characterization of joint edge-model sparse learning from the perspective of sample complexity and convergence rate in achieving zero generalization error. It proves analytically that both sampling important nodes and pruning neurons with lowest-magnitude can reduce the sample complexity and improve convergence without compromising the test accuracy. Although the analysis is centered on two-layer GNNs with structural constraints on data, the insights are applicable to more general setups and justified by both synthetic and practical citation datasets.",https://openreview.net/pdf/00006f5bb32f82b464f8ded7c219a7fd58ebfe86.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=49N06mWPFUm,Provably Efficient Reinforcement Learning for Online Adaptive Influence Maximization,"['Kaixuan Huang', 'Yu Wu', 'Xuezhou Zhang', 'Shenyinying Tu', 'Qingyun Wu', 'Mengdi Wang', 'Huazheng Wang']","['~Kaixuan_Huang1', '~Yu_Wu6', '~Xuezhou_Zhang2', '~Shenyinying_Tu1', '~Qingyun_Wu2', '~Mengdi_Wang1', '~Huazheng_Wang1']","['influence maximization', 'reinforcement learning']","Online influence maximization aims to maximize the influence spread of a content in a social network with an unknown network model by selecting a few seed nodes. Recent studies followed a non-adaptive setting, where the seed nodes are selected before the start of the diffusion process and network parameters are updated when the diffusion stops. We consider an adaptive version of content-dependent online influence maximization problem where the seed nodes are sequentially activated based on real-time feedback. In this paper, we formulate the problem as an infinite-horizon discounted MDP under a linear diffusion process and present a model-based reinforcement learning solution. Our algorithm maintains a network model estimate and selects seed users adaptively, exploring the social network while improving the optimal policy optimistically. We establish $\widetilde O(\sqrt{T})$ regret bound for our algorithm. Empirical evaluations on synthetic and real-world networks demonstrate the efficiency of our algorithm. ",https://openreview.net/pdf/4ccd0d9620c0b958caf094a1cb6a8f4d849310c6.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=3z1Ws6GEYV4,Multi-Objective GFlowNets,"['Moksh Jain', 'Sharath Chandra Raparthy', 'Alex Hernández-García', 'Jarrid Rector-Brooks', 'Yoshua Bengio', 'Santiago Miret', 'Emmanuel Bengio']","['~Moksh_Jain1', '~Sharath_Chandra_Raparthy3', '~Alex_Hernández-García1', '~Jarrid_Rector-Brooks2', '~Yoshua_Bengio1', '~Santiago_Miret1', '~Emmanuel_Bengio1']","['generative flow networks', 'multi-objective optimization', 'drug discovery', 'material design']","In many applications of machine learning, like drug discovery and material design, the goal is to generate candidates that simultaneously maximize a set of objectives. As these objectives are often conflicting, there is no single candidate that simultaneously maximizes all objectives, but rather a set of Pareto-optimal candidates where one objective cannot be improved without worsening another. Moreover, these objectives, when considered in practice are often under-specified, making diversity of candidates a key consideration. The existing multi-objective optimization methods focus predominantly on covering the Pareto front, failing the capture diversity in the space of candidates. Motivated by the success of GFlowNets for generation of diverse candidates in a single objective setting, in this paper we consider Multi-Objective GFlowNets (MOGFNs). MOGFNs consist of a Conditional GFlowNet which models a family of single-objective sub-problems derived by decomposing the multi-objective optimization problem. Our work is the first to empirically demonstrate conditional GFlowNets. Through a series of experiments on synthetic tasks and real-world domains, we empirically demonstrate that MOGFNs outperform existing methods in terms of Hypervolume, R2-distance and candidate diversity. We also demonstrate the effectiveness of MOGFNs over existing methods in active learning settings. Finally, we supplement our empirical results with a careful analysis of each component of MOGFNs.",https://openreview.net/pdf/24b42af86ed06105d5360735d44b9cbba4395cf0.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=3ZHX6_Mydd7,Invariant Aggregator for Defending against Federated Backdoor Attacks,"['Xiaoyang Wang', 'Dimitrios Dimitriadis', 'Oluwasanmi O Koyejo', 'Shruti Tople']","['~Xiaoyang_Wang6', '~Dimitrios_Dimitriadis1', '~Oluwasanmi_O_Koyejo1', '~Shruti_Tople2']","['Federated learning', 'robustness', 'backdoor attack', 'invariant learning']","Federated learning is gaining popularity as it enables training of high-utility models across several clients without directly sharing their private data. As a downside, the federated setting makes the model vulnerable to various adversarial attacks in the presence of malicious clients. Specifically, an adversary can perform backdoor attacks to control model predictions via poisoning the training dataset with a trigger. In this work, we propose a mitigation for backdoor attacks in a federated learning setup. Our solution forces the model optimization trajectory to focus on the invariant directions that are generally useful for utility and avoid selecting directions that favor few and possibly malicious clients. Concretely, we consider the sign consistency of the pseudo-gradient (the client update) as an estimation of the invariance. Following this, our approach performs dimension-wise filtering to remove pseudo-gradient elements with low sign consistency. Then, a robust mean estimator eliminates outliers among the remaining dimensions. Our theoretical analysis further shows the necessity of the defense combination and illustrates how our proposed solution defends the federated learning model. Empirical results on three datasets with different modalities and varying number of clients show that our approach mitigates backdoor attacks with a negligible cost on the model utility.
",https://openreview.net/pdf/7d276a3d040fd17084877f013dc787c461fdeb85.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=3OaBBATwsvP,Generative Modeling Helps Weak Supervision (and Vice Versa),"['Benedikt Boecking', 'Nicholas Roberts', 'Willie Neiswanger', 'Stefano Ermon', 'Frederic Sala', 'Artur Dubrawski']","['~Benedikt_Boecking1', '~Nicholas_Roberts2', '~Willie_Neiswanger2', '~Stefano_Ermon1', '~Frederic_Sala1', '~Artur_Dubrawski2']","['generative model', 'weak supervision']","Many promising applications of supervised machine learning face hurdles in the acquisition of labeled data in sufficient quantity and quality, creating an expensive bottleneck. To overcome such limitations, techniques that do not depend on ground truth labels have been studied, including weak supervision and generative modeling. While these techniques would seem to be usable in concert, improving one another, how to build an interface between them is not well-understood. In this work, we propose a model fusing programmatic weak supervision and generative adversarial networks and provide theoretical justification motivating this fusion. The proposed approach captures discrete latent variables in the data alongside the weak supervision derived label estimate. Alignment of the two allows for better modeling of sample-dependent accuracies of the weak supervision sources, improving the estimate of unobserved labels. It is the first approach to enable data augmentation through weakly supervised synthetic images and pseudolabels. Additionally, its learned latent variables can be inspected qualitatively. The model outperforms baseline weak supervision label models on a number of multiclass image classification datasets, improves the quality of generated images, and further improves end-model performance through data augmentation with synthetic samples.",https://openreview.net/pdf/bb17eb04238e75fcb4c9ceee6174d6c2e0d19afd.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=2vmGv5wPDBZ,Learning to Estimate Single-View Volumetric Flow Motions without 3D Supervision,"['Aleksandra Franz', 'Barbara Solenthaler', 'Nils Thuerey']","['~Aleksandra_Franz1', '~Barbara_Solenthaler1', '~Nils_Thuerey1']",[],"We address the challenging problem of jointly inferring the 3D flow and volumetric densities moving in a fluid from a monocular input video with a deep neural network. Despite the complexity of this task, we show that it is possible to train the corresponding networks without requiring any 3D ground truth for training. In the absence of ground truth data we can train our model with observations from real-world capture setups instead of relying on synthetic reconstructions. We make this unsupervised training approach possible by first generating an initial prototype volume which is then moved and transported over time without the need for volumetric supervision. Our approach relies purely on image-based losses, an adversarial discriminator network, and regularization. Our method can estimate long-term sequences in a stable manner, while achieving closely matching targets for inputs such as rising smoke plumes.",https://openreview.net/pdf/3c22f015a738c086993a46935c708a6a13671b83.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=2nocgE1m0A,KnowDA: All-in-One Knowledge Mixture Model for Data Augmentation in Low-Resource NLP,"['Yufei Wang', 'Jiayi Zheng', 'Can Xu', 'Xiubo Geng', 'Tao Shen', 'Chongyang Tao', 'Daxin Jiang']","['~Yufei_Wang7', '~Jiayi_Zheng1', '~Can_Xu2', '~Xiubo_Geng2', '~Tao_Shen1', '~Chongyang_Tao1', '~Daxin_Jiang2']","['Data Augmentation', 'Low-Resource NLP']","This paper focuses on data augmentation for low-resource NLP tasks where the training set is limited. The existing solutions either leverage task-independent heuristic rules (e.g., Synonym Replacement) or fine-tune general-purpose pre-trained language models (e.g., GPT2) using the limited training instances to produce new synthetic data. Consequently, they have trivial task-specific knowledge and are limited to yielding low-quality synthetic data. To combat this issue, we propose Knowledge Mixture Data Augmentation Model (KnowDA), a Seq2Seq language model pretrained on a mixture of diverse NLP tasks under a novel framework of Knowledge Mixture Training (KoMT). The goal of KoMT is to condense diverse NLP task-specific knowledge into the single KnowDA model
(i.e., all-in-one). The resulting KnowDA could utilize these knowledge to quickly grasp the inherent synthesis law of the target task through limited training instances. Specifically, KoMT reformulates input examples from various heterogeneous NLP tasks into a unified text-to-text format and employs denoising training objectives in different granularity to learn to reconstruct partial or complete samples. To the best of our knowledge, we are the first to attempt to apply 100+ NLP multi-task training for data augmentation. Extensive experiments show that i) the synthetic data produced by KnowDA successfully improves the performance of the strong pre-trained language
models (i.e., Bert, ALBert and Deberta) by a large margin on the low-resource NLP benchmark FewGLUE, CoNLL’03 and WikiAnn; ii) KnowDA successful transfer the task knowledge to NLP tasks whose types are seen and unseen in KoMT.",https://openreview.net/pdf/92d40698b0d55d0fbb40c50c4921bf1bb8cd40aa.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=2aSj08z30A1,ReaKE: Contrastive Molecular Representation Learning with Chemical Synthetic Knowledge Graph,"['Yi Wang', 'Shuangjia Zheng', 'Jiahua Rao', 'Yunan Luo', 'Yuedong Yang']","['~Yi_Wang30', '~Shuangjia_Zheng2', '~Jiahua_Rao1', '~Yunan_Luo1', '~Yuedong_Yang1']",[],"Molecular representation learning has demonstrated great promise in bridging machine learning and chemical science and in supporting novel chemical discoveries. State-of-the-art methods mostly employ graph neural networks (GNNs) with self-supervised learning (SSL) and extra chemical reaction knowledge to empower the learned embeddings. However, prior works ignore three major issues in modeling reaction data, that is abnormal energy flow, ambiguous embeddings, and sparse embedding space problems. To address these problems, we propose ReaKE, a chemical synthetic knowledge graph-driven pre-training framework for molecular representation learning. We first construct a large-scale chemical synthetic knowledge graph comprising reactants, products and reaction rules. We then propose triplet-level and graph-level contrastive learning strategies to jointly optimize the knowledge graph and molecular embeddings. Representations learned by ReaKE can capture intermolecular relationships reflected in the semantic knowledge graph and molecular structures. By comparing with other state-of-the-art methods, we show that ReaKE can achieve competitive performance on the reaction prediction pretext task and the learned representations transfer well to various downstream tasks, including reaction classification, yield prediction, and molecule property prediction. Further visualization shows that the learned representations can capture the fine-grained differences both between reactions and between molecules.",https://openreview.net/pdf/14c668c88ed13d87eeaefce9cbd4e52684100ecd.pdf,{'title_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=20GtJ6hIaPA,Self-Supervised Category-Level Articulated Object Pose Estimation with Part-Level SE(3) Equivariance,"['Xueyi Liu', 'Ji Zhang', 'Ruizhen Hu', 'Haibin Huang', 'He Wang', 'Li Yi']","['~Xueyi_Liu1', '~Ji_Zhang6', '~Ruizhen_Hu1', '~Haibin_Huang1', '~He_Wang5', '~Li_Yi2']",[],"Category-level articulated object pose estimation aims to estimate a hierarchy of articulation-aware object poses of an unseen articulated object from a known category. To reduce the heavy annotations needed for supervised learning methods, we present a novel self-supervised strategy that solves this problem without any human labels. Our key idea is to factorize canonical shapes and articulated object poses from input articulated shapes through part-level equivariant shape analysis. Specifically, we first introduce the concept of part-level SE(3) equivariance and devise a network to learn features of such property. Then, through a carefully designed fine-grained pose-shape disentanglement strategy, we expect that canonical spaces to support pose estimation could be induced automatically. Thus, we could further predict articulated object poses as per-part rigid transformations describing how parts transform from their canonical part spaces to the camera space. Extensive experiments demonstrate the effectiveness of our method on both complete and partial point clouds from synthetic and real articulated object datasets.",https://openreview.net/pdf/58588985182b7adae53071aa8b2da82ff6db8141.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=1mU6ADbjk-c,Neural Frailty Machine: Beyond proportional hazard assumption in neural survival regressions,"['Jiawei Qiao', 'Ruofan Wu', 'Mingzhe Wu', 'Wen Yu', 'Ming Zheng', 'Tengfei LIU', 'Tianyi Zhang', 'Weiqiang Wang']","['~Jiawei_Qiao1', '~Ruofan_Wu1', '~Mingzhe_Wu1', '~Wen_Yu1', 'mingzheng@fudan.edu.cn', '~Tengfei_LIU2', '~Tianyi_Zhang5', '~Weiqiang_Wang4']","['survival analysis', 'sieve method', 'theory']","We present neural frailty machine (NFM), a powerful and flexible neural modeling framework for survival regressions. The NFM framework utilizes the classical idea of multiplicative frailty in survival analysis to capture unobserved heterogeneity among individuals, at the same time being able to leverage the strong approximation power of neural architectures for handling nonlinear covariate dependence. Two concrete models are derived under the framework that extends neural proportional hazard models and nonparametric hazard regression models. Both models allow efficient training under the likelihood objective. Theoretically, for both proposed models, we establish statistical guarantees of neural function approximation with respect to nonparametric components via characterizing their rate of convergence. Empirically, we provide synthetic experiments that verify our theoretical statements. We also conduct experimental evaluations over 6 benchmark datasets of different scales, showing that the proposed NFM models outperform state-of-the-art survival models in terms of predictive performance. ",https://openreview.net/pdf/565b7bbe89e60e146158ac65399a30f3e6dc3181.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=1mNssCWt_v,STaSy: Score-based Tabular data Synthesis,"['Jayoung Kim', 'Chaejeong Lee', 'Noseong Park']","['~Jayoung_Kim1', '~Chaejeong_Lee1', '~Noseong_Park1']","['Score-based generative model', 'Tabular data', 'Self-paced learning']","Tabular data synthesis is a long-standing research topic in machine learning. Many different methods have been proposed over the past decades, ranging from statistical methods to deep generative methods. However, it has not always been successful due to the complicated nature of real-world tabular data. In this paper, we present a new model named $\textbf{S}$core-based $\textbf{Ta}$bular data $\textbf{Sy}$nthesis ($\texttt{STaSy}$) and its training strategy based on the paradigm of score-based generative modeling. Despite the fact that score-based generative models have resolved many issues in generative models, there still exists room for improvement in tabular data synthesis. Our proposed training strategy includes a self-paced learning technique and a fine-tuning strategy, which further increases the sampling quality and diversity by stabilizing the denoising score matching training. Furthermore, we also conduct rigorous experimental studies in terms of the generative task trilemma: sampling quality, diversity, and time. In our experiments with 15 benchmark tabular datasets and 7 baselines, our method outperforms existing methods in terms of task-dependant evaluations and diversity.
",https://openreview.net/pdf/7cc08c44de490f3e79794b5827aa36b84f99c4c3.pdf,{'title_filter': 'Data Synthesis'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=1jDN-RfQfrb,Unveiling Transformers with LEGO: A Synthetic Reasoning Task,"['Yi Zhang', 'Arturs Backurs', 'Sebastien Bubeck', 'Ronen Eldan', 'Suriya Gunasekar', 'Tal Wagner']","['~Yi_Zhang1', '~Arturs_Backurs1', '~Sebastien_Bubeck1', '~Ronen_Eldan1', '~Suriya_Gunasekar1', '~Tal_Wagner1']","['transformers', 'logical reasoning', 'role of pretraining', 'attention pattern']","We propose a synthetic reasoning task, LEGO (Learning Equality and Group Operations), that encapsulates the problem of following a chain of reasoning, and we study how the Transformer architectures learn this task. We pay special attention to data effects such as pretraining (on seemingly unrelated NLP tasks) and dataset composition (e.g., differing chain length at training and test time), as well as architectural variants such as weight-tied layers or adding convolutional components. We study how the trained models eventually succeed at the task, and in particular, we are able to understand (to some extent) some of the attention heads as well as how the information flows in the network. Based on these observations we propose a hypothesis that here pretraining helps for LEGO tasks due to certain structured attention patterns, and we experimentally verify this hypothesis. We also observe that in some data regimes the trained transformer finds ``shortcut"" solutions to follow the chain of reasoning, which impedes the model's robustness, and moreover we propose ways to prevent it. Motivated by our findings on structured attention patterns, we propose to replace certain attention heads with hardcoded patterns. This architectural change significantly reduces Flops and maintains or even improves the model's performance at large-scale pretraining.",https://openreview.net/pdf/be8333b7e949f26f36a5b69a15a511e07abb0eb1.pdf,{'title_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=1bLT3dGNS0,Relational Curriculum Learning for Graph Neural Networks,"['Zheng Zhang', 'Junxiang Wang', 'Liang Zhao']","['~Zheng_Zhang10', '~Junxiang_Wang1', '~Liang_Zhao6']","['Graph neural networks', 'Curriculum learning']","Graph neural networks have achieved great success in representing structured data and its downstream tasks such as node classification. The key idea is to recursively propagate and aggregate information along the edges of a given graph topology. However, edges in real-world graphs often have varying degrees of difficulty, and some edges may even be noisy to the downstream tasks. Therefore, existing graph neural network models may lead to suboptimal learned representations because they usually consider every edge in a given graph topology equally. On the other hand, curriculum learning, which mimics the human learning principle of learning data samples in a meaningful order, has been shown to be effective in improving the generalization ability of representation learners by gradually proceeding from easy to more difficult samples during training. Unfortunately, most existing curriculum learning strategies are designed for i.i.d data samples and cannot be trivially generalized to handle structured data with dependencies. In order to address these issues, in this paper we propose a novel curriculum learning method for structured data to leverage the various underlying difficulties of data dependencies to improve the quality of learned representations on structured data. Specifically, we design a learning strategy that gradually incorporates edges in a given graph topology into training according to their difficulty from easy to hard, where the degree of difficulty is measured by a self-supervised learning paradigm. We demonstrate the strength of our proposed method in improving the generalization ability of learned representations through extensive experiments on nine synthetic datasets and seven real-world datasets with different commonly used graph neural network models as backbone models.",https://openreview.net/pdf/6e6bc5f3a58802af58bb06f329a6e1accd60462e.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=1Wo0vqaZ8WJ,Let Offline RL Flow: Training Conservative Agents in the Latent Space of Normalizing Flow,"['Dmitry Akimov', 'Vladislav Kurenkov', 'Alexander Nikulin', 'Denis Tarasov', 'Sergey Kolesnikov']","['~Dmitry_Akimov2', '~Vladislav_Kurenkov1', '~Alexander_Nikulin1', '~Denis_Tarasov1', '~Sergey_Kolesnikov1']","['Offline Reinforcement Learning', 'Normalizing Flows']","Offline reinforcement learning aims to train a policy on a pre-recorded and fixed dataset without any additional environment interactions. There are two major challenges in this setting: (1) extrapolation error caused by approximating the value of state-action pairs not well-covered by the training data and (2) distributional shift between behavior and inference policies. One way to tackle these problems is to induce conservatism - i.e., keeping the learned policies closer to the behavioral ones. To achieve this, we build upon recent works on learning policies in latent action spaces and use a special form of normalizing flow for constructing a generative model, which we use as a conservative action encoder. This normalizing flow action encoder is pre-trained in a supervised manner on the offline dataset, and then an additional policy model - controller in the latent space - is trained via reinforcement learning. This approach avoids querying actions outside of the training dataset and therefore does not require additional regularization for out-of-dataset actions. We evaluate our method on various locomotion and navigation tasks, demonstrating that our approach outperforms recently proposed algorithms with generative action models on a large portion of datasets.",https://openreview.net/pdf/f86a805d1f98bbacca90bf4f817bcaa7fbcb8514.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=1TxMUE7cF6_,Modeling Temporal Data as Continuous Functions with Process Diffusion,"['Marin Biloš', 'Kashif Rasul', 'Anderson Schneider', 'Yuriy Nevmyvaka', 'Stephan Günnemann']","['~Marin_Biloš1', '~Kashif_Rasul1', '~Anderson_Schneider1', '~Yuriy_Nevmyvaka1', '~Stephan_Günnemann1']","['time series', 'stochastic process', 'diffusion', 'probabilistic forecasting', 'score-based matching']","Temporal data like time series are often observed at irregular intervals which is a challenging setting for  the existing machine learning methods. To tackle this problem, we view such data as samples from some underlying continuous function. We then define a diffusion-based generative model that adds  noise from a predefined stochastic process while  preserving the  continuity of the resulting underlying function. A neural network is trained to reverse this process which allows us to sample new realizations from the learned distribution. We define suitable stochastic processes as noise sources and introduce novel denoising and score-matching models on processes. Further, we show how to apply this approach to the  multivariate probabilistic forecasting and imputation tasks. Through our extensive experiments, we demonstrate that our method outperforms previous models on synthetic and real-world datasets.",https://openreview.net/pdf/35295d83ddcb697e14c238a173d942928357a18b.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=15lSKp0wBnm,"3D-IntPhys: Learning 3D Visual Intuitive Physics for Fluids, Rigid Bodies, and Granular Materials","['Haotian Xue', 'Antonio Torralba', 'Daniel LK Yamins', 'Joshua B. Tenenbaum', 'Yunzhu Li', 'Hsiao-Yu Tung']","['~Haotian_Xue1', '~Antonio_Torralba1', '~Daniel_LK_Yamins1', '~Joshua_B._Tenenbaum1', '~Yunzhu_Li1', '~Hsiao-Yu_Tung1']","['Visual Intuitive Physics', 'Neural Implicit Representations', 'Graph Neural Networks', 'Learning-Based Dynamics Modeling', 'Particle-Based Dynamics']","Given a visual scene, humans have strong intuitions about how a scene can evolve over time under given actions. The intuition, often termed visual intuitive physics, is a critical ability that allows us to make effective plans to manipulate the scene to achieve desired outcomes without relying on extensive trial and error. In this paper, we present a framework capable of learning 3D-grounded visual intuitive physics models purely from unlabeled images. Our method is composed of a conditional Neural Radiance Field (NeRF)-style visual frontend and a 3D point-based dynamics prediction backend, in which we impose strong relational and structural inductive bias to capture the structure of the underlying environment. Unlike existing intuitive point-based dynamics works that rely on the supervision of dense point trajectory from simulators, we relax the requirements and only assume access to multi-view RGB images and (imperfect) instance masks. This enables the proposed model to handle scenarios where accurate point estimation and tracking are hard or impossible. We evaluate the models on three challenging scenarios involving fluid, granular materials, and rigid objects, where standard detection and tracking methods are not applicable. We show our model can make long-horizon future predictions by learning from raw images and significantly outperforms models that do not employ an explicit 3D representation space. We also show that, once trained, our model can achieve strong generalization in complex scenarios under extrapolate settings.",https://openreview.net/pdf/73e44a63b8b8c3861aca4a5d4064103b62a77043.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=0xHVGIiYK2n,Multi-Agent Sequential Decision-Making via Communication,"['Ziluo Ding', 'Kefan Su', 'Weixin Hong', 'Liwen Zhu', 'Tiejun Huang', 'Zongqing Lu']","['~Ziluo_Ding1', '~Kefan_Su1', '~Weixin_Hong1', '~Liwen_Zhu1', '~Tiejun_Huang1', '~Zongqing_Lu2']","['multi-agent communication', 'multi-agent reinforcement learning']"," Communication helps agents to obtain information about others so that better coordinated behavior can be learned. Some existing work communicates predicted future trajectory with others, hoping to get clues about what others would do for better coordination. However, circular dependencies sometimes can occur when agents are treated synchronously so it is hard to coordinate decision-making. In this paper, we propose a novel communication scheme, Sequential Communication (SeqComm). SeqComm treats agents asynchronously (the upper-level agents make decisions before the lower-level ones) and has two communication phases. In negotiation phase, agents determine the priority of decision-making by communicating hidden states of observations and comparing the value of intention, which is obtained by modeling the environment dynamics. In launching phase, the upper-level agents take the lead in making decisions and communicate their actions with the lower-level agents. Theoretically, we prove the policies learned by SeqComm are guaranteed to improve monotonically and converge. Empirically, we show that SeqComm outperforms existing methods in various multi-agent cooperative tasks.
",https://openreview.net/pdf/c1788f4d5f395c9a121f290bd9f17fcc2fb6e4b7.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=0pdSt3oyJa1,Specformer: Spectral Graph Neural Networks Meet Transformers,"['Deyu Bo', 'Chuan Shi', 'Lele Wang', 'Renjie Liao']","['~Deyu_Bo1', '~Chuan_Shi1', '~Lele_Wang1', '~Renjie_Liao1']","['Spectral Graph Neural Networks', 'Transformer']","Spectral graph neural networks (GNNs) learn graph representations via spectral-domain graph convolutions. However, most existing spectral graph filters are scalar-to-scalar functions, i.e., mapping a single eigenvalue to a single filtered value, thus ignoring the global pattern of the spectrum. Furthermore, these filters are often constructed based on some fixed-order polynomials, which have limited expressiveness and flexibility. To tackle these issues, we introduce Specformer, which effectively encodes the set of all eigenvalues and performs self-attention in the spectral domain, leading to a learnable set-to-set spectral filter. We also design a decoder with learnable bases to enable non-local graph convolution. Importantly, Specformer is equivariant to permutation. By stacking multiple Specformer layers, one can build a powerful spectral GNN. On synthetic datasets, we show that our Specformer can better recover ground-truth spectral filters than other spectral GNNs. Extensive experiments of both node-level and graph-level tasks on real-world graph datasets show that our Specformer outperforms state-of-the-art GNNs and learns meaningful spectrum patterns. Code and data are available at https://github.com/bdy9527/Specformer.",https://openreview.net/pdf/4bf614d9277dc7ba7ec87eb0ccfccf6b765d3979.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=0aAd19ZQp11,Efficient Bayesian Optimization with Deep Kernel Learning and Transformer Pre-trained on Muliple Heterogeneous Datasets,"['Wenlong Lyu', 'Shoubo Hu', 'Jie Chuai', 'Zhitang Chen']","['~Wenlong_Lyu1', '~Shoubo_Hu1', 'chuaijie@huawei.com', '~Zhitang_Chen1']","['Pre-training', 'Bayesian optimization', 'Transformer', 'Transfer learning']","Bayesian optimization (BO) is widely adopted in black-box optimization problems and it relies on a surrogate model to approximate the black-box response function. With the increasing number of black-box optimization tasks solved and even more to solve, the ability to learn from multiple prior tasks to jointly pre-train a surrogate model is long-awaited to further boost optimization efficiency. In this paper, we propose a simple approach to pre-train a surrogate, which is a Gaussian process (GP) with a kernel defined on deep features learned from a Transformer-based encoder, using datasets from prior tasks with possibly heterogeneous input spaces. In addition, we provide a simple yet effective mix-up initialization strategy for input tokens corresponding to unseen input variables and therefore accelerate new tasks' convergence. Experiments on both synthetic and real benchmark problems demonstrate the effectiveness of our proposed pre-training and transfer BO strategy over existing methods.",https://openreview.net/pdf/fa972f7d3401955378ea1f6d7d4bc9f68dd76142.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=0YXmOFLb1wQ,MotifExplainer: a Motif-based Graph Neural Network Explainer,"['Zhaoning Yu', 'Hongyang Gao']","['~Zhaoning_Yu2', '~Hongyang_Gao1']","['Graph Neural Networks', 'Explainer', 'Motif']","We consider the explanation problem of Graph Neural Networks (GNNs). Most existing GNN explanation methods identify the most important edges or nodes but fail to consider substructures, which are more important for graph data. One method considering subgraphs tries to search all possible subgraphs and identifies the most significant ones. However, the subgraphs identified may not be recurrent or statistically important for interpretation. This work proposes a novel method, named MotifExplainer, to explain GNNs by identifying important motifs, which are recurrent and statistically significant patterns in graphs. Our proposed motif-based methods can provide better human-understandable explanations than methods based on nodes, edges, and regular subgraphs. Given an instance graph and a pre-trained GNN model, our method first extracts motifs in the graph using domain-specific motif extraction rules. Then, a motif embedding is encoded by feeding motifs into the pre-trained GNN. Finally, we employ an attention-based method to identify the most influential motifs as explanations for the prediction results. The empirical studies on both synthetic and real-world datasets demonstrate the effectiveness of our method.",https://openreview.net/pdf/1e00b18281b486873768fcbdbd648a6820101c0b.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=0LJRS7B3r4_,Advantage Constrained Proximal Policy Optimization in Multi-Agent Reinforcement Learning,['Weifan Li'],['~Weifan_Li1'],"['Multi agent', 'reinforcement learning', 'neural network', 'deep learning', 'trust region.']","We explore the value-based method and policy gradient combination in multi-agent reinforcement learning (MARL). In value-based MARL, {\itshape{Individual-Global-Max}} (IGM) principle plays an important role, which maintains the consistency between joint and local action values. At the same time, IGM is difficult to guarantee in multi-agent policy gradient methods due to stochastic exploration and conflicting gradient directions. In this paper, we propose a novel multi-agent policy gradient algorithm called {\itshape{Advantage Constrained Proximal Policy Optimization}} (ACPPO). Based on {\itshape{multi-agent advantage decomposition lemma}}, ACPPO introduces an advantage network for each agent to estimate current local state-action advantage. The coefficient of each agent constrains the joint-action advantage according to the consistency of the estimated joint-action advantage and local advantage. Unlike previous policy gradient-based MARL algorithms, ACPPO does not need an extra sampled baseline to reduce variance. We evaluate the proposed methods for continuous matrix game and Multi-Agent MuJoCo tasks. Results show that ACPPO outperforms the baselines such as MAPPO, MADDPG, and HAPPO.",https://openreview.net/pdf/8441bdf7caa8a9e3ffa807b1eef3347da04951a9.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=0DwzMsUNIr,From Points to Functions: Infinite-dimensional Representations in Diffusion Models,"['Sarthak Mittal', 'Guillaume Lajoie', 'Stefan Bauer', 'Arash Mehrjou']","['~Sarthak_Mittal1', '~Guillaume_Lajoie1', '~Stefan_Bauer1', '~Arash_Mehrjou1']","['representation learning', 'diffusion models', 'score-based learning']","Diffusion-based generative models learn to iteratively transfer unstructured noise to a complex target distribution as opposed to Generative Adversarial Networks (GANs) or the decoder of Variational Autoencoders (VAEs) which produce samples from the target distribution in a single step. Thus, in diffusion models every sample is naturally connected to a random trajectory which is a solution to a learned stochastic differential equation (SDE). Generative models are only concerned with the final state of this trajectory that delivers samples from the desired distribution. \cite{abstreiter2021diffusion} showed that these stochastic trajectories can be seen as continuous filters that wash out information along the way. Consequently, it is reasonable to ask if there is an intermediate time step at which the preserved information is optimal for a given downstream task. In this work, we show that a combination of information content from different time steps gives a strictly better representation for the downstream task. We introduce an attention and recurrence based modules that ``learn to mix'' information content of various time-steps such that the resultant representation leads to superior performance in downstream tasks.
",https://openreview.net/pdf/c938315f41ad379588ffadbc38372c32e2fc50d6.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=-z7O7fk_Cs,Invertible normalizing flow neural networks by JKO scheme,"['Chen Xu', 'Xiuyuan Cheng', 'Yao Xie']","['~Chen_Xu12', '~Xiuyuan_Cheng1', '~Yao_Xie2']","['Normalizing flow', 'invertible neural networks', 'JKO scheme']","Normalizing flow is a class of deep generative models for efficient sampling and density estimation. In practice, the flow often appears as a chain of invertible neural network blocks. To facilitate training, past works have regularized flow trajectories and designed special network architectures. The current paper develops a neural ODE flow network inspired by the Jordan-Kinderleherer-Otto (JKO) scheme, which allows an efficient \textit{block-wise} training procedure: as the JKO scheme unfolds the dynamic of gradient flow, the proposed model naturally stacks residual network blocks one-by-one and reduces the memory load as well as the difficulty of training deep networks. We also develop an adaptive time-reparametrization of the flow network with a progressive refinement of the trajectory in probability space, which improves the optimization efficiency and model accuracy in practice.  
On high-dimensional generative tasks for tabular data, JKO-Flow can process larger data batches and perform competitively as or better than continuous and discrete flow models, using 10X less number of iterations (e.g., batches) and significantly less time per iteration. ",https://openreview.net/pdf/74e2d2e5661eb174de11f1239b2a77db05bff8ff.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=-SKvXtXPCaJ,Learning Control by Iterative Inversion,"['Gal Leibovich', 'Guy Jacob', 'Or Avner', 'Gal Novik', 'Aviv Tamar']","['~Gal_Leibovich1', '~Guy_Jacob1', '~Or_Avner1', '~Gal_Novik1', '~Aviv_Tamar2']","['RL', 'IRL']","We formulate learning for control as an inverse problem - inverting a dynamical system to give the actions which yield desired behavior. The key challenge in this formulation is a distribution shift in the inputs to the function to be inverted - the learning agent can only observe the forward mapping (its actions' consequences) on trajectories that it can execute, yet must learn the inverse mapping for inputs-outputs that correspond to a different, desired behavior. We propose a general recipe for inverse problems with a distribution shift that we term $\textit{iterative inversion}$ - learn the inverse mapping under the current input distribution (policy), then use it on the desired output samples to obtain a new input distribution, and repeat.
As we show, iterative inversion can converge to the desired inverse mapping, but under rather strict conditions on the mapping itself.
We next apply iterative inversion to learn control. Our input is a set of demonstrations of desired behavior, given as video embeddings of trajectories (without actions), and our method iteratively learns to imitate trajectories generated by the current policy, perturbed by random exploration noise. We find that constantly adding the demonstrated trajectory embeddings as input to the policy when generating trajectories to imitate, a-la iterative inversion, we effectively steer the learning towards the desired trajectory distribution. To the best of our knowledge, this is the first exploration of learning control from the viewpoint of inverse problems, and the main advantage of our approach is simplicity - it does not require rewards, and only employs supervised learning, which can be easily scaled to use state-of-the-art trajectory embedding techniques and policy representations. Indeed, with a VQ-VAE embedding, and a transformer-based policy, we demonstrate non-trivial continuous control on several tasks. Further, we report an improved performance on imitating diverse behaviors compared to reward based methods. ",https://openreview.net/pdf/dac83de44f4e9858598471c3518db217d7b629e0.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=-RwZOVybbj,Risk-Aware Reinforcement Learning with Coherent Risk Measures and Non-linear Function Approximation,"['Thanh Lam', 'Arun Verma', 'Bryan Kian Hsiang Low', 'Patrick Jaillet']","['~Thanh_Lam1', '~Arun_Verma1', '~Bryan_Kian_Hsiang_Low1', '~Patrick_Jaillet1']","['Risk-Aware Reinforcement Learning', 'Coherent Risk Measures', 'Non-linear Function Approximation']","We study the risk-aware reinforcement learning (RL) problem in the episodic finite-horizon Markov decision process with unknown transition and reward functions. In contrast to the risk-neutral RL problem, we consider minimizing the risk of having low rewards, which arise due to the intrinsic randomness of the MDPs and imperfect knowledge of the model. Our work provides a unified framework to analyze the regret of risk-aware RL policy with coherent risk measures in conjunction with non-linear function approximation, which gives the first sub-linear regret bounds in the setting. Finally, we validate our theoretical results via empirical experiments on synthetic and real-world data.",https://openreview.net/pdf/12ed9c605b0fa8dc9237a38935722f9687e15641.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=zzL_5WoI3I,An Adaptive Entropy-Regularization Framework for Multi-Agent Reinforcement Learning,"['Woojun Kim', 'Youngchul Sung']","['~Woojun_Kim1', '~Youngchul_Sung1']","['Multi-Agent Reinforcement Learning', 'Entropy Regularization', 'Exploration-Exploitation Tradeoff']","In this paper, we propose an adaptive entropy-regularization framework (ADER) for multi-agent reinforcement learning (RL) to learn the adequate amount of exploration for each agent based on the degree of required exploration. In order to handle instability arising from updating multiple entropy temperature parameters for multiple agents, we disentangle the soft value function into two types: one for pure reward and the other for entropy. By applying multi-agent value factorization to the disentangled value function of pure reward, we obtain a relevant metric to assess the necessary degree of exploration for each agent. Based on this metric, we propose the ADER algorithm based on maximum entropy RL, which controls the necessary level of exploration across agents over time by learning the proper target entropy for each agent. Experimental results show that the proposed scheme significantly outperforms current state-of-the-art multi-agent RL algorithms. ",https://openreview.net/pdf/326b9e492a2f9b8c9c6b57df0cc2821d16942084.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=ztgT8Iok130,Sample-efficient multi-objective molecular optimization with GFlowNets,"['Yiheng Zhu', 'Jialu Wu', 'Chaowen Hu', 'Jiahuan Yan', 'Chang-Yu Hsieh', 'Tingjun Hou', 'Jian Wu']","['~Yiheng_Zhu3', '~Jialu_Wu1', '~Chaowen_Hu1', '~Jiahuan_Yan1', '~Chang-Yu_Hsieh1', '~Tingjun_Hou1', '~Jian_Wu6']","['multi-objective molecular optimization', 'Bayesian optimization', 'generative flow networks']","Many crucial scientific problems involve designing novel molecules with desired properties, which can be formulated as an expensive black-box optimization problem over the discrete chemical space. Computational methods have achieved initial success but still struggle with simultaneously optimizing multiple competing properties in a sample-efficient manner. In this work, we propose a multi-objective Bayesian optimization (MOBO) algorithm leveraging the hypernetwork-based GFlowNets (HN-GFN) as an acquisition function optimizer, with the purpose of sampling a diverse batch of candidate molecular graphs from an approximate Pareto front. Using a single preference-conditioned hypernetwork, HN-GFN learns to explore various trade-offs between objectives. Inspired by reinforcement learning, we further propose a hindsight-like off-policy strategy to share high-performing molecules among different preferences in order to speed up learning for HN-GFN. Through synthetic experiments, we illustrate that HN-GFN has adequate capacity to generalize over preferences. Extensive experiments show that our framework outperforms the best baselines by a large margin in terms of hypervolume in various real-world MOBO settings.",https://openreview.net/pdf/e071eb49a79f32cd751f8aa514e16320a17f8442.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=znLlSgN-4S0,"More Centralized Training, Still Decentralized Execution: Multi-Agent Conditional Policy Factorization","['Jiangxing Wang', 'Deheng Ye', 'Zongqing Lu']","['~Jiangxing_Wang2', '~Deheng_Ye1', '~Zongqing_Lu2']",['Multi-Agent Reinforcement Learning'],"In cooperative multi-agent reinforcement learning (MARL), combining value decomposition with actor-critic enables agents to learn stochastic policies, which are more suitable for the partially observable environment. Given the goal of learning local policies that enable decentralized execution, agents are commonly assumed to be independent of each other, even in centralized training. However, such an assumption may prohibit agents from learning the optimal joint policy. To address this problem, we explicitly take the dependency among agents into centralized training. Although this leads to the optimal joint policy, it may not be factorized for decentralized execution. Nevertheless, we theoretically show that from such a joint policy, we can always derive another joint policy that achieves the same optimality but can be factorized for decentralized execution. To this end, we propose multi-agent conditional policy factorization (MACPF), which takes more centralized training but still enables decentralized execution. We empirically verify MACPF in various cooperative MARL tasks and demonstrate that MACPF achieves better performance or faster convergence than baselines. Our code is available at https://github.com/PKU-RL/FOP-DMAC-MACPF.",https://openreview.net/pdf/8258fe1c50fe61494176aa41b2c207716e3d556b.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=zZXztocaN9,BO-Muse: A Human expert and AI teaming framework for accelerated experimental design ,"['Sunil Gupta', 'Alistair Shilton', 'Shannon Ryan', 'Arun Kumar Anjanapura Venkatesh', 'Majid Abdolshah', 'Hung Le', 'Santu Rana', 'Julian Berk', 'Mahad Rashid', 'Svetha Venkatesh']","['~Sunil_Gupta2', '~Alistair_Shilton1', '~Shannon_Ryan1', '~Arun_Kumar_Anjanapura_Venkatesh1', '~Majid_Abdolshah1', '~Hung_Le1', '~Santu_Rana1', '~Julian_Berk1', '~Mahad_Rashid1', '~Svetha_Venkatesh1']","['Experimental Design', 'Machine learning', 'Optimisation', 'Bayesian optimisation', 'Human-AI Teaming']","In this paper we introduce BO-Muse, a new approach to human-AI teaming for the optimisation of expensive blackbox functions. Inspired by the intrinsic difficulty of extracting expert knowledge and distilling it back into AI models and by observations of human behaviour in real-world experimental design, our algorithm lets the human expert take the lead in the experimental process. The human expert can use their domain expertise to its full potential, while the AI plays the role of a muse, injecting novelty and searching for areas of weakness to break the human out of over-exploitation induced by cognitive entrenchment. With mild assumptions, we show that our algorithm converges sub-linearly, at a rate faster than the AI or human alone. We validate our algorithm using synthetic data and with human experts performing real-world experiments.",https://openreview.net/pdf/692b01680e7fd5f063d8b26e23d90632c95bfe54.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=zWwrB9wenY1U,Soundness and Completeness: An Algorithmic Perspective on Evaluation of Feature Attribution,"['Yawei Li', 'Yang Zhang', 'Bernd Bischl', 'Mina Rezaei']","['~Yawei_Li3', '~Yang_Zhang22', '~Bernd_Bischl1', '~Mina_Rezaei1']","['explainable AI', 'explainability', 'feature attribution']","Feature attribution is a fundamental approach to explaining neural networks by quantifying the importance of input features for a model's prediction. Although a variety of feature attribution methods have been proposed, there is little consensus on the assessment of attribution methods. In this study, we empirically show the limitations of \emph{order-based} and \emph{model-retraining} metrics. To overcome the limitations and enable evaluation with higher granularity, we propose a novel method to evaluate the \emph{completeness} and \emph{soundness} of feature attribution methods. Our proposed evaluation metrics are mathematically grounded on algorithm theory and require no knowledge of ""ground truth"" informative features. We validate our proposed metrics by conducting experiments on synthetic and real-world datasets. Lastly, we use the proposed metrics to benchmark a wide range of feature attribution methods. Our evaluation results provide an innovative perspective on comparing feature attribution methods. Code is in the supplementary material. ",https://openreview.net/pdf/3965624d91f69d61d00ec23383b65212b1c7305b.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=zT5T9gHpGI,Adversarial Counterfactual Environment Model Learning,"['Xiong-Hui Chen', 'Yang Yu', 'Zhengmao Zhu', 'ZhiHua Yu', 'Chen Zhenjun', 'Chenghe Wang', 'Yinan Wu', 'Hongqiu Wu', 'Rong-Jun Qin', 'Ruijin Ding', 'Huang Fangsheng']","['~Xiong-Hui_Chen1', '~Yang_Yu5', '~Zhengmao_Zhu1', '~ZhiHua_Yu2', '~Chen_Zhenjun1', '~Chenghe_Wang1', '~Yinan_Wu2', '~Hongqiu_Wu2', '~Rong-Jun_Qin1', '~Ruijin_Ding1', '~Huang_Fangsheng1']","['offline environment model learning', 'reinforcement learning', 'causal inference']","A good model for action-effect prediction, i.e., the environment model, is essential for sample-efficient policy learning, in which the agent can take numerous free trials to find good policies. Currently, the model is commonly learned by fitting historical transition data through empirical risk minimization (ERM). However, we discover that simple data fitting can lead to a model that will be totally wrong in guiding policy learning due to the selection bias in offline dataset collection. In this work, we introduce weighted empirical risk minimization (WERM) to handle this problem in model learning.  A typical WERM method utilizes inverse propensity scores to re-weight the training data to approximate the target distribution. However, during the policy training, the data distributions of the candidate policies can be various and unknown. Thus, we propose an adversarial weighted empirical risk minimization (AWRM) objective that learns the model with respect to the worst case of the target distributions. We implement AWRM in a sequential decision structure, resulting in the GALILEO model learning algorithm. We also discover that GALILEO is closely related to adversarial model learning, explaining the empirical effectiveness of the latter. We apply GALILEO in synthetic tasks and verify that GALILEO makes accurate predictions on counterfactual data. We finally applied GALILEO in real-world offline policy learning tasks and found that GALILEO significantly improves policy performance in real-world testing.",https://openreview.net/pdf/61ab5d197c127522a0ca862d515a2ea1973016ea.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=zH9GcZ3ZGXu,Feature Reconstruction From Outputs Can Mitigate Simplicity Bias in Neural Networks,"['Sravanti Addepalli', 'Anshul Nasery', 'Venkatesh Babu Radhakrishnan', 'Praneeth Netrapalli', 'Prateek Jain']","['~Sravanti_Addepalli1', '~Anshul_Nasery2', '~Venkatesh_Babu_Radhakrishnan2', '~Praneeth_Netrapalli1', '~Prateek_Jain1']","['Simplicity Bias', 'Out-of-distribution robustness', 'OOD Generalization', 'Deep Learning']","Deep Neural Networks are known to be brittle to even minor distribution shifts compared to the training distribution. While one line of work has demonstrated that \emph{Simplicity Bias} (SB) of DNNs -- bias towards learning only the simplest features -- is a key reason for this brittleness, another recent line of work has surprisingly found that diverse/ complex features are indeed learned by the backbone, and their brittleness is due to the linear classification head relying primarily on the simplest features. To bridge the gap between these two lines of work, we first hypothesize and verify that while SB may not altogether preclude learning complex features, it amplifies simpler features over complex ones. Namely, simple features are replicated several times in the learned representations while complex features might not be replicated. This phenomenon, we term \emph{Feature  Replication  Hypothesis}, coupled with the \emph{Implicit Bias} of SGD to converge to maximum margin solutions in the feature space, leads the models to rely mostly on the simple features for classification. To mitigate this bias, we propose \emph{Feature Reconstruction Regularizer (FRR)} to ensure that the learned features can be reconstructed back from the logits. The use of \emph{FRR} in linear layer training (\emph{FRR-L}) encourages the use of more diverse features for classification. We further propose to finetune the full network by freezing the weights of the linear layer trained using \emph{FRR-L}, to refine the learned features, making them more suitable for classification. Using this simple solution, we demonstrate up to 15\% gains in OOD accuracy on the recently introduced semi-synthetic datasets with extreme distribution shifts. Moreover, we demonstrate noteworthy gains over existing SOTA methods on the standard OOD benchmark DomainBed as well.",https://openreview.net/pdf/d04b89a2199e2c436eabe69c7d7b984b0f21db55.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=ynD_LAMwar2,Reinforcement Logic Rule Learning for Temporal Point Processes ,"['Chao Yang', 'Lu Wang', 'Kun Gao', 'Shuang Li']","['~Chao_Yang9', '~Lu_Wang11', '~Kun_Gao1', '~Shuang_Li3']","['temporal point processes', 'explainable models', 'rule learning']","We aim to learn a set of temporal logic rules to explain the occurrence of temporal events. Leveraging the temporal point process modeling and learning framework, the rule content and rule weights are jointly learned by maximizing the likelihood of the observed noisy event sequences. The proposed algorithm alternates between a master problem, where the rule weights are updated, and a subproblem, where a new rule is searched and included. The formulated master problem is convex and relatively easy to solve, whereas the subproblem requires searching the huge combinatorial rule predicate and relationship space. To tackle this challenge, we propose a neural search policy to learn to generate the new rule content as a sequence of actions. The policy parameters will be trained end-to-end using the reinforcement learning framework, where the reward signals can be efficiently queried by evaluating the subproblem objective. The trained policy can be used to generate new rules, and moreover, the well-trained policies can be directly transferred to other tasks to speed up the rule searching procedure in the new task. We evaluate our methods on both synthetic and real-world datasets, obtaining promising results.",https://openreview.net/pdf/6dc861c4da6b6dd8d33c05f7362d16a9cafd6ed6.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=yFQjggu62T,Scalable and Privacy-enhanced Graph Generative Model for Graph Neural Networks,"['Minji Yoon', 'Yue Wu', 'John Palowitch', 'Bryan Perozzi', 'Russ Salakhutdinov']","['~Minji_Yoon1', '~Yue_Wu17', '~John_Palowitch1', '~Bryan_Perozzi1', '~Russ_Salakhutdinov1']","['graph generative model', 'graph neural networks', 'graph convolutional networks', 'benchmark graph generation']","As the field of Graph Neural Networks (GNN) continues to grow, it experiences a corresponding increase in the need for large, real-world datasets to train and test new GNN models on challenging, realistic problems. Unfortunately, such graph datasets are often generated from online, highly privacy-restricted ecosystems, which makes research and development on these datasets hard, if not impossible. This greatly reduces the amount of benchmark graphs available to researchers, causing the field to rely only on a handful of publicly-available datasets. To address this dilemma, we introduce a novel graph generative model, Computation Graph Transformer (CGT) that can learn and reproduce the distribution of real-world graphs in a privacy-enhanced way. Our proposed model (1) generates effective benchmark graphs on which GNNs show similar task performance as on the source graphs, (2) scales to process large-scale real-world graphs, (3) guarantees privacy for end-users. Extensive experiments across a vast body of graph generative models show that only our model can successfully generate privacy-controlled, synthetic substitutes of large-scale real-world graphs that can be effectively used to evaluate GNN models.",https://openreview.net/pdf/0bcbfa22875adf615372a04dc0242e01763e53ab.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=yAYHho4fATa,CFlowNets: Continuous Control with Generative Flow Networks,"['Yinchuan Li', 'Shuang Luo', 'Haozhi Wang', 'Jianye HAO']","['~Yinchuan_Li1', '~Shuang_Luo1', '~Haozhi_Wang1', '~Jianye_HAO1']","['Continuous control tasks', 'Generative flow networks']","Generative flow networks (GFlowNets), as an emerging technique, can be used as an alternative to reinforcement learning for exploratory control tasks. GFlowNets aims to sample actions with a probability proportional to the reward, similar to sampling different candidates in an active learning fashion. However, existing GFlowNets cannot adapt to continuous control tasks because GFlowNets need to form a DAG and compute the flow matching loss by traversing the inflows and outflows of each node in the trajectory. In this paper, we propose generative continuous flow networks (CFlowNets) that can be applied to continuous control tasks. First, we present the theoretical formulation of CFlowNets. Then, a training framework for CFlowNets is proposed, including the action selection process, the flow approximation algorithm, and the continuous flow matching loss function. Afterward, we theoretically prove the error bound of the flow approximation. The error decreases rapidly as the number of flow samples increases. Finally, experimental results on continuous control tasks demonstrate the performance advantages of CFlowNets compared to many reinforcement learning methods, especially regarding exploration ability.",https://openreview.net/pdf/d04aea952ea57b0759baa3d16e05576bc4d9fd2b.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=xgFfr5IIuXP,Clustering and Ordering Variable-Sized Sets: The Catalog Problem,"['Mateusz Maria Jurewicz', 'Graham W. Taylor', 'Leon Derczynski']","['~Mateusz_Maria_Jurewicz1', '~Graham_W._Taylor1', '~Leon_Derczynski1']","['neural clustering', 'set-to-sequence', 'supervised clustering', 'structure prediction', 'set representation', 'learning to order']","Prediction of a varying number of ordered clusters from sets of any cardinality is a challenging task for neural networks, combining elements of set representation, clustering and learning to order. This task arises in many diverse areas, ranging from medical triage, through multi-channel signal analysis for petroleum exploration to product catalog structure prediction. This paper focuses on the latter, which exemplifies a number of challenges inherent to adaptive ordered clustering, referred to further as the eponymous Catalog Problem. These include learning variable cluster constraints, exhibiting relational reasoning and managing combinatorial complexity. Despite progress in both neural clustering and set-to-sequence methods, no joint, fully differentiable model exists to-date. We develop such a modular architecture, referred to further as Neural Ordered Clusters (NOC), enhance it with a specific mechanism for learning cluster-level cardinality constraints, and provide a robust comparison of its performance in relation to alternative models. We test our method on three datasets, including synthetic catalog structures and PROCAT, a dataset of real-world catalogs consisting of over 1.5M products, achieving state-of-the-art results on a new, more challenging formulation of the underlying problem, which has not been addressed before. Additionally, we examine the network's ability to learn higher-order interactions and investigate its capacity to learn both compositional and structural rulesets.",https://openreview.net/pdf/33dbec164decabd10f2ecd63e1fc9c52adb04912.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=xeg2fW5E2l3,Set-Level Self-Supervised Learning from Noisily-Labeled Data,"['Chia-Ching Lin', 'Shang-Fu Chen', 'Fu-En Yang', 'Yu-Chiang Frank Wang', 'Chin-Laung Lei']","['~Chia-Ching_Lin1', '~Shang-Fu_Chen2', '~Fu-En_Yang1', '~Yu-Chiang_Frank_Wang2', '~Chin-Laung_Lei1']","['Self-supervised learning', 'Noisy label learning', 'Meta-learning', 'EM algorithm']","Noisy labels are inevitably presented in real-world datasets due to labeling error or visual content ambiguity. Existing methods generally approach the task of noisy label learning (NLL) by either properly regularizing the model, or reweighting clean/noisy labeled samples. While self-supervised learning (SSL) has been applied to pre-train deep neural networks without label supervision, downstream tasks like image classification still require clean labeled data. And, most SSL strategies are performed at the instance level, regardless of the correctness of its label. In this paper, we propose set-level self-supervised learning (SLSSL), which performs SSL at mini-batch levels with observed noisy labels. By corrupting the labels of each training mini-batch, our SLSSL enforces the model to exhibit sufficient robustness. Moreover, the proposed SLSSL can also be utilized for sample reweighting technique. As a result, the proposed learning scheme can be applied as an expectation-maximization (EM) algorithm during model training. Extensive experiments on synthetic and real-world noisy label data confirm the effectiveness of our framework.",https://openreview.net/pdf/2216db2b926f80ad83932fad5ebbd912d8d3c584.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=xYlJRpzZtsY,ROSCOE: A Suite of Metrics for Scoring Step-by-Step Reasoning,"['Olga Golovneva', 'Moya Peng Chen', 'Spencer Poff', 'Martin Corredor', 'Luke Zettlemoyer', 'Maryam Fazel-Zarandi', 'Asli Celikyilmaz']","['~Olga_Golovneva1', '~Moya_Peng_Chen1', '~Spencer_Poff1', '~Martin_Corredor1', '~Luke_Zettlemoyer1', '~Maryam_Fazel-Zarandi1', '~Asli_Celikyilmaz1']","['step-by-step reasoning', 'evaluation']","Large language models show improved downstream task performance when prompted to generate step-by-step reasoning to justify their final answers. These reasoning steps greatly improve model interpretability and verification, but objectively studying their correctness (independent of the final answer) is difficult without reliable methods for automatic evaluation. We simply do not know how often the stated reasoning steps actually support the final end task predictions. In this work, we present ROSCOE, a suite of interpretable, unsupervised automatic scores that improve and extend previous text generation evaluation metrics. To evaluate ROSCOE against baseline metrics, we design a typology of reasoning errors and collect synthetic and human evaluation scores on commonly used reasoning datasets. In contrast with existing metrics, ROSCOE can measure semantic consistency, logicality, informativeness, fluency, and factuality — among other traits — by leveraging properties of step-by-step rationales. We empirically verify the strength of our metrics on five human annotated and six programmatically perturbed diagnostics datasets - covering a diverse set of tasks that require reasoning skills and show that ROSCOE can consistently outperform baseline metrics.",https://openreview.net/pdf/3f6164615b8f835462171508e65f188740d76ee8.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=xTWoeTdHgH-,Evaluating Unsupervised Denoising Requires Unsupervised Metrics,"['Adria Marcos Morales', 'Matan Leibovich', 'Sreyas Mohan', 'Joshua Lawrence Vincent', 'Piyush Haluai', 'MAI TAN', 'Peter Crozier', 'Carlos Fernandez-Granda']","['~Adria_Marcos_Morales1', '~Matan_Leibovich1', '~Sreyas_Mohan1', '~Joshua_Lawrence_Vincent1', '~Piyush_Haluai1', '~MAI_TAN1', '~Peter_Crozier1', '~Carlos_Fernandez-Granda1']","['Denoising', 'Unsupervised Learning', 'Evaluation Metrics', 'Statistical Estimation', 'Imaging', 'Electron Microscopy']","Unsupervised denoising is a crucial challenge in real-world imaging applications. Unsupervised deep-learning methods have demonstrated impressive performance on benchmarks based on synthetic noise. However, no metrics are available to evaluate these methods in an unsupervised fashion. This is highly problematic for the many practical applications where ground-truth clean images are not available. In this work, we propose two novel metrics: the unsupervised mean squared error (MSE) and the unsupervised peak signal-to-noise ratio (PSNR), which are computed using only noisy data. We provide a theoretical analysis of these metrics, showing that they are asymptotically consistent estimators of the supervised MSE and PSNR. Controlled numerical experiments with synthetic noise confirm that they provide accurate approximations in practice. We validate our approach on real-world data from two imaging modalities:  videos in raw format and transmission electron microscopy. Our results demonstrate that the proposed metrics enable unsupervised evaluation of denoising methods based exclusively on noisy data.",https://openreview.net/pdf/099f905ccf6961644075ea89e9bfdf0986eab786.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=wkg_b4-IwTZ,A Closer Look at Model Adaptation using Feature Distortion and Simplicity Bias,"['Puja Trivedi', 'Danai Koutra', 'Jayaraman J. Thiagarajan']","['~Puja_Trivedi1', '~Danai_Koutra1', '~Jayaraman_J._Thiagarajan3']","['Transfer Learning', 'Robustness', 'Adaptation', 'Data Augmentation']","Advances in the expressivity of pretrained models have increased interest in the design of adaptation protocols which enable safe and effective transfer learning. Going beyond conventional linear probing (LP) and fine tuning (FT) strategies, protocols that can effectively control feature distortion, i.e., the failure to update features orthogonal to the in-distribution, have been found to achieve improved out-of-distribution generalization (OOD). In order to limit this distortion, the LP+FT protocol, which first learns a linear probe and then uses this initialization for subsequent FT, was proposed. However, in this paper, we find when adaptation protocols (LP, FT, LP+FT) are also evaluated on a variety of safety objectives (e.g., calibration, robustness, etc.), a complementary perspective to feature distortion is helpful to explain protocol behavior. To this end, we study the susceptibility of protocols to simplicity bias (SB), i.e. the well-known propensity of deep neural networks to rely upon simple features, as SB has recently been shown to underlie several problems in robust generalization. Using a synthetic dataset, we demonstrate the susceptibility of existing protocols to SB. Given the strong effectiveness of LP+FT, we then propose modified linear probes that help mitigate SB, and lead to better initializations for subsequent FT. We verify the effectiveness of the proposed LP+FT variants for decreasing SB in a controlled setting, and their ability to improve OOD generalization and safety on three adaptation datasets.",https://openreview.net/pdf/a96c8869749346661838b9c685006ca0e44e9011.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=wPVw218szF,Near Optimal Private and Robust Linear Regression,"['Xiyang Liu', 'Prateek Jain', 'Weihao Kong', 'Sewoong Oh', 'Arun Suggala']","['~Xiyang_Liu1', '~Prateek_Jain1', '~Weihao_Kong1', '~Sewoong_Oh1', '~Arun_Suggala1']","['differential privacy', 'private estimation', 'linear regression', 'label corruption']","We study the canonical statistical estimation problem of linear regression from $n$ i.i.d. examples under $(\varepsilon,\delta)$-differential privacy when a fraction of response variables are adversarially corrupted.   We propose a variant of the popular differentially private stochastic gradient descent (DP-SGD) algorithm with two innovations: a full-batch gradient descent to improve sample complexity and a novel adaptive clipping to guarantee robustness. When there is no adversarial corruption, this algorithm improves upon the existing state-of-the-art approach and achieves near optimal sample complexity. Under label-corruption, this is the first efficient linear regression algorithm to provably guarantee both $(\epsilon,\delta)$-DP and robustness. Synthetic experiments confirm the superiority of our approach. ",https://openreview.net/pdf/a1a787bd958b8f381601462126fd3b05687b3b53.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=w9WUQkBvpI,Subsampling in Large Graphs Using Ricci Curvature,"['Shushan Wu', 'Huimin Cheng', 'Jiazhang Cai', 'Ping Ma', 'Wenxuan Zhong']","['~Shushan_Wu1', '~Huimin_Cheng1', '~Jiazhang_Cai1', '~Ping_Ma1', '~Wenxuan_Zhong1']","['Graph subsampling', 'Ricci curvature']","In the past decades, many large graphs with millions of nodes have been collected/constructed. The high computational cost and significant visualization difficulty hinder the analysis of large graphs. To overcome the difficulties, researchers have developed many graph subsampling approaches to provide a rough sketch that preserves global properties. By selecting representative nodes, these graph subsampling methods can help researchers estimate the graph statistics, e.g., the number of communities, of the large graph from the subsample. However, the available subsampling methods, e.g., degree node sampler and random walk sampler, tend to leave out minority communities because nodes with high degrees are more likely to be sampled. To overcome the shortcomings of the existing methods, we are motivated to apply the community information hidden in the graph to the subsampling method. Though the community structure is unavailable, community structure information can be obtained by applying geometric methods to a graph. An analog of Ricci curvature in the manifold is defined for the graph, i.e., Ollivier Ricci curvature. Based on the asymptotic results about the within-community edge and between-community edge's OR curvature, we propose a subsampling algorithm based on our theoretical results, the Ollivier-Ricci curvature Gradient-based subsampling (ORG-sub) algorithm. The proposed ORG-sub algorithm has two main contributions: First, ORG-sub provides a rigorous theoretical guarantee that the probability of ORG-sub taking all communities into the final subgraph converges to one. Second, extensive experiments on synthetic and benchmark datasets demonstrate the advantages of our algorithm.",https://openreview.net/pdf/028be470cd7466da953f6e016e46cf5dfb5947b5.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=w2mDq-p9EEf,Learning Latent Structural Causal Models,"['Jithendaraa Subramanian', 'Yashas Annadani', 'Ivaxi Sheth', 'Nan Rosemary Ke', 'Tristan Deleu', 'Stefan Bauer', 'Derek Nowrouzezahrai', 'Samira Ebrahimi Kahou']","['~Jithendaraa_Subramanian1', '~Yashas_Annadani1', '~Ivaxi_Sheth1', '~Nan_Rosemary_Ke1', '~Tristan_Deleu1', '~Stefan_Bauer1', '~Derek_Nowrouzezahrai1', '~Samira_Ebrahimi_Kahou1']","['Causal discovery', 'Bayesian inference']","Causal learning has long concerned itself with the accurate recovery of underlying causal mechanisms. Such causal modelling enables better explanations of out-of-distribution data. Prior works on causal learning assume that the high-level causal variables are given. However, in machine learning tasks, one often operates on low-level data like image pixels or high-dimensional vectors. In such settings, the entire Structural Causal Model (SCM) -- structure, parameters, \textit{and} high-level causal variables -- is unobserved and needs to be learnt from low-level data. We treat this problem as Bayesian inference of the latent SCM, given low-level data. For linear Gaussian additive noise SCMs, we present a tractable approximate inference method which performs joint inference over the causal variables, structure and parameters of the latent SCM from random, known interventions. Experiments are performed on synthetic datasets and a causally generated image dataset to demonstrate the efficacy of our approach. We also perform image generation from unseen interventions, thereby verifying out of distribution generalization for the proposed causal model.",https://openreview.net/pdf/63a5676e151b88e25ccf790f232ac1921e110b1b.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=vxln_lFKkfc,Untangling Effect and Side Effect: Consistent Causal Inference in Non-Targeted Trials,"['Georgios Mavroudeas', 'Malik Magdon-Ismail', 'Kristin Bennett', 'Jason Kuruzovich']","['~Georgios_Mavroudeas1', '~Malik_Magdon-Ismail1', '~Kristin_Bennett1', '~Jason_Kuruzovich1']","['Causal Inference', 'Non Targeted Trials', 'Machine Learning', 'Heterogeneous Treatment Effects']","A treatment is usually appropriate for some group (the ``sick"" group) on whom it has an effect, but it can also have a side-effect when given to subjects from another group (the ``healthy"" group). In a non-targeted trial both sick and healthy subjects may be treated, producing
heterogeneous effects within the treated group. Inferring the correct treatment effect on the sick population is then 
difficult, because the effect and side-effect are tangled. We propose an efficient nonparametric approach to untangling the effect and side-effect, called  PCM (pre-cluster and merge). We prove its asymptotic consistency in a general setting and
show, on synthetic data, 
more than a 10x improvement in accuracy over existing state-of-the-art.
",https://openreview.net/pdf/56cdd812acaceee6a2b77038f8b66c792ecc1a64.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=vmFwJeiSx4X,Multi-Layered 3D Garments Animation,"['Yidi Shao', 'Chen Change Loy', 'Bo Dai']","['~Yidi_Shao1', '~Chen_Change_Loy2', '~Bo_Dai2']",[],"Most existing 3D garment animation datasets are restricted to human bodies with single-layered garments. Even though cases with upper shirts and lower pants are included, only a few overlap areas among such garment combinations exist. Moreover, they often regard human body movement as the only driving factor that causes garment animation. Approaches developed on top of these datasets thus tend to model garments as functions of human body parameters such as body shape and pose. While such treatment leads to promising performance on existing datasets, it leaves a gap between experimental environments and real scenarios, where a body can wear multiple layered garments and the corresponding garment dynamics can be affected by environmental factors and garment attributes. Consequently, existing approaches often struggle to generalize to multi-layered garments and realistic scenarios. To facilitate the advance of 3D garment animation toward handling more challenging cases, this paper presents a new large-scale synthetic dataset called LAYERS, covering 4,900 different combinations of multi-layered garments with 700k frames in total. The animation of these multi-layered garments follows the laws of physics and is affected by not only human body movements but also random environmental wind and garment attributes. To demonstrate the quality of LAYERS, we further propose a novel method, LayersNet, for 3D garment animation, which represents garments as unions of particles and subsequently adopts a neural network to animate garments via particle-based simulation. In this way, the interactions between different parts of one garment, different garments on the same body, and garments against various driving factors, can be naturally and uniformly handled via the interactions of particles. Through comprehensive experiments, LayersNet demonstrates superior performance in terms of animation accuracy and generality over baselines. The proposed dataset, LAYERS, as well as the proposed method, LayersNet, will be publicly available.",https://openreview.net/pdf/5bf39d3e86e854d81de7ff1abf2c1aa05a2d6380.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=vjSKpocWeGf,Lipschitz regularized gradient flows and latent generative particles,"['Hyemin Gu', 'Panagiota Birmpa', 'Yannis Pantazis', 'Markos Katsoulakis', 'Luc Rey-Bellet']","['~Hyemin_Gu1', '~Panagiota_Birmpa1', '~Yannis_Pantazis1', '~Markos_Katsoulakis1', '~Luc_Rey-Bellet1']","['probability divergences', 'generative models', 'Lipschitz regularization', 'gradient flows', 'autoencoders', 'particle algorithms']","Lipschitz regularized $f$-divergences are constructed by imposing a bound on the Lipschitz constant of the discriminator in the variational representation. These divergences interpolate between the Wasserstein metric and $f$-divergences and provide a flexible family of loss functions for non-absolutely continuous (e.g. empirical) distributions, possibly with heavy tails. We first construct Lipschitz regularized gradient flows on the space of probability measures based on these divergences. Examples of such gradient flows are Lipschitz regularized Fokker-Planck and porous medium partial differential equations (PDEs) for the Kullback-Leibler and $\alpha$-divergences, respectively. The regularization corresponds to imposing a Courant–Friedrichs–Lewy numerical stability condition on the PDEs. For empirical measures, the Lipschitz regularization on gradient flows induces a numerically stable transporter/discriminator particle algorithm, where the generative particles are transported along the gradient of the discriminator. The gradient structure leads to a regularized Fisher information which is the total kinetic energy of the particles and can be used to track the convergence of the algorithm. The Lipschitz regularized discriminator can be implemented via neural network spectral normalization and the particle algorithm generates approximate samples from possibly high-dimensional distributions known only from data. Notably, our particle algorithm can generate synthetic data even in small sample size regimes. A new data processing inequality for the regularized divergence allows us to combine our particle algorithm with representation learning, e.g. autoencoder architectures. The resulting particle algorithm in latent space yields markedly improved generative properties in terms of efficiency and quality of the synthetic samples. From a statistical mechanics perspective the encoding can be interpreted dynamically as learning a better mobility for the generative particles. ",https://openreview.net/pdf/f95b8bee808d335bb430ec2c78a939cb49d8409e.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=vaf8KQ8bhS,RbX: Region-based explanations of prediction models,"['Ismael Lemhadri', 'Harrison H Li', 'Trevor Hastie']","['~Ismael_Lemhadri1', '~Harrison_H_Li1', '~Trevor_Hastie1']",[],"We introduce region-based explanations (RbX), a novel, model-agnostic method to generate local explanations of scalar outputs from a black-box prediction model using only query access. RbX is based on a greedy algorithm for building a convex polytope that approximates a region of feature space where model predictions are close to the prediction at some target point. This region is fully specified by the user on the scale of the predictions, rather than on the scale of the features. The geometry of this polytope - specifically the change in each coordinate necessary to escape the polytope - quantifies the local sensitivity of the predictions to each of the features. These “escape distances” can then be standardized to rank the features by local importance. RbX is guaranteed to satisfy a “sparsity” axiom, which requires that features which do not enter into the prediction model are assigned zero importance. At the same time, real data examples and synthetic experiments show how RbX can more readily detect all locally relevant features than existing methods.",https://openreview.net/pdf/c54650701a3023e84ebf4ae863c2ccf168538608.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=v61jhmI2zz,Discovering Bugs in Vision Models using Off-the-shelf Image Generation and Captioning,"['Olivia Wiles', 'Isabela Albuquerque', 'Sven Gowal']","['~Olivia_Wiles1', '~Isabela_Albuquerque1', '~Sven_Gowal2']","['robustness', 'failure discovery']","Automatically discovering failures in vision models under real-world settings remains an open challenge. This work shows how off-the-shelf, large-scale, image-to-text and text-to-image models, trained on vast amounts of data, can be leveraged to automatically find such failures. In essence, a conditional text-to-image generative model is used to generate large amounts of synthetic, yet realistic, inputs given a ground-truth label. A captioning model is used to describe misclassified inputs. Descriptions are used in turn to generate more inputs, thereby assessing whether specific descriptions induce more failures than expected. As failures are grounded to natural language, we automatically obtain a high-level, human-interpretable explanation of each failure. We use this pipeline to demonstrate that we can effectively interrogate classifiers trained on ImageNet to find specific failure cases and discover spurious correlations. We also show that we can scale the approach to generate adversarial datasets targeting specific classifier architectures. This work demonstrates the utility of large-scale generative models to automatically discover bugs in vision models in an open-ended manner. We also describe a number of limitations and pitfalls related to this approach.",https://openreview.net/pdf/3c3da633058982171bc01205d90d6dbeea96b163.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=v3y68gz-WEz,Riemannian Metric Learning via Optimal Transport,"['Christopher Scarvelis', 'Justin Solomon']","['~Christopher_Scarvelis1', '~Justin_Solomon1']","['optimal transport', 'riemannian geometry', 'manifold learning', 'time series']","We introduce an optimal transport-based model for learning a metric tensor from cross-sectional samples of evolving probability measures on a common Riemannian manifold. We neurally parametrize the metric as a spatially-varying matrix field and efficiently optimize our model's objective using a simple alternating scheme. Using this learned metric, we can non-linearly interpolate between probability measures and compute geodesics on the manifold. We show that metrics learned using our method improve the quality of trajectory inference on scRNA and bird migration data at the cost of little additional cross-sectional data.",https://openreview.net/pdf/ef540eb6d8d75498298baa5bf7417a3542a7b4e8.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=v-3dUexkNn,Towards predicting dynamic stability of power grids with Graph Neural Networks,"['Christian Nauck', 'Michael Lindner', 'Konstantin Schürholt', 'Frank Hellmann']","['~Christian_Nauck1', '~Michael_Lindner1', '~Konstantin_Schürholt1', '~Frank_Hellmann1']","['Power grids', 'dynamic stability', 'Graph Neural Networks']","To mitigate climate change, the share of renewable energies in power production needs to be increased. Renewables introduce new challenges to power grids regarding the dynamic stability due to decentralization, reduced inertia and volatility in production. However, dynamic stability simulations are intractable and exceedingly expensive for large grids. Graph Neural Networks (GNNs) are a promising method to reduce the computational effort of analyzing dynamic stability of power grids. We provide new datasets of dynamic stability of synthetic power grids and find that GNNs are surprisingly effective at predicting highly non-linear targets from topological information only. We show that large GNNs outperform GNNs from previous work as well as as handcrafted graph features and semi-analytic approximations. Further, we demonstrate GNNs can accurately identify \emph{trouble maker}-nodes in the power grids. Lastly, we show that GNNs trained on small grids can perform accurately on a large synthetic Texan power grid model, which illustrates the potential of our approach.",https://openreview.net/pdf/07bb7e3741389dfb3cbe989b8389443c5dc4e089.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=uyqks-LILZX,Modeling the Data-Generating Process is Necessary for Out-of-Distribution Generalization,"['Jivat Neet Kaur', 'Emre Kiciman', 'Amit Sharma']","['~Jivat_Neet_Kaur1', '~Emre_Kiciman1', '~Amit_Sharma3']",[],"Recent empirical studies on domain generalization (DG) have shown that DG algorithms that perform well on some distribution shifts fail on others, and no state-of-the-art DG algorithm performs consistently well on all shifts. Moreover, real-world data often has multiple distribution shifts over different attributes; hence we introduce multi-attribute distribution shift datasets and find that the accuracy of existing DG algorithms falls even further. To explain these results, we provide a formal characterization of generalization under multi-attribute shifts using a canonical causal graph. Based on the relationship between spurious attributes and the classification label, we obtain realizations of the canonical causal graph that characterize common distribution shifts and show that each shift entails different independence constraints over observed variables. As a result, we prove that any algorithm based on a single, fixed constraint cannot work well across all shifts, providing theoretical evidence for mixed empirical results on DG algorithms. Based on this insight, we develop Causally Adaptive Constraint Minimization (CACM), an algorithm that uses knowledge about the data-generating process to adaptively identify and apply the correct independence constraints for regularization. Results on fully synthetic, MNIST, small NORB, and Waterbirds datasets, covering binary and multi-valued attributes and labels, show that adaptive dataset-dependent constraints lead to the highest accuracy on unseen domains whereas incorrect constraints fail to do so. Our results demonstrate the importance of modeling the causal relationships inherent in the data-generating process.",https://openreview.net/pdf/4048ed797cd1ecee3eb0807128459f763f1cd777.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=ufCQZeAMZzf,Low-Rank Graph Neural Networks Inspired by the Weak-balance Theory in Social Networks,"['Langzhang Liang', 'Xiangjing Hu', 'Zenglin Xu', 'Zixing Song', 'Irwin King']","['~Langzhang_Liang1', '~Xiangjing_Hu1', '~Zenglin_Xu1', '~Zixing_Song1', '~Irwin_King1']","['graph neural networks', 'heterophily', 'social theory', 'low rank']","Graph Neural Networks (GNNs) have achieved state-of-the-art performance on node classification tasks by exploiting both the graph structures and node features. Generally, most existing GNNs depend on the implicit homophily assumption that nodes belonging to the same class are more likely to be connected. However, GNNs may fail to model heterophilious graphs where nodes with different labels tend to be linked, as shown in recent studies.  To address this issue, we propose a generic GNN applicable to both homophilious and heterophilious graphs, namely Low-Rank Graph Neural Network (LRGNN). In detail, we aim at computing a coefficient matrix such that the sign of each coefficient reveals whether the corresponding two nodes belong to the same class, which is similar to the sign inference problem. In Signed Social Networks (SSNs), the sign inference problem can be modeled as a low-rank matrix factorization (LRMF) problem due to the global low-rank structure described by the weak balance theory. In this paper, we show that signed graphs are naturally generalized weakly-balanced when considering node classification tasks. Motivated by this observation, we propose to leverage LRMF to recover a coefficient matrix from a partially observed signed adjacency matrix. To effectively capture the node similarity, we further incorporate the low-rank representation (LRR) method. Our theoretical result shows that under our update rule of node representations, LRR obtained by solving a subspace clustering problem can recover the subspace structure of node representations. To solve the corresponding optimization problem, we utilize an iterative optimization algorithm with a convergence guarantee and develop a neural-style initialization manner that enables fast convergence. Finally, extensive experimental evaluation on both real-world and synthetic graphs has validated the superior performance of LRGNN over various state-of-the-art GNNs. In particular, LRGNN can offer clear performance gains in a scenario when the node features are not informative enough.",https://openreview.net/pdf/5f8a49029fefca9e88dcd4273d9cfa7c7e447a59.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=uKmuzIuVl8z,Structure-based Drug Design with Equivariant Diffusion Models,"['Arne Schneuing', 'Yuanqi Du', 'Charles Harris', 'Arian Rokkum Jamasb', 'Ilia Igashov', 'weitao Du', 'Tom Leon Blundell', 'Pietro Lio', 'Carla P Gomes', 'Max Welling', 'Michael M. Bronstein', 'Bruno Correia']","['~Arne_Schneuing1', '~Yuanqi_Du1', '~Charles_Harris2', '~Arian_Rokkum_Jamasb1', '~Ilia_Igashov1', '~weitao_Du1', '~Tom_Leon_Blundell1', '~Pietro_Lio1', '~Carla_P_Gomes1', '~Max_Welling1', '~Michael_M._Bronstein1', '~Bruno_Correia1']","['Diffusion Models', 'Equivariant Neural Networks', 'Structure-based Drug Design', 'Molecule Generation', 'Conditional Generation']","Structure-based drug design (SBDD) aims to design small-molecule ligands that bind with high affinity and specificity to pre-determined protein targets. Traditional SBDD pipelines start with large-scale docking of compound libraries from public databases, thus limiting the exploration of chemical space to existent previously studied regions.
Recent machine learning methods approached this problem using an atom-by-atom generation approach, which is computationally expensive. 
In this paper, we formulate SBDD as a 3D-conditional generation problem and present DiffSBDD, an E(3)-equivariant 3D-conditional diffusion model that generates novel ligands conditioned on protein pockets. 
Furthermore, we curate a new dataset of experimentally determined binding complex data from Binding MOAD to provide realistic binding scenario rather than the synthetic CrossDocked dataset. Comprehensive in silico experiments demonstrate the efficiency of DiffSBDD in generating novel and diverse drug-like ligands that engage protein pockets with high binding energies as predicted by in silico docking.",https://openreview.net/pdf/534070e1a8092ce852688c63211857cb33856123.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=u9hnCwX99I1,Centralized Training with Hybrid Execution in Multi-Agent Reinforcement Learning,"['Pedro Pinto Santos', 'Diogo S. Carvalho', 'Miguel Vasco', 'Francisco S. Melo', 'Alberto Sardinha', 'Pedro A. Santos', 'Ana Paiva']","['~Pedro_Pinto_Santos1', '~Diogo_S._Carvalho1', '~Miguel_Vasco1', '~Francisco_S._Melo1', '~Alberto_Sardinha1', '~Pedro_A._Santos1', '~Ana_Paiva2']",['Multi-Agent Reinforcement Learning'],"We introduce hybrid execution in multi-agent reinforcement learning (MARL), a new paradigm in which agents aim to successfully perform cooperative tasks with any communication level at execution time by taking advantage of information-sharing among the agents. Under hybrid execution, the communication level can range from a setting in which no communication is allowed between agents (fully decentralized), to a setting featuring full communication (fully centralized). To formalize our setting, we define a new class of multi-agent partially observable Markov decision processes (POMDPs) that we name hybrid-POMDPs, which explicitly models a communication process between the agents. We contribute MARO, an approach that combines an autoregressive predictive model to estimate missing agents' observations, and a dropout-based RL training scheme that simulates different communication levels during the centralized training phase. We evaluate MARO on standard scenarios and extensions of previous benchmarks tailored to emphasize the negative impact of partial observability in MARL. Experimental results show that our method consistently outperforms baselines, allowing agents to act with faulty communication while successfully exploiting shared information.",https://openreview.net/pdf/1e453f0df117752fa75e7810ace4310c4099f97c.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=u0aNcjqhEJ,Consciousness-Aware Multi-Agent Reinforcement Learning,"['Jianzhun Shao', 'Hongchang Zhang', 'Yun Qu', 'Chang Liu', 'Shuncheng He', 'Yuhang Jiang', 'Xiangyang Ji']","['~Jianzhun_Shao1', '~Hongchang_Zhang1', '~Yun_Qu2', '~Chang_Liu9', '~Shuncheng_He1', '~Yuhang_Jiang3', '~Xiangyang_Ji1']",['multi-agent reinforcement learning'],"In cooperative multi-agent reinforcement learning, centralized training with decentralized execution (CTDE) shows great promise for a trade-off between independent Q-learning and joint action learning. However, vanilla CTDE methods assumed a fixed number of agents could hardly adapt to real-world scenarios where dynamic team compositions typically suffer from the dilemma of dramatic partial observability variance. Specifically, agents with extensive sight ranges are prone to be affected by trivial environmental substrates, dubbed the “attention distraction” issue; ones with limited observability can hardly sense their teammates, hindering the quality of cooperation. In this paper, we propose a Consciousness-Aware Multi-Agent reinforcement learning (CAMA) approach, which roots in a divide-and-conquer strategy to facilitate stable and sustainable teamwork. Concretely, CAMA targets dividing the input entities with controlled observability masks by an Entity Dividing Module (EDM) according to their execution relevance for consciousness learning. To tackle the attention distraction issue, the highly related entities are fed to a Consciousness Enhancement Module (CEM) for consciousness-aware representation extraction via action prediction with an inverse model. For better out-of-sight-range cooperation, the lowly related ones are compressed to brief messages by a Consciousness Replenishment Module (CRM) with a conditional mutual information estimator. Our CAMA outperforms the SOTA methods significantly on the challenging StarCraftII, MPE, and Traffic Junction benchmarks.",https://openreview.net/pdf/997d626ea381b73966bba7980d7607707ea0a50d.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=ttnf-Wibn2R,An Analytic Framework for Robust Training of Differentiable Hypothesis,"['Ramin Barati', 'Reza Safabakhsh', 'Mohammad Rahmati']","['~Ramin_Barati1', '~Reza_Safabakhsh1', '~Mohammad_Rahmati1']",[],"The reliability of a learning model is key to the successful deployment of machine learning in various industries. Creating a robust model, particularly one unaffected by adversarial attacks, requires a comprehensive understanding of the adversarial examples phenomenon. However, it is difficult to describe the phenomenon due to the complicated nature of the problems in machine learning. Consequently, many studies investigate the phenomenon by proposing a simplified model of how adversarial examples occur and validate it by predicting some aspect of the phenomenon. While these studies cover many different characteristics of the adversarial examples, they have not reached a holistic approach to the geometric and analytic modeling of the phenomenon. We observe the phenomenon in many applications of machine learning, and its effects seems to be independent of the choice of the hypothesis class. In this paper, we propose a formalization of robustness in learning theoretic terms and give a geometrical description of the phenomenon in analytic classifiers. We then utilize the proposal to devise a robust classification learning rule for differentiable hypothesis classes and showcase our framework on synthetic and real-world data.",https://openreview.net/pdf/21d61c913c546d572488600f61aeaeb4ae075dec.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=tsPXEkMzPjB,Learning to Decouple Complex System for Sequential Data,"['Zihan Zhou', 'Minxin Ao', 'Tianshu Yu']","['zihanzhou1@link.cuhk.edu.cn', '121050006@link.cuhk.edu.cn', '~Tianshu_Yu2']","['neural differential equation', 'sequential learning', 'decoupling complex system']","A complex system with cluttered observations may be a coupled mixture of multiple simple sub-systems corresponding to \emph{latent entities}. Such sub-systems may hold distinct dynamics in the continuous-time domain, therein complicated interactions between sub-systems also evolve over time.  This setting is fairly common in the real world, but has been less considered. In this paper, we propose a sequential learning approach under this setting by decoupling a complex system for handling irregularly sampled and cluttered sequential observations. Such decoupling brings about not only subsystems describing the dynamics of each latent entity, but also a meta-system capturing the interaction between entities over time. Specifically, we argue that the meta-system of interactions is governed by a smoothed version of \emph{projected differential equations}. Experimental results on synthetic and real-world datasets show the advantages of our approach when facing complex and cluttered sequential data compared to the state-of-the-art.",https://openreview.net/pdf/cda7ea238c2f1abf3dbc2a930938d6eb3f6eba78.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=tlhsswFz9x,Learning Graph Neural Network Topologies,"['Avishkar Saha', 'Oscar Mendez Maldonado', 'Chris Russell', 'Richard Bowden']","['~Avishkar_Saha1', '~Oscar_Mendez_Maldonado1', '~Chris_Russell3', '~Richard_Bowden1']",[],"Graph convolutional networks (GCNs) enable end-to-end learning on graph structured data. However, many works begin by assuming a given graph structure. As the ideal graph structure is often unknown, this limits applicability. To address this, we present a novel end-to-end differentiable graph-generator which builds the graph topology on the fly. Our module can be readily integrated into existing pipelines involving graph convolution operations, replacing the predetermined or existing adjacency matrix with one that is learned, and optimised, as part of the general objective. As such it is applicable to any GCN. We show that integrating our module into both node classification and trajectory prediction pipelines improves accuracy across a range of datasets and backbones.",https://openreview.net/pdf/48868383be4fb6c14a1396585baddcc526fb4ed0.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=tPrRs6YB2P,Scenario-based Question Answering with Interacting Contextual Properties,"['Haitian Sun', 'William W. Cohen', 'Ruslan Salakhutdinov']","['~Haitian_Sun2', '~William_W._Cohen2', '~Ruslan_Salakhutdinov1']",['Question Answering'],"In the scenario-based Question Answering (QA) task, models are asked to find answers that are appropriate to the user scenarios associated with the question and identify information that is missing from the scenarios but is necessary for the answers to hold. Scenarios commonly include multiple properties of users, such as age, employment status, and income level for the question “How much can I claim from this benefit”. The properties relevant to a potential answer are given in a document, which will state conditions necessary for the answer to hold. Documents also may specify how conditions interact with each other, e.g. with text like “one of the conditions below must apply”. Although understanding the relationship between conditions is crucial for solving this challenging QA task, limited work has been done so far in modeling this. In this paper, we propose the T-Reasoner model, which solves this problem with three jointly learned modules: an entailment module which checks whether a condition has been satisfied by the scenario, a decoding module which locates eligible answers from documents, and a reasoning module which infers the relationship between conditions and performs a reasoning step to determine the logically consistent answers and identify missing conditions. T-Reasoner outperforms strong baselines on a synthetic scenario-based QA dataset and achieves a new state-of-the-art on two scenario-based QA benchmarks, outperforming the prior best models by 3-10 points.",https://openreview.net/pdf/3fd9ea33c70845a298ecbb8cf8b7cdb1cb25c4c1.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=tKMLGb7MWC,A Reinforcement Learning Approach to Estimating Long-term Treatment Effects,"['Ziyang Tang', 'Yiheng Duan', 'Stephanie Zhang', 'Lihong Li']","['~Ziyang_Tang1', 'yiheng@amazon.com', 'stepzhan@amazon.com', '~Lihong_Li1']","['reinforcement learning', 'off-policy evaluation', 'A/B testing']","Randomized experiments (a.k.a. A/B tests) are a powerful tool for estimating treatment effects, to inform decisions making in business, healthcare and other applications. In many problems, the treatment has a lasting effect that evolves over time. A limitation with randomized experiments is that they do not easily extend to measure long-term effects, since running long experiments is time-consuming and expensive. In this paper, we take a reinforcement learning (RL) approach that estimates the average reward in a Markov process. Motivated by real-world scenarios where the observed state transition is nonstationary, we develop a new algorithm for a class of nonstationary problems, and demonstrate promising results in two synthetic datasets and one online store dataset.",https://openreview.net/pdf/693e8525df90817f1b0757b468adabfbceec5b7d.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=tHsu1olr9ZcQ,Variational Reparametrized Policy Learning with Differentiable Physics,"['Zhiao Huang', 'Litian Liang', 'Zhan Ling', 'Xuanlin Li', 'Chuang Gan', 'Hao Su']","['~Zhiao_Huang1', '~Litian_Liang1', '~Zhan_Ling2', '~Xuanlin_Li1', '~Chuang_Gan1', '~Hao_Su1']",['Differentiable Physics Reinforcement Learning'],"We study the problem of policy parameterization for reinforcement learning (RL) with high-dimensional continuous action space. Our goal is to find a good way to parameterize the policy of continuous RL as a multi-modality distribution. To this end, we propose to treat the continuous RL policy as a generative model over the distribution of optimal trajectories. We use a diffusion process-like strategy to model the policy and derive a novel variational bound which is the optimization objective to learn the policy. To maximize the objective by gradient descent, we introduce the Reparameterized Policy Gradient Theorem. This theorem elegantly connects classical method REINFORCE and trajectory return optimization for computing the gradient of a policy. Moreover, our method enjoys strong exploration ability due to the multi-modality policy parameterization; notably, when a strong differentiable world model presents, our method also enjoys the fast convergence speed of trajectory optimization. We evaluate our method on numerical problems and manipulation tasks within a differentiable simulator. Qualitative results show its ability to capture the multi-modality distribution of optimal trajectories, and quantitative results show that it can avoid local optima and outperforms baseline approaches.",https://openreview.net/pdf/4bb6ca9d02ccb14c66ebf2c868d1edfdf199b98b.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=swEskiem99,Feature selection and low test error in shallow low-rotation ReLU networks,['Matus Telgarsky'],['~Matus_Telgarsky1'],"['gradient descent', 'gradient flow', 'margin maximization', 'test error', 'neural collapse', 'generalization']","This work establishes low test error of gradient flow (GF) and stochastic gradient descent (SGD) on two-layer ReLU networks with standard initialization scale, in three regimes where key sets of weights rotate little (either naturally due to GF and SGD, or due to an artificial constraint), and making use of margins as the core analysis technique. The first regime is near initialization, specifically until the weights have moved by $\mathcal{O}(\sqrt m)$, where $m$ denotes the network width, which is in sharp contrast to the $\mathcal{O}(1)$ weight motion allowed by the Neural Tangent Kernel (NTK); here it is shown that GF and SGD only need a network width and number of samples inversely proportional to the NTK margin, and moreover that GF attains at least the NTK margin itself and in particular escapes bad KKT points of the margin objective, whereas prior work could only establish nondecreasing but arbitrarily small margins. The second regime is the Neural Collapse (NC) setting, where data lies in well-separated groups, and the sample complexity scales with the number of groups; here the contribution over prior work is an analysis of the entire GF trajectory from initialization. Lastly, if the inner layer weights are constrained to change in norm only and can not rotate, then GF with large widths achieves globally maximal margins, and its sample complexity scales with their inverse; this is in contrast to prior work, which required infinite width and a tricky dual convergence assumption.
",https://openreview.net/pdf/fcbfd7f8d46076e87300ed63c39d60a6e8c11a7e.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=shzu8d6_YAR,FaiREE: fair classification with finite-sample and distribution-free guarantee,"['Puheng Li', 'James Zou', 'Linjun Zhang']","['~Puheng_Li1', '~James_Zou1', '~Linjun_Zhang1']","['algorithmic fairness', 'distribution-free', 'finite-sample', 'classification']","Algorithmic fairness plays an increasingly critical role in machine learning research. Several group fairness notions and algorithms have been proposed. However, the fairness guarantee of existing fair classification methods mainly depend on specific data distributional assumptions, often requiring large sample sizes, and fairness could be violated when there is a modest number of samples, which is often the case in practice. In this paper, we propose FaiREE, a fair classification algorithm which can satisfy group fairness constraints with finite-sample and distribution-free theoretical guarantees. FaiREE can be adapted to satisfying various group fairness notions (e.g., Equality of Opportunity, Equalized Odds, Demographic Parity, etc.) and achieve the optimal accuracy. These theoretical guarantees are further supported by experiments on both synthetic and real data. FaiREE is shown to have favorable performance over state-of-the-art algorithms.",https://openreview.net/pdf/0ef42c8eae510f399cb004342de52a2a9b3005e3.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=sPCKNl5qDps,Ollivier-Ricci Curvature for Hypergraphs: A Unified Framework,"['Corinna Coupette', 'Sebastian Dalleiger', 'Bastian Rieck']","['~Corinna_Coupette1', '~Sebastian_Dalleiger1', '~Bastian_Rieck1']","['curvature', 'hypergraphs', 'graphs', 'Wasserstein distance', 'topological data analysis', 'random walks', 'probability measure']","Bridging geometry and topology, curvature is a powerful and expressive invariant. While the utility of curvature has been theoretically and empirically confirmed in the context of manifolds and graphs, its generalization to the emerging domain of hypergraphs has remained largely unexplored. On graphs, the Ollivier-Ricci curvature measures differences between random walks via Wasserstein distances, thus grounding a geometric concept in ideas from probability theory and optimal transport. We develop Orchid, a flexible framework generalizing Ollivier-Ricci curvature to hypergraphs, and prove that the resulting curvatures have favorable theoretical properties. Through extensive experiments on synthetic and real-world hypergraphs from different domains, we demonstrate that Orchid curvatures are both scalable and useful to perform a variety of hypergraph tasks in practice.",https://openreview.net/pdf/cf1554077cc4c42ade51993934dbe9c8c16d4ef0.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=sMsShmoszg,Mind the Privacy Budget: How Generative Models Spend their Privacy Budgets,"['Georgi Ganev', 'Kai Xu', 'Emiliano De Cristofaro']","['~Georgi_Ganev1', '~Kai_Xu4', '~Emiliano_De_Cristofaro1']","['synthetic data', 'differential privacy', 'generative models', 'graphical models', 'GANs']","Numerous Differentially Private (DP) generative models have been presented that aim to produce synthetic data while minimizing privacy risks.
As there is no single model that works well in all settings, empirical analysis is needed to establish and optimize trade-offs vis-\`a-vis the intended use of the synthetic data.
In this paper, we identify and address several challenges in the empirical evaluation of such models.
First, we analyze the steps in which different algorithms ``spend'' their privacy budget.
We evaluate the effects on the performance of downstream tasks to identify problem settings they are most likely to be successful at.
Then, we experiment with increasingly wider and taller training sets with various features, decreasing privacy budgets, and different DP mechanisms and generative models.

Our empirical evaluation, performed on both graphical and deep generative models, sheds light on the distinctive features of different models/mechanisms that make them well-suited for different settings and tasks.
Graphical models distribute the privacy budget horizontally and cannot handle relatively wide datasets, while the performance on the task they were optimized for monotonically increases with more data.
Deep generative models spend their budget per iteration, and their behavior is less predictable with varying dataset dimensions, but could perform better if trained on more features.
Also, low levels of privacy ($\epsilon\geq100$) could help some models generalize, achieving better results than without applying DP.",https://openreview.net/pdf/daaecd76c5fd7ec4ba7da0be8aa9e5cccaa35aa4.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=sKWlRDzPfd7,MAESTRO: Open-Ended Environment Design for Multi-Agent Reinforcement Learning,"['Mikayel Samvelyan', 'Akbir Khan', 'Michael D Dennis', 'Minqi Jiang', 'Jack Parker-Holder', 'Jakob Nicolaus Foerster', 'Roberta Raileanu', 'Tim Rocktäschel']","['~Mikayel_Samvelyan1', '~Akbir_Khan1', '~Michael_D_Dennis1', '~Minqi_Jiang1', '~Jack_Parker-Holder1', '~Jakob_Nicolaus_Foerster1', '~Roberta_Raileanu2', '~Tim_Rocktäschel1']","['reinforcement learning', 'multi-agent learning', 'unsupervised environment design']","Open-ended learning methods that automatically generate a curriculum of increasingly challenging tasks serve as a promising avenue toward generally capable reinforcement learning agents. Existing methods adapt curricula independently over either environment parameters (in single-agent settings) or co-player policies (in multi-agent settings). However, the strengths and weaknesses of co-players can manifest themselves differently depending on environmental features. It is thus crucial to consider the dependency between the environment and co-player when shaping a curriculum in multi-agent domains. In this work, we use this insight and extend Unsupervised Environment Design (UED) to multi-agent environments. We then introduce Multi-Agent Environment Design Strategist for Open-Ended Learning (MAESTRO), the first multi-agent UED approach for two-player zero-sum settings. MAESTRO efficiently produces adversarial, joint curricula over both environments and co-players and attains minimax-regret guarantees at Nash equilibrium. Our experiments show that MAESTRO outperforms a number of strong baselines on competitive two-player games, spanning discrete and continuous control settings.",https://openreview.net/pdf/e65b3ee9b4e5db11d48c773dc4e02702868ef8e6.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=sKDtBKYOdIP,Beam Tree Recursive Cells,"['Jishnu Ray Chowdhury', 'Cornelia Caragea']","['~Jishnu_Ray_Chowdhury2', '~Cornelia_Caragea2']","['Recursive Neural Networks', 'RvNNs', 'length generalization', 'systematicity']","Recursive Neural Networks (RvNNs) generalize Recurrent Neural Networks (RNNs) by allowing sequential composition in a more flexible order, typically, based on some tree structure. While initially user-annotated tree structures were used, in due time, several approaches were proposed to automatically induce tree-structures from raw text to guide the recursive compositions in RvNNs. In this paper, we present an approach called Beam Tree Recursive Cell (or BT-Cell) based on a simple yet overlooked backpropagation-friendly framework. BT-Cell applies beam search on easy-first parsing for simulating RvNNs with automatic structure-induction. Our results show that BT-Cell achieves near-perfect performance on several aspects of challenging structure-sensitive synthetic tasks like ListOps and also comparable performance in realistic data to other RvNN-based models. We further introduce and analyze several extensions of BT-Cell based on relaxations of the hard top-k operators in beam search. We evaluate the models in different out of distribution splits in both synthetic and realistic data. Additionally, we identify a previously unknown failure case for neural models in generalization to unseen number of arguments in ListOps. We will release our code.",https://openreview.net/pdf/aa2e1e69e8e0fe1ed5ec53bac9e9268a7b9c2336.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=rde9B5ue32F,Compressed Predictive Information Coding,"['Rui Meng', 'Tianyi Luo', 'Kristofer Bouchard']","['~Rui_Meng3', '~Tianyi_Luo2', '~Kristofer_Bouchard1']","['Predictive information', 'time series', 'variational inference']","Unsupervised learning plays an important role in many fields, such as machine learning, data compression, and neuroscience. Compared to static data, methods for extracting low-dimensional structure for dynamic data are lagging. We developed a novel information-theoretic framework, Compressed Predictive Information Coding (CPIC), to extract predictive latent representations from dynamic data. Predictive information quantifies the ability to predict the future of a time series from its past. CPIC selectively projects the past (input) into a low dimensional space that is predictive about the compressed data projected from the future (output). The key insight of our framework is to learn representations by balancing the minimization of compression complexity with maximization of the predictive information in the latent space. We derive tractable variational bounds of the CPIC loss by leveraging bounds on mutual information. The CPIC loss induces the latent space to capture information that is maximally predictive of the future of the data from the past. We demonstrate that introducing stochasticity in the encoder and maximizing the predictive information in latent space contributes to learning more robust latent representations. Furthermore, our variational approaches perform better in mutual information estimation compared with estimates under the Gaussian assumption commonly used. We show numerically in synthetic data that CPIC can recover dynamical systems embedded in noisy observation data with low signal-to-noise ratio. Finally, we demonstrate that CPIC extracts features more predictive of forecasting exogenous variables as well as auto-forecasting in various real datasets compared with other state-of-the-art representation learning models. Together, these results indicate that CPIC will be broadly useful for extracting low-dimensional dynamic structure from high-dimensional, noisy time-series data.",https://openreview.net/pdf/e31289b8891e15176d39fb5f99092ca98df29324.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=raU07GpP0P,Improving Deep Regression with Ordinal Entropy,"['Shihao Zhang', 'Linlin Yang', 'Michael Bi Mi', 'Xiaoxu Zheng', 'Angela Yao']","['~Shihao_Zhang1', '~Linlin_Yang1', '~Michael_Bi_Mi1', '~Xiaoxu_Zheng1', '~Angela_Yao1']","['regression', 'classification', 'entropy', 'depth estimation', 'counting', 'age estimation']","In computer vision, it is often observed that formulating regression problems as a classification task yields better performance. We investigate this curious phenomenon and provide a derivation to show that classification, with the cross-entropy loss, outperforms regression with a mean squared error loss in its ability to learn high-entropy feature representations. Based on the analysis, we propose an ordinal entropy loss to encourage higher-entropy feature spaces while maintaining ordinal relationships to improve the performance of regression tasks. Experiments on synthetic and real-world regression tasks demonstrate the importance and benefits of increasing entropy for regression.",https://openreview.net/pdf/3fa28db76e89d4a3ce4e48a57a415e706ad74b51.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=r9hNv76KoT3,Rethinking the Expressive Power of GNNs via Graph Biconnectivity,"['Bohang Zhang', 'Shengjie Luo', 'Liwei Wang', 'Di He']","['~Bohang_Zhang1', '~Shengjie_Luo1', '~Liwei_Wang1', '~Di_He1']","['Graph Neural Networks', 'Expressive Power', 'Weisfeiler-Lehman test', 'Graph Transformer', 'Biconnectivity']","Designing expressive Graph Neural Networks (GNNs) is a central topic in learning graph-structured data. While numerous approaches have been proposed to improve GNNs with respect to the Weisfeiler-Lehman (WL) test, for most of them, there is still a lack of deep understanding of what additional power they can systematically and provably gain. In this paper, we take a fundamentally different perspective to study the expressive power of GNNs beyond the WL test. Specifically, we introduce a novel class of expressivity metrics via graph biconnectivity and highlight their importance in both theory and practice. As biconnectivity can be easily calculated using simple algorithms that have linear computational costs, it is natural to expect that popular GNNs can learn it easily as well. However, after a thorough review of prior GNN architectures, we surprisingly find that most of them are not expressive for any of these metrics. The only exception is the ESAN framework (Bevilacqua et al., 2022), for which we give a theoretical justification of its power. We proceed to introduce a principled and more efficient approach, called the Generalized Distance Weisfeiler-Lehman (GD-WL), which is provably expressive for all biconnectivity metrics. Practically, we show GD-WL can be implemented by a Transformer-like architecture that preserves expressiveness and enjoys full parallelizability. A set of experiments on both synthetic and real datasets demonstrates that our approach can consistently outperform prior GNN architectures.",https://openreview.net/pdf/be0ebeff1b3c008481709874f052f374a1d68dec.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=r0xte-t40I,Learning Human-Compatible Representations for Case-Based Decision Support,"['Han Liu', 'Yizhou Tian', 'Chacha Chen', 'Shi Feng', 'Yuxin Chen', 'Chenhao Tan']","['~Han_Liu12', '~Yizhou_Tian1', '~Chacha_Chen1', '~Shi_Feng1', '~Yuxin_Chen1', '~Chenhao_Tan1']","['human-compatible representation learning', 'human triplet judgments']","Algorithmic case-based decision support provides examples to help human make sense of predicted labels and aid human in decision-making tasks. Despite the promising performance of supervised learning, representations learned by supervised models may not align well with human intuitions: what models consider as similar examples can be perceived as distinct by humans. As a result, they have limited effectiveness in case-based decision support. In this work, we incorporate ideas from metric learning with supervised learning to examine the importance of alignment for effective decision support. In addition to instance-level labels, we use human-provided triplet judgments to learn human-compatible decision-focused representations. Using both synthetic data and human subject experiments in multiple classification tasks, we demonstrate that such representation is better aligned with human perception than representation solely optimized for classification. Human-compatible representations identify nearest neighbors that are perceived as more similar by humans and allow humans to make more accurate predictions, leading to substantial improvements in human decision accuracies (17.8% in butterfly vs. moth classification and 13.2% in pneumonia classification).",https://openreview.net/pdf/8a16439b8778f846cdadf78cfd6ce542a48cbfbe.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=quCOIL8JQnp,Improving Adversarial Robustness by Contrastive Guided Diffusion Process,"['Yidong Ouyang', 'Liyan Xie', 'Guang Cheng']","['~Yidong_Ouyang1', '~Liyan_Xie2', '~Guang_Cheng1']",[],"Synthetic data generation has become an emerging tool to help improve the adversarial robustness in classification tasks since robust learning requires a significantly larger amount of training samples compared with standard classification tasks. Among various deep generative models, the diffusion model has been shown to produce high-quality synthetic images and has achieved good performance in improving the adversarial robustness. However, diffusion-type methods are typically slow in data generation as compared with other generative models. Although different acceleration techniques have been proposed recently, it is also of great importance to study how to improve the sample efficiency of generated data for the downstream task. In this paper, we first analyze the optimality condition of synthetic distribution for achieving non-trivial robust accuracy. We show that enhancing the distinguishability among the generated data is critical for improving adversarial robustness. Thus, we propose the Contrastive-Guided Diffusion Process (Contrastive-DP), which adopts the contrastive loss to guide the diffusion model in data generation. We verify our theoretical results using simulations and demonstrate the good performance of Contrastive-DP on image datasets.",https://openreview.net/pdf/df68fb33d3112faeae607e91d4d1dcd318d633a3.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=qihMOPw4Sf_,Valid P-Value for Deep Learning-driven Salient Region,"['Miwa Daiki', 'Vo Nguyen Le Duy', 'Ichiro Takeuchi']","['miwa.daiki.mllab.nit@gmail.com', '~Vo_Nguyen_Le_Duy1', '~Ichiro_Takeuchi1']","['Saliency Map', 'Attention', 'Selective Inference', 'Uncertainty Quantification', 'P-value', 'Statistical Hypothesis Testing']","Various saliency map methods have been proposed to interpret and explain predictions of deep learning models. Saliency maps allow us to interpret which parts of the input signals have a strong influence on the prediction results. However, since a saliency map is obtained by complex computations in deep learning models, it is often difficult to know how reliable the saliency map itself is. In this study, we propose a method to quantify the reliability of a saliency region in the form of p-values. Our idea is to consider a saliency map as a selected hypothesis by the trained deep learning model and employ the selective inference framework. The proposed method provably provides a valid p-value for the detected salient region, i.e., we can provably control the false positive rate of the detected salient region. We demonstrate the validity of the proposed method through numerical examples in synthetic and real datasets. Furthermore, we develop a Keras-based framework for conducting the proposed selective inference for a wide class of CNNs without additional implementation cost.",https://openreview.net/pdf/4648f8cd96b71924f57fd9418c3d9e7fe45ce8c8.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=qU6NIcpaSi-,Learning Heterogeneous Interaction Strengths by Trajectory Prediction with Graph Neural Network,"['Seungwoong Ha', 'Hawoong Jeong']","['~Seungwoong_Ha1', 'hjeong@kaist.edu']","['relational learning', 'complex systems', 'dynamic systems', 'graph learning']","Dynamical systems with interacting agents are universal in nature, commonly modeled by a graph of relationships between their constituents. Recently, various works have been presented to tackle the problem of inferring those relationships from the system trajectories via deep neural networks, but most of the studies assume binary or discrete types of interactions for simplicity. In the real world, the interaction kernels often involve continuous interaction strengths, which cannot be accurately approximated by discrete relations. In this work, we propose the relational attentive inference network (RAIN) to infer continuously weighted interaction graphs without any ground-truth interaction strengths. Our model employs a novel pairwise attention (PA) mechanism to refine the trajectory representations and a graph transformer to extract heterogeneous interaction weights for each pair of agents. We show that our RAIN model with the PA mechanism accurately infers continuous interaction strengths for simulated physical systems in an unsupervised manner. Further, RAIN with PA successfully predicts trajectories from motion capture data with an interpretable interaction graph, demonstrating the virtue of modeling unknown dynamics with continuous weights.",https://openreview.net/pdf/d2a42a569af4609051ef2c5ee6d8844663d49142.pdf,{'title_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=qLKammDlpF,Fusion over the Grassmann Manifold for Incomplete-Data Clustering,"['Jeremy Scott Johnson', 'Huanran Li', 'Chun Gan', 'Zheng Lu', 'Matthew Malloy', 'Daniel L. Pimentel-Alarcón']","['~Jeremy_Scott_Johnson1', '~Huanran_Li1', '~Chun_Gan1', '~Zheng_Lu5', '~Matthew_Malloy1', '~Daniel_L._Pimentel-Alarcón1']","['high-rank matrix completion', 'subspace clustering', 'manifold learning']","This paper presents a new paradigm to cluster incomplete vectors using subspaces as proxies to exploit the geometry of the Grassmannian. We leverage this new perspective to develop an algorithm to cluster and complete data in a union of subspaces via a fusion penalty formulation. Our approach does not require prior knowledge of the number of subspaces, is naturally suited to handle noise, and only requires an upper bound on the subspaces’ dimensions. In developing our model, we present local convergence guarantees. We describe clustering, completion, model selection, and sketching techniques that can be used in practice, and complement our analysis with synthetic and real-data experiments.",https://openreview.net/pdf/fb8cb9c0430aa29664c0a8339ed19eaa2ab5d855.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=qFVVBzXxR2V,Language Models Are Greedy Reasoners: A Systematic Formal Analysis of Chain-of-Thought,"['Abulhair Saparov', 'He He']","['~Abulhair_Saparov1', '~He_He2']","['large language models', 'reasoning', 'question answering', 'chain-of-thought', 'in-context learning']","Large language models (LLMs) have shown remarkable reasoning capabilities given chain-of-thought prompts (examples with intermediate reasoning steps). Existing benchmarks measure reasoning ability indirectly, by evaluating accuracy on downstream tasks such as mathematical reasoning. However, it is unclear how these models obtain the answers and whether they rely on simple heuristics rather than the generated chain-of-thought. To enable systematic exploration of the reasoning ability of LLMs, we present a new synthetic question-answering dataset called PrOntoQA, where each example is generated from a synthetic world model represented in first-order logic. This allows us to parse the generated chain-of-thought into symbolic proofs for formal analysis. Our analysis on InstructGPT and GPT-3 shows that LLMs are quite capable of making correct individual deduction steps, and so are generally capable of reasoning, even in fictional contexts. However, they have difficulty with proof planning: When multiple valid deduction steps are available, they are not able to systematically explore the different options.",https://openreview.net/pdf/e73172f359a19430928855ff049b5dd1e7a4d987.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=q4qocCgE3uM,MARLlib: Extending RLlib for Multi-agent Reinforcement Learning,"['Siyi Hu', 'Yifan Zhong', 'Minquan Gao', 'Weixun Wang', 'Hao Dong', 'Zhihui Li', 'Xiaodan Liang', 'Yaodong Yang', 'Xiaojun Chang']","['~Siyi_Hu1', '~Yifan_Zhong2', '~Minquan_Gao1', '~Weixun_Wang1', '~Hao_Dong3', '~Zhihui_Li1', '~Xiaodan_Liang2', '~Yaodong_Yang1', '~Xiaojun_Chang1']",['MARL'],"Despite the fast development of multi-agent reinforcement learning (MARL) methods, there is a lack of commonly-acknowledged baseline implementation and evaluation platforms. As a result, an urgent need for MARL researchers is to develop an integrated library suite, similar to the role of RLlib in single-agent RL, that delivers reliable MARL implementation and replicable evaluation in various bechmarks. To fill such a research gap, in this paper, we propose Multi-Agent RLlib (MARLlib), a comprehensive MARL algorithm library that facilitates RLlib for solving multi-agent problems. With a novel design of agent-level distributed dataflow, MARLlib manages to unify tens of algorithms, including different types of independent learning, centralized critic, and value decomposition methods; this leads to a highly composable integration of MARL algorithms that are not possible to unify before. Furthermore, MARLlib goes beyond current work by integrating diverse environment interfaces and providing flexible parameter sharing strategies; this allows to create versatile solutions to  cooperative, competitive, and mixed tasks with minimal code modifications for end users. A plethora of experiments  are conducted to substantiate the correctness of our implementation, based on which we further derive new insights on the relationship between the  performance and the design of algorithmic components. With MARLlib, we expect researchers to be able to tackle broader real-world multi-agent problems with trustworthy solutions. Our code\footnote{\url{https://github.com/ICLR2023Paper4242/MARLlib}} and documentation\footnote{\url{https://iclr2023marllib.readthedocs.io/}} are released for reference.",https://openreview.net/pdf/04ba705e659133d6bcc9f84de40160913411a7f5.pdf,{'abstract_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=q3F0UBAruO,Towards Effective and Interpretable Human-Agent Collaboration in MOBA Games: A Communication Perspective,"['Yiming Gao', 'Feiyu Liu', 'Liang Wang', 'Zhenjie Lian', 'Weixuan Wang', 'Siqin Li', 'Xianliang Wang', 'Xianhan Zeng', 'Rundong Wang', 'jiawei wang', 'QIANG FU', 'Yang Wei', 'Lanxiao Huang', 'Wei Liu']","['~Yiming_Gao4', '~Feiyu_Liu1', '~Liang_Wang10', '~Zhenjie_Lian1', '~Weixuan_Wang1', '~Siqin_Li1', '~Xianliang_Wang1', '~Xianhan_Zeng1', '~Rundong_Wang1', '~jiawei_wang2', '~QIANG_FU8', '~Yang_Wei2', '~Lanxiao_Huang1', '~Wei_Liu3']","['game playing', 'multi-agent', 'human-ai communication', 'human-ai collaboration', 'deep reinforcement learning']","MOBA games, e.g., Dota2 and Honor of Kings, have been actively used as the testbed for the recent AI research on games, and various AI systems have been developed at the human level so far. However, these AI systems mainly focus on how to compete with humans, less on exploring how to collaborate with humans. To this end, this paper makes the first attempt to investigate human-agent collaboration in MOBA games. In this paper, we propose to enable humans and agents to collaborate through explicit communication by designing an efficient and interpretable Meta-Command Communication-based framework, dubbed MCC, for accomplishing effective human-agent collaboration in MOBA games. The MCC framework consists of two pivotal modules: 1) an interpretable communication protocol, i.e., the Meta-Command, to bridge the communication gap between humans and agents; 2) a meta-command value estimator, i.e., the Meta-Command Selector, to select a valuable meta-command for each agent to achieve effective human-agent collaboration. Experimental results in Honor of Kings demonstrate that MCC agents can collaborate reasonably well with human teammates and even generalize to collaborate with different levels and numbers of human teammates. Videos are available at https://sites.google.com/view/mcc-demo.",https://openreview.net/pdf/05be94f6c3da0d1f97a06aaecf42515ddc07d159.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=q2vsXnsjNB_,ConserWeightive Behavioral Cloning for Reliable Offline Reinforcement Learning,"['Tung Nguyen', 'Qinqing Zheng', 'Aditya Grover']","['~Tung_Nguyen2', '~Qinqing_Zheng1', '~Aditya_Grover1']","['offline RL', 'behavioral cloning', 'conservatism']","The goal of offline reinforcement learning (RL) is to learn near-optimal policies from static logged datasets, thus sidestepping expensive online interactions. Behavioral cloning (BC) provides a straightforward solution to offline RL by mimicking offline trajectories via supervised learning. Recent advances~\cite{chen2021decision, janner2021offline, emmons2021rvs} have shown that by conditioning on desired future returns, BC can perform competitively to their value-based counterparts, while enjoying much more simplicity and training stability. However, the distribution of returns in the offline dataset can be arbitrarily skewed and suboptimal, which poses a unique challenge for conditioning BC on expert returns at test-time. We propose ConserWeightive Behavioral Cloning (\name), a simple and effective method for improving the performance of conditional BC for offline RL with two key components: trajectory weighting and conservative regularization. Trajectory weighting addresses the bias-variance tradeoff in conditional BC and provides a principled mechanism to learn from both low return trajectories (typically plentiful) and high return trajectories (typically few). Further, we analyze the notion of conservatism in existing BC methods, and propose a novel conservative regularizer that explicitly encourages the policy to stay close to the data distribution. The regularizer helps achieve more reliable performance, and removes the need for ad-hoc tuning of the conditioning value during evaluation. We instantiate \name{} in the context of Reinforcement Learning via Supervised Learning (RvS)~\cite{emmons2021rvs} and Decision Transformer (DT)~\citep{chen2021decision}, and empirically show that it significantly boosts the performance and stability of prior methods on various offline RL benchmarks.",https://openreview.net/pdf/e96627d536d6dc8b87a9863dee93c760d899ad2e.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=q-PbpHD3EOk,Learning Fast and Slow for Online Time Series Forecasting,"['Quang Pham', 'Chenghao Liu', 'Doyen Sahoo', 'Steven Hoi']","['~Quang_Pham1', '~Chenghao_Liu1', '~Doyen_Sahoo1', '~Steven_Hoi2']","['online time series forecasting', 'continual learning']","Despite the recent success of deep learning for time series forecasting, these methods are not scalable for many real-world applications where data arrives sequentially. Training deep neural forecasters on the fly is notoriously challenging because of their limited ability to adapt to non-stationary environments and remember old knowledge. We argue that the fast adaptation capability of deep neural networks is critical and successful solutions require handling changes to both new and recurring patterns effectively. In this work, inspired by the Complementary Learning Systems (CLS) theory, we propose Fast and Slow learning Network (FSNet) as a novel framework to address the challenges of online forecasting. Particularly, FSNet improves the slowly-learned backbone by dynamically balancing fast adaptation to recent changes and retrieving similar old knowledge. FSNet achieves this mechanism via an interaction between two novel complementary components: (i) a per-layer adapter to support fast learning from individual layers, and (ii) an associative memory to support remembering, updating, and recalling repeating events. Extensive experiments on real and synthetic datasets validate FSNet's efficacy and robustness to both new and recurring patterns. Our code is publicly available at: \url{https://github.com/salesforce/fsnet/}.",https://openreview.net/pdf/44160e05022c0f1eeba06011cd69f40c1abe57b3.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=pxStyaf2oJ5,Domain-Indexing Variational Bayes: Interpretable Domain Index for Domain Adaptation,"['Zihao Xu', 'Guang-Yuan Hao', 'Hao He', 'Hao Wang']","['~Zihao_Xu2', '~Guang-Yuan_Hao1', '~Hao_He1', '~Hao_Wang3']",[],"Previous studies have shown that leveraging ""domain index"" can significantly boost domain adaptation performance (Wang et al., 2020; Xu et al., 2022). However, such domain indices are not always available. To address this challenge, we first provide a formal definition of domain index from the probabilistic perspective, and then propose an adversarial variational Bayesian framework that infers domain indices from multi-domain data, thereby providing additional insight on domain relations and improving domain adaptation performance. Our theoretical analysis shows that our adversarial variational Bayesian framework finds the optimal domain index at equilibrium. Empirical results on both synthetic and real data verify that our model can produce interpretable domain indices which enable us to achieve superior performance compared to state-of-the-art domain adaptation methods. Code is available at https://github.com/Wang-ML-Lab/VDI.",https://openreview.net/pdf/4340ecd2eb1d6cddf23d0257a4ab36cd01fba41e.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=pm7O7gJObtk,NIERT: Accurate Numerical Interpolation through Unifying Scattered Data Representations using Transformer Encoder,"['Shizhe Ding', 'Dongbo Bu']","['~Shizhe_Ding2', '~Dongbo_Bu1']","['numerical interpolation', 'transformer encoder', 'mask mechanism', 'pre-training model']","Numerical interpolation for scattered data, i.e., estimating values for target points based on those of some observed points, is widely used in  computational science and engineering. The existing approaches either require explicitly pre-defined basis functions, which makes them inflexible and limits their performance in practical scenarios, or train neural networks as interpolators, which still have limited interpolation accuracy as they treat observed and target points separately and cannot effectively exploit the correlations among data points. Here, we present a learning-based approach to numerical interpolation for scattered data using encoder representation of Transformers (called NIERT). Unlike the recent learning-based approaches, NIERT treats observed and target points in a unified fashion through embedding them into the same representation space, thus gaining the advantage of  effectively exploiting the correlations among them. The specially-designed partial self-attention mechanism used by NIERT makes it escape from the unexpected interference of target points on observed points. We further show that the partial self-attention is essentially a learnable interpolation module combining multiple neural basis functions, which provides interpretability of NIERT. Through pre-training on large-scale synthetic datasets,  NIERT achieves considerable improvement in interpolation accuracy for practical tasks. On both synthetic and real-world datasets, NIERT  outperforms the existing approaches, e.g., on the TFRD-ADlet dataset for temperature field reconstruction, NIERT achieves an MAE of $1.897\times 10^{-3}$, substantially better than the state-of-the-art  approach (MAE: $27.074\times 10^{-3}$).  The source code of NIERT is available at  https://anonymous.4open.science/r/NIERT-2BCF.",https://openreview.net/pdf/a0f6d830ec74e59d52bccf2cb4e3736bdd6ab295.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=pgJp7rDc_hk,Coreset for Rational Functions,"['David Denisov', 'Ibrahim Jubran', 'Dan Feldman']","['~David_Denisov1', '~Ibrahim_Jubran1', '~Dan_Feldman1']","['Coreset', 'Auto-regression', 'rational functions', 'non-convex optimization']","We consider the problem of fitting a rational function $f:\mathbb{R}\to\mathbb{R}$ to a time-series $g:\{1,\cdots,n\}\to\mathbb{R}$. This is by minimizing the sum of distances (loss function) $\ell(f):=\sum_{i=1}^n |f(i)-g(i)|$, possibly with additional constraints and regularization terms that may depend on $f$. Our main motivation is to approximate such a time-series by a recursive sequence model $F_n=\sum_{i=1}^k \theta_i F_{n-i}$, e.g. a Fibonacci sequence, where $\theta\in \mathbb{R}^k$ are the model parameters, and $k\geq1$ is constant.
For $\varepsilon\in(0,1)$, an $\varepsilon$-coreset for this problem is a small data structure that approximates $\ell(g)$ up to $1\pm\varepsilon$ multiplicative factor, for every rational function $g$ of constant degree.
We prove that every signal has an $\varepsilon$-coreset of size $O(n^{0.001}/\varepsilon^2)$, and provide a construction algorithm that computes it in $O(n^{1.001})$ time.
Open source code is provided, as well as extensive experimental results, on both real and synthetic datasets, which compare our method to existing solvers from Scipy.",https://openreview.net/pdf/1f70add33d89167e0abad3640d14807aa9595389.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=pX21pH4CsNB,Differentially Private Diffusion Models,"['Tim Dockhorn', 'Tianshi Cao', 'Arash Vahdat', 'Karsten Kreis']","['~Tim_Dockhorn1', '~Tianshi_Cao1', '~Arash_Vahdat3', '~Karsten_Kreis1']","['Diffusion models', 'Differential Privacy', 'Generative Modeling']","While modern machine learning models rely on increasingly large training datasets, data is often limited in privacy-sensitive domains. Generative models trained with differential privacy (DP) on sensitive data can sidestep this challenge, providing access to synthetic data instead. However, training DP generative models is highly challenging due to the noise injected into training to enforce DP. We propose to leverage diffusion models (DMs), an emerging class of deep generative models, and introduce Differentially Private Diffusion Models (DPDMs), which enforce privacy using differentially private stochastic gradient descent (DP-SGD). We motivate why DP-SGD is well suited for training DPDMs, and thoroughly investigate the DM parameterization and the sampling algorithm, which turn out to be crucial ingredients in DPDMs. Furthermore, we propose noise multiplicity, a simple yet powerful modification of the DM training objective tailored to the DP setting to boost performance. We validate our novel DPDMs on widely-used image generation benchmarks and achieve state-of-the-art (SOTA) performance by large margins. For example, on MNIST we improve the SOTA FID from 48.4 to 5.01 and downstream classification accuracy from 83.2% to 98.1% for the privacy setting DP-$(\varepsilon=10, \delta=10^{-5})$. Moreover, on standard benchmarks, classifiers trained on DPDM-generated synthetic data perform on par with task-specific DP-SGD-trained classifiers, which has not been demonstrated before for DP generative models.",https://openreview.net/pdf/80b3c1437da640596290ef697263339b9b5b129a.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=p4bZLgHUB6L,Learn Low-dimensional Shortest-path Representation of Large-scale and Complex Graphs,"['Haoyu Wang', 'Chun Yuan', 'Lei Li', 'Jiahui Jin']","['~Haoyu_Wang1', '~Chun_Yuan1', '~Lei_Li12', '~Jiahui_Jin1']","['shortest-path distance', 'graph representation learning', 'random walk']","Estimation of shortest-path (SP) distance lies at the heart of network analysis tasks. Along with the rapid emergence of large-scale and complex graphs, approximate SP-representing algorithms that transform a graph into compact and low-dimensional representations are critical for fast and scalable online analysis. Among different approaches, learning-based representation methods have made a breakthrough both in response time and accuracy. Several competitive works in learning-based methods heuristically leverage truncated random walk and optimization on the arbitrary linkage for SP representation learning. However, they have limitations on both exploration range and distance preservation. We propose in this paper an efficient and interpretable SP representation method called Betweenness Centrality-based Distance Resampling (BCDR). First, we prove that betweenness centrality-based random walk can occupy a wider exploration range of distance due to its awareness of high-order path structures. Second, we leverage distance resampling to simulate random shortest paths from original paths and prove that the optimization on such shortest paths preserves distance relations via implicitly decomposing SP distance-based similarity matrix. BCDR yields an average improvement of 25% accuracy and 25-30% query speed, compared to all existing approximate methods when evaluated on a broad class of real-world and synthetic graphs with diverse sizes and structures.",https://openreview.net/pdf/cda4b61f3b2e14b9a6b37a3241b06325fecf5fdd.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=p0MBhpO5wQ,Rethinking the Explanation of Graph Neural Network via Non-parametric Subgraph Matching,"['Fang Wu', 'Lirong Wu', 'Siyuan Li', 'Dragomir Radev', 'Wenbing Huang']","['~Fang_Wu1', '~Lirong_Wu1', '~Siyuan_Li6', '~Dragomir_Radev2', '~Wenbing_Huang1']","['Graph Neural Networks', 'Graph Matching', 'Explanation']","The great success in graph neural networks (GNNs) provokes the question about explainability: ``Which fraction of the input graph is the most determinant to the prediction?'' However, current approaches usually resort to a black-box to decipher another black-box (i.e., GNN), making it difficult to understand how the explanation is made. Based on the observation that graphs typically share some joint motif patterns, we propose a novel subgraph matching framework named MatchExplainer to explore explanatory subgraphs. 
It couples the target graph with other counterpart instances and identifies the most crucial joint substructure by minimizing the node corresponding-based distance between them. After that, an external graph ranking is followed to select the most informative substructure from all subgraph candidates. Thus, MatchExplainer is entirely non-parametric. 
Moreover, present graph sampling or node dropping methods usually suffer from the false positive sampling problem. To ameliorate that issue, we take advantage of MatchExplainer to fix the most informative portion of the graph and merely operate graph augmentations on the rest less informative part, which is dubbed as MatchDrop. 
We conduct extensive experiments on both synthetic and real-world datasets, showing the effectiveness of our MatchExplainer by outperforming all parametric baselines with large margins. Additional results also demonstrate that our MatchDrop is a general paradigm to be equipped with GNNs for enhanced performance.",https://openreview.net/pdf/9d53b55fbc0dadcccdcb198a65f156a5b7d0ca03.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=oo-X0K4XAn,Neural Constraint Inference: Inferring Energy Constraints in Interacting Systems,"['Armand Comas', 'Yilun Du', 'Sandesh Ghimire', 'Christian Fernandez Lopez', 'Mario Sznaier', 'Joshua B. Tenenbaum', 'Octavia Camps']","['~Armand_Comas1', '~Yilun_Du1', '~Sandesh_Ghimire2', '~Christian_Fernandez_Lopez1', '~Mario_Sznaier1', '~Joshua_B._Tenenbaum1', '~Octavia_Camps1']","['relational inference', 'energy-based models', 'energy constraints', 'trajectory prediction', 'graph neural networks']","Systems consisting of interacting agents are prevalent in the world, ranging from dynamical systems in physics to complex biological networks. To build systems which can interact robustly in the real world, it is thus important to be able to infer the precise interactions governing such systems.  Existing approaches typically discover such interactions by explicitly modeling the feedforward dynamics of the trajectories. In this work, we propose Neural Constraint Inference (NCI) model as an alternative approach to discover such interactions: it discovers a set of relational constraints, represented as energy functions, which when optimized reconstruct the original trajectory. We illustrate how NCI can faithfully predict future trajectory dynamics, achieving  more consistent long-rollouts than existing approaches. We show that the constraints discovered by NCI are disentangled and may be intermixed with constraints from other trajectories. Finally, we illustrate how those constraints enable the incorporation of external test-time constraints.",https://openreview.net/pdf/30028c09947aab35f10c7eb0d1e277a9caecb8a7.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=ohQPU2G3r3C,Faster Hyperparameter Search for GNNs via Calibrated Dataset Condensation,"['Mucong Ding', 'Xiaoyu Liu', 'Tahseen Rabbani', 'Teresa Ranadive', 'Tai-Ching Tuan', 'Furong Huang']","['~Mucong_Ding1', '~Xiaoyu_Liu3', '~Tahseen_Rabbani1', 'tranadive@lps.umd.edu', 'tctuan@lps.umd.edu', '~Furong_Huang1']","['Graph Condensation', 'Dataset Condensation', 'Hyperparameter Optimization', 'Graph Neural Networks', 'Graph Compression']","Dataset condensation aims to reduce the computational cost of training multiple models on a large dataset by condensing the training dataset into a small synthetic set. State-of-the-art approaches rely on matching the model gradients for the real and synthetic data and have recently been applied to condense large-scale graphs for node classification tasks. Although dataset condensation may be efficient when training multiple models for hyperparameter optimization, there is no theoretical guarantee on the generalizability of the condensed data: data condensation often generalizes poorly across hyperparameters/architectures in practice, while we find and prove this overfitting is much more severe on graphs. In this paper, we consider a different condensation objective specifically geared towards hyperparameter search. We aim to generate the synthetic dataset so that the validation-performance rankings of the models, with different hyperparameters, on the condensed and original datasets are comparable. We propose a novel hyperparameter-calibrated dataset condensation algorithm, which obtains the synthetic validation data by matching the hyperparameter gradients computed via implicit differentiation and efficient inverse Hessian approximation. HCDC employs a supernet with differentiable hyperparameters, making it suitable for modeling GNNs with widely different convolution filters. Experiments demonstrate that the proposed framework effectively maintains the validation-performance rankings of GNNs and speeds up hyperparameter/architecture search on graphs.",https://openreview.net/pdf/ffb89454a92c83824e2754db20f608d907ce4731.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=oap4aDN9yS2,Bi-Level Dynamic Parameter Sharing among Individuals and Teams for Promoting Collaborations in Multi-Agent Reinforcement Learning,"['Yan Liu', 'Ying Tiffany He', 'Fei Yu', 'Zhong Ming']","['~Yan_Liu17', '~Ying_Tiffany_He1', '~Fei_Yu13', '~Zhong_Ming1']","['Multi-Agent Reinforcement Learning', 'Reinforcement Learning']","Parameter sharing has greatly contributed to the success of multi-agent reinforcement learning in recent years. However, most existing parameter sharing mechanisms are static, and parameters are indiscriminately shared among individuals, ignoring the dynamic environments and different roles of multiple agents. In addition, although a single-level selective parameter sharing mechanism can promote the diversity of strategies, it is hard to establish complementary and cooperative relationships between agents. To address these issues, we propose a bi-level dynamic parameter sharing mechanism among individuals and teams for promoting effective collaborations (BDPS). Specifically, at the individual level, we define virtual dynamic roles based on the long-term cumulative advantages of agents and share parameters among agents in the same role. At the team level, we combine agents of different virtual roles and share parameters of agents in the same group. Through the joint efforts of these two levels, we achieve a dynamic balance between the individuality and commonality of agents, enabling agents to learn more complex and complementary collaborative relationships. We evaluate BDPS on a challenging set of StarCraft II micromanagement tasks. The experimental results show that our method outperforms the current state-of-the-art baselines, and we demonstrate the reliability of our proposed structure through ablation experiments.",https://openreview.net/pdf/a5306aac11abd8d0df98e4099859e8b005f6ef17.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=nhKHA59gXz,Self-Stabilization: The Implicit Bias of Gradient Descent at the Edge of Stability,"['Alex Damian', 'Eshaan Nichani', 'Jason D. Lee']","['~Alex_Damian1', '~Eshaan_Nichani1', '~Jason_D._Lee1']","['gradient descent', 'optimization', 'edge of stability', 'implicit regularization', 'implicit bias']","Traditional analyses of gradient descent show that when the largest eigenvalue of the Hessian, also known as the sharpness $S(\theta)$, is bounded by $2/\eta$, training is ""stable"" and the training loss decreases monotonically. Recent works, however, have observed that this assumption does not hold when training modern neural networks with full batch or large batch gradient descent. Most recently, Cohen at al. (2021) detailed two important phenomena. The first, dubbed \emph{progressive sharpening}, is that the sharpness steadily increases throughout training until it reaches the instability cutoff $2/\eta$. The second, dubbed \emph{edge of stability}, is that the sharpness hovers at $2/\eta$ for the remainder of training while the loss continues decreasing, albeit non-monotonically. We demonstrate that, far from being chaotic, the dynamics of gradient descent at the edge of stability can be captured by a cubic Taylor expansion: as the iterates diverge in direction of the top eigenvector of the Hessian due to instability, the cubic term in the local Taylor expansion of the loss function causes the curvature to decrease until stability is restored. This property, which we call \emph{self-stabilization}, is a general property of gradient descent and explains its behavior at the edge of stability. A key consequence of self-stabilization is that gradient descent at the edge of stability implicitly follows \emph{projected} gradient descent (PGD) under the constraint $S(\theta) \le 2/\eta$. Our analysis provides precise predictions for the loss, sharpness, and deviation from the PGD trajectory throughout training, which we verify both empirically in a number of standard settings and theoretically under mild conditions. Our analysis uncovers the mechanism for gradient descent's implicit bias towards stability.",https://openreview.net/pdf/5ce767b4f951bb7db5b2c04af424d1c59c1e9387.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=nYWqxUwFc3x,Learning Vortex Dynamics for Fluid Inference and Prediction,"['Yitong Deng', 'Hong-Xing Yu', 'Jiajun Wu', 'Bo Zhu']","['~Yitong_Deng1', '~Hong-Xing_Yu1', '~Jiajun_Wu1', '~Bo_Zhu2']",[],"We propose a novel differentiable vortex particle (DVP) method to infer and predict fluid dynamics from a single video. Lying at its core is a particle-based latent space to encapsulate the hidden, Lagrangian vortical evolution underpinning the observable, Eulerian flow phenomena. Our differentiable vortex particles are coupled with a learnable, vortex-to-velocity dynamics mapping to effectively capture the complex flow features in a physically-constrained, low-dimensional space. This representation facilitates the learning of a fluid simulator tailored to the input video that can deliver robust, long-term future predictions. The value of our method is twofold: first, our learned simulator enables the inference of hidden physics quantities (e.g., velocity field) purely from visual observation; secondly, it also supports future prediction, constructing the input video's sequel along with its future dynamics evolution. We compare our method with a range of existing methods on both synthetic and real-world videos, demonstrating improved reconstruction quality, visual plausibility, and physical integrity.",https://openreview.net/pdf/2027a65f6a0320b8b07a33d5d3ff6b1cb6a0580a.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=nUmCcZ5RKF,IS SYNTHETIC DATA FROM GENERATIVE MODELS READY FOR IMAGE RECOGNITION?,"['Ruifei He', 'Shuyang Sun', 'Xin Yu', 'Chuhui Xue', 'Wenqing Zhang', 'Philip Torr', 'Song Bai', 'XIAOJUAN QI']","['~Ruifei_He1', '~Shuyang_Sun1', '~Xin_Yu6', '~Chuhui_Xue2', '~Wenqing_Zhang1', '~Philip_Torr1', '~Song_Bai3', '~XIAOJUAN_QI2']","['data generation', 'image recognition', 'text-to-image synthesis']","Recent text-to-image generation models have shown promising results in generating high-fidelity photo-realistic images. Though the results are astonishing to human eyes, how applicable these generated images are for recognition tasks remains under-explored. In this work, we extensively study whether and how synthetic images generated from state-of-the-art text-to-image generation models can be used for image recognition tasks, and focus on two perspectives: synthetic data for improving classification models in the data-scare settings (i.e. zero-shot and few-shot), and synthetic data for large-scale model pre-training for transfer learning. We showcase the powerfulness and shortcomings of synthetic data from existing generative models, and propose strategies for better applying synthetic data for recognition tasks. Code: https://github.com/CVMI-Lab/SyntheticData. ",https://openreview.net/pdf/530478d6bc03dbd80ae4d0e00c93647edd522adc.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=nIGza1_wxk,Model Transferability with Responsive Decision Subjects ,"['Yang Liu', 'Yatong Chen', 'Zeyu Tang', 'Kun Zhang']","['~Yang_Liu3', '~Yatong_Chen1', '~Zeyu_Tang1', '~Kun_Zhang1']","['transferability', 'responsive decision subjects', 'induced distribution shift', 'human-ML interaction', 'performance bound']","This paper studies model transferability when human decision subjects respond to a deployed machine learning model. In our setting, an agent or a user corresponds to a sample $(X,Y)$ drawn from a distribution $\mathcal{D}$ and will face a model $h$ and its classification result $h(X)$. Agents can modify $X$ to adapt to $h$, which will incur a distribution shift on $(X,Y)$. Therefore, when training $h$, the learner will need to consider the subsequently ``induced"" distribution when the output model is deployed. Our formulation is motivated by applications where the deployed machine learning models interact with human agents, and will ultimately face \emph{responsive} and interactive data distributions. We formalize the discussions of the transferability of a model by studying how the model trained on the available source distribution (data) would translate to the performance on the induced domain. We provide both upper bounds for the performance gap due to the induced domain shift, as well as lower bound for the trade-offs that a classifier has to suffer on either the source training distribution or the induced target distribution. We provide further instantiated analysis for two popular domain adaptation settings with covariate shift and target shift.",https://openreview.net/pdf/9f8fc08ed653c3511babee63e9f40cb240dab2f0.pdf,{'abstract_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=n1bLgxHW6jW,Zeroth-Order Optimization with Trajectory-Informed Derivative Estimation,"['Yao Shu', 'Zhongxiang Dai', 'Weicong Sng', 'Arun Verma', 'Patrick Jaillet', 'Bryan Kian Hsiang Low']","['~Yao_Shu1', '~Zhongxiang_Dai1', '~Weicong_Sng1', '~Arun_Verma1', '~Patrick_Jaillet1', '~Bryan_Kian_Hsiang_Low1']","['zeroth-order optimization', 'derivative estimation', 'finite difference']","Zeroth-order (ZO) optimization, in which the derivative is unavailable, has recently succeeded in many important machine learning applications. Existing algorithms rely on finite difference (FD) methods for derivative estimation and gradient descent (GD)-based approaches for optimization. However, these algorithms suffer from query inefficiency because many additional function queries are required for derivative estimation in their every GD update, which typically hinders their deployment in real-world applications where every function query is expensive. To this end, we propose a trajectory-informed derivative estimation method which only employs the optimization trajectory (i.e., the history of function queries during optimization) and hence can eliminate the need for additional function queries to estimate a derivative. Moreover, based on our derivative estimation, we propose the technique of dynamic virtual updates, which allows us to reliably perform multiple steps of GD updates without reapplying derivative estimation. Based on these two contributions, we introduce the zeroth-order optimization with trajectory-informed derivative estimation (ZoRD) algorithm for query-efficient ZO optimization. We theoretically demonstrate that our trajectory-informed derivative estimation and our ZoRD algorithm improve over existing approaches, which is then supported by our real-world experiments such as black-box adversarial attack, non-differentiable metric optimization, and derivative-free reinforcement learning.",https://openreview.net/pdf/83be469cfb05989fdaa09e9ae079b8dd86eecccc.pdf,{'title_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=moIlFZfj_1b,Latent Neural ODEs with Sparse Bayesian Multiple Shooting,"['Valerii Iakovlev', 'Cagatay Yildiz', 'Markus Heinonen', 'Harri Lähdesmäki']","['~Valerii_Iakovlev1', '~Cagatay_Yildiz1', '~Markus_Heinonen1', '~Harri_Lähdesmäki1']",[],"Training dynamic models, such as neural ODEs, on long trajectories is a hard problem that requires using various tricks, such as trajectory splitting, to make model training work in practice. These methods are often heuristics with poor theoretical justifications, and require iterative manual tuning. We propose a principled multiple shooting technique for neural ODEs that splits the trajectories into manageable short segments, which are optimized in parallel, while ensuring probabilistic control on continuity over consecutive segments. We derive variational inference for our shooting-based latent neural ODE models and propose amortized encodings of irregularly sampled trajectories with a transformer-based recognition network with temporal attention and relative positional encoding. We demonstrate efficient and stable training, and state-of-the-art performance on multiple large-scale benchmark datasets.",https://openreview.net/pdf/071adbc58872effe03fcbbb9ee55c07fab778bd9.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=mfIX4QpsARJ,EAGLE: Large-scale Learning of Turbulent Fluid Dynamics with Mesh Transformers,"['Steeven JANNY', 'Aurélien Bénéteau', 'Madiha Nadri', 'Julie Digne', 'Nicolas THOME', 'Christian Wolf']","['~Steeven_JANNY2', '~Aurélien_Bénéteau1', '~Madiha_Nadri1', '~Julie_Digne1', '~Nicolas_THOME2', '~Christian_Wolf5']","['Learning Fluid Mechanics', 'Simulation', 'Graph networks']","Estimating fluid dynamics is classically done through the simulation and integration of numerical models solving the Navier-Stokes equations, which is computationally complex and time-consuming even on high-end hardware. This is a notoriously hard problem to solve, which has recently been addressed with machine learning, in particular graph neural networks (GNN) and variants trained and evaluated on datasets of static objects in static scenes with fixed geometry. We attempt to go beyond existing work in complexity and introduce a new model, method and benchmark. We propose EAGLE: a large-scale dataset of ∼1.1 million 2D meshes resulting from simulations of unsteady fluid dynamics caused by a moving flow source interacting with nonlinear scene structure of varying geometries, with 600 different scenes of three different types in total. To perform future forecasting of pressure and velocity on the challenging EAGLE dataset, we introduce a new mesh transformer. It leverages node clustering, graph pooling and global attention to learn long-range dependencies between spatially distant data points without needing a large number of iterations, as existing GNN methods do. We show that our transformer outperforms state-of-the-art performance on, both, existing synthetic and real datasets and on EAGLE. Finally, we highlight that our approach learns to attend to airflow, integrating complex information in a single iteration.",https://openreview.net/pdf/09aee140cdc4dcf6fcc6f93e1be103f7e4d37584.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=me09xlTmm8,Transport with Support: Data-Conditional Diffusion Bridges,"['Ella Tamir', 'Martin Trapp', 'Arno Solin']","['~Ella_Tamir1', '~Martin_Trapp2', '~Arno_Solin1']","['diffusion models', 'optimal transport', 'particle filtering', 'stochastic control', 'sequential Monte Carlo']","The dynamic Schrödinger bridge problem provides an appealing setting for posing optimal transport problems as learning non-linear diffusion processes and enables efficient iterative solvers. Recent works have demonstrated state-of-the-art results (eg, in modelling single-cell embryo RNA sequences or sampling from complex posteriors) but are typically limited to learning bridges with only initial and terminal constraints. Our work extends this paradigm by proposing the Iterative Smoothing Bridge (ISB). We combine learning diffusion models with Bayesian filtering and optimal control, allowing for constrained stochastic processes governed by sparse observations at intermediate stages and terminal constraints. We assess the effectiveness of our method on synthetic and real-world data and show that the ISB generalises well to high-dimensional data, is computationally efficient, and provides accurate estimates of the marginals at intermediate and terminal times. ",https://openreview.net/pdf/da8b6fd7f6b624d5851c386395325541be03d90e.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=mduJQSy7KE,Meta-Weighted Language Model Tuning for Augmentation-Enhanced Few-Shot Learning,"['Yu Meng', 'Martin Michalski', 'Jiaxin Huang', 'Yu Zhang', 'Tarek Abdelzaher', 'Jiawei Han']","['~Yu_Meng1', '~Martin_Michalski1', '~Jiaxin_Huang1', '~Yu_Zhang26', '~Tarek_Abdelzaher1', '~Jiawei_Han1']","['Few-Shot Learning', 'Natural Language Understanding']","Recent studies have revealed the intriguing few-shot learning ability of pretrained language models (PLMs): They can quickly adapt to a new task when fine-tuned on a small amount of labeled data formulated as prompts, without requiring abundant task-specific annotations. Despite their promising performance, most existing few-shot approaches that only learn from the small training set still underperform fully supervised training by nontrivial margins. In this work, we study few-shot learning with PLMs from a different perspective: We first tune an autoregressive PLM on the few-shot samples and then use it as a generator to synthesize a large amount of novel training samples which augment the original training set. To encourage the generator to produce label-discriminative samples, we train it via weighted maximum likelihood where the weight of each token is automatically adjusted based on a discriminative meta-learning objective. A classification PLM can then be fine-tuned on both the few-shot and the synthetic samples with regularization for better generalization and stability. Our approach FewGen achieves an overall better result across seven classification tasks of the GLUE benchmark than existing few-shot learning methods.",https://openreview.net/pdf/50d66620b5f01201047a2cf8af74c89a53ba89eb.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=mcJvCys7DX7,Counterfactual Generation Under Confounding,"['Abbavaram Gowtham Reddy', 'Saloni Dash', 'Amit Sharma', 'Vineeth N. Balasubramanian']","['~Abbavaram_Gowtham_Reddy1', 'salonidash77@gmail.com', '~Amit_Sharma3', '~Vineeth_N._Balasubramanian2']","['counterfactual', 'confounding', 'cycleGAN', 'classification']","A machine learning model, under the influence of observed or unobserved confounders in the training data, can learn spurious correlations and fail to generalize when deployed. For image classifiers, augmenting a training dataset using counterfactual examples has been empirically shown to break spurious correlations.  However, the counterfactual generation task itself becomes more difficult as the level of confounding increases. Existing methods for counterfactual generation under confounding consider a fixed set of interventions (e.g., texture, rotation) and are not flexible enough to capture diverse data-generating processes. Given a causal generative process, we formally characterize the adverse effects of confounding on any downstream tasks and show that the correlation between generative factors (attributes) can be used to quantitatively measure confounding between generative factors. To minimize such correlation, we propose a counterfactual generation method that learns to modify the value of any attribute in an image and generate new images given a set of observed attributes, even when the dataset is highly confounded. These counterfactual images are then used to regularize the downstream classifier such that the learned representations are the same across various generative factors conditioned on the class label. Our method is computationally efficient, simple to implement, and works well for any number of generative factors and confounding variables. Our experimental results on both synthetic (MNIST variants) and real-world (CelebA) datasets show the usefulness of our approach.",https://openreview.net/pdf/e7eee5a5d5e72e5ad1a1d0f15e71d12b1b497f42.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=mb7PtrUbHa,Skill Decision Transformer,"['Shyam Sudhakaran', 'Sebastian Risi']","['~Shyam_Sudhakaran1', '~Sebastian_Risi1']","['Transformer', 'Offline Reinforcement Learning']","Recent work has shown that Large Language Models (LLMs) can be incredibly effective for offline reinforcement learning (RL) by representing the traditional RL problem as a sequence modelling problem. However many of these methods only optimize for high returns, and may not extract much information from a diverse dataset of trajectories. Generalized Decision Transformers (GDTs)  have shown that by utilizing future trajectory information, in the form of information statistics, can help extract more information from offline trajectory data. Building upon this, we propose Skill Decision Transformer (Skill DT). Skill DT draws inspiration from hindsight relabelling and skill discovery methods to discover a diverse set of \emph{primitive behaviors}, or skills. We show that Skill DT can not only perform offline state-marginal matching (SMM), but can discovery descriptive behaviors that can be easily sampled. Furthermore, we show that through purely reward-free optimization, Skill DT is still competitive with supervised offline RL approaches on the D4RL benchmark.",https://openreview.net/pdf/4346de4e9114548caf57d3cabb1d218902d9bb95.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=mX56bKDybu5,Neural Radiance Field Codebooks,"['Matthew Wallingford', 'Aditya Kusupati', 'Alex Fang', 'Vivek Ramanujan', 'Aniruddha Kembhavi', 'Roozbeh Mottaghi', 'Ali Farhadi']","['~Matthew_Wallingford1', '~Aditya_Kusupati1', '~Alex_Fang1', '~Vivek_Ramanujan1', '~Aniruddha_Kembhavi1', '~Roozbeh_Mottaghi1', '~Ali_Farhadi3']","['Object-Centric Representation Learning', 'Representation Learning', 'Neural Radiance Fields']","Compositional representations of the world are a promising step towards enabling high-level scene understanding and efficient transfer to downstream tasks. Learning such representations for complex scenes and tasks remains an open challenge. Towards this goal, we introduce Neural Radiance Field Codebooks (NRC), a scalable method for learning object-centric representations through novel view reconstruction. NRC learns to reconstruct scenes from novel views using a dictionary of object codes which are decoded through a volumetric renderer. This enables the discovery of reoccurring visual and geometric patterns across scenes which are transferable to downstream tasks. We show that NRC representations transfer well to object navigation in THOR, outperforming 2D and 3D representation learning methods by 3.1\% success rate. We demonstrate that our approach is able to perform unsupervised segmentation for more complex synthetic (THOR) and real scenes (NYU Depth) better than prior methods (.101 ARI). Finally, we show that NRC improves on the task of depth ordering by 5.5% accuracy in THOR.",https://openreview.net/pdf/b938c8f0acccd59571a25bc4c07a69bf24a26be3.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=mVn2JGzlET,Partial transportability for domain generalization,"['Alexis Bellot', 'Elias Bareinboim']","['~Alexis_Bellot1', '~Elias_Bareinboim2']","['Causality', 'domain generalization']","Learning prediction models that generalize to related domains is one of the most fundamental challenges in artificial intelligence. There exists a growing literature that argues for learning invariant associations using data from multiple source domains. However, whether invariant predictors generalize to a given target domain depends crucially on the assumed structural changes between domains. Using the perspective of transportability theory, we show that invariance learning, and the settings in which invariant predictors are optimal in terms of worst-case losses, is a special case of a more general partial transportability task. Specifically, the partial transportability task seeks to identify / bound a conditional expectation $\mathbb E_{P_{\pi^*}}[y\mid\mathbf x]$ in an unseen domain $\pi^*$ using knowledge of qualitative changes across domains in the form of causal graphs and data from source domains $\pi^1,\dots,\pi^k$. We show that solutions to this problem have a much wider generalization guarantee that subsumes those of invariance learning and other robust optimization methods that are inspired by causality. For computations in practice, we develop an algorithm that provably provides tight bounds asymptotically in the number of data samples from source domains for any partial transportability problem with discrete observables and illustrate its use on synthetic datasets. ",https://openreview.net/pdf/269b72af4fe951aceb0ae0c226bec28f0e2c77d4.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=mBkUeW8rpD6,DiscoBAX - Discovery of optimal intervention sets in genomic experiment design,"['Clare Lyle', 'Arash Mehrjou', 'Pascal Notin', 'Andrew Jesson', 'Stefan Bauer', 'Yarin Gal', 'Patrick Schwab']","['~Clare_Lyle1', '~Arash_Mehrjou1', '~Pascal_Notin1', '~Andrew_Jesson1', '~Stefan_Bauer1', '~Yarin_Gal1', '~Patrick_Schwab1']","['Optimal experiment design', 'Bayesian Algorithm Execution', 'Active learning', 'Genetic intervention', 'Drug design']","The discovery of novel therapeutics to cure genetic pathologies relies on the identification of the different genes involved in the underlying disease mechanism. With billions of potential hypotheses to test, an exhaustive  exploration of the entire space of potential interventions is impossible in practice. Sample-efficient methods based on active learning or bayesian optimization bear the promise of identifying interesting targets using the least experiments possible. However, genomic perturbation experiments typically rely on proxy outcomes measured in biological model systems that may not completely correlate with the outcome of interventions in humans. In practical experiment design, one aims to find a set of interventions which maximally move a target phenotype via a diverse set of mechanisms in order to reduce the risk of failure in future stages of trials. To that end, we introduce DiscoBAX — a sample-efficient algorithm for the discovery of genetic interventions that maximize the movement of a phenotype in a direction of interest while covering a diverse set of underlying mechanisms. We provide theoretical guarantees on the optimality of the approach under standard assumptions, conduct extensive experiments in synthetic and real-world settings relevant to genomic discovery and demonstrate that DiscoBAX outperforms state-of-the-art active learning and Bayesian optimization methods in this task. Better methods for selecting effective and diverse perturbations in biological systems could enable researchers to potentially discover novel therapeutics for a range of genetically-driven diseases.",https://openreview.net/pdf/51adb7bf889afdfb6e66bf261d3a9ad9fc7a6e03.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=lXMlDL78Alx,Causal Attention to Exploit Transient Emergence of Causal Effect,"['Xiaolei Ru', 'Xin-Ya Zhang', 'Jack Murdoch Moore', 'Gang Yan']","['~Xiaolei_Ru1', '~Xin-Ya_Zhang1', '~Jack_Murdoch_Moore1', '~Gang_Yan2']","['causal attention mechanism', 'coupling-drive', 'sparse causal effect', 'neural dynamics', 'causal network reconstruction']","We propose a causal reasoning mechanism called $\textit{causal attention}$ that can improve performance of machine learning models on a class of causal inference tasks by revealing the generation process behind the observed data. We consider the problem of reconstructing causal networks (e.g., biological neural networks) connecting large numbers of variables (e.g., nerve cells), of which evolution is governed by nonlinear dynamics consisting of weak coupling-drive (i.e., causal effect) and strong self-drive (dominants the evolution). The core difficulty is sparseness of causal effect that emerges (the coupling force is significant) only momentarily and otherwise remains dormant in the neural activity sequence. $\textit{Causal attention}$ is designed to guide the model to make inference focusing on the critical regions of time series data where causality may manifest. Specifically, attention coefficients are assigned autonomously by a neural network trained to maximise the Attention-extended Transfer Entropy, which is a novel generalization of the iconic transfer entropy metric. Our results show that, without any prior knowledge of dynamics, $\textit{causal attention}$ explicitly identifies areas where the strength of coupling-drive is distinctly greater than zero. This innovation substantially improves reconstruction performance for both synthetic and real causal networks using data generated by neuronal models widely used in neuroscience.",https://openreview.net/pdf/1b78da17b9da4589e4845f01df383929a8ec92dc.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=lTt4KjHSsyl,Emergence of Maps in the Memories of Blind Navigation Agents,"['Erik Wijmans', 'Manolis Savva', 'Irfan Essa', 'Stefan Lee', 'Ari S. Morcos', 'Dhruv Batra']","['~Erik_Wijmans1', '~Manolis_Savva1', '~Irfan_Essa1', '~Stefan_Lee1', '~Ari_S._Morcos1', '~Dhruv_Batra1']","['embodied AI', 'navigation', 'characterizing representations']","Animal navigation research posits that organisms build and maintain internal spa- tial representations, or maps, of their environment. We ask if machines – specifically, artificial intelligence (AI) navigation agents – also build implicit (or ‘mental’) maps. A positive answer to this question would (a) explain the surprising phenomenon in recent literature of ostensibly map-free neural-networks achieving strong performance, and (b) strengthen the evidence of mapping as a fundamental mechanism for navigation by intelligent embodied agents, whether they be biological or artificial. Unlike animal navigation, we can judiciously design the agent’s perceptual system and control the learning paradigm to nullify alternative navigation mechanisms. Specifically, we train ‘blind’ agents – with sensing limited to only egomotion and no other sensing of any kind – to perform PointGoal navigation (‘go to $\Delta$x, $\Delta$y’) via reinforcement learning. Our agents are composed of navigation-agnostic components (fully-connected and recurrent neural networks), and our experimental setup provides no inductive bias towards mapping. Despite these harsh conditions, we find that blind agents are (1) surprisingly effective navigators in new environments (∼95% success); (2) they utilize memory over long horizons (remembering ∼1,000 steps of past experience in an episode); (3) this memory enables them to exhibit intelligent behavior (following walls, detecting collisions, taking shortcuts); (4) there is emergence of maps and collision detection neurons in the representations of the environment built by a blind agent as it navigates; and (5) the emergent maps are selective and task dependent (e.g. the agent ‘forgets’ exploratory detours). Overall, this paper presents no new techniques for the AI audience, but a surprising finding, an insight, and an explanation.",https://openreview.net/pdf/6aff51942ab3664378283e5da2b36db1cd04db62.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=lGz9u1ubUXE,Relative Behavioral Attributes: Filling the Gap between Symbolic Goal Specification and Reward Learning from Human Preferences,"['Lin Guan', 'Karthik Valmeekam', 'Subbarao Kambhampati']","['~Lin_Guan1', '~Karthik_Valmeekam1', '~Subbarao_Kambhampati1']","['Neuro-Symbolic', 'Human-AI Interaction']","Generating complex behaviors that satisfy the preferences of non-expert users is a crucial requirement for AI agents. Interactive reward learning from trajectory comparisons (a.k.a. RLHF) is one way to allow non-expert users to convey complex objectives by expressing preferences over short clips of agent behaviors. Even though this parametric method can encode complex tacit knowledge present in the underlying tasks, it implicitly assumes that the human is unable to provide richer feedback than binary preference labels, leading to intolerably high feedback complexity and poor user experience. While providing a detailed symbolic closed-form specification of the objectives might be tempting, it is not always feasible even for an expert user. However, in most cases, humans are aware of how the agent should change its behavior along meaningful axes to fulfill their underlying purpose, even if they are not able to fully specify task objectives symbolically. Using this as motivation, we introduce the notion of Relative Behavioral Attributes, which allows the users to tweak the agent behavior through symbolic concepts (e.g., increasing the softness or speed of agents' movement). We propose two practical methods that can learn to model any kind of behavioral attributes from ordered behavior clips. We demonstrate the effectiveness of our methods on four tasks with nine different behavioral attributes, showing that once the attributes are learned, end users can produce desirable agent behaviors relatively effortlessly, by providing feedback just around ten times. This is over an order of magnitude less than that required by the popular learning-from-human-preferences baselines. The supplementary video and source code are available at: https://guansuns.github.io/pages/rba.",https://openreview.net/pdf/8ddd06f0bef80e495ca1650eb74874f576793c38.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=lEkl0jdSb7B,Any-scale Balanced Samplers for Discrete Space,"['Haoran Sun', 'Bo Dai', 'Charles Sutton', 'Dale Schuurmans', 'Hanjun Dai']","['~Haoran_Sun2', '~Bo_Dai1', '~Charles_Sutton1', '~Dale_Schuurmans1', '~Hanjun_Dai1']","['MCMC', 'Discrete Space Sampling', 'Locally Balanced Proposal']","The locally balanced informed proposal has proved to be highly effective for sampling from discrete spaces. However, its success relies on the ""local'' factor, which ensures that whenever the proposal distribution is restricted to be near the current state, the locally balanced weight functions are asymptotically optimal and the gradient approximations are accurate.  In seeking a more efficient sampling algorithm, many recent works have considered increasing the scale of the proposal distributions, but this causes the ""local'' factor to no longer hold. Instead, we propose any-scale balanced samplers to repair the gap in non-local proposals. In particular, we substitute the locally balanced function with an any-scale balanced function that can self-adjust to achieve better efficiency for proposal distributions at any scale. We also use quadratic approximations to capture curvature of the target distribution and reduce the error in the gradient approximation, while employing a Gaussian integral trick with a special estimated diagonal to efficiently sample from the quadratic proposal distribution. On various synthetic and real distributions, the proposed sampler substantially outperforms existing approaches.",https://openreview.net/pdf/52af7225d7de609b61840c7cb0d899b963a2013e.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=kvAQEZZ_BI1,Learning from conflicting data with hidden contexts,"['Tianren Zhang', 'Yizhou Jiang', 'Xin Su', 'Shangqi Guo', 'Chongkai Gao', 'Feng Chen']","['~Tianren_Zhang1', '~Yizhou_Jiang1', '~Xin_Su1', '~Shangqi_Guo2', '~Chongkai_Gao1', '~Feng_Chen1']","['Conflicting data', 'hidden contexts', 'subjective learning', 'multi-domain learning']","Classical supervised learning assumes a stable relation between inputs and outputs. However, this assumption is often invalid in real-world scenarios where the input-output relation in the data depends on some hidden contexts. We formulate a more general setting where the training data is sampled from multiple unobservable domains, while different domains may possess semantically distinct input-output maps. Training data exhibits inherent conflict in this setting, rendering vanilla empirical risk minimization problematic. We propose to tackle this problem by introducing an allocation function that learns to allocate conflicting data to different prediction models, resulting in an algorithm that we term LEAF. We draw an intriguing connection between our approach and a variant of the Expectation-Maximization algorithm. We provide theoretical justifications for LEAF on its identifiability, learnability, and generalization error. Empirical results demonstrate the efficacy and potential applications of LEAF in a range of regression and classification tasks on both synthetic data and real-world datasets.",https://openreview.net/pdf/e89c7abcdab7060e9736517761458c562edd25a2.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=krFbWKl3Sz,Achieving Communication-Efficient Policy Evaluation for Multi-Agent Reinforcement Learning: Local TD-Steps or Batching?,"['FNU Hairi', 'Zifan Zhang', 'Jia Liu']","['~FNU_Hairi1', 'zhang.9256@osu.edu', '~Jia_Liu1']",[],"In many consensus-based actor-critic multi-agent reinforcement learning (MARL) strategies, one of the key components is the MARL policy evaluation (PE) problem, where a set of $N$ agents work cooperatively to evaluate the value function of the global states under a given policy only through communicating with their neighbors.
In MARL-PE, a critical challenge is how to lower the communication complexity, which is defined as the rounds of communication between neighboring nodes in order to converge to some $\epsilon$-stationary point.
To lower communication complexity in MARL-PE, there exist two ``natural'' ideas: i) using batching to reduce the variance of TD (temporal difference) errors, which in turn improves the convergence rate of MARL-PE; and ii) performing multiple local TD update steps between each consecutive rounds of communication, so as to reduce the communication frequency.
While the effectiveness of the batching approach has been verified and relatively well-understood, the validity of the local TD-steps approach remains unclear due to the potential ``agent-drift'' phenomenon resulted from various heterogeneity factors across agents.
This leads to an interesting open question in MARL-PE: *Does the local TD-steps approach really work and how does it perform in comparison to the batching approach?*
In this paper, we take the first attempt to answer this interesting and fundamental question.
Our theoretical analysis and experimental results confirm that allowing multiple local TD steps is indeed a valid approach in lowering the communication complexity of MARL-PE compared to vanilla consensus-based MARL-PE algorithms.
Specifically, the local TD steps between two consecutive communication rounds can be as large as 
$\mathcal{O}(\sqrt{1/\epsilon}\log{(1/\epsilon)})$ in order to converge to an $\epsilon$-stationary point of MARL-PE. 
Theoretically, we show that in order to reach the optimal sample complexity up to a log factor, the communication complexity is $\mathcal{O}(\sqrt{1/\epsilon}\log{(1/\epsilon)})$, which is *considerably worse* than TD learning with batching, whose communication complexity is $\mathcal{O}(\log (1/\epsilon))$. However, the experimental results show that the allowing multiple steps can be as good as the batch approach. ",https://openreview.net/pdf/6c86aac15ef0304fc0b8012a40dbf8eee3c6ada2.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=khF4d1SRrGH,COFS: COntrollable Furniture layout Synthesis,"['Wamiq Reyaz Para', 'Paul Guerrero', 'Niloy Mitra', 'Peter Wonka']","['~Wamiq_Reyaz_Para1', '~Paul_Guerrero1', '~Niloy_Mitra1', '~Peter_Wonka1']","['generative modelling', 'conditional generation', 'layouts', 'transformers']","Realistic, scalable, and controllable generation of furniture layouts is essential for many applications in virtual reality, augmented reality, game development and synthetic data generation. The most successful current methods tackle this problem as a sequence generation problem which imposes a specific ordering on the elements of the layout, making it hard to exert fine-grained control over the attributes of a generated scene. Existing methods provide control through object-level conditioning, or scene completion, where generation can be conditioned on an arbitrary subset of furniture objects. However, attribute-level conditioning, where generation can be conditioned on an arbitrary subset of object attributes, is not supported. We propose COFS, a method to generate furniture layouts that enables fine-grained control through attribute-level conditioning. For example, COFS allows specifying only the scale and type of objects that should be placed in the scene and the generator chooses their positions and orientations; or the position that should be occupied by objects can be specified and the generator chooses their type, scale, orientation, etc. Our results show both qualitatively and quantitatively that we significantly outperform existing methods on attribute-level conditioning.",https://openreview.net/pdf/fc91c5266695fec4a2e41f98930228517f9faa06.pdf,{'title_filter': 'Data Synthesis'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=kcemndN1Tw,Deep Generative Model based Rate-Distortion for Image Downscaling Assessment,"['Yuanbang Liang', 'Bhavesh Garg', 'Paul L Rosin', 'Yipeng Qin']","['~Yuanbang_Liang1', 'bh05avesh@gmail.com', '~Paul_L_Rosin1', '~Yipeng_Qin1']",[],"In this paper, we propose a novel measure, namely Image Downscaling Assessment by Rate-Distortion (IDA-RD), to quantitatively evaluate image downscaling algorithms. In contrast to image-based methods that measure the quality of downscaled images, ours is process-based that draws ideas from the rate-distortion theory to measure the distortion incurred during downscaling. Our main idea is that downscaling and super-resolution (SR) can be viewed as the encoding and decoding processes in the rate-distortion model, respectively, and that a downscaling algorithm that preserves more details in the resulting low-resolution (LR) images should lead to less distorted high-resolution (HR) images in SR. In other words, the distortion should increase as the downscaling algorithm deteriorates. However, it is non-trivial to measure this distortion as it requires the SR algorithm to be blind and stochastic. Our key insight is that such requirements can be met by recent SR algorithms based on deep generative models that can find all matching HR images for a given LR image on their learned image manifolds. Empirically, we first validate our IDA-RD measure with synthetic downscaling algorithms which simulate distortions by adding various types and levels of degradations to the downscaled images. We then test our measure on traditional downscaling algorithms such as bicubic, bilinear, nearest neighbor interpolation as well as state-of-the-art downscaling algorithms such as DPID, L0-regularized downscaling, and Perceptual downscaling. Experimental results show the effectiveness of our IDA-RD in evaluating image downscaling algorithms.",https://openreview.net/pdf/bd1bd4cde5a7030a3caf47dd561d77d09137fb45.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=kL67fyKb6A,Online black-box adaptation to label-shift in the presence of conditional-shift,"['Faruk Ahmed', 'Aaron Courville']","['~Faruk_Ahmed1', '~Aaron_Courville3']","['label-shift', 'online', 'black-box', 'adaptation', 'Bayesian']","We consider an out-of-distribution setting where trained predictive models are deployed online in new locations (inducing conditional-shift), such that these locations are also associated with differently skewed target distributions (label-shift). While approaches for online adaptation to label-shift have recently been discussed by Wu et al. (2021), the potential presence of concurrent conditional-shift has not been considered in the literature, although one might anticipate such distributional shifts in realistic deployments. In this paper, we empirically explore the effectiveness of online adaptation methods in such situations on three synthetic and two realistic datasets, comprising both classification and regression problems. We show that it is possible to improve performance in these settings by learning additional hyper-parameters to account for the presence of conditional-shift by using appropriate validation sets. ",https://openreview.net/pdf/f6144c522d2971b6cfec7b624115016202bb2dd8.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=k-JvYGkA9o,How Normalization and Weight Decay Can Affect SGD? Insights from a Simple Normalized Model,"['Ruosi Wan', 'Qiaosen Wang', 'Xiangyu Zhang', 'Yu-Wing Tai', 'Jian Sun', 'Chi-Keung Tang']","['~Ruosi_Wan4', '~Qiaosen_Wang1', '~Xiangyu_Zhang1', '~Yu-Wing_Tai2', '~Jian_Sun4', '~Chi-Keung_Tang1']","['normalization', 'stochastic gradient descent', 'optimization']","Recent works(Li et al., 2020, Wan et al., 2021) characterize an important mechanism of normalized model trained with SGD and WD (Weight Decay), called Spherical Motion Dynamics (SMD), confirming its widespread effects in practice. However, no theoretical study is available on the influence of SMD on the training process of normalized models in literature. In this work, we seek to understand the effect of SMD by theoretically analyzing a simple normalized model, named as Noisy Rayleigh Quotient (NRQ). On NRQ, We theoretically prove SMD can dominate the whole training process via controlling the evolution of angular update (AU), an essential feature of SMD. Specifically, we show: 1) within equilibrium state of SMD, the convergence rate and limiting risk of NRQ are mainly determined by the theoretical value of AU; and 2) beyond equilibrium state, the evolution of AU can interfere the optimization trajectory, causing odd phenomena such as ``escape'' behavior. We further show the insights drawn from NRQ is consistent with empirical observations in experiments on real datasets. We believe our theoretical results shed new light on the role of normalization techniques during the training of modern deep learning models.",https://openreview.net/pdf/7ab1a96d414b7a98c0e7f7c134209d0ceacf31a3.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=jyHAGzMu-1Q,Learning to Communicate using Contrastive Learning ,"['Yat Long Lo', 'Biswa Sengupta', 'Jakob Nicolaus Foerster', 'Michael Noukhovitch']","['~Yat_Long_Lo1', '~Biswa_Sengupta5', '~Jakob_Nicolaus_Foerster1', '~Michael_Noukhovitch1']","['Reinforcement Learning', 'Multi-Agent Reinforcement Learning', 'Multi-Agent Communication']","Communication is a powerful tool for coordination in multi-agent RL.  Inducing an effective, common language has been a difficult challenge, particularly in the decentralized setting. In this work, we introduce an alternative perspective where communicative messages sent between agents are considered as different incomplete views of the environment state. Based on this perspective, we propose to learn to communicate using contrastive learning by maximizing the mutual information between messages of a given trajectory. In communication-essential environments, our method outperforms previous work in both performance and learning speed. Using qualitative metrics and representation probing, we show that our method induces more symmetric communication and captures task-relevant information from the environment. Finally, we demonstrate promising results on zero-shot communication, a first for MARL. Overall, we show the power of contrastive learning, and self-supervised learning in general, as a method for learning to communicate.",https://openreview.net/pdf/e901a42f1e5f6d94ecc4d7d03e3d6fcda30dfd85.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=jny79Mfgkno,Dealing with missing data using attention and latent space regularization,"['Jahan Che Penny-Dimri', 'Christoph Bergmeir', 'Julian Smith']","['~Jahan_Che_Penny-Dimri1', '~Christoph_Bergmeir1', 'julian.smith@monash.edu']","['missing data', 'missingness', 'latent space regularization', 'measure theory']","Most practical data science problems encounter missing data. A wide variety of solutions exist, each with strengths and weaknesses that depend upon the missingness-generating process. Here we develop a theoretical framework for training and inference using only observed variables enabling modeling of incomplete datasets without imputation. Using an information and measure-theoretic argument we construct models with latent space representations that regularize against the potential bias introduced by missing data. The theoretical properties of this approach are demonstrated empirically using a synthetic dataset. The performance of this approach is tested on 11 benchmarking datasets with missingness and 18 datasets corrupted across three missingness patterns with comparison against a state-of-the-art model and industry-standard imputation. We show that our proposed method outperforms common imputation methods and the current state-of-the-art with statistical significance.
",https://openreview.net/pdf/e7ab604c4a951e5e1412f357c07d4f1e98851318.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=jgmuRzM-sb6,DAG Matters! GFlowNets Enhanced Explainer for Graph Neural Networks,"['Wenqian Li', 'Yinchuan Li', 'Zhigang Li', 'Jianye HAO', 'Yan Pang']","['~Wenqian_Li1', '~Yinchuan_Li1', '~Zhigang_Li7', '~Jianye_HAO1', '~Yan_Pang1']","['GNN', 'Interpretability']","Uncovering rationales behind predictions of graph neural networks (GNNs) has received increasing attention over the years. Existing literature mainly focus on selecting a subgraph, through combinatorial optimization, to provide faithful explanations. However, the exponential size of candidate subgraphs limits the applicability of state-of-the-art methods to large-scale GNNs. We enhance on this through a different approach: by proposing a generative structure – GFlowNets-based GNN Explainer (GFlowExplainer), we turn the optimization problem into a step-by-step generative problem. Our GFlowExplainer aims to learn a policy that generates a distribution of subgraphs for which the probability of a subgraph is proportional to its’ reward. The proposed approach eliminates the influence of node sequence and thus does not need any pre-training strategies. We also propose a new cut vertex matrix to efficiently explore parent states for GFlowNets structure, thus making our approach applicable in a large-scale setting. We conduct extensive experiments on both synthetic and real datasets, and both qualitative and quantitative results show the superiority of our GFlowExplainer.",https://openreview.net/pdf/8a760853df1498c71ec2c328ac4842a2fcba52ee.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=jdEXFqGjdh,CI-VAE: a Class-Informed Deep Variational Autoencoder for Enhanced Class-Specific Data Interpolation,"['Mohsen Nabian', 'Zahra Eftekhari', 'Alec Wong']","['~Mohsen_Nabian1', 'zeftekhari@coh.org', 'alecwong@coh.org']","['Variational Auto Encoder', 'Supervised', 'Latent Space Traversal', 'Data Interpolation', 'Discriminator']","We proposed Class-Informed Variational Autoencoder (CI-VAE) to enable interpolation between arbitrary pairs of observations of the same class. CI-VAE combines the general VAE architecture with a linear discriminator layer on the latent space to enforce the construction of a latent space such that observations from different classes are linearly separable. In conventional VAEs, class overlapping on the latent space usually occurs. However, in CI-VAE, the enforced linear separability of classes on the latent space allows for robust latent-space linear traversal and data generation between two arbitrary observations of the same class. Class-specific data interpolation has extensive potential applications in science, particularly in biology, such as uncovering the biological trajectory of diseases or cancer. We used the MNIST dataset of handwritten digits as a case study to compare the performance of CI-VAE and VAE in class-specific data augmentation. We showed that CI-VAE significantly improved class-specific linear traversal and data augmentation compared with VAE while maintaining comparable reconstruction error. In a study of Colon cancer genomics data, we showed that the interpolation between normal cells and tumor cells using CI-VAE may enhance our understanding of cancer development. ",https://openreview.net/pdf/624f471b9f14ecb2d4fa00ab4342ef9a3d520854.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=jK02XX9ZpJkt,CAMA: A New Framework for Safe Multi-Agent Reinforcement Learning  Using Constraint Augmentation,"['Ziyan Wang', 'Yali Du', 'Aivar Sootla', 'Haitham Bou Ammar', 'Jun Wang']","['~Ziyan_Wang3', '~Yali_Du1', '~Aivar_Sootla1', '~Haitham_Bou_Ammar1', '~Jun_Wang2']","['Safe', 'Multi-agent Reinforcement Learning', 'Augmentation']","With the widespread application of multi-agent reinforcement learning (MARL) in real-life settings, the ability to meet safety constraints has become an urgent problem to solve. For example, it is necessary to avoid collisions to reach a common goal in controlling multiple drones. We address this problem by introducing the Constraint Augmented Multi-Agent framework --- CAMA. CAMA can serve as a plug-and-play module to the popular MARL algorithms, including centralized training, decentralized execution and independent learning frameworks. In our approach, we represent the safety constraint as the sum of discounted safety costs bounded by the predefined value, which we call the safety budget. Experiments demonstrate that CAMA can converge quickly to a high degree of constraint satisfaction and surpasses other state-of-the-art safety counterpart algorithms in both cooperative and competitive settings. ",https://openreview.net/pdf/8b89e7d633833aae6b6595c02ad7370b9c920784.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=jHc8dCx6DDr,Memory Gym: Partially Observable Challenges to Memory-Based Agents,"['Marco Pleines', 'Matthias Pallasch', 'Frank Zimmer', 'Mike Preuss']","['~Marco_Pleines1', 'matthias.pallasch@udo.edu', 'frank.zimmer@hochschule-rhein-waal.de', '~Mike_Preuss1']","['Deep Reinforcement Learning', 'Memory', 'Benchmark', 'Proximal Policy Optimization', 'Gated Recurrent Unit', 'HELM']","Memory Gym is a novel benchmark for challenging Deep Reinforcement Learning agents to memorize events across long sequences, be robust to noise, and generalize. It consists of the partially observable 2D and discrete control environments Mortar Mayhem, Mystery Path, and Searing Spotlights. These environments are believed to be unsolvable by memory-less agents because they feature strong dependencies on memory and frequent agent-memory interactions. Empirical results based on Proximal Policy Optimization (PPO) and Gated Recurrent Unit (GRU) underline the strong memory dependency of the contributed environments. The hardness of these environments can be smoothly scaled, while different levels of difficulty (some of them unsolved yet) emerge for Mortar Mayhem and Mystery Path. Surprisingly, Searing Spotlights poses a tremendous challenge to GRU-PPO, which remains an open puzzle. Even though the
randomly moving spotlights reveal parts of the environment’s ground truth, environmental ablations hint that these pose a severe perturbation to agents that leverage recurrent model architectures as their memory. 
Source Code: https://github.com/MarcoMeter/drl-memory-gym/",https://openreview.net/pdf/311f37d9f91d2b654e7ef5b66aab43a60b5f0e8b.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=jHA-yCyBGb,DIFFUSION GENERATIVE MODELS ON SO(3),"['Yesukhei Jagvaral', 'Francois Lanusse', 'Rachel Mandelbaum']","['~Yesukhei_Jagvaral1', '~Francois_Lanusse2', '~Rachel_Mandelbaum1']","['Deep Generative Models', 'Manifold Learning', 'SO(3)', 'Denoising Diffusion', 'Score-based models']","Diffusion-based generative models represent the current state-of-the-art for image generation. However, standard diffusion models are based on Euclidean geometry and do not translate directly to manifold-valued data. In this work, we develop extensions of both score-based generative models (SGMs) and Denoising Diffusion Probabilistic Models (DDPMs) to the Lie group of 3D rotations, SO(3). SO(3) is of particular interest in many disciplines such as robotics, biochemistry and astronomy/planetary science. Contrary to more general Riemannian manifolds, SO(3) admits a tractable solution to heat diffusion, and allows us to implement efficient training of Diffusion models. We apply both SO(3) DDPMs and SGMs to synthetic densities on SO(3) and demonstrate state-of-the-art results.",https://openreview.net/pdf/f1c2d0eb57fd34923011bf3c763b6e8cca56abfa.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=jClGv3Qjhb,"A Theoretical Understanding of Shallow Vision Transformers: Learning, Generalization, and Sample Complexity","['Hongkang Li', 'Meng Wang', 'Sijia Liu', 'Pin-Yu Chen']","['~Hongkang_Li1', '~Meng_Wang4', '~Sijia_Liu1', '~Pin-Yu_Chen1']","['Vision transformer', 'Learning', 'Generalization', 'Sample comeplxity', 'Token sparsification', 'Theory']","Vision Transformers (ViTs) with self-attention modules have recently achieved great empirical success in many vision tasks. Due to non-convex interactions across layers, however, the theoretical learning and generalization analysis is mostly elusive. Based on a data model characterizing both label-relevant and label-irrelevant tokens, this paper provides the first theoretical analysis of training a three-layer ViT, i.e., one self-attention layer followed by a two-layer perceptron, for a classification task. We characterize the sample complexity to achieve a zero generalization error. Our sample complexity bound is positively correlated with the inverse of the fraction of label-relevant tokens, the token noise level, and the initial model error. We also prove that a training process using stochastic gradient descent (SGD) leads to a sparse attention map, which is a formal verification of the general intuition about the success of attention. Moreover,  this paper indicates that a proper token sparsification can improve the test performance by removing label-irrelevant and/or noisy tokens, including spurious correlations. Empirical experiments on synthetic data and CIFAR-10 dataset justify our theoretical results and generalize to deeper ViTs. ",https://openreview.net/pdf/31d1481db9db8d93532ef30aa9a64f3a33b188b1.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=jCdoLxMZxf,Copula Conformal Prediction for Multi-step Time Series Forecasting,"['Sophia Huiwen Sun', 'Rose Yu']","['~Sophia_Huiwen_Sun1', '~Rose_Yu1']","['Conformal Prediction', 'time series', 'uncertainty quantification', 'calibration', 'RNN']","Accurate uncertainty measurement is a key step to building robust and reliable machine learning systems. Conformal prediction is a distribution-free uncertainty quantification algorithm popular for its ease of implementation, statistical coverage guarantees, and versatility for underlying forecasters. However, existing conformal prediction algorithms for time series are limited to single-step prediction without considering the temporal dependency. In this paper we propose a Copula-based Conformal Prediction algorithm for multivariate, multi-step Time Series forecasting, CopulaCPTS. On several synthetic and real-world multivariate time series datasets, we show that CopulaCPTS produces more calibrated and sharp confidence intervals for multi-step prediction tasks than existing techniques.",https://openreview.net/pdf/a357c2785026e23479c5fab30ac3cfbe3b3cd378.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=ipflrGaf7ry,Can Agents Run Relay Race with Strangers? Generalization of RL to Out-of-Distribution Trajectories,"['Li-Cheng Lan', 'Huan Zhang', 'Cho-Jui Hsieh']","['~Li-Cheng_Lan1', '~Huan_Zhang1', '~Cho-Jui_Hsieh1']","['Genralization', 'Reinforcement Learning']","In this paper, we evaluate and improve the generalization performance for reinforcement learning (RL) agents on the set of ``controllable'' states, where good policies exist on these states to achieve the goal. An RL agent that generally masters a task should reach its goal starting from any controllable state of the environment instead of memorizing a small set of trajectories. To practically evaluate this type of generalization, we propose relay evaluation, which starts the test agent from the middle of other independently well-trained stranger agents' trajectories. With extensive experimental evaluation, we show the prevalence of generalization failure on controllable states from stranger agents. For example, in the Humanoid environment, we observed that a well-trained Proximal Policy Optimization (PPO) agent, with only 3.9\% failure rate during regular testing, failed on 81.6\% of the states generated by well-trained stranger PPO agents. To improve ""relay generalization,"" we propose a novel method called Self-Trajectory Augmentation (STA), which will reset the environment to the agent's old states according to the Q function during training. After applying STA to the Soft Actor Critic's (SAC) training procedure, we reduced the failure rate of SAC under relay-evaluation by more than three times in most settings without impacting agent performance and increasing the needed number of environment interactions. Our code is available at https://github.com/lan-lc/STA.",https://openreview.net/pdf/80245884d3c21d7b21166281784b35962b9f3e1f.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=ig4E0Y11pX,Theoretical  Characterization of Neural Network Generalization with Group Imbalance,"['Hongkang Li', 'Shuai Zhang', 'Meng Wang', 'Yihua Zhang', 'Pin-Yu Chen', 'Sijia Liu']","['~Hongkang_Li1', '~Shuai_Zhang6', '~Meng_Wang4', '~Yihua_Zhang1', '~Pin-Yu_Chen1', '~Sijia_Liu1']","['Group imbalance', 'Sample complexity', 'Generelization analysis', 'Gaussian mixture model', 'Empirical risk minimization']","Group imbalance has been a known problem in empirical risk minimization (ERM), where the achieved high \textit{average} accuracy could be accompanied by low accuracy in a \textit{minority} group. Despite various algorithmic efforts to improve the minority group accuracy, a theoretical study of the generalization performance of ERM on individual groups remains elusive. By formulating the group imbalance problem with the Gaussian Mixture Model, this paper quantifies the impact of individual groups on the sample complexity, the convergence rate, and the average and group-level testing performance. Although our theoretical framework is centered on binary classification using a one-hidden-layer neural network, to the best of our knowledge, we provide the first theoretical analysis of the group-level generalization of ERM in addition to the commonly studied average generalization performance. Sample insights of our theoretical results include that when all group-level co-variance is in the medium regime and all mean are close to zero,  the learning performance is most desirable in the sense of a small sample complexity, a fast training rate, and a high average and group-level testing accuracy. Moreover, we show that increasing the fraction of the minority group in the training data does not necessarily improve the generalization performance of the minority group.  Our theoretical results are validated on both synthetic and empirical datasets such as CelebA and CIFAR-10 in image classification.",https://openreview.net/pdf/916bd547510f5d8e329f209f7ed060d4d92b45ee.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=icmTV7mhxuQ,Entity Divider with Language Grounding in Multi-Agent Reinforcement Learning,"['Ziluo Ding', 'Wanpeng Zhang', 'Junpeng Yue', 'Xiangjun Wang', 'Tiejun Huang', 'Zongqing Lu']","['~Ziluo_Ding1', '~Wanpeng_Zhang1', '~Junpeng_Yue1', '~Xiangjun_Wang1', '~Tiejun_Huang1', '~Zongqing_Lu2']","['language-based reinforcement learning', 'multi-agent reinforcement learning']","We investigate the use of natural language to drive the generalization of policies in multi-agent settings. Unlike single-agent settings, the generalization of policies should also consider the influence of other agents. Besides, with the increasing number of entities in multi-agent settings, more agent-entity interactions are needed for language grounding, and the enormous search space could impede the learning process. Moreover, given a simple general instruction, e.g., beating all enemies, agents are required to decompose it into multiple subgoals and figure out the right one to focus on. Inspired by previous work, we try to address these issues at the entity level and propose a novel framework for language grounding in multi-agent reinforcement learning, entity divider (EnDi). EnDi enables agents to independently learn subgoal division at the entity level and act in the environment based on the associated entities. The subgoal division is regularized by opponent modeling to avoid subgoal conflicts and promote coordinated strategies. Empirically, EnDi demonstrates the strong generalization ability to unseen games with new dynamics and expresses the superiority over existing methods. ",https://openreview.net/pdf/9aa7ecfdc42fe3363be61a38c480260d8c08f4e0.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=iaYcJKpY2B_,CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis,"['Erik Nijkamp', 'Bo Pang', 'Hiroaki Hayashi', 'Lifu Tu', 'Huan Wang', 'Yingbo Zhou', 'Silvio Savarese', 'Caiming Xiong']","['~Erik_Nijkamp2', '~Bo_Pang4', '~Hiroaki_Hayashi1', '~Lifu_Tu1', '~Huan_Wang1', '~Yingbo_Zhou1', '~Silvio_Savarese1', '~Caiming_Xiong1']","['Program synthesis', 'multi-turn generation', 'code generation', 'large language models', 'generative models']","Program synthesis strives to generate a computer program as a solution to a given problem specification, expressed with input-output examples or natural language descriptions. The prevalence of large language models advances the state-of-the-art for program synthesis, though limited training resources and data impede open access to such models. To democratize this, we train and release a family of large language models up to 16.1B parameters, called CODEGEN, on natural language and programming language data, and open source the training library JAXFORMER. We show the utility of the trained model by demonstrating that it is competitive with the previous state-of-the-art on zero-shot Python code generation on HumanEval. We further investigate the multi-step paradigm for program synthesis, where a single program is factorized into multiple prompts specifying subproblems. To this end, we construct an open benchmark, Multi-Turn Programming Benchmark (MTPB), consisting of 115 diverse problem sets that are factorized into multi-turn prompts. Our analysis on MTPB shows that the same intent provided to CODEGEN in multi-turn fashion significantly improves program synthesis over that provided as a single turn. We make the training library JAXFORMER and model checkpoints available as open source contribution: https://github.com/salesforce/CodeGen.",https://openreview.net/pdf/003bbce081e6ee9edeead69fcdba6fbe3882de42.pdf,{'title_filter': 'Data Synthesis'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=i_1rbq8yFWC,Rhino: Deep Causal Temporal Relationship Learning with History-dependent Noise,"['Wenbo Gong', 'Joel Jennings', 'Cheng Zhang', 'Nick Pawlowski']","['~Wenbo_Gong1', 'joeljennings@microsoft.com', '~Cheng_Zhang1', '~Nick_Pawlowski2']","['Structure learning', 'Causal discovery', 'Time series', 'Structure equation model', 'deep generative model']","Discovering causal relationships between different variables from time series data has been a long-standing challenge for many domains. For example, in stock markets, the announcement of acquisitions from leading companies may have immediate effects on stock prices and increase the uncertainty of the future market due to this past action. To discover causal relations in such case, the model needs to consider non-linear relations between variables, instantaneous effect and the change of noise distribution due to past actions. We name the latter as history-dependent noise. However, previous works do not offer a solution addressing all these problems together. In this paper, we propose a structural equation model, called Rhino, which combines vector auto-regression, deep learning and variational inference to model non-linear relationships with instantaneous effects while allowing the noise distribution to be modulated by history observations. Theoretically, we prove the structural identifiability of Rhino. Our empirical results from extensive synthetic experiments and two real-world benchmarks demonstrate better discovery performance compared to relevant baselines, with ablation studies revealing its robustness under model misspecification.",https://openreview.net/pdf/fbac1494936fa6cf98eb5c4fb5a71e68dee7d101.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=iYvbPx8GTta,SeedGNN: Graph Neural Network for Supervised Seeded Graph Matching,"['Liren Yu', 'Jiaming Xu', 'Xiaojun Lin']","['~Liren_Yu1', '~Jiaming_Xu4', '~Xiaojun_Lin1']","['seeded graph matching', 'Graph Neural Network (GNN)', 'percolation', 'multi-hop witnesses']","There have been significant interests in designing Graph Neural Networks (GNNs) for seeded graph matching, which aims to match two (unlabeled) graphs using only topological information and a small set of seeds. However, most previous GNNs for seeded graph matching employ a semi-supervised approach, which requires a large number of seeds and can not learn knowledge transferable to unseen graphs. In contrast, this paper proposes a new supervised approach that can learn from a training set how to match unseen graphs with only a few seeds. At the core of our SeedGNN architecture are two novel modules: 1) a convolution module that can easily learn the capability of counting and using witnesses of different hops; 2) a percolation module that can use easily-matched pairs as new seeds to percolate and match other nodes. We evaluate SeedGNN on both synthetic and real graphs, and demonstrate significant performance improvement over both non-learning and learning algorithms in the existing literature. Further, our experiments confirm that the knowledge learned by SeedGNN from training graphs can be generalized to test graphs with different sizes and categories. ",https://openreview.net/pdf/84b1b802a22de7a01efc3bf0304a21ed09271265.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=iI8zWfCyCIQ,Graph Backup: Data Efficient Backup Exploiting Markovian Transitions,"['zhengyao jiang', 'Tianjun Zhang', 'Robert Kirk', 'Tim Rocktäschel', 'Edward Grefenstette']","['~zhengyao_jiang2', '~Tianjun_Zhang1', '~Robert_Kirk1', '~Tim_Rocktäschel1', '~Edward_Grefenstette1']","['reinforcement learning', 'graph structure', 'neuro-symbolic methods', 'data efficient reinforcement learning']","The successes of deep Reinforcement Learning (RL) are limited to settings where we have a large stream of online experiences, but applying RL in the data-efficient setting with limited access to online interactions is still challenging. A key to data-efficient RL is good value estimation, but current methods in this space fail to fully utilise the structure of the trajectory data gathered from the environment. In this paper, we treat the transition data of the MDP as a graph, and define a novel backup operator, Graph Backup, which exploits this graph structure for better value estimation. Compared to multi-step backup methods such as $n$-step $Q$-Learning and TD($\lambda$), Graph Backup can perform counterfactual credit assignment and gives stable value estimates for a state regardless of which trajectory the state is sampled from. Our method, when combined with popular off-policy value-based methods, provides improved performance over one-step and multi-step methods on a suite of data-efficient RL benchmarks including MiniGrid, Minatar and Atari100K. We further analyse the reasons for this performance boost through a novel visualisation of the transition graphs of Atari games.",https://openreview.net/pdf/ddcfee6e9d1aa340c21f833a02b68179af160b7a.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=iF0B-U0J5fG,Teach me how to Interpolate a Myriad of Embeddings,"['Shashanka Venkataramanan', 'Ewa Kijak', 'laurent amsaleg', 'Yannis Avrithis']","['~Shashanka_Venkataramanan2', '~Ewa_Kijak1', '~laurent_amsaleg1', '~Yannis_Avrithis2']",[],"Mixup refers to interpolation-based data augmentation, originally motivated as a way to go beyond empirical risk minimization (ERM). Yet, its extensions focus on the definition of interpolation and the space where it takes place, while the augmentation itself is less studied: For a mini-batch of size $m$, most methods interpolate between $m$ pairs with a single scalar interpolation factor $\lambda$.

In this work, we make progress in this direction by introducing MultiMix, which interpolates an arbitrary number $n$ of tuples, each of length $m$, with one vector $\lambda$ per tuple. On sequence data, we further extend to dense interpolation and loss computation over all spatial positions. Overall, we increase the number of tuples per mini-batch by orders of magnitude at little additional cost. This is possible by interpolating at the very last layer before the classifier. Finally, to address inconsistencies due to linear target interpolation, we introduce a self-distillation approach to generate and interpolate synthetic targets.

We empirically show that our contributions result in significant improvement over state-of-the-art mixup methods on four benchmarks. By analyzing the embedding space, we observe that the classes are more tightly clustered and uniformly spread over the embedding space, thereby explaining the improved behavior.",https://openreview.net/pdf/bfaeb93f7410c4bb27a84e52f66fa239d797365c.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=iAPs7yMjjyQ,Evaluating Counterfactual Explainers,"['Diego Velazquez', 'Pau Rodriguez', 'Alexandre Lacoste', 'Issam H. Laradji', 'Xavier Roca', 'Jordi Gonzàlez']","['~Diego_Velazquez1', '~Pau_Rodriguez2', '~Alexandre_Lacoste1', '~Issam_H._Laradji1', 'xavier.roca@uab.cat', '~Jordi_Gonzàlez3']","['Explainability', 'Counterfactuals', 'XAI']","Explainability methods have been widely used to provide insight into the decisions made by statistical models, thus facilitating their adoption in various domains within the industry. Counterfactual explanation methods aim to improve our understanding of a model by perturbing samples in a way that would alter its response in an unexpected manner. This information is helpful for users and for machine learning practitioners to understand and improve their models. Given the value provided by counterfactual explanations, there is a growing interest in the research community to investigate and propose new methods. However, we identify two issues that could hinder the progress in this field. (1) Existing metrics do not accurately reflect the value of an explainability method for the users. (2) Comparisons between methods are usually performed with datasets like CelebA, where images are annotated with attributes that do not fully describe them and with subjective attributes such as ``Attractive''. In this work, we address these problems by proposing an evaluation method with a principled metric to evaluate and compare different counterfactual explanation methods. The evaluation method is based on a synthetic dataset where images are fully described by their annotated attributes. As a result, we are able to perform a fair comparison of multiple explainability methods in the recent literature, obtaining insights about their performance. We make the code public for the benefit of the research community.",https://openreview.net/pdf/c8f0e18f77fe43fa9c5165846d4b0af760612bf4.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=i8AnfJYMvz,Beyond Reward: Offline Preference-guided Policy Optimization,"['Yachen Kang', 'Diyuan Shi', 'Jinxin Liu', 'Li He', 'Donglin Wang']","['~Yachen_Kang1', '~Diyuan_Shi1', '~Jinxin_Liu1', '~Li_He3', '~Donglin_Wang1']","['offline reinforcement learning', 'preference-based reinforcement learning', 'hindsight information matching', 'preference-guided policy optimization']","In this work, we study offline preference-based reinforcement learning (PbRL), which relaxes the two fundamental supervisory signals in standard reinforcement learning (online accessible transition dynamics and rewards). In other words, the agent is provided with fixed offline trajectory transitions and human preferences between pairs of trajectories. Due to the orthogonality property of rewards and dynamics, one common practice is combining prior PbRL-based reward learning objectives with off-the-shelf offline RL algorithms to bridge preference modeling and offline learning. However, such two isolated optimizations require learning a separate reward function and thus place an information bottleneck on reward learning (the bridge). As an alternative, we propose offline preference-guided policy optimization (OPPO), an end-to-end offline PbRL formulation, which jointly learns to model the preference (for finding the optimal task policy) and the offline data (for eliminating OOD). In particular, OPPO introduces an offline hindsight information matching objective and a preference modeling objective. Then, iterating the two objectives over, we can directly extract a well-performing decision policy, avoiding a separate reward learning. We empirically show that OPPO can effectively model the offline preference and outperform prior competing baselines (including the offline RL algorithms performed over the true reward function).",https://openreview.net/pdf/08ca314c182c5472b446bcfed456750a6514c5eb.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=hxUwnEGxW87,Statistical Theory of Differentially Private Marginal-based Data Synthesis Algorithms,"['Ximing Li', 'Chendi Wang', 'Guang Cheng']","['~Ximing_Li2', '~Chendi_Wang2', '~Guang_Cheng1']","['Synthetic data', 'differential privacy', 'marginal-based method', 'Bayesian network', 'learning theory']"," Marginal-based methods achieve promising performance in the synthetic data competition hosted by the National Institute of Standards and Technology (NIST).
 To deal with high-dimensional data, the distribution of synthetic data is represented by a probabilistic graphical model (e.g., a Bayesian network), while the raw data distribution is approximated by a collection of low-dimensional marginals.
 Differential privacy (DP) is guaranteed by introducing random noise to each low-dimensional marginal distribution.
 Despite its promising performance in practice, the statistical properties of marginal-based methods are rarely studied in the literature.
 In this paper, we study DP data synthesis algorithms based on Bayesian networks (BN) from a statistical perspective. We establish a rigorous accuracy guarantee for BN-based algorithms, where the errors are measured by the total variation (TV) distance or the $L^2$ distance. 
 Related to downstream machine learning tasks, an upper bound for the utility error of the DP synthetic data is also derived. To complete the picture, we establish a lower bound for TV accuracy that holds for every $\epsilon$-DP synthetic data generator.",https://openreview.net/pdf/3058893e9f851ac461611b0b24f93d716651a067.pdf,{'title_filter': 'Data Synthesis'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=hp_RwhKDJ5,Learning to Induce Causal Structure ,"['Nan Rosemary Ke', 'Silvia Chiappa', 'Jane X Wang', 'Jorg Bornschein', 'Anirudh Goyal', 'Melanie Rey', 'Theophane Weber', 'Matthew Botvinick', 'Michael Curtis Mozer', 'Danilo Jimenez Rezende']","['~Nan_Rosemary_Ke1', '~Silvia_Chiappa1', '~Jane_X_Wang1', '~Jorg_Bornschein1', '~Anirudh_Goyal1', '~Melanie_Rey1', '~Theophane_Weber1', '~Matthew_Botvinick1', '~Michael_Curtis_Mozer1', '~Danilo_Jimenez_Rezende2']","['causality', 'deep learning']","The fundamental challenge in causal induction is to infer the underlying graph structure given observational and/or interventional data. Most existing causal induction algorithms operate by generating candidate graphs and evaluating them using either score-based methods (including continuous optimization) or independence tests. In our work, we instead treat the inference process as a black box and design a neural network architecture that learns the mapping from both observational and interventional data to graph structures via supervised training on synthetic graphs. The learned model generalizes to new synthetic graphs, is robust to train-test distribution shifts, and achieves state-of-the-art performance on naturalistic graphs for low sample complexity.",https://openreview.net/pdf/643ee1c6aa6829fd0ace9b8add8fa3bf34b9861f.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=hhvkdRdWt1F,Dual Algorithmic Reasoning,"['Danilo Numeroso', 'Davide Bacciu', 'Petar Veličković']","['~Danilo_Numeroso1', '~Davide_Bacciu1', '~Petar_Veličković1']","['Algorithmic Reasoning', 'Deep Learning for Graphs']","Neural Algorithmic Reasoning is an emerging area of machine learning which seeks to infuse algorithmic computation in neural networks, typically by training neural models to approximate steps of classical algorithms. In this context, much of the current work has focused on learning reachability and shortest path graph algorithms, showing that joint learning on similar algorithms is beneficial for generalisation. However, when targeting more complex problems, such ""similar"" algorithms become more difficult to find. Here, we propose to learn algorithms by exploiting duality of the underlying algorithmic problem. Many algorithms solve optimisation problems. We demonstrate that simultaneously learning the dual definition of these optimisation problems in algorithmic learning allows for better learning and qualitatively better solutions. Specifically, we exploit the max-flow min-cut theorem to simultaneously learn these two algorithms over synthetically generated graphs, demonstrating the effectiveness of the proposed approach. We then validate the real-world utility of our dual algorithmic reasoner by deploying it on a challenging brain vessel classification task, which likely depends on the vessels’ flow properties. We demonstrate a clear performance gain when using our model within such a context, and empirically show that learning the max-flow and min-cut algorithms together is critical for achieving such a result.",https://openreview.net/pdf/68736260b81982cea120df8994f055abbfe1ec5c.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=hfaNXjEQB47,Dissecting adaptive methods in GANs,"['Samy Jelassi', 'David Dobre', 'Arthur Mensch', 'Yuanzhi Li', 'Gauthier Gidel']","['~Samy_Jelassi1', '~David_Dobre1', '~Arthur_Mensch1', '~Yuanzhi_Li1', '~Gauthier_Gidel1']","['deep learning theory', 'generative adversarial networks', 'adaptive methods']","Adaptive methods are a crucial component widely used for training generative adversarial networks (GANs). While there has been some work to pinpoint the “marginal value of adaptive methods” in standard tasks, it remains unclear why they are still critical for GAN training. In this paper, we formally study how adaptive methods help train GANs; inspired by the grafting method proposed in (Agarwal et al. 2021), we separate the magnitude and direction components of the Adam updates, and graft them to the direction and magnitude of SGDA updates respectively. By considering an update rule with the magnitude of the Adam update and the normalized direction of SGD, we empirically show that the adaptive magnitude of Adam is key for GAN training. This motivates us to have a closer look at the class of normalized stochastic gradient descent ascent (nSGDA) methods in the context of GAN training. We propose a synthetic theoretical framework to compare the performance of nSGDA and SGDA for GAN training with neural networks. We prove that in that setting, GANs trained with nSGDA recover all the modes of the true distribution, whereas the same networks trained with SGDA (and any learning rate configuration) suffer from mode collapse. The critical insight in our analysis is that normalizing the gradients forces the discriminator and generator to be updated at the same pace. We also experimentally show that for several datasets, Adam's performance can be recovered with nSGDA methods.",https://openreview.net/pdf/0967253aa888b77695501305aff4af8a65f886f4.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=hFUlfiyf1oQ,Rethinking Uniformity in Self-Supervised Representation Learning,"['Xianghong Fang', 'Jian Li', 'Xiangchu Feng', 'Benyou Wang']","['~Xianghong_Fang1', '~Jian_Li17', '~Xiangchu_Feng1', '~Benyou_Wang2']","['Collapse Analysis', 'Wasserstein Distance', 'Self-Supervised Representation Learning']","Self-supervised representation learning has achieved great success in many machine learning tasks. While many research efforts focus on learning better representations by preventing the model from the \emph{collapse} problem, less attention has been drawn to analyzing the collapse degrees of representations. In this paper, we present a formal study of collapse analysis via the \emph{uniformity} metric, which measures how uniformly learned representations distribute on the surface of the unit hypersphere. We fundamentally find that \textit{representation that obeys zero-mean isotropic Gaussian distribution is with the ideal uniformity} since its $l_2$-normalized form uniformly distributes on the surface of the unit hypersphere. Therefore, we propose to use the Wasserstein distance between the distribution of learned representations and the ideal distribution as a quantifiable metric of \emph{uniformity}. Moreover, we design five desirable constraints for ideal uniformity metrics, based on which we find that the proposed uniformity metric satisfies all constraints while the existing one does not. Synthetic experiments also demonstrate the proposed uniformity metric is capable to deal with the dimensional collapse while the existing one is insensitive. Furthermore, we impose the proposed \emph{uniformity} metric as an auxiliary loss term for various existing self-supervised methods, which consistently improves the downstream performance. ",https://openreview.net/pdf/6f6c5196ecf1b5bb0559799cdaaff7e163ae3320.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=hF1WEiIYPNb,Query The Agent: Improving Sample Efficiency Through Epistemic Uncertainty Estimation,"['Julian Alverio', 'Boris Katz', 'Andrei Barbu']","['~Julian_Alverio1', '~Boris_Katz1', '~Andrei_Barbu3']","['goal-conditioned reinforcement learning', 'reinforcement learning', 'goal-conditioned', 'goal', 'model-free', 'sample efficiency', 'deep reinforcement learning']","Curricula for goal-conditioned reinforcement learning agents typically rely on poor estimates of the agent's epistemic uncertainty or fail to consider the agents' epistemic uncertainty altogether, resulting in poor sample efficiency. We propose a novel algorithm, Query The Agent (QTA), which significantly improves sample efficiency by estimating the agent's epistemic uncertainty throughout the state space and setting goals in highly uncertain areas. Encouraging the agent to collect data in highly uncertain states allows the agent to improve its estimation of the value function rapidly. QTA utilizes a novel technique for estimating epistemic uncertainty, Predictive Uncertainty Networks (PUN), to allow QTA to assess the agent's uncertainty in all previously observed states. We demonstrate that QTA offers decisive sample efficiency improvements over preexisting methods.",https://openreview.net/pdf/bc691e68c2328c093a66a9df67d7f41932321395.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=h5z_RaWLdG1,How Does Adaptive Optimization Impact Local Neural Network Geometry?,"['Kaiqi Jiang', 'Dhruv Malik', 'Yuanzhi Li']","['~Kaiqi_Jiang2', '~Dhruv_Malik1', '~Yuanzhi_Li1']","['optimization', 'adaptive algorithms', 'neural networks']","Adaptive optimization methods are well known to achieve superior convergence relative to vanilla gradient methods. The traditional viewpoint in optimization, particularly in convex optimization, explains this improved performance by arguing that, unlike vanilla gradient schemes, adaptive algorithms mimic the behavior of a second-order method by adapting to the global geometry of the loss function. We argue that in the context of neural network optimization, this traditional viewpoint is insufficient. Instead, we advocate for a local trajectory analysis. For iterate trajectories produced by running a generic optimization algorithm OPT, we introduce $R^{\text{OPT}}_{\text{med}}$, a statistic that is analogous to the condition number of the loss Hessian evaluated at the iterates. Through extensive experiments, we show that adaptive methods such as Adam bias the trajectories towards regions where $R^{\text{Adam}}_{\text{med}}$ is small, where one might expect faster convergence. By contrast, vanilla gradient methods like SGD bias the trajectories towards regions where $R^{\text{SGD}}_{\text{med}}$ is comparatively large. We complement these empirical observations with a theoretical result that provably demonstrates this phenomenon in the simplified setting of a two-layer linear network. We view our findings as evidence for the need of a new explanation of the success of adaptive methods, one that is different than the conventional wisdom.",https://openreview.net/pdf/d0db70ed12b5ea04b5fa438347082a94d7c797b7.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=h5OpjGd_lo6,Self-Guided Noise-Free Data Generation for Efficient Zero-Shot Learning,"['Jiahui Gao', 'Renjie Pi', 'LIN Yong', 'Hang Xu', 'Jiacheng Ye', 'Zhiyong Wu', 'WEIZHONG ZHANG', 'Xiaodan Liang', 'Zhenguo Li', 'Lingpeng Kong']","['~Jiahui_Gao2', '~Renjie_Pi1', '~LIN_Yong1', '~Hang_Xu1', '~Jiacheng_Ye2', '~Zhiyong_Wu3', '~WEIZHONG_ZHANG2', '~Xiaodan_Liang2', '~Zhenguo_Li1', '~Lingpeng_Kong1']","['Pre-Trained Language Model', 'Prompt-Based Learning', 'Efficient Zero-Shot Learning']","There is a rising interest in further exploring the zero-shot learning potential of large pre-trained language models (PLMs). A new paradigm called data-generation-based zero-shot learning has achieved impressive success. In this paradigm, the synthesized data from the PLM acts as the carrier of knowledge, which is used to train a task-specific model with orders of magnitude fewer parameters than the PLM, achieving both higher performance and efficiency than prompt-based zero-shot learning methods on PLMs. The main hurdle of this approach is that the synthesized data from PLM usually contains a significant portion of low-quality samples. Fitting on such data will greatly hamper the performance of the task-specific model, making it unreliable for deployment. Previous methods remedy this issue mainly by filtering synthetic data using heuristic metrics(e.g., output confidence), or refining the data with the help of a human expert, which comes with excessive manual tuning or expensive costs. In this paper, we propose a novel noise-robust re-weighting framework SunGen to automatically construct high-quality data for zero-shot classification problems. Our framework features the ability to learn the sample weights indicating data quality without requiring any human annotation. We theoretically and empirically verify the ability of our method to help construct good-quality synthetic datasets. Notably, SunGen-LSTM yields a 9.8% relative improvement than the baseline on average accuracy across eight different established text classification tasks.",https://openreview.net/pdf/82812310fbf1dff5ce1f72fe99e2d46523ca8d5a.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=h3vfP9ASoXEK,Recovering Top-Two Answers and Confusion Probability in Multi-Choice Crowdsourcing,"['Hyeonsu Jeong', 'Hye Won Chung']","['~Hyeonsu_Jeong1', '~Hye_Won_Chung2']","['Crowdsourcing', 'multiple choice', 'detecting confusion', 'task difficulty', 'two-stage inference algorithm', 'minimax optimal convergence rate']","We consider multi-choice crowdsourced labeling with the goal of recovering not only the ground truth but also the most confusing answer and the confusion probability. The most confusing answer provides useful information about the task by revealing the most plausible answer other than the ground truth and how plausible it is. To theoretically analyze such scenarios, we propose a model where there are top-two plausible answers for each task, distinguished from the rest of choices. Task difficulty is quantified by the confusion probability between the top two, and worker reliability is quantified by the probability of giving an answer among the top two. Under this model, we propose a two-stage inference algorithm to infer the top-two answers, where the first stage uses the spectral method to obtain an initial estimate for the top two, and the second stage uses the result of the first stage to refine the estimates based on the maximum likelihood estimator (MLE). We show that our algorithm achieves the minimax optimal convergence rate. We conduct both synthetic and real-data experiments and demonstrate that our algorithm achieves the performance near the optimal MLE for synthetic datasets and the best performance for real datasets compared to other recent algorithms. This shows that our model explains well the real datasets with heterogeneous task difficulties due to confusion between plausible answers. 
",https://openreview.net/pdf/833b7e5cc8f70abc63cf95cd1670323b855b4fce.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=h21yJhdzbwz,Towards One-shot Neural Combinatorial Solvers: Theoretical and Empirical Notes on the Cardinality-Constrained Case,"['Runzhong Wang', 'Li Shen', 'Yiting Chen', 'Xiaokang Yang', 'Dacheng Tao', 'Junchi Yan']","['~Runzhong_Wang1', '~Li_Shen1', '~Yiting_Chen1', '~Xiaokang_Yang1', '~Dacheng_Tao1', '~Junchi_Yan2']","['deep learning', 'combinatorial optimization', 'facility location problem', 'max coverage problem', 'portfolio optimization']","One-shot non-autoregressive neural networks, different from RL-based ones, have been actively adopted for solving combinatorial optimization (CO) problems, which can be trained by the objective score in a self-supervised manner. Such methods have shown their superiority in efficiency (e.g. by parallelization) and potential for tackling predictive CO problems for decision-making under uncertainty. While the discrete constraints often become a bottleneck for gradient-based neural solvers, as currently handled in three typical ways: 1) adding a soft penalty in the objective, where a bounded violation of the constraints cannot be guaranteed, being critical to many constraint-sensitive scenarios; 2) perturbing the input to generate an approximate gradient in a black-box manner, though the constraints are exactly obeyed while the approximate gradients can hurt the performance on the objective score; 3) a compromise by developing soft algorithms whereby the output of neural networks obeys a relaxed constraint, and there can still occur an arbitrary degree of constraint-violation. Towards the ultimate goal of establishing a general framework for neural CO solver with the ability to control an arbitrary-small degree of constraint violation, in this paper, we focus on a more achievable and common setting: the cardinality constraints, which in fact can be readily encoded by a differentiable optimal transport (OT) layer. Based on this observation, we propose OT-based cardinality constraint encoding for end-to-end CO problem learning with two variants: Sinkhorn and Gumbel-Sinkhorn, whereby their violation of the constraints can be exactly characterized and bounded by our theoretical results. On synthetic and real-world CO problem instances, our methods surpass the state-of-the-art CO network and are comparable to (if not superior to) the commercial solver Gurobi. In particular, we further showcase a case study of applying our approach to the predictive portfolio optimization task on real-world asset price data, improving the Sharpe ratio from 1.1 to 2.0 of a strong LSTM+Gurobi baseline under the classic predict-then-optimize paradigm.",https://openreview.net/pdf/47ff06773ffd6757c65cd362fde9c7bfd3176168.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=gvMAooaEi3,Revisiting Higher-Order Gradient Methods for Multi-Agent Reinforcement Learning,"['Ariyan Bighashdel', 'Daan De Geus', 'Pavol Jancura', 'Gijs Dubbelman']","['~Ariyan_Bighashdel1', '~Daan_De_Geus1', '~Pavol_Jancura1', '~Gijs_Dubbelman1']","['Multi-agent reinforcement learning', 'Higher-order gradient-based optimization']","This paper revisits Higher-Order Gradient (HOG) methods for Multi-Agent Reinforcement Learning (MARL). HOG methods are algorithms in which agents use higher-order gradient information to account for other agents' anticipated learning, and are shown to improve coordination in games with self-interested agents. So far, however, HOG methods are only applied to games with low-dimensional state spaces due to inefficient computation and preservation of higher-order gradient information. In this work, we solve these limitations and propose a HOG framework that can be applied to games with higher-dimensional state spaces. Moreover, we show that current HOG methods, when applied to games with common-interested agents, i.e., team games, can lead to miscoordination between the agents. To solve this, we propose Hierarchical Reasoning (HR) to improve coordination in team games, and we experimentally show that our proposed HR significantly outperforms state-of-the-art methods in standard multi-agent games. With our contributions, we greatly improve the applicability of HOG methods for MARL. For reproducibility, the code used for our work will be shared after the reviewing process.",https://openreview.net/pdf/f643b474fdd5fd715a0190110804c1a9d1281f0d.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=gmufyyjyjnN,Semi-supervised consistency regularization for accurate cell type fraction and gene expression estimation,"['Robin Khatri', 'Pierre Machart', 'Stefan Bonn']","['~Robin_Khatri1', '~Pierre_Machart1', '~Stefan_Bonn1']","['Cell deconvolution', 'consistency regularization']","Cell deconvolution is the estimation of cell type fractions and cell type-specific gene expression from mixed data with unknown composition. In biomedical research, cell deconvolution, which is a source separation task, is used to obtain mechanistic and diagnostic insights into human diseases. An unmet challenge in cell deconvolution, however, is the scarcity of realistic training data and the strong domain shift observed in synthetic training data that is used in contemporary methods. Here, we hypothesize that simultaneous consistency regularization of the target and training domains will improve deconvolution performance. By adding this biologically motivated consistency loss to two novel deep learning-based deconvolution algorithms, we achieve state-of-the-art performance on both cell fraction and gene expression estimation. Our method, DISSECT, outperforms competing algorithms across several biomedical gene expression datasets and can be easily adapted to deconvolve other biomedical data types, as exemplified by our spatial expression deconvolution experiments.",https://openreview.net/pdf/370db8f62798093a50ef3191900279fc242ac6f5.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=gmL46YMpu2J,Promptagator: Few-shot Dense Retrieval From 8 Examples,"['Zhuyun Dai', 'Vincent Y Zhao', 'Ji Ma', 'Yi Luan', 'Jianmo Ni', 'Jing Lu', 'Anton Bakalov', 'Kelvin Guu', 'Keith Hall', 'Ming-Wei Chang']","['~Zhuyun_Dai1', '~Vincent_Y_Zhao1', '~Ji_Ma3', '~Yi_Luan1', '~Jianmo_Ni2', '~Jing_Lu4', 'abakalov@google.com', '~Kelvin_Guu1', '~Keith_Hall2', '~Ming-Wei_Chang3']","['large language model', 'few-shot prompting', 'information retrieval']","Much recent research on information retrieval has focused on how to transfer from one task (typically with abundant supervised data) to various other retrieval tasks where supervision is limited, with the implicit assumption that it is possible to generalize from one task to all the rest. However, this overlooks the fact that there are many diverse and unique retrieval problems, each targeting different search intents, queries, and search domains. In this paper, we suggest to work on Few-shot Dense Retrieval, a setting where each task comes with a short description and a few examples. To address this, we introduce Prompt-based Query Generation forRetrieval (Promptagator): for each task, we feed the few-shot examples to a large language model (LLM) and prompt it to behave as a task-specific query generator. Using this, we can synthetically generate a large number of relevant queries for any document, yielding abundant data for training task-specific retrievers --- with no reliance on traditional resources such as Natural Questions (Kwiatkowskiet al., 2019) or MS MARCO (Nguyen et al., 2016). Surprisingly, Promptagator with only 8 annotated examples enables efficient dual encoder retrievers to outperform computationally more expensive models trained on MS MARCO such as ColBERT v2 (Santhanam et al., 2022) by more than 1.2 points nDCG@10 on average on 11 retrieval sets. Further training standard-size re-rankers using the same generated data yields another 5.0 points nDCG@10 improvement. Our studies show that synthetic query generation can be far more effective than previously observed, especially when a small amount of task-specific knowledge is given.",https://openreview.net/pdf/79a0f9b78ef87a8465c2f60eac8f96b996c84b38.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=gfHLOC35Zh,Modality Complementariness: Towards Understanding Multi-modal Robustness,"['Siting Li', 'Chenzhuang Du', 'Yu Huang', 'Longbo Huang', 'Hang Zhao']","['~Siting_Li1', '~Chenzhuang_Du1', '~Yu_Huang3', '~Longbo_Huang2', '~Hang_Zhao1']",['multimodal robustness theory'],"Along with the success of multi-modal learning, the robustness of multi-modal learning is receiving attention due to real-world safety concerns. Multi-modal models are anticipated to be more robust due to the possible redundancy between modalities. However, some empirical results have offered contradictory conclusions. In this paper, we point out an essential factor that causes this discrepancy: The difference in the amount of modality-wise complementary information. We provide an information-theoretical analysis of how the modality complementariness affects the multi-modal robustness. Based on the analysis, we design a metric for quantifying how complementary the modalities are to others and propose an effective pipeline to calculate our metric. Experiments on carefully-designed synthetic data verify our theory. Further, we apply our metric to real-world multi-modal datasets and reveal their property. To our best knowledge, we are the first to identify modality complementariness as an important factor affecting multi-modal robustness.",https://openreview.net/pdf/0384c775320ecca7718d0862f61eefd5cb6de26a.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=gVSJ83n47IT,Imposing conservation properties in deep dynamics modeling via contrastive learning,"['Wang Zhang', 'Subhro Das', 'Tsui-Wei Weng', 'Alexandre Megretski', 'Luca Daniel', 'Lam M. Nguyen']","['~Wang_Zhang2', '~Subhro_Das1', '~Tsui-Wei_Weng1', '~Alexandre_Megretski1', '~Luca_Daniel1', '~Lam_M._Nguyen1']","['dynamical system modeling', 'contrastive learning', 'learning conservation property']","Deep neural networks (DNN) has shown great capacity of modeling a dynamical system, but these DNN-based dynamical models usually do not obey conservation laws. To impose the learned DNN dynamical models with key physical properties such as conservation laws, this paper proposes a two-step approach to endow the invariant priors into the simulations. We first establish a contrastive learning framework to capture the system invariants along the trajectory observations. During the dynamics modeling, we design a projection layer of DNNs to preserve the system invariance. Through experiments, we show our method consistently outperforms the baseline in both coordinate error and conservation metrics and can be further extended to complex and large dynamics by leveraging autoencoder. Notably, a byproduct of our framework is the automated conservation law discovery for dynamical systems with single conservation property. ",https://openreview.net/pdf/803eab6ff008ea0fe1d46dcbe8960ae8ad77319d.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=gULfK60oYr1,Never Revisit: Continuous Exploration in Multi-Agent Reinforcement Learning,"['Chenghao Li', 'Tonghan Wang', 'Xiaoran Wu', 'Jun Yang', 'Qianchuan Zhao', 'Chongjie Zhang']","['~Chenghao_Li1', '~Tonghan_Wang1', '~Xiaoran_Wu1', '~Jun_Yang6', '~Qianchuan_Zhao1', '~Chongjie_Zhang1']",[],"Recently, intrinsic motivations are wildly used for exploration in multi-agent reinforcement learning. We discover that coming with intrinsic rewards is the issue of revisitation -- the relative values of intrinsic rewards fluctuate, causing a sub-space visited before becomes attractive after a period of exploration to other areas. Consequently, agents risk exploring some sub-spaces repeatedly. In this paper, we formally define the concept of revisitation, based on which we propose an observation-distribution matching approach to detect the appearance of revisitation. To avoid it, we add branches to agents' local Q-networks and the mixing network to separate sub-spaces which have already been revisited. Furthermore, to prevent adding branches excessively, we design intrinsic rewards to reduce the probability of and penalize the occurrence of revisitation. By virtue of these advances, our method achieves superior performance on three challenging Google Research Football (GRF) scenarios with sparse rewards. ",https://openreview.net/pdf/9890e1758fb80f530d2e5f85da06beca6c1d1de8.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=gOZ_pKANaPW,Unsupervised Model Selection for Time Series Anomaly Detection,"['Mononito Goswami', 'Cristian Ignacio Challu', 'Laurent Callot', 'Lenon Minorics', 'Andrey Kan']","['~Mononito_Goswami1', '~Cristian_Ignacio_Challu1', '~Laurent_Callot1', '~Lenon_Minorics1', '~Andrey_Kan1']","['Time Series', 'Anomaly Detection', 'Model Selection', 'Unsupervised Learning', 'Rank Aggregation']","Anomaly detection in time-series has a wide range of practical applications. While numerous anomaly detection methods have been proposed in the literature, a recent survey concluded that no single method is the most accurate across various datasets. To make matters worse, anomaly labels are scarce and rarely available in practice. The practical problem of selecting the most accurate model for a given dataset without labels has received little attention in the literature. This paper answers this question \textit{i.e.} Given an unlabeled dataset and a set of candidate anomaly detectors, how can we select the most accurate model? To this end, we identify three classes of surrogate (unsupervised) metrics, namely, \textit{prediction error}, \textit{model centrality}, and \textit{performance on injected synthetic anomalies}, and show that some metrics are highly correlated with standard supervised anomaly detection performance metrics such as the $F_1$ score, but to varying degrees. We formulate metric combination with multiple imperfect surrogate metrics as a robust rank aggregation problem. We then provide theoretical justification behind the proposed approach. Large-scale experiments on multiple real-world datasets demonstrate that our proposed unsupervised approach is as effective as selecting the most accurate model based on partially labeled data.",https://openreview.net/pdf/b9338f8e0cd4d78c188aa60e26ced6737232b2a8.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=gLl0fZQo6Vu,Agent-Controller Representations: Principled Offline RL with Rich Exogenous Information,"['Riashat Islam', 'Manan Tomar', 'Alex Lamb', 'Hongyu Zang', 'Yonathan Efroni', 'Dipendra Misra', 'Xin Li', 'Harm van Seijen', 'Remi Tachet des Combes', 'John Langford']","['~Riashat_Islam1', '~Manan_Tomar1', '~Alex_Lamb1', '~Hongyu_Zang1', '~Yonathan_Efroni2', '~Dipendra_Misra1', '~Xin_Li31', '~Harm_van_Seijen1', '~Remi_Tachet_des_Combes1', '~John_Langford1']","['offline RL', 'exogenous information', 'representation learning', 'latent state recovery', 'robustness']","Learning to control an agent from data collected offline in a rich pixel-based visual observation space is vital for real-world applications of reinforcement learning (RL). A major challenge in this setting is the presence of input information that is hard to model and irrelevant to controlling the agent. This problem has been approached by the theoretical RL community through the lens of exogenous information, i.e, any control-irrelevant information contained in observations. For example, a robot navigating in busy streets needs to ignore irrelevant information, such as other people walking in the background, textures of objects, or birds in the sky. In this paper, we focus on the setting with visually detailed exogenous information, and introduce new offline RL benchmarks offering the ability to study this problem. We find that contemporary representation learning techniques can fail on datasets where the noise is a complex and time dependent process, which is prevalent in practical applications. To address these, we propose to use multi-step inverse models, which have seen a great deal of interest in the RL theory community, to learn Agent-Controller Representations for Offline-RL (ACRO). Despite being simple and requiring no reward, we show theoretically and empirically that the representation created by this objective greatly outperforms baselines.  ",https://openreview.net/pdf/ade16b484acbf893d68b474e358135e8d62075bc.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=gL68u5UuWa,Maximum Likelihood Learning of Energy-Based Models for Simulation-Based Inference,"['Pierre Glaser', 'Michael Arbel', 'Arnaud Doucet', 'Arthur Gretton']","['~Pierre_Glaser1', '~Michael_Arbel1', '~Arnaud_Doucet2', '~Arthur_Gretton1']","['Simulation Based Inference', 'Energy Based Models', 'Maximum Likelihood']","We introduce two Synthetic Likelihood methods for Simulation-Based Inference (SBI), to conduct either amortized or targeted inference from experimental observations when a high-fidelity simulator is available. Both methods learn a Conditional Energy-Based Model (EBM) of the likelihood using synthetic data generated by the simulator, conditioned on parameters drawn from a proposal distribution. The learned likelihood can then be combined with any prior to obtain a posterior estimate, from which samples can be drawn using MCMC. 
Our methods uniquely combine a flexible Energy-Based Model and the minimization of a KL loss: this is in contrast to other synthetic likelihood methods, which either rely on normalizing flows, or minimize score-based objectives; choices that come with known pitfalls. Our first method, Amortized Unnormalized Neural Likelihood Estimation (AUNLE), introduces a tilting trick during training that allows to perform inference using efficient MCMC techniques. Our second method, Sequential UNLE (SUNLE), employs a doubly intractable approach in order to re-use simulation data and improve posterior accuracy for a specific observation. 
We demonstrate the properties of both methods on a range of synthetic datasets, and apply it to a neuroscience model of the pyloric network in the crab, matching the performance of other synthetic likelihood methods at a fraction of the simulation budget.",https://openreview.net/pdf/6971b4f3894d344b153122e3bbefca375a68ea31.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=fxkACnJZmy_,Monotonicity and Double Descent in Uncertainty Estimation with Gaussian Processes,"['Liam Hodgkinson', 'Chris van der Heide', 'Fred Roosta', 'Michael W. Mahoney']","['~Liam_Hodgkinson1', '~Chris_van_der_Heide1', '~Fred_Roosta1', '~Michael_W._Mahoney1']","['double descent', 'Gaussian processes', 'Bayesian statistics']","The quality of many modern machine learning models improves as model complexity increases, an effect that has been quantified—for predictive performance—with the non-monotonic double descent learning curve. Here, we address the overarching question: is there an analogous theory of double descent for models which estimate uncertainty? We provide a partially affirmative and partially negative answer in the setting of Gaussian processes (GP). Under standard assumptions, we prove that higher model quality for optimally-tuned GPs (including uncertainty prediction) under marginal likelihood is realized for larger input dimensions, and therefore exhibits a monotone learning curve. After showing that marginal likelihood does not naturally exhibit double descent in the input dimension, we highlight related forms of posterior predictive loss that do. Finally, we verify empirically that our results hold for real data, beyond our considered assumptions, and explore unusual consequences involving synthetic covariates.",https://openreview.net/pdf/54418a897b8bb492061140d4dee332ff00966ccb.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=fwP9Bc4E71,Learning to Take a Break: Sustainable Optimization of Long-Term User Engagement,"['Eden Saig', 'Nir Rosenfeld']","['~Eden_Saig1', '~Nir_Rosenfeld2']","['Lotka-Volterra dynamics', 'breaking policies', 'digital well-being', 'feed-based recommendation']","Optimizing user engagement is a key goal for modern recommendation systems, but blindly pushing users towards increased consumption risks burn-out, churn, or even addictive habits. To promote digital well-being, most platforms now offer a service that periodically prompts users to take a break. These, however, must be set up manually, and so may be suboptimal for both users and the system.
In this paper, we propose a framework for optimizing long-term engagement by learning individualized breaking policies. Using Lotka-Volterra dynamics, we model users as acting based on two balancing latent states: drive, and interest---which must be conserved. We then give an efficient learning algorithm, provide theoretical guarantees, and empirically evaluate its performance on semi-synthetic data.",https://openreview.net/pdf/5129aa55cfb729f7a9771384175ef0ddeec72c5b.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=fvvcpsEl3Z6,Taming the Long Tail of Deep Probabilistic Forecasting,"['Mayank Sharan', 'Jedrzej Kozerawski', 'Rose Yu']","['~Mayank_Sharan1', '~Jedrzej_Kozerawski1', '~Rose_Yu1']","['Deep probabilistic forecasting', 'Long tail error', 'Time Series forecasting', 'Trajectory forecasting']","Deep probabilistic forecasting is gaining attention in numerous applications from weather prognosis, through electricity consumption estimation, to autonomous vehicle trajectory prediction. However, existing approaches focus on improvements on average metrics without addressing the long tailed distribution of errors. In this work, we observe long tail behavior in the error distribution of state-of-the-art deep learning methods for probabilistic forecasting. We present two loss augmentation methods to reduce tailedness: Pareto Loss and Kurtosis Loss. Both methods are related to the concept of moments, which measures the shape of a distribution. Kurtosis Loss is based on a symmetric measure, the fourth moment. Pareto Loss is based on an asymmetric measure of right tailedness and models loss using a Generalized Pareto Distribution (GPD). We demonstrate the performance of our methods on several real-world datasets, including time series and spatiotemporal trajectories, achieving significant improvements on tail error metrics, while maintaining and even improving upon average error metrics.",https://openreview.net/pdf/8cf58e1f717e40027965dd695157091b07324600.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=fsa9jrF73fo,Learning Reduced Fluid Dynamics,"['zherong pan', 'Xifeng Gao', 'Kui Wu']","['~zherong_pan1', '~Xifeng_Gao1', '~Kui_Wu2']","['Fluid Dynamics', 'Model Reduction']","Predicting the state evolution of ultra high-dimensional, time-reversible fluid dynamic system is a crucial but computationally expensive task. Model-reduction has been proven to be an effective method to reduce the computational cost by learning a low-dimensional state embedding. However, existing reduced models are irrespective of either the time reversible property or the nonlinear dynamics, leading to sub-optimal performance. We propose a model-based approach to identify locally optimal, model-reduced, time reversible, nonlinear fluid dynamic systems. Our main idea is to use stochastic Riemann optimization to obtain a high-quality a reduced fluid model by minimizing the expected trajectory-wise model-reduction error over a given distribution of initial conditions. To this end, our method formulates the reduced fluid dynamics as an invertible state transfer function parameterized by the reduced subspace. We further show that the reduced trajectories are differentiable with respect to the subspace bases over the entire Grassmannian manifold, under proper choices of timestep sizes and numerical integrators. Finally, we propose a loss function measuring the trajectory-wise discrepancy between the original and reduced models. By tensor precomputation, we show that gradient information of such loss functions can be evaluated efficiently over a long trajectory without time-integrating the high-dimensional dynamic system. Through evaluations on a row of simulation benchmarks, we show that our method lower the discrepancy by 45%-97% over conventional reduced models.",https://openreview.net/pdf/f0beb980578e017d4225abbcc4d300ea41bf4f7c.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=fkNZtv_-BeW,Backdoors Stuck At The Frontdoor: Multi-Agent Backdoor Attacks That Backfire,"['Siddhartha Datta', 'Nigel Shadbolt']","['~Siddhartha_Datta1', '~Nigel_Shadbolt1']",[],"Malicious agents in collaborative learning and outsourced data collection threaten the training of clean models. Backdoor attacks, where an attacker poisons a model during training to successfully achieve targeted misclassification, are a major concern to train-time robustness. In this paper, we investigate a multi-agent backdoor attack scenario, where multiple attackers attempt to backdoor a victim model simultaneously. A consistent backfiring phenomenon is observed across a wide range of games, where agents suffer from a low collective attack success rate. We examine different modes of backdoor attack configurations, non-cooperation / cooperation, joint distribution shifts, and game setups to return an equilibrium attack success rate at the lower bound. The results motivate the re-evaluation of backdoor defense research for practical environments.",https://openreview.net/pdf/150b65c5f31f62a36049393cda88c5406f3043e2.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=fWWFv--P0xP,On the Importance and Applicability of Pre-Training for Federated Learning,"['Hong-You Chen', 'Cheng-Hao Tu', 'Ziwei Li', 'Han Wei Shen', 'Wei-Lun Chao']","['~Hong-You_Chen1', '~Cheng-Hao_Tu1', '~Ziwei_Li3', '~Han_Wei_Shen1', '~Wei-Lun_Chao1']","['federated learning', 'pre-training']","Pre-training is prevalent in nowadays deep learning to improve the learned model's performance. However, in the literature on federated learning (FL), neural networks are mostly initialized with random weights. These attract our interest in conducting a systematic study to explore pre-training for FL. Across multiple visual recognition benchmarks, we found that pre-training can not only improve FL, but also close its accuracy gap to the counterpart centralized learning, especially in the challenging cases of non-IID clients' data. To make our findings applicable to situations where pre-trained models are not directly available, we explore pre-training with synthetic data or even with clients' data in a decentralized manner, and found that they can already improve FL notably. Interestingly, many of the techniques we explore are complementary to each other to further boost the performance, and we view this as a critical result toward scaling up deep FL for real-world applications. We conclude our paper with an attempt to understand the effect of pre-training on FL. We found that pre-training enables the learned global models under different clients' data conditions to converge to the same loss basin, and makes global aggregation in FL more stable. Nevertheless, pre-training seems to not alleviate local model drifting, a fundamental problem in FL under non-IID data.",https://openreview.net/pdf/d1a6a32bc6d3abc4be477317cdca0f63fe17a19b.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=fSa5IjNMmmi,Multi-objective optimization via equivariant deep hypervolume approximation,"['Jim Boelrijk', 'Bernd Ensing', 'Patrick Forré']","['~Jim_Boelrijk1', '~Bernd_Ensing1', '~Patrick_Forré1']","['Multi-objective optimization', 'Hypervolume approximation', 'Geometric deep learning', 'Bayesian optimization', 'Evolutionary algorithms']","Optimizing multiple competing objectives is a common problem across science and industry. The inherent inextricable trade-off between those objectives leads one to the task of exploring their Pareto front. A meaningful quantity for the purpose of the latter is the hypervolume indicator, which is used in Bayesian Optimization (BO) and Evolutionary Algorithms (EAs). However, the computational complexity for the calculation of the hypervolume scales unfavorably with increasing number of objectives and data points, which restricts its use in those common multi-objective optimization frameworks. 
To overcome these restrictions, previous work has focused on approximating the hypervolume using deep learning. In this work, we propose a novel deep learning architecture to approximate the hypervolume function, which we call DeepHV. For better sample efficiency and generalization, we exploit the fact that the hypervolume is scale equivariant in each of the objectives as well as permutation invariant w.r.t. both the objectives and the samples, by using a deep neural network that is equivariant w.r.t. the combined group of scalings and permutations. We show through an ablation study that including these symmetries leads to significantly improved model accuracy. 
We evaluate our method against exact, and approximate hypervolume methods in terms of accuracy, computation time, and generalization. We also apply and compare our methods to state-of-the-art multi-objective BO methods and EAs on a range of synthetic and real-world benchmark test cases. The results show that our methods are promising for such multi-objective optimization tasks.",https://openreview.net/pdf/a46f7e06fdd5abd79f16e1e24307e1e051bf3f9e.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=fPVRcJqspu,GOGGLE: Generative Modelling for Tabular Data by Learning Relational Structure,"['Tennison Liu', 'Zhaozhi Qian', 'Jeroen Berrevoets', 'Mihaela van der Schaar']","['~Tennison_Liu1', '~Zhaozhi_Qian1', '~Jeroen_Berrevoets1', '~Mihaela_van_der_Schaar2']","['tabular data', 'synthetic data', 'generative model']","Deep generative models learn highly complex and non-linear representations to generate realistic synthetic data. While they have achieved notable success in computer vision and natural language processing, similar advances have been less demonstrable in the tabular domain. This is partially because generative modelling of tabular data entails a particular set of challenges, including heterogeneous relationships, limited number of samples, and difficulties in incorporating prior knowledge. Additionally, unlike their counterparts in image and sequence domain, deep generative models for tabular data almost exclusively employ fully-connected layers, which encode weak inductive biases about relationships between inputs. Real-world data generating processes can often be represented using relational structures, which encode sparse, heterogeneous relationships between variables. In this work, we learn and exploit relational structure underlying tabular data to better model variable dependence, and as a natural means to introduce regularization on relationships and include prior knowledge. Specifically, we introduce GOGGLE, an end-to-end message passing scheme that jointly learns the relational structure and corresponding functional relationships as the basis of generating synthetic samples. Using real-world datasets, we provide empirical evidence that the proposed method is effective in generating realistic synthetic data and exploiting domain knowledge for downstream tasks. ",https://openreview.net/pdf/7589a804d2686c2acfc5aa8c679329619789df08.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=f3dqV4KLZV1,Adaptive Client Sampling in Federated Learning via Online Learning with Bandit Feedback,"['Boxin Zhao', 'Ziqi Liu', 'Chaochao Chen', 'mladen kolar', 'Zhiqiang Zhang', 'JUN ZHOU']","['~Boxin_Zhao1', '~Ziqi_Liu2', '~Chaochao_Chen3', '~mladen_kolar1', '~Zhiqiang_Zhang4', '~JUN_ZHOU6']","['Federated Learning', 'Client Sampling', 'Optimization']","Due to the high cost of communication, federated learning (FL) systems need to sample a subset of clients that are involved in each round of training. As a result, client sampling plays an important role in FL systems as it affects the convergence rate of optimization algorithms used to train machine learning models. Despite its importance, there is limited work on how to sample clients effectively. In this paper, we cast client sampling as an online learning task with bandit feedback, which we solve with an online stochastic mirror descent (OSMD) algorithm designed to minimize the sampling variance. We then theoretically show how our sampling method can improve the convergence speed of optimization algorithms. To handle the tuning parameters in OSMD that depend on the unknown problem parameters, we use the online ensemble method and doubling trick. We prove a dynamic regret bound relative to any sampling sequence. The regret bound depends on the total variation of the comparator sequence, which naturally captures the intrinsic difficulty of the problem. To the best of our knowledge, these theoretical contributions are new and the proof technique is of independent interest. Through both synthetic and real data experiments, we illustrate advantages of the proposed client sampling algorithm over the widely used uniform sampling and existing online learning based sampling strategies. The proposed adaptive sampling procedure is applicable beyond the FL problem studied here and can be used to improve the performance of stochastic optimization procedures such as stochastic gradient descent and stochastic coordinate descent.",https://openreview.net/pdf/6bd69a4ef1e97f9382a07ee51b7286352318d746.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=esRySujigfO,CLIP-FLOW: CONTRASTIVE LEARNING WITH ITERATIVE PSEUDO LABELING FOR OPTICAL FLOW,"['Zhiqi Zhang', 'Nitin Bansal', 'Changjiang Cai', 'Pan Ji', 'Qingan Yan', 'Xiangyu Xu', 'Yi Xu']","['~Zhiqi_Zhang1', '~Nitin_Bansal1', '~Changjiang_Cai1', '~Pan_Ji2', '~Qingan_Yan2', '~Xiangyu_Xu4', '~Yi_Xu7']","['Optical Flow', 'Contrastvie Learning', 'Semi-supervised Learning']","Synthetic datasets are often used to pretrain end-to-end optical flow networks, due to the lack of a large amount of labeled, real scene data. But major drops in accuracy occur when moving from synthetic to real scenes. How do we better transfer the knowledge learned from synthetic to real domains? To this end, we propose CLIP-Flow, a semi-supervised iterative pseudo labeling framework to transfer the pretraining knowledge to the target real domain. We leverage large-scale, unlabeled real data to facilitate transfer learning with the supervision of iteratively updated pseudo ground truth labels, bridging the domain gap between the synthetic and the real. In addition, we propose a contrastive flow loss on reference features and the warped features by pseudo ground truth flows, to further boost the accurate matching and dampen the mismatching due to motion, occlusion, or noisy pseudo labels. We adopt RAFT as the backbone and obtain an F1-all error of 4.11%, i.e., a 19% error reduction from RAFT (5.10%) and ranking 2nd place at submission on KITTI 2015 benchmark. Our framework can also be extended to other models, e.g., CRAFT, reducing the F1-all error from 4.79% to 4.66% on KITTI 2015 benchmark.  ",https://openreview.net/pdf/011943cd7aa6977f8665225f7ab2a14651b9928d.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=eExA3Mk0Dxp,Robust Multi-Agent Reinforcement Learning against Adversaries on Observation,"['Chenghe Wang', 'Yuhang Ran', 'Lei Yuan', 'Yang Yu', 'Zongzhang Zhang']","['~Chenghe_Wang1', '~Yuhang_Ran1', '~Lei_Yuan2', '~Yang_Yu5', '~Zongzhang_Zhang1']","['multi-agent reinforcement learning', 'robust reinforcement learning', 'cooperative multi-agent systems', 'adversarial training']","With the broad applications of deep learning, such as image classification, it is becoming increasingly essential to tackle the vulnerability of neural networks when facing adversarial attacks, which have been widely studied recently. In the cooperative multi-agent reinforcement learning field, which has also shown potential in real-life domains, little work focuses on the problem of adversarial attacks. However, adversarial attacks on observations that can undermine the coordination among agents are likely to occur in actual deployment. This paper proposes a training framework that progressively generates adversarial attacks on agents' observations to help agents learn a robust cooperative policy. One attacker makes decisions on a hybrid action space that it first chooses an agent to attack and then outputs the perturbation vector. The victim policy is then trained against the attackers. Experimental results show that our generated adversarial attacks are diverse enough to improve the agents' robustness against possible disturbances. ",https://openreview.net/pdf/0a82f38bab922a92e0d32ed7ef3897fae15382b7.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=eDLwjKmtYFt,EquiMod: An Equivariance Module to Improve Visual Instance Discrimination,"['Alexandre DEVILLERS', 'Mathieu Lefort']","['~Alexandre_DEVILLERS1', '~Mathieu_Lefort1']","['Representation learning', 'Self-supervised learning', 'Contrastive learning', 'Equivariance']","Recent self-supervised visual representation methods are closing the gap with supervised learning performance. Most of these successful methods rely on maximizing the similarity between embeddings of related synthetic inputs created through data augmentations. This can be seen as a task that encourages embeddings to leave out factors modified by these augmentations, i.e. to be invariant to them. However, this only considers one side of the trade-off in the choice of the augmentations: they need to strongly modify the images to avoid simple solution shortcut learning (e.g. using only color histograms), but on the other hand, augmentations-related information may be lacking in the representations for some downstream tasks (e.g. literature shows that color is important for bird and flower classification). Few recent works proposed to mitigate this problem of using only an invariance task by exploring some form of equivariance to augmentations. This has been performed by learning additional embeddings space(s), where some augmentation(s) cause embeddings to differ, yet in a non-controlled way. In this work, we introduce EquiMod a generic equivariance module that structures the learned latent space, in the sense that our module learns to predict the displacement in the embedding space caused by the augmentations. We show that applying that module to state-of-the-art invariance models, such as BYOL and SimCLR, increases the performances on the usual CIFAR10 and ImageNet datasets. Moreover, while our model could collapse to a trivial equivariance, i.e. invariance, we observe that it instead automatically learns to keep some augmentations-related information beneficial to the representations. ",https://openreview.net/pdf/86ebacd324e18555c29ba7483c276055948f3c1c.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=dz8i-yzXeVg,Elicitation Inference Optimization for Multi-Principal-Agent Alignment,"['Andrew Konya', 'Yeping Lina Qiu', 'Michael P Varga', 'Aviv Ovadya']","['~Andrew_Konya1', '~Yeping_Lina_Qiu1', '~Michael_P_Varga1', '~Aviv_Ovadya1']","['alignment', 'large language models', 'LLMs', 'NLP', 'transfer learning', 'human-centered AI', 'LLMs', 'preference modeling']","In multi-principal-agent alignment scenarios spanning governance, markets, diplomacy, and AI, it is infeasible to elicit every principal's view on all perspectives relevant to agent decisions. Elicitation inference optimization (EIO) aims to minimize the $n$ elicitations needed to approximate $N$ principal's views across $K$ perspectives. In this work, we demonstrate an EIO approach where data efficiency ($NK/n$) increases with scale. We introduce STUMP: an elicitation inference model which integrates an LLM with a latent factor model to enable learning transfer across samples, contexts, and languages.  Then, we characterize STUMP's performance on a set of elicitation primitives from which scalable elicitation (sampling) protocols can be constructed. Building from these results, we design and demonstrate two scalable elicitation protocols for STUMP where data efficiency grows boundlessly, scaling like $O(n)$ in the number of elicitations $n$. This makes it possible to obtain complex, high-dimensional preference signals spanning principal populations at any scale.",https://openreview.net/pdf/46746608209d3fc39afecb2a59bf74dfec6c57ef.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=dqZ_GFn7Nuh,AUTOMATIC CURRICULUM FOR UNSUPERVISED REIN- FORCEMENT LEARNING,"['Yucheng Yang', 'Tianyi Zhou', 'Tianhong Dai', 'Meng Fang', 'Mykola Pechenizkiy']","['~Yucheng_Yang2', '~Tianyi_Zhou1', '~Tianhong_Dai1', '~Meng_Fang1', '~Mykola_Pechenizkiy1']",[],"Recent unsupervised reinforcement learning (URL) can learn meaningful skills without task rewards by carefully designed training objectives. However, most existing works lack quantitative evaluation metrics for URL but mainly rely on visualizations of trajectories to compare the performance. Moreover, each URL method only focuses on a single training objective, which can hinder further learning progress and the development of new skills. To bridge these gaps, we first propose multiple evaluation metrics for URL that can cover different preferred properties. We show that balancing these metrics leads to what a “good” trajectory visualization embodies. Next, we use these metrics to develop an automatic curriculum that can change the URL objective across different learning stages in order to improve and balance all metrics. Specifically, we apply a non-stationary multi-armed bandit algorithm to select an existing URL objective for each episode according to the metrics evaluated in previous episodes. Extensive experiments indifferent environments demonstrate the advantages of our method on achieving promising and balanced performance over all URL metrics.",https://openreview.net/pdf/93251ac00b1df67d7f89c189341931d918b25907.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=dmWMfJeZMM,uGLAD: A deep learning model to recover conditional independence graphs,"['Harsh Shrivastava', 'Urszula Chajewska', 'Robin Abraham', 'Xinshi Chen']","['~Harsh_Shrivastava1', '~Urszula_Chajewska1', '~Robin_Abraham1', '~Xinshi_Chen1']","['Graphical Lasso', 'Deep Learning', 'Unrolled Algorithms', 'Conditional Independence graphs', 'Sparse graphs']","Probabilistic Graphical Models are generative models of complex systems. They rely on conditional independence assumptions between variables to learn sparse representations which can be visualized in a form of a graph. Such models are used for domain exploration and structure discovery in poorly understood domains. This work introduces a novel technique to perform sparse graph recovery by optimizing deep unrolled networks. Assuming that the input data $X\in\mathbb{R}^{M\times D}$ comes from an underlying multivariate Gaussian distribution, we apply a deep model on $X$ that outputs the precision matrix $\Theta$. Then, the partial correlation matrix \mathrm{P} is calculated which can also be interpreted as providing a list of conditional independence assertions holding in the input distribution. Our model, \texttt{uGLAD}, builds upon and extends the state-of-the-art model \texttt{GLAD} to the unsupervised setting. The key benefits of our model are (1) \texttt{uGLAD} automatically optimizes sparsity-related regularization parameters leading to better performance than existing algorithms. (2) We introduce multi-task learning based `consensus' strategy for robust handling of missing data in an unsupervised setting. We evaluate performance on synthetic Gaussian, non-Gaussian data generated from Gene Regulatory Networks, and present case studies in anaerobic digestion and infant mortality.",https://openreview.net/pdf/bc80a9227fea49be8184c7c7b8337a59e740d921.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=dhYUMMy0_Eg,Equal Improvability: A New Fairness Notion Considering the Long-term Impact,"['Ozgur Guldogan', 'Yuchen Zeng', 'Jy-yong Sohn', 'Ramtin Pedarsani', 'Kangwook Lee']","['~Ozgur_Guldogan1', '~Yuchen_Zeng1', '~Jy-yong_Sohn1', '~Ramtin_Pedarsani1', '~Kangwook_Lee1']","['Fairness and Bias in Artificial Intelligence', 'Machine Learning']","Devising a fair classifier that does not discriminate against different groups is an important problem in machine learning. Although researchers have proposed various ways of defining group fairness, most of them only focused on the immediate fairness, ignoring the long-term impact of a fair classifier under the dynamic scenario where each individual can improve its feature over time. Such dynamic scenarios happen in real world, e.g., college admission and credit loaning, where each rejected sample makes effort to change its features to get accepted afterwards. In this dynamic setting, the long-term fairness should equalize the samples’ feature distribution across different groups after the rejected samples make some effort to improve. In order to promote long-term fairness, we propose a new fairness notion called Equal Improvability (EI), which equalizes the potential acceptance rate of the rejected samples across different groups assuming a bounded level of effort will be spent by each rejected sample. We analyze the properties of EI and its connections with existing fairness notions. To find a classifier that satisfies the EI requirement, we propose and study three different approaches that solve EI regularized optimization problems. Through experiments on both synthetic and real datasets, we demonstrate that the proposed EI-regularized algorithms encourage us to find a fair classifier in terms of EI. Finally, we provide experimental results on dynamic scenarios which highlight the advantages of our EI metric in achieving the long-term fairness. Codes are available in anonymous GitHub repository.",https://openreview.net/pdf/97ea07ad031609a62cd7a8f682fec684434f45cf.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=dcN0CaXQhT,Causal Reasoning in the Presence of Latent Confounders via Neural ADMG Learning,"['Matthew Ashman', 'Chao Ma', 'Agrin Hilmkil', 'Joel Jennings', 'Cheng Zhang']","['~Matthew_Ashman1', '~Chao_Ma2', '~Agrin_Hilmkil1', '~Joel_Jennings1', '~Cheng_Zhang1']","['causality', 'causal discovery', 'causal inference', 'structural equation model', 'latent confounders', 'variational inference']","Latent confounding has been a long-standing obstacle for causal reasoning from observational data. One popular approach is to model the data using acyclic directed mixed graphs (ADMGs), which describe ancestral relations between variables using directed and bidirected edges. However, existing methods using ADMGs are based on either linear functional assumptions or a discrete search that is complicated to use and lacks computational tractability for large datasets. In this work, we further extend the existing body of work and develop a novel gradient-based approach to learning an ADMG with nonlinear functional relations from observational data. We first show that the presence of latent confounding is identifiable under the assumptions of bow-free ADMGs with nonlinear additive noise models. With this insight, we propose a novel neural causal model based on autoregressive flows. This not only enables us to model complex causal relationships behind the data, but also estimate their functional relationships (hence treatment effects) simultaneously. We further validate our approach via experiments on both synthetic and real-world datasets, and demonstrate the competitive performance against relevant baselines.",https://openreview.net/pdf/149ce81bce210b81430db7d28cdb51750814141c.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=dPOLZ2u4SKV,Expected Probabilistic Hierarchies,"['Marcel Kollovieh', 'Bertrand Charpentier', 'Daniel Zügner', 'Stephan Günnemann']","['~Marcel_Kollovieh1', '~Bertrand_Charpentier2', '~Daniel_Zügner1', '~Stephan_Günnemann1']","['Hierarchical Clustering', 'Graph Clustering', 'Clustering', 'Probabilistic Models']","Hierarchical clustering has usually been addressed by discrete optimization using heuristics or continuous optimization of relaxed scores for hierarchies. In this work, we propose to optimize expected scores under a probabilistic model over hierarchies. (1) We show theoretically that the global optimum of the expected Dasgupta cost and Tree-Sampling divergence (TSD), two unsupervised metrics for hierarchical clustering scores, are equal to the optimum of their discrete counterparts contrary to some relaxed scores. (2) We propose Expected Probabilistic Hierarchies (EPH), a probabilistic model to learn hierarchies in data by optimizing expected scores. EPH uses differentiable hierarchy sampling enabling end-to-end gradient-descent based optimizations, and an unbiased subgraph sampling approach to scale to large datasets. (3) We evaluate EPH on synthetic and real-world datasets including vector and graph datasets. EPH outperforms all other approaches on quantitative results and provides meaningful hierarchies in qualitative evaluations.",https://openreview.net/pdf/6a7f462685c75c4f84a25bad4bb5cf8722ed9bd2.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=dO4aZ9-CsTn,Hierarchical Prototypes for  Unsupervised Dynamics Generalization in Model-Based Reinforcement Learning,"['Jiaxian Guo', 'Mingming Gong', 'Yali Du', 'Zhen Wang', 'Dacheng Tao']","['~Jiaxian_Guo2', '~Mingming_Gong1', '~Yali_Du1', '~Zhen_Wang9', '~Dacheng_Tao1']","['Unsupervised Dynamics Generalization', 'Model-Based Reinforcement Learning']","By incorporating the environment-specific factor into the dynamics prediction, model-based reinforcement learning (MBRL) is able to generalise to environments with diverse dynamics.In the majority of real-world scenarios, the environment-specific factor is not observable, so existing methods attempt to estimate it from historical transition segments. Nevertheless,earlier research was unable to identify distinct clusters for environment-specific factors learned from different environments, resulting in poor performance.
To address this issue,
We introduce a set of environmental prototypes to represent the environmental-specified representation for each environment. By encouraging learned environment-specific factors to resemble their assigned environmental prototypes more closely, the discrimination between factors estimated from distinct environments will be enhanced. To learn such prototypes, we first construct prototypes for each sampled trajectory and then hierarchically combine trajectory prototypes with similar semantics into one environmental prototype. Experiments demonstrate that environment-specific factors estimated by our method have superior clustering performance and can consistently improve MBRL's generalisation performance in six environments consistently.",https://openreview.net/pdf/20e881856fbf47168891abe80e2abf024ecf7b50.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=dCwBpTXbfIq,Identifying Weight-Variant Latent Causal Models,"['Yuhang Liu', 'Zhen Zhang', 'Dong Gong', 'Mingming Gong', 'Biwei Huang', 'Anton van den Hengel', 'Kun Zhang', 'Javen Qinfeng Shi']","['~Yuhang_Liu1', '~Zhen_Zhang2', '~Dong_Gong1', '~Mingming_Gong1', '~Biwei_Huang1', '~Anton_van_den_Hengel1', '~Kun_Zhang1', '~Javen_Qinfeng_Shi1']",[],"The task of causal representation learning aims to uncover latent higher-level causal representations that affect lower-level observations. Identifying true latent causal representations from observed data, while allowing instantaneous causal relations among latent variables,  remains a challenge, however. To this end, we start from the analysis of three intrinsic properties in identifying latent space from observations: transitivity, permutation indeterminacy, and scaling indeterminacy. We find that transitivity acts as a key role in impeding the identifiability of latent causal representations. To address the unidentifiable issue due to transitivity, we introduce a novel identifiability condition where the underlying latent causal model satisfies a linear-Gaussian model, in which the causal coefficients and the distribution of Gaussian noise are modulated by an additional observed variable. Under some mild assumptions, we can show that the latent causal representations can be identified up to trivial permutation and scaling. Furthermore, based on this theoretical result, we propose a novel method, termed Structural caUsAl Variational autoEncoder, which directly learns latent causal representations and causal relationships among them, together with the mapping from the latent causal variables to the observed ones. We show that the proposed method learns the true parameters asymptotically. Experimental results on synthetic and real data demonstrate the identifiability and consistency results and the efficacy of the proposed method in learning latent causal representations.",https://openreview.net/pdf/e1cc392b92d7216219e68b06cb14a851814bee68.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=dCOL0inGl3e,Certifiably Robust Policy Learning against Adversarial Multi-Agent Communication,"['Yanchao Sun', 'Ruijie Zheng', 'Parisa Hassanzadeh', 'Yongyuan Liang', 'Soheil Feizi', 'Sumitra Ganesh', 'Furong Huang']","['~Yanchao_Sun1', '~Ruijie_Zheng1', '~Parisa_Hassanzadeh1', '~Yongyuan_Liang1', '~Soheil_Feizi2', '~Sumitra_Ganesh1', '~Furong_Huang1']","['certifiable robustness', 'reinforcement learning', 'multi-agent system', 'adversarial communication', 'adversarial attack']","Communication is important in many multi-agent reinforcement learning (MARL) problems for agents to share information and make good decisions. However, when deploying trained communicative agents in a real-world application where noise and potential attackers exist, the safety of communication-based policies becomes a severe issue that is underexplored. Specifically, if communication messages are manipulated by malicious attackers, agents relying on untrustworthy communication may take unsafe actions that lead to catastrophic consequences. Therefore, it is crucial to ensure that agents will not be misled by corrupted communication, while still benefiting from benign communication. In this work, we consider an environment with $N$ agents, where the attacker may arbitrarily change the communication from any $C<\frac{N-1}{2}$ agents to a victim agent. For this strong threat model, we propose a certifiable defense by constructing a message-ensemble policy that aggregates multiple randomly ablated message sets. Theoretical analysis shows that this message-ensemble policy can utilize benign communication while being certifiably robust to adversarial communication, regardless of the attacking algorithm. Experiments in multiple environments verify that our defense significantly improves the robustness of trained policies against various types of attacks.",https://openreview.net/pdf/f1c6ea43513dada0ace7e97e3a9c8f26b83250a8.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=d8tJcOxnzF9,Learning Multiobjective Program Through Online Learning,"['Chaosheng Dong', 'Yijia Wang', 'Bo Zeng']","['~Chaosheng_Dong1', 'yiw94@pitt.edu', '~Bo_Zeng1']","['Learning Multiobjective Program', 'Multiobjective Optimization']","We investigate the problem of learning the parameters (i.e., objective functions or constraints) of a multiobjective decision making model, based on a set of sequentially arrived decisions. In particular, these decisions might not be exact and possibly carry measurement noise or are generated with the bounded rationality of decision makers. In this paper, we propose a general online learning framework to deal with this learning problem using inverse multiobjective optimization, and prove that this framework converges at a rate of $\mathcal{O}(1/\sqrt{T})$ under certain regularity conditions. More precisely, we develop two online learning algorithms with implicit update rules which can handle noisy data. Numerical results with both synthetic and real world datasets show that both algorithms can learn the parameters of a multiobjective program with great accuracy and are robust to noise.",https://openreview.net/pdf/5f53b3e7d9b8ec6ab6b6356217048e4e5dec2c67.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=d7Q0vVfJ0wO,Implicit Regularization for Group Sparsity,"['Jiangyuan Li', 'Thanh V Nguyen', 'Chinmay Hegde', 'Raymond K. W. Wong']","['~Jiangyuan_Li1', '~Thanh_V_Nguyen1', '~Chinmay_Hegde1', '~Raymond_K._W._Wong1']","['gradient descent', 'implicit regularization', 'structured/group sparsity', 'linear neural network']","We study the implicit regularization of gradient descent towards structured sparsity via a novel neural reparameterization, which we call a diagonally grouped linear neural network. We show the following intriguing property of our reparameterization: gradient descent over the squared regression loss, without any explicit regularization, biases towards solutions with a group sparsity structure. In contrast to many existing works in understanding implicit regularization, we prove that our training trajectory cannot be simulated by mirror descent. We analyze the gradient dynamics of the corresponding regression problem in the general noise setting and obtain minimax-optimal error rates. Compared to existing bounds for implicit sparse regularization using diagonal linear networks, our analysis with the new reparameterization shows improved sample complexity. In the degenerate case of size-one groups, our approach gives rise to a new algorithm for sparse linear regression. Finally, we demonstrate the efficacy of our approach with several numerical experiments.",https://openreview.net/pdf/efa20f315f25148216c11b749723e1e6e8fac117.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=d3QNWD_pcFv,"Neural Lagrangian Schr\""{o}dinger Bridge: Diffusion Modeling for Population Dynamics","['Takeshi Koshizuka', 'Issei Sato']","['~Takeshi_Koshizuka1', 'isseis@gmail.com']","['Population Dynamics', 'Trajectory Inference', 'Neural SDEs', 'Stochastic Optimal Transport', 'Schrödinger Bridge']","Population dynamics is the study of temporal and spatial variation in the size of populations of organisms and is a major part of population ecology. One of the main difficulties in analyzing population dynamics is that we can only obtain observation data with coarse time intervals from fixed-point observations due to experimental costs or measurement constraints. Recently, modeling population dynamics by using continuous normalizing flows (CNFs) and dynamic optimal transport has been proposed to infer the sample trajectories from a fixed-point observed population. While the sample behavior in CNFs is deterministic, the actual sample in biological systems moves in an essentially random yet directional manner. Moreover, when a sample moves from point A to point B in dynamical systems, its trajectory typically follows the principle of least action in which the corresponding action has the smallest possible value. To satisfy these requirements of the sample trajectories, we formulate the Lagrangian Schrödinger bridge (LSB) problem and propose to solve it approximately by modeling the advection-diffusion process with regularized neural SDE. We also develop a model architecture that enables faster computation of the loss function. Experimental results show that the proposed method can efficiently approximate the population-level dynamics even for high-dimensional data and that using the prior knowledge introduced by the Lagrangian enables us to estimate the sample-level dynamics with stochastic behavior.",https://openreview.net/pdf/4f5dfd7d5e9825029e736d0ace01eda002efdcb8.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=cytNlkyjWOq,Multi-Agent Multi-Game Entity Transformer,"['Rundong Wang', 'Weixuan Wang', 'Xianhan Zeng', 'Liang Wang', 'Zhenjie Lian', 'Yiming Gao', 'Feiyu Liu', 'Siqin Li', 'Xianliang Wang', 'QIANG FU', 'Yang Wei', 'Lanxiao Huang', 'Longtao Zheng', 'Zinovi Rabinovich', 'Bo An']","['~Rundong_Wang1', '~Weixuan_Wang1', '~Xianhan_Zeng1', '~Liang_Wang10', '~Zhenjie_Lian1', '~Yiming_Gao4', '~Feiyu_Liu1', '~Siqin_Li1', '~Xianliang_Wang1', '~QIANG_FU8', '~Yang_Wei2', '~Lanxiao_Huang1', '~Longtao_Zheng1', '~Zinovi_Rabinovich1', '~Bo_An2']","['reinforcement learning', 'multi-agent reinforcement learing', 'transformer', 'pretrained model']","Building large-scale generalist pre-trained models for many tasks is becoming an emerging and potential direction in reinforcement learning (RL). Research such as Gato and Multi-Game Decision Transformer have displayed outstanding performance and generalization capabilities on many games and domains. However, there exists a research blank about developing highly capable and generalist models in multi-agent RL (MARL), which can substantially accelerate progress towards general AI. To fill this gap, we propose Multi-Agent multi-Game ENtity TrAnsformer (MAGENTA) from the entity perspective as an orthogonal research to previous time-sequential modeling. Specifically, to deal with different state/observation spaces in different games, we analogize games as languages, thus training different ""tokenizers"" for various games. The feature inputs are split according to different entities and tokenized in the same continuous space. Then, two types of transformer-based model are proposed as permutation-invariant architectures to deal with various numbers of entities and capture the attention over different entities. MAGENTA is trained on Honor of Kings, Starcraft II micromanagement, and Neural MMO with a single set of transformer weights. Extensive experiments show that MAGENTA can play games across various categories with arbitrary numbers of agents and increase the efficiency of fine-tuning in new games and scenarios by 50\%-100\%. See our project page at \url{https://sites.google.com/view/rl-magenta}.",https://openreview.net/pdf/d62239eae00ca98ce343574d3709068d2631674b.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=cp5PvcI6w8_,TabPFN: A Transformer That Solves Small Tabular Classification Problems in a Second,"['Noah Hollmann', 'Samuel Müller', 'Katharina Eggensperger', 'Frank Hutter']","['~Noah_Hollmann1', '~Samuel_Müller1', '~Katharina_Eggensperger1', '~Frank_Hutter1']","['Tabular Data', 'AutoML', 'Green AI', 'Bayesian prediction', 'Causal Reasoning', 'Real-time Machine Learning']","We present TabPFN, a trained Transformer that can do supervised classification for small tabular datasets in less than a second, needs no hyperparameter tuning and is competitive with state-of-the-art classification methods.
TabPFN is fully entailed in the weights of our network, which accepts training and test samples as a set-valued input and yields predictions for the entire test set in a single forward pass.
TabPFN is a Prior-Data Fitted Network (PFN) and is trained offline once, to approximate Bayesian inference on synthetic datasets drawn from our prior.
This prior incorporates ideas from causal reasoning: It entails a large space of structural causal models with a preference for simple structures.
On the $18$ datasets in the OpenML-CC18 suite that contain up to 1000 training data points, up to 100 purely numerical features without missing values, and up to 10 classes, we show that our method clearly outperforms boosted trees and performs on par with complex state-of-the-art AutoML systems with up to $230\times$ speedup.
This increases to a $5\,700\times$ speedup when using a GPU. We also validate these results on an additional 67 small numerical datasets from OpenML.
We provide all our code, the trained TabPFN, an interactive browser demo and a Colab notebook at https://github.com/automl/TabPFN.",https://openreview.net/pdf/a14bada70718d8e2f05879f7f5dd162a0adbe28c.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=cnsHSSLnHVV,Equivariant 3D-Conditional Diffusion Models for Molecular Linker Design,"['Ilia Igashov', 'Hannes Stärk', 'Clement Vignac', 'Victor Garcia Satorras', 'Pascal Frossard', 'Max Welling', 'Michael M. Bronstein', 'Bruno Correia']","['~Ilia_Igashov1', '~Hannes_Stärk1', '~Clement_Vignac1', '~Victor_Garcia_Satorras2', '~Pascal_Frossard1', '~Max_Welling1', '~Michael_M._Bronstein1', '~Bruno_Correia1']","['Molecules', 'Drug Discovery', 'Molecular Linker Design', 'Equivariant', 'Diffusion Models']","Fragment-based drug discovery has been an effective paradigm in early-stage drug development. An open challenge in this area is designing linkers between disconnected molecular fragments of interest to obtain chemically-relevant candidate drug molecules. In this work, we propose DiffLinker, an E(3)-equivariant 3D-conditional diffusion model for molecular linker design. Given a set of disconnected fragments, our model places missing atoms in between and designs a molecule incorporating all the initial fragments. Unlike previous approaches that are only able to connect pairs of molecular fragments, our method can link an arbitrary number of fragments. Additionally, the model automatically determines the number of atoms in the linker and its attachment points to the input fragments. We demonstrate that DiffLinker outperforms other methods on the standard datasets generating more diverse and synthetically-accessible molecules. Besides, we experimentally test our method in real-world applications, showing that it can successfully generate valid linkers conditioned on target protein pockets.",https://openreview.net/pdf/b751e84e6906e915b3a30a97f53604c591114635.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=cddbeL1HWaD,Cheap Talk Discovery and Utilization in Multi-Agent Reinforcement Learning,"['Yat Long Lo', 'Christian Schroeder de Witt', 'Samuel Sokota', 'Jakob Nicolaus Foerster', 'Shimon Whiteson']","['~Yat_Long_Lo1', '~Christian_Schroeder_de_Witt1', '~Samuel_Sokota1', '~Jakob_Nicolaus_Foerster1', '~Shimon_Whiteson1']","['Reinforcement Learning', 'Multi-Agent Reinforcement Learning']","By enabling agents to communicate, recent cooperative multi-agent reinforcement learning (MARL) methods have demonstrated better task performance and more coordinated behavior. Most existing approaches facilitate inter-agent communication by allowing agents to send messages to each other through free communication channels, i.e., \emph{cheap talk channels}. Current methods require these channels to be constantly accessible and known to the agents a priori. In this work, we lift these requirements such that the agents must discover the cheap talk channels and learn how to use them. Hence, the problem has two main parts: \emph{cheap talk discovery} (CTD) and \emph{cheap talk utilization} (CTU). We introduce a novel conceptual framework for both parts and develop a new algorithm based on mutual information maximization that outperforms existing algorithms in CTD/CTU settings. We also release a novel benchmark suite to stimulate future research in CTD/CTU.",https://openreview.net/pdf/efb6725925bb04b66d9a794a929e5ed57ea8ef69.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=cZM4iZmxzR7,Simple Spectral Graph Convolution from an Optimization Perspective,"['Hao Zhu', 'Piotr Koniusz']","['~Hao_Zhu2', '~Piotr_Koniusz1']","['Graph Convolution', 'Graph Fourier Transformation', 'Unsupervised Learning']","Recent studies on SGC, PageRank and S\textsuperscript{2}GC have demonstrated that several graph diffusion techniques are straightforward, quick, and effective for tasks in the graph domain like node classification. Even though these techniques do not even need labels, they can nevertheless produce more discriminating features than raw attributes for downstream tasks with different classifiers. These methods are data-independent and thus primarily rely on some empirical parameters on polynomial bases (e.g., Monomial and Chebyshev), which ignore the homophily of graphs and the attribute distribution. They are more insensitive to heterophilous graphs due to the low-pass filtering. Although there are many approaches focusing on GNNs based on heterophilous graphs, these approaches are dependent on label information to learn model parameters. In this paper, we study the question: are labels a necessity for GNNs with heterophilous graphs? Based on this question, we propose a framework of self-representation on graphs related to the Least Squares problem. Specifically, we use Generalized Minimum RESidual (GMRES) method, which finds the least squares solution over Krylov subspaces. In theoretical analysis, without label information, we enjoy better features with graph convolution. 
The proposed method, like previous data-independent methods, is not a deep model and is, therefore, quick, scalable, and simple. We  also show performance guarantees for models on real and synthetic data. On a benchmark of real-world datasets, empirically, our method is competitive with existing deep models for node classification.",https://openreview.net/pdf/4dfec7b41fd7e6502bbccc24b2cb1a405d85029f.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=cYZupNY8DS4,Online Policy Optimization for Robust MDP,"['Jing Dong', 'Jingwei Li', 'Baoxiang Wang', 'Jingzhao Zhang']","['~Jing_Dong3', '~Jingwei_Li2', '~Baoxiang_Wang1', '~Jingzhao_Zhang2']",[],"Reinforcement learning (RL) has exceeded human performance in many synthetic settings such as video games and Go. However, real-world deployment of end-to-end RL models is rare, as RL models can be very sensitive to slight perturbation of the environment. The robust Markov decision process (MDP) framework---in which the transition probabilities belong to an uncertainty set around a nominal model---provides one way to develop robust models. While previous analysis shows RL algorithms are effective assuming access to a generative model, it remains unclear whether RL can be efficient under a more realistic online setting, which requires carefully balancing exploration and exploitation. In this work, we consider online robust MDP by interacting with an unknown nominal system. We propose a robust optimistic policy optimization algorithm that is provably efficient. To address the additional uncertainty caused by an adversarial environment, our model features a new optimistic update rule derived via Fenchel conjugates. Our analysis establishes the first regret upper bound for online robust MDPs. ",https://openreview.net/pdf/e03cc06b2f45de1a09d00394817980d9798ee452.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=cVFD6qE8gnY,Planning with Sequence Models through Iterative Energy Minimization,"['Hongyi Chen', 'Yilun Du', 'Yiye Chen', 'Joshua B. Tenenbaum', 'Patricio A. Vela']","['~Hongyi_Chen2', '~Yilun_Du1', '~Yiye_Chen1', '~Joshua_B._Tenenbaum1', '~Patricio_A._Vela1']","['Reinforcement Learning', 'Planning', 'Language Model', 'Decision Transformer']","Recent works have shown that language modeling can be effectively used to train reinforcement learning (RL) policies. However, the success of applying existing language models to planning, in which we wish to obtain a trajectory of actions to reach some goal, is less straightforward. The typical autoregressive generation procedures of language models preclude sequential refinement of earlier steps, which limits the effectiveness of a predicted plan. In this paper, we suggest an approach towards integrating planning with language models based on the idea of iterative energy minimization, and illustrate how such a procedure leads to improved RL performance across different tasks. We train a masked language model to capture an implicit energy function over trajectories of actions, and formulate planning as finding a trajectory of actions with minimum energy. We illustrate how this procedure enables improved performance over recent approaches across BabyAI and Atari environments. We further demonstrate unique benefits of our iterative optimization procedure, involving new task generalization, test-time constraints adaptation, and the ability to compose plans together. Project webpage: https://hychen-naza.github.io/projects/LEAP/index.html",https://openreview.net/pdf/b6ee4b3ab28ce8f9c2f94ec81b64cf338bfdfafe.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=cH4MVZsScm,OoD-Control: Out-of-Distribution Generalization for Adaptive UAV Flight Control,"['Yuxiao Duan', 'Jundong Zhou', 'Zhaoyu Zeng', 'Haoqi Zeng', 'Nanyang Ye']","['~Yuxiao_Duan1', 'zhoujundong@sjtu.edu.cn', '~Zhaoyu_Zeng1', 'zeng-hq@sjtu.edu.cn', '~Nanyang_Ye1']",[],"Data-driven control methods have demonstrated precise and agile control of Unmanned Aerial Vehicles (UAVs) over turbulence environments. However, they are relatively weak at taming the out-of-distribution (OoD) data, i.e., encountering the generalization problem when faced with unknown environments with different data distributions from the training set. Many studies have designed algorithms to reduce the impact of the OoD problem, a common but tricky problem in machine learning. To tackle the OoD generalization problem in control, we propose a theoretically guaranteed approach: OoD-Control. We provide proof that for any perturbation within some range on the states, the control error can be upper bounded by a constant. In this paper, we present our OoD-Control generalization algorithm for online adaptive flight control and execute it on two instances. Experiments show that systems trained by the proposed OoD-Control algorithm perform better in quite different environments from training. And the control method is extensible and pervasively applicable and can be applied to different dynamical models. OoD-Control is validated on UAV dynamic models, and we find it performs state-of-the-art in positioning stability and trajectory tracking problems.",https://openreview.net/pdf/94b6438d7340dda1dffb706c2eefa825fbdd2541.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=cEygmQNOeI,Language Models are Realistic Tabular Data Generators,"['Vadim Borisov', 'Kathrin Sessler', 'Tobias Leemann', 'Martin Pawelczyk', 'Gjergji Kasneci']","['~Vadim_Borisov1', '~Kathrin_Sessler1', '~Tobias_Leemann1', '~Martin_Pawelczyk1', '~Gjergji_Kasneci2']","['tabular data', 'tabular data generation', 'large language models', 'transformers', 'probabilistic modeling', 'deep neural networks']","Tabular data is among the oldest and most ubiquitous forms of data. However, the generation of synthetic samples with the original data’s characteristics remains a significant challenge for tabular data. While many generative models from the computer vision domain, such as variational autoencoders or generative adversarial networks, have been adapted for tabular data generation, less research has been directed towards recent transformer-based large language models (LLMs), which are also generative in nature. To this end, we propose GReaT (Generation of Realistic Tabular data), which exploits an auto-regressive generative LLM to sample synthetic and yet highly realistic tabular data. Furthermore, GReaT can model tabular data distributions by conditioning on any subset of features; the remaining features are sampled without additional overhead. We demonstrate the effectiveness of the proposed approach in a series of experiments that quantify the validity and quality of the produced data samples from multiple angles. We find that GReaT maintains state-of-the-art performance across numerous real-world and synthetic data sets with heterogeneous feature types coming in various sizes.",https://openreview.net/pdf/93e938176cd4da2511c79883813c6bb7781f9804.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=cDVL245jZa,GAPS: Few-Shot Incremental Semantic Segmentation via Guided Copy-Paste Synthesis,"['Ri-Zhao Qiu', 'Peiyi Chen', 'Wangzhe Sun', 'Yu-Xiong Wang', 'Kris Hauser']","['~Ri-Zhao_Qiu1', 'peiyic2@illinois.edu', 'wangzhe.sun@vanderbilt.edu', '~Yu-Xiong_Wang1', '~Kris_Hauser2']","['continual learning', 'incremental learning', 'incremental segmentation', 'few-shot learning']","Few-shot incremental segmentation is the task of updating a segmentation model, as novel classes are introduced online overtime with a small number of training images. Although incremental segmentation methods exist in the literature, they tend to fall short in the few-shot regime and when given partially-annotated training images, where only the novel class is segmented. This paper proposes a data synthesizer, Guided copy-And-Paste Synthesis (GAPS), that improves the performance of few-shot incremental segmentation in a model-agnostic fashion. Despite the great success of copy-paste synthesis in the conventional offline visual recognition, we demonstrate substantially degraded performance of its naive extension in our online scenario, due to newly encountered challenges. To this end, GAPS (i) addresses the partial-annotation problem by leveraging copy-paste to generate fully-labeled data for training, (ii) helps augment the few images of novel objects by introducing a guided sampling process, and (iii) mitigates catastrophic forgetting by employing a diverse memory-replay buffer. Compared to existing state-of-the-art methods, GAPS dramatically boosts the novel IoU of baseline methods on established few-shot incremental segmentation benchmarks by up to 80%. More notably, GAPS maintains good performance in even more impoverished annotation settings, where only single instances of novel objects are annotated.",https://openreview.net/pdf/35e0d095a41834d2bdd84e60fb8229c67a3aab46.pdf,{'title_filter': 'Data Synthesis'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=cA77NrVEuqn,Efficient Planning in a Compact Latent Action Space,"['zhengyao jiang', 'Tianjun Zhang', 'Michael Janner', 'Yueying Li', 'Tim Rocktäschel', 'Edward Grefenstette', 'Yuandong Tian']","['~zhengyao_jiang2', '~Tianjun_Zhang1', '~Michael_Janner1', '~Yueying_Li1', '~Tim_Rocktäschel1', '~Edward_Grefenstette1', '~Yuandong_Tian1']","['Model-based RL', 'Planning', 'Sequence Modelling RL', 'Generative Model', 'Offline Reinforcement Learning']","Planning-based reinforcement learning has shown strong performance in tasks in discrete and low-dimensional continuous action spaces. However, planning usually brings significant computational overhead for decision making, so scaling such methods to high-dimensional action spaces remains challenging. To advance efficient planning for high-dimensional continuous control, we propose Trajectory Autoencoding Planner (TAP), which learns low-dimensional latent action codes with a state-conditional VQ-VAE. The decoder of the VQ-VAE thus serves as a novel dynamics model that takes latent actions and current state as input and reconstructs long-horizon trajectories. During inference time, given a starting state, TAP searches over discrete latent actions to find trajectories that have both high probability under the training distribution and high predicted cumulative reward. Empirical evaluation in the offline RL setting demonstrates low decision latency which is indifferent to the growing raw action dimensionality. For Adroit robotic hand manipulation tasks with high-dimensional continuous action space, TAP surpasses existing model-based methods by a large margin and also beats strong model-free actor-critic baselines.",https://openreview.net/pdf/18c1efd356786f3071db813b03dac9cd5621a032.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=c5-qKzTbP2O,Interpretable (meta)factorization of clinical questionnaires to identify general dimensions of psychopathology,"['Ka Chun Lam', 'Bridget W Mahony', 'Armin Raznahan', 'Francisco Pereira']","['~Ka_Chun_Lam1', 'bridgetwmahony@gmail.com', 'raznahana@mail.nih.gov', '~Francisco_Pereira1']","['Factor analysis', 'matrix factorization', 'meta-factors', 'latent constructs', 'Healthy Brain Network Study']","Psychiatry research aims at understanding manifestations of psychopathology in behavior, in terms of a small number of latent constructs. These are usually inferred from questionnaire data using factor analysis. The resulting factors and relationship to the original questions are not necessarily interpretable. Furthermore, this approach does not provide a way to separate the effect of confounds from those of constructs, and requires explicit imputation for missing data. Finally, there is no clear way to integrate multiple sets of constructs estimated from different questionnaires. An important question is whether there is a universal, compact set of constructs that would span all the psychopathology issues listed across those questionnaires.  We propose a new matrix factorization method designed for questionnaires aimed at promoting interpretability, through bound and sparsity constraints. We provide an optimization procedure with theoretical convergence guarantees, and validate automated methods to detect latent dimensionality on synthetic data. We first demonstrate the method on a commonly used general-purpose questionnaire. We then show it can be used to extract a broad set of 15 psychopathology factors spanning 21 questionnaires from the Healthy Brain Network study. We show that our method preserves diagnostic information against competing methods, even as it imposes more constraints. Finally, we demonstrate that it can be used for defining a short, general questionnaire that allows recovery of those 15 meta-factors, using data more efficiently than other methods.",https://openreview.net/pdf/10045f2f053bc0ee378cc946cf2413ef2d945f1f.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=bzaPGEllsjE,"A view of mini-batch SGD via generating functions: conditions of convergence, phase transitions,  benefit from negative momenta.","['Maksim Velikanov', 'Denis Kuznedelev', 'Dmitry Yarotsky']","['~Maksim_Velikanov1', '~Denis_Kuznedelev1', '~Dmitry_Yarotsky1']","['SGD', 'linear models', 'optimization', 'analytic framework', 'NTK']","Mini-batch SGD with momentum is a fundamental algorithm for learning large predictive models. In this paper we develop a new analytic framework to analyze noise-averaged properties of mini-batch SGD for linear models at constant learning rates, momenta and sizes of batches. Our key idea is to consider the dynamics of the second moments of model parameters for a special family of ""Spectrally Expressible"" approximations. This allows to obtain an explicit expression for the generating function of the sequence of loss values. By analyzing this generating function, we find, in particular, that 1) the SGD dynamics exhibits several convergent and divergent regimes depending on the spectral distributions of the problem; 2) the convergent regimes admit explicit stability conditions, and explicit loss asymptotics in the case of power-law spectral distributions; 3) the optimal convergence rate can be achieved at negative momenta. We verify our theoretical predictions by extensive experiments with MNIST and synthetic problems, and find a good quantitative agreement.",https://openreview.net/pdf/90d22c6df28d1d2983dce952bd3a17a819ab5b3b.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=bRwBpKrNzF7,Faster Last-iterate Convergence of Policy Optimization in Zero-Sum Markov Games,"['Shicong Cen', 'Yuejie Chi', 'Simon Shaolei Du', 'Lin Xiao']","['~Shicong_Cen1', '~Yuejie_Chi1', '~Simon_Shaolei_Du1', '~Lin_Xiao1']","['zero-sum Markov game', 'entropy regularization', 'policy optimization', 'global convergence', 'multiplicative updates']","Multi-Agent Reinforcement Learning (MARL)---where multiple agents learn to interact in a shared dynamic environment---permeates across a wide range of critical applications. While there has been substantial progress on understanding the global convergence of policy optimization methods in single-agent RL, designing and analysis of efficient policy optimization algorithms in the MARL setting present significant challenges and new desiderata, which unfortunately, remain highly inadequately addressed by existing theory. In this paper, we focus on the most basic setting of competitive multi-agent RL, namely two-player zero-sum Markov games, and study equilibrium finding algorithms in both the infinite-horizon discounted setting and the finite-horizon episodic setting. We propose a single-loop policy optimization method with symmetric updates from both agents, where the policy is updated via the entropy-regularized optimistic multiplicative weights update (OMWU) method and the value is updated on a slower timescale. We show that, in the full-information tabular setting, the proposed method achieves a finite-time last-iterate linear convergence to the quantal response equilibrium of the regularized problem, which translates to a sublinear convergence to the Nash equilibrium by controlling the amount of regularization. Our convergence results improve upon the best known iteration complexities, and lead to a better understanding of policy optimization in competitive Markov games.",https://openreview.net/pdf/d08b35cf66974eeaf9743746b69c38f772753301.pdf,{'abstract_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=bLmSMXbqXr,Quality-Similar Diversity via Population Based Reinforcement Learning,"['Shuang Wu', 'Jian Yao', 'Haobo Fu', 'Ye Tian', 'Chao Qian', 'Yaodong Yang', 'QIANG FU', 'Yang Wei']","['~Shuang_Wu3', '~Jian_Yao7', '~Haobo_Fu2', '~Ye_Tian1', '~Chao_Qian1', '~Yaodong_Yang1', '~QIANG_FU8', '~Yang_Wei2']","['quality diversity', 'reinforcement learning', 'user-defined', 'population']","Diversity is a growing research topic in Reinforcement Learning (RL). Previous research on diversity has mainly focused on promoting diversity to encourage exploration and thereby improve quality (the cumulative reward), maximizing diversity subject to quality constraints, or jointly maximizing quality and diversity, known as the quality-diversity problem. In this work, we present the quality-similar diversity problem that features diversity among policies of similar qualities. In contrast to task-agnostic diversity, we focus on task-specific diversity defined by a set of user-specified Behavior Descriptors (BDs). A BD is a scalar function of a trajectory (e.g., the fire action rate for an Atari game), which delivers the type of diversity the user prefers. To derive the gradient of the user-specified diversity with respect to a policy, which is not trivially available, we introduce a set of BD estimators and connect it with the classical policy gradient theorem. Based on the diversity gradient, we develop a population-based RL algorithm to adaptively and efficiently optimize the population diversity at multiple quality levels throughout training. Extensive results on MuJoCo and Atari demonstrate that our algorithm significantly outperforms previous methods in terms of generating user-specified diverse policies across different quality levels.",https://openreview.net/pdf/d8f5cd723fc580efed10ef08df13eda8c3ad877f.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=bHpOeIXvSX2,On the Interplay Between Misspecification and Sub-optimality Gap: From Linear Contextual Bandits to Linear MDPs,"['Weitong Zhang', 'Jiafan He', 'Zhiyuan Fan', 'Quanquan Gu']","['~Weitong_Zhang2', '~Jiafan_He1', '~Zhiyuan_Fan1', '~Quanquan_Gu1']",[],"We study linear contextual bandits in the misspecified setting, where the expected reward function can be approximated by a linear function class up to a bounded misspecification level $\zeta>0$. We propose an algorithm based on a novel data selection scheme, which only selects the contextual vectors with large uncertainty for online regression. We show that, when the misspecification level $\zeta$ is dominated by $\tilde O(\Delta / \sqrt{d})$ with $\Delta$ being the minimal sub-optimality gap and $d$ being the dimension of the contextual vectors, our algorithm enjoys the same gap-dependent regret bound $\tilde O ({d^2} /{\Delta})$ as in the well-specified setting up to logarithmic factors. Together with a lower bound adapted from Du et al. (2019); Lattimore et al.(2020), our result suggests an interplay between misspecification level and the sub-optimality gap: (1) the linear contextual bandit model is efficiently learnable when $\zeta \leq \tilde O({\Delta} / \sqrt{d})$; and (2) it is not efficiently learnable when $\zeta \geq \tilde \Omega({\Delta} / {\sqrt{d}})$. We also extend our algorithm to reinforcement learning with linear Markov decision processes (linear MDPs), and obtain a parallel result of gap-dependent regret. Experiments on both synthetic and real-world datasets corroborate our theoretical results.",https://openreview.net/pdf/630e09ff71ed6b7b040ca735961cb4f96d47dd32.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=aKcS3xojnwY,GEASS: Neural causal feature selection for high-dimensional biological data,"['Mingze Dong', 'Yuval Kluger']","['~Mingze_Dong1', '~Yuval_Kluger1']","['Granger causality', 'feature selection', 'neural networks', 'single-cell genomics', 'spatial transcriptomics']","Identifying nonlinear causal relationships in high-dimensional biological data is an important task. However, current neural network based causality detection approaches for such data suffer from poor interpretability and cannot scale well to the high dimensional regime. Here we present GEASS (Granger fEAture Selection of Spatiotemporal data), which identifies sparse Granger causality mechanisms of high dimensional spatiotemporal data by a single neural network. GEASS maximizes sparsity-regularized modified transfer entropy with a theoretical guarantee of recovering features with spatial/temporal Granger causal relationships. The sparsity regularization is achieved by a novel combinatorial stochastic gate layer to select sparse non-overlapping feature subsets. We demonstrate the efficacy of GEASS in several synthetic datasets and real biological data from single-cell RNA sequencing and spatial transcriptomics.",https://openreview.net/pdf/cae8ae2947fab56338cdfefd11f686b7a431f9f7.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=aCQt_BrkSjC,Learning Hyper Label Model for Programmatic Weak Supervision,"['Renzhi Wu', 'Shen-En Chen', 'Jieyu Zhang', 'Xu Chu']","['~Renzhi_Wu1', '~Shen-En_Chen2', '~Jieyu_Zhang1', '~Xu_Chu2']","['Programmatic Weak Supervision', 'Data Programming', 'Label Model']","To reduce the human annotation efforts, the programmatic weak supervision (PWS) paradigm abstracts weak supervision sources as labeling functions (LFs) and involves a label model to aggregate the output of multiple LFs to produce training labels. Most existing label models require a parameter learning step for each dataset. In this work, we present a hyper label model that (once learned) infers the ground-truth labels for each dataset in a single forward pass without dataset-specific parameter learning. The hyper label model approximates an optimal analytical (yet computationally intractable) solution of the ground-truth labels. We train the model on synthetic data generated in the way that ensures the model approximates the analytical optimal solution, and build the model upon Graph Neural Network (GNN) to ensure the model prediction being invariant (or equivariant) to the permutation of LFs (or data points). On 14 real-world datasets, our hyper label model outperforms the best existing methods in both accuracy (by 1.4 points on average) and efficiency (by six times on average). Our code is available at https://github.com/wurenzhi/hyper_label_model",https://openreview.net/pdf/1d4db3190f142ad660f267b6ac768334b52564af.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=_tIZQEMcWyv,Adaptive Gradient Methods with Local Guarantees,"['Zhou Lu', 'Wenhan Xia', 'Sanjeev Arora', 'Elad Hazan']","['~Zhou_Lu1', '~Wenhan_Xia1', '~Sanjeev_Arora1', '~Elad_Hazan1']",[],"Adaptive gradient methods are the method of choice for optimization in machine learning and used to train the largest deep models. In this paper we study the problem of learning a local preconditioner, that can change as the data is changing along the optimization trajectory. We propose an adaptive gradient method that has provable adaptive regret guarantees vs. the best local preconditioner. To derive this guarantee, we prove a new adaptive regret bound in online learning that improves upon previous adaptive online learning methods. 
We demonstrate the robustness of our method in automatically choosing the optimal learning rate schedule for popular benchmarking tasks in vision and language domains. Without the need to manually tune a learning rate schedule, our method can, in a single run, achieve comparable and stable task accuracy as a fine-tuned optimizer.",https://openreview.net/pdf/f5305a9cb2bcd3cd13cfc6e43cc7ef0ce185d9c2.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=_qVhsWyWB9,"Deep Learning From Crowdsourced Labels: Coupled Cross-Entropy Minimization, Identifiability, and Regularization","['Shahana Ibrahim', 'Tri Nguyen', 'Xiao Fu']","['~Shahana_Ibrahim1', '~Tri_Nguyen2', '~Xiao_Fu1']","['deep learning', 'learning under noisy labels', 'neural classifier', 'end-to-end learning', 'crowdsourcing']","Using noisy crowdsourced labels from multiple annotators, a deep learning-based end-to-end (E2E) system aims to learn the label correction mechanism and the neural classifier simultaneously. To this end, many E2E systems concatenate the neural classifier with multiple annotator-specific label confusion layers and co-train the two parts in a parameter-coupled manner. The formulated coupled cross-entropy minimization (CCEM)-type criteria are intuitive and work well in practice. Nonetheless, theoretical understanding of the CCEM criterion has been limited. The contribution of this work is twofold: First, performance guarantees of the CCEM criterion are presented. Our analysis reveals for the first time that the CCEM can indeed correctly identify the annotators' confusion characteristics and the desired ``ground-truth'' neural classifier under realistic conditions, e.g., when only incomplete annotator labeling and finite samples are available. Second, based on the insights learned from our analysis, two regularized variants of the CCEM are proposed.  The regularization terms provably enhance the identifiability of the target model parameters in various more challenging cases. A series of synthetic and real data experiments are presented to showcase the effectiveness of our approach.",https://openreview.net/pdf/49ef61c9a86ec546eaf7789c562a056aff1ad491.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=_lPNXhQ4uvS,Atomized Deep Learning Models,"['Yi-Lin Tuan', 'Zih-Yun Chiu', 'William Yang Wang']","['~Yi-Lin_Tuan1', '~Zih-Yun_Chiu1', '~William_Yang_Wang2']",[],"Deep learning models often tackle the intra-sample structure, such as the order of words in a sentence and pixels in an image, but have not pay much attention to the inter-sample relationship. In this paper, we show that explicitly modeling the inter-sample structure to be more discretized can potentially help model's expressivity. We propose a novel method, Atom Modeling, that can discretize a continuous latent space by drawing an analogy between a data point and an {\it atom}, which is naturally spaced away from other atoms with distances depending on their intra structures. Specifically, we model each data point as an atom composed of electrons, protons, and neutrons and minimize the potential energy caused by the interatomic force among data points. Through experiments with qualitative analysis in our proposed Atom Modeling on synthetic and real datasets, we find that Atom Modeling can improve the performance by maintaining the inter-sample relation and can capture an interpretable intra-sample relation by mapping each component in a data point to electron/proton/neutron.",https://openreview.net/pdf/52c1437e83cf3f24210904f85b1db2d185c2ea4c.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=_j4ZUpoNO1e,NEW TRAINING FRAMEWORK FOR SPEECH ENHANCEMENT USING REAL NOISY SPEECH,"['Szu-Wei Fu', 'Cheng Yu', 'Yu Tsao', 'Vishak Gopal', 'Jayant Gupchup', 'Ross Cutler']","['~Szu-Wei_Fu1', '~Cheng_Yu3', '~Yu_Tsao1', 'vishak.gopal@microsoft.com', '~Jayant_Gupchup1', '~Ross_Cutler1']","['Speech enhancement', 'Quality prediction', 'Semi-supervised learning', 'Adversarially robust']","Recently, deep learning-based speech enhancement (SE) models have gained
significant improvements. However, the success is mainly based on using synthetic
training data created by adding clean speech with noise. On the other hand, in spite
of its large amount, real noisy speech is hard to be applied for SE model training
because of lack of its clean reference. In this paper, we propose a novel method
to utilize real noisy speech for SE model training based on a non-intrusive speech
quality prediction model. The SE model is trained through the guide of the quality
prediction model. We also find that a speech quality predictor with better accuracy
may not necessarily be an appropriate teacher to guide the SE model. In addition,
we show that if the quality prediction model is adversarially robust, then the
prediction model itself can also be served as a SE model by modifying the input
noisy speech through gradient backpropagation. Objective experiment results show
that, under the same SE model structure, the proposed new training method trained
on a large amount of real noisy speech can outperform the conventional supervised
model trained on synthetic noisy speech. Lastly, the two training methods can be
combined to utilize both benefits of synthetic noisy speech (easy to learn) and real
noisy speech (large amount) to form semi-supervised learning which can further
boost the performance both objectively and subjectively. The code will be released
after publication.",https://openreview.net/pdf/ae110c0ecbfaa6ca123e7bbd77465d98bd280e95.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=_d2f3hRn0hT,Single-level Adversarial Data Synthesis based on Neural Tangent Kernels,"['Yu-Rong Zhang', 'Reddy Su', 'Sheng-Yen Chou', 'Shan-Hung Wu']","['~Yu-Rong_Zhang1', '~Reddy_Su1', '~Sheng-Yen_Chou1', '~Shan-Hung_Wu1']","['Adversarial', 'Data Synthesis', 'Neural Tangent Kernels']","Generative adversarial networks (GANs) have achieved impressive performance in data synthesis and have driven the development of many applications. How- ever, GANs are known to be hard to train due to their bilevel objective, which leads to the problems of convergence, mode collapse, and gradient vanishing. In this paper, we propose a new generative model called the generative adversarial NTK (GA-NTK) that has a single-level objective. The GA-NTK keeps the spirit of adversarial learning (which helps generate plausible data) while avoiding the training difficulties of GANs. This is done by modeling the discriminator as a Gaussian process with a neural tangent kernel (NTK-GP) whose training dynam- ics can be completely described by a closed-form formula. We analyze the conver- gence behavior of GA-NTK trained by gradient descent and give some sufficient conditions for convergence. We also conduct extensive experiments to study the advantages and limitations of GA-NTK and propose some techniques that make GA-NTK more practical.",https://openreview.net/pdf/1bff923193249d356324a448be8c46945ace0df0.pdf,{'title_filter': 'Data Synthesis'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=_-FN9mJsgg,Improving Object-centric Learning with Query Optimization,"['Baoxiong Jia', 'Yu Liu', 'Siyuan Huang']","['~Baoxiong_Jia1', '~Yu_Liu26', '~Siyuan_Huang2']",['unsupervised object-centric learning'],"The ability to decompose complex natural scenes into meaningful object-centric abstractions lies at the core of human perception and reasoning. In the recent culmination of unsupervised object-centric learning, the Slot-Attention module has played an important role with its simple yet effective design and fostered many powerful variants. These methods, however, have been exceedingly difficult to train
without supervision and are ambiguous in the notion of object, especially for complex natural scenes. In this paper, we propose to address these issues by investigating the potential of learnable queries as initializations for Slot-Attention learning, uniting it with efforts from existing attempts on improving Slot-Attention learning with bi-level optimization. With simple code adjustments on Slot-Attention, our model, Bi-level Optimized Query Slot Attention, achieves state-of-the-art results on 3 challenging synthetic and 7 complex real-world datasets in unsupervised image segmentation and reconstruction, outperforming previous baselines by a large margin. We provide thorough ablative studies to validate the necessity and effectiveness of our design. Additionally, our model exhibits great potential for concept binding and zero-shot learning. Our work is made publicly available at https://bo-qsa.github.io.",https://openreview.net/pdf/d5ec9ca4a9c3d9b9a0b66373194a2f787d2e515c.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=ZzdBhtEH9yB,Implicit regularization in Heavy-ball momentum accelerated stochastic gradient descent,"['Avrajit Ghosh', 'He Lyu', 'Xitong Zhang', 'Rongrong Wang']","['~Avrajit_Ghosh1', '~He_Lyu1', '~Xitong_Zhang1', '~Rongrong_Wang1']",[],"It is well known that the finite step-size ($h$) in Gradient descent (GD) implicitly regularizes solutions to flatter minimas. A natural question to ask is \textit{Does the momentum parameter $\beta$ (say) play a role in implicit regularization in Heavy-ball (H.B) momentum accelerated gradient descent (GD+M)?}. To answer this question, first, we show that  the trajectory traced by discrete H.B momentum update (GD+M) is $O(h^2)$ close to a continuous trajectory induced by a modified loss, which consists of an original loss and an implicit regularizer. This implicit regularizer for (GD+M) is indeed stronger than that of (GD) by factor of $(\frac{1+\beta}{1-\beta})$, thus explaining why (GD+M) shows better generalization performance and higher test accuracy than (GD). Furthermore, we extend our analysis to stochastic version of gradient descent with momentum (SGD+M) and propose a deterministic continuous trajectory that is $O(h^2)$ close to the discrete update of (SGD+M) in a strong approximation sense. We explore the implicit regularization in (SGD+M) and (GD+M) through a series of experiments validating our theory. ",https://openreview.net/pdf/dbc1161118a53cfa8a20ab379843b210af71728b.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=ZrEbzL9eQ3W,Scaling Laws for a Multi-Agent Reinforcement Learning Model,"['Oren Neumann', 'Claudius Gros']","['~Oren_Neumann1', 'gros@itp.uni-frankfurt.de']","['Neural scaling laws', 'Multi-agent reinforcement learning', 'AlphaZero']","The recent observation of neural power-law scaling relations has made a significant impact in the field of deep learning. A substantial amount of attention has been dedicated as a consequence to the description of scaling laws, although mostly for supervised learning and only to a reduced extent for reinforcement learning frameworks. In this paper we present an extensive study of performance scaling for a cornerstone reinforcement learning algorithm, AlphaZero. On the basis of a relationship between Elo rating, playing strength and power-law scaling, we train AlphaZero agents on the games Connect Four and Pentago and analyze their performance. We find that player strength scales as a power law in neural network parameter count when not bottlenecked by available compute, and as a power of compute when training optimally sized agents. We observe nearly identical scaling exponents for both games. Combining the two observed scaling laws we obtain a power law relating optimal size to compute similar to the ones observed for language models. We find that the predicted scaling of optimal neural network size fits our data for both games. This scaling law implies that previously published state-of-the-art game-playing models are significantly smaller than their optimal size, given the respective compute budgets. We also show that large AlphaZero models are more sample efficient, performing better than smaller models with the same amount of training data.",https://openreview.net/pdf/f98ab0085243b503d56efc920c90c19b95dc7ec8.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Zob4P9bRNcK,Learning Cut Selection for Mixed-Integer Linear Programming via Hierarchical Sequence Model,"['Zhihai Wang', 'Xijun Li', 'Jie Wang', 'Yufei Kuang', 'Mingxuan Yuan', 'Jia Zeng', 'Yongdong Zhang', 'Feng Wu']","['~Zhihai_Wang1', '~Xijun_Li1', '~Jie_Wang1', '~Yufei_Kuang1', '~Mingxuan_Yuan1', '~Jia_Zeng1', '~Yongdong_Zhang2', '~Feng_Wu1']","['mixed-integer linear programming', 'cut selection', 'deep reinforcement learning', 'sequence to sequence learning']","Cutting planes (cuts) are important for solving mixed-integer linear programs (MILPs), which formulate a wide range of important real-world applications. Cut selection---which aims to select a proper subset of the candidate cuts to improve the efficiency of solving MILPs---heavily depends on (P1) which cuts should be preferred, and (P2) how many cuts should be selected. Although many modern MILP solvers tackle (P1)-(P2) by manually designed heuristics, machine learning offers a promising approach to learn more effective heuristics from MILPs collected from specific applications. However, many existing learning-based methods focus on learning which cuts should be preferred, neglecting the importance of learning the number of cuts that should be selected. Moreover, we observe from extensive empirical results that (P3) what order of selected cuts should be preferred has a significant impact on the efficiency of solving MILPs as well. To address this challenge, we propose a novel hierarchical sequence model (HEM) to learn cut selection policies via reinforcement learning. Specifically, HEM consists of a two-level model: (1) a higher-level model to learn the number of cuts that should be selected, (2) and a lower-level model---that formulates the cut selection task as a sequence to sequence learning problem---to learn policies selecting an ordered subset with the size determined by the higher-level model. To the best of our knowledge, HEM is the first method that can tackle (P1)-(P3) in cut selection simultaneously from a data-driven perspective. Experiments show that HEM significantly improves the efficiency of solving MILPs compared to human-designed and learning-based baselines on both synthetic and large-scale real-world MILPs, including MIPLIB 2017. Moreover, experiments demonstrate that HEM well generalizes to MILPs that are significantly larger than those seen during training.",https://openreview.net/pdf/6885b5f02c9a39764dee43349192398b48a69fd5.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=ZZCJv2biATn,Target Conditioned Representation Independence (TCRI); from Domain-Invariant to Domain-General Representations,"['Olawale Elijah Salaudeen', 'Oluwasanmi O Koyejo']","['~Olawale_Elijah_Salaudeen1', '~Oluwasanmi_O_Koyejo1']","['Domain Generalization', 'Out-of-distribution Generalization', 'Transfer Learning', 'Distribution Shift', 'Covariate Shift']","We propose a Target Conditioned Representation Independence (TCRI) objective for domain generalization. TCRI addresses the limitations of existing domain generalization methods due to incomplete constraints. Specifically, TCRI implements regularizers motivated by conditional independence constraints that are sufficient to strictly learn complete sets of invariant mechanisms, which we show are necessary and sufficient for domain generalization. Empirically, we show that TCRI is effective on both synthetic and real-world data. TCRI is competitive with baselines in average accuracy while outperforming them in worst-domain accuracy, indicating desired cross-domain stability.",https://openreview.net/pdf/c42fd0b1a918283db9e8ad1e5441d9efd2339543.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=ZS8L3Fbv-L,The Value of Out-of-distribution Data,"['Ashwin De Silva', 'Rahul Ramesh', 'Carey Priebe', 'Pratik Chaudhari', 'Joshua T Vogelstein']","['~Ashwin_De_Silva1', '~Rahul_Ramesh2', '~Carey_Priebe1', '~Pratik_Chaudhari1', '~Joshua_T_Vogelstein1']","['Distribution Shift', 'Learning Theory']","More data is expected to help us generalize to a task. But real datasets can contain out-of-distribution (OOD) data; this can come in the form of heterogeneity such as intra-class variability but also in the form of temporal shifts or concept drifts. We demonstrate a counter-intuitive phenomenon for such problems: generalization error of the task can be a non-monotonic function of the number of OOD samples; a small number of OOD samples can improve generalization but if the number of OOD samples is beyond a threshold, then the generalization error can deteriorate. We also show that if we know which samples are OOD, then using a weighted objective between the target and OOD samples ensures that the generalization error decreases monotonically. We demonstrate and analyze this phenomenon using linear classifiers on synthetic datasets and medium-sized neural networks on vision benchmarks such as MNIST, CIFAR-10, CINIC-10, PACS, and DomainNet, and observe the effect data augmentation, hyperparameter optimization, and pre-training have on this behavior. ",https://openreview.net/pdf/2a040acaed5593c005905e432e20f78733547ae3.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=ZBUthI6wK9h,Robust Scheduling with GFlowNets,"['David W Zhang', 'Corrado Rainone', 'Markus Peschl', 'Roberto Bondesan']","['~David_W_Zhang1', '~Corrado_Rainone1', 'mpeschl@qti.qualcomm.com', '~Roberto_Bondesan1']","['Scheduling', 'GFlowNets', 'Combinatorial Optimization']","Finding the best way to schedule operations in a computation graph is a classical NP-hard problem which is central to compiler optimization. However, evaluating the goodness of a schedule on the target hardware can be very time-consuming. Traditional approaches as well as previous machine learning ones typically optimize proxy metrics, which are fast to evaluate but can lead to bad schedules when tested on the target hardware. In this work, we propose a new approach to scheduling by sampling proportionally to the proxy metric using a novel GFlowNet method. We introduce a technique to control the trade-off between diversity and goodness of the proposed schedules at inference time and demonstrate empirically that the pure optimization baselines can lead to subpar performance with respect to our approach when tested on a target model. Furthermore, we show that conditioning the GFlowNet on the computation graph enables generalization to unseen scheduling problems for both synthetic and real-world compiler datasets.",https://openreview.net/pdf/194aa63ea4f72f9cbdb927436fcd60b93e807444.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Z4lOwCEJQ8Z,Training Normalizing Flows from Dependent Data,"['Matthias Kirchler', 'Christoph Lippert', 'Marius Kloft']","['~Matthias_Kirchler1', '~Christoph_Lippert1', '~Marius_Kloft1']",['Normalizing Flows'],"Normalizing flows are powerful non-parametric statistical models that function as a hybrid between density estimators and generative models. Current learning algorithms for normalizing flows assume that data points are sampled independently, an assumption that is frequently violated in practice, which may lead to erroneous density estimation and data generation. We propose a likelihood objective of normalizing flows incorporating dependencies between the data points, for which we derive a flexible and efficient learning algorithm suitable for different dependency structures. We show that respecting dependencies between observations can improve empirical results on both synthetic and real-world data.

",https://openreview.net/pdf/6a6216ea87352439b3c7c6325a6497e22a690f6e.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=YfUICnZMwk7,Weighted Clock Logic Point Process,"['Ruixuan Yan', 'Yunshi Wen', 'Debarun Bhattacharjya', 'Ronny Luss', 'Tengfei Ma', 'Achille Fokoue', 'Anak Agung Julius']","['~Ruixuan_Yan1', 'weny2@rpi.edu', '~Debarun_Bhattacharjya1', '~Ronny_Luss1', '~Tengfei_Ma1', '~Achille_Fokoue1', '~Anak_Agung_Julius1']","['Multivariate event data', 'Neuro-symbolic models', 'Temporal point process', 'Propositional logic']","Datasets involving multivariate event streams are prevalent in numerous applications. We present a novel framework for modeling temporal point processes called clock logic neural networks (CLNN) which learn weighted clock logic (wCL) formulas as interpretable temporal rules by which some events promote or inhibit other events. Specifically, CLNN models temporal relations between events using conditional intensity rates informed by a set of wCL formulas, which are more expressive than related prior work. Unlike conventional approaches of searching for generative rules through expensive combinatorial optimization, we design smooth activation functions for components of wCL formulas that enable a continuous relaxation of the discrete search space and efficient learning of wCL formulas using gradient-based methods. Experiments on synthetic datasets manifest our model's ability to recover the ground-truth rules and improve computational efficiency. In addition, experiments on real-world datasets show that our models perform competitively when compared with state-of-the-art models. ",https://openreview.net/pdf/eb9a99d990427c8b4ac5187f36e3bf4c618b20bf.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=YdFkY-QHkPl,Provably Learning Diverse Features in Multi-View Data with Midpoint Mixup,"['Muthu Chidambaram', 'Xiang Wang', 'Chenwei Wu', 'Rong Ge']","['~Muthu_Chidambaram1', '~Xiang_Wang1', '~Chenwei_Wu1', '~Rong_Ge1']","['mixup', 'data augmentation', 'theory', 'optimization', 'multi-view', 'feature learning', 'generalization', 'deep learning']","Mixup is a data augmentation technique that relies on training using random convex combinations of data points and their labels. In recent years, Mixup has become a standard primitive used in the training of state-of-the-art image classification models due to its demonstrated benefits over empirical risk minimization with regards to generalization and robustness. In this work, we try to explain some of this success from a feature learning perspective. We focus our attention on classification problems in which each class may have multiple associated features (or views) that can be used to predict the class correctly. Our main theoretical results demonstrate that, for a non-trivial class of data distributions with two features per class, training a 2-layer convolutional network using empirical risk minimization can lead to learning only one feature for almost all classes while training with a specific instantiation of Mixup succeeds in learning both features for every class. We also show empirically that these theoretical insights extend to the practical settings of image benchmarks modified to have additional synthetic features.",https://openreview.net/pdf/9df8ff47ef9647935015f25d7345b30473336380.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Whf5OGxibGR,Causal discovery from conditionally stationary time series,"['Carles Balsells Rodas', 'Ruibo Tu', 'Hedvig Kjellstrom', 'Yingzhen Li']","['~Carles_Balsells_Rodas1', '~Ruibo_Tu1', '~Hedvig_Kjellstrom1', '~Yingzhen_Li1']","['causal discovery', 'temporal data', 'graph neural network', 'time series', 'non-stationary', 'probabilistic modelling']","Causal discovery, i.e., inferring underlying causal relationships from observational data, has been shown to be highly challenging for AI systems. In time series modeling context, traditional causal discovery methods mainly consider constrained scenarios with fully observed variables and/or data from stationary time-series. We develop a causal discovery approach to handle a wide class of non-stationary time-series that are conditionally stationary, where the non-stationary behaviour is modeled as stationarity conditioned on a set of (possibly hidden) state variables. Named state-dependent causal inference (SDCI), our approach is able to recover the underlying causal dependencies, provably with fully-observed states and empirically with hidden states. The latter is confirmed by experiments on synthetic linear system and nonlinear particle interaction data, where SDCI achieves superior performance over baseline causal discovery methods. Improved results over non-causal RNNs on modeling NBA player movements demonstrate the potential of our method and motivate the use causality-driven methods for forecasting.",https://openreview.net/pdf/46b3e389e9891387fa794849be72a7ac46cec7ac.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=WbyWDWoXD3,Feint in Multi-Player Games,"['Junyu Liu', 'Wangkai Jin', 'Xiangjun Peng']","['~Junyu_Liu5', '~Wangkai_Jin1', '~Xiangjun_Peng1']","['Feint', 'Multi-Player Games']","This paper introduces the first formalization, implementation and quantitative evaluation of \feint in Multi-Player Games. Our work first formalizes \feint from the perspective of Multi-Player Games, in terms of the temporal, spatial and their collective impacts. The formalization is built upon \textit{Non-transitive Active Markov Game Model}, where \feint can have a considerable amount of impacts. Then, our work considers practical implementation details of \feint in Multi-Player Games, under the state-of-the-art progress of multi-agent modeling to date (namely Multi-Agent Reinforcement Learning). Finally, our work quantitatively examines the effectiveness of our design, and the results show that our design of Feint can (1) greatly improve the reward gains from the game; (2) significantly improve the diversity of Multi-Player Games; and (3) only incur negligible overheads in terms of time consumption. We conclude that our design of Feint is effective and practical, to make Multi-Player Games more interesting.",https://openreview.net/pdf/8f3d206a3499ff07ce036109c750a257444d22a8.pdf,{'abstract_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=WOquZTLCBO1,VIPeR: Provably Efficient Algorithm for Offline RL with Neural Function Approximation,"['Thanh Nguyen-Tang', 'Raman Arora']","['~Thanh_Nguyen-Tang1', '~Raman_Arora1']","['Offline Reinforcement Learning', 'Neural Networks']","We propose a novel algorithm for offline reinforcement learning called Value Iteration with Perturbed Rewards (VIPeR), which amalgamates the pessimism principle with random perturbations of the value function. Most current offline RL algorithms explicitly construct statistical confidence regions to obtain pessimism via lower confidence bounds (LCB), which cannot easily scale to complex problems where a neural network is used to estimate the value functions. Instead, VIPeR implicitly obtains pessimism by simply perturbing the offline data multiple times with carefully-designed i.i.d. Gaussian noises to learn an ensemble of estimated state-action {value functions} and acting greedily with respect to the minimum of the ensemble. The estimated state-action values are obtained by fitting a parametric model (e.g., neural networks) to the perturbed datasets using gradient descent. As a result, VIPeR only needs $\mathcal{O}(1)$ time complexity for action selection, while LCB-based algorithms require at least $\Omega(K^2)$, where $K$ is the total number of trajectories in the offline data. We also propose a novel data-splitting technique that helps remove a factor involving the log of the covering number in our bound. We prove that VIPeR yields a provable uncertainty quantifier with overparameterized neural networks and enjoys a bound on sub-optimality of $\tilde{\mathcal{O}}(  { \kappa H^{5/2}  \tilde{d} }/{\sqrt{K}})$, where $\tilde{d}$ is the effective dimension, $H$ is the horizon length and $\kappa$ measures the distributional shift. We corroborate the statistical and computational efficiency of VIPeR with an empirical evaluation on a wide set of synthetic and real-world datasets. To the best of our knowledge, VIPeR is the first algorithm for offline RL that is provably efficient for general Markov decision processes (MDPs) with neural network function approximation. ",https://openreview.net/pdf/9a8eb48070ffcd0332fa35d7aaa9229cea1438c4.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=WL8FlAugqQ,Neural DAG Scheduling via One-Shot Priority Sampling,"['Wonseok Jeon', 'Mukul Gagrani', 'Burak Bartan', 'Weiliang Will Zeng', 'Harris Teague', 'Piero Zappi', 'Christopher Lott']","['~Wonseok_Jeon1', '~Mukul_Gagrani2', '~Burak_Bartan1', '~Weiliang_Will_Zeng1', '~Harris_Teague1', 'pzappi@qti.qualcomm.com', '~Christopher_Lott1']","['Combinatorial Optimization', 'Directed Acyclic Graph', 'Scheduling', 'Graph Neural Network', 'Reinforcement Learning']","We consider the problem of scheduling operations/nodes, the dependency among which is characterized by a Directed Acyclic Graph (DAG). Due to its NP-hard nature, heuristic algorithms were traditionally used to acquire reasonably good solutions, and more recent works have proposed Machine Learning (ML) heuristics that can generalize to unseen graphs and outperform the non-ML heuristics. However, it is computationally costly to generate solutions using existing ML schedulers since they adopt the episodic reinforcement learning framework that necessitates multi-round neural network processing. We propose a novel ML scheduler that uses a one-shot neural network encoder to sample node priorities which are converted by list scheduling to the final schedules. Since the one-shot encoder can efficiently sample the priorities in parallel, our algorithm runs significantly faster than existing ML baselines and has comparable run time with the fast traditional heuristics. We empirically show that our algorithm generates better schedules than both non-neural and neural baselines across various real-world and synthetic scheduling tasks.",https://openreview.net/pdf/20210ea69d6b5ccead90b146eeb53cf34ed79f34.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=WF7dU23lRCo,A $2$-parameter Persistence Layer for Learning,"['Cheng Xin', 'Soham Mukherjee', 'Shreyas N. Samaga', 'Tamal K. Dey']","['~Cheng_Xin2', '~Soham_Mukherjee1', '~Shreyas_N._Samaga1', '~Tamal_K._Dey1']","['topological data analysis', 'graph representation', 'persistent homology', '2-parameter persistence', 'graph neural network']","$1$-parameter persistent homology, a cornerstone in Topological Data Analysis (TDA), studies the evolution of topological features such as cycle basis hidden in data. It has found its application in strengthening the representation power of deep learning models like Graph Neural Networks (GNN). To enrich the representations of topological features,  here we propose to study $2$-parameter persistence modules induced by bi-filtration functions. In order to incorporate these representations into machine learning models, we introduce a novel vectorization on $2$-parameter persistence modules called Generalized Rank Invariant Landscape {\textsc{Gril}}. We show that this vector representation is stable and differentiable with respect to underlying filtration functions and can be easily integrated into machine learning models to augment encoding topological features. We present an algorithm to compute the vectorization and its gradients. We also test our methods on synthetic graph datasets and compare the results with some popular graph neural networks.",https://openreview.net/pdf/46ed6a698d545f9875361a36b2245291559665d4.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=WA35e2vPlFT,Neural Implicit Manifold Learning for Topology-Aware Generative Modelling,"['Brendan Leigh Ross', 'Gabriel Loaiza-Ganem', 'Anthony L. Caterini', 'Jesse C Cresswell']","['~Brendan_Leigh_Ross1', '~Gabriel_Loaiza-Ganem1', '~Anthony_L._Caterini1', '~Jesse_C_Cresswell1']","['Manifold Learning', 'Unsupervised Learning', 'Density Estimation', 'Topology', 'Differential Geometry', 'Generative Modelling']","Natural data observed in $\mathbb{R}^n$ is often constrained to an $m$-dimensional manifold $\mathcal{M}$, where $m < n$. Current probabilistic models represent this manifold by mapping an $m$-dimensional latent variable through a neural network $f_\theta: \mathbb{R}^m \to \mathbb{R}^n$. Such procedures, which we call pushforward models, incur a straightforward limitation: manifolds cannot in general be represented with a single parameterization, meaning that attempts to do so will incur either computational instability or the inability to learn probability densities within the manifold. To remedy this problem, we propose to model $\mathcal{M}$ as a neural implicit manifold: the set of zeros of a neural network. To learn the data distribution within $\mathcal{M}$, we introduce constrained energy-based models, which use a constrained variant of Langevin dynamics to train and sample within a learned manifold. The resulting model can be manipulated with an arithmetic of manifolds, which allows practitioners to take unions and intersections of model manifolds. In experiments on synthetic and natural data, we show that constrained EBMs can learn manifold-supported distributions with complex topologies more accurately than pushforward models.",https://openreview.net/pdf/24f8008772887d2a345bebc8b5a675d77f5b064a.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Vo1MVffQED,Oracles and Followers: Stackelberg Equilibria in Deep Multi-Agent Reinforcement Learning,"['Matthias Gerstgrasser', 'David C. Parkes']","['~Matthias_Gerstgrasser1', '~David_C._Parkes1']","['Multi-Agent Reinforcement Learning', 'Game Theory', 'Security Games', 'Mechanism Design', 'Stackelberg Equilibrium', 'Indirect Mechanism Design']","Stackelberg equilibria arise naturally in a range of popular learning problems, such as in security games or indirect mechanism design, and have received in- creasing attention in the reinforcement learning literature. We present a general framework for implementing Stackelberg equilibria search as a multi-agent RL problem, allowing a wide range of algorithmic design choices. We discuss how previous approaches can be seen as specific instantiations of this framework. As a key insight, we note that the design space allows for approaches not previously seen in the literature, for instance by leveraging multitask and meta-RL techniques for follower convergence. We propose one such approach using contextual poli- cies and evaluate it experimentally on standard benchmark domains. Finally, we illustrate the effect of adopting designs outside the borders of our framework in controlled experiments.",https://openreview.net/pdf/13cece9567e53f9dfc4afb43faab46f604980177.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Vf6WcUDnY7c,Optimizing Spca-based Continual Learning: A Theoretical Approach,"['Chunchun Yang', 'Malik Tiomoko', 'Zengfu Wang']","['~Chunchun_Yang1', '~Malik_Tiomoko1', 'zfwang@ustc.edu.cn']","['continual learning', 'high dimensional statistics', 'machine learning theory']","Catastrophic forgetting and the stability-plasticity dilemma are two major obstacles to continual learning. In this paper we first propose a theoretical analysis of a SPCA-based continual learning algorithm using high dimensional statistics. Second, we design OSCL  (Optimized Spca-based Continual Learning) which builds on a flexible task optimization based on the theory. By optimizing a single task, catastrophic forgetting can be prevented theoretically. While optimizing multi-tasks, the trade-off between integrating knowledge from the new task and retaining previous knowledge of the old task can be achieved by assigning appropriate weights to corresponding tasks in compliance with the objectives. Experimental results confirm that the various theoretical conclusions are robust to a wide range of data distributions. Besides, several applications on synthetic and real data show that the proposed method while being computationally efficient, achieves comparable results with some state of the art.",https://openreview.net/pdf/a20ec8899b62b37efc84fd55afa5fc1c384cbb3a.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Vf2DK1Ol0ed,A Benchmark Dataset for Learning from Label Proportions,"['Anand Paresh Brahmbhatt', 'Mohith Pokala', 'Rishi Saket', 'Aravindan Raghuveer']","['~Anand_Paresh_Brahmbhatt1', '~Mohith_Pokala1', '~Rishi_Saket1', '~Aravindan_Raghuveer1']","['Learning from Label Proportions', 'Benchmark Dataset', 'LLP']","Learning from label proportions (LLP) has recently emerged as an important technique of weakly supervised learning on aggregated labels. In LLP, a model is trained on groups (a.k.a bags) of feature-vectors and their corresponding label proportions to predict labels for individual feature-vectors. While previous works have developed a variety of techniques for LLP, including novel loss functions, model architectures and their optimization, they typically evaluated their methods on pseudo-synthetically generated LLP training data using common small scale supervised learning datasets by randomly sampling or partitioning their instances into bags.  Despite growing interest in this important task there are no large scale open source LLP benchmarks to compare various approaches. Construction of such a benchmark is hurdled by two challenges a) lack of natural large scale LLP like data, b) large number of mostly artificial methods of forming bags from instance level datasets. 
In this paper we propose LLP-Bench: a large scale LLP benchmark constructed from   the Criteo Kaggle CTR dataset. We do an in-depth, systematic study of the Criteo dataset and propose a methodology to create a  benchmark as a collection of diverse and large scale LLP datasets. We choose the Criteo dataset since it admits multiple natural collections of bags formed by grouping  subsets of its 26 categorical features. We analyze all bag collections obtained through grouping by one or two categorical features, in terms of their bag-level statistics as well as embedding based distance metrics quantifying the geometric separation of bags. We then propose to include in LLP-Bench a few groupings to fairly represent real world bag distributions.
We also measure the performance of state of the art models, loss functions (adapted to LLP) and optimizers on LLP-Bench. We perform a series of ablations and explain the performance of various techniques  on LLP-Bench. To the best of our knowledge LLP-Bench is the first open source benchmark for the LLP task. We hope that the proposed benchmark and the evaluation methodology will be used by ML researchers and practitioners to better understand and hence devise state of art LLP algorithms. ",https://openreview.net/pdf/091a6ae3959a706a0135d23c9032fbae501e415d.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=VYaTFO2Myi5,Towards Controllable Policy through Goal-Masked Transformers,"['Xinyao Niu', 'Tong Sang', 'Yuchen Sun', 'Xiangjun Wang']","['~Xinyao_Niu1', '~Tong_Sang1', '~Yuchen_Sun1', '~Xiangjun_Wang1']",[],"Offline goal-conditioned supervised learning (GCSL) can learn to achieve various goals from purely offline datasets without reward information, enhancing control over the policy. However, we argue that learning a composite policy switchable among different goals seamlessly should be an essential task for obtaining a controllable policy. This feature should be learnable if the dataset contains enough data about such switches. Unfortunately, most existing datasets either partially or entirely lack such switching demonstrations. Current GCSL approaches that use hindsight information concentrate primarily on reachability at the state or return level. They might not work as expected when the goal is changed within an episode. To this end, we present Goal-Masked Transformers (GMT), an efficient GCSL algorithm based on transformers with goal masking. GMT makes use of trajectory-level hindsight information, which is automatically gathered and can be adjusted for various statistics of interest. Due to the autoregressive nature of GMT, we can change the goal and control the policy at any time. We empirically evaluate GMT on MuJoCo continuous control benchmarks and Atari discrete control games with image states to compare GMT against baselines. We illustrate that GMT can infer the missing switching processes from the given dataset and thus switch smoothly among different goals. As a result, GMT demonstrates its ability to control policy and succeeds on all the tasks with low variance, while existing GCSL works can hardly succeed in goal-switching.",https://openreview.net/pdf/b4514e1359fdafebf8abe27cda428e460f2a3cf6.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=VIwEYmMID9R,DPMAC: Differentially Private Communication for Cooperative Multi-Agent Reinforcement Learning,"['Canzhe Zhao', 'Yanjie Ze', 'Jing Dong', 'Baoxiang Wang', 'Shuai Li']","['~Canzhe_Zhao1', '~Yanjie_Ze1', '~Jing_Dong3', '~Baoxiang_Wang1', '~Shuai_Li3']","['Communication in deep multi-agent reinforcement learning', 'Deep multi-agent reinforcement learning', 'Differential privacy', 'Game theory']","Communication lays the foundation for cooperation in human society and in multi-agent reinforcement learning (MARL). Humans also desire to maintain their privacy when communicating with others, yet such privacy concern has not been considered in existing works in MARL. We propose the \textit{differentially private multi-agent communication} (DPMAC) algorithm, which protects the sensitive information of individual agents by equipping each agent with a local message sender with rigorous $(\epsilon, \delta)$-differential privacy (DP) guarantee. In contrast to directly perturbing the messages with predefined DP noise as commonly done in privacy-preserving scenarios, we adopt a stochastic message sender for each agent respectively and incorporate the DP requirement into the sender, which automatically adjusts the learned message distribution to alleviate the instability caused by DP noise. Further, we prove the existence of a Nash equilibrium in cooperative MARL with privacy-preserving communication, which suggests that this problem is game-theoretically learnable. Extensive experiments demonstrate a clear advantage of DPMAC over baseline methods in privacy-preserving scenarios.",https://openreview.net/pdf/9daeb42348ce59d12ca4cf4989941cbfffedcfcc.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=VILHmvACcR,Learning to perceive objects by prediction,"['Tushar Arora', 'JOHN DAY', 'Li Erran Li', 'Ming Bo Cai']","['~Tushar_Arora1', '~JOHN_DAY1', '~Li_Erran_Li1', '~Ming_Bo_Cai1']","['self supervised learning', 'predictive learning', 'object-centric representation', '3D perception', 'sensory grounding']","The representation of objects is the building block of higher-level concepts. Infants develop the notion of objects without supervision, for which the prediction error of future sensory input is likely a major teaching signal. We assume that the goal of representing objects distinctly is to allow the prediction of the coherent motion of all parts of an object independently from the background while keeping track of relatively fewer parameters of the object's motion. To realize this, we propose a framework to extract object-centric representations from single 2D images by learning to predict future scenes containing moving objects. The model learns to explicitly infer objects' locations in a 3D environment, generate 2D segmentation masks of objects, and perceive depth. Importantly, the model requires no supervision or pre-training but assumes rigid-body motion and only needs the observer's self-motion at training time. Further, by evaluating on a new synthetic dataset with more complex textures of objects and background, we found our model overcomes the reliance on clustering colors for segmenting objects, which is a limitation for previous models not using motion information. Our work demonstrates a new approach to learning symbolic representation grounded in sensation and action.",https://openreview.net/pdf/07bf7a9bb819a7e18997f00a905fdde03f665130.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=VE1s3e5xriA,Dual Student Networks for Data-Free Model Stealing,"['James Beetham', 'Navid Kardan', 'Ajmal Saeed Mian', 'Mubarak Shah']","['~James_Beetham1', '~Navid_Kardan1', '~Ajmal_Saeed_Mian1', '~Mubarak_Shah3']",[],"Data-free model stealing aims to replicate a target model without direct access to either the training data or the target model. To accomplish this, existing methods use a generator to produce samples in order to train a student model to match the target model outputs. To this end, the two main challenges are estimating gradients of the target model without access to its parameters, and generating a diverse set of training samples that thoroughly explores the input space. We propose a Dual Student method where two students are symmetrically trained in order to provide the generator a criterion to generate samples that the two students disagree on. On one hand, disagreement on a sample implies at least one student has classified the sample incorrectly when compared to the target model. This incentive towards disagreement implicitly encourages the generator to explore more diverse regions of the input space. On the other hand, our method utilizes gradients of student models to indirectly estimate gradients of the target model. We show that this novel training objective for the generator network is equivalent to optimizing a lower bound on the generator's loss if we had access to the target model gradients. In other words, our method alters the standard data-free model stealing paradigm by substituting the target model with a separate student model, thereby creating a lower bound which can be directly optimized without additional target model queries or separate synthetic datasets. We show that our new optimization framework provides more accurate gradient estimation of the target model and better accuracies on benchmark classification datasets. Additionally, our approach balances improved query efficiency with training computation cost. Finally, we demonstrate that our method serves as a better proxy model for transfer-based adversarial attacks than existing data-free model stealing methods.",https://openreview.net/pdf/41d38335bded64c06dfd2672ead107cdf3b3e2d9.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=V2BQvSIWnYD,Learning Arborescence with An Efficient Inference Algorithm,"['Nan Jiang', 'Maxwell J Jacobson', 'Yexiang Xue']","['~Nan_Jiang7', '~Maxwell_J_Jacobson1', '~Yexiang_Xue1']","['minimum weight arborescence', 'arborescence Learning']","We consider a class of structured learning problems on arborescence (i.e., the directed spanning tree) from the input graph. The key step involved in this problem is predicting the minimal weight arborescence (MWA) from the learned model. In literature, there are two lines of research for predicting MWA: the Chu-Liu Edmonds (CLE) and the Lovasz methods.  The CLE method is easy to implement while it takes $\mathcal{O}(n)$ cycle contractions. Here $n$ is the graph size.  The Lovasz method reduces to the multi-pair shortest path (MPSP) problem and takes only $\mathcal{O}(\log n)$ contractions. Nevertheless, in the CPU setting, MPSP has the same time complexity as finding MWA. The Lovasz method only attains time efficiency under a sufficient GPU setting. Both the aforementioned methods are painfully slow for large-scale learning tasks.  In this research, we find the general MPSP problem can be simplified when working with machine learning models. This is because the learning model predicts edge weights for all pairs of vertices and the graph we process is always complete.  Therefore, we only need to handle those paths that directly enter every weakly connected component (WCC) while the classic Lovasz method needs to handle all possible paths. This allows us to propose LAzy LoVAz (Lava) method that enjoys $\mathcal{O}(\log n)$ contractions as well as efficient performance in both CPU and GPU settings. In experiments, we consider synthetic datasets and two real-world learning tasks, i.e., graph-based dependency parsing and unsupervised parsing on ListOps.  The empirical results exhibit important gains of our Lava method to the classic CLE and Lovasz methods, that Lava boosts the training time for arborescence learning tasks.",https://openreview.net/pdf/bc40b11773f87e44c9cbaad664670bd51ad5bf49.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Uzgfy7_v7BH,Causal Mean Field Multi-Agent Reinforcement Learning,"['Hao Ma', 'Zhiqiang Pu', 'Yi Pan', 'Boyin Liu', 'Min Chen', 'Shijie Wang']","['~Hao_Ma5', '~Zhiqiang_Pu1', 'yi.pan@ia.ac.cn', '~Boyin_Liu2', 'chenmin161@mails.ucas.ac.cn', 'shijie.wang2022@outlook.com']","['multi-agent reinforcement mearning', 'causal inference']","Scalability remains a challenge in multi-agent reinforcement learning and is currently under active research. However, existing works lack the ability to identify the essential interaction under the non-stationary environment. We propose causal mean field Q-learning (CMFQ) to address this problem. It has the advantage of MFQ, which can compress the space size dramatically. Besides, it is ever more robust toward the non-stationary caused by increasing agents. We enable agents to identify which ally or opponent is more crucial by asking ""what if"" with the help of the structural causal model (SCM), then pay more attention to more crucial ones. We test CMFQ in mixed cooperative-competitive and cooperative games, which verify our method's scalability performance.",https://openreview.net/pdf/f63600d93314ac2fbf21e84d755a6a063521277e.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=UrzBg1Zz7ob,Towards a More Rigorous Science of Blindspot Discovery in Image Models,"['Gregory Plumb', 'Nari Johnson', 'Angel Cabrera', 'Ameet Talwalkar']","['~Gregory_Plumb2', '~Nari_Johnson1', '~Angel_Cabrera1', '~Ameet_Talwalkar1']",[],"A growing body of work studies Blindspot Discovery Methods (BDMs): methods for finding semantically meaningful subsets of the data where an image classifier performs significantly worse, without making strong assumptions. Motivated by observed gaps in prior work, we introduce a new framework for evaluating BDMs, SpotCheck, that uses synthetic image datasets to train models with known blindspots and a new BDM, PlaneSpot, that uses a 2D image representation. We use SpotCheck to run controlled experiments that identify factors that influence BDM performance (e.g., the number of blindspot in a model) and show that PlaneSpot outperforms existing BDMs. Importantly, we validate these findings using real data. Overall, we hope that the methodology and analyses presented in this work will serve as a guide for future work on blindspot discovery.",https://openreview.net/pdf/51d998560ec0d5bb53370e7bc09f768675b6001b.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=UmU9mydWRV3,Neural DAEs: Constrained neural networks,"['Tue Boesen', 'Eldad Haber', 'Uri M. Ascher']","['~Tue_Boesen1', '~Eldad_Haber3', 'ascher@cs.ubc.ca']","['neural networks', 'differential algebraic equations', 'constraints']","In this article we investigate the effect of explicitly adding auxiliary trajectory information to neural networks for dynamical systems. We draw inspiration from the field of differential-algebraic equations and differential equations on manifolds and implement similar methods in residual neural networks. We discuss constraints through stabilization as well as projection methods, and show when to use which method based on experiments involving simulations of multi-body pendulums and molecular dynamics scenarios. Several of our methods are easy to implement in existing code and have limited impact on performance while giving significant boosts in terms of inference.",https://openreview.net/pdf/31a8d71c7983fafb342736a1828d1de79007f0f0.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=UkU05GOH7_6,Generating Diverse Cooperative Agents by Learning Incompatible Policies,"['Rujikorn Charakorn', 'Poramate Manoonpong', 'Nat Dilokthanakul']","['~Rujikorn_Charakorn1', '~Poramate_Manoonpong1', '~Nat_Dilokthanakul1']","['multi-agent systems', 'cooperation', 'collaboration', 'reinforcement learning', 'diversity', 'robustness']","Training a robust cooperative agent requires diverse partner agents. However, obtaining those agents is difficult. Previous works aim to learn diverse behaviors by changing the state-action distribution of agents. But, without information about the task's goal, the diversified agents are not guided to find other important, albeit sub-optimal, solutions: the agents might learn only variations of the same solution. In this work, we propose to learn diverse behaviors via policy compatibility. Conceptually, policy compatibility measures whether policies of interest can coordinate effectively. We theoretically show that incompatible policies are not similar. Thus, policy compatibility—which has been used exclusively as a measure of robustness—can be used as a proxy for learning diverse behaviors. Then, we incorporate the proposed objective into a population-based training scheme to allow concurrent training of multiple agents. Additionally, we use state-action information to induce local variations of each policy. Empirically, the proposed method consistently discovers more solutions than baseline methods across various multi-goal cooperative environments. Finally, in multi-recipe Overcooked, we show that our method produces populations of behaviorally diverse agents, which enables generalist agents trained with such a population to be more robust.

See our project page at https://bit.ly/marl-lipo
",https://openreview.net/pdf/ac9e4f47a8a7afc2d31fe69575bb97700dd88071.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=UYS38ssi1M,Learning GFlowNets from partial episodes for improved convergence and stability,"['Kanika Madan', 'Jarrid Rector-Brooks', 'Maksym Korablyov', 'Emmanuel Bengio', 'Moksh Jain', 'Andrei Cristian Nica', 'Tom Bosc', 'Yoshua Bengio', 'Nikolay Malkin']","['~Kanika_Madan3', '~Jarrid_Rector-Brooks2', '~Maksym_Korablyov1', '~Emmanuel_Bengio1', '~Moksh_Jain1', '~Andrei_Cristian_Nica1', '~Tom_Bosc1', '~Yoshua_Bengio1', '~Nikolay_Malkin1']","['GFlowNets', 'probabilistic modeling', 'reinforcement learning']","Generative flow networks (GFlowNets) are a family of algorithms for training a sequential sampler of discrete objects under an unnormalized target density and have been successfully used for various probabilistic modeling tasks. Existing training objectives for GFlowNets are either local to states or transitions, or propagate a reward signal over an entire sampling trajectory. We argue that these alternatives represent opposite ends of a gradient bias-variance tradeoff and propose a way to exploit this tradeoff to mitigate its harmful effects. Inspired by the TD($\lambda$) algorithm in reinforcement learning, we introduce subtrajectory balance or SubTB($\lambda$), a GFlowNet training objective that can learn from partial action subsequences of varying lengths. We show that SubTB($\lambda$) accelerates sampler convergence in previously studied and new environments and enables training GFlowNets in environments with longer action sequences and sparser reward landscapes than what was possible before. We also perform a comparative analysis of stochastic gradient dynamics, shedding light on the bias-variance tradeoff in GFlowNet training and the advantages of subtrajectory balance.",https://openreview.net/pdf/8bdb6b759d5bda81ec90b669c7cbec534c1db61d.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=UP_GHHPw7rP,Nearly Minimax Optimal Offline Reinforcement Learning with Linear Function Approximation: Single-Agent MDP and Markov Game,"['Wei Xiong', 'Han Zhong', 'Chengshuai Shi', 'Cong Shen', 'Liwei Wang', 'Tong Zhang']","['~Wei_Xiong9', '~Han_Zhong1', '~Chengshuai_Shi1', '~Cong_Shen1', '~Liwei_Wang1', '~Tong_Zhang2']",['RL theory'],"Offline reinforcement learning (RL) aims at learning an optimal strategy using a pre-collected dataset without further interactions with the environment. While various algorithms have been proposed for offline RL in the previous literature, the minimax optimality has only been (nearly) established for tabular Markov decision processes (MDPs). In this paper, we focus on offline RL with linear function approximation and propose a new pessimism-based algorithm for offline linear MDP. At the core of our algorithm is the uncertainty decomposition via a reference function, which is new in the literature of offline RL under linear function approximation. Theoretical analysis demonstrates that our algorithm can match the performance lower bound up to logarithmic factors. We also extend our techniques to the two-player zero-sum Markov games (MGs), and establish a new performance lower bound for MGs, which tightens the existing result, and verifies the nearly minimax optimality of the proposed algorithm. To the best of our knowledge, these are the first computationally efficient and nearly minimax optimal algorithms for offline single-agent MDPs and MGs with linear function approximation.",https://openreview.net/pdf/4ec7b1dd165364db85e719d8b2232962869eb44d.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=UJ4nGMHZYI,Factor Learning Portfolio Optimization Informed by Continuous-Time Finance Models,"['Sinong Geng', 'houssam nassif', 'Zhaobin Kuang', 'Anders Max Reppen', 'K. Ronnie Sircar']","['~Sinong_Geng1', '~houssam_nassif1', '~Zhaobin_Kuang1', '~Anders_Max_Reppen1', '~K._Ronnie_Sircar1']",[],"We study financial portfolio optimization in the presence of unknown and uncontrolled system variables referred to as stochastic factors. Existing work falls into two distinct categories: (i) reinforcement learning employs end-to-end policy learning with flexible factor representation, but does not precisely model the dynamics of asset prices or factors; (ii) continuous-time finance methods, in contrast, take advantage of explicitly modeled dynamics but pre-specify, rather than learn, factor representation. We propose FaLPO (factor learning portfolio optimization), a framework that interpolates between these two approaches. Specifically, FaLPO hinges on deep policy gradient to learn a performant investment policy that takes advantage of flexible representation for stochastic factors. Meanwhile, FaLPO also incorporates continuous-time finance models when modeling the dynamics. It uses the optimal policy functional form derived from such models and optimizes an objective that combines policy learning and model calibration. We prove the convergence of FaLPO, and provide performance guarantees via a finite-sample bound. On both synthetic and real-world portfolio optimization tasks, we observe that FaLPO outperforms five leading methods. Finally, we show that FaLPO can be extended to other decision-making problems with stochastic factors.",https://openreview.net/pdf/92cd77cc4d9da949c287fa768b8ff1f8c1df33cf.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=U0jfsqmoV-4,Instruction-Following Agents with Jointly Pre-Trained Vision-Language Models,"['Hao Liu', 'Lisa Lee', 'Kimin Lee', 'Pieter Abbeel']","['~Hao_Liu1', '~Lisa_Lee1', '~Kimin_Lee1', '~Pieter_Abbeel2']","['reinforcement learning', 'pre-training', 'multimodal representation', 'representation learning', 'transformer']","Humans are excellent at understanding language and vision to accomplish a wide range of tasks. In contrast, creating general instruction-following embodied agents remains a difficult challenge. Prior work that uses pure language-only models lack visual grounding, making it difficult to connect language instructions with visual observations. On the other hand, methods that use pre-trained vision-language models typically come with divided language and visual representations, requiring designing specialized network architecture to fuse them together. We propose a simple yet effective model for robots to solve instruction-following tasks in vision-based environments. Our InstructRL method consists of a multimodal transformer that encodes visual observations and language instructions, and a policy transformer that predicts actions based on encoded representations. The multimodal transformer is pre-trained on millions of image-text pairs and natural language text, thereby producing generic cross-modal representations of observations and instructions. The policy transformer keeps track of the full history of observations and actions, and predicts actions autoregressively. We show that this unified transformer model outperforms all state-of-the-art pre-trained or trained-from-scratch methods in both single-task and multi-task settings. Our model also shows better model scalability and generalization ability than prior work.",https://openreview.net/pdf/ccaa63e0939bc0518db8c562fc78c1f7787d73e6.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=TnzdAU7c8WM,Learning Visual Representation with Synthetic Images and Topologically-defined Labels,"['Shizuo Kaji', 'Yohsuke Watanabe']","['~Shizuo_Kaji1', '~Yohsuke_Watanabe1']","['topology', 'persistent homology', 'self-supervised learning', 'synthetic image']","We propose a scheme for neural networks to learn visual representation with synthetic images and mathematically-defined labels that capture topological information. To verify that the model acquires a different visual representation than with the usual supervised learning with manually-defined labels, we show that the models pretrained with our scheme can be finetuned for image classification tasks to achieve an improved convergence compared to those trained from scratch. 
Convolutional neural networks, built upon iterative local operations, are good at learning local features of the image, such as texture, whereas they tend to pay less attention to larger structures. Our method provides a simple way to encourage the model to learn global features through a specifically designed task based on topology. Furthermore, our method requires no real images nor manual labels; hence it sheds light on some of the lately concerned topics in computer vision, such as the cost and the fairness in data collection and annotation.",https://openreview.net/pdf/eca47190f4243002b44c64fadae87121aa45e4fa.pdf,{'title_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Th98b8dH4yr,Tangential Wasserstein Projections,"['Florian Gunsilius', 'Meng Hsuan Hsieh', 'Myung Jin Lee']","['~Florian_Gunsilius1', '~Meng_Hsuan_Hsieh1', '~Myung_Jin_Lee1']","['Optimal Transport', 'Wasserstein', 'Generalized geodesics', 'Projection', 'Tangent Cone', 'Causal Inference']","We develop a notion of projections between sets of probability measures using the geometric properties of the $2$-Wasserstein space. It is designed for general multivariate probability measures, is computationally efficient to implement, and provides a unique solution in regular settings. The idea is to work on regular tangent cones of the Wasserstein space using generalized geodesics. Its structure and computational properties make the method applicable in a variety of settings, from causal inference to the analysis of object data. An application to estimating causal effects yields a generalization of the notion of synthetic controls for systems with general heterogeneity described via multivariate probability measures, as well as a way to estimate optimal weights jointly over all time periods.",https://openreview.net/pdf/e5532e5044e7064cdd070609e8d691381bc88c09.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=TdTGGj7fYYJ,Unsupervised Meta-learning via Few-shot Pseudo-supervised Contrastive Learning,"['Huiwon Jang', 'Hankook Lee', 'Jinwoo Shin']","['~Huiwon_Jang1', '~Hankook_Lee1', '~Jinwoo_Shin1']","['unsupervised meta-learning', 'supervised contrastive learning', 'self-supervised learning']","Unsupervised meta-learning aims to learn generalizable knowledge across a distribution of tasks constructed from unlabeled data. Here, the main challenge is how to construct diverse tasks for meta-learning without label information; recent works have proposed to create, e.g., pseudo-labeling via pretrained representations or creating synthetic samples via generative models. However, such a task construction strategy is fundamentally limited due to heavy reliance on the immutable pseudo-labels during meta-learning and the quality of the representations or the generated samples. To overcome the limitations, we propose a simple yet effective unsupervised meta-learning framework, coined Pseudo-supervised Contrast (PsCo), for few-shot classification. We are inspired by the recent self-supervised learning literature; PsCo utilizes a momentum network and a queue of previous batches to improve pseudo-labeling and construct diverse tasks in a progressive manner. Our extensive experiments demonstrate that PsCo outperforms existing unsupervised meta-learning methods under various in-domain and cross-domain few-shot classification benchmarks. We also validate that PsCo is easily scalable to a large-scale benchmark, while recent prior-art meta-schemes are not.",https://openreview.net/pdf/65c63b72201856c7d08ce81fba8f12b50947aa77.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Tb3ZJBDF7aA,Pre-training Protein Structure Encoder via Siamese Diffusion Trajectory Prediction,"['Zuobai Zhang', 'Minghao Xu', 'Aurelie Lozano', 'Vijil Chenthamarakshan', 'Payel Das', 'Jian Tang']","['~Zuobai_Zhang1', '~Minghao_Xu1', '~Aurelie_Lozano1', '~Vijil_Chenthamarakshan1', '~Payel_Das1', '~Jian_Tang1']","['Protein representation learning', 'diffusion models', 'self-supervised learning']","Due to the determining role of protein structures on diverse protein functions, pre-training representations of proteins on massive unlabeled protein structures has attracted rising research interests. Among recent efforts on this direction, mutual information (MI) maximization based methods have gained the superiority on various downstream benchmark tasks. The core of these methods is to design correlated views that share common information about a protein. Previous view designs focus on capturing structural motif co-occurrence on the same protein structure, while they cannot capture detailed atom/residue interactions. To address this limitation, we propose the Siamese Diffusion Trajectory Prediction (SiamDiff) method. SiamDiff builds a view as the trajectory that gradually approaches protein native structure from scratch, which facilitates the modeling of atom/residue interactions underlying the protein structural dynamics. Specifically, we employ the multimodal diffusion process as a faithful simulation of the structure-sequence co-diffusion trajectory, where rich patterns of protein structural changes are embedded. On such basis, we design a principled theoretical framework to maximize the MI between correlated multimodal diffusion trajectories. We study the effectiveness of SiamDiff on both residue-level and atom-level structures. On the EC and ATOM3D benchmarks, we extensively compare our method with previous protein structure pre-training approaches. The experimental results verify the consistently superior or competitive performance of SiamDiff on all benchmark tasks compared to existing baselines. The source code will be made public upon acceptance.",https://openreview.net/pdf/1c7b861dfae0a1beada9e33038d8d6adb117d5c4.pdf,{'title_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=TPiwkItUSu,Behind the Scenes of Gradient Descent: A Trajectory Analysis via Basis Function Decomposition,"['Jianhao Ma', 'Lingjun Guo', 'Salar Fattahi']","['~Jianhao_Ma1', '~Lingjun_Guo1', '~Salar_Fattahi2']","['nonconvex optimization', 'trajectory analysis', 'neural network optimization']","This work analyzes the solution trajectory of gradient-based algorithms via a novel basis function decomposition. We show that, although solution trajectories of gradient-based algorithms may vary depending on the learning task, they behave almost monotonically when projected onto an appropriate orthonormal function basis. Such projection gives rise to a basis function decomposition of the solution trajectory. Theoretically, we use our proposed basis function decomposition to establish the convergence of gradient descent (GD) on several representative learning tasks. In particular, we improve the convergence of GD on symmetric matrix factorization and provide a completely new convergence result for the orthogonal symmetric tensor decomposition. Empirically, we illustrate the promise of our proposed framework on realistic deep neural networks (DNNs) across different architectures, gradient-based solvers, and datasets. Our key finding is that gradient-based algorithms monotonically learn the coefficients of a particular orthonormal function basis of DNNs defined as the eigenvectors of the conjugate kernel after training.",https://openreview.net/pdf/ca6112e62d0190aca22c33e237c6215e3ad9962e.pdf,{'title_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=TMYzh1hsHd,MA2QL: A Minimalist Approach to Fully Decentralized Multi-Agent Reinforcement Learning,"['Kefan Su', 'Siyuan Zhou', 'Chuang Gan', 'Xiangjun Wang', 'Zongqing Lu']","['~Kefan_Su1', '~Siyuan_Zhou2', '~Chuang_Gan1', '~Xiangjun_Wang1', '~Zongqing_Lu2']",['multi-agent reinforcement learning'],"Decentralized learning has shown great promise for cooperative multi-agent reinforcement learning (MARL). However, non-stationarity remains a significant challenge in fully decentralized learning. In the paper, we tackle the non-stationarity problem in the simplest and fundamental way and propose multi-agent alternate Q-learning (MA2QL), where agents take turns to update their Q-functions by Q-learning. MA2QL is a minimalist approach to fully decentralized cooperative MARL but is theoretically grounded. We prove that when each agent guarantees $\varepsilon$-convergence at each turn, their joint policy converges to a Nash equilibrium. In practice, MA2QL only requires minimal changes to independent Q-learning (IQL). We empirically evaluate MA2QL on a variety of cooperative multi-agent tasks. Results show MA2QL consistently outperforms IQL, which verifies the effectiveness of MA2QL, despite such minimal changes.",https://openreview.net/pdf/64d8a2ca3d5acc89e42a1e5fbd1436913b71078b.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=TLx9diIRJVj,SynBench: Task-Agnostic Benchmarking of Pretrained Representations using Synthetic Data,"['Ching-Yun Ko', 'Pin-Yu Chen', 'Jeet Mohapatra', 'Payel Das', 'Luca Daniel']","['~Ching-Yun_Ko1', '~Pin-Yu_Chen1', '~Jeet_Mohapatra1', '~Payel_Das1', '~Luca_Daniel1']",[],"Recent success in fine-tuning large models, that are pretrained on broad data at scale, on downstream tasks has led to a significant paradigm shift in deep learning, from task-centric model design to task-agnostic representation learning and task-specific fine-tuning. As the representations of pretrained models are used as a foundation for different downstream tasks, this paper proposes a new task-agnostic framework, \textit{SynBench}, to measure the quality of pretrained representations using synthetic data. We set up a reference by a theoretically-derived robustness-accuracy tradeoff of the class conditional Gaussian mixture. Given a pretrained model, the representations of data synthesized from the Gaussian mixture are used to compare with our reference to infer the quality. By comparing the ratio of area-under-curve between the raw data and their representations, SynBench offers a quantifiable score for robustness-accuracy performance benchmarking. Our framework applies to a wide range of pretrained models taking continuous data inputs and is independent of the downstream tasks and datasets. Evaluated with several pretrained vision transformer models, the experimental results show that our SynBench score well matches the actual linear probing performance of the pre-trained model when fine-tuned on downstream tasks. Moreover, our framework can be used to inform the design of robust linear probing on pretrained representations to mitigate the robustness-accuracy tradeoff in downstream tasks.",https://openreview.net/pdf/7d4c6af5e3f9c83b39cd7960f76b0f8500ab585b.pdf,{'title_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=TJPmwnQIMmw,Adversarial Causal Augmentation for Graph Covariate Shift,"['Yongduo Sui', 'Xiang Wang', 'Jiancan Wu', 'An Zhang', 'Xiangnan He', 'Tat-Seng Chua']","['~Yongduo_Sui1', '~Xiang_Wang6', '~Jiancan_Wu1', '~An_Zhang2', '~Xiangnan_He1', '~Tat-Seng_Chua2']","['Graph Data Augmentation', 'Graph Neural Networks', 'Covariate Shift', 'OOD Generalization']","Out-of-distribution (OOD) generalization on graphs is drawing widespread attention. However, existing efforts mainly focus on the OOD issue of correlation shift. While another type, covariate shift, remains largely unexplored but is the focus of this work. From a data generation view, causal features are stable substructures in data, which play key roles in OOD generalization. While their complementary parts, environments, are unstable features that often lead to various distribution shifts. Correlation shift establishes spurious statistical correlations between environments and labels. In contrast, covariate shift means that there exist unseen environmental features in test data. Existing strategies of graph invariant learning and data augmentation suffer from limited environments or unstable causal features, which greatly limits their generalization ability on covariate shift. In view of that, we propose a novel graph augmentation strategy: Adversarial Causal Augmentation (AdvCA), to alleviate the covariate shift. Specifically, it adversarially augments the data to explore diverse distributions of the environments. Meanwhile, it keeps the causal features invariant across diverse environments. It maintains the environmental diversity while ensuring the invariance of the causal features, thereby effectively alleviating the covariate shift. Extensive experimental results with in-depth analyses demonstrate that AdvCA can outperform 14 baselines on synthetic and real-world datasets with various covariate shifts.",https://openreview.net/pdf/7d9688e93892271720938ff6bfa929724e3f6a56.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=TBOFHtBariC,On discrete symmetries of robotics systems: A group-theoretic and data-driven analysis,"['Daniel Ordonez-Apraez', 'Mario Martin', 'Antonio Agudo', 'Francesc Moreno-Noguer']","['~Daniel_Ordonez-Apraez1', '~Mario_Martin2', '~Antonio_Agudo3', '~Francesc_Moreno-Noguer1']","['Morphological Symmetries', 'Discrete Symmetries of Dynamical Systems', 'Equivariant Dynamics', 'Equivariant Function Approximators', 'Geometric Deep Learning']","In this work, we study the Morphological Symmetries of dynamical systems with one or more planes of symmetry, a predominant feature in animal biology and robotic systems, characterized by the duplication and balanced distribution of body parts. These morphological symmetries imply that the system's dynamics are symmetric (or approximately symmetric), which in turn imprints symmetries in optimal control policies and in all proprioceptive and exteroceptive measurements related to the evolution of the system's dynamics. For data-driven methods, symmetry represents an inductive bias that justifies data augmentation and the construction of symmetric function approximators. To this end, we use Group Theory to present a theoretical and practical framework allowing for (1) the identification of the system's morphological symmetry Group $\G$, (2) the characterization of how the group acts upon the system state variables and any relevant measurement living in the Euclidean space, and (3) the exploitation of data symmetries through the use of $\G$-equivariant/$\G$-invariant Neural Networks, for which we present experimental results on synthetic and real-world applications, demonstrating how symmetry constraints lead to better sample efficiency and generalization while reducing the number of trainable parameters.",https://openreview.net/pdf/f79b3ac494d465f44557e3e5b9f6d460668b91fc.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=T6HPzkhaKeS,Action Matching: A Variational Method for Learning Stochastic Dynamics from Samples,"['Kirill Neklyudov', 'Daniel Severo', 'Alireza Makhzani']","['~Kirill_Neklyudov1', '~Daniel_Severo1', '~Alireza_Makhzani1']",[],"Stochastic dynamics are ubiquitous in many fields of science, from the evolution of quantum systems in physics to diffusion-based models in machine learning. Existing methods such as score matching can be used to simulate these physical processes by assuming that the dynamics is a diffusion, which is not always the case. In this work, we propose a method called ""Action Matching"" that enables us to learn a much broader family of stochastic dynamics. Our method requires access only to samples from different time-steps, makes no explicit assumptions about the underlying dynamics, and can be applied even when samples are uncorrelated (i.e., are not part of a trajectory). Action Matching directly learns an underlying mechanism to move samples in time without modeling the distributions at each time-step. In this work, we showcase how Action Matching can be used for several computer vision tasks such as generative modeling, super-resolution, colorization, and inpainting; and further discuss potential applications in other areas of science.",https://openreview.net/pdf/be11a3215548703bc487696afb43b9cd7a63f81d.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=SxO-qoAwVM,Understanding Hindsight Goal Relabeling Requires Rethinking Divergence Minimization,"['Lunjun Zhang', 'Bradly C. Stadie']","['~Lunjun_Zhang1', '~Bradly_C._Stadie1']","['reinforcement learning', 'multi-goal reinforcement learning', 'imitation learning']","Hindsight goal relabeling has become a foundational technique for multi-goal reinforcement learning (RL). The idea is quite simple: any arbitrary trajectory can be seen as an expert demonstration for reaching the trajectory's end state. Intuitively, this procedure trains a goal-conditioned policy to imitate a sub-optimal expert. However, this connection between imitation and hindsight relabeling is not well understood. Modern imitation learning algorithms are described in the language of divergence minimization, and yet it remains an open problem how to recast hindsight goal relabeling into that framework. In this work, we develop a unified objective for goal-reaching that explains such a connection, from which we can derive goal-conditioned supervised learning (GCSL) and the reward function in hindsight experience replay (HER) from first principles. Experimentally, we find that despite recent advances in goal-conditioned behaviour cloning (BC), multi-goal Q-learning can still outperform BC-like methods; moreover, a vanilla combination of both actually hurts model performance. Under our framework, we study when BC is expected to help, and empirically validate our findings. Our work further bridges goal-reaching and generative modeling, illustrating the nuances and new pathways of extending the success of generative models to RL.",https://openreview.net/pdf/916bf81972cae1705a77d99a562a532a60fa090c.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=SaRj2ka1XZ3,Language Models Can Teach Themselves to Program Better,"['Patrick Haluptzok', 'Matthew Bowers', 'Adam Tauman Kalai']","['~Patrick_Haluptzok1', '~Matthew_Bowers1', '~Adam_Tauman_Kalai1']","['deep learning', 'natural language processing', 'program synthesis', 'large language models']","Recent Language Models (LMs) achieve breakthrough performance in code generation when trained on human-authored problems, even solving some competitive-programming problems. Self-play has proven useful in games such as Go, and thus it is natural to ask whether LMs can generate their own instructive programming problems to improve their performance. We show that it is possible for an LM to synthesize programming problems and solutions, which are filtered for correctness by a Python interpreter. The LM’s performance is then seen to improve when it is fine-tuned on its own synthetic problems and verified solutions; thus the model “improves itself” using the Python interpreter. Problems are specified formally as programming puzzles [Schuster et al. , 2021], a code-based problem format where solutions can easily be verified for correctness by execution. In experiments on publicly-available LMs, test accuracy more than doubles. This work demonstrates the potential for code LMs, with an interpreter, to generate instructive problems and improve their own performance.",https://openreview.net/pdf/70f1e70fce89088da12b7493b7d1a8d444a2acec.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=S9GpoS2TmN,Abstract-to-Executable Trajectory Translation for One-Shot Task Generalization,"['Stone Tao', 'Xiaochen Li', 'Tongzhou Mu', 'Zhiao Huang', 'Yuzhe Qin', 'Hao Su']","['~Stone_Tao1', '~Xiaochen_Li1', '~Tongzhou_Mu1', '~Zhiao_Huang1', '~Yuzhe_Qin1', '~Hao_Su1']","['Trajectory Translation', 'One-Shot Generalization', 'Long-Horizon Task', 'Reinforcement Learning']","Training long-horizon robotic policies in complex physical environments is essential for many applications, such as robotic manipulation. However, learning a policy that can generalize to unseen tasks is challenging. In this work, we propose to achieve one-shot task generalization by decoupling plan generation and plan execution. Specifically, our method solves complex long-horizon tasks in three steps: build a paired abstract environment by simplifying geometry and physics, generate abstract trajectories, and solve the original task by an abstract-to-executable trajectory translator. In the abstract environment, complex dynamics such as physical manipulation are removed, making abstract trajectories easier to generate. However, this introduces a large domain gap between abstract trajectories and the actual executed trajectories as abstract trajectories lack low-level details and aren’t aligned frame-to-frame with the executed trajectory. In a manner reminiscent of language translation, our approach leverages a seq-to-seq model to overcome the large domain gap between the abstract and executable trajectories, enabling the low-level policy to follow the abstract trajectory. Experimental results on various unseen long-horizon tasks with different robot embodiments demonstrate the practicability of our methods to achieve one-shot task generalization. Videos and more details can be found in the supplementary materials and project page: https://sites.google.com/view/abstract-to-executable-iclr23/",https://openreview.net/pdf/8cbd0d88c301cc75e09f0b4d0bd54348b35ff3a9.pdf,{'title_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=S80ioOGLpD9,Joint-Predictive Representations for Multi-Agent Reinforcement Learning,"['Mingxiao Feng', 'Wengang Zhou', 'Yaodong Yang', 'Houqiang Li']","['~Mingxiao_Feng1', '~Wengang_Zhou1', '~Yaodong_Yang1', '~Houqiang_Li1']",[],"The recent advances in reinforcement learning have demonstrated the effectiveness of vision-based self-supervised learning (SSL). However, the main efforts on this direction have been paid on single-agent setting, making multi-agent reinforcement learning~(MARL) lags thus far. There are two significant obstacles that prevent applying off-the-shelf SSL approaches with MARL on a partially observable multi-agent system : (a) each agent only gets a partial observation, and (b) previous SSL approaches only take consistent temporal representations into account, while ignoring the characterization that captures the interaction and fusion among agents. In this paper, we propose \textbf{M}ulti-\textbf{A}gent  \textbf{Jo}int-Predictive \textbf{R}epresentations~(MAJOR), a novel framework to explore self-supervised learning on cooperative MARL. Specifically, we treat the latent representations of local observations of all agents as the sequence of masked contexts of the global state, and we then learn effective representations by predicting the future latent representations for each agent with the help of the agent-level information interactions in a joint transition model. We have conducted extensive experiments on wide-range MARL environments, including both vision-based and state-based scenarios, and show that our proposed MAJOR achieves superior asymptotic performance and sample efficiency against other state-of-the-art methods.",https://openreview.net/pdf/75a8a39509ea0cb056d3a45d1a5d964aaa0d9d12.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Rywi6F_HVCO,Augmentative Topology Agents For Open-Ended Learning,"['Muhammad Umair Nasir', 'Michael Beukman', 'Steven James', 'Christopher Wesley Cleghorn']","['~Muhammad_Umair_Nasir1', '~Michael_Beukman1', '~Steven_James1', '~Christopher_Wesley_Cleghorn1']","['Open-Ended Learning', 'NeuroEvolution']","In this work, we tackle the problem of Open-Ended Learning by a method that simultaneously evolves agents and increasingly challenging environments. Unlike previous open-ended approaches that optimize agents using a fixed neural network topology, we hypothesize that generalization can be improved by allowing agents' controllers to become more complex as they encounter more difficult environments.  Our method, Augmentative Topology EPOET (ATEP), extends the Enhanced Paired Open-Ended Trailblazer (EPOET) algorithm by allowing agents to evolve their own neural network structures over time, adding complexity and capacity as necessary. Empirical results demonstrate that ATEP results in general agents capable of solving more environments than a fixed-topology baseline. We also investigate mechanisms for transferring agents between environments and find that a species-based approach further improves the performance and generalization of agents.",https://openreview.net/pdf/9ea7a6b152b9c122bca52e8aefeccb287c6a4c7f.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=RvV2xvoML7G,Treatment Effect Estimation with Collider Bias and Confounding Bias,"['Baohong Li', 'Kun Kuang', 'Ruoxuan Xiong', 'Fei Wu']","['~Baohong_Li1', '~Kun_Kuang1', '~Ruoxuan_Xiong1', '~Fei_Wu1']",[],"To answer causal questions from observational data, it is important to consider the mechanisms that determine which data values are observed and which are missing. Prior work has considered the treatment assignment mechanism and proposed methods to remove the confounding bias from the common causes of treatment and outcome. However, there are other issues in sample selection, commonly overlooked in prior work, that can bias the treatment effect estimation, such as the issue of censored outcome as a form of collider bias. In this paper, we propose the novel Selection Controlled CounterFactual Regression (SC-CFR) to simultaneously address confounding and collider bias. Specifically, we first calculate the magnitude of the collider bias of different instances by estimating the selection model and then add a control term to remove the collider bias while learning a balanced representation to remove the confounding bias when estimating the outcome model. Our method is shown to provide unbiased treatment effect estimates from observational data with confounding and collider bias. Extensive empirical results on both synthetic and real-world datasets show that our method consistently outperforms benchmarks when both types of biases exist.",https://openreview.net/pdf/151198ad73360596d2db0ab55778eea91986fa19.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Rl4ihTreFnV,Robust Multi-Agent Reinforcement Learning with State Uncertainties,"['Sihong He', 'Songyang Han', 'Sanbao Su', 'Shuo Han', 'Shaofeng Zou', 'Fei Miao']","['~Sihong_He1', '~Songyang_Han1', '~Sanbao_Su1', '~Shuo_Han3', '~Shaofeng_Zou1', '~Fei_Miao1']","['multi-agent reinforcement learning', 'robust reinforcement learning']","In real-world multi-agent reinforcement learning (MARL) applications, agents may not have perfect state information (e.g., due to inaccurate measurement or malicious attacks), which challenges the robustness of agents' policies. Though robustness is getting important in MARL deployment, little prior work has studied state uncertainties in MARL, neither in problem formulation nor algorithm design. Motivated by this robustness issue, we study the problem of MARL with state uncertainty in this work. We provide the first attempt to the theoretical and empirical analysis of this challenging problem. We first model the problem as a Markov Game with state perturbation adversaries (MG-SPA), and introduce Robust Equilibrium as the solution concept. We conduct fundamental analysis regarding MG-SPA and give conditions under which such an equilibrium exists. Then we propose a robust multi-agent Q-learning (RMAQ) algorithm to find such an equilibrium, with convergence guarantees. To handle high-dimensional state-action space, we design a robust multi-agent actor-critic (RMAAC) algorithm based on an analytical expression of the policy gradient derived in the paper. Our experiments show that the proposed RMAQ algorithm converges to the optimal value function; our RMAAC algorithm outperforms several MARL methods that do not consider the state uncertainty in several multi-agent environments.",https://openreview.net/pdf/b8fe6046a426a2e16266d9d47f18306135307820.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=RIJM-pJF_3K,Causally Constrained Data Synthesis For Private Data Release,"['Varun Chandrasekaran', 'Darren Edge', 'Somesh Jha', 'Lukas Wutschitz', 'Amit Sharma', 'Cheng Zhang', 'Shruti Tople']","['~Varun_Chandrasekaran1', 'darren.edge@microsoft.com', '~Somesh_Jha1', '~Lukas_Wutschitz1', '~Amit_Sharma3', '~Cheng_Zhang1', '~Shruti_Tople2']",[],"Data privacy is critical in many decision-making contexts, such as healthcare and finance. A common mechanism is to create differentially private synthetic data using generative models. Such data generation reflects certain statistical properties of the original data, but often has an unacceptable privacy vs. utility trade-off. Since natural data inherently exhibits causal structure, we propose incorporating \emph{causal information} into the training process to favorably navigate the aforementioned trade-off. Under certain assumptions for linear gaussian models and a broader class of models, we theoretically prove that causally informed generative models provide better differential privacy guarantees than their non-causal counterparts. We evaluate our proposal using variational autoencoders, and demonstrate that the trade-off is mitigated through better utility for comparable privacy.",https://openreview.net/pdf/accaf0a0c437aa4aa099c6d5ada1e2c443734628.pdf,{'title_filter': 'Data Synthesis'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Qi4oCA89CmO,Why Did This Model Forecast This Future? Information-Theoretic Temporal Saliency for Counterfactual Explanations of Probabilistic Forecasts,"['Chirag Raman', 'Hayley Hung', 'Marco Loog']","['~Chirag_Raman2', '~Hayley_Hung2', '~Marco_Loog1']","['probabilistic forecasting', 'saliency', 'explainability']","Probabilistic forecasting of multivariate time series is significant to several research domains where multiple futures exist for a single observed sequence. Identifying the observations on which a well-performing model bases its forecasts can enable domain experts to form data-driven hypotheses about the causal relationships between features. Consequently, we begin by revisiting the question: what constitutes a causal explanation? One hurdle in the landscape of explainable artificial intelligence is that what constitutes an explanation is not well-grounded. We build upon Miller's framework of explanations derived from research in multiple social science disciplines, and establish a conceptual link between counterfactual reasoning and saliency-based explanation techniques. However, the complication is a lack of a consistent and principled notion of saliency. Also, commonly derived saliency maps may be inconsistent with the data generation process and the underlying model. We therefore leverage a unifying definition of information-theoretic saliency grounded in preattentive human visual cognition and extend it to forecasting settings. In contrast to existing methods that require either explicit training of the saliency mechanism or access to the internal parameters of the underlying model, we obtain a closed-form solution for the resulting saliency map for commonly used density functions in probabilistic forecasting. To empirically evaluate our explainability framework in a principled manner, we construct a synthetic dataset of conversation dynamics and demonstrate that our method recovers the true salient timesteps for a forecast given a well-performing underlying model.",https://openreview.net/pdf/eea73f7fc60694325dc6eb8762ebf6bc3bffcf2a.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Qc_OopMEBnC,Learning to Segment from Noisy Annotations: A Spatial Correction Approach,"['Jiachen Yao', 'Yikai Zhang', 'Songzhu Zheng', 'Mayank Goswami', 'Prateek Prasanna', 'Chao Chen']","['~Jiachen_Yao1', '~Yikai_Zhang1', '~Songzhu_Zheng1', '~Mayank_Goswami1', '~Prateek_Prasanna3', '~Chao_Chen1']",[],"Noisy labels can significantly affect the performance of deep neural networks (DNNs). In medical image segmentation tasks, annotations are error-prone due to the high demand in annotation time and in the annotators' expertise. Existing methods mostly tackle label noise in classification tasks. Their independent-noise assumptions do not fit label noise in segmentation task. In this paper, we propose a novel noise model for segmentation problems that encodes spatial correlation and bias, which are prominent in segmentation annotations. Further, to mitigate such label noise, we propose a label correction method to recover true label progressively. We provide theoretical guarantees of the correctness of the proposed method. Experiments show that our approach outperforms current state-of-the-art methods on both synthetic and real-world noisy annotations.",https://openreview.net/pdf/3a19f70c903f3d5336ce11a5aa6ac1f5f12152af.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Qamz7Q_Ta1k,Direct Embedding of Temporal Network Edges via Time-Decayed Line Graphs,"['Sudhanshu Chanpuriya', 'Ryan A. Rossi', 'Sungchul Kim', 'Tong Yu', 'Jane Hoffswell', 'Nedim Lipka', 'Shunan Guo', 'Cameron N Musco']","['~Sudhanshu_Chanpuriya1', '~Ryan_A._Rossi2', '~Sungchul_Kim1', '~Tong_Yu3', 'jhoffs@adobe.com', '~Nedim_Lipka1', 'sguo@adobe.com', '~Cameron_N_Musco1']","['temporal', 'networks', 'graphs', 'embedding']","Temporal networks model a variety of important phenomena involving timed interactions between entities. Existing methods for machine learning on temporal networks generally exhibit at least one of two limitations. First, many methods assume time to be discretized, so if the time data is continuous, the user must determine the discretization and discard precise time information. Second, edge representations can only be calculated indirectly from the nodes, which may be suboptimal for tasks like edge classification. We present a simple method that avoids both shortcomings: construct the line graph of the network, which includes a node for each interaction, and weigh the edges of this graph based on the difference in time between interactions. From this derived graph, edge representations for the original network can be computed with efficient classical methods. The simplicity of this approach facilitates explicit theoretical analysis: we can constructively show the effectiveness of our method's representations for a natural synthetic model of temporal networks. Empirical results on real-world networks demonstrate our method's efficacy and efficiency on both link classification and prediction.",https://openreview.net/pdf/90f557dbe9c9290881d4da0fddf557a84bd2da96.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=QWQM0ZwZdRS,Fake It Until You Make It : Towards Accurate Near-Distribution Novelty Detection,"['Hossein Mirzaei', 'Mohammadreza Salehi', 'Sajjad Shahabi', 'Efstratios Gavves', 'Cees G. M. Snoek', 'Mohammad Sabokrou', 'Mohammad Hossein Rohban']","['~Hossein_Mirzaei1', '~Mohammadreza_Salehi2', '~Sajjad_Shahabi1', '~Efstratios_Gavves1', '~Cees_G._M._Snoek1', '~Mohammad_Sabokrou1', '~Mohammad_Hossein_Rohban1']",[],"We aim for image-based novelty detection. Despite considerable progress, existing models either fail or face dramatic drop under the so-called ``near-distribution"" setup, where the differences between normal and anomalous samples are subtle. We first demonstrate existing methods could experience up to 20\% decrease in their AUCs in the near-distribution setting. Next, we propose to exploit a score-based generative model to produce synthetic near-distribution anomalous data. Our model is then fine-tuned to distinguish such data from the normal samples. We make quantitative as well as qualitative evaluation of this strategy, and compare the results with a variety of GAN-based models.  Effectiveness of our method for both near-distribution and standard novelty detection is assessed through extensive experiments on datasets in diverse applications such as medical images, object classification, and quality control. This reveals that our method significantly improves upon existing models, and consistently decreases the gap between the near-distribution and standard novelty detection AUCs by a considerable amount.",https://openreview.net/pdf/adb38cfa18f4064baa8532ba96fd48c4ad2cf87a.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=QTXKTXJKIh,Achieving Near-Optimal Individual Regret & Low Communications in Multi-Agent Bandits,"['Xuchuang Wang', 'Lin Yang', 'Yu-Zhen Janice Chen', 'Xutong Liu', 'Mohammad Hajiesmaili', 'Don Towsley', 'John C.S. Lui']","['~Xuchuang_Wang1', 'linyang@nju.edu.cn', '~Yu-Zhen_Janice_Chen1', '~Xutong_Liu1', '~Mohammad_Hajiesmaili1', '~Don_Towsley1', '~John_C.S._Lui2']","['Multi-agent multi-armed bandits', 'individual regret', 'communication']","Cooperative multi-agent multi-armed bandits (CM2AB) study how distributed agents cooperatively play the same multi-armed bandit game. Most existing CM2AB works focused on maximizing the group performance of all agents---the accumulation of all agents' individual performance (i.e., individual reward). However, in many applications, the performance of the system is more sensitive to the ``bad'' agent---the agent with the worst individual performance. For example, in a drone swarm, a ``bad'' agent may crash into other drones and severely degrade the system performance. In that case, the key of the learning algorithm design is to coordinate computational and communicational resources among agents so to optimize the individual learning performance of the ``bad'' agent. In CM2AB, maximizing the group performance is equivalent to minimizing the group regret of all agents, and minimizing the individual performance can be measured by minimizing the maximum (worst) individual regret among agents. Minimizing the maximum individual regret was largely ignored in prior literature, and currently, there is little work on how to minimize this objective with a low communication overhead. In this paper, we propose a near-optimal algorithm on both individual and group regrets, in addition,  we also propose a novel communication module in the algorithm, which only needs \(O(\log (\log T))\) communication times where \(T\) is the number of decision rounds. We also conduct simulations to illustrate the advantage of our algorithm by comparing it to other known baselines.",https://openreview.net/pdf/04213bd9368859af7649a1f1b85b691f3a583f8b.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Q120_4COf-K,Synthetic Data Generation of Many-to-Many Datasets via Random Graph Generation,"['Kai Xu', 'Georgi Ganev', 'Emile Joubert', 'Rees Davison', 'Olivier Van Acker', 'Luke Robinson']","['~Kai_Xu4', '~Georgi_Ganev1', '~Emile_Joubert1', '~Rees_Davison1', '~Olivier_Van_Acker1', '~Luke_Robinson1']","['synthetic data generation', 'random graph generation', 'differential privacy']","Synthetic data generation (SDG) has become a popular approach to release private datasets.
In SDG, a generative model is fitted on the private real data, and samples drawn from the model are released as the protected synthetic data.
While real-world datasets usually consist of multiple tables with potential \emph{many-to-many} relationships (i.e.~\emph{many-to-many datasets}), recent research in SDG mostly focuses on modeling tables \emph{independently} or only considers generating datasets with special cases of many-to-many relationships such as \emph{one-to-many}.
In this paper, we first study challenges of building faithful generative models for many-to-many datasets, identifying limitations of existing methods.
We then present a novel factorization for many-to-many generative models,  which leads to a scalable generation framework by combining recent results from random graph theory and representation learning.
Finally, we extend the framework to establish the notion of $(\epsilon,\delta)$-differential privacy.
Through a real-world dataset, we demonstrate that our method can generate synthetic datasets while preserving information within and across tables better than its closest competitor.",https://openreview.net/pdf/be7956b2e543e1b8e0ec80abee0a911606aee3cb.pdf,{'title_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Q-neeWNVv1,Order Matters: Agent-by-agent Policy Optimization,"['Xihuai Wang', 'Zheng Tian', 'Ziyu Wan', 'Ying Wen', 'Jun Wang', 'Weinan Zhang']","['~Xihuai_Wang1', '~Zheng_Tian1', '~Ziyu_Wan2', '~Ying_Wen1', '~Jun_Wang2', '~Weinan_Zhang1']",['Multi-agent Reinforcement Learning'],"While multi-agent trust region algorithms have achieved great success empirically in solving coordination tasks, most of them,  however, suffer from a non-stationarity problem since agents update their policies simultaneously. In contrast, a sequential scheme that updates policies agent-by-agent provides another perspective and shows strong performance. However, sample inefficiency and lack of monotonic improvement guarantees for each agent are still the two significant challenges for the sequential scheme. In this paper, we propose the \textbf{A}gent-by-\textbf{a}gent \textbf{P}olicy \textbf{O}ptimization (A2PO) algorithm to improve the sample efficiency and retain the guarantees of monotonic improvement for each agent during training. We justify the tightness of the monotonic improvement bound compared with other trust region algorithms. From the perspective of sequentially updating agents, we further consider the effect of agent updating order and extend the theory of non-stationarity into the sequential update scheme. To evaluate A2PO, we conduct a comprehensive empirical study on four benchmarks: StarCraftII, Multi-agent MuJoCo, Multi-agent Particle Environment, and Google Research Football full game scenarios. A2PO consistently outperforms strong baselines.",https://openreview.net/pdf/b7c35e63818d65e4523a6ae4314674a0eeb7bb36.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=PxohstFQm9q,Simplicity bias in $1$-hidden layer neural networks,"['Depen Morwani', 'Praneeth Netrapalli', 'jatin batra', 'Karthikeyan Shanmugam', 'Prateek Jain']","['~Depen_Morwani1', '~Praneeth_Netrapalli1', '~jatin_batra1', '~Karthikeyan_Shanmugam1', '~Prateek_Jain1']","['Simplicity Bias', 'Neural Network', 'Gradient Descent']","Recent works \citep{shah2020pitfalls,chen2021intriguing} have demonstrated that neural networks exhibit extreme \emph{simplicity bias} (SB). That is,  they learn \emph{only the simplest} features  to solve a task at hand, even in the presence of other, more robust but more complex features. Due to lack of a general and rigorous definition of \emph{features}, these works showcase SB on \emph{semi-synthetic} datasets such as Color-MNIST, MNIST-CIFAR where defining features is relatively easier. 

In this work, we rigorously define as well as thoroughly establish SB for \emph{one hidden layer} neural networks. More concretely, (i) we define SB as the network essentially being a function of a low dimensional projection of the inputs (ii) theoretically, we show that when the data is linearly separable, the network primarily depends on only the linearly separable ($1$-dimensional) subspace even in the presence of an arbitrarily large number of other, more complex features which could have led to a significantly more robust classifier,  (iii) empirically, we show that models trained on \emph{real} datasets such as Imagenette and Waterbirds-Landbirds indeed depend on a low dimensional projection of the inputs, thereby demonstrating SB on these datasets, iv) finally, we present a natural ensemble approach that encourages diversity in  models by training successive models on features not used by earlier models, and demonstrate that it yields models that are significantly more robust to Gaussian noise.",https://openreview.net/pdf/6c2a71a1119e9c2f644c96629d1ffc4c00bd7512.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=PfPrnKDtvIG,Multi-Agent Reinforcement Learning with Shared Resources for Inventory Management,"['Yuandong Ding', 'Mingxiao Feng', 'Guozi Liu', 'Wei Jiang', 'Chuheng Zhang', 'Li Zhao', 'Lei Song', 'Houqiang Li', 'Yan Jin', 'Jiang Bian']","['~Yuandong_Ding1', '~Mingxiao_Feng1', '~Guozi_Liu1', 'weij4@illinois.edu', '~Chuheng_Zhang1', '~Li_Zhao1', '~Lei_Song3', '~Houqiang_Li1', '~Yan_Jin3', '~Jiang_Bian1']","['Multi-Agent Reinforcement Learning', 'Inventory Mangement']","In this paper, we consider the inventory management (IM) problem where we need to make replenishment decisions for a large number of stock keeping units (SKUs) to balance their supply and demand. In our setting, the constraint on the shared resources (such as the inventory capacity) couples the otherwise independent control for each SKU. We formulate the problem with this structure as Shared-Resource Stochastic Game (SRSG) and propose an efficient algorithm called Context-aware Decentralized PPO (CD-PPO). Through extensive experiments, we demonstrate that CD-PPO can accelerate the learning procedure compared with standard MARL algorithms.",https://openreview.net/pdf/a057d061dce08b6196f98519eeb910da2526caad.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Peot1SFDX0,Preference Transformer: Modeling Human Preferences using Transformers for RL,"['Changyeon Kim', 'Jongjin Park', 'Jinwoo Shin', 'Honglak Lee', 'Pieter Abbeel', 'Kimin Lee']","['~Changyeon_Kim1', '~Jongjin_Park1', '~Jinwoo_Shin1', '~Honglak_Lee2', '~Pieter_Abbeel2', '~Kimin_Lee1']","['preference-based reinforcement learning', 'human-in-the-loop reinforcement learning', 'deep reinforcement learning']","Preference-based reinforcement learning (RL) provides a framework to train agents using human preferences between two behaviors. However, preference-based RL has been challenging to scale since it requires a large amount of human feedback to learn a reward function aligned with human intent. In this paper, we present Preference Transformer, a neural architecture that models human preferences using transformers. Unlike prior approaches assuming human judgment is based on the Markovian rewards which contribute to the decision equally, we introduce a new preference model based on the weighted sum of non-Markovian rewards. We then design the proposed preference model using a transformer architecture that stacks causal and bidirectional self-attention layers. We demonstrate that Preference Transformer can solve a variety of control tasks using real human preferences, while prior approaches fail to work. We also show that Preference Transformer can induce a well-specified reward and attend to critical events in the trajectory by automatically capturing the temporal dependencies in human decision-making. Code is available on the project website: https://sites.google.com/view/preference-transformer.",https://openreview.net/pdf/8a47190a33890c3b90463d493dc6f9bb78af91ee.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=PAKkOriJBd,Coordination Scheme Probing for Generalizable Multi-Agent Reinforcement Learning,"['Hao Ding', 'Chengxing Jia', 'Cong Guan', 'Feng Chen', 'Lei Yuan', 'Zongzhang Zhang', 'Yang Yu']","['~Hao_Ding5', '~Chengxing_Jia1', '~Cong_Guan1', '~Feng_Chen12', '~Lei_Yuan2', '~Zongzhang_Zhang1', '~Yang_Yu5']","['reinforcement learning', 'multi-agent reinforcement learning', 'agent modeling']","Coordinating with previously unknown teammates without joint learning is a crucial need for real-world multi-agent applications, such as human-AI interaction. An active research topic on this problem is ad hoc teamwork, which improves agents' coordination ability in zero-shot settings. However, previous works can only solve the problem of a single agent's coordination with different teams, which is not in line with arbitrary group-to-group coordination in complex multi-agent scenarios. Moreover, they commonly suffer from limited adaptation ability within an episode in a zero-shot setting. To address these problems, we introduce the Coordination Scheme Probing (CSP) approach that applies a disentangled scheme probing module to represent and classify the newly arrived teammates beforehand with limited pre-collected episodic data and makes multi-agent control accordingly. To achieve generalization, CSP learns a meta-policy with multiple sub-policies that follow distinguished coordination schemes in an end-to-end fashion and automatically reuses it to coordinate with unseen teammates. Empirically, we show that the proposed method achieves remarkable performance compared to existing ad hoc teamwork and policy generalization methods in various multi-agent cooperative scenarios.",https://openreview.net/pdf/0d0633049838da07b4f5de064de1fbac697d92c3.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=P3PJokAqGW,Learning with Stochastic Orders,"['Carles Domingo-Enrich', 'Yair Schiff', 'Youssef Mroueh']","['~Carles_Domingo-Enrich1', '~Yair_Schiff1', '~Youssef_Mroueh1']","['optimal transport', 'stochastic order', 'Choquet order', 'convex function', 'input convex neural network', 'integral probability metric', 'image generation', 'statistical rates']","Learning high-dimensional distributions is often done with explicit likelihood modeling or implicit modeling via minimizing integral probability metrics (IPMs). In this paper, we expand this learning paradigm to stochastic orders, namely, the convex or Choquet order between probability measures. Towards this end, exploiting the relation between convex orders and optimal transport, we introduce the Choquet-Toland distance between probability measures, that can be used as a drop-in replacement for IPMs. We also introduce the Variational Dominance Criterion (VDC) to learn probability measures with dominance constraints, that encode the desired stochastic order between the learned measure and a known baseline. We analyze both quantities and show that they suffer from the curse of dimensionality and propose surrogates via input convex maxout networks (ICMNs), that enjoy parametric rates. We provide a min-max framework for learning with stochastic orders and validate it experimentally on synthetic and high-dimensional image generation, with promising results. Finally, our ICMNs class of convex functions and its derived Rademacher Complexity are of independent interest beyond their application in convex orders. Code to reproduce experimental results is available at https://github.com/yair-schiff/stochastic-orders-ICMN.",https://openreview.net/pdf/69bf232a5f31365934fcdc570925118eede29e06.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=P1MaSJlwdT4,Go-Explore with a guide: Speeding up search in sparse reward settings with goal-directed intrinsic rewards,"['Chong Min John Tan', 'Mehul Motani']","['~Chong_Min_John_Tan2', '~Mehul_Motani1']","['reinforcement learning', 'intrinsic motivation', 'goal-directed rewards', 'hippocampal replay', 'hard-exploration', 'sparse rewards']","Reinforcement Learning (RL) agents have traditionally been very sample-intensive to train, especially in environments with sparse rewards. Seeking inspiration from neuroscience experiments of rats learning the structure of a maze without needing extrinsic rewards, we seek to incorporate additional intrinsic rewards to guide behavior. We propose a potential-based goal-directed intrinsic reward (GDIR), which provides a reward signal regardless of whether the task is achieved, and ensures that learning can always take place. While GDIR may be similar to approaches such as reward shaping in incorporating goal-based rewards, we highlight that GDIR is innate to the agent and hence applicable across a wide range of environments without needing to rely on a properly shaped environment reward. We also note that GDIR is different from curiosity-based intrinsic motivation, which can diminish over time and lead to inefficient exploration. Go-Explore is a well-known state-of-the-art algorithm for sparse reward domains, and we demonstrate that by incorporating GDIR in the ``Go"" and ``Explore"" phases, we can improve Go-Explore's performance and enable it to learn faster across multiple environments, for both discrete (2D grid maze environments, Towers of Hanoi, Game of Nim) and continuous (Cart Pole and Mountain Car) state spaces. Furthermore, to consolidate learnt trajectories better, our method also incorporates a novel approach of hippocampal replay to update the values of GDIR and reset state visit and selection counts of states along the successful trajectory. As a benchmark, we also show that our proposed approaches learn significantly faster than traditional extrinsic-reward-based RL algorithms such as Proximal Policy Optimization, TD-learning, and Q-learning.",https://openreview.net/pdf/792d0f553c3b9eb4af6aa81dea97790a1288f830.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=P-73JPgRs0R,Effects of Graph Convolutions in Multi-layer Networks,"['Aseem Baranwal', 'Kimon Fountoulakis', 'Aukosh Jagannath']","['~Aseem_Baranwal1', '~Kimon_Fountoulakis1', '~Aukosh_Jagannath1']","['graph neural networks', 'node classification', 'classification threshold', 'contextual stochastic block model']","Graph Convolutional Networks (GCNs) are one of the most popular architectures that are used to solve classification problems accompanied by graphical information. We present a rigorous theoretical understanding of the effects of graph convolutions in multi-layer networks. We study these effects through the node classification problem of a non-linearly separable Gaussian mixture model coupled with a stochastic block model. First, we show that a single graph convolution expands the regime of the distance between the means where multi-layer networks can classify the data by a factor of at least $1/\sqrt[4]{\rm deg}$, where ${\rm deg}$ denotes the expected degree of a node. Second, we show that with a slightly stronger graph density, two graph convolutions improve this factor to at least $1/\sqrt[4]{n}$, where $n$ is the number of nodes in the graph. Finally, we provide both theoretical and empirical insights into the performance of graph convolutions placed in different combinations among the layers of a neural network, concluding that the performance is mutually similar for all combinations of the placement. We present extensive experiments on both synthetic and real-world data that illustrate our results.",https://openreview.net/pdf/d210fced5bf1ca06dc521b5bd8088e97ffbdc31e.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=OxBl7cSgo6_,Heterogeneous-Agent Mirror Learning,"['Jakub Grudzien Kuba', 'Xidong Feng', 'Shiyao Ding', 'Hao Dong', 'Yaodong Yang']","['~Jakub_Grudzien_Kuba1', '~Xidong_Feng1', '~Shiyao_Ding1', '~Hao_Dong2', '~Yaodong_Yang1']","['deep multi-agent reinforcement learning', 'multi-agent reinforcement learning theory']","The necessity for cooperation among intelligent machines has popularised cooperative multi-agent reinforcement learning (MARL) in the artificial intelligence (AI) research community. However, many research endeavours have been focused on developing practical MARL algorithms whose effectiveness has been studied only empirically, thereby lacking theoretical guarantees. As recent studies have revealed, MARL methods often achieve performance that is unstable in terms of reward monotonicity or suboptimal at convergence. To resolve these issues, in this paper, we introduce a novel framework named Heterogeneous-Agent Mirror Learning (HAML) that provides a general template for MARL algorithmic designs. We prove that algorithms derived from the HAML template satisfy the desired properties of the monotonic improvement of the joint reward and the convergence to Nash equilibrium. We verify the practicality of HAML by proving that the current state-of-the-art cooperative MARL algorithms, HATRPO and HAPPO, are in fact HAML instances. Next, as a natural outcome of our theory, we propose HAML extensions of two well-known RL algorithms, HAA2C (for A2C) and HADDPG (for DDPG), and demonstrate their effectiveness against strong baselines on StarCraftII and Multi-Agent MuJoCo tasks.",https://openreview.net/pdf/32ce8ddc549d03e30882ae6ec449f757a2cb36c7.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Or8rcTLo7U,Maximal Correlation-Based Post-Nonlinear Learning for Bivariate Causal Discovery,"['Tianjian Zhang', 'Feng Yin', 'Zhi-Quan Luo']","['~Tianjian_Zhang1', '~Feng_Yin1', '~Zhi-Quan_Luo1']",[],"Bivariate causal discovery aims to determine the causal relationship between two random variables from passive observational data (as intervention is not affordable in many scientific fields), which is considered fundamental and challenging. Designing algorithms based on the post-nonlinear (PNL) model has aroused much attention for its generality. However, the state-of-the-art (SOTA) PNL-based algorithms involve highly non-convex objectives for neural network training, which are time-consuming and unable to produce meaningful solutions with finite samples. In this paper, we propose a novel method that incorporates maximal correlation into the PNL model learning (short as MC-PNL) such that the underlying nonlinearities can be accurately recovered. Owing to the benign structure of our objective function when modeling the nonlinearities with linear combinations of random Fourier features, the target optimization problem can be solved rather efficiently and rapidly via the block coordinate descent. We also compare the MC-PNL with SOTA methods on the downstream synthetic and real causal discovery tasks to show its superiority in time and accuracy. Our code is available at https://anonymous.4open.science/r/MC-PNL-E446/.",https://openreview.net/pdf/05d9675703d87f470fb7035a9985486e4f238476.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=OhUAblg27z,Harnessing Mixed Offline Reinforcement Learning Datasets via Trajectory Weighting,"['Zhang-Wei Hong', 'Pulkit Agrawal', 'Remi Tachet des Combes', 'Romain Laroche']","['~Zhang-Wei_Hong1', '~Pulkit_Agrawal1', '~Remi_Tachet_des_Combes1', '~Romain_Laroche1']","['offline reinforcement learning', 'reinforcement learning', 'sampling', 'experience replay']","Most offline reinforcement learning (RL) algorithms return a target policy maximizing a trade-off between (1) the expected performance gain over the behavior policy that collected the dataset, and (2) the risk stemming from the out-of-distribution-ness of the induced state-action occupancy. It follows that the performance of the target policy is strongly related to the performance of the behavior policy and, thus, the trajectory return distribution of the dataset. We show that in mixed datasets consisting of mostly low-return trajectories and minor high-return trajectories, state-of-the-art offline RL algorithms are overly restrained by low-return trajectories and fail to exploit high-performing trajectories to the fullest. To overcome this issue, we show that, in deterministic MDPs with stochastic initial states, the dataset sampling can be re-weighted to induce an artificial dataset whose behavior policy has a higher return. This re-weighted sampling strategy may be combined with any offline RL algorithm. We further analyze that the opportunity for performance improvement over the behavior policy correlates with the positive-sided variance of the returns of the trajectories in the dataset. We empirically show that while CQL, IQL, and TD3+BC achieve only a part of this potential policy improvement, these same algorithms combined with our reweighted sampling strategy fully exploit the dataset. Furthermore, we empirically demonstrate that, despite its theoretical limitation, the approach may still be efficient in stochastic environments. ",https://openreview.net/pdf/b83963010af384d9aa84006520ff14a6370f893e.pdf,{'title_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=OfaJyiYonBk,Iteratively Learning Novel Strategies with Diversity Measured in State Distances,"['Wei Fu', 'Weihua Du', 'Jingwei Li', 'Sunli Chen', 'Jingzhao Zhang', 'Yi Wu']","['~Wei_Fu1', '~Weihua_Du1', '~Jingwei_Li2', '~Sunli_Chen1', '~Jingzhao_Zhang2', '~Yi_Wu1']","['diverse behavior', 'multi-agent reinforcement learning', 'deep reinforcement learning']","In complex reinforcement learning (RL) problems, policies with similar rewards may have substantially different behaviors. Yet, to not only optimize rewards but also discover as many diverse strategies as possible remains a challenging problem. A natural approach to this task is constrained population-based training (PBT), which simultaneously learns a collection of policies subject to diversity constraints. However, due to the unaffordable computation cost of PBT, we adopt an alternative approach, iterative learning (IL), which repeatedly learns a single novel policy that is sufficiently different from previous ones. We first analyze these two frameworks and prove that, for any policy pool derived by PBT, we can always use IL to obtain another policy pool of the same rewards and competitive diversity scores. In addition, we also present a novel state-based diversity measure with two tractable realizations. Such a metric can impose a stronger and much smoother diversity constraint than existing action-based metrics. Combining IL and the state-based diversity measure, we develop a powerful diversity-driven RL algorithm, State-based Intrinsic-reward Policy Optimization (SIPO), with provable convergence properties. We empirically examine our algorithm in complex multi-agent environments including StarCraft Multi-Agent Challenge and Google Research Football. SIPO is able to consistently derive strategically diverse and human-interpretable policies that cannot be discovered by existing baselines.",https://openreview.net/pdf/8104275e81fb11ab8c218e2b324d5dc7edd8a827.pdf,{'abstract_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=OTbRTIY4YS,Global Explainability of GNNs via Logic Combination of Learned Concepts,"['Steve Azzolin', 'Antonio Longa', 'Pietro Barbiero', 'Pietro Lio', 'Andrea Passerini']","['~Steve_Azzolin2', '~Antonio_Longa1', '~Pietro_Barbiero1', '~Pietro_Lio1', '~Andrea_Passerini2']","['Explainability', 'Graph Neural Networks', 'Concept Learning']","While instance-level explanation of GNN is a well-studied problem with plenty of approaches being developed, providing a global explanation for the behaviour of a GNN is much less explored, despite its potential in interpretability and debugging. Existing solutions either simply list local explanations for a given class, or generate a synthetic prototypical graph with maximal score for a given class, completely missing any combinatorial aspect that the GNN could have learned.
In this work, we propose GLGExplainer (Global Logic-based GNN Explainer), the first Global Explainer capable of generating explanations as arbitrary Boolean combinations of learned graphical concepts. GLGExplainer is a fully differentiable architecture that takes local explanations as inputs and combines them into a logic formula over graphical concepts, represented as clusters of local explanations. 
Contrary to existing solutions, GLGExplainer provides accurate and human-interpretable global explanations that are perfectly aligned with ground-truth explanations (on synthetic data) or match existing domain knowledge (on real-world data). Extracted formulas are faithful to the model predictions, to the point of providing insights into some occasionally incorrect rules learned by the model, making GLGExplainer a promising diagnostic tool for learned GNNs.",https://openreview.net/pdf/4bc7378db838b1014f2e7b981b34a3e0aadaaf09.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=ORp91sAbzI,Leveraging Unlabeled Data to Track Memorization,"['Mahsa Forouzesh', 'Hanie Sedghi', 'Patrick Thiran']","['~Mahsa_Forouzesh2', '~Hanie_Sedghi1', '~Patrick_Thiran1']","['memorization', 'label noise', 'generalization', 'unlabeled data', 'deep learning']","Deep neural networks may easily memorize noisy labels present in real-world data, which degrades their ability to generalize. It is therefore important to track and evaluate the robustness of models against noisy label memorization. We propose a metric, called $\textit{susceptibility}$, to gauge such memorization for neural networks. Susceptibility is simple and easy to compute during training. Moreover, it does not require access to ground-truth labels and it only uses unlabeled data. We empirically show the effectiveness of our metric in tracking memorization on various architectures and datasets and provide theoretical insights into the design of the susceptibility metric. Finally, we show through extensive experiments on datasets with synthetic and real-world label noise that one can utilize susceptibility and the overall training accuracy to distinguish models that maintain a low memorization on the training set and generalize well to unseen clean data. ",https://openreview.net/pdf/fd7c9f38e71ea9b881d14aa1c553aee5ee725757.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=OIcMPYZXFPL,Mastering Spatial Graph Prediction of Road Networks,"['Sotiris Anagnostidis', 'Aurelien Lucchi', 'Thomas Hofmann']","['~Sotiris_Anagnostidis1', '~Aurelien_Lucchi1', '~Thomas_Hofmann1']",[],"Accurately predicting road networks from satellite images requires a global understanding of the network topology. We propose to capture such high-level information by introducing a graph-based framework that simulates the addition of sequences of graph edges using a reinforcement learning (RL) approach. In particular, given a partially generated graph associated with a satellite image, an RL agent nominates modifications that maximize a cumulative reward. As opposed to standard supervised techniques that tend to be more restricted to commonly used surrogate losses, these rewards can be based on various complex, potentially non-continuous, metrics of interest. This yields more power and flexibility to encode problem-dependent knowledge. Empirical results on several benchmark datasets demonstrate enhanced performance and increased high-level reasoning about the graph topology when using a tree-based search. We further highlight the superiority of our approach under substantial occlusions by introducing a new synthetic benchmark dataset for this task.",https://openreview.net/pdf/d57ed684b0a65bd250f36888d7420fbd173e8cad.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=OAsXFPBfTBh,Autoregressive Conditional Neural Processes,"['Wessel Bruinsma', 'Stratis Markou', 'James Requeima', 'Andrew Y. K. Foong', 'Tom Andersson', 'Anna Vaughan', 'Anthony Buonomo', 'Scott Hosking', 'Richard E Turner']","['~Wessel_Bruinsma1', '~Stratis_Markou1', '~James_Requeima1', '~Andrew_Y._K._Foong1', 'tomand@bas.ac.uk', '~Anna_Vaughan1', 'ab2707@cam.ac.uk', 'jask@bas.ac.uk', '~Richard_E_Turner1']",[],"Conditional neural processes (CNPs; Garnelo et al., 2018a) are attractive meta-learning models which produce well-calibrated predictions and are trainable via a simple maximum likelihood procedure. Although CNPs have many advantages, they are unable to model dependencies in their predictions. Various works propose solutions to this, but these come at the cost of either requiring approximate inference or being limited to Gaussian predictions. In this work, we instead propose to change how CNPs are deployed at test time, without any modifications to the model or training procedure. Instead of making predictions independently for every target point, we autoregressively define a joint predictive distribution using the chain rule of probability, taking inspiration from the neural autoregressive density estimator (NADE) literature. We show that this simple procedure allows factorised Gaussian CNPs to model highly dependent, non-Gaussian predictive distributions. Perhaps surprisingly, in an extensive range of tasks with synthetic and real data, we show that CNPs in autoregressive (AR) mode not only significantly outperform non-AR CNPs, but are also competitive with more sophisticated models that are significantly more computationally expensive and challenging to train. This performance is remarkable given that AR CNPs are not trained to model joint dependencies. Our work provides an example of how ideas from neural distribution estimation can benefit neural processes, and motivates research into the AR deployment of other neural process models.",https://openreview.net/pdf/8333abe2794ea3baf2d24fc271dbef749d5a4565.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=O5rKg7IRQIO,Guarded Policy Optimization with Imperfect Online Demonstrations,"['Zhenghai Xue', 'Zhenghao Peng', 'Quanyi Li', 'Zhihan Liu', 'Bolei Zhou']","['~Zhenghai_Xue1', '~Zhenghao_Peng1', '~Quanyi_Li1', '~Zhihan_Liu1', '~Bolei_Zhou5']","['reinforcement learning', 'guarded policy optimization', 'imperfect demonstrations', 'shared control', 'metadrive simulator']","The Teacher-Student Framework (TSF) is a reinforcement learning setting where a teacher agent guards the training of a student agent by intervening and providing online demonstrations. Assuming optimal, the teacher policy has the perfect timing and capability to intervene in the learning process of the student agent, providing safety guarantee and exploration guidance. Nevertheless, in many real-world settings it is expensive or even impossible to obtain a well-performing teacher policy. In this work, we relax the assumption of a well-performing teacher and develop a new method that can incorporate arbitrary teacher policies with modest or inferior performance. We instantiate an Off-Policy Reinforcement Learning algorithm, termed Teacher-Student Shared Control (TS2C), which incorporates teacher intervention based on trajectory-based value estimation. Theoretical analysis validates that the proposed TS2C algorithm attains efficient exploration and substantial safety guarantee without being affected by the teacher's own performance. Experiments on various continuous control tasks show that our method can exploit teacher policies at different performance levels while maintaining a low training cost. Moreover, the student policy surpasses the imperfect teacher policy in terms of higher accumulated reward in held-out testing environments. Code is available at https://metadriverse.github.io/TS2C.",https://openreview.net/pdf/e19dee281e43ab70ef8f8640d6ccb689bed45bd8.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=NnOZT_CR26Z,GoBigger: A Scalable Platform for Cooperative-Competitive Multi-Agent Interactive Simulation,"['Ming Zhang', 'Shenghan Zhang', 'Zhenjie Yang', 'Lekai Chen', 'Jinliang Zheng', 'Chao Yang', 'Chuming Li', 'Hang Zhou', 'Yazhe Niu', 'Yu Liu']","['~Ming_Zhang10', '~Shenghan_Zhang1', '~Zhenjie_Yang1', '~Lekai_Chen1', '~Jinliang_Zheng1', '~Chao_Yang3', '~Chuming_Li1', '~Hang_Zhou9', '~Yazhe_Niu1', '~Yu_Liu2']","['Reinforcement Learning', 'Environment', 'Cooperation', 'Competition', 'Scalable']","The emergence of various multi-agent environments has motivated powerful algorithms to explore agents' cooperation or competition. Even though this has greatly promoted the development of multi-agent reinforcement learning  (MARL), it is still not enough to support further exploration on the behavior of swarm intelligence between multiple teams, and cooperation between multiple agents due to their limited scalability. To alleviate this, we introduce GoBigger, a scalable platform for cooperative-competition multi-agent interactive simulation. GoBigger is an enhanced environment for the Agar-like game, enabling the simulation of multiple scales of agent intra-team cooperation and inter-team competition. Compared with existing multi-agent simulation environments, our platform supports multi-team games with more than two teams simultaneously, which dramatically expands the diversity of agent cooperation and competition, and can more effectively simulate the swarm intelligent agent behavior. Besides, in GoBigger, the cooperation between the agents in a team can lead to much higher performance. We offer a diverse set of challenging scenarios, built-in bots, and visualization tools for best practices in benchmarking. We evaluate several state-of-the-art algorithms on GoBigger and demonstrate the potential of the environment. We believe this platform can inspire various emerging research directions in MARL, swarm intelligence, and large-scale agent interactive learning. Both GoBigger and its related benchmark are open-sourced. More information could be found at https://github.com/opendilab/GoBigger.",https://openreview.net/pdf/a9b5c1cac35cce14dad1036f5b0f324ad899d11f.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=NYtq-CsRP3H,Parameter Averaging for Feature Ranking,"['Talip Ucar', 'Ehsan Hajiramezanali']","['~Talip_Ucar2', '~Ehsan_Hajiramezanali1']","['Parameter averaging', 'feature ranking', 'feature importance', 'robustness', 'interpretability', 'tabular data']","Neural Networks are known to be sensitive to initialisation. The methods that rely on neural networks for feature ranking are not robust since they can have variations in their ranking when the model is initialized and trained with different random seeds. In this work, we introduce a novel method based on parameter averaging to estimate accurate and robust feature importance in tabular data setting, referred as XTab. We first initialize and train multiple instances of a shallow network (referred as local masks) with ""different random seeds"" for a downstream task. We then obtain a global mask model by ""averaging the parameters"" of local masks. We show that although the parameter averaging might result in a global model with higher loss, it still leads to the discovery of the ground-truth feature importance more consistently than an individual model does. We conduct extensive experiments on a variety of synthetic and real-world data, demonstrating that the XTab can be used to obtain the global feature importance that is not sensitive to sub-optimal model initialisation.",https://openreview.net/pdf/e79336859855d12aa07cfc4418982b3c988a4068.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=NTCYXulK9qm,Co-Evolution As More Than a Scalable Alternative for Multi-Agent Reinforcement Learning,['Patrick Grzywok'],['~Patrick_Grzywok1'],"['reinforcement learning', 'multi-agent reinforcement learning', 'policy search', 'co-evolution', 'evolutionary algorithm']","In recent years, gradient based multi-agent reinforcement learning is growing in success. One contributing factor is the use of shared parameters for learning policy networks. While this approach scales well with the number of agents during execution it lacks this ambiguity for training as the number of produced samples grows linearly with the number of agents. For a very large number of agents, this could lead to an inefficient use of the circumstantial amount of produced samples. Moreover in single-agent reinforcement learning policy search with evolutionary algorithms showed viable success when sampling can be parallelized on a larger scale. The here proposed method does not only consider sampling in concurrent environments but further investigates sampling diverse parameters from the population in co-evolution in joint environments during training. This co-evolutionary policy search has shown to be capable of training a large number of agents. Beyond that, it has been shown to produce competitive results in smaller environments in comparison to gradient descent based methods. This surprising result make evolutionary algorithms a promising candidate for further research in the context of multi-agent reinforcement learning.",https://openreview.net/pdf/ef90a358c1b140d624af9e72ce4070931d4ad77a.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=NO0ThzteQdI,NERDS: A General Framework to Train Camera Denoisers from Raw-RGB Noisy Image Pairs,"['Heewon Kim', 'Kyoung Mu Lee']","['~Heewon_Kim2', '~Kyoung_Mu_Lee2']",[],"  We aim to train accurate denoising networks for smartphone/digital cameras from single noisy images. Downscaling is commonly used as a practical denoiser for low-resolution images. Based on this processing, we found that the pixel variance of the natural images is more robust to downscaling than the pixel variance of the camera noises. Intuitively, downscaling easily removes high-frequency noises than natural textures. To utilize this property, we can adopt noisy/clean image synthesis at low-resolution to train camera denoisers. On this basis, we propose a new solution pipeline -- NERDS that estimates camera noises and synthesizes noisy-clean image pairs from only noisy images.  In particular, it first models the noise in raw-sensor images as a Poisson-Gaussian distribution, then estimates the noise parameters using the difference of pixel variances by downscaling. We formulate the noise estimation as a gradient-descent-based optimization problem through a reparametrization trick. We further introduce a new Image Signal Processor (ISP) estimation method that enables denoiser training in a human-readable RGB space by transforming the synthetic raw images to the style of a given RGB noisy image. The noise and ISP estimations utilize rich augmentation to synthesize image pairs for denoiser training. Experiments show that our NERDS can accurately train CNN-based denoisers (e.g., DnCNN, ResNet-style network) outperforming previous noise-synthesis-based and self-supervision-based denoisers in real datasets.",https://openreview.net/pdf/bdebcf036670b6aad12923bc167527b706b42167.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=N4K5ck-BTT,Scaffolding a Student to Instill Knowledge,"['Anil Kag', 'Durmus Alp Emre Acar', 'Aditya Gangrade', 'Venkatesh Saligrama']","['~Anil_Kag1', '~Durmus_Alp_Emre_Acar1', '~Aditya_Gangrade1', '~Venkatesh_Saligrama1']","['knowledge distillation', 'tiny capacity student', 'large capacity teacher', 'budget constrained learning']","We propose a novel knowledge distillation (KD) method to selectively instill teacher knowledge into a student model motivated by situations where the student's capacity is significantly smaller than that of the teachers. In vanilla KD, the teacher primarily sets a predictive target for the student to follow, and we posit that this target is overly optimistic due to the student's lack of capacity. We develop a novel scaffolding scheme where the teacher, in addition to setting a predictive target, also scaffolds the student's prediction by censoring hard-to-learn examples. Scaffolding utilizes the same information as the teacher's soft-max predictions as inputs, and in this sense, our proposal can be viewed as a natural variant of vanilla KD. We show on synthetic examples that censoring hard-examples leads to smoothening the student's loss landscape so that the student encounters fewer local minima. As a result, it has good generalization properties. Against vanilla KD, we achieve improved performance and are comparable to more intrusive techniques that leverage feature matching on benchmark datasets.
",https://openreview.net/pdf/c8a1e11f100899f2bd81fb3442a4721f0872fe17.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Mof47lISH6N,DifFace: Blind Face Restoration with Diffused Error Contraction,"['Zongsheng Yue', 'Chen Change Loy']","['~Zongsheng_Yue1', '~Chen_Change_Loy2']","['Face Restoration', 'Diffusion Model', 'Super-resolution']","While deep learning-based methods for blind face restoration have achieved unprecedented success, they still suffer from two major limitations. First, most of them deteriorate when facing complex degradations out of their training data. Second, these methods require multiple constraints, e.g., fidelity, perceptual, and adversarial losses, which requires laborious hyper-parameters tuning to stabilize and balance their influences. In this work, we propose a novel method named DifFace, being able to cope with unseen and complex degradations more gracefully without complicated loss designs. The key of our method is to establish a posterior distribution from the observed low-quality (LQ) image to its high-quality (HQ) counterpart. In particular, we design a transition distribution from the LQ image to the intermediate state of a pre-trained diffusion model and then gradually transmit from this intermediate state to the HQ target by recursively applying a pre-trained diffusion model. The transition distribution only relies on a restoration backbone that is trained with L2 loss on some synthetic data, which favorably avoids the cumbersome training process in existing methods. Moreover, the transition distribution is capable of contracting the error of the restoration backbone and thus makes our method more robust to unknown degradations. Comprehensive experiments show that DifFace is superior to current state-of-the-art methods, especially in cases with severe degradations. Code and model will be released.",https://openreview.net/pdf/9670b623722d76aa64038405e42aa4d07e8d46ec.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=MhuFzFsrfvH,Optimal Transport for Offline Imitation Learning,"['Yicheng Luo', 'zhengyao jiang', 'Samuel Cohen', 'Edward Grefenstette', 'Marc Peter Deisenroth']","['~Yicheng_Luo1', '~zhengyao_jiang2', '~Samuel_Cohen1', '~Edward_Grefenstette1', '~Marc_Peter_Deisenroth1']","['offline reinforcement learning', 'optimal transport', 'imitation learning']","With the advent of large datasets, offline reinforcement learning is a promising framework for learning good decision-making policies without the need to interact with the real environment.
However, offline RL requires the dataset to be reward-annotated, which presents practical challenges when reward engineering is difficult or when obtaining reward annotations is labor-intensive.
In this paper, we introduce Optimal Transport Relabeling (OTR), an imitation learning algorithm that can automatically relabel offline data of mixed and unknown quality with rewards from a few good demonstrations. OTR's key idea is to use optimal transport to compute an optimal alignment between an unlabeled trajectory in the dataset and an expert demonstration to obtain a similarity measure that can be interpreted as a reward, which can then be used by an offline RL algorithm to learn the policy. OTR is easy to implement and computationally efficient. On D4RL benchmarks, we demonstrate that OTR with a single demonstration can consistently match the performance of offline RL with ground-truth rewards.
",https://openreview.net/pdf/3c2503af4f49d5f2f79a720075d8cfc042c50960.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=MdiVU9lMmVS,Very Large Scale Multi-Agent Reinforcement Learning with Graph Attention Mean Field,['Qianyue Hao'],['~Qianyue_Hao1'],"['Multi-agent reinforcement learning', 'large-scale problems', 'graph attention', 'mean field']","With recent advances in reinforcement learning, we have witnessed countless successes of intelligent agents in various domains. Especially, multi-agent reinforcement learning (MARL) is suitable for many real-world scenarios and has vast potential applications. However, typical MARL methods can only handle tens of agents, leaving scenarios with up to hundreds or even thousands of agents almost unexplored. There exist two key challenges in scaling up the number of agents: (1) agent-agent interactions are critical in multi-agent systems while the number of interactions grows quadratically with the number of agents, causing great computational complexity and difficulty in strategies-learning; (2) the strengths of interactions vary among agents and over time, making it difficult to precisely model such interactions. In this paper, we propose the Graph Attention Mean Field (GAT-MF) method, where we convert agent-agent interactions into interactions between each agent and a weighted mean field, greatly reducing the computational complexity. We mathematically prove the correctness of this conversion. We design a graph attention mechanism to automatically capture the different and time-varying strengths of interactions, ensuring the ability of our method to precisely model interactions among the agents. We conduct extensive experiments in both manual and real-world scenarios with up to more than 3000 agents, demonstrating that comparing existing MARL methods, our method reaches superior performance and 9.4 times computational efficiency.",https://openreview.net/pdf/beb6830c8b16328725a483b96dbef96a1491de65.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=MbWntPvE5Tg,Planning Immediate Landmarks of Targets for Model-Free Skill Transfer across Agents,"['Minghuan Liu', 'Zhengbang Zhu', 'Menghui Zhu', 'Yuzheng Zhuang', 'Weinan Zhang', 'Jianye HAO']","['~Minghuan_Liu1', '~Zhengbang_Zhu1', '~Menghui_Zhu1', '~Yuzheng_Zhuang1', '~Weinan_Zhang1', '~Jianye_HAO1']","['reinforcement learning', 'transfer learning']","In reinforcement learning applications, agents usually need to deal with various input/output features when specified with different state and action spaces by their developers or physical restrictions, indicating re-training from scratch and considerable sample inefficiency, especially when agents follow similar solution steps to achieve tasks.
In this paper, we aim to transfer pre-trained skills to alleviate the above challenge. Specifically, we propose PILoT, i.e., Planning Immediate Landmarks of Targets. PILoT utilizes the universal decoupled policy optimization to learn a goal-conditioned state planner; then, we distill a goal-planner to plan immediate landmarks in a model-free style that can be shared among different agents. In our experiments, we show the power of PILoT on various transferring challenges, including few-shot transferring across action spaces and dynamics, from low-dimensional vector states to image inputs, from simple robot to complicated morphology; and we also illustrate PILoT provides a zero-shot transfer solution from a simple 2D navigation task to the harder Ant-Maze task.",https://openreview.net/pdf/1268f4a67e362911d65e2a20d7838b6c7a80f1fd.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=M_MvkWgQSt,Real-time variational method for learning neural trajectory and its dynamics,"['Matthew Dowling', 'Yuan Zhao', 'Il Memming Park']","['~Matthew_Dowling2', '~Yuan_Zhao1', '~Il_Memming_Park1']","['neural dynamics', 'neural trajectory', 'online variational inference']","Latent variable models have become instrumental in computational neuroscience for reasoning about neural computation.  This has fostered the development of powerful offline algorithms for extracting latent neural trajectories from neural recordings.  However, despite the potential of real-time alternatives to give immediate feedback to experimentalists, and enhance experimental design, they have received markedly less attention.  In this work, we introduce the exponential family variational Kalman filter (eVKF), an online recursive Bayesian method aimed at inferring latent trajectories while simultaneously learning the dynamical system generating them.  eVKF works for arbitrary likelihoods and utilizes the constant base measure exponential family to model the latent state stochasticity. We derive a closed-form variational analog to the predict step of the Kalman filter which leads to a provably tighter bound on the ELBO compared to another online variational method. We validate our method on synthetic and real-world data, and, notably, show that it achieves competitive performance.",https://openreview.net/pdf/f2a3ae5af4f08eb6ca19ee6d8642f0023b244943.pdf,{'title_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=MZFDUB40NJ,Uncertainty-aware off policy learning,"['Xiaoying Zhang', 'Junpu Chen', 'Hongning Wang', 'Hong Xie', 'Hang Li']","['~Xiaoying_Zhang3', '~Junpu_Chen1', '~Hongning_Wang1', '~Hong_Xie2', '~Hang_Li4']","['off-policy learning', 'uncertainty']","Off-policy learning, referring to the procedure of policy optimization with access only to logged feedback data, has shown importance in various real-world applications, such as search engines, recommender systems, etc.  While the ground-truth logging policy, which generates the logged data, is usually unknown, previous work directly takes its estimated value in off-policy learning, resulting in a biased estimator. This estimator has both high bias and variance on samples with small and inaccurate estimated logging probabilities. 
In this work, we explicitly model the uncertainty in the estimated logging policy and propose a novel  \underline{U}ncertainty-aware \underline{I}nverse  \underline{P}ropensity \underline{S}core estimator (UIPS) for improved off-policy learning. Experiment results on synthetic and three real-world  recommendation datasets demonstrate the advantageous sample efficiency of the proposed UIPS estimator.",https://openreview.net/pdf/82abf43a1a49fce58d576fe6273ca74fccae387e.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=LiXDW7CF94J,How robust is unsupervised representation learning to distribution shift?,"['Yuge Shi', 'Imant Daunhawer', 'Julia E Vogt', 'Philip Torr', 'Amartya Sanyal']","['~Yuge_Shi1', '~Imant_Daunhawer2', '~Julia_E_Vogt1', '~Philip_Torr1', '~Amartya_Sanyal1']","['distribution shift', 'OOD generalisation', 'spurious correlation', 'simplicity bias', 'SSL', 'unsupervised learning', 'auto-encoder']","The robustness of machine learning algorithms to distributions shift is primarily discussed in the context of supervised learning (SL). As such, there is a lack of insight on the robustness of the representations learned from unsupervised methods, such as self-supervised learning (SSL) and auto-encoder based algorithms (AE), to distribution shift. We posit that the input-driven objectives of unsupervised algorithms lead to representations that are more robust to distribution shift than the target-driven objective of SL. We verify this by extensively evaluating the performance of SSL and AE on both synthetic and realistic distribution shift datasets. Following observations that the linear layer used for classification itself can be susceptible to spurious correlations, we evaluate the representations using a linear
head trained on a small amount of out-of-distribution (OOD) data, to isolate the robustness of the learned representations from that of the linear head. We also develop “controllable” versions of existing realistic domain generalisation datasets with adjustable degrees of distribution shifts. This allows us to study the robustness of different learning algorithms under versatile yet realistic distribution shift
conditions. Our experiments show that representations learned from unsupervised learning algorithms generalise better than SL under a wide variety of extreme as well as realistic distribution shifts.",https://openreview.net/pdf/4e056f415188ed58053ecc69d8168e2e3af4699f.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=LUql3ZOFwFD,Differentially Private Conditional Text Generation For Synthetic Data Production,"['Pranav Putta', 'Ander Steele', 'Joseph W Ferrara']","['~Pranav_Putta1', '~Ander_Steele1', '~Joseph_W_Ferrara1']","['differential privacy', 'conditional text generation', 'NLP']","Companies have faced increasing pressure in recent years to anonymize user collected data when sharing internally or to third parties. Text data in particular contains copious amounts of personally identifiable information that has proven to be difficult to de-identify while remain useful for the party of interest. Previous works have suggested that synthetic text generation could provide a promising avenue to curate high performant and private datasets. In this paper, we introduce an approach to synthesize high utility text classification datasets by performing conditional generation through a large language model, distilGPT2, while providing measurable guarantees via differential privacy. We show that naive approaches suffer heavily from utility loss by entangling task-relevant factors in the transformer embedding space, making controlled generation more difficult. We analyze how incorporating a secondary learning objective can improve the performance of the generative model, improving utility of the generated data.",https://openreview.net/pdf/da80055e8a1f2af09d27a65feb9e5b15654769cf.pdf,{'title_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=LNpMtk15AS4,Boosting Causal Discovery via Adaptive Sample Reweighting,"['An Zhang', 'Fangfu Liu', 'Wenchang Ma', 'Zhibo Cai', 'Xiang Wang', 'Tat-Seng Chua']","['~An_Zhang2', '~Fangfu_Liu2', '~Wenchang_Ma1', '~Zhibo_Cai1', '~Xiang_Wang6', '~Tat-Seng_Chua2']","['Causal Structure Learning', 'Score-based Causal Discovery', 'Adaptive Sample Reweighting']","Under stringent model type and variable distribution assumptions, score-based causal discovery methods learn the directed acyclic graph (DAG) from observational data by evaluating candidate graphs over an averaged score function. Despite the great success in low-dimensional linear systems, it has been observed that these approaches overly exploits easier-to-fit samples, thus inevitably learning spurious edges. Worse still, the common homogeneity assumption of most causal discovery methods can be easily violated due to the widespread existence of heterogeneous data in the real world, resulting in performance vulnerability when noise distributions vary. We propose a simple yet effective model-agnostic framework to boost causal discovery performance by dynamically learning the adaptive weights for the Reweighted Score function, ReScore for short, where the learned weights tailors quantitatively to the important degree of each samples. Intuitively, we leverage the bilevel optimization scheme to alternatively train a standard DAG learner first, then upweight the samples that the DAG learner fails to fit well and downweight the samples that the DAG learner easily extracts the causation information from. Extensive experiments on both synthetic and real-world datasets are carried out to validate the effectiveness of ReScore. We observe consistent and significant boosts in structure learning performance. We further visualize that ReScore concurrently mitigates the influence of spurious edges and generalizes to heterogeneous data. Finally, we perform theoretical analysis to guarantee the structure identifiability and the weight adaptive properties of ReScore. Our codes are available at https://github.com/anzhang314/ReScore.",https://openreview.net/pdf/490a8e5885f74912244f797f7afd7060d7d2bbe9.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=LIV7-_7pYPl,DexDeform: Dexterous Deformable Object Manipulation with Human Demonstrations and Differentiable Physics,"['Sizhe Li', 'Zhiao Huang', 'Tao Chen', 'Tao Du', 'Hao Su', 'Joshua B. Tenenbaum', 'Chuang Gan']","['~Sizhe_Li1', '~Zhiao_Huang1', '~Tao_Chen1', '~Tao_Du1', '~Hao_Su1', '~Joshua_B._Tenenbaum1', '~Chuang_Gan1']","['Deformable Object Manipulation', 'Dexterous Manipulation', 'Differentiable Physics']","In this work, we aim to learn dexterous manipulation of deformable objects using multi-fingered hands. Reinforcement learning approaches for dexterous rigid object manipulation would struggle in this setting due to the complexity of physics interaction with deformable objects. At the same time, previous trajectory optimization approaches with differentiable physics for deformable manipulation would suffer from local optima caused by the explosion of contact modes from hand-object interactions. To address these challenges, we propose DexDeform, a principled framework that abstracts dexterous manipulation skills from human demonstration, and refines the learned skills with differentiable physics. Concretely, we first collect a small set of human demonstrations using teleoperation. And we then train a skill model using demonstrations for planning over action abstractions in imagination. To explore the goal space, we further apply augmentations to the existing deformable shapes in demonstrations and use a gradient optimizer to refine the actions planned by the skill model. Finally, we adopt the refined trajectories as new demonstrations for finetuning the skill model. To evaluate the effectiveness of our approach, we introduce a suite of six challenging dexterous deformable object manipulation tasks. Compared with baselines, DexDeform is able to better explore and generalize across novel goals unseen in the initial human demonstrations. Additional materials can be found at our project website: https://sites.google.com/view/dexdeform.",https://openreview.net/pdf/40f58e1097499c5bdbba2b9dea60f73decfcf1b9.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=L6CKiPH3hI,Enriching Online Knowledge Distillation with Specialist Ensemble,"['Mincheol Park', 'Woojeong Kim', 'Junsik Bang', 'Won Woo Ro', 'Suhyun Kim']","['~Mincheol_Park1', '~Woojeong_Kim1', '~Junsik_Bang1', '~Won_Woo_Ro1', '~Suhyun_Kim1']","['Online knowledge distillation', 'Label prior shift', 'Ensemble learning']","Online Knowledge Distillation (KD) has an advantage over traditional KD works in that it removes the necessity for a pre-trained teacher. Indeed, an ensemble of small teachers has become typical guidance for a student's learning trajectory. Previous works emphasized diversity to create helpful ensemble knowledge and further argued that the size of diversity should be significant to prevent homogenization. This paper proposes a well-founded online KD framework with naturally derived specialists. In supervised learning, the parameters of a classifier are optimized by stochastic gradient descent based on a training dataset distribution. If the training dataset is shifted, the optimal point and corresponding parameters change accordingly, which is natural and explicit.
We first introduce a label prior shift to induce evident diversity among the same teachers, which assigns a skewed label distribution to each teacher and simultaneously specializes them through importance sampling. Compared to previous works, our specialization achieves the highest level of diversity and maintains it throughout training. Second, we propose a new aggregation that uses post-compensation in specialist outputs and conventional model averaging. The aggregation empirically exhibits the advantage of ensemble calibration even if applied to previous diversity-eliciting methods. Finally, through extensive experiments, we demonstrate the efficacy of our framework on top-1 error rate, negative log-likelihood, and notably expected calibration error.",https://openreview.net/pdf/2ff38143ff2c4a2d71c39020214dc3f2f42ea25d.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=L2MUOUp0beo,CoRTX: Contrastive Framework for Real-time Explanation,"['Yu-Neng Chuang', 'Guanchu Wang', 'Fan Yang', 'Quan Zhou', 'Pushkar Tripathi', 'Xuanting Cai', 'Xia Hu']","['~Yu-Neng_Chuang1', '~Guanchu_Wang1', '~Fan_Yang27', '~Quan_Zhou5', '~Pushkar_Tripathi2', '~Xuanting_Cai1', '~Xia_Hu4']","['Interpretability', 'explainability', 'real-time explanation', 'feature attribution', 'feature importance ranking']","Recent advancements in explainable machine learning provide effective and faithful solutions for interpreting model behaviors. However, many explanation methods encounter efficiency issues, which largely limit their deployments in practical scenarios. Real-time explainer (RTX) frameworks have thus been proposed to accelerate the model explanation process by learning an one-feed-forward explainer. Existing RTX frameworks typically build the explainer under the supervised learning paradigm, which requires large amounts of explanation labels as the ground truth. Considering that accurate explanation labels are usually hard to obtain, due to constrained computational resources and limited human efforts, effective explainer training is still challenging in practice. In this work, we propose a COntrastive Real-Time eXplanation (CoRTX) framework to learn the explanation-oriented representation and relieve the intensive dependence of explainer training on explanation labels. Specifically, we design a synthetic strategy to select positive and negative instances for explanation representation learning. Theoretical analysis show that our selection strategy can benefit the contrastive learning process on explanation tasks. Experimental results on three real-world datasets further demonstrate the efficiency and efficacy of our proposed CoRTX framework.",https://openreview.net/pdf/8e9825a8e9446ab79ae7406ff203d26aef5828ed.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Kn43SKplAn,3D Surface Reconstruction in the Wild by Deforming Shape Priors from Synthetic Data,"['Nicolai Haeni', 'Jun-Jee Chao', 'Volkan Isler']","['~Nicolai_Haeni1', '~Jun-Jee_Chao1', '~Volkan_Isler1']","['3D reconstruction', 'pose estimation', 'shape deformation']","We present a new method for category-specific 3D reconstruction from a single image. A limitation of current color image-based 3D reconstruction models is that they do not generalize across datasets, due to domain shift. In contrast, we show that one can learn to reconstruct objects across datasets by shape priors learned from synthetic 3D data and a point cloud pose canonicalization method. Given a single depth image at test time, we first place this partial point cloud in a canonical pose. Then, we use a neural deformation field in the canonical coordinate frame to reconstruct the 3D surface of the object. Finally, we jointly optimize object pose and 3D shape to fit the partial depth observation. Our approach achieves state-of-the-art reconstruction performance across several real-world datasets, even when trained without ground truth camera poses (which are required by some of the state-of-the-art methods). We further show that our method generalizes to different input modalities, from dense depth images to sparse and noisy LIDAR scans. ",https://openreview.net/pdf/98af33e19325b70a87c0c15d55ea7d44cf48cab7.pdf,{'title_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=KiT3-iN8wHJ,Uncertainty and Traffic Light Aware Pedestrian Crossing Intention Prediction,"['Minali Upreti', 'Jayanth Ramesh', 'Chandan R Kumar', 'Bodhisattwa Chakraborty', 'VIKRAM BALISAVIRA', 'Phillip Czech', 'Vitali Kaiser', 'Markus Roth']","['~Minali_Upreti1', '~Jayanth_Ramesh1', '~Chandan_R_Kumar1', '~Bodhisattwa_Chakraborty1', '~VIKRAM_BALISAVIRA1', '~Phillip_Czech1', '~Vitali_Kaiser1', '~Markus_Roth1']","['deep learning', 'computer vision', 'recurrent neural networks', 'uncertainty estimation', 'intention prediction', 'attention mechanism', 'autonomous driving']","Predicting Vulnerable Road User (VRU) crossing intention is one of the major challenges in automated driving. Crossing intention prediction systems trained only on pedestrian features underperform in situations that are most obvious to humans, as the latter take additional context features into consideration. Moreover, such systems tend to be over-confident for out-of-distribution samples, therefore making them less reliable to be used by downstream tasks like sensor fusion and trajectory planning for automated vehicles. In this work, we demonstrate that the results of crossing intention prediction systems can be improved by incorporating traffic light status as an additional input. Further, we make the model robust and interpretable by estimating uncertainty. Experiments on the PIE dataset show that the F1-score improved from 0.77 to 0.82 and above for three different baseline systems when considering traffic-light context. By adding uncertainty, we show increased uncertainty values for out-of-distribution samples, therefore leading to interpretable and reliable predictions of crossing intention.",https://openreview.net/pdf/569a45050d5aeaea2b37970f9bca09dc84f54b9b.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Ki4ocDm364,Scaling Pareto-Efficient Decision Making via Offline Multi-Objective RL,"['Baiting Zhu', 'Meihua Dang', 'Aditya Grover']","['~Baiting_Zhu1', '~Meihua_Dang1', '~Aditya_Grover1']","['Reinforcement Learning', 'Offline Reinforcement Learning', 'Multi-Objective Reinforcement Learning', 'Decision Transformer', 'Sequential Decision Making']","The goal of multi-objective reinforcement learning (MORL) is to learn policies that simultaneously optimize multiple competing objectives. In practice, an agent's preferences over the objectives may not be known apriori, and hence, we require policies that can generalize to arbitrary preferences at test time. In this work, we propose a new data-driven setup for offline MORL, where we wish to learn a preference-agnostic policy agent using only a finite dataset of offline demonstrations of other agents and their preferences. The key contributions of this work are two-fold. First, we introduce D4MORL, (D)atasets for MORL that are specifically designed for offline settings. It contains 1.8 million annotated demonstrations obtained by rolling out reference policies that optimize for randomly sampled preferences on 6 MuJoCo environments with 2-3 objectives each. Second, we propose Pareto-Efficient Decision Agents (PEDA), a family of offline MORL algorithms that builds and extends Decision Transformers via a novel preference-and-return-conditioned policy. Empirically, we show that PEDA closely approximates the behavioral policy on the D4MORL benchmark and provides an excellent approximation of the Pareto-front with appropriate conditioning, as measured by the hypervolume and sparsity metrics. ",https://openreview.net/pdf/3d73c1e257eb3d1dd034f43fe3b51884a6dfade4.pdf,{'abstract_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=KaeYRGTaODt,Multi-Agent Policy Transfer via Task Relationship Modeling,"['Rong-Jun Qin', 'Feng Chen', 'Tonghan Wang', 'Lei Yuan', 'Xiaoran Wu', 'Yipeng Kang', 'Zongzhang Zhang', 'Chongjie Zhang', 'Yang Yu']","['~Rong-Jun_Qin1', '~Feng_Chen12', '~Tonghan_Wang1', '~Lei_Yuan2', '~Xiaoran_Wu1', '~Yipeng_Kang1', '~Zongzhang_Zhang1', '~Chongjie_Zhang1', '~Yang_Yu5']","['Multi-agent reinforcement learning', 'cooperative transfer learning']","Team adaptation to new cooperative tasks is a hallmark of human intelligence, which has yet to be fully realized in learning agents. Previous works on multi-agent transfer learning accommodate teams of different sizes, but heavily rely on the generalization ability of neural networks for adapting to unseen tasks. We posit that the relationship among tasks provides the key information for policy adaptation. To utilize such relationship for efficient transfer, we try to discover and exploit the knowledge among tasks from different teams, propose to learn effect-based task representations as a common latent space among tasks, and use it to build an alternatively fixed training scheme. We demonstrate that the task representation can capture the relationship among teams and generalize to unseen tasks. As a result, the proposed method can help transfer learned cooperation knowledge to new tasks after training on a few source tasks, and the learned transferred policies can also help solve tasks that are hard to learn from scratch.",https://openreview.net/pdf/fc1720abd9708aa25ab7ce8f93ed89d2794e3e3f.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=K1Z-P0Le0DT,Recurrent Real-valued Neural Autoregressive Density Estimator for Online Density Estimation and Classification of Streaming Data,"['Tianyu Li', 'Bogdan Mazoure', 'Guillaume Rabusseau']","['~Tianyu_Li3', '~Bogdan_Mazoure1', '~Guillaume_Rabusseau1']","['density estimation', 'online learning', 'streaming data', 'classification']","In contrast with the traditional offline learning, where complete data accessibility is assumed, many modern applications involve processing data in a streaming fashion. This online learning setting raises various challenges, including concept drift, hardware memory constraints, etc. In this paper, we propose the Recurrent Real-valued Neural Autoregressive Density Estimator (RRNADE), a flexible density-based model for online classification and density estimation. RRNADE combines a neural Gaussian mixture density module with a recurrent module. This combination allows RRNADE to exploit possible sequential correlations in the streaming task, which are often ignored in the classical streaming setting where each input is assumed to be independent from the previous ones. We showcase the ability of RRNADE to adapt to concept drifts on synthetic density estimation tasks. We also apply RRNADE to online classification tasks on both real world and synthetic datasets and compare it with multiple density based as well as nondensity based online classification methods. In almost all of these tasks, RRNADE outperforms the other methods. Lastly, we conduct an ablation study demonstrating the complementary benefits of the density and the recurrent modules.",https://openreview.net/pdf/21ee454f7a986d75f2e134372e9c2fb5b25a1848.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=K1NKDaNM9i,Counterfactual Vision-Language Data Synthesis with Intra-Sample Contrast Learning,"['Zhecan Wang', 'Yicheng He', 'Wenhao Li', 'Haoxuan You', 'Long Chen', 'Noel C Codella', 'Yulei Niu', 'Kai-Wei Chang', 'Shih-Fu Chang']","['~Zhecan_Wang2', 'yh3330@columbia.edu', 'wl2750@columbia.edu', '~Haoxuan_You1', '~Long_Chen8', '~Noel_C_Codella1', '~Yulei_Niu1', '~Kai-Wei_Chang1', '~Shih-Fu_Chang3']","['counterfactual', 'data augmentation', 'vision language', 'kowledge distillation', 'vcr', 'vqa', 'visual question answering', 'commonsense reasoning', 'multimodal', 'robust', 'domain-shift', 'debiased']","Existing Visual Learning (VL) benchmarks often contain exploitative biases. Most former works only attempted to mitigate biases in semantically low-level and conventional visual-question-answering typed datasets like VQA and GQA. However, these methods cannot generalize to recently emerging highly semantic VL datasets like VCR and are also difficult to scale due to many severe problems like high-cost labors, drastically disrupting the data distribution\textit{, etc.}To resolve those problems and also address other unique biases on VCR-like datasets, we first conduct in-depth analysis and identify important biases in VCR dataset. We further propose a generalized solution that synthesizes counterfactual image and text data based on the original query's semantic focus while producing less distortion to the data distribution. To utilize our synthesized data, we also design an innovative intra-sample contrastive training strategy to assist QA learning in Visual Commonsense Reasoning (VCR). Moreover, our synthesized VL data also serve as a highly-semantic debiased benchmark for evaluating future VL models' robustness. Extensive experiments show that our proposed synthesized data and training strategy improve existing VL models' performances on both the original VCR dataset and our proposed debiased benchmark.",https://openreview.net/pdf/d1b5c296ac9bf1fd5add23936a6a867caf241799.pdf,{'title_filter': 'Data Synthesis'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=JtC6yOHRoJJ,Human-level Atari 200x faster,"['Steven Kapturowski', 'Víctor Campos', 'Ray Jiang', 'Nemanja Rakicevic', 'Hado van Hasselt', 'Charles Blundell', 'Adria Puigdomenech Badia']","['~Steven_Kapturowski1', '~Víctor_Campos1', '~Ray_Jiang1', '~Nemanja_Rakicevic1', '~Hado_van_Hasselt1', '~Charles_Blundell1', '~Adria_Puigdomenech_Badia2']","['Reinforcement Learning', 'Data-efficiency', 'Exploration', 'Off-policy']","The task of building general agents that perform well over a wide range of tasks has been an important goal in reinforcement learning since its inception. The problem has been subject of research of a large body of work, with performance frequently measured by observing scores over the wide range of environments contained in the Atari 57 benchmark. Agent57 was the first agent to surpass the human benchmark on all 57 games, but this came at the cost of poor data-efficiency, requiring nearly 80 billion frames of experience to achieve. Taking Agent57 as a starting point, we employ a diverse set of strategies to achieve a 200-fold reduction of experience needed to outperform the human baseline, within our novel agent MEME. We investigate a range of instabilities and bottlenecks we encountered while reducing the data regime, and propose effective solutions to build a more robust and efficient agent. We also demonstrate competitive performance with high-performing methods such as Muesli and MuZero. Our contributions aim to achieve faster propagation of learning signals related to rare events, stabilize learning under differing value scales, improve the neural network architecture, and make updates more robust under a rapidly-changing policy.",https://openreview.net/pdf/b23bc123e103d66e46f6b7516e3fb6dffd1d2cba.pdf,{'abstract_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=JsrvkgM8gO2,Large Learning Rate Matters for Non-Convex Optimization,"['Amirkeivan Mohtashami', 'Martin Jaggi', 'Sebastian U Stich']","['~Amirkeivan_Mohtashami1', '~Martin_Jaggi1', '~Sebastian_U_Stich1']","['large learning rates', 'GD', 'SGD', 'non-convex optimization']","When training neural networks, it has been widely observed that a large step size is essential in stochastic gradient descent (SGD) for obtaining superior models. However, the effect of large step sizes on the success of SGD is not well understood theoretically. 
Several previous works have attributed this success to the stochastic noise present in SGD.  However, we show through a novel set of experiments that the stochastic noise is not sufficient to explain good non-convex training, and that instead the effect of a large learning rate itself is essential for obtaining best performance.
We demonstrate the same effects also in the noise-less case, i.e. for full-batch GD. We formally prove that GD with large step size---on certain non-convex function classes---follows a different trajectory than GD with a small step size, which can lead to convergence to a global minimum instead of a local one. 
Finally, we also demonstrate the difference in trajectories for small and large learning rates for real neural networks, again observing that large learning rates allow escaping from a local minimum, confirming this behavior is indeed relevant in practice.",https://openreview.net/pdf/dfe38e5de9e409abd5d1ac3a7204d02508e79e62.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=JmkjrlVE-DG,Over-Training with Mixup May Hurt Generalization,"['Zixuan Liu', 'Ziqiao Wang', 'Hongyu Guo', 'Yongyi Mao']","['~Zixuan_Liu3', '~Ziqiao_Wang1', '~Hongyu_Guo1', '~Yongyi_Mao2']","['Mixup', 'Generalization', 'Overfitting', 'Regularization']","Mixup, which creates synthetic training instances by linearly interpolating random sample pairs, is a simple and yet effective regularization technique to boost the performance of deep models trained with SGD. In this work, we report a previously unobserved phenomenon in Mixup raining: on a number of standard datasets, the performance of Mixup-trained models starts to decay after training for a large number of epochs, giving rise to a  U-shaped generalization curve. This behavior is further aggravated when the size of original dataset is reduced. To help understand such a behavior of Mixup, we show theoretically that Mixup training may introduce undesired data-dependent label noises to the synthesized data. Via analyzing a least-square regression problem with a random feature model, we explain why noisy labels may cause the U-shaped curve to occur: Mixup improves generalization through fitting the clean patterns at the early training stage,  but as training progresses, Mixup becomes over-fitting to the noise in the synthetic data. Extensive experiments are performed on a variety of benchmark datasets, validating this explanation.",https://openreview.net/pdf/9b1abc99da7f78ec360a4288ad20cecabb1eed6a.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=JdTnc9gjVfJ,MoDem: Accelerating Visual Model-Based Reinforcement Learning with Demonstrations,"['Nicklas Hansen', 'Yixin Lin', 'Hao Su', 'Xiaolong Wang', 'Vikash Kumar', 'Aravind Rajeswaran']","['~Nicklas_Hansen1', '~Yixin_Lin1', '~Hao_Su1', '~Xiaolong_Wang3', '~Vikash_Kumar2', '~Aravind_Rajeswaran1']","['model-based reinforcement learning', 'visual reinforcement learning', 'learning from demonstrations']","Poor sample efficiency continues to be the primary challenge for deployment of deep Reinforcement Learning (RL) algorithms for real-world applications, and in particular for visuo-motor control. Model-based RL has the potential to be highly sample efficient by concurrently learning a world model and using synthetic rollouts for planning and policy improvement. However, in practice, sample-efficient learning with model-based RL is bottlenecked by the exploration challenge. In this work, we find that leveraging just a handful of demonstrations can dramatically improve the sample-efficiency of model-based RL. Simply appending demonstrations to the interaction dataset, however, does not suffice. We identify key ingredients for leveraging demonstrations in model learning -- policy pretraining, targeted exploration, and oversampling of demonstration data -- which forms the three phases of our model-based RL framework. We empirically study three complex visuo-motor control domains and find that our method is 160%-250% more successful in completing sparse reward tasks compared to prior approaches in the low data regime (100k interaction steps, 5 demonstrations). Code and videos are available at https://nicklashansen.github.io/modemrl.",https://openreview.net/pdf/6a5db4c4bb6e33558fd94164736145a682ec92a3.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=JVlyfHEEm0k,Understanding Train-Validation Split in Meta-Learning with Neural Networks,"['Xinzhe Zuo', 'Zixiang Chen', 'Huaxiu Yao', 'Yuan Cao', 'Quanquan Gu']","['~Xinzhe_Zuo1', '~Zixiang_Chen1', '~Huaxiu_Yao1', '~Yuan_Cao1', '~Quanquan_Gu1']","['meta-learning', 'neural networks', 'deep learning', 'train-validation split', 'convolutional neural network']","The goal of meta-learning is to learn a good prior model from a collection of tasks such that the learned prior is able to adapt quickly to new tasks without accessing many data from the new tasks. A common practice in meta-learning is to perform a train-validation split on each task, where the training set is used for adapting the model parameter to that specific task and the validation set is used for learning a prior model that is shared across all tasks. Despite its success and popularity in multitask learning and few-shot learning, the understanding of the train-validation split is still limited, especially when the neural network models are used. In this paper, we study the benefit of train-validation split for classification problems with neural network models trained by gradient descent. We prove that the train-validation split is necessary to learn a good prior model when the noise in the training sample is large, while the train-train method fails. We validate our theory by conducting experiment on both synthetic and real datasets. To the best of our knowledge, this is the first work towards the theoretical understanding of train-validation split in meta-learning with neural networks.",https://openreview.net/pdf/b36628c00cf099f06c22fb730529a978598fddfa.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=JUNKYmGGuEw,Neural multi-event forecasting on spatio-temporal point processes using probabilistically enriched transformers,"['Negar Erfanian', 'Santiago Segarra', 'Maarten V. de Hoop']","['~Negar_Erfanian1', '~Santiago_Segarra1', '~Maarten_V._de_Hoop2']","['Stochastic Point Processes', 'Multi-event Prediction', 'Transformers', 'Normalizing Flows', 'Hawkes Process', 'Deep Learning', 'Generative Models']","Predicting discrete events in time and space has many scientific applications, such as predicting hazardous earthquakes and outbreaks of infectious diseases. History-dependent spatio-temporal Hawkes processes are often used to mathematically model these point events. However, previous approaches have faced numerous challenges, particularly when attempting to forecast multiple future events. In this work, we propose a new neural architecture for multi-event forecasting of spatio-temporal point processes, utilizing transformers, augmented with normalizing flows and probabilistic layers. Our network makes batched predictions of complex history-dependent spatio-temporal distributions of future discrete events, achieving state-of-the-art performance on a variety of benchmark datasets including the South California Earthquakes, Citibike, Covid19, and Hawkes synthetic Pinwheel datasets. More generally, we illustrate how our network can be applied to any dataset of discrete events with associated markers, even when no underlying physics is known.",https://openreview.net/pdf/886cc923e40101cd74cec91aa5c918686d5a8dc9.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=JOix_wb4AeM,In-distribution and Out-of-distribution Generalization for Graph Neural Networks,"['Emmanuel Sales', 'Renjie Liao', 'Nick Harvey']","['~Emmanuel_Sales1', '~Renjie_Liao1', '~Nick_Harvey1']","['Graph Neural Networks', 'Generalization Bounds', 'Out-of-distribution generalization', 'Learning theory']","Graph neural networks (GNNs) are models that allow learning with structured data of varying size. Despite their popularity, theoretical understanding of the generalization of GNNs is an under-explored topic. In this work, we expand the theoretical understanding of both in-distribution and out-of-distribution generalization of GNNs. Firstly, we improve upon the state-of-the-art PAC-Bayes (in-distribution) generalization bound primarily by reducing an exponential dependency on the node degree to a linear dependency. Secondly, utilizing tools from spectral graph theory, we prove some rigorous guarantees about the out-of-distribution (OOD) size generalization of GNNs, where graphs in the training set have different numbers of nodes and edges from those in the test set. To empirically verify our theoretical findings, we conduct experiments on both synthetic and real-world graph datasets. Our computed generalization gaps for the in-distribution case significantly improve the state-of-the-art PAC-Bayes results. For the OOD case, experiments on community classification tasks in large social networks show that GNNs achieve strong size generalization performance in cases guaranteed by our theory.",https://openreview.net/pdf/fafbe048be3a4216c1eb808b8c7e1ea7512b71e2.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=JDuEddUsSb,Efficient Discovery of Dynamical Laws in Symbolic Form,"['Sören Becker', 'Michal Klein', 'Alexander Neitz', 'Giambattista Parascandolo', 'Niki Kilbertus']","['~Sören_Becker2', '~Michal_Klein1', '~Alexander_Neitz1', '~Giambattista_Parascandolo1', '~Niki_Kilbertus1']","['Symbolic', 'ODE', 'Transformer']","We propose a transformer-based sequence-to-sequence model that recovers scalar ordinary differential equations (ODEs) in symbolic form from time-series data of a single observed solution trajectory of the ODE. Our method is efficiently scalable: after one-time pretraining on a large set of ODEs, we can infer the governing laws of a new observed solution in a few forward passes of the model. First, we generate and make available a large dataset of more than 3M ODEs together with more than 63M numerical solutions for different initial conditions that may serve as a useful benchmark for future work on machine learning for dynamical systems. Then we show that our model performs better or on par with existing methods in various test cases in terms of accurate symbolic recovery of the ODE, especially for more complex expressions. Reliably recovering the symbolic form of dynamical laws is important as it allows for further dissemination of the inferred dynamics as well as meaningful modifications for predictions under interventions.",https://openreview.net/pdf/090b4b0ec856b04f45884d46e851b8ee2a8ee404.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=J7CTp-jNyJ,SYNG4ME: Model Evaluation using Synthetic Test Data,"['Boris van Breugel', 'Nabeel Seedat', 'Fergus Imrie', 'Mihaela van der Schaar']","['~Boris_van_Breugel2', '~Nabeel_Seedat1', '~Fergus_Imrie1', '~Mihaela_van_der_Schaar2']","['Model Evaluation', 'Synthetic data']","Model evaluation is a crucial step in ensuring reliable machine learning systems. Currently, predictive models are evaluated on held-out test data, quantifying aggregate model performance. Limitations of available test data make it challenging to evaluate model performance on small subgroups or when the environment changes. Synthetic test data provides a unique opportunity to address this challenge; instead of evaluating predictive models on real data, we propose to use synthetic data. This brings two advantages. First, supplementing and increasing the amount of evaluation data can lower the variance of model performance estimates compared to evaluation on the original test data. This is especially true for local performance evaluation in low-density regions, e.g. minority or intersectional groups. Second, generative models can be conditioned as to induce a shift in the synthetic data distribution, allowing us to evaluate how supervised models could perform in different target settings. In this work, we propose SYNG4ME: an automated suite of synthetic data generators for model evaluation. By generating smart synthetic data sets, data practitioners have a new tool for exploring how supervised models may perform on subgroups of the data, and how robust methods are to distributional shifts. We show experimentally that SYNG4ME achieves more accurate performance estimates compared to using the test data alone.",https://openreview.net/pdf/07814e3fdf1a092fbe16856bc382b68d8260fb58.pdf,{'title_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=IVESH65r0Ar,A Simple Yet Powerful Deep Active Learning With Snapshots Ensembles,"['Seohyeon Jung', 'Sanghyun Kim', 'Juho Lee']","['~Seohyeon_Jung1', '~Sanghyun_Kim2', '~Juho_Lee2']","['Active learning', 'Snapshot ensemble', 'Uncertainty estimation']","Given an unlabeled pool of data and the experts who can label them, active learning aims to build an agent that can effectively acquire data to be queried to the experts, maximizing the gain in performance when trained with them. While there are several principles for active learning, a prevailing approach is to estimate uncertainties of predictions for unlabeled samples and use them to define acquisition functions. Active learning with the uncertainty principle works well for deep learning, especially for large-scale image classification tasks with deep neural networks. Still, it is often overlooked how the uncertainty of predictions is estimated, despite the common findings on the difficulty of accurately estimating uncertainties of deep neural networks. In this paper, we highlight the effectiveness of snapshot ensembles for deep active learning. Compared to the previous approaches based on Monte-Carlo dropout or deep ensembles, we show that a simple acquisition strategy based on uncertainties estimated from parameter snapshots gathered from a single optimization path significantly improves the quality of the acquired samples. Based on this observation, we further propose an efficient active learning algorithm that maintains a single learning trajectory throughout the entire active learning episodes, unlike the existing algorithms training models from scratch for every active learning episode. Through the extensive empirical comparison, we demonstrate the effectiveness of snapshot ensembles for deep active learning.",https://openreview.net/pdf/4b4df3d988ecc07d73d78a6a4063cc0c3153a2aa.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=HnSceSzlfrY,RPM: Generalizable Multi-Agent Policies for Multi-Agent Reinforcement Learning,"['Wei Qiu', 'Xiao Ma', 'Bo An', 'Svetlana Obraztsova', 'Shuicheng YAN', 'Zhongwen Xu']","['~Wei_Qiu3', '~Xiao_Ma2', '~Bo_An2', '~Svetlana_Obraztsova1', '~Shuicheng_YAN3', '~Zhongwen_Xu1']","['multi-agent system', 'multi-agent reinforcement learning']","Despite the recent advancement in multi-agent reinforcement learning (MARL), the MARL agents easily overfit the training environment and perform poorly in evaluation scenarios where other agents behave differently. Obtaining generalizable policies for MARL agents is thus necessary but challenging mainly due to complex multi-agent interactions. In this work, we model the MARL problem with Markov Games and propose a simple yet effective method, called ranked policy memory (RPM), i.e., to maintain a look-up memory of policies to achieve good generalizability. The main idea of RPM is to train MARL policies via gathering massive multi-agent interaction data. In particular, we first rank each agent’s policies by its training episode return, i.e., the episode return of each agent in the training environment; we then save the ranked policies in the memory; when an episode starts, each agent can randomly select a policy from the RPM as the behavior policy. Each agent uses the behavior policy to gather multi-agent interaction data for MARL training. This innovative self-play framework guarantees the diversity of multi-agent interaction in the training data. Experimental results on Melting Pot demonstrate that RPM enables MARL agents to interact with unseen agents in multi-agent generalization evaluation scenarios and complete given tasks. It significantly boosts the performance up to 818% on average.",https://openreview.net/pdf/e0f67e22108de8d6be84c75330ee0de82ed3ae5a.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Hh0BdBf6Ls,UNREAL: Unlabeled Nodes Retrieval and Labeling for Heavily-imbalanced Node Classification,"['Liang Yan', 'Shengzhong Zhang', 'Bisheng Li', 'min zhou', 'Zengfeng Huang']","['~Liang_Yan5', '~Shengzhong_Zhang1', '~Bisheng_Li1', '~min_zhou1', '~Zengfeng_Huang1']","['Node Classification', 'Heavily-imbalanced Representation Learning', 'Graph Neural Networks']","Extremely skewed label distributions are common in real-world node classification tasks. If not dealt with appropriately, it significantly hurts the performance of GNNs on minority classes. Due to the practical importance, there have been a series of recent researches devoted to this challenge. Existing over-sampling techniques smooth the label distribution by generating ''fake'' minority nodes and synthesize their features and local topology, which largely ignore the rich information of unlabeled nodes on graphs. Recent methods based on loss function modification re-weight different samples or change classification margins, which achieve good performance. However, representative methods need label information to estimate the distance of each node to its class center, which is unavailable on unlabeled nodes.  In this paper, we propose UNREAL, which is an iterative over-sampling method. The first key difference is that we only add unlabeled nodes instead of synthetic nodes, which eliminates the challenge of feature and neighborhood generation. To select which unlabeled nodes to add, we propose geometric ranking, which ranks unlabeled nodes based on unsupervised learning results in the node embedding space. Finally, we identify the issue of geometric imbalance in the embedding space and provide a simple metric to filter out geometrically imbalanced nodes. Extensive experiments on real-world benchmark datasets are conducted, and the empirical results show that our method significantly outperforms current state-of-the-art methods consistent on different datasets with different imbalance ratios.",https://openreview.net/pdf/fbef3bc8c57cb06ba0e6b7d601a18175a2d40e87.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=H8XpqEkbua_,Differentially Private Dataset Condensation,"['Tianhang Zheng', 'Baochun Li']","['~Tianhang_Zheng2', '~Baochun_Li1']",[],"Recent work in ICML'22 builds a theoretical connection between dataset condensation (DC) and differential privacy (DP) and claims that DC can provide privacy protection for free. However, the connection is problematic because of two controversial assumptions. In this paper, we revisit the ICML'22 work and elucidate the issues in the two controversial assumptions. To correctly connect DC and DP, we propose two differentially private dataset condensation (DPDC) algorithms---LDPDC and NDPDC. Through extensive evaluations on multiple datasets, we demonstrate that LDPDC has comparable performance to recent DP generative methods despite its simplicity. NDPDC provides acceptable DP guarantees with a mild utility loss, compared to the state-of-the-art DC method. Additionally, NDPDC allows a flexible trade-off between the synthetic data utility and DP budget.",https://openreview.net/pdf/05f6f7a918ed03b2dcd4f472eee2f4e0f14e67bb.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=H6LVUiHzYDE,MEGAN: Multi Explanation Graph Attention Network,"['Jonas Teufel', 'Luca Torresi', 'Patrick Nicholas Reiser', 'Pascal Friederich']","['~Jonas_Teufel1', '~Luca_Torresi1', '~Patrick_Nicholas_Reiser1', '~Pascal_Friederich1']","['explainable artificial intelligence', 'interpretable machine learning', 'graph neural networks', 'attention network', 'graph regression', 'graph classification']","Explainable artificial intelligence (XAI) methods are expected to improve trust during human-AI interactions, provide tools for model analysis and extend human understanding of complex problems. Attention-based models are an important subclass of XAI methods, partly due to their full differentiability and the potential to improve explanations by means of explanation-supervised training. We propose the novel multi-explanation graph attention network (MEGAN). Our graph regression and classification model features multiple explanation channels, which can be chosen independently of the task specifications. We first validate our model on a synthetic graph regression dataset, where our model produces single-channel explanations with quality similar to GNNExplainer. Furthermore, we demonstrate the advantages of multi-channel explanations on one synthetic and two real-world datasets: The prediction of water solubility of molecular graphs and sentiment classification of movie reviews. We find that our model produces explanations consistent with human intuition, opening the way to learning from our model in less well-understood tasks.",https://openreview.net/pdf/3e9c0a43ac73486c039e8cb907bf13b8b015ca71.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=H0gdPxSwkPb,Diffusion Adversarial Representation Learning for Self-supervised Vessel Segmentation,"['Boah Kim', 'Yujin Oh', 'Jong Chul Ye']","['~Boah_Kim1', '~Yujin_Oh1', '~Jong_Chul_Ye1']","['Diffusion model', 'Adversarial learning', 'Self-supervised learning', 'Vessel segmentation']","Vessel segmentation in medical images is one of the important tasks in the diagnosis of vascular diseases and therapy planning. Although learning-based segmentation approaches have been extensively studied, a large amount of ground-truth labels are required in supervised methods and confusing background structures make neural networks hard to segment vessels in an unsupervised manner. To address this, here we introduce a novel diffusion adversarial representation learning (DARL) model that leverages a denoising diffusion probabilistic model with adversarial learning, and apply it to vessel segmentation. In particular, for self-supervised vessel segmentation, DARL learns the background signal using a diffusion module, which lets a generation module effectively provide vessel representations. Also, by adversarial learning based on the proposed switchable spatially-adaptive denormalization, our model estimates synthetic fake vessel images as well as vessel segmentation masks, which further makes the model capture vessel-relevant semantic information. Once the proposed model is trained, the model generates segmentation masks in a single step and can be applied to general vascular structure segmentation of coronary angiography and retinal images. Experimental results on various datasets show that our method significantly outperforms existing unsupervised and self-supervised vessel segmentation methods.",https://openreview.net/pdf/daadbc20b5665f981c5c27eeb20cb5e9ba6ac96e.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=GvMuB-YsiK6,Explaining Patterns in Data  with  Language Models via Interpretable Autoprompting,"['Chandan Singh', 'John Xavier Morris', 'Jyoti Aneja', 'Alexander M Rush', 'Jianfeng Gao']","['~Chandan_Singh1', '~John_Xavier_Morris1', '~Jyoti_Aneja2', '~Alexander_M_Rush1', '~Jianfeng_Gao1']","['Interpretability', 'explainability', 'XAI', 'AI for science']","Large language models (LLMs) have displayed an impressive ability to harness natural language to perform complex tasks. In this work, we explore whether we can leverage this learned ability to find and explain patterns in data. Specifically, given a pre-trained LLM and data examples, we introduce interpretable autoprompting (iPrompt), an algorithm that generates a natural-language string explaining the data. iPrompt iteratively alternates between generating explanations with an LLM and reranking them based on their performance when used as a prompt. Experiments on a wide range of datasets, from synthetic mathematics to natural-language understanding, show that iPrompt can yield meaningful insights by accurately finding groundtruth dataset descriptions. Moreover, the prompts produced by iPrompt are simultaneously human-interpretable and highly effective for generalization: on real-world sentiment classification datasets, iPrompt produces prompts that match or even improve upon human-written prompts for GPT-3. Finally, experiments with an fMRI dataset show the potential for iPrompt to aid in scientific discovery.",https://openreview.net/pdf/2607a064389bdde9d47bd61f38b952fb58cb49c2.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=GVWySHBD3Cl,Estimating Treatment Effects using Neurosymbolic Program Synthesis,"['Abbavaram Gowtham Reddy', 'Vineeth N. Balasubramanian']","['~Abbavaram_Gowtham_Reddy1', '~Vineeth_N._Balasubramanian2']","['Causal effect', 'treatment effect', 'neurosymbolic programming', 'domain specific language']","Estimating treatment effects from observational data is a central problem in causal inference. Methods to solve this problem exploit inductive biases and heuristics from causal inference to design multi-head neural network architectures and regularizers. In this work, we propose to use neurosymbolic program synthesis, a data-efficient, and interpretable technique, to solve the treatment effect estimation problem. We theoretically show that neurosymbolic programming can solve the treatment effect estimation problem. By designing a Domain Specific Language (DSL) for treatment effect estimation based on the inductive biases used in literature, we argue that neurosymbolic programming is a better alternative to treatment effect estimation than traditional models. Our empirical study reveals that our model, which implicitly encodes inductive biases in a DSL, achieves better performance on benchmark datasets than the state-of-the-art models.",https://openreview.net/pdf/52795a7ad62996e037db584b54e9bcd13a3771ac.pdf,{'title_filter': 'Data Synthesis'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=GUfVNbxIYv,$\Phi$-DVAE: Learning Physically Interpretable Representations with Nonlinear Filtering,"['Alex John Glyn-Davies', 'Connor Duffin', 'Omer Deniz Akyildiz', 'Mark Girolami']","['~Alex_John_Glyn-Davies1', '~Connor_Duffin1', '~Omer_Deniz_Akyildiz1', '~Mark_Girolami2']","['variational autoencoder', 'nonlinear filter', 'physics-informed', 'parameter estimation', 'variational inference', 'Bayesian inverse problems']","Incorporating unstructured data into physical models is a challenging problem that is emerging in data assimilation. Traditional approaches focus on well-defined observation operators whose functional forms are typically assumed to be known. This prevents these methods from achieving a consistent model-data synthesis in configurations where the mapping from data-space to model-space is unknown. To address these shortcomings, in this paper we develop a physics-informed dynamical variational autoencoder ($\Phi$-DVAE) for embedding diverse data streams into time-evolving physical systems described by differential equations. Our approach combines a standard (possibly nonlinear) filter for the latent state-space model and a VAE, to embed the unstructured data stream into the latent dynamical system. A variational Bayesian framework is used for the joint estimation of the embedding, latent states, and unknown system parameters. To demonstrate the method, we look at three examples: video datasets generated by the advection and Korteweg-de Vries partial differential equations, and a velocity field generated by the Lorenz-63 system. Comparisons with relevant baselines show that the $\Phi$-DVAE provides a data efficient dynamics encoding methodology that is competitive with standard approaches, with the added benefit of incorporating a physically interpretable latent space.",https://openreview.net/pdf/35c27b781c88ecab409bb0dacde7e7b97d010388.pdf,{'abstract_filter': 'Data Synthesis'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=GULFHQfgw0g,Neural Agents Struggle to Take Turns in Bidirectional Emergent Communication,"['Valentin Taillandier', 'Dieuwke Hupkes', 'Benoît Sagot', 'Emmanuel Dupoux', 'Paul Michel']","['~Valentin_Taillandier1', '~Dieuwke_Hupkes1', '~Benoît_Sagot1', '~Emmanuel_Dupoux1', '~Paul_Michel1']","['language emergence', 'turn-taking', 'conversation', 'communication', 'neural agents', 'cooperative game', 'reinforcement learning']","The spontaneous exchange of turns is a central aspect of human communication. Although turn-taking conventions come to us naturally, artificial dialogue agents struggle to coordinate, and must rely on hard-coded rules to engage in interactive conversations with human interlocutors. In this paper, we investigate the conditions under which artificial agents may naturally develop turn-taking conventions in a simple language game. We describe a cooperative task where success is contingent on the exchange of information along a shared communication channel where talking over each other hinders communication. Despite these environmental constraints, neural-network based agents trained to solve this task with reinforcement learning do not systematically adopt turn-taking conventions. However, we find that agents that do agree on turn-taking protocols end up performing better. 
Moreover, agents that are forced to perform turn-taking can learn to solve the task more quickly. 
This suggests that turn-taking may help to generate conversations that are easier for speakers to interpret.",https://openreview.net/pdf/f6e0700b1a4de32f13aabefaa7a865a60b7ce2f2.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=GKsNIC_mQRG,Emergence of Exploration in Policy Gradient Reinforcement Learning via Resetting,"['Sotetsu Koyamada', 'Paavo Parmas', 'Tadashi Kozuno', 'Shin Ishii']","['~Sotetsu_Koyamada1', '~Paavo_Parmas1', '~Tadashi_Kozuno1', '~Shin_Ishii1']",[],"In reinforcement learning (RL), many exploration methods explicitly promote stochastic policies, e.g., by adding an entropy bonus. We argue that exploration only matters in RL because the agent repeatedly encounters the same or similar states, so that it is beneficial to gradually improve the performance over the encounters; otherwise, the greedy policy would be optimal. Based on this intuition, we propose ReMax, an objective for RL whereby stochastic exploration arises as an emergent property, without adding any explicit exploration bonus. In ReMax, an episode is modified so that the agent can reset to previous states in the trajectory, and the agent’s goal is to maximize the best return in the trajectory tree. We show that this ReMax objective can be directly optimized with an unbiased policy gradient method. Experiments confirm that ReMax leads to the emergence of a stochastic exploration policy, and improves the performance compared to RL with no exploration bonus.",https://openreview.net/pdf/c06884cb07438f1f31c60d5151e54b39e26d33d4.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=G7E_K3WaLpK,Infusing Lattice Symmetry Priors in Neural Networks Using Soft Attention Masks,"['Mattia Atzeni', 'Mrinmaya Sachan', 'Andreas Loukas']","['~Mattia_Atzeni1', '~Mrinmaya_Sachan3', '~Andreas_Loukas1']",[],"Infusing inductive biases and knowledge priors in artificial neural networks is a promising approach for achieving sample efficiency in current deep learning models. Core knowledge priors of human intelligence have been studied extensively in developmental science and recent work has postulated the idea that research on artificial intelligence should revolve around the same basic priors. As a step towards this direction, in this paper, we introduce LatFormer, a model that incorporates lattice geometry and topology priors in attention masks.
Our study of the properties of these masks motivates a modification to the standard attention mechanism, where attention weights are scaled using soft attention masks generated by a convolutional neural network. Our experiments on ARC and on synthetic visual reasoning tasks show that LatFormer requires 2-orders of magnitude fewer data than standard attention and transformers in these tasks. Moreover, our results on ARC tasks that incorporate geometric priors provide preliminary evidence that deep learning can tackle this complex dataset, which is widely viewed as an important open challenge for AI research.",https://openreview.net/pdf/0c40eeab7a893043ada108b7be6a59b17fb16241.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=F_EhNDSamN,Parametrizing Product Shape Manifolds by Composite Networks,"['Josua Sassen', 'Klaus Hildebrandt', 'Martin Rumpf', 'Benedikt Wirth']","['~Josua_Sassen1', '~Klaus_Hildebrandt1', '~Martin_Rumpf1', '~Benedikt_Wirth1']","['shape spaces', 'product manifolds', 'nonlinear statistics', 'low-dimensional data manifolds']","Parametrizations of data manifolds in shape spaces can be computed using the rich toolbox of Riemannian geometry. This, however, often comes with high computational costs, which raises the question if one can learn an efficient neural network approximation. We show that this is indeed possible for shape spaces with a special product structure, namely those smoothly approximable by a direct sum of low-dimensional manifolds. Our proposed architecture leverages this structure by separately learning approximations for the low-dimensional factors and a subsequent combination. After developing the approach as a general framework, we apply it to a shape space of triangular surfaces. Here, typical examples of data manifolds are given through datasets of articulated models and can be factorized, for example, by a Sparse Principal Geodesic Analysis (SPGA). We demonstrate the effectiveness of our proposed approach with experiments on synthetic data as well as manifolds extracted from data via SPGA.",https://openreview.net/pdf/2832887c23c3957ac23c919a6f7a43abde5a7ef2.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=FJdSi_seSg,Do We Always Need to Penalize Variance of Losses for Learning with Label Noise?,"['Yexiong Lin', 'Yu Yao', 'Yuxuan Du', 'Jun Yu', 'Bo Han', 'Mingming Gong', 'Tongliang Liu']","['~Yexiong_Lin1', '~Yu_Yao3', '~Yuxuan_Du2', '~Jun_Yu3', '~Bo_Han1', '~Mingming_Gong1', '~Tongliang_Liu1']",[],"Algorithms which minimize the averaged loss have been widely designed for dealing with noisy labels. Intuitively, when there is a finite training sample, penalizing the variance of losses will improve the stability and generalization of the algorithms. Interestingly, we found that the variance of losses sometimes needs to be increased for the problem of learning with noisy labels. Specifically, increasing the variance of losses would boost the memorization effect and reduce the harmfulness of incorrect labels. Regularizers can be easily designed to increase the variance of losses and be plugged in many existing algorithms. Empirically, the proposed method by increasing the variance of losses could improve the generalization ability of baselines on both synthetic and real-world datasets.",https://openreview.net/pdf/ea6946cc1e63e2067130c3c79c0b89cdb7dad2a4.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=F5uYcwABMu,"Same Pre-training Loss, Better Downstream: Implicit Bias Matters for Language Models","['Hong Liu', 'Sang Michael Xie', 'Zhiyuan Li', 'Tengyu Ma']","['~Hong_Liu5', '~Sang_Michael_Xie1', '~Zhiyuan_Li2', '~Tengyu_Ma1']","['Language Modeling', 'Implicit Bias']","Language modeling on large-scale datasets leads to impressive performance gains on various downstream language tasks.  The (validation) pre-training loss (or perplexity in autoregressive language modeling) is often used as the evaluation metric when developing language models since the pre-training loss tends to be well-correlated with downstream performance (which is itself difficult to evaluate comprehensively). Contrary to this conventional wisdom, this paper shows that 1) pre-training loss cannot fully explain downstream performance and 2) flatness of the model is well-correlated with downstream performance where pre-training loss is not. On simplified datasets, we identify three ways to produce models with the same (statistically optimal) pre-training loss but different downstream performance: continue pre-training after convergence, increasing the model size, and changing the training algorithm.  These experiments demonstrate the existence of implicit bias of pre-training algorithms/optimizers---among models with the same minimal pre-training loss, they implicitly prefer more transferable ones. Toward understanding this implicit bias, we prove that SGD with standard mini-batch noise implicitly prefers flatter minima in language models, and empirically observe a strong correlation between flatness and downstream performance among models with the same minimal pre-training loss. We also prove in a synthetic language setting that among the models with the minimal pre-training loss, the flattest model transfers to downstream tasks.",https://openreview.net/pdf/7f758bfc0a1a58c52ba31364a2db83a58c023658.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=EpvL_FaLtw,Multi-Treatment Effect Estimation with Proxy: Contrastive Learning and Rank Weighting,"['Minqin Zhu', 'Anpeng Wu', 'Ruoxuan Xiong', 'Kun Kuang']","['~Minqin_Zhu1', '~Anpeng_Wu1', '~Ruoxuan_Xiong1', '~Kun_Kuang1']",[],"We study the treatment effect estimation problem for continuous and multi-dimensional treatments, in the setting with unobserved confounders, but high-dimension proxy variables for unobserved confounders are available. Existing methods either directly adjust the relationship between observed covariates and treatments or recover the hidden confounders by probabilistic models. However, they either rely on a correctly specified treatment assignment model or require strong prior of the unobserved confounder distribution. To relax these requirements, we propose a Contrastive Regularizer (CR) to learn the proxy representation that  contains all the relevant information in unobserved confounders. Based on the CR, we propose a novel ranked weighting method (Rw) to de-bias the treatment assignment. Combining Cr and Rw, we propose a neural network framework named CRNet to estimate the effects of multiple continuous treatments under unobserved confounders, evaluated by the Average Dose-Response Function. Empirically, we demonstrate that CRNet achieves state-of-the-art performance on both synthetic and semi-synthetic datasets.",https://openreview.net/pdf/2407bbda886499fbfc7788ca329d0c2ec027531b.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=ERjQnrmLKH4,Learning Counterfactually Invariant Predictors,"['Francesco Quinzan', 'Cecilia Casolo', 'Krikamol Muandet', 'Niki Kilbertus', 'Yucen Luo']","['~Francesco_Quinzan1', '~Cecilia_Casolo1', '~Krikamol_Muandet1', '~Niki_Kilbertus1', '~Yucen_Luo1']","['causality', 'kernel mean embeddings', 'counterfactual fairness', 'counterfactual invariance']","We propose a method to learn predictors that are invariant under counterfactual changes of certain covariates. This method is useful when the prediction target is causally influenced by covariates that should not affect the predictor output. For instance, this could prevent an object recognition model from being influenced by position, orientation, or scale of the object itself. We propose a model-agnostic regularization term based on conditional kernel mean embeddings to enforce counterfactual invariance during training. We prove the soundness of our method, which can handle mixed categorical and continuous multivariate attributes. Empirical results on synthetic and real-world data demonstrate the efficacy of our method in a variety of settings.",https://openreview.net/pdf/f97ee6813bf33599b18a5255910356dfd0d95830.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=ED2Jjms9A4H,Efficient Exploration via Fragmentation and Recall,"['Jaedong Hwang', 'Zhang-Wei Hong', 'Eric R Chen', 'Akhilan Boopathy', 'Pulkit Agrawal', 'Ila R Fiete']","['~Jaedong_Hwang1', '~Zhang-Wei_Hong1', '~Eric_R_Chen1', '~Akhilan_Boopathy1', '~Pulkit_Agrawal1', '~Ila_R_Fiete1']","['fragmentation', 'recall', 'exploration', 'cognitive science', 'neuroscience', 'curiosity', 'reinforcement learning', 'spatial navigation']","Efficient exploration and model-building are critical for learning in large state- spaces. However, agents typically face problems like getting stuck locally during exploration and catastrophic forgetting in their construction of models when the environments are heterogeneous. Here, we propose and apply the concept of Fragmentation-and-Recall to solve spatial (FarMap) and reinforcement learning problems (FarCuriosity). Agents construct local maps or local models, respectively, which are used to predict the current observation. High surprisal points lead to a fragmentation event. At fracture points, we store the current map or model fragment in a long-term memory (LTM) and initialize a new fragment. On the other hand, Fragments are recalled (and thus reused) from LTM if the observations of their fracture points match the agent’s current observation during exploration. The set of fracture points defines a set of intrinsic potential subgoals. Agents choose their next subgoal from the set of near and far potential subgoals in the current fragment or LTM, respectively. Thus, local maps and model fragments guide exploration locally and avoid catastrophic forgetting in learning heterogeneous environments, while LTM promotes exploration more globally. We evaluate FarMap and FarCuriosity on complex procedurally-generated spatial environments and on reinforcement learning benchmarks and demonstrate that the proposed methods are more efficient at exploration and memory use, and in harvesting extrinsic rewards, respectively.",https://openreview.net/pdf/f07f4d9ba345a1688439bd1531056ed3169d52e2.pdf,{'abstract_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=E8mzu3JbdR,ChordMixer: A Scalable Neural Attention Model for Sequences with Different Length,"['Ruslan Khalitov', 'Tong Yu', 'Lei Cheng', 'Zhirong Yang']","['~Ruslan_Khalitov1', '~Tong_Yu4', '~Lei_Cheng1', '~Zhirong_Yang1']","['Mixer', 'Attention', 'Scalable']","Sequential data naturally have different lengths in many domains, with some very long sequences. As an important modeling tool, neural attention should capture long-range interaction in such sequences. However, most existing neural attention models admit only short sequences, or they have to employ chunking or padding to enforce a constant input length. Here we propose a simple neural network building block called ChordMixer which can model the attention for long sequences with variable lengths. Each ChordMixer block consists of a position-wise rotation layer without learnable parameters and an element-wise MLP layer. Repeatedly applying such blocks forms an effective network backbone that mixes the input signals towards the learning targets. We have tested ChordMixer on the synthetic adding problem, long document classification, and DNA sequence-based taxonomy classification. The experiment results show that our method substantially outperforms other neural attention models.",https://openreview.net/pdf/dbeed2c3d0b79691b83802ee788e14ea278798b1.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=E3ip6qBLF7,Distributionally Robust Recourse Action,"['Duy Nguyen', 'Ngoc Bui', 'Viet Anh Nguyen']","['~Duy_Nguyen2', '~Ngoc_Bui1', '~Viet_Anh_Nguyen2']","['Robust Optimization', 'Explainable AI', 'Algorithmic Recourse']","A recourse action aims to explain a particular algorithmic decision by showing one specific way in which the instance could be modified to receive an alternate outcome. Existing recourse generation methods often assume that the machine learning model does not change over time. However, this assumption does not always hold in practice because of data distribution shifts, and in this case, the recourse action may become invalid. To redress this shortcoming, we propose the Distributionally Robust Recourse Action (DiRRAc) framework, which generates a recourse action that has high probability of being valid under a mixture of model shifts. We first formulate the robustified recourse setup as a min-max optimization problem, where the max problem is specified by Gelbrich distance over an ambiguity set around the distribution of model parameters. Then we suggest a projected gradient descent algorithm to find a robust recourse according to the min-max objective. We also show that our DiRRAc framework can be extended to hedge against the misspecification of the mixture weights. Numerical experiments with both synthetic and three real-world datasets demonstrate the benefits of our proposed framework over the state-of-the-art recourse methods, which generate robust recourses.
",https://openreview.net/pdf/2ba3251326914f789659bf5c76f1bc06b8567cb4.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Do9MOlwWHu0,Learning Sparse Group Models Through Boolean Relaxation,"['Yijie Wang', 'Yuan Zhou', 'Xiaoqing Huang', 'Kun Huang', 'Jie Zhang', 'Jianzhu Ma']","['~Yijie_Wang2', '~Yuan_Zhou1', '~Xiaoqing_Huang1', '~Kun_Huang2', '~Jie_Zhang20', '~Jianzhu_Ma2']","['Structured sparisity', 'Convex relaxation', 'Cardinality-constrained program', 'Small sample size']","We introduce an efficient algorithmic framework for learning sparse group models formulated as the natural convex relaxation of a cardinality-constrained program with Boolean variables. We provide theoretical techniques to characterize the equivalent condition when the relaxation achieves the exact integral optimal solution, as well as a rounding algorithm to produce a feasible integral solution once the optimal relaxation solution is fractional. We demonstrate the power of our equivalent condition by applying it to two ensembles of random problem instances that are challenging and popularly used in literature and prove that our method achieves exactness with overwhelming probability and nearly optimal sample complexity. Empirically, we use synthetic datasets to demonstrate that our proposed method significantly outperforms the state-of-the-art group sparse learning models in terms of individual and group support recovery when the number of samples is small. Furthermore, we show the out-performance of our method in cancer drug response prediction.",https://openreview.net/pdf/0760530295a66fdff783489bb9ee1628a6ed3880.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=DeG07_TcZvT,Emergent World Representations: Exploring a Sequence Model Trained on a Synthetic Task,"['Kenneth Li', 'Aspen K Hopkins', 'David Bau', 'Fernanda Viégas', 'Hanspeter Pfister', 'Martin Wattenberg']","['~Kenneth_Li1', '~Aspen_K_Hopkins1', '~David_Bau1', '~Fernanda_Viégas1', '~Hanspeter_Pfister1', '~Martin_Wattenberg1']","['world representation', 'GPT']","Language models show a surprising range of capabilities, but the source of their apparent competence is unclear. Do these networks just memorize a collection of surface statistics, or do they rely on internal representations of the process that generates the sequences they see? We investigate this question by applying a variant of the GPT model to the task of predicting legal moves in a simple board game, Othello. Although the network has no a priori knowledge of the game or its rules, we uncover evidence of an emergent nonlinear internal representation of the board state. Interventional experiments indicate this representation can be used to control the output of the network and create ""latent saliency maps"" that can help explain predictions in human terms.",https://openreview.net/pdf/70fb51a26cffdf3304e24f4d2e803b729904fe20.pdf,{'title_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=De4FYqjFueZ,Transformers Learn Shortcuts to Automata,"['Bingbin Liu', 'Jordan T. Ash', 'Surbhi Goel', 'Akshay Krishnamurthy', 'Cyril Zhang']","['~Bingbin_Liu1', '~Jordan_T._Ash1', '~Surbhi_Goel1', '~Akshay_Krishnamurthy1', '~Cyril_Zhang1']","['Transformer', 'self-attention', 'group theory', 'semigroup theory', 'algebraic automata theory', 'shortcut learning', 'theory of deep learning']","Algorithmic reasoning requires capabilities which are most naturally understood through recurrent models of computation, like the Turing machine. However, Transformer models, while lacking recurrence, are able to perform such reasoning using far fewer layers than the number of reasoning steps. This raises the question: what solutions are these shallow and non-recurrent models finding? We investigate this question in the setting of learning automata, discrete dynamical systems naturally suited to recurrent modeling and expressing algorithmic tasks. Our theoretical results completely characterize shortcut solutions, whereby a shallow Transformer with only $o(T)$ layers can exactly replicate the computation of an automaton on an input sequence of length $T$. By representing automata using the algebraic structure of their underlying transformation semigroups, we obtain $O(\log T)$-depth simulators for all automata and $O(1)$-depth simulators for all automata whose associated groups are solvable. Empirically, we perform synthetic experiments by training Transformers to simulate a wide variety of automata, and show that shortcut solutions can be learned via standard training. We further investigate the brittleness of these solutions and propose potential mitigations.",https://openreview.net/pdf/6fceba3e100352173ef8f64b4743424fc99f1e8d.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Db_WALIfbdC,Bayesian Optimal Experimental Design for the Survey Bandit Setting,"['Sang T. Truong', 'Willie Neiswanger', 'Susan Athey']","['~Sang_T._Truong1', '~Willie_Neiswanger2', '~Susan_Athey1']","['Bayesian optimal experimental design', 'contextual bandit', 'survey']","The contextual bandit is a classic problem in sequential decision making under uncertainty that finds broad application to tasks in precision medicine, personalized education, and drug discovery. Here, a decision maker repeatedly receives a context, takes an action, and then observes an associated outcome, with the goal of choosing actions that achieve a minimal regret. However, in many settings, the context is not given, and the decision maker must instead collect some information to infer a context before proceeding. For example, when a doctor does not have prior information about a patient, they might ask a sequence of questions before recommending a medical treatment. In this paper, we aim to develop methods for this setting—which we refer to as the \emph{survey bandit}—where the decision maker is not given access to the context but can ask a finite sequence of questions to gain information about the context before taking an action and observing an outcome. Using insights from Bayesian optimal experimental design (BOED) and decision-theoretic information theory, we view the interaction with each user as a BOED task, where the goal is to ask a sequence of questions that elicit the most information about the optimal action for this user. Our procedure is agnostic to the choice of probabilistic model, and we demonstrate its usefulness in a few common classes of distributions. Our algorithm achieves significantly better performance on both synthetic and real data relative to existing baseline methods while remaining statistically efficient, interpretable, and computationally friendly.",https://openreview.net/pdf/7404513cf6a65ffdebcd858cb1aa8056a9935f24.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=DAxQXzdq8SF,SOM-CPC: Unsupervised Contrastive Learning with Self-Organizing Maps for Structured Representations of High-Rate Time Series,"['Iris A.M. Huijben', 'Arthur Andreas Nijdam', 'Sebastiaan Overeem', 'Merel M Van Gilst', 'Ruud Van Sloun']","['~Iris_A.M._Huijben1', '~Arthur_Andreas_Nijdam1', '~Sebastiaan_Overeem1', '~Merel_M_Van_Gilst1', '~Ruud_Van_Sloun1']","['Contrastive Predictive Coding', 'Self-Organizing Maps', 'Time series', 'Dimensionality Reduction']","Continuous monitoring with an ever-increasing number of sensors has become ubiquitous across many application domains. Acquired data are typically high-dimensional and difficult to interpret, but they are also hypothesized to lie on a low-dimensional manifold. Dimensionality reduction techniques have, therefore, been sought for. Popular linear methods like Principle Component Analysis (PCA) have been extended to non-linear techniques such as Self-Organizing Maps (SOMs) or deep learning (DL) models. DL models have the ability to act on raw data, preventing heuristic feature selection, but the resulting latent space is often unstructured and still multi-dimensional. PCA and SOMs, on the other hand, need to be preceded with a feature-extraction step, but can then map high-dimensional features to 2D space. In this work we propose SOM-CPC, a model that jointly optimizes Contrastive Predictive Coding and a SOM to find an organized 2D manifold. We address a largely unexplored and challenging set of scenarios comprising high-rate time series, and show on both synthetic and real-life data (medical sleep data and audio recordings) that SOM-CPC outperforms both DL-based feature extraction, followed by PCA, K-means or a SOM, and strong deep-SOM baselines that jointly optimize a DL model and a SOM. SOM-CPC has great potential to expose latent patterns in high-rate data streams and may therefore contribute to a better understanding of many different processes and systems. ",https://openreview.net/pdf/f85ad885376722f740ab9f661f2599ae480d5a3d.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=CxPw6TeByX4,SoundNeRirF: Receiver-to-Receiver Sound Neural Room Impulse Response Field,"['Yuhang He', 'Jia-Xing Zhong', 'Zhuangzhuang Dai', 'Niki Trigoni', 'Andrew Markham']","['~Yuhang_He3', '~Jia-Xing_Zhong1', '~Zhuangzhuang_Dai1', '~Niki_Trigoni1', '~Andrew_Markham2']","['Sound Neural Rendering Field', 'Sound Prediction', 'Representation Learning', 'Receiver-to-Receiver Modelling']","We present SoundNeRirF, a framework that learns a continuous receiver-to-receiver neural room impulse response field~(r2r-RIR) to help robot efficiently predict the sound to be heard at novel locations. It represents a room acoustic scene as a continuous 6D function, whose input is a reference receiver's 3D position and a target receiver's 3D position, and whose outputs are an inverse room impulse response~(inverse-RIR) and a forward room impulse response~(forward-RIR) that jointly project the sound from the reference position to the target position. SoundNeRirF requires knowledge of neither sound source (e.g. location and number of sound sources) nor room acoustic properties~(e.g. room size, geometry, materials). Instead, it merely depends on a sparse set of sound receivers' positions, as well as the recorded sound at each position. We instantiate the continuous 6D function as multi-layer perceptrons~(MLP), so it is fully differentiable and continuous at any spatial position. SoundNeRirF is encouraged, during the training stage, to implicitly encode the interaction between sound sources, receivers and room acoustic properties by minimizing the discrepancy between the predicted sound and the truly heard sound at the target position. During inference, the sound at a novel position is predicted by giving a reference position and the corresponding reference sound. Extensive experiments on both synthetic and real-world datasets show SoundNeRirF is capable of predicting high-fidelity and audio-realistic sound that fully captures room reverberation characteristics, significantly outperforming existing methods in terms of accuracy and efficiency.",https://openreview.net/pdf/d53f3d8fe3cd72b5ed2fd9bc88252b05e394dabf.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Cx1xYn6vVm2,A Mutual Information Duality Algorithm for Multi-Agent Specialization,"['Stefan Juang', 'Qiyang Cao', 'Yuan Zhou', 'Ruochen Liu', 'Nevin Zhang', 'Elvis S. Liu']","['~Stefan_Juang1', '~Qiyang_Cao1', '~Yuan_Zhou9', '~Ruochen_Liu2', '~Nevin_Zhang1', '~Elvis_S._Liu1']","['Multi-agent', 'Reinforcement Learning', 'Mutual Information', 'Duality', 'Policy Gradient', 'Social Graph']","The social behavior change in a population has long been studied as an essential component of multi-agent learning. The learning of behavioral change not only involves reinforcement learning (RL), but also be measured against the general population with mutual information (MI). The combination of RL and MI led us to derive MI optimizations from policy gradient. With MI as multi-agent's optimization objective, we discover that the dual properties of MI can result in distinctly different population behaviors. From MI maximization that maximizes the stability of a population to MI minimization that enables specialization among the agents, the dual of MI creates a significant change in a population's behavioral properties. In this paper, we propose a minimax formulation of MI (M\&M) that enables agents specialization with stable regularization. Empirically we evaluated M\&M against the prior SOTA MARL framework, and analyze the social behavior change in performance, diversity, and the stability of their social graphs. ",https://openreview.net/pdf/c4b4baec433aaa241d9588a232e85cb024d88c48.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Cp-io_BoFaE,FluidLab: A Differentiable Environment for Benchmarking Complex Fluid Manipulation,"['Zhou Xian', 'Bo Zhu', 'Zhenjia Xu', 'Hsiao-Yu Tung', 'Antonio Torralba', 'Katerina Fragkiadaki', 'Chuang Gan']","['~Zhou_Xian1', '~Bo_Zhu2', '~Zhenjia_Xu1', '~Hsiao-Yu_Tung2', '~Antonio_Torralba1', '~Katerina_Fragkiadaki1', '~Chuang_Gan1']","['Complex Fluid Manipulation', 'Differentiable Physics']","Humans manipulate various kinds of fluids in their everyday life: creating latte art, scooping floating objects from water, rolling an ice cream cone, etc. Using robots to augment or replace human labors in these daily settings remain as a challenging task due to the multifaceted complexities of fluids. Previous research in robotic fluid manipulation mostly consider fluids governed by an ideal, Newtonian model in simple task settings (e.g., pouring water into a container). However, the vast majority of real-world fluid systems manifest their complexities in terms of the fluid’s complex material behaviors (e.g., elastoplastic deformation) and multi-component interactions (e.g. coffee and frothed milk when making latte art), both of which were well beyond the scope of the current literature. To evaluate robot learning algorithms on understanding and interacting with such complex fluid systems, a comprehensive virtual platform with versatile simulation capabilities and well-established tasks is needed. In this work, we introduce FluidLab, a simulation environment with a diverse set of manipulation tasks involving complex fluid dynamics. These tasks address interactions between solid and fluid as well as among multiple fluids. At the heart of our platform is a fully differentiable physics simulator, FluidEngine, providing GPU-accelerated simulations and gradient calculations for various material types and their couplings, extending the scope of the existing differentiable simulation engines. We identify several challenges for fluid manipulation learning by evaluating a set of reinforcement learning and trajectory optimization methods on our platform. To address these challenges, we propose several domain-specific optimization schemes coupled with differentiable physics, which are empirically shown to be effective in tackling optimization problems featured by fluid system’s non-convex and non-smooth properties. Furthermore, we demonstrate reasonable sim-to-real transfer by deploying optimized trajectories in real-world settings. FluidLab is publicly available at: https://fluidlab2023.github.io.",https://openreview.net/pdf/6f396409f5100c7dca4d9a23810e4e4aefb8c5f2.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Cn6JkFnKgPX,Analysis of differentially private synthetic data: a general measurement error approach,"['Yangdi Jiang', 'Yi Liu', 'Xiaodong Yan', 'Anne-Sophie Charest', 'Linglong Kong', 'Bei Jiang']","['~Yangdi_Jiang1', '~Yi_Liu13', '~Xiaodong_Yan1', '~Anne-Sophie_Charest1', '~Linglong_Kong2', '~Bei_Jiang1']","['Measurement Error Model', 'Differential Privacy', 'Regression', 'Statistical Inference']","Differential private (DP) synthetic datasets have been receiving significant attention from academia, industry, and government. However, little is known about how to perform statistical inference using DP synthetic datasets. Naive approaches that do not take into account the induced uncertainty due to DP mechanism will result in biased estimators and invalid inferences. In this paper, we present a general class of bias-corrected DP estimators with valid asymptotic confidence intervals for parameters in regression settings, by establishing the connection between additive DP mechanisms and measurement error models. Our simulation shows that when the sample covariance between DP noises and data is close to zero, our estimator is far superior to the widely used sufficient statistic perturbation algorithm, and the CIs can achieve better coverage when comparing to the naive CIs obtained from ignoring the DP mechanism.",https://openreview.net/pdf/066a8bbdf9a4c5d46cca6f988e4e83de5ee753cf.pdf,{'title_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=CgCmwcfgEdH,PGrad: Learning Principal Gradients For Domain Generalization,"['Zhe Wang', 'Jake Grigsby', 'Yanjun Qi']","['~Zhe_Wang19', '~Jake_Grigsby1', '~Yanjun_Qi1']",[],"Machine learning models fail to perform when facing out-of-distribution (OOD) domains, a challenging task known as domain generalization (DG). In this work, we develop a novel DG training strategy, we call PGrad, to learn a robust gradient direction, improving models' generalization ability on unseen domains.  The proposed gradient aggregates the principal directions of a sampled roll-out optimization trajectory that measures the training dynamics across all training domains. PGrad gradient design forces the DG training to ignore domain-dependent noise signals and updates all training domains with a robust direction covering main components of parameter dynamics.  We further improve PGrad via bijection-based computational refinement and directional plus length-based calibrations. Our theoretical proof connects PGrad to the spectral analysis of Hessian in training neural networks. Experiments on DomainBed and WILDS benchmarks demonstrate that our approach effectively enables robust DG optimization and leads to smoothly decreased loss curves.  Empirically, PGrad achieves competitive results across seven datasets, demonstrating its efficacy across both synthetic and real-world distributional shifts.",https://openreview.net/pdf/3624aed42e1bd899a25cf9a4c59dd981a3281799.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=CcXTudu9bvu,DELTA: Diverse Client Sampling for Fasting Federated Learning,"['Lin Wang', 'Yongxin Guo', 'Tao Lin', 'Xiaoying Tang']","['~Lin_Wang14', '~Yongxin_Guo1', '~Tao_Lin1', '~Xiaoying_Tang2']","['federated learning', 'client sampling']","Partial client participation has been widely adopted in Federated Learning (FL) to efficiently reduce the communication burden. However, an improper client sampling scheme will select unrepresentative subsets, which will cause a large variance in the model update and slows down the convergence. Existing sampling methods are either biased or can be further improved to accelerate the convergence. In this paper, we propose an unbiased sampling scheme, termed DELTA, to alleviate this problem. In particular, DELTA characterizes the impact of client diversity and local variance and samples the representative clients who carry valuable information for global model updates. Moreover, DELTA is a provably optimal unbiased sampling scheme that minimizes the variance caused by partial client participation and achieves better convergence than other unbiased sampling schemes. We corroborate our results with experiments on both synthetic and real data sets.",https://openreview.net/pdf/cd9451c5dbdec976074c7253d011835e70ceec1e.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=COZDy0WYGg,Hungry Hungry Hippos: Towards Language Modeling with State Space Models,"['Daniel Y Fu', 'Tri Dao', 'Khaled Kamal Saab', 'Armin W Thomas', 'Atri Rudra', 'Christopher Re']","['~Daniel_Y_Fu1', '~Tri_Dao1', '~Khaled_Kamal_Saab1', '~Armin_W_Thomas1', '~Atri_Rudra1', '~Christopher_Re1']","['language modeling', 'state space models', 'efficiency']","State space models (SSMs) have demonstrated state-of-the-art sequence modeling performance in some modalities, but underperform attention in language modeling. Moreover, despite scaling nearly linearly in sequence length instead of quadratically, SSMs are still slower than Transformers due to poor hardware utilization. In this paper, we make progress on understanding the expressivity gap between SSMs and attention in language modeling, and on reducing the hardware barrier between SSMs and attention. First, we use synthetic language modeling tasks to understand the gap between SSMs and attention. We find that existing SSMs struggle with two capabilities: recalling earlier tokens in the sequence and comparing tokens across the sequence. To understand the impact on language modeling, we propose a new SSM layer, H3, that is explicitly designed for these abilities. H3 matches attention on the synthetic languages and comes within 0.4 PPL of Transformers on OpenWebText. Furthermore, a hybrid 125M-parameter H3-attention model that retains two attention layers surprisingly outperforms Transformers on OpenWebText by 1.0 PPL. Next, to improve the efficiency of training SSMs on modern hardware, we propose FlashConv. FlashConv uses a fused block FFT algorithm to improve efficiency on sequences up to 8K, and introduces a novel state passing algorithm that exploits the recurrent properties of SSMs to scale to longer sequences. FlashConv yields 2$\times$ speedup on the long-range arena benchmark and allows hybrid language models to generate text 2.4$\times$ faster than Transformers. Using FlashConv, we scale hybrid H3-attention language models up to 2.7B parameters on the Pile and find promising initial results, achieving lower perplexity than Transformers and outperforming Transformers in zero- and few-shot learning on a majority of tasks in the SuperGLUE benchmark.",https://openreview.net/pdf/b3774a7e6b7bda0783528bf1dc8e2600707d797f.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=CJl2S0w1mbq,A UNIFIED VIEW OF FINDING AND TRANSFORMING WINNING LOTTERY TICKETS,"['Kun Wang', 'Yuxuan Liang', 'Pengkun Wang', 'Pengfei Gu', 'Zhengyang Zhou', 'Chao Huang', 'Yang Wang']","['~Kun_Wang15', '~Yuxuan_Liang1', '~Pengkun_Wang1', '~Pengfei_Gu1', '~Zhengyang_Zhou1', '~Chao_Huang7', '~Yang_Wang32']","['Lottery Tickets Hypothesis', 'Dual Lottery Tickets Hypothesis', 'Non-linear increased regularization', 'early stopping']","While over-parameterized deep neural networks obtain prominent results on various machine learning tasks, their superfluous parameters usually make model training and inference notoriously inefficient. Lottery Ticket Hypothesis (LTH) addresses this issue from a novel perspective: it articulates that there always exist sparse and admirable subnetworks in a randomly initialized dense network, which can be realized by an iterative pruning strategy. Dual Lottery Ticket Hypothesis (DLTH) further investigates sparse network training from a complementary view. Concretely, it introduces a gradually increased regularization term to transform a dense network to an ultra-light subnetwork without sacrificing learning capacity. After revisiting the success of LTH and DLTH, we unify these two research lines by coupling the stability of iterative pruning and the excellent performance of increased regularization, resulting in two new algorithms (UniLTH and UniDLTH) for finding and transforming winning tickets, respectively. Unlike either LTH without regularization or DLTH which applies regularization across the training, our methods first train the network without any regularization force until the model reaches a certain point (i.e., the validation loss does not decrease for several epochs), and then employ increased regularization for information extrusion and iteratively perform magnitude pruning till the end. We theoretically prove that the early stopping mechanism acts analogously as regularization and can help the optimization trajectory stop at a particularly better point in space than regularization. This not only prevent the parameters from being excessively skewed to the training distribution (over-fitting), but also better stimulate the network potential to obtain more powerful subnetworks. Extensive experiments are conducted to show the superiority of our methods in terms of accuracy and sparsity. ",https://openreview.net/pdf/bcd1bd832e5b83da08fcab57c4b9be71415ce9ea.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=CGBCTp2M6lA,Leveraging Future Relationship Reasoning for Vehicle Trajectory Prediction,"['Daehee Park', 'Hobin Ryu', 'Yunseo Yang', 'Jegyeong Cho', 'Jiwon Kim', 'Kuk-Jin Yoon']","['~Daehee_Park1', '~Hobin_Ryu2', '~Yunseo_Yang1', '~Jegyeong_Cho1', '~Jiwon_Kim8', '~Kuk-Jin_Yoon1']","['Trajectory prediction', 'Autonomous driving', 'Neural relation inference', 'Stochasticity modeling', 'Multimodal prediction']","Understanding the interaction between multiple agents is crucial for realistic vehicle trajectory prediction. 
Existing methods have attempted to infer the interaction from the observed past trajectories of agents using pooling, attention, or graph-based methods, which rely on a deterministic approach. 
However, these methods can fail under complex road structures, as they cannot predict various interactions that may occur in the future. 
In this paper, we propose a novel approach that uses lane information to predict a stochastic future relationship among agents. 
To obtain a coarse future motion of agents, our method first predicts the probability of lane-level waypoint occupancy of vehicles. 
We then utilize the temporal probability of passing adjacent lanes for each agent pair, assuming that agents passing adjacent lanes will highly interact. 
We also model the interaction using a probabilistic distribution, which allows for multiple possible future interactions. 
The distribution is learned from the posterior distribution of interaction obtained from ground truth future trajectories. 
We validate our method on popular trajectory prediction datasets: nuScenes and Argoverse. 
The results show that the proposed method brings remarkable performance gain in prediction accuracy, and achieves state-of-the-art performance in long-term prediction benchmark dataset.",https://openreview.net/pdf/26afa69e0c70599af069b4e1fd67c5256d02890a.pdf,{'title_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=CBfYffLqWqb,Evolving Populations of Diverse RL Agents with MAP-Elites,"['Thomas PIERROT', 'Arthur Flajolet']","['~Thomas_PIERROT1', '~Arthur_Flajolet2']",[],"Quality Diversity (QD) has emerged as a powerful alternative optimization paradigm that aims at generating large and diverse collections of solutions, notably with its flagship algorithm MAP-ELITES (ME) which evolves solutions through mutations and crossovers. While very effective for some unstructured problems, early ME implementations relied exclusively on random search to evolve the population of solutions, rendering them notoriously sample-inefficient for high-dimensional problems, such as when evolving neural networks. Follow-up works considered exploiting gradient information to guide the search in order to address these shortcomings through techniques borrowed from either Black-Box Optimization (BBO) or Reinforcement Learning (RL). While mixing RL techniques with ME unlocked state-of-the-art performance for robotics control problems that require a good amount of exploration, it also plagued these ME variants with limitations common among RL algorithms that ME was free of, such as hyperparameter sensitivity, high stochasticity as well as training instability, including when the population size increases as some components are shared across the population in recent approaches. Furthermore, existing approaches mixing ME with RL tend to be tied to a specific RL algorithm, which effectively prevents their use on problems where the corresponding RL algorithm fails. To address these shortcomings, we introduce a flexible framework that allows the use of any RL algorithm and alleviates the aforementioned limitations by evolving populations of agents (whose definition include hyperparameters and all learnable parameters) instead of just policies. We demonstrate the benefits brought about by our framework through extensive numerical experiments on a number of robotics control problems, some of which with deceptive rewards, taken from the QD-RL literature. We open source an efficient JAX-based implementation of our algorithm in the QDax library. ",https://openreview.net/pdf/7647093a5e985828f881513eb78bf7d36bde7a04.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=C9uEwyfklBE,Pareto Manifold Learning: Tackling multiple tasks via ensembles of single-task models,"['Nikolaos Dimitriadis', 'Pascal Frossard', 'François Fleuret']","['~Nikolaos_Dimitriadis1', '~Pascal_Frossard1', '~François_Fleuret2']","['Multi-Task Learning', 'multitask learning', 'mode connectivity', 'loss landscape', 'pareto optimal', 'pareto frontier']","In Multi-Task Learning, tasks may compete and limit the performance achieved on each other rather than guiding the optimization trajectory to a common solution, superior to its single-task counterparts. There is often not a single solution that is optimal for all tasks, leading practitioners to balance tradeoffs between tasks' performance, and to resort to optimality in the Pareto sense. Current Multi-Task Learning methodologies either completely neglect this aspect of functional diversity, and produce one solution in the Pareto Front predefined by their optimization schemes, or produce diverse but discrete solutions, each requiring a separate training run. In this paper, we conjecture that there exist Pareto Subspaces, i.e., weight subspaces where multiple optimal functional solutions lie. We propose Pareto Manifold Learning, an ensembling method in weight space that is able to discover such a parameterization and produces a continuous Pareto Front in a single training run, allowing practitioners to modulate the performance on each task during inference on the fly. We validate the proposed method on a diverse set of multi-task learning benchmarks, ranging from image classification to tabular datasets and scene understanding, and show that Pareto Manifold Learning outperforms state-of-the-art algorithms.
",https://openreview.net/pdf/79fc1069d1fe37ce839928e691c8f281db7c7fb9.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=C8by2OoY6Y2,Zero-Shot Retrieval with Search Agents and Hybrid Environments,"['Michelle Chen Huebscher', 'Christian Buck', 'Massimiliano Ciaramita', 'Sascha Rothe']","['~Michelle_Chen_Huebscher1', '~Christian_Buck1', '~Massimiliano_Ciaramita2', '~Sascha_Rothe1']","['learning to search', 'information retrieval', 'document ranking', 'relevance feedback', 'zero shot', 'language models', 'behavioral cloning']","Learning to search is the task of building artificial agents that learn to autonomously use a search box to find information. So far, it has been shown that current language models can learn symbolic query reformulation policies, in combination with traditional term-based retrieval, but fall short of outperforming neural retrievers. We extend the previous learning to search setup to a hybrid environment, which accepts discrete query refinement operations, after a first-pass retrieval step performed by a dual encoder. Experiments on the BEIR task show that search agents, trained via behavioral cloning, outperform the underlying search system based on a combined dual encoder retriever and cross encoder reranker. Furthermore, we find that simple heuristic Hybrid Retrieval Environments (HRE) can improve baseline performance by several nDCG points. The search agent based on the HRE environment (HaRE) produces state-of-the-art performance on both zero-shot and in-domain evaluations. We carry out an extensive qualitative analysis to shed light on the agents policies.",https://openreview.net/pdf/762770bc48f41ed202ffb6be40f0058989516d0f.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=C0q9oBc3n4,Temporal Dependencies in Feature Importance for Time Series Prediction,"['Kin Kwan Leung', 'Clayton Rooke', 'Jonathan Smith', 'Saba Zuberi', 'Maksims Volkovs']","['~Kin_Kwan_Leung1', '~Clayton_Rooke1', '~Jonathan_Smith2', '~Saba_Zuberi1', '~Maksims_Volkovs3']","['time series', 'recurrent', 'explainability']","Time series data introduces two key challenges for explainability methods: firstly, observations of the same feature over subsequent time steps are not independent, and secondly, the same feature can have varying importance to model predictions over time. In this paper, we propose Windowed Feature Importance in Time (WinIT), a feature removal based explainability approach to address these issues. Unlike existing feature removal explanation methods, WinIT explicitly accounts for the temporal dependence between different observations of the same feature in the construction of its importance score. Furthermore, WinIT captures the varying importance of a feature over time, by summarizing its importance over a window of past time steps. We conduct an extensive empirical study on synthetic and real-world data, compare against a wide range of leading explainability methods, and explore the impact of various evaluation strategies. Our results show that WinIT achieves significant gains over existing methods, with more consistent performance across different evaluation metrics.",https://openreview.net/pdf/0f72b3a91d343251112a9846581eefec130b00b6.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=C-xa_D3oTj6,DEP-RL: Embodied Exploration for Reinforcement Learning in Overactuated and Musculoskeletal Systems,"['Pierre Schumacher', 'Daniel Haeufle', 'Dieter Büchler', 'Syn Schmitt', 'Georg Martius']","['~Pierre_Schumacher1', '~Daniel_Haeufle1', '~Dieter_Büchler1', '~Syn_Schmitt1', '~Georg_Martius1']","['reinforcement learning', 'musculoskeletal', 'correlated exploration']","Muscle-actuated organisms are capable of learning an unparalleled diversity of dexterous movements despite their vast amount of muscles. 
Reinforcement learning (RL) on large musculoskeletal models, however, has not been able to show similar performance.  
We conjecture that ineffective exploration in large overactuated action spaces is a key problem.
This is supported by the finding that common exploration noise strategies are inadequate in synthetic examples of overactuated systems. 
We identify differential extrinsic plasticity (DEP), a method from the domain of self-organization, as being able to induce state-space covering exploration within seconds of interaction. 
By integrating DEP into RL, we achieve fast learning of reaching and locomotion in musculoskeletal systems, outperforming current approaches in all considered tasks in sample efficiency and robustness.",https://openreview.net/pdf/e3ebc4afb3c3051ac2670b1f21a54881897fe728.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Bq1-IOPKet,Optimal Transport-Based Supervised Graph Summarization,"['Sepideh Neshatfar', 'Abram Magner', 'Salimeh Yasaei Sekeh']","['~Sepideh_Neshatfar1', '~Abram_Magner1', '~Salimeh_Yasaei_Sekeh1']","['Graph Summarization', 'Optimal Transport', 'Supervised Learning', 'Mutual Information']","Graph summarization is the problem of producing smaller graph representations of an input graph dataset, in such a way that
  the smaller ``compressed'' graphs capture relevant structural information for downstream tasks.  One graph summarization
  method, recently proposed in Garg & Jaakkola (2019), formulates an optimal transport-based framework that allows prior information
  about node, edge, and attribute importance to be incorporated into the graph summarization process. We extend the optimal transport framework to a supervised graph summarization setting, wherein we seek to preserve relevant information about a class label.  We first formulate the problem in terms of maximizing the mutual information between the summarized graph and the class label.  We then propose a method that incorporates mutual information estimates between random variables associated with sample graphs and class labels into
  the optimal transport compression framework from Garg & Jaakkola (2019).  We empirically show performance improvements over the previous work by Garg & Jaakkola (2019), in terms of classification and compression on synthetic and real datasets.  We then theoretically show limitations of the optimal transport approach: e.g., that it fails to satisfy a certain desirable information monotonicity property.  ",https://openreview.net/pdf/c862f73b59ac7901d308f37d0e938a9e4d7ddaf6.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=Bo7eeXm6An8,Multi-lingual Evaluation of Code Generation Models,"['Ben Athiwaratkun', 'Sanjay Krishna Gouda', 'Zijian Wang', 'Xiaopeng Li', 'Yuchen Tian', 'Ming Tan', 'Wasi Uddin Ahmad', 'Shiqi Wang', 'Qing Sun', 'Mingyue Shang', 'Sujan Kumar Gonugondla', 'Hantian Ding', 'Varun Kumar', 'Nathan Fulton', 'Arash Farahani', 'Siddhartha Jain', 'Robert Giaquinto', 'Haifeng Qian', 'Murali Krishna Ramanathan', 'Ramesh Nallapati', 'Baishakhi Ray', 'Parminder Bhatia', 'Sudipta Sengupta', 'Dan Roth', 'Bing Xiang']","['~Ben_Athiwaratkun1', '~Sanjay_Krishna_Gouda1', '~Zijian_Wang1', '~Xiaopeng_Li1', 'tiayuche@amazon.com', '~Ming_Tan2', '~Wasi_Uddin_Ahmad1', '~Shiqi_Wang2', '~Qing_Sun2', '~Mingyue_Shang1', '~Sujan_Kumar_Gonugondla1', '~Hantian_Ding1', '~Varun_Kumar3', '~Nathan_Fulton2', '~Arash_Farahani1', '~Siddhartha_Jain1', '~Robert_Giaquinto1', '~Haifeng_Qian1', '~Murali_Krishna_Ramanathan1', '~Ramesh_Nallapati1', '~Baishakhi_Ray2', '~Parminder_Bhatia1', 'sudipta@amazon.com', '~Dan_Roth3', '~Bing_Xiang2']","['code generation', 'execution-based evaluation', 'test-based evaluation', 'language models', 'multi-lingual code generation benchmark', 'code insertion', 'code summarization', 'robustness for code', 'code translation', 'zero-shot code translation', 'multi-lingual', 'mono-lingual', 'language models.']","We present two new benchmarks, MBXP and Multilingual HumanEval, designed to evaluate code completion models in over 10 programming languages. These datasets are generated using a conversion framework that transpiles prompts and test cases from the original MBPP and HumanEval datasets into the corresponding data in the target language. By using these benchmarks, we are able to assess the performance of code generation models in a multi-lingual fashion, and discovered generalization ability of language models on out-of-domain languages, advantages of multi-lingual models over mono-lingual, the ability of  few-shot prompting to teach the model new languages, and zero-shot translation abilities. In addition, we use our code generation model to perform large-scale bootstrapping to obtain synthetic canonical solutions in several languages, which can be used for other code-related evaluations such as code insertion, robustness, or summarization tasks.",https://openreview.net/pdf/c2ba4659e44c45ec67969ec9a74097a37184ad62.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=BgMo9ofIQi6,GENERALIZED MATRIX LOCAL LOW RANK REPRESENTATION BY RANDOM PROJECTION AND SUBMATRIX PROPAGATION,"['Pengtao Dang', 'Wennan Chang', 'Haiqi Zhu', 'Changlin Wan', 'Tong Zhao', 'Tingo Guo', 'Paul Salama', 'Sha Cao', 'Chi Zhang']","['~Pengtao_Dang1', '~Wennan_Chang1', '~Haiqi_Zhu1', '~Changlin_Wan1', '~Tong_Zhao2', 'guoti@iu.edu', '~Paul_Salama1', '~Sha_Cao1', '~Chi_Zhang18']","['Matrix decomposition', 'Local Low Rank matrix detection', 'Representation learning', 'Subspace learning']","Detecting distinct submatrices of low rank property is a highly desirable matrix representation learning technique for the ease of data interpretation, called the matrix local low rank representation (MLLRR). Based on different mathematical assumptions of the local pattern, the MLLRR problem could be categorized into two sub-problems, namely local constant variation (LCV) and local linear low rank (LLR). Existing solutions on MLLRR only focused on the LCV problem, which misses a substantial amount of true and interesting patterns. In this work, we develop a novel matrix computational framework called RPSP (Random Probing based submatrix Propagation) that provides an effective solution for both of the LCV and LLR problems. RPSP detects local low rank patterns that grow from small submatrices of low rank property, which are determined by a random projection approach. RPSP is supported by theories of random projection. Experiments on synthetic data demonstrate that RPSP outperforms all state-of-the-art methods, with the capacity to robustly and correctly identify the low rank matrices under both LCV and LLR settings. On real-world datasets, RPSP also demonstrates its effectiveness in identifying interpretable local low rank matrices.
",https://openreview.net/pdf/b0f398213087ced361c7136cd33800f94b074f47.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=BYWWwSY2G5s,Score-based Continuous-time Discrete Diffusion Models,"['Haoran Sun', 'Lijun Yu', 'Bo Dai', 'Dale Schuurmans', 'Hanjun Dai']","['~Haoran_Sun2', '~Lijun_Yu1', '~Bo_Dai1', '~Dale_Schuurmans1', '~Hanjun_Dai1']","['discrete space diffusion', 'discrete score matching', 'continuous-time diffusion']","Score-based modeling through stochastic differential equations (SDEs) has provided a new perspective on diffusion models, and demonstrated superior performance on continuous data. However, the gradient of the log-likelihood function, \ie, the score function, is not properly defined for discrete spaces. This makes it non-trivial to adapt SDE with score functions to categorical data. In this paper, we extend diffusion models to discrete variables by introducing a stochastic jump process where the reverse process denoises via a continuous-time Markov chain. This formulation admits an analytical simulation during backward sampling. To learn the reverse process, we extend score matching to general categorical data, and show that an unbiased estimator can be obtained via simple matching of the conditional marginal distributions. We demonstrate the effectiveness of the proposed method on a set of synthetic and real-world music and image benchmarks.",https://openreview.net/pdf/d96e90543a3d04a3e6248eacc3088b15b0907078.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=BR_ZhvcYbGJ,Explaining Temporal Graph Models through an Explorer-Navigator Framework,"['Wenwen Xia', 'Mincai Lai', 'Caihua Shan', 'Yao Zhang', 'Xinnan Dai', 'Xiang Li', 'Dongsheng Li']","['~Wenwen_Xia1', '~Mincai_Lai1', '~Caihua_Shan1', '~Yao_Zhang6', '~Xinnan_Dai1', '~Xiang_Li24', '~Dongsheng_Li2']","['graph neural networks', 'gnn explainers', 'temporal graphs']","While GNN explanation has recently received significant attention, existing works are consistently designed for static graphs. Due to the prevalence of temporal graphs, many temporal graph models have been proposed, but explaining their predictions remains to be explored. To bridge the gap, in this paper, we propose T-GNNExplainer for temporal graph model explanation. Specifically, we regard a temporal graph constituted by a sequence of temporal events. Given a target event, our task is to find a subset of previously occurred events that lead to the model's prediction for it. To handle this combinatorial optimization problem, T-GNNExplainer includes an explorer to find the event subsets with Monte Carlo Tree Search (MCTS)  and a navigator that learns the correlations between events and helps reduce the search space. In particular, the navigator is trained in advance and then integrated with the explorer to speed up searching and achieve better results. To the best of our knowledge, T-GNNExplainer is the first explainer tailored for temporal graph models. We conduct extensive experiments to evaluate the performance of T-GNNExplainer. Experimental results on both real-world and synthetic datasets demonstrate that T-GNNExplainer can achieve superior performance with up to about 50% improvement in Area under Fidelity-Sparsity Curve. ",https://openreview.net/pdf/f236c13f60a0bf5c74cb31ee8bd5bf77939d656b.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=BNsuf5g-JRd,Solving Partial Label Learning Problem with Multi-Agent Reinforcement Learning,"['Xinyi Zhang', 'Xingdong Feng', 'Fan Zhou']","['~Xinyi_Zhang5', '~Xingdong_Feng1', '~Fan_Zhou7']",[],"Partial label learning (PLL) deals with classifications when a set of candidate labels instead of the true one is given for each training instance. As a weakly supervised learning problem, the main target of PLL is to discover latent relationships within training samples, and utilize such information to disambiguate noisy labels. Many existing methods choose nearest neighbors of each partially-labeled instance in an unsupervised way such that the obtained instance similarities can be empirically non-optimal and unrelated to the downstream classification task. To address this issue, we propose a novel multi-agent reinforcement learning (MARL) framework which models the connection between each pair of training samples as a reinforcement learning (RL) agent. We use attention-based graph neural network (GNN) to learn the instance similarity, and adaptively refine it using a deterministic policy gradient approach until some pre-defined scoring function is optimized. Different from those two-stage and alternative optimization algorithms whose training procedures are not end-to-end, our RL-based approach directly optimizes the objective function and estimates the instance similarities more precisely. The experimental results show that our method outperforms state-of-the-art competitors with a higher classification accuracy in both synthetic and real examples. ",https://openreview.net/pdf/d7bd458b34d72121a2a6cea8eb5e6af29e8ea8dc.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=BLOkjU9iS24,Constrained Reinforcement Learning for Safety-Critical Tasks via Scenario-Based Programming,"['Davide Corsi', 'Raz Yerushalmi', 'Guy Amir', 'Alessandro Farinelli', 'David Harel', 'Guy Katz']","['~Davide_Corsi1', '~Raz_Yerushalmi1', '~Guy_Amir1', '~Alessandro_Farinelli1', 'david.harel@weizmann.ac.il', '~Guy_Katz1']","['Constrained Reinforcement Learning', 'Scenario Based Programming', 'Safety', 'Robotic Navigation']","Deep reinforcement learning (DRL) has achieved groundbreaking successes in various applications, including robotics. A natural consequence is the adoption of this paradigm for safety-critical tasks, where human safety and expensive hardware can be involved. In this context, it is crucial to optimize the performance of DRL-based agents while providing guarantees about their behavior. This paper presents a novel technique for incorporating domain-expert knowledge into a constrained DRL training loop. Our technique exploits the scenario-based programming paradigm, designed to specify such knowledge in a simple and intuitive way. While our approach can be considered general purpose, we validated our method by performing experiments on a synthetic set of benchmark environments, and the popular robotic mapless navigation problem, in simulation and on the actual platform. Our results demonstrate that using our approach to leverage expert knowledge dramatically improves the safety and performance of the agent.",https://openreview.net/pdf/037db8a93436a735e5b8586baefc2e78a15985e7.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=B4maZQLLW0_,Stateful Active Facilitator: Coordination and Environmental Heterogeneity in Cooperative Multi-Agent Reinforcement Learning,"['Dianbo Liu', 'Vedant Shah', 'Oussama Boussif', 'Cristian Meo', 'Anirudh Goyal', 'Tianmin Shu', 'Michael Curtis Mozer', 'Nicolas Heess', 'Yoshua Bengio']","['~Dianbo_Liu2', '~Vedant_Shah2', '~Oussama_Boussif1', 'c.meo@tudelft.nl', '~Anirudh_Goyal1', '~Tianmin_Shu1', '~Michael_Curtis_Mozer1', '~Nicolas_Heess1', '~Yoshua_Bengio1']",[],"In cooperative multi-agent reinforcement learning, a team of agents works together
to achieve a common goal. Different environments or tasks may require varying
degrees of coordination among agents in order to achieve the goal in an optimal
way. The nature of coordination will depend on properties of the environment—its
spatial layout, distribution of obstacles, dynamics, etc. We term this variation
of properties within an environment as heterogeneity. Existing literature has not
sufficiently addressed the fact that different environments may have different levels
of heterogeneity. We formalize the notions of coordination level and heterogeneity
level of an environment and present HECOGrid, a suite of multi-agent RL
environments that facilitates empirical evaluation of different MARL approaches
across different levels of coordination and environmental heterogeneity by providing
a quantitative control over coordination and heterogeneity levels of the
environment. Further, we propose a Centralized Training Decentralized Execution
learning approach called Stateful Active Facilitator (SAF) that enables agents to
work efficiently in high-coordination and high-heterogeneity environments through
a differentiable and shared knowledge source used during training and dynamic
selection from a shared pool of policies. We evaluate SAF and compare its performance
against baselines IPPO and MAPPO on HECOGrid. Our results show
that SAF consistently outperforms the baselines across different tasks and different
heterogeneity and coordination levels.",https://openreview.net/pdf/e91b82d1a670376c4dd37b3ff6ed712eff719b12.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=B-z41MBL_tH,Causal Imitation Learning via Inverse Reinforcement Learning,"['Kangrui Ruan', 'Junzhe Zhang', 'Xuan Di', 'Elias Bareinboim']","['~Kangrui_Ruan1', '~Junzhe_Zhang3', '~Xuan_Di1', '~Elias_Bareinboim2']","['Causal Inference', 'Graphical Models']","One of the most common ways children learn when unfamiliar with the environment is by mimicking adults. Imitation learning concerns an imitator learning to behave in an unknown environment from an expert's demonstration; reward signals remain latent to the imitator. This paper studies imitation learning through causal lenses and extends the analysis and tools developed for behavior cloning (Zhang, Kumor, Bareinboim, 2020) to inverse reinforcement learning. First, we propose novel graphical conditions that allow the imitator to learn a policy performing as well as the expert's behavior policy, even when the imitator and the expert's state-action space disagree, and unobserved confounders (UCs) are present. When provided with parametric knowledge about the unknown reward function, such a policy may outperform the expert's. Also, our method is easily extensible and allows one to leverage existing IRL algorithms even when UCs are present, including the multiplicative-weights algorithm (MWAL) (Syed & Schapire, 2008) and the generative adversarial imitation learning (GAIL) (Ho & Ermon, 2016). Finally, we validate our framework by simulations using real-world and synthetic data.",https://openreview.net/pdf/2d0bee07a9f373073524d04d2dae5fab301d34be.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=B-dM7df9Axo,Learning PDE Solution Operator for Continuous Modeling of Time-Series,"['Yesom Park', 'Jaemoo Choi', 'Changyeon Yoon', 'Chang hoon Song', 'Myungjoo Kang']","['~Yesom_Park1', '~Jaemoo_Choi1', '~Changyeon_Yoon1', '~Chang_hoon_Song1', '~Myungjoo_Kang1']","['Neural ODEs', 'Partial differential equations', 'Neural operators', 'Time-series']","Learning underlying dynamics from data is important and challenging in many real-world scenarios. Incorporating differential equations (DEs) to design continuous networks has drawn much attention recently, the most prominent of which is Neural ODE. Most prior works make specific assumptions on the type of DEs or restrict them to first or second-order DEs, making the model specialized for certain problems. Furthermore, due to the use of numerical integration, they suffer from computational expensiveness and numerical instability. Building upon recent Fourier neural operator (FNO), this work proposes a partial differential equation (PDE) based framework which improves the dynamics modeling capability and circumvents the need for costly numerical integration. FNO is hard to be directly applied to real applications because it is mainly confined to physical PDE problems. To fill this void, we propose a continuous-in-time FNO to deal with irregularly-sampled time series and provide a theoretical result demonstrating its universality. Moreover, we reveal an intrinsic property of PDEs that increases the stability of the model. Several numerical evidence shows that our method represents a broader range of problems, including synthetic, image classification, and irregular time-series. Our framework opens up a new way for a continuous representation of neural networks that can be readily adopted for real-world applications.",https://openreview.net/pdf/1875ce999b29a2f8ac87318e95b36e4fe1e5a792.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=AuEgNlEAmed,A theoretical study of inductive biases in contrastive learning,"['Jeff Z. HaoChen', 'Tengyu Ma']","['~Jeff_Z._HaoChen1', '~Tengyu_Ma1']","['theory of self-supervised learning', 'theory of contrastive learning']","Understanding self-supervised learning is important but challenging. Previous theoretical works study the role of pretraining losses, and view neural networks as general black boxes. However, the recent work of [Saunshi et al.] argues that the model architecture --- a component largely ignored by previous works --- also has significant influences on the downstream performance of self-supervised learning. In this work, we provide the first theoretical analysis of self-supervised learning that incorporates the effect of inductive biases originating from the model class. In particular, we focus on contrastive learning --- a popular self-supervised learning method that is widely used in the vision domain. We show that when the model has limited capacity, contrastive representations would recover certain special clustering structures that are compatible with the model architecture, but ignore many other clustering structures in the data distribution. As a result, our theory can capture the more realistic setting where contrastive representations have much lower dimensionality than the number of clusters in the data distribution. We instantiate our theory on several synthetic data distributions, and provide empirical evidence to support the theory.",https://openreview.net/pdf/c0e1dd5361d9fbb78aee85364df2ab49854653b4.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=AjC0KBjiMu,Contrastive Learning Can Find An Optimal Basis For Approximately View-Invariant Functions,"['Daniel D. Johnson', 'Ayoub El Hanchi', 'Chris J. Maddison']","['~Daniel_D._Johnson1', '~Ayoub_El_Hanchi1', '~Chris_J._Maddison1']","['contrastive learning', 'self-supervised learning', 'representation learning', 'kernel', 'kernel PCA', 'positive definite', 'eigenfunction', 'spectral clustering', 'invariance', 'Markov chain', 'minimax optimal']","Contrastive learning is a powerful framework for learning self-supervised representations that generalize well to downstream supervised tasks. We show that multiple existing contrastive learning methods can be reinterpeted as learning kernel functions that approximate a fixed *positive-pair kernel*. We then prove that a simple representation obtained by combining this kernel with PCA provably minimizes the worst-case approximation error of linear predictors, under a straightforward assumption that positive pairs have similar labels. Our analysis is based on a decomposition of the target function in terms of the eigenfunctions of a positive-pair Markov chain, and a surprising equivalence between these eigenfunctions and the output of Kernel PCA. We give generalization bounds for downstream linear prediction using our kernel PCA representation, and show empirically on a set of synthetic tasks that applying kernel PCA to contrastive learning models can indeed approximately recover the Markov chain eigenfunctions, although the accuracy depends on the kernel parameterization as well as on the augmentation strength.",https://openreview.net/pdf/470d0d377fbd21359685cd8abe602339d5f71751.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=AP0iZoaRaS,Interactive Portrait Harmonization,"['Jeya Maria Jose Valanarasu', 'HE Zhang', 'Jianming Zhang', 'Yilin Wang', 'Zhe Lin', 'Jose Echevarria', 'Yinglan Ma', 'Zijun Wei', 'Kalyan Sunkavalli', 'Vishal Patel']","['~Jeya_Maria_Jose_Valanarasu1', '~HE_Zhang2', '~Jianming_Zhang1', '~Yilin_Wang4', '~Zhe_Lin1', '~Jose_Echevarria1', 'yingma@adobe.com', '~Zijun_Wei2', '~Kalyan_Sunkavalli1', '~Vishal_Patel2']","['harmonization', 'image editing', 'low-level vision']","Current image harmonization methods consider the entire background as the guidance for harmonization. However, this may limit the capability for user to choose any specific object/person in the background to guide the harmonization. To enable flexible interaction between user and harmonization, we introduce interactive harmonization, a new setting where the harmonization is performed with respect to a selected region in the reference image instead of the entire background. A new flexible framework that allows users to pick certain regions of the background image and use it to guide the harmonization is proposed. Inspired by professional portrait harmonization users, we also introduce a new luminance matching loss to optimally match the color/luminance conditions between the composite foreground and select reference region. This framework provides more control to the image harmonization pipeline achieving visually pleasing portrait edits. Furthermore, we also introduce a new dataset carefully curated for validating portrait harmonization. Extensive experiments on both synthetic and real-world datasets show that the proposed approach is efficient and robust compared to previous harmonization baselines, especially for portraits.",https://openreview.net/pdf/8fecedc380fae9d1025815dc9e8f0bdac4616474.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=AGLG_ncNp0X,Personalized Federated Hypernetworks for Privacy Preservation in Multi-Task Reinforcement Learning,"['Doseok Jang', 'Larry Yan', 'Lucas Spangher', 'Selvaprabu Nadarajah', 'Costas Spanos']","['~Doseok_Jang1', 'yanlarry@berkeley.edu', '~Lucas_Spangher1', '~Selvaprabu_Nadarajah1', '~Costas_Spanos1']","['microgrid clusters', 'energy demand response', 'transactive energy control', 'neural networks', 'multi-agent reinforcement learning', 'reinforcement learning', 'multi-task learning', 'transfer learning', 'hypernetworks', 'federated learning', 'personalized federated learning', 'microgrids']","Multi-Agent Reinforcement Learning currently focuses on implementations where all data and training can be centralized to one machine. But what if local agents are split across multiple tasks, and need to keep data private between each? We develop the first application of Personalized Federated Hypernetworks (PFH) to Reinforcement Learning (RL). We then present a novel application of PFH to few-shot transfer, and demonstrate significant initial increases in learning. PFH has never been demonstrated beyond supervised learning benchmarks, so we apply PFH to an important domain: RL price-setting for energy demand response. We consider a general case across where agents are split across multiple microgrids, wherein energy consumption data must be kept private within each microgrid. Together, our work explores how the fields of personalized federated learning and RL can come together to make learning efficient across multiple tasks while keeping data secure.",https://openreview.net/pdf/4b9fd7dcf31573a4c496b1dca9451051ca9aae7d.pdf,{'abstract_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=A09CypdRq8D,Partial Advantage Estimator for Proximal Policy Optimization,"['Xiulei Song', 'Yizhao Jin', 'Gregory Slabaugh', 'Simon Lucas']","['~Xiulei_Song2', '~Yizhao_Jin1', '~Gregory_Slabaugh2', '~Simon_Lucas1']","['Reinforcement learning', 'value estimator']","Estimation of value in policy gradient methods is a fundamental problem. Generalized Advantage Estimation (GAE) is an exponentially-weighted estimator of an advantage function similar to TD($\lambda$). It substantially reduces the variance of policy gradient estimates at the expense of bias. In practical applications, a truncated GAE is used due to the incompleteness of the trajectory, which results in a large bias during estimation. To address this challenge, instead of using the all truncated GAE, we propose to take a part of the calculated GAE for updates, which significantly reduces the bias due to the incomplete trajectory.  We perform experiments in MuJoCo and $\mu$RTS to investigate the effect of different partial coefficient and sampling lengths. We show that our partial GAE approach yields better empirical results in both environments.",https://openreview.net/pdf/c28b221c8c849bf17d74b8eea6ea662ca5d48596.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=9bVBH1GD5sr,FOCUS: Fairness via Agent-Awareness for Federated Learning on Heterogeneous Data,"['Wenda Chu', 'Chulin Xie', 'Boxin Wang', 'Linyi Li', 'Lang Yin', 'Han Zhao', 'Bo Li']","['~Wenda_Chu1', '~Chulin_Xie1', '~Boxin_Wang1', '~Linyi_Li1', '~Lang_Yin1', '~Han_Zhao1', '~Bo_Li19']","['federated learning', 'fairness', 'data heterogeneity', 'clustering', 'expectation–maximization (EM)']","Federated learning (FL) provides an effective collaborative training paradigm, allowing local agents to train a global model jointly without sharing their local data to protect privacy.
On the other hand, due to the heterogeneous nature of local agents, it is challenging to optimize or even define the fairness for agents, which may discourage valuable participation. For instance, the trained global model may sacrifice the performance of a minority user with high-quality data based on loss optimization over all users.
Existing work usually considers accuracy equity as fairness for different users in FL, which is limited especially under the heterogeneous setting, since it is intuitively ""unfair"" that agents with low-quality data would achieve similar accuracy.
In this work, we aim to address such limitations and propose a formal fairness definition in FL, fairness via agent-awareness (FAA), which takes the heterogeneous data contributions of local agents into account. In addition, we propose a fair FL training algorithm based on agent clustering (FOCUS) to achieve FAA. Theoretically, we prove the convergence and optimality of  FOCUS under mild conditions for linear and general convex loss functions with bounded smoothness. We also prove that FOCUS always achieves higher fairness measured by FAA compared with standard FedAvg protocol under both linear and general convex loss functions. Empirically, we evaluate FOCUS on four datasets, including synthetic data, images, and texts under different settings, and we show that FOCUS achieves significantly higher fairness based on FAA while maintaining similar or even higher prediction accuracy compared with FedAvg and other existing fair FL algorithms.
",https://openreview.net/pdf/efce74618927c1b658562643f202ee2c472d2056.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=9Y0P3YoERSy,The GANfather: Controllable generation of malicious activity to expose detection weaknesses and improve defence systems.,"['Ricardo Ribeiro Pereira', 'Jacopo Bono', 'João Tiago Ascensão', 'David Oliveira Aparicio', 'Pedro Manuel Pinto Ribeiro', 'Pedro Bizarro']","['~Ricardo_Ribeiro_Pereira1', '~Jacopo_Bono1', '~João_Tiago_Ascensão1', '~David_Oliveira_Aparicio1', '~Pedro_Manuel_Pinto_Ribeiro1', '~Pedro_Bizarro1']",[],"Criminal activities are typically adversarial in nature, where an attacker and a defence system are constantly adapting to each other's behaviour. If the defence systems are helped by automated detection methods, then those methods need to be updated frequently. In practice, this means that the defence systems are always one step behind the attackers. For example, in anti-money laundering systems, new labels representing suspicious activity are frequently delayed by weeks or months and some money laundering activity may never be found, leading to detection systems that are inaccurate and resulting in an estimated undetected €0.7-3 trillion being laundered annually.

To tackle the problem of missing or delayed labels in adversarial settings, we propose The GANfather, an adversarial and label-free method to both (1) generate a variety of meaningful attacks, as guided by a custom, user-defined objective function; and (2) train a defence system to detect such attacks. Optionally, we can ensure that the generated attacks escape an existing detection system, revealing current weaknesses which the new defence system actively corrects. Our method is inspired by generative adversarial networks (GANs), but unlike GANs we nudge our generator to produce out-of-distribution data using a loss function that characterises criminal activity. Importantly, our method does not require any labelled examples.

We test our framework in two real-world use-cases, namely injection attacks in recommendation systems and anti-money laundering. In the former, we show how an injection attack with a limited number of generated fake profiles is sufficient to successfully recommend an item to a large number of users. These generated injection attacks are more effective in recommending the target item than naive ‘bombing’ strategies and harder to detect. In the latter, the generated attacks are able to simulate money laundering and move cumulative amounts close to 250 thousand dollars through a network of accounts without being detected by existing systems. We also show how we can train a new defence system that captures all these synthetic attacks, potentially saving millions of dollars in detected criminal activity. Our method is generic and applicable in a variety of adversarial domains, exposing current liabilities with the generated data and strengthening the defence systems against current and future malicious attacks.",https://openreview.net/pdf/42bc64d5cad694bdc4905e3b0483c583e339edab.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=9WdB5yVICCA,CausalAgents: A Robustness Benchmark for Motion Forecasting Using Causal Relationships,"['Rebecca Roelofs', 'Liting Sun', 'Benjamin Caine', 'Khaled S. Refaat', 'Benjamin Sapp', 'Scott Ettinger', 'Wei Chai']","['~Rebecca_Roelofs1', '~Liting_Sun1', '~Benjamin_Caine1', '~Khaled_S._Refaat1', '~Benjamin_Sapp3', '~Scott_Ettinger1', 'chaiwei@google.com']","['robustness', 'motion forecasting', 'self-driving cars']","As machine learning models become increasingly prevalent in motion forecasting systems for autonomous vehicles (AVs), it is critical that we ensure that model predictions are safe and reliable. However, exhaustively collecting and labeling the data necessary to fully test the long tail of rare and challenging scenarios is difficult and expensive. In this work, we construct a new benchmark for evaluating and improving model robustness by applying perturbations to existing data. Specifically, we conduct an extensive labeling effort to identify causal agents, or agents whose presence influences human driver behavior in any way, in the Waymo Open Motion Dataset (WOMD), and we use these labels to perturb the data by deleting non-causal agents from the scene. We then evaluate a diverse set of state-of-the-art deep-learning model architectures on our proposed benchmark and find that all models exhibit large shifts under perturbation. Under non-causal perturbations, we observe a 25-38% relative change in minADE as compared to the original. We then investigate techniques to improve model robustness, including increasing the training dataset size and using targeted data augmentations that drop agents throughout training. We provide the causal agent labels as an additional attribute to WOMD and release the robustness benchmarks to aid the community in building more reliable and safe deep-learning models for motion forecasting. 
",https://openreview.net/pdf/bfb992bb824c13285ca88bca7b97ffe32757c4a3.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=9JjGZsDvHb,Metro: Memory-Enhanced Transformer for Retrosynthetic Planning via Reaction Tree,"['Songtao Liu', 'Zhitao Ying', 'Zuobai Zhang', 'Peilin Zhao', 'Jian Tang', 'Lu Lin', 'Dinghao Wu']","['~Songtao_Liu2', '~Zhitao_Ying1', '~Zuobai_Zhang1', '~Peilin_Zhao2', '~Jian_Tang1', '~Lu_Lin2', '~Dinghao_Wu1']","['Retrosynthetic Planning', 'Transformer', 'Memory Network', 'Reaction Database', 'Reaction tree']","Retrosynthetic planning plays a critical role in drug discovery and organic chemistry. Starting from a target molecule as the root node, it aims to find a complete reaction tree subject to the constraint that all leaf nodes belong to a set of starting materials. The multi-step reactions are crucial because they determine the flow chart in the production of the Organic Chemical Industry. However, existing datasets lack curation of tree-structured multi-step reactions and fail to provide such reaction trees, limiting models' understanding of organic molecule transformations. In this work, we first develop a benchmark curated for the retrosynthetic planning task, which consists of 124,869 reaction trees retrieved from the public USPTO-full dataset. On top of that, we propose Metro: Memory-Enhanced Transformer for RetrOsynthetic planning. Specifically, the dependency among molecules in the reaction tree is captured as context information for multi-step retrosynthesis predictions through transformers with a memory module. Extensive experiments show that Metro dramatically outperforms existing single-step retrosynthesis models by at least 10.7% in top-1 accuracy. The experiments demonstrate the superiority of exploiting context information in the retrosynthetic planning task. Moreover, the proposed model can be directly used for synthetic accessibility analysis, as it is trained on reaction trees with the shortest depths. Our work is the first step towards a brand new formulation for retrosynthetic planning in the aspects of data construction, model design, and evaluation.",https://openreview.net/pdf/ae5a91db6a4c68feea708424f46b7478c93fa89a.pdf,{'title_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=9IlzJa5cAv,DT+GNN: A Fully Explainable Graph Neural Network using Decision Trees,"['Peter Müller', 'Lukas Faber', 'Karolis Martinkus', 'Roger Wattenhofer']","['~Peter_Müller2', '~Lukas_Faber1', '~Karolis_Martinkus1', '~Roger_Wattenhofer1']",[],"We propose a new Decision Tree Graph Neural Network (DT+GNN) architecture for Graph Neural Network (GNN) explanation. Existing post-hoc explanation methods highlight important inputs but fail to reveal how a GNN uses these inputs. In contrast DT+GNN is fully explainable: Humans can inspect and understand the decision making of DT+GNN at every step. DT+GNN internally uses a novel GNN layer that is restricted to categorical state spaces for nodes and messages. After training with gradient descent we can easily distill these layers into decision trees. These trees are further pruned using our newly proposed method to ensure they are small and easy to interpret. DT+GNN can also compute node-level importance scores like the existing explanation methods. We demonstrate on real-world GNN benchmarks that DT+GNN has competitive classification accuracy and computes competitive explanations. Furthermore, we leverage DT+GNN's full explainability to inspect the decision processes in synthetic and real-world datasets with surprising results. We make this inspection accessible through an interactive web tool.",https://openreview.net/pdf/2067637eaa2922f308ff534774c4c36ae465e074.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=9DZKk85Z4zA,Gradient-Guided Importance Sampling for Learning Binary Energy-Based Models,"['Meng Liu', 'Haoran Liu', 'Shuiwang Ji']","['~Meng_Liu3', '~Haoran_Liu1', '~Shuiwang_Ji1']",[],"Learning energy-based models (EBMs) is known to be difficult especially on discrete data where gradient-based learning strategies cannot be applied directly. Although ratio matching is a sound method to learn discrete EBMs, it suffers from expensive computation and excessive memory requirements, thereby resulting in difficulties in learning EBMs on high-dimensional data. Motivated by these limitations, in this study, we propose ratio matching with gradient-guided importance sampling (RMwGGIS). Particularly, we use the gradient of the energy function w.r.t. the discrete data space to approximately construct the provably optimal proposal distribution, which is subsequently used by importance sampling to efficiently estimate the original ratio matching objective. We perform experiments on density modeling over synthetic discrete data, graph generation, and training Ising models to evaluate our proposed method. The experimental results demonstrate that our method can significantly alleviate the limitations of ratio matching, perform more effectively in practice, and scale to high-dimensional problems. Our implementation is available at https://github.com/divelab/RMwGGIS.",https://openreview.net/pdf/5b2f9ad18b0930a16ef891e03d537cc91c0c7e09.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=99RpBVpLiX,Distilling Model Failures as Directions in Latent Space,"['Saachi Jain', 'Hannah Lawrence', 'Ankur Moitra', 'Aleksander Madry']","['~Saachi_Jain1', '~Hannah_Lawrence1', '~Ankur_Moitra1', '~Aleksander_Madry1']","['datasets', 'biases', 'subpopulations']","Existing methods for isolating hard subpopulations and spurious correlations in datasets often require human intervention. This can make these methods labor-intensive and dataset-specific. To address these shortcomings, we present a scalable method for automatically distilling a model's failure modes. Specifically, we harness linear classifiers to identify consistent error patterns, and, in turn, induce a natural representation of these failure modes as directions within the feature space. We demonstrate that this framework allows us to discover and automatically caption challenging subpopulations within the training dataset. Moreover, by combining our framework with off-the-shelf diffusion models, we can generate images that are especially challenging for the analyzed model, and thus can be used to perform synthetic data augmentation that helps remedy the model's failure modes.",https://openreview.net/pdf/c9daa261ea96d95a6dee52da157a59e14333cf07.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=8xuFD1yCoH,TuneUp: A Training Strategy for Improving Generalization of Graph Neural Networks,"['Weihua Hu', 'Kaidi Cao', 'Kexin Huang', 'Edward W Huang', 'Karthik Subbian', 'Jure Leskovec']","['~Weihua_Hu1', '~Kaidi_Cao1', '~Kexin_Huang1', '~Edward_W_Huang1', '~Karthik_Subbian1', '~Jure_Leskovec1']","['Graph Neural Networks', 'Curriculum learning', 'Tail nodes']","Despite many advances in Graph Neural Networks (GNNs), their training strategies simply focus on minimizing a loss over nodes in a graph. However, such simplistic training strategies may be sub-optimal as they neglect that certain nodes are much harder to make accurate predictions on than others. Here we present TuneUp, a curriculum learning strategy for better training GNNs. Crucially, TuneUp trains a GNN in two stages. The first stage aims to produce a strong base GNN. Such base GNNs tend to perform well on head nodes (nodes with large degrees) but less so on tail nodes (nodes with small degrees). So, the second stage of TuneUp specifically focuses on improving prediction on tail nodes. Concretely, TuneUp synthesizes many additional supervised tail node data by dropping edges from head nodes and reusing the supervision on the original head nodes. TuneUp then minimizes the loss over the synthetic tail nodes to finetune the base GNN. TuneUp is a general training strategy that can be used with any GNN architecture and any loss, making TuneUp applicable to a wide range of prediction tasks. Extensive evaluation of TuneUp on two GNN architectures, three types of prediction tasks, and both inductive and transductive settings shows that TuneUp significantly improves the performance of the base GNN on tail nodes, while often even improving the performance on head nodes, which together leads up to 58.5% relative improvement in GNN predictive performance. Moreover, TuneUp significantly outperforms its variants without the two-stage curriculum learning, existing graph data augmentation techniques, as well as other specialized methods for tail nodes.",https://openreview.net/pdf/c1fcb0581242deb2e9ea2725f4b54e66dd444123.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=8sSnD78NqTN,Learning Soft Constraints From Constrained Expert Demonstrations,"['Ashish Gaurav', 'Kasra Rezaee', 'Guiliang Liu', 'Pascal Poupart']","['~Ashish_Gaurav1', '~Kasra_Rezaee1', '~Guiliang_Liu1', '~Pascal_Poupart2']","['inverse reinforcement learning', 'constraint learning']","Inverse reinforcement learning (IRL) methods assume that the expert data is generated by an agent optimizing some reward function. However, in many settings, the agent may optimize a reward function subject to some constraints, where the constraints induce behaviors that may be otherwise difficult to express with just a reward function. We consider the setting where the reward function is given, and the constraints are unknown, and propose a method that is able to recover these constraints satisfactorily from the expert data. While previous work has focused on recovering hard constraints, our method can recover cumulative soft constraints that the agent satisfies on average per episode. In IRL fashion, our method solves this problem by adjusting the constraint function iteratively through a constrained optimization procedure, until the agent behavior matches the expert behavior. We demonstrate our approach on synthetic environments, robotics environments and real world highway driving scenarios.",https://openreview.net/pdf/8fcf77a080574ee36abb6525663524292f7b5217.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=8WTAh0tj2jC,Agent-based Graph Neural Networks,"['Karolis Martinkus', 'Pál András Papp', 'Benedikt Schesch', 'Roger Wattenhofer']","['~Karolis_Martinkus1', '~Pál_András_Papp1', '~Benedikt_Schesch1', '~Roger_Wattenhofer1']","['Graph Neural Networks', 'GNN', 'Graph Classification', 'Expressive Graph Neural Networks', 'Sublinear algorithms']","We present a novel graph neural network we call AgentNet, which is designed specifically for graph-level tasks. AgentNet is inspired by sublinear algorithms, featuring a computational complexity that is independent of the graph size. The architecture of AgentNet differs fundamentally from the architectures of traditional graph neural networks. In AgentNet, some trained \textit{neural agents} intelligently walk the graph, and then collectively decide on the output. We provide an extensive theoretical analysis of AgentNet: We show that the agents can learn to systematically explore their neighborhood and that AgentNet can distinguish some structures that are even indistinguishable by 2-WL. Moreover, AgentNet is able to separate any two graphs which are sufficiently different in terms of subgraphs. We confirm these theoretical results with synthetic experiments on hard-to-distinguish graphs and real-world graph classification tasks. In both cases, we compare favorably not only to standard GNNs but also to computationally more expensive GNN extensions.",https://openreview.net/pdf/a33a54dc51ae12d26281cd196933bb3be33a76f3.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=8U4joMeLRF,Rethinking Self-Supervised Visual Representation Learning in Pre-training for 3D Human Pose and Shape Estimation,"['Hongsuk Choi', 'Hyeongjin Nam', 'Taeryung Lee', 'Gyeongsik Moon', 'Kyoung Mu Lee']","['~Hongsuk_Choi1', 'namhj28@gmail.com', 'trlee94@snu.ac.kr', '~Gyeongsik_Moon1', '~Kyoung_Mu_Lee2']","['pre-training', '3D human pose and shape estimation', 'self-supervised representation learning']","Recently, a few self-supervised representation learning (SSL) methods have outperformed the ImageNet classification pre-training for vision tasks such as object detection. However, its effects on 3D human body pose and shape estimation (3DHPSE) are open to question, whose target is fixed to a unique class, the human, and has an inherent task gap with SSL. We empirically study and analyze the effects of SSL and further compare it with other pre-training alternatives for 3DHPSE. The alternatives are 2D annotation-based pre-training and synthetic data pre-training, which share the motivation of SSL that aims to reduce the labeling cost. They have been widely utilized as a source of weak-supervision or fine-tuning, but have not been remarked as a pre-training source. SSL methods underperform the conventional ImageNet classification pre-training on multiple 3DHPSE benchmarks by 7.7% on average. In contrast, despite a much less amount of pre-training data, the 2D annotation-based pre-training improves accuracy on all benchmarks and shows faster convergence during fine-tuning. Our observations challenge the naive application of the current SSL pre-training to 3DHPSE and relight the value of other data types in the pre-training aspect.",https://openreview.net/pdf/6017994942dfe60d2f4cb69be42afc4cd3675da8.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=8JsaP7j1cL0,Correlative Information Maximization Based Biologically Plausible Neural Networks for Correlated Source Separation,"['Bariscan Bozkurt', 'Ateş İsfendiyaroğlu', 'Cengiz Pehlevan', 'Alper Tunga Erdogan']","['~Bariscan_Bozkurt1', '~Ateş_İsfendiyaroğlu1', '~Cengiz_Pehlevan2', '~Alper_Tunga_Erdogan1']","['Biologically Plausible Neural Networks', 'Blind Correlated Source Separation', 'Correlative Information Maximization']","The brain effortlessly extracts latent causes of stimuli, but how it does this at the network level remains unknown. Most prior attempts at this problem proposed neural networks that implement independent component analysis, which works under the limitation that latent elements are mutually independent. Here, we relax this limitation and propose a biologically plausible neural network that extracts correlated latent sources by exploiting information about their domains. To derive this network, we choose maximum correlative information transfer from inputs to outputs as the separation objective under the constraint that the outputs are restricted to their presumed sets. The online formulation of this optimization problem naturally leads to neural networks with local learning rules. Our framework incorporates infinitely many source domain choices and flexibly models complex latent structures. Choices of simplex or polytopic source domains result in networks with piecewise-linear activation functions. We provide numerical examples to demonstrate the superior correlated source separation capability for both synthetic and natural sources.",https://openreview.net/pdf/ef092df8bb544b27c12e88fa9b2d3dd15abedb01.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=89GT-S49mGd,Function-space regularized Rényi divergences,"['Jeremiah Birrell', 'Yannis Pantazis', 'Paul Dupuis', 'Luc Rey-Bellet', 'Markos Katsoulakis']","['~Jeremiah_Birrell1', '~Yannis_Pantazis1', '~Paul_Dupuis1', '~Luc_Rey-Bellet1', '~Markos_Katsoulakis1']","['Rényi divergence', 'integral probability metrics', 'variational formulas', 'worst-case-regret']","We propose a new family of regularized Rényi divergences parametrized not only by the order $\alpha$ but also by a variational function space. These new objects are defined by taking the infimal convolution of the standard Rényi divergence with the integral probability metric (IPM) associated with the chosen function space. We derive a novel dual variational representation that can be used to construct numerically tractable divergence estimators. This representation avoids risk-sensitive terms and therefore exhibits lower variance, making it well-behaved  when $\alpha>1$; this addresses a notable weakness of prior approaches. We prove several properties of these new divergences, showing that they interpolate between the classical Rényi divergences and IPMs. We also study the $\alpha\to\infty$ limit, which leads to a regularized worst-case-regret and a new variational representation in the classical case. Moreover, we show that the proposed regularized Rényi divergences inherit features from IPMs such as the ability to compare distributions that are not absolutely continuous, e.g., empirical measures and distributions with low-dimensional support. We present numerical results on both synthetic and real datasets, showing the utility of these new divergences in both estimation and GAN training applications; in particular, we demonstrate significantly reduced variance and improved training performance.",https://openreview.net/pdf/2e551aaf5e4f3d5a15272f0f78bcaf860e9cb8bd.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=7tJyBmu9iCj,Neural-based classification rule learning for sequential data,"['Marine Collery', 'Philippe Bonnard', 'François Fages', 'Remy Kusters']","['~Marine_Collery1', 'philippe.bonnard@fr.ibm.com', 'francois.fages@inria.fr', '~Remy_Kusters1']","['classification rule learning', 'binary neural network', 'interpretable AI', 'sequential data']","Discovering interpretable patterns for classification of sequential data is of key importance for a variety of fields, ranging from genomics to fraud detection or more generally interpretable decision-making.
In this paper, we propose a novel differentiable fully interpretable method to discover both local and global patterns (i.e. catching a relative or absolute temporal dependency) for rule-based binary classification.
It consists of a convolutional binary neural network with an interpretable neural filter and a training strategy based on dynamically-enforced sparsity.
We demonstrate the validity and usefulness of the approach on synthetic datasets and on an open-source peptides dataset.
Key to this end-to-end differentiable method is that the expressive patterns used in the rules are learned alongside the rules themselves.",https://openreview.net/pdf/6ccbb01a7fbb6ea6edfc173772ccb005e84f5af1.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=7t3ggLCjl7G,When Do Models Generalize? A Perspective From Data-Algorithm Compatibility,"['Jing Xu', 'Jiaye Teng', 'Yang Yuan', 'Andrew C Yao']","['~Jing_Xu4', '~Jiaye_Teng2', '~Yang_Yuan4', '~Andrew_C_Yao1']","['generalization', 'data-algorithm compatibility', 'early stopping', 'overparameterized linear regression']","One of the major open problems in machine learning is to characterize generalization in the overparameterized regime, where most traditional generalization bounds become inconsistent (Nagarajan and Kolter, 2019). In many scenarios, their failure can be attributed to obscuring the crucial interplay between the training algorithm and the underlying data distribution. To address this issue, we propose a concept named compatibility, which quantitatively characterizes generalization in a both data-relevant and algorithm relevant manner. By considering the entire training trajectory and focusing on early-stopping iterates, compatibility exploits the data and the algorithm information and is therefore a more suitable notion for generalization. We validate this by theoretically studying compatibility under the setting of solving overparameterized linear regression with gradient descent. Specifically, we perform a data-dependent trajectory analysis and derive a sufficient condition for compatibility in such a setting. Our theoretical results demonstrate that in the sense of compatibility, generalization holds with significantly weaker restrictions on the problem instance than the previous last iterate analysis.",https://openreview.net/pdf/c5460ab3b5514c4b20509e754f3bfb2d3effc83f.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=7qyLeRm1e3,Improving Generative Flow Networks with Path Regularization,"['Anh Do', 'Duy Dinh', 'Tan Minh Nguyen', 'Nguyen Duy Khuong', 'Stanley Osher', 'Nhat Ho']","['~Anh_Do1', '~Duy_Dinh1', '~Tan_Minh_Nguyen1', '~Nguyen_Duy_Khuong1', '~Stanley_Osher1', '~Nhat_Ho1']","['generative flow networks', 'path regularization', 'optimal transport']","Generative Flow Networks (GFlowNets) are recently proposed models for learning stochastic policies that generate compositional objects by sequences of actions with the probability proportional to a given reward function. The central problem of GFlowNets is to improve their exploration and generalization. In this work, we propose a novel path regularization method based on optimal transport theory that places prior constraints on the underlying structure of the GFlowNets. The prior is designed to help the GFlowNets better discover the latent structure of the target distribution or enhance its ability to explore the environment in the context of active learning. The path regularization controls the flow in GFlowNets to generate more diverse and novel candidates via maximizing the optimal transport distances between two forward policies or to improve the generalization via minimizing the optimal transport distances. In addition, we derive an efficient implementation of the regularization by finding its closed form solutions in specific cases and a meaningful upper bound that can be used as an approximation to minimize the regularization term. We empirically demonstrate the advantage of our path regularization on a wide range of tasks, including synthetic hypergrid environment modeling, discrete probabilistic modeling, and biological sequence design.",https://openreview.net/pdf/632e0c6b9d8b29dfe716e2e1649b44f639bcefce.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=6jqSG88Mf_D,3D Neural Embedding Likelihood for Robust Sim-to-Real Transfer in Inverse Graphics,"['Guangyao Zhou', 'Nishad Gothoskar', 'Lirui Wang', 'Joshua B. Tenenbaum', 'Dan Gutfreund', 'Miguel Lazaro-Gredilla', 'Dileep George', 'Vikash Mansinghka']","['~Guangyao_Zhou1', '~Nishad_Gothoskar1', '~Lirui_Wang1', '~Joshua_B._Tenenbaum1', '~Dan_Gutfreund1', '~Miguel_Lazaro-Gredilla1', '~Dileep_George1', '~Vikash_Mansinghka1']","['3D inverse graphics', 'probabilistic inference', 'likelihood', 'RGB-D', 'neural embedding', 'object pose estimation']","A central challenge in 3D scene perception via inverse graphics is robustly modeling the gap between 3D graphics and real-world data. We propose a novel 3D Neural Embedding Likelihood (3DNEL) over RGB-D images to address this gap. 3DNEL uses neural embeddings to predict 2D-3D correspondences from RGB and combines this with depth in a principled manner. 3DNEL is trained entirely from synthetic images and generalizes to real-world data. To showcase this capability, we develop a multi-stage inverse graphics pipeline that uses 3DNEL for 6D object pose estimation from real RGB-D images. Our method outperforms the previous state-of-the-art in sim-to-real pose estimation on the YCB-Video dataset, and improves robustness, with significantly fewer large-error predictions. Unlike existing bottom-up, discriminative approaches that are specialized for pose estimation, 3DNEL adopts a probabilistic generative formulation that jointly models multi-object scenes. This generative formulation enables easy extension of 3DNEL to additional tasks like object and camera tracking from video, using principled inference in the same probabilistic model without task specific retraining.",https://openreview.net/pdf/23d64ef5b29f3a75efd042239d0494b351f11ac8.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=6f47WT-HtuH,Unfair geometries: exactly solvable data model with fairness implications,"['Stefano Sarao Mannelli', 'Federica Gerace', 'Negar Rostamzadeh', 'Luca Saglietti']","['~Stefano_Sarao_Mannelli1', '~Federica_Gerace1', '~Negar_Rostamzadeh1', '~Luca_Saglietti1']","['statistical physics', 'statistical mechanics of learning', 'generalization model', 'modelling structured data', 'data imbalance', 'bias', 'fairness', 'bias mitigation']","Machine learning (ML) may be oblivious to human bias but it is not immune to its perpetuation. Marginalisation and iniquitous group representation are often traceable in the very data used for training, and may be reflected or even enhanced by the learning models.
In the present work, we aim at clarifying the role played by data geometry in the emergence of ML bias. We introduce an exactly solvable high-dimensional model of data imbalance, where parametric control over the many bias-inducing factors allows for an extensive exploration of the bias inheritance mechanism.Through the tools of statistical physics, we analytically characterise the typical properties of learning models trained in this synthetic framework and obtain exact predictions for the observables that are commonly employed for fairness assessment.
Despite the simplicity of the data model, we retrace and unpack typical unfairness behaviour observed on real-world datasets. 
We also obtain a detailed analytical characterisation of a class of bias mitigation strategies. We first consider a basic loss-reweighing scheme, which allows for an implicit minimisation of different unfairness metrics, and quantify the incompatibilities between some existing fairness criteria. Then, we consider a novel mitigation strategy based on a matched inference approach, consisting in the introduction of coupled learning models. Our theoretical analysis of this approach shows that the coupled strategy can strike superior fairness-accuracy trade-offs.",https://openreview.net/pdf/85e02011c5684dd0587c387806bb6805d8630cb0.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=6apN9AQ-3fN,Distance VS. Coordinate: Distance Based Embedding Improves Model Generalization for Routing Problems,"['Hongsen Liao', 'Ruiyuan Wu', 'Yuyang Han', 'Yuncong Hu', 'Ke Xing', 'Jinghua Hao', 'Renqing He']","['liaohongsen@meituan.com', 'wuruiyuan@meituan.com', 'hanyuyang02@meituan.com', 'huyuncong03@meituan.com', 'xingke@meituan.com', 'haojinghua@meituan.com', 'herenqing@meituan.com']","['routing problems', 'travelling salesman problem', 'combinatorial optimization', 'pickup and delivery', 'embedding']","Routing problems, such as traveling salesman problem (TSP) and vehicle routing problem, are among the most classic research topics in combinatorial optimization and operations research (OR). In recent years, with the rapid development of online service platforms, there has been renewed interest in applying this study to facilitate emerging industrial applications, such as food delivery and logistics services. While OR methods remain the mainstream technique, increasing efforts have been put into exploiting deep learning (DL) models for tackling routing problems. The existing ML methods often consider the embedding of the route point coordinate as a key model input and are capable of delivering competing performance in synthetic or simplified settings. However, it is empirically noted that this line of work appears to lack robustness and generalization ability that are crucial for real-world applications. In this paper, we demonstrate that the coordinate can unexpectedly lead to these problems. There are two factors that make coordinate rather `poisonous' for DL models: i) the definition of distance between route points is far more complex than what coordinate can depict; ii) the coordinate can hardly be sufficiently `traversed' by the training data. To circumvent these limitations, we propose to abandon the coordinate and instead use the relative distance for route point embedding. We show in both synthetic TSP and real-world food pickup and delivery route prediction problem that our design can significantly improve model's generalization ability, and deliver competitive or better performance with existing models. ",https://openreview.net/pdf/38fe12d316a1646460d951450e7cad85c0cb8a58.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=6ZajpxqTlQ,Generalize Learned Heuristics to Solve Large-scale Vehicle Routing Problems in Real-time,"['Qingchun Hou', 'Jingwei Yang', 'Yiqiang Su', 'Xiaoqing Wang', 'Yuming Deng']","['~Qingchun_Hou1', '~Jingwei_Yang2', 'yiqiang.syq@alibaba-inc.com', '~Xiaoqing_Wang1', '~Yuming_Deng1']","['Learning', 'Vehicle Routing Problem', 'Large-scale Vehicle Routing Problem', 'Generalization', 'Combinatorial Optimization', 'Reinforcement Learning', 'Attention']","Large-scale Vehicle Routing Problems (VRPs) are widely used in logistics, transportation, supply chain, and robotic systems. Recently, data-driven VRP heuristics are proposed to generate real-time VRP solutions with up to 100 nodes. Despite this progress, current heuristics for large-scale VRPs still face three major challenges: 1) Difficulty in generalizing the heuristics learned on small-scale VRPs to large-scale VRPs without retraining; 2) Challenge in generating real-time solutions for large-scale VRPs; 3) Difficulty in embedding global constraints into learned heuristics. We contribute in the three directions: We propose a Two-stage Divide Method (TAM) to generate sub-route sequence rather than node sequence for generalizing the heuristics learned on small-scale VRPs to solve large-scale VRPs in real-time. A  two-step reinforcement learning method with new reward and padding techniques is proposed to train our TAM.  A global mask function is proposed to keep the global constraints satisfied when dividing a large-scale VRP into several small-scale Traveling Salesman Problems (TSPs). As result, we can solve the small-scale TSPs in parallel quickly. The experiments on synthetic and real-world large-scale VRPs show our method could generalize the learned heuristics trained on datasets of VRP 100 to solve VRPs with over 5000 nodes in real-time while keeping the solution quality better than data-driven heuristics and competitive with traditional heuristics.",https://openreview.net/pdf/1360725553e9aebf2b149f234ac6d83c46a077d4.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=6TugHflAGRU,Eigenvalue Initialisation and Regularisation for Koopman Autoencoders,"['Jack William Miller', ""Charles O'Neill"", 'Navid C Constantinou', 'Omri Azencot']","['~Jack_William_Miller1', ""~Charles_O'Neill2"", '~Navid_C_Constantinou1', '~Omri_Azencot1']","['koopman', 'deep learning', 'dynamical systems', 'autoencoders', 'physics-constrained learning', 'neural networks']","Regularising the parameter matrices of neural networks is ubiquitous in training deep models. Typical regularisation approaches suggest initialising weights using small random values, and to penalise weights to promote sparsity. However, these widely used techniques may be less effective in certain scenarios. Here, we study the Koopman autoencoder model which includes an encoder, a Koopman operator layer, and a decoder. These models have been designed and dedicated to tackle physics-related problems with interpretable dynamics and an ability to incorporate physics-related constraints. However, the majority of existing work employs standard regularisation practices. In our work, we take a step toward augmenting Koopman autoencoders with initialisation and penalty schemes tailored for physics-related settings. Specifically, we propose the ""eigeninit"" initialisation scheme that samples initial Koopman operators from specific eigenvalue distributions. In addition, we suggest the ""eigenloss"" penalty scheme that penalises the eigenvalues of the Koopman operator during training. We demonstrate the utility of these schemes on two synthetic data sets: a driven pendulum and flow past a cylinder; and two real-world problems: ocean surface temperatures and cyclone wind fields. We find on these datasets that eigenloss and eigeninit improves the convergence rate by a factor of 2 to 5, and that they reduce the cumulative long-term prediction error by up to a factor of 2.5. Such a finding points to the utility of incorporating similar schemes as an inductive bias in other physics-related deep learning approaches.",https://openreview.net/pdf/3e6cd9e443be11630af76bfecab1d8c524fd459e.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=6P9Y25Pljl6,FedDAR: Federated Domain-Aware Representation Learning,"['Aoxiao Zhong', 'Hao He', 'Zhaolin Ren', 'Na Li', 'Quanzheng Li']","['~Aoxiao_Zhong1', '~Hao_He1', '~Zhaolin_Ren1', '~Na_Li3', '~Quanzheng_Li1']","['federated learning', 'healthcare', 'fairness', 'personalization']","Cross-silo Federated learning (FL) has become a promising tool in machine learning applications for healthcare. It allows hospitals/institutions to train models with sufficient data while the data is kept private. To make sure the FL model is robust when facing heterogeneous data among FL clients, most efforts focus on personalizing models for clients. However, the latent relationships between clients' data are ignored. In this work, we focus on a special non-iid FL problem, called Domain-mixed FL, where each client's data distribution is assumed to be a mixture of several predefined domains.  Recognizing the diversity of domains and the similarity within domains, we propose a novel method, FedDAR, which learns a domain shared representation and domain-wise personalized prediction heads in a decoupled manner. For simplified linear regression settings, we have theoretically proved that FedDAR enjoys a linear convergence rate.  For general settings, we have performed intensive empirical studies on both synthetic and real-world medical datasets which demonstrate its superiority over prior FL methods. Our code is available at https://github.com/zlz0414/FedDAR.     ",https://openreview.net/pdf/665489145995b4ea0d25bd9c551dc68004d604e5.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=6OxI4WqGr6,Semi-Supervised Offline Reinforcement Learning with Action-Free Trajectories,"['Qinqing Zheng', 'Mikael Henaff', 'Brandon Amos', 'Aditya Grover']","['~Qinqing_Zheng1', '~Mikael_Henaff1', '~Brandon_Amos1', '~Aditya_Grover1']",[],"Natural agents can effectively learn from multiple data sources that differ in size, quality, and types of measurements. We study this heterogeneity in the context of offline reinforcement learning (RL) by introducing a new, practically motivated semi-supervised setting. Here, an agent has access to two sets of trajectories: labelled trajectories containing state, action, reward triplets at every timestep, along with unlabelled trajectories that contain only state and reward information.  For this setting, we develop a simple meta-algorithmic pipeline that learns an inverse-dynamics model on the labelled data to obtain proxy-labels for the unlabelled data, followed by the use of any offline RL algorithm on the true and proxy-labelled trajectories. Empirically, we find this simple pipeline to be highly successful --- on several D4RL benchmarks~\cite{fu2020d4rl}, certain offline RL algorithms can match the performance of variants trained on a fully labeled dataset even when we label only 10\% trajectories from the low return regime. Finally, we perform a large-scale controlled empirical study investigating the interplay of data-centric properties of the labelled and unlabelled datasets, with algorithmic design choices (e.g., inverse dynamics, offline RL algorithm) to identify general trends and best practices for training RL agents on semi-supervised offline datasets.",https://openreview.net/pdf/468e24a12a4ceda397ca5c03c35ad253af39b4c3.pdf,{'title_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=6Fq1-57gff,The World is Changing: Improving Fair Training under Correlation Shifts,"['Yuji Roh', 'Kangwook Lee', 'Steven Euijong Whang', 'Changho Suh']","['~Yuji_Roh1', '~Kangwook_Lee1', '~Steven_Euijong_Whang1', '~Changho_Suh1']","['trustworthy AI', 'fairness', 'correlation shifts']","Model fairness is an essential element for Trustworthy AI. While many techniques for model fairness have been proposed, most of them assume that the training and deployment data distributions are identical, which is often not true in practice. In particular, when the bias between labels and sensitive groups changes, the fairness of the trained model is directly influenced and can worsen. We make two contributions for solving this problem. First, we analytically show that existing in-processing fair algorithms have fundamental limits in accuracy and fairness. We introduce the notion of correlation shifts, which can explicitly capture the change of the above bias. Second, we propose a novel pre-processing step that samples the input data to reduce correlation shifts and thus enables the in-processing approaches to overcome their limitations. We formulate an optimization problem for adjusting the data ratio among labels and sensitive groups to reflect the shifted correlation. A key advantage of our approach lies in decoupling the roles of pre-processing and in-processing approaches: correlation adjustment via pre-processing and unfairness mitigation on the processed data via in-processing. Experiments show that our framework effectively improves existing in-processing fair algorithms w.r.t. accuracy and fairness, both on synthetic and real datasets.",https://openreview.net/pdf/d45d1b5f76f00c2730c516502d29dbe70c9b005b.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=5ohslQBnxUw,On the Convergence of Gradient Flow on Multi-layer Linear Models,"['Hancheng Min', 'Rene Vidal', 'Enrique Mallada']","['~Hancheng_Min1', '~Rene_Vidal1', '~Enrique_Mallada1']","['Multi-layer Linear Networks', 'Non-convex optimization', 'Gradient Flow', 'Training invariance']","In this paper, we analyze the convergence of gradient flow on a multi-layer linear model with a loss function of the form $f(W_1W_2\cdots W_L)$. We show that when $f$ satisfies the gradient dominance property, proper weight initialization leads to exponential convergence of the gradient flow to a global minimum of the loss. Moreover, the convergence rate depends on two trajectory-specific quantities that are controlled by the weight initialization: the \emph{imbalance matrices}, which measure the difference between the weights of adjacent layers, and the least singular value of the \emph{weight product} $W=W_1W_2\cdots W_L$. Our analysis provides improved rate bounds for several multi-layer network models studied in the literature, leading to novel characterizations of the effect of weight imbalance on the rate of convergence. Our results apply to most regression losses and extend to classification ones.",https://openreview.net/pdf/9af3591b25e63987502cada12e3331cac6c72277.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=5lgD4vU-l24s,Recursive Time Series Data Augmentation,"['Amine Mohamed Aboussalah', 'Minjae Kwon', 'Raj G Patel', 'Cheng Chi', 'Chi-Guhn Lee']","['~Amine_Mohamed_Aboussalah1', '~Minjae_Kwon1', '~Raj_G_Patel1', '~Cheng_Chi3', '~Chi-Guhn_Lee1']","['Time Series', 'Data augmentation', 'Representation Learning', 'Deep Learning', 'Reinforcement Learning']","Time series observations can be seen as realizations of an underlying dynamical system governed by rules that we typically do not know. For time series learning tasks we create our model using available data. Training on available realizations, where data is limited, often induces severe over-fitting thereby preventing generalization. To address this issue, we introduce a general recursive framework for time series augmentation, which we call the Recursive Interpolation Method (RIM). New augmented time series are generated using a recursive interpolation function from the original time series for use in training. We perform theoretical analysis to characterize the proposed RIM and to guarantee its performance under certain conditions. We apply RIM to diverse synthetic and real-world time series cases to achieve strong performance over non-augmented data on a variety of learning tasks. Our method is also computationally more efficient and leads to better performance when compared to state of the art time series data augmentation.
",https://openreview.net/pdf/59b64e2daa15ab42b1105a5c3ae7a533e5612b26.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=5cAI0qXxyv,$\mathscr{N}$-WL: A New Hierarchy of Expressivity for Graph Neural Networks,"['Qing Wang', 'Dillon Ze Chen', 'Asiri Wijesinghe', 'Shouheng Li', 'Muhammad Farhan']","['~Qing_Wang14', '~Dillon_Ze_Chen1', '~Asiri_Wijesinghe1', '~Shouheng_Li1', 'muhammad.farhan@anu.edu.au']","['Graph neural network', 'Weisfeiler-Lehman algorithm', 'k-WL hierarchy', 'graph classification']","The expressive power of Graph Neural Networks (GNNs) is fundamental for understanding their capabilities and  limitations, i.e., what graph properties can or cannot be learnt by a GNN. Since standard GNNs have been characterised to be upper-bounded by the Weisfeiler-Lehman (1-WL) algorithm, recent attempts concentrated on developing more expressive GNNs in terms of the $k$-WL hierarchy, a well-established framework for graph isormorphism tests. In this work we show that, contrary to the widely accepted view, the $k$-WL hierarchy is not well-suited for measuring expressive GNNs. This is due to limitations that are inherent to high-dimensional WL algorithms such as the lack of a natural interpretation and high computational costs, which makes it difficult to draw any firm conclusions about the expressive power of GNNs beyond 1-WL. Thus, we propose a novel hierarchy of graph isomorphism tests, namely Neighbourhood WL ($\mathscr{N}$-WL), and also establish a new theorem on the equivalence of expressivity between induced connected subgraphs and induced subgraphs within this hierarchy. Further, we design a GNN model upon $\mathscr{N}$-WL, Graph Neighbourhood Neural Network (G3N), and empirically verify its expressive power on synthetic and real-world benchmarks.",https://openreview.net/pdf/a1b6ae5c041645625de45e46ad10cdde373f930c.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=5ZLWi--i57,BQ-NCO: Bisimulation Quotienting for Generalizable Neural Combinatorial Optimization,"['Darko Drakulic', 'Sofia Michel', 'Florian Mai', 'Arnaud Sors', 'Jean-Marc Andreoli']","['~Darko_Drakulic1', '~Sofia_Michel1', '~Florian_Mai1', '~Arnaud_Sors1', '~Jean-Marc_Andreoli2']",[],"Despite the success of Neural Combinatorial Optimization methods for end-to-end heuristic learning, out-of-distribution generalization remains a challenge. 
In this paper, we present a novel formulation of combinatorial optimization (CO) problems as Markov Decision Processes (MDPs) that effectively leverages symmetries of the CO problems to improve out-of-distribution robustness. 
Starting from the standard MDP formulation of constructive heuristics, we introduce a generic transformation based on bisimulation quotienting (BQ) in MDPs. 
This transformation allows to reduce the state space by accounting for the intrinsic symmetries of the CO problem and facilitates the MDP solving.
We illustrate our approach on the Traveling Salesman and Capacitated Vehicle Routing Problems. We present a BQ reformulation of these problems and introduce a simple attention-based policy network that we train by imitation of (near) optimal solutions for small instances from a single distribution. 
We obtain new state-of-the-art generalization results for instances with up to 1000 nodes from synthetic and realistic benchmarks that vary both in size and node distributions.",https://openreview.net/pdf/9e5664814062cee41ae9b1f9912e810124d98970.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=5Z1rblK1Be5,A Risk-Averse Equilibrium for Multi-Agent Systems,"['Oliver Slumbers', 'David Henry Mguni', 'Stephen Marcus McAleer', 'Jun Wang', 'Yaodong Yang']","['~Oliver_Slumbers1', '~David_Henry_Mguni1', '~Stephen_Marcus_McAleer1', '~Jun_Wang2', '~Yaodong_Yang1']","['game theory', 'safe game theory', 'risk averse game theory', 'safe equilibrium', 'population learning', 'game theory equilibrium']","In multi-agent systems, intelligent agents are tasked with making decisions that lead to optimal outcomes when actions of the other agents are as expected, whilst also being prepared for their unexpected behaviour. In this work, we introduce a novel risk-averse solution concept that allows the learner to accommodate low probability actions by finding the strategy with minimum variance, given any level of expected utility. We first prove the existence of such a risk-averse equilibrium, and propose one fictitious-play type learning algorithm for smaller games that enjoys provable convergence guarantees in games classes including zero-sum and potential. Furthermore, we propose an approximation method for larger games based on iterative population-based training that generates a population of risk- averse agents. Empirically, our equilibrium is shown to be able to reduce the utility variance, specifically in the sense that other agents’ low probability behaviour is better accounted for by our equilibrium in comparison to playing other solutions. Importantly, we show that our population of agents that approximate a risk-averse equilibrium is particularly effective against unseen opposing populations, especially in the case of guaranteeing a minimum level of performance, which is critical to safety-aware multi-agent systems.",https://openreview.net/pdf/284654ccfdebb570fb3b07841cb59de942740f1f.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=5R96mIU85IW,Effectively using  public data in privacy preserving Machine learning,"['Milad Nasr', 'Saeed Mahloujifar', 'Xinyu Tang', 'Prateek Mittal', 'Amir Houmansadr']","['~Milad_Nasr2', '~Saeed_Mahloujifar1', '~Xinyu_Tang1', '~Prateek_Mittal1', '~Amir_Houmansadr1']","['Privacy preserving machine learning', 'dp-sgd', 'public data in privacy']","A key challenge towards differentially private machine learning is balancing the trade-off between privacy and utility. 
A recent line of work has demonstrated that leveraging  \emph{public data samples} can enhance the utility of DP-trained models (for the same privacy guarantees). 
In this work, we show that public data can be used to improve utility in DP models significantly more than shown in recent works.  
Towards this end, we introduce a modified DP-SGD algorithm that leverages public data during its training process. 
Our technique uses public data in two complementary ways: (1) it uses generative models trained on public data to produce synthetic data that is effectively embedded in multiple steps of the training pipeline; (2) it uses a new gradient clipping mechanism  (required for achieving differential privacy) which changes the \emph{origin} of gradient vectors using information inferred from available public and synthesized data. 
Our experimental results demonstrate the effectiveness of our approach in improving the state-of-the-art in differentially private machine learning across multiple datasets, network architectures, and application domains. 
Notably, we achieve a $75\%$ accuracy on CIFAR10  when using only $2,000$ public images;  this is \emph{significantly higher} than the  state-of-the-art which is $68\%$  for DP-SGD with the privacy budget of $\varepsilon=2,\delta=10^{-5}$ (given the same number of public data points).",https://openreview.net/pdf/7be872a1a9b55b33468b92dc0615aa3fd4e13f4b.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=5O2uzDusEN5,DFlow: Learning to Synthesize Better Optical Flow Datasets via a Differentiable Pipeline,"['Kwon Byung-Ki', 'Nam Hyeon-Woo', 'Ji-Yun Kim', 'Tae-Hyun Oh']","['~Kwon_Byung-Ki1', '~Nam_Hyeon-Woo1', '~Ji-Yun_Kim1', '~Tae-Hyun_Oh3']","['Synthetic data', 'Optical flow']","Comprehensive studies of synthetic optical flow datasets have attempted to reveal what properties lead to accuracy improvement in learning-based optical flow estimation. However, manually identifying and verifying the properties that contribute to accurate optical flow estimation require large-scale trial-and-error experiments with iteratively generating whole synthetic datasets and training on them, \ie, impractical. To address this challenge, we propose a differentiable optical flow data generation pipeline and a loss function to drive the pipeline, called DFlow. DFlow efficiently synthesizes a dataset effective for a target domain without the need for cumbersome try-and-errors.  This favorable property is achieved by proposing an efficient dataset comparison method that uses neural networks to approximately encode each dataset and compares the proxy networks instead of explicitly comparing datasets in a pairwise way. Our experiments show the competitive performance of our DFlow against the prior arts in pre-training. Furthermore, compared to competing datasets, DFlow achieves the best fine-tuning performance on the Sintel public benchmark with RAFT.",https://openreview.net/pdf/0ef1c24f1cf3ba80131634c7b890f2eb921fef95.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=5Jq1ASp33L,Understanding Incremental Learning of Gradient Descent: A Fine-grained analysis of Matrix Sensing,"['Jikai Jin', 'Zhiyuan Li', 'Kaifeng Lyu', 'Simon Shaolei Du', 'Jason D. Lee']","['~Jikai_Jin1', '~Zhiyuan_Li2', '~Kaifeng_Lyu2', '~Simon_Shaolei_Du1', '~Jason_D._Lee1']","['deep learning theory', 'incremental learning', 'non-convex optimization']","The implicit bias of optimization algorithms such as gradient descent (GD) is believed to play an important role in generalization of modern machine learning methods such as deep learning. This paper provides a fine-grained analysis of the dynamics of GD for the matrix sensing problem, whose goal is to recover a low-rank ground-truth matrix from near-isotropic linear measurements. With small initialization, we that GD behaves similarly to the greedy low-rank learning heuristics~\citep{li2020towards} and follows an incremental learning procedure~\citep{gissin2019implicit}. That is, GD sequentially learns solutions with increasing ranks until it recovers the ground-truth matrix. Compared to existing works which only analyze the first learning phase for rank-1 solutions, our result is stronger because it characterizes the whole learning process. Moreover, our analysis of the incremental learning procedure applies to the
under-parameterized regime as well. As a key ingredient of our analysis, we observe that GD always follows an approximately low-rank trajectory and develops novel landscape properties for matrix sensing with low-rank parameterization. Finally, we conduct numerical experiments which confirm our theoretical findings.",https://openreview.net/pdf/2cce058d1de5c68cf20d3d81301d21dce920e1fc.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=5HLoTvVGDe,Dual Diffusion Implicit Bridges for Image-to-Image Translation,"['Xuan Su', 'Jiaming Song', 'Chenlin Meng', 'Stefano Ermon']","['~Xuan_Su1', '~Jiaming_Song1', '~Chenlin_Meng1', '~Stefano_Ermon1']",[],"Common image-to-image translation methods rely on joint training over data from both source and target domains. The training process requires concurrent access to both datasets, which hinders data separation and privacy protection; and existing models cannot be easily adapted for translation of new domain pairs. We present Dual Diffusion Implicit Bridges (DDIBs), an image translation method based on diffusion models, that circumvents training on domain pairs. Image translation with DDIBs relies on two diffusion models trained independently on each domain, and is a two-step process: DDIBs first obtain latent encodings for source images with the source diffusion model, and then decode such encodings using the target model to construct target images. Both steps are defined via ordinary differential equations (ODEs), thus the process is cycle consistent only up to discretization errors of the ODE solvers. Theoretically, we interpret DDIBs as concatenation of source to latent, and latent to target Schrodinger Bridges, a form of entropy-regularized optimal transport, to explain the efficacy of the method. Experimentally, we apply DDIBs on synthetic and high-resolution image datasets, to demonstrate their utility in a wide variety of translation tasks and their inherent optimal transport properties.",https://openreview.net/pdf/91f1c96de0279c81fb44166262ba54d69daf0fe4.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=5FqeE2SojJi,Proportional Amplitude Spectrum Training Augmentation for Synthetic-to-Real Domain Generalization,"['Prithvijit Chattopadhyay', 'Kartik Sarangmath', 'Vivek Vijaykumar', 'Judy Hoffman']","['~Prithvijit_Chattopadhyay1', '~Kartik_Sarangmath1', '~Vivek_Vijaykumar1', '~Judy_Hoffman1']","['Synthetic-to-Real Generalization', 'Fourier Space Augmentation', 'Single Domain Generalization']","Synthetic data offers the promise of cheap and bountiful training data for settings where lots of labeled real-world data for some task is unavailable. However, models trained on synthetic data significantly underperform on real-world data. In this paper, we propose Proportional Amplitude Spectrum Training Augmentation (PASTA), a simple and effective augmentation strategy to improve out-of-the-box synthetic-to-real (syn-to-real) generalization performance. PASTA involves perturbing the amplitude spectrums of the synthetic images in the Fourier domain to generate augmented views. We design PASTA to perturb the amplitude spectrums in a structured manner such that high-frequency components are perturbed relatively more than the low-frequency ones. For the tasks of semantic segmentation (GTAV→Real), object detection (Sim10K→Real), and object recognition (VisDAC Syn→Real), across a total of 5 syn-to-real shifts, we find that PASTA  either outperforms or is consistently competitive with more complex state-of-the-art methods while being complementary to other generalization approaches.",https://openreview.net/pdf/ea0a4357b3615f0b7f01aadea9d0fcba72677b7e.pdf,{'title_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=5Egggz1q575,Explaining RL Decisions with Trajectories,"['Shripad Vilasrao Deshmukh', 'Arpan Dasgupta', 'Balaji Krishnamurthy', 'Nan Jiang', 'Chirag Agarwal', 'Georgios Theocharous', 'Jayakumar Subramanian']","['~Shripad_Vilasrao_Deshmukh2', 'arpan.dasgupta@research.iiit.ac.in', '~Balaji_Krishnamurthy1', '~Nan_Jiang2', '~Chirag_Agarwal1', '~Georgios_Theocharous1', '~Jayakumar_Subramanian1']","['Explainable RL', 'Explainable AI', 'Offline Reinforcement Learning', 'Trajectory Attribution', 'Decision-Aware AI']","Explanation is a key component for the adoption of reinforcement learning (RL) in many real-world decision-making problems. In the literature,  the explanation is often provided by saliency attribution to the features of the RL agent's state. In this work, we propose a complementary approach to these explanations, particularly for offline RL, where we attribute the policy decisions of a trained RL agent to the trajectories encountered by it during training. To do so, we encode trajectories in offline training data individually as well as collectively (encoding a set of trajectories). We then attribute policy decisions to a set of trajectories in this encoded space by estimating the sensitivity of the decision with respect to that set.  Further, we demonstrate the effectiveness of the proposed approach in terms of quality of attributions as well as practical scalability in diverse environments that involve both discrete and continuous state and action spaces such as grid-worlds, video games (Atari) and continuous control (MuJoCo). We also conduct a human study on a simple navigation task to observe how their understanding of the task compares with data attributed for a trained RL policy.",https://openreview.net/pdf/8c14263279e4c45dd0a74d7e52a0c6d707338882.pdf,{'title_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=54F8woU8vhq,Context and History Aware Other-Shaping,"['Akbir Khan', 'Newton Kwan', 'Timon Willi', 'Chris Lu', 'Andrea Tacchetti', 'Jakob Nicolaus Foerster']","['~Akbir_Khan1', '~Newton_Kwan1', '~Timon_Willi1', '~Chris_Lu1', '~Andrea_Tacchetti1', '~Jakob_Nicolaus_Foerster1']","['Shaping', 'Multi-Agent', 'Reinforcement Learning', 'Meta Reinforcement Learning']","Cooperation failures, in which self-interested agents converge to collectively worst-case outcomes, are a common failure mode of Multi-Agent Reinforcement Learning (MARL) methods. Methods such as Model-Free Opponent Shaping (MFOS) and The Good Shepherd address this issue by shaping their co-player’s learning into mutual cooperation. However, these methods fail to capture important co-player learning dynamics or do not scale to co-players parameterised by deep neural networks. To address these issues, we propose Context and History Aware Other-Shaping (CHAOS). A CHAOS agent is a meta-learner parameterised by a recurrent neural network that learns to shape its co-player over multiple trials. CHAOS considers both the context (inter-episode information), and history (intra-episode information) to shape co-players successfully. CHAOS also successfully scales to shaping co-players parameterised by deep neural networks. In a set of experiments, we show that CHAOS achieves state-of-the-art shaping in matrix games. We provide extensive ablations, motivating the importance of both context and history. CHAOS also successfully shapes on a complex grid-worldbased game, demonstrating CHAOS’s scalability empirically. Finally, we provide empirical evidence that, counterintuitively, the widely-used Coin Game environment does not require history to learn shaping because states are often indicative of past actions. This suggests that the Coin Game is, in contrast to common understanding, unsuitable for investigating shaping in high-dimensional, multi-step environments.",https://openreview.net/pdf/f9eac9c1c3d3e044031b8e259b0aef0f785280e6.pdf,{'abstract_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=53T6FlFulCV,SoundCount: Sound Counting from Raw Audio with Dyadic Decomposition Neural Network,"['Yuhang He', 'Zhuangzhuang Dai', 'Niki Trigoni', 'Andrew Markham']","['~Yuhang_He3', '~Zhuangzhuang_Dai1', '~Niki_Trigoni1', '~Andrew_Markham2']","['Sound Crowd Count', 'Dyadic Decomposition Network', 'Learnable Filters', 'Acoustic Crowd Counting']","In this paper, we study an underexplored, yet important and challenging problem: counting the number of distinct sound events in data characterized by a high degree of polyphonicity and spectral overlap. A key example is counting individual bird calls in bioacoustic data, from which biodiversity can be estimated. We do so by systematically proposing a novel end-to-end trainable neural network, designing new evaluation protocols, quantifying the difficulty of counting depending on sound polyphonicity, and creating a new dataset tailored for concurrent sound event counting. Unlike existing methods that all apply frequency-selective filters on the raw waveform in a one-stage manner, our neural network progressively decomposes the raw waveform dyadically in frequency domain. Taking inspiration from wavelet decomposition, intermediate waveforms convolved by a parent filter are successively processed by a pair of children filters that evenly split the parent filter's carried frequency response. An energy gain normalization module is introduced to normalize received sound events' loudness variance and spectrum overlap. The network is fully convolutional and parameter-frugal so it is light-weight and computationally efficient. We further design a set of polyphony-aware metrics to quantify sound counting difficulty level from different perspectives. To show the efficiency and generalization of our method (we call DyDecNet), we do experiments on both bioacoustic bird sound (both synthetic and real-world sound), telephone-ring sound and music sound data. Comprehensive experiment results show our method outperforms existing sound event detection (SED) methods significantly. The dyadic decomposition front-end network can be used by existing methods to improve their performance accordingly.",https://openreview.net/pdf/0780a4e6c458c1373c635f988f2ca4fc8a91a4ea.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=4vfv4GDG6G,Agent Prioritization with Interpretable Relation for Trajectory Prediction,"['Manh Huynh', 'Hengbo Ma', 'Gita Alaghband', 'Chiho Choi']","['~Manh_Huynh1', '~Hengbo_Ma1', '~Gita_Alaghband1', '~Chiho_Choi2']",[],"In this paper, we present a novel multi-agent trajectory prediction model, which discovers interpretable relations among agents and prioritize agent's motion. Different from existing approaches, our interpretable design is inspired by the fundamental navigation and motion functions of agent movements, which represent 'where' and 'how' the agents move in the scenes. Specifically, it generates the relation matrix, where each element indicates the motion impact from one to another. In addition, in highly interactive scenarios, one agent may implicitly gain higher priority to move, while the motion of other agents may be impacted by the prioritized agents with higher priority (e.g., a vehicle stopping or reducing its speed due to crossing pedestrians). Based on this intuition, we design a novel motion prioritization module to learn the agent motion priorities based on the inferred relation matrix. Then, a decoder is proposed to sequentially predict and iteratively update the future trajectories of each agent based on their priority orders and the learned relation structures. We first demonstrate the effectiveness of our prediction model on simulated Charged Particles dataset. Next, extensive evaluations are performed on commonly-used datasets for robot navigation, human-robot interactions, and autonomous agents: real-world NBA basketball and INTERACTION. Finally, we  show that the proposed model outperforms other state-of-the-art relation based methods, and is capable to infer interpretable, meaningful relations among agents.",https://openreview.net/pdf/6d44363cfb7955228633941af81203887b9786a6.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=4UldFtZ_CVF,Joint Edge-Model Sparse Learning is Provably Efficient for Graph Neural Networks,"['Shuai Zhang', 'Meng Wang', 'Pin-Yu Chen', 'Sijia Liu', 'Songtao Lu', 'Miao Liu']","['~Shuai_Zhang6', '~Meng_Wang4', '~Pin-Yu_Chen1', '~Sijia_Liu1', '~Songtao_Lu1', '~Miao_Liu1']","['Learning theory', 'Graph neural networks', 'Generalization analysis', 'Graph sparisification']","Due to the significant computational challenge of training large-scale graph neural networks (GNNs), various sparse learning techniques have been exploited to reduce memory and storage costs. Examples include graph sparsification that samples a subgraph to reduce the amount of data aggregation and model sparsification that prunes the neural network to reduce the number of trainable weights. Despite the empirical successes in reducing the training cost while maintaining the test accuracy, the theoretical generalization analysis of sparse learning for GNNs remains elusive. To the best of our knowledge, this paper provides the first theoretical characterization of joint edge-model sparse learning from the perspective of sample complexity and convergence rate in achieving zero generalization error. It proves analytically that both sampling important nodes and pruning neurons with lowest-magnitude can reduce the sample complexity and improve convergence without compromising the test accuracy. Although the analysis is centered on two-layer GNNs with structural constraints on data, the insights are applicable to more general setups and justified by both synthetic and practical citation datasets.",https://openreview.net/pdf/00006f5bb32f82b464f8ded7c219a7fd58ebfe86.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=49N06mWPFUm,Provably Efficient Reinforcement Learning for Online Adaptive Influence Maximization,"['Kaixuan Huang', 'Yu Wu', 'Xuezhou Zhang', 'Shenyinying Tu', 'Qingyun Wu', 'Mengdi Wang', 'Huazheng Wang']","['~Kaixuan_Huang1', '~Yu_Wu6', '~Xuezhou_Zhang2', '~Shenyinying_Tu1', '~Qingyun_Wu2', '~Mengdi_Wang1', '~Huazheng_Wang1']","['influence maximization', 'reinforcement learning']","Online influence maximization aims to maximize the influence spread of a content in a social network with an unknown network model by selecting a few seed nodes. Recent studies followed a non-adaptive setting, where the seed nodes are selected before the start of the diffusion process and network parameters are updated when the diffusion stops. We consider an adaptive version of content-dependent online influence maximization problem where the seed nodes are sequentially activated based on real-time feedback. In this paper, we formulate the problem as an infinite-horizon discounted MDP under a linear diffusion process and present a model-based reinforcement learning solution. Our algorithm maintains a network model estimate and selects seed users adaptively, exploring the social network while improving the optimal policy optimistically. We establish $\widetilde O(\sqrt{T})$ regret bound for our algorithm. Empirical evaluations on synthetic and real-world networks demonstrate the efficiency of our algorithm. ",https://openreview.net/pdf/4ccd0d9620c0b958caf094a1cb6a8f4d849310c6.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=3z1Ws6GEYV4,Multi-Objective GFlowNets,"['Moksh Jain', 'Sharath Chandra Raparthy', 'Alex Hernández-García', 'Jarrid Rector-Brooks', 'Yoshua Bengio', 'Santiago Miret', 'Emmanuel Bengio']","['~Moksh_Jain1', '~Sharath_Chandra_Raparthy3', '~Alex_Hernández-García1', '~Jarrid_Rector-Brooks2', '~Yoshua_Bengio1', '~Santiago_Miret1', '~Emmanuel_Bengio1']","['generative flow networks', 'multi-objective optimization', 'drug discovery', 'material design']","In many applications of machine learning, like drug discovery and material design, the goal is to generate candidates that simultaneously maximize a set of objectives. As these objectives are often conflicting, there is no single candidate that simultaneously maximizes all objectives, but rather a set of Pareto-optimal candidates where one objective cannot be improved without worsening another. Moreover, these objectives, when considered in practice are often under-specified, making diversity of candidates a key consideration. The existing multi-objective optimization methods focus predominantly on covering the Pareto front, failing the capture diversity in the space of candidates. Motivated by the success of GFlowNets for generation of diverse candidates in a single objective setting, in this paper we consider Multi-Objective GFlowNets (MOGFNs). MOGFNs consist of a Conditional GFlowNet which models a family of single-objective sub-problems derived by decomposing the multi-objective optimization problem. Our work is the first to empirically demonstrate conditional GFlowNets. Through a series of experiments on synthetic tasks and real-world domains, we empirically demonstrate that MOGFNs outperform existing methods in terms of Hypervolume, R2-distance and candidate diversity. We also demonstrate the effectiveness of MOGFNs over existing methods in active learning settings. Finally, we supplement our empirical results with a careful analysis of each component of MOGFNs.",https://openreview.net/pdf/24b42af86ed06105d5360735d44b9cbba4395cf0.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=3ZHX6_Mydd7,Invariant Aggregator for Defending against Federated Backdoor Attacks,"['Xiaoyang Wang', 'Dimitrios Dimitriadis', 'Oluwasanmi O Koyejo', 'Shruti Tople']","['~Xiaoyang_Wang6', '~Dimitrios_Dimitriadis1', '~Oluwasanmi_O_Koyejo1', '~Shruti_Tople2']","['Federated learning', 'robustness', 'backdoor attack', 'invariant learning']","Federated learning is gaining popularity as it enables training of high-utility models across several clients without directly sharing their private data. As a downside, the federated setting makes the model vulnerable to various adversarial attacks in the presence of malicious clients. Specifically, an adversary can perform backdoor attacks to control model predictions via poisoning the training dataset with a trigger. In this work, we propose a mitigation for backdoor attacks in a federated learning setup. Our solution forces the model optimization trajectory to focus on the invariant directions that are generally useful for utility and avoid selecting directions that favor few and possibly malicious clients. Concretely, we consider the sign consistency of the pseudo-gradient (the client update) as an estimation of the invariance. Following this, our approach performs dimension-wise filtering to remove pseudo-gradient elements with low sign consistency. Then, a robust mean estimator eliminates outliers among the remaining dimensions. Our theoretical analysis further shows the necessity of the defense combination and illustrates how our proposed solution defends the federated learning model. Empirical results on three datasets with different modalities and varying number of clients show that our approach mitigates backdoor attacks with a negligible cost on the model utility.
",https://openreview.net/pdf/7d276a3d040fd17084877f013dc787c461fdeb85.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=3OaBBATwsvP,Generative Modeling Helps Weak Supervision (and Vice Versa),"['Benedikt Boecking', 'Nicholas Roberts', 'Willie Neiswanger', 'Stefano Ermon', 'Frederic Sala', 'Artur Dubrawski']","['~Benedikt_Boecking1', '~Nicholas_Roberts2', '~Willie_Neiswanger2', '~Stefano_Ermon1', '~Frederic_Sala1', '~Artur_Dubrawski2']","['generative model', 'weak supervision']","Many promising applications of supervised machine learning face hurdles in the acquisition of labeled data in sufficient quantity and quality, creating an expensive bottleneck. To overcome such limitations, techniques that do not depend on ground truth labels have been studied, including weak supervision and generative modeling. While these techniques would seem to be usable in concert, improving one another, how to build an interface between them is not well-understood. In this work, we propose a model fusing programmatic weak supervision and generative adversarial networks and provide theoretical justification motivating this fusion. The proposed approach captures discrete latent variables in the data alongside the weak supervision derived label estimate. Alignment of the two allows for better modeling of sample-dependent accuracies of the weak supervision sources, improving the estimate of unobserved labels. It is the first approach to enable data augmentation through weakly supervised synthetic images and pseudolabels. Additionally, its learned latent variables can be inspected qualitatively. The model outperforms baseline weak supervision label models on a number of multiclass image classification datasets, improves the quality of generated images, and further improves end-model performance through data augmentation with synthetic samples.",https://openreview.net/pdf/bb17eb04238e75fcb4c9ceee6174d6c2e0d19afd.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=2vmGv5wPDBZ,Learning to Estimate Single-View Volumetric Flow Motions without 3D Supervision,"['Aleksandra Franz', 'Barbara Solenthaler', 'Nils Thuerey']","['~Aleksandra_Franz1', '~Barbara_Solenthaler1', '~Nils_Thuerey1']",[],"We address the challenging problem of jointly inferring the 3D flow and volumetric densities moving in a fluid from a monocular input video with a deep neural network. Despite the complexity of this task, we show that it is possible to train the corresponding networks without requiring any 3D ground truth for training. In the absence of ground truth data we can train our model with observations from real-world capture setups instead of relying on synthetic reconstructions. We make this unsupervised training approach possible by first generating an initial prototype volume which is then moved and transported over time without the need for volumetric supervision. Our approach relies purely on image-based losses, an adversarial discriminator network, and regularization. Our method can estimate long-term sequences in a stable manner, while achieving closely matching targets for inputs such as rising smoke plumes.",https://openreview.net/pdf/3c22f015a738c086993a46935c708a6a13671b83.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=2nocgE1m0A,KnowDA: All-in-One Knowledge Mixture Model for Data Augmentation in Low-Resource NLP,"['Yufei Wang', 'Jiayi Zheng', 'Can Xu', 'Xiubo Geng', 'Tao Shen', 'Chongyang Tao', 'Daxin Jiang']","['~Yufei_Wang7', '~Jiayi_Zheng1', '~Can_Xu2', '~Xiubo_Geng2', '~Tao_Shen1', '~Chongyang_Tao1', '~Daxin_Jiang2']","['Data Augmentation', 'Low-Resource NLP']","This paper focuses on data augmentation for low-resource NLP tasks where the training set is limited. The existing solutions either leverage task-independent heuristic rules (e.g., Synonym Replacement) or fine-tune general-purpose pre-trained language models (e.g., GPT2) using the limited training instances to produce new synthetic data. Consequently, they have trivial task-specific knowledge and are limited to yielding low-quality synthetic data. To combat this issue, we propose Knowledge Mixture Data Augmentation Model (KnowDA), a Seq2Seq language model pretrained on a mixture of diverse NLP tasks under a novel framework of Knowledge Mixture Training (KoMT). The goal of KoMT is to condense diverse NLP task-specific knowledge into the single KnowDA model
(i.e., all-in-one). The resulting KnowDA could utilize these knowledge to quickly grasp the inherent synthesis law of the target task through limited training instances. Specifically, KoMT reformulates input examples from various heterogeneous NLP tasks into a unified text-to-text format and employs denoising training objectives in different granularity to learn to reconstruct partial or complete samples. To the best of our knowledge, we are the first to attempt to apply 100+ NLP multi-task training for data augmentation. Extensive experiments show that i) the synthetic data produced by KnowDA successfully improves the performance of the strong pre-trained language
models (i.e., Bert, ALBert and Deberta) by a large margin on the low-resource NLP benchmark FewGLUE, CoNLL’03 and WikiAnn; ii) KnowDA successful transfer the task knowledge to NLP tasks whose types are seen and unseen in KoMT.",https://openreview.net/pdf/92d40698b0d55d0fbb40c50c4921bf1bb8cd40aa.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=2aSj08z30A1,ReaKE: Contrastive Molecular Representation Learning with Chemical Synthetic Knowledge Graph,"['Yi Wang', 'Shuangjia Zheng', 'Jiahua Rao', 'Yunan Luo', 'Yuedong Yang']","['~Yi_Wang30', '~Shuangjia_Zheng2', '~Jiahua_Rao1', '~Yunan_Luo1', '~Yuedong_Yang1']",[],"Molecular representation learning has demonstrated great promise in bridging machine learning and chemical science and in supporting novel chemical discoveries. State-of-the-art methods mostly employ graph neural networks (GNNs) with self-supervised learning (SSL) and extra chemical reaction knowledge to empower the learned embeddings. However, prior works ignore three major issues in modeling reaction data, that is abnormal energy flow, ambiguous embeddings, and sparse embedding space problems. To address these problems, we propose ReaKE, a chemical synthetic knowledge graph-driven pre-training framework for molecular representation learning. We first construct a large-scale chemical synthetic knowledge graph comprising reactants, products and reaction rules. We then propose triplet-level and graph-level contrastive learning strategies to jointly optimize the knowledge graph and molecular embeddings. Representations learned by ReaKE can capture intermolecular relationships reflected in the semantic knowledge graph and molecular structures. By comparing with other state-of-the-art methods, we show that ReaKE can achieve competitive performance on the reaction prediction pretext task and the learned representations transfer well to various downstream tasks, including reaction classification, yield prediction, and molecule property prediction. Further visualization shows that the learned representations can capture the fine-grained differences both between reactions and between molecules.",https://openreview.net/pdf/14c668c88ed13d87eeaefce9cbd4e52684100ecd.pdf,{'title_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=20GtJ6hIaPA,Self-Supervised Category-Level Articulated Object Pose Estimation with Part-Level SE(3) Equivariance,"['Xueyi Liu', 'Ji Zhang', 'Ruizhen Hu', 'Haibin Huang', 'He Wang', 'Li Yi']","['~Xueyi_Liu1', '~Ji_Zhang6', '~Ruizhen_Hu1', '~Haibin_Huang1', '~He_Wang5', '~Li_Yi2']",[],"Category-level articulated object pose estimation aims to estimate a hierarchy of articulation-aware object poses of an unseen articulated object from a known category. To reduce the heavy annotations needed for supervised learning methods, we present a novel self-supervised strategy that solves this problem without any human labels. Our key idea is to factorize canonical shapes and articulated object poses from input articulated shapes through part-level equivariant shape analysis. Specifically, we first introduce the concept of part-level SE(3) equivariance and devise a network to learn features of such property. Then, through a carefully designed fine-grained pose-shape disentanglement strategy, we expect that canonical spaces to support pose estimation could be induced automatically. Thus, we could further predict articulated object poses as per-part rigid transformations describing how parts transform from their canonical part spaces to the camera space. Extensive experiments demonstrate the effectiveness of our method on both complete and partial point clouds from synthetic and real articulated object datasets.",https://openreview.net/pdf/58588985182b7adae53071aa8b2da82ff6db8141.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=1mU6ADbjk-c,Neural Frailty Machine: Beyond proportional hazard assumption in neural survival regressions,"['Jiawei Qiao', 'Ruofan Wu', 'Mingzhe Wu', 'Wen Yu', 'Ming Zheng', 'Tengfei LIU', 'Tianyi Zhang', 'Weiqiang Wang']","['~Jiawei_Qiao1', '~Ruofan_Wu1', '~Mingzhe_Wu1', '~Wen_Yu1', 'mingzheng@fudan.edu.cn', '~Tengfei_LIU2', '~Tianyi_Zhang5', '~Weiqiang_Wang4']","['survival analysis', 'sieve method', 'theory']","We present neural frailty machine (NFM), a powerful and flexible neural modeling framework for survival regressions. The NFM framework utilizes the classical idea of multiplicative frailty in survival analysis to capture unobserved heterogeneity among individuals, at the same time being able to leverage the strong approximation power of neural architectures for handling nonlinear covariate dependence. Two concrete models are derived under the framework that extends neural proportional hazard models and nonparametric hazard regression models. Both models allow efficient training under the likelihood objective. Theoretically, for both proposed models, we establish statistical guarantees of neural function approximation with respect to nonparametric components via characterizing their rate of convergence. Empirically, we provide synthetic experiments that verify our theoretical statements. We also conduct experimental evaluations over 6 benchmark datasets of different scales, showing that the proposed NFM models outperform state-of-the-art survival models in terms of predictive performance. ",https://openreview.net/pdf/565b7bbe89e60e146158ac65399a30f3e6dc3181.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=1mNssCWt_v,STaSy: Score-based Tabular data Synthesis,"['Jayoung Kim', 'Chaejeong Lee', 'Noseong Park']","['~Jayoung_Kim1', '~Chaejeong_Lee1', '~Noseong_Park1']","['Score-based generative model', 'Tabular data', 'Self-paced learning']","Tabular data synthesis is a long-standing research topic in machine learning. Many different methods have been proposed over the past decades, ranging from statistical methods to deep generative methods. However, it has not always been successful due to the complicated nature of real-world tabular data. In this paper, we present a new model named $\textbf{S}$core-based $\textbf{Ta}$bular data $\textbf{Sy}$nthesis ($\texttt{STaSy}$) and its training strategy based on the paradigm of score-based generative modeling. Despite the fact that score-based generative models have resolved many issues in generative models, there still exists room for improvement in tabular data synthesis. Our proposed training strategy includes a self-paced learning technique and a fine-tuning strategy, which further increases the sampling quality and diversity by stabilizing the denoising score matching training. Furthermore, we also conduct rigorous experimental studies in terms of the generative task trilemma: sampling quality, diversity, and time. In our experiments with 15 benchmark tabular datasets and 7 baselines, our method outperforms existing methods in terms of task-dependant evaluations and diversity.
",https://openreview.net/pdf/7cc08c44de490f3e79794b5827aa36b84f99c4c3.pdf,{'title_filter': 'Data Synthesis'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=1jDN-RfQfrb,Unveiling Transformers with LEGO: A Synthetic Reasoning Task,"['Yi Zhang', 'Arturs Backurs', 'Sebastien Bubeck', 'Ronen Eldan', 'Suriya Gunasekar', 'Tal Wagner']","['~Yi_Zhang1', '~Arturs_Backurs1', '~Sebastien_Bubeck1', '~Ronen_Eldan1', '~Suriya_Gunasekar1', '~Tal_Wagner1']","['transformers', 'logical reasoning', 'role of pretraining', 'attention pattern']","We propose a synthetic reasoning task, LEGO (Learning Equality and Group Operations), that encapsulates the problem of following a chain of reasoning, and we study how the Transformer architectures learn this task. We pay special attention to data effects such as pretraining (on seemingly unrelated NLP tasks) and dataset composition (e.g., differing chain length at training and test time), as well as architectural variants such as weight-tied layers or adding convolutional components. We study how the trained models eventually succeed at the task, and in particular, we are able to understand (to some extent) some of the attention heads as well as how the information flows in the network. Based on these observations we propose a hypothesis that here pretraining helps for LEGO tasks due to certain structured attention patterns, and we experimentally verify this hypothesis. We also observe that in some data regimes the trained transformer finds ``shortcut"" solutions to follow the chain of reasoning, which impedes the model's robustness, and moreover we propose ways to prevent it. Motivated by our findings on structured attention patterns, we propose to replace certain attention heads with hardcoded patterns. This architectural change significantly reduces Flops and maintains or even improves the model's performance at large-scale pretraining.",https://openreview.net/pdf/be8333b7e949f26f36a5b69a15a511e07abb0eb1.pdf,{'title_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=1bLT3dGNS0,Relational Curriculum Learning for Graph Neural Networks,"['Zheng Zhang', 'Junxiang Wang', 'Liang Zhao']","['~Zheng_Zhang10', '~Junxiang_Wang1', '~Liang_Zhao6']","['Graph neural networks', 'Curriculum learning']","Graph neural networks have achieved great success in representing structured data and its downstream tasks such as node classification. The key idea is to recursively propagate and aggregate information along the edges of a given graph topology. However, edges in real-world graphs often have varying degrees of difficulty, and some edges may even be noisy to the downstream tasks. Therefore, existing graph neural network models may lead to suboptimal learned representations because they usually consider every edge in a given graph topology equally. On the other hand, curriculum learning, which mimics the human learning principle of learning data samples in a meaningful order, has been shown to be effective in improving the generalization ability of representation learners by gradually proceeding from easy to more difficult samples during training. Unfortunately, most existing curriculum learning strategies are designed for i.i.d data samples and cannot be trivially generalized to handle structured data with dependencies. In order to address these issues, in this paper we propose a novel curriculum learning method for structured data to leverage the various underlying difficulties of data dependencies to improve the quality of learned representations on structured data. Specifically, we design a learning strategy that gradually incorporates edges in a given graph topology into training according to their difficulty from easy to hard, where the degree of difficulty is measured by a self-supervised learning paradigm. We demonstrate the strength of our proposed method in improving the generalization ability of learned representations through extensive experiments on nine synthetic datasets and seven real-world datasets with different commonly used graph neural network models as backbone models.",https://openreview.net/pdf/6e6bc5f3a58802af58bb06f329a6e1accd60462e.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=1Wo0vqaZ8WJ,Let Offline RL Flow: Training Conservative Agents in the Latent Space of Normalizing Flow,"['Dmitry Akimov', 'Vladislav Kurenkov', 'Alexander Nikulin', 'Denis Tarasov', 'Sergey Kolesnikov']","['~Dmitry_Akimov2', '~Vladislav_Kurenkov1', '~Alexander_Nikulin1', '~Denis_Tarasov1', '~Sergey_Kolesnikov1']","['Offline Reinforcement Learning', 'Normalizing Flows']","Offline reinforcement learning aims to train a policy on a pre-recorded and fixed dataset without any additional environment interactions. There are two major challenges in this setting: (1) extrapolation error caused by approximating the value of state-action pairs not well-covered by the training data and (2) distributional shift between behavior and inference policies. One way to tackle these problems is to induce conservatism - i.e., keeping the learned policies closer to the behavioral ones. To achieve this, we build upon recent works on learning policies in latent action spaces and use a special form of normalizing flow for constructing a generative model, which we use as a conservative action encoder. This normalizing flow action encoder is pre-trained in a supervised manner on the offline dataset, and then an additional policy model - controller in the latent space - is trained via reinforcement learning. This approach avoids querying actions outside of the training dataset and therefore does not require additional regularization for out-of-dataset actions. We evaluate our method on various locomotion and navigation tasks, demonstrating that our approach outperforms recently proposed algorithms with generative action models on a large portion of datasets.",https://openreview.net/pdf/f86a805d1f98bbacca90bf4f817bcaa7fbcb8514.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=1TxMUE7cF6_,Modeling Temporal Data as Continuous Functions with Process Diffusion,"['Marin Biloš', 'Kashif Rasul', 'Anderson Schneider', 'Yuriy Nevmyvaka', 'Stephan Günnemann']","['~Marin_Biloš1', '~Kashif_Rasul1', '~Anderson_Schneider1', '~Yuriy_Nevmyvaka1', '~Stephan_Günnemann1']","['time series', 'stochastic process', 'diffusion', 'probabilistic forecasting', 'score-based matching']","Temporal data like time series are often observed at irregular intervals which is a challenging setting for  the existing machine learning methods. To tackle this problem, we view such data as samples from some underlying continuous function. We then define a diffusion-based generative model that adds  noise from a predefined stochastic process while  preserving the  continuity of the resulting underlying function. A neural network is trained to reverse this process which allows us to sample new realizations from the learned distribution. We define suitable stochastic processes as noise sources and introduce novel denoising and score-matching models on processes. Further, we show how to apply this approach to the  multivariate probabilistic forecasting and imputation tasks. Through our extensive experiments, we demonstrate that our method outperforms previous models on synthetic and real-world datasets.",https://openreview.net/pdf/35295d83ddcb697e14c238a173d942928357a18b.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=15lSKp0wBnm,"3D-IntPhys: Learning 3D Visual Intuitive Physics for Fluids, Rigid Bodies, and Granular Materials","['Haotian Xue', 'Antonio Torralba', 'Daniel LK Yamins', 'Joshua B. Tenenbaum', 'Yunzhu Li', 'Hsiao-Yu Tung']","['~Haotian_Xue1', '~Antonio_Torralba1', '~Daniel_LK_Yamins1', '~Joshua_B._Tenenbaum1', '~Yunzhu_Li1', '~Hsiao-Yu_Tung1']","['Visual Intuitive Physics', 'Neural Implicit Representations', 'Graph Neural Networks', 'Learning-Based Dynamics Modeling', 'Particle-Based Dynamics']","Given a visual scene, humans have strong intuitions about how a scene can evolve over time under given actions. The intuition, often termed visual intuitive physics, is a critical ability that allows us to make effective plans to manipulate the scene to achieve desired outcomes without relying on extensive trial and error. In this paper, we present a framework capable of learning 3D-grounded visual intuitive physics models purely from unlabeled images. Our method is composed of a conditional Neural Radiance Field (NeRF)-style visual frontend and a 3D point-based dynamics prediction backend, in which we impose strong relational and structural inductive bias to capture the structure of the underlying environment. Unlike existing intuitive point-based dynamics works that rely on the supervision of dense point trajectory from simulators, we relax the requirements and only assume access to multi-view RGB images and (imperfect) instance masks. This enables the proposed model to handle scenarios where accurate point estimation and tracking are hard or impossible. We evaluate the models on three challenging scenarios involving fluid, granular materials, and rigid objects, where standard detection and tracking methods are not applicable. We show our model can make long-horizon future predictions by learning from raw images and significantly outperforms models that do not employ an explicit 3D representation space. We also show that, once trained, our model can achieve strong generalization in complex scenarios under extrapolate settings.",https://openreview.net/pdf/73e44a63b8b8c3861aca4a5d4064103b62a77043.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=0xHVGIiYK2n,Multi-Agent Sequential Decision-Making via Communication,"['Ziluo Ding', 'Kefan Su', 'Weixin Hong', 'Liwen Zhu', 'Tiejun Huang', 'Zongqing Lu']","['~Ziluo_Ding1', '~Kefan_Su1', '~Weixin_Hong1', '~Liwen_Zhu1', '~Tiejun_Huang1', '~Zongqing_Lu2']","['multi-agent communication', 'multi-agent reinforcement learning']"," Communication helps agents to obtain information about others so that better coordinated behavior can be learned. Some existing work communicates predicted future trajectory with others, hoping to get clues about what others would do for better coordination. However, circular dependencies sometimes can occur when agents are treated synchronously so it is hard to coordinate decision-making. In this paper, we propose a novel communication scheme, Sequential Communication (SeqComm). SeqComm treats agents asynchronously (the upper-level agents make decisions before the lower-level ones) and has two communication phases. In negotiation phase, agents determine the priority of decision-making by communicating hidden states of observations and comparing the value of intention, which is obtained by modeling the environment dynamics. In launching phase, the upper-level agents take the lead in making decisions and communicate their actions with the lower-level agents. Theoretically, we prove the policies learned by SeqComm are guaranteed to improve monotonically and converge. Empirically, we show that SeqComm outperforms existing methods in various multi-agent cooperative tasks.
",https://openreview.net/pdf/c1788f4d5f395c9a121f290bd9f17fcc2fb6e4b7.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=0pdSt3oyJa1,Specformer: Spectral Graph Neural Networks Meet Transformers,"['Deyu Bo', 'Chuan Shi', 'Lele Wang', 'Renjie Liao']","['~Deyu_Bo1', '~Chuan_Shi1', '~Lele_Wang1', '~Renjie_Liao1']","['Spectral Graph Neural Networks', 'Transformer']","Spectral graph neural networks (GNNs) learn graph representations via spectral-domain graph convolutions. However, most existing spectral graph filters are scalar-to-scalar functions, i.e., mapping a single eigenvalue to a single filtered value, thus ignoring the global pattern of the spectrum. Furthermore, these filters are often constructed based on some fixed-order polynomials, which have limited expressiveness and flexibility. To tackle these issues, we introduce Specformer, which effectively encodes the set of all eigenvalues and performs self-attention in the spectral domain, leading to a learnable set-to-set spectral filter. We also design a decoder with learnable bases to enable non-local graph convolution. Importantly, Specformer is equivariant to permutation. By stacking multiple Specformer layers, one can build a powerful spectral GNN. On synthetic datasets, we show that our Specformer can better recover ground-truth spectral filters than other spectral GNNs. Extensive experiments of both node-level and graph-level tasks on real-world graph datasets show that our Specformer outperforms state-of-the-art GNNs and learns meaningful spectrum patterns. Code and data are available at https://github.com/bdy9527/Specformer.",https://openreview.net/pdf/4bf614d9277dc7ba7ec87eb0ccfccf6b765d3979.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=0aAd19ZQp11,Efficient Bayesian Optimization with Deep Kernel Learning and Transformer Pre-trained on Muliple Heterogeneous Datasets,"['Wenlong Lyu', 'Shoubo Hu', 'Jie Chuai', 'Zhitang Chen']","['~Wenlong_Lyu1', '~Shoubo_Hu1', 'chuaijie@huawei.com', '~Zhitang_Chen1']","['Pre-training', 'Bayesian optimization', 'Transformer', 'Transfer learning']","Bayesian optimization (BO) is widely adopted in black-box optimization problems and it relies on a surrogate model to approximate the black-box response function. With the increasing number of black-box optimization tasks solved and even more to solve, the ability to learn from multiple prior tasks to jointly pre-train a surrogate model is long-awaited to further boost optimization efficiency. In this paper, we propose a simple approach to pre-train a surrogate, which is a Gaussian process (GP) with a kernel defined on deep features learned from a Transformer-based encoder, using datasets from prior tasks with possibly heterogeneous input spaces. In addition, we provide a simple yet effective mix-up initialization strategy for input tokens corresponding to unseen input variables and therefore accelerate new tasks' convergence. Experiments on both synthetic and real benchmark problems demonstrate the effectiveness of our proposed pre-training and transfer BO strategy over existing methods.",https://openreview.net/pdf/fa972f7d3401955378ea1f6d7d4bc9f68dd76142.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=0YXmOFLb1wQ,MotifExplainer: a Motif-based Graph Neural Network Explainer,"['Zhaoning Yu', 'Hongyang Gao']","['~Zhaoning_Yu2', '~Hongyang_Gao1']","['Graph Neural Networks', 'Explainer', 'Motif']","We consider the explanation problem of Graph Neural Networks (GNNs). Most existing GNN explanation methods identify the most important edges or nodes but fail to consider substructures, which are more important for graph data. One method considering subgraphs tries to search all possible subgraphs and identifies the most significant ones. However, the subgraphs identified may not be recurrent or statistically important for interpretation. This work proposes a novel method, named MotifExplainer, to explain GNNs by identifying important motifs, which are recurrent and statistically significant patterns in graphs. Our proposed motif-based methods can provide better human-understandable explanations than methods based on nodes, edges, and regular subgraphs. Given an instance graph and a pre-trained GNN model, our method first extracts motifs in the graph using domain-specific motif extraction rules. Then, a motif embedding is encoded by feeding motifs into the pre-trained GNN. Finally, we employ an attention-based method to identify the most influential motifs as explanations for the prediction results. The empirical studies on both synthetic and real-world datasets demonstrate the effectiveness of our method.",https://openreview.net/pdf/1e00b18281b486873768fcbdbd648a6820101c0b.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=0LJRS7B3r4_,Advantage Constrained Proximal Policy Optimization in Multi-Agent Reinforcement Learning,['Weifan Li'],['~Weifan_Li1'],"['Multi agent', 'reinforcement learning', 'neural network', 'deep learning', 'trust region.']","We explore the value-based method and policy gradient combination in multi-agent reinforcement learning (MARL). In value-based MARL, {\itshape{Individual-Global-Max}} (IGM) principle plays an important role, which maintains the consistency between joint and local action values. At the same time, IGM is difficult to guarantee in multi-agent policy gradient methods due to stochastic exploration and conflicting gradient directions. In this paper, we propose a novel multi-agent policy gradient algorithm called {\itshape{Advantage Constrained Proximal Policy Optimization}} (ACPPO). Based on {\itshape{multi-agent advantage decomposition lemma}}, ACPPO introduces an advantage network for each agent to estimate current local state-action advantage. The coefficient of each agent constrains the joint-action advantage according to the consistency of the estimated joint-action advantage and local advantage. Unlike previous policy gradient-based MARL algorithms, ACPPO does not need an extra sampled baseline to reduce variance. We evaluate the proposed methods for continuous matrix game and Multi-Agent MuJoCo tasks. Results show that ACPPO outperforms the baselines such as MAPPO, MADDPG, and HAPPO.",https://openreview.net/pdf/8441bdf7caa8a9e3ffa807b1eef3347da04951a9.pdf,{'title_filter': 'Agent'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=0DwzMsUNIr,From Points to Functions: Infinite-dimensional Representations in Diffusion Models,"['Sarthak Mittal', 'Guillaume Lajoie', 'Stefan Bauer', 'Arash Mehrjou']","['~Sarthak_Mittal1', '~Guillaume_Lajoie1', '~Stefan_Bauer1', '~Arash_Mehrjou1']","['representation learning', 'diffusion models', 'score-based learning']","Diffusion-based generative models learn to iteratively transfer unstructured noise to a complex target distribution as opposed to Generative Adversarial Networks (GANs) or the decoder of Variational Autoencoders (VAEs) which produce samples from the target distribution in a single step. Thus, in diffusion models every sample is naturally connected to a random trajectory which is a solution to a learned stochastic differential equation (SDE). Generative models are only concerned with the final state of this trajectory that delivers samples from the desired distribution. \cite{abstreiter2021diffusion} showed that these stochastic trajectories can be seen as continuous filters that wash out information along the way. Consequently, it is reasonable to ask if there is an intermediate time step at which the preserved information is optimal for a given downstream task. In this work, we show that a combination of information content from different time steps gives a strictly better representation for the downstream task. We introduce an attention and recurrence based modules that ``learn to mix'' information content of various time-steps such that the resultant representation leads to superior performance in downstream tasks.
",https://openreview.net/pdf/c938315f41ad379588ffadbc38372c32e2fc50d6.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=-z7O7fk_Cs,Invertible normalizing flow neural networks by JKO scheme,"['Chen Xu', 'Xiuyuan Cheng', 'Yao Xie']","['~Chen_Xu12', '~Xiuyuan_Cheng1', '~Yao_Xie2']","['Normalizing flow', 'invertible neural networks', 'JKO scheme']","Normalizing flow is a class of deep generative models for efficient sampling and density estimation. In practice, the flow often appears as a chain of invertible neural network blocks. To facilitate training, past works have regularized flow trajectories and designed special network architectures. The current paper develops a neural ODE flow network inspired by the Jordan-Kinderleherer-Otto (JKO) scheme, which allows an efficient \textit{block-wise} training procedure: as the JKO scheme unfolds the dynamic of gradient flow, the proposed model naturally stacks residual network blocks one-by-one and reduces the memory load as well as the difficulty of training deep networks. We also develop an adaptive time-reparametrization of the flow network with a progressive refinement of the trajectory in probability space, which improves the optimization efficiency and model accuracy in practice.  
On high-dimensional generative tasks for tabular data, JKO-Flow can process larger data batches and perform competitively as or better than continuous and discrete flow models, using 10X less number of iterations (e.g., batches) and significantly less time per iteration. ",https://openreview.net/pdf/74e2d2e5661eb174de11f1239b2a77db05bff8ff.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=-SKvXtXPCaJ,Learning Control by Iterative Inversion,"['Gal Leibovich', 'Guy Jacob', 'Or Avner', 'Gal Novik', 'Aviv Tamar']","['~Gal_Leibovich1', '~Guy_Jacob1', '~Or_Avner1', '~Gal_Novik1', '~Aviv_Tamar2']","['RL', 'IRL']","We formulate learning for control as an inverse problem - inverting a dynamical system to give the actions which yield desired behavior. The key challenge in this formulation is a distribution shift in the inputs to the function to be inverted - the learning agent can only observe the forward mapping (its actions' consequences) on trajectories that it can execute, yet must learn the inverse mapping for inputs-outputs that correspond to a different, desired behavior. We propose a general recipe for inverse problems with a distribution shift that we term $\textit{iterative inversion}$ - learn the inverse mapping under the current input distribution (policy), then use it on the desired output samples to obtain a new input distribution, and repeat.
As we show, iterative inversion can converge to the desired inverse mapping, but under rather strict conditions on the mapping itself.
We next apply iterative inversion to learn control. Our input is a set of demonstrations of desired behavior, given as video embeddings of trajectories (without actions), and our method iteratively learns to imitate trajectories generated by the current policy, perturbed by random exploration noise. We find that constantly adding the demonstrated trajectory embeddings as input to the policy when generating trajectories to imitate, a-la iterative inversion, we effectively steer the learning towards the desired trajectory distribution. To the best of our knowledge, this is the first exploration of learning control from the viewpoint of inverse problems, and the main advantage of our approach is simplicity - it does not require rewards, and only employs supervised learning, which can be easily scaled to use state-of-the-art trajectory embedding techniques and policy representations. Indeed, with a VQ-VAE embedding, and a transformer-based policy, we demonstrate non-trivial continuous control on several tasks. Further, we report an improved performance on imitating diverse behaviors compared to reward based methods. ",https://openreview.net/pdf/dac83de44f4e9858598471c3518db217d7b629e0.pdf,{'abstract_filter': 'Trajectory'},ICLR.cc,2023,Conference
https://openreview.net/forum?id=-RwZOVybbj,Risk-Aware Reinforcement Learning with Coherent Risk Measures and Non-linear Function Approximation,"['Thanh Lam', 'Arun Verma', 'Bryan Kian Hsiang Low', 'Patrick Jaillet']","['~Thanh_Lam1', '~Arun_Verma1', '~Bryan_Kian_Hsiang_Low1', '~Patrick_Jaillet1']","['Risk-Aware Reinforcement Learning', 'Coherent Risk Measures', 'Non-linear Function Approximation']","We study the risk-aware reinforcement learning (RL) problem in the episodic finite-horizon Markov decision process with unknown transition and reward functions. In contrast to the risk-neutral RL problem, we consider minimizing the risk of having low rewards, which arise due to the intrinsic randomness of the MDPs and imperfect knowledge of the model. Our work provides a unified framework to analyze the regret of risk-aware RL policy with coherent risk measures in conjunction with non-linear function approximation, which gives the first sub-linear regret bounds in the setting. Finally, we validate our theoretical results via empirical experiments on synthetic and real-world data.",https://openreview.net/pdf/12ed9c605b0fa8dc9237a38935722f9687e15641.pdf,{'abstract_filter': 'Synthetic'},ICLR.cc,2023,Conference
