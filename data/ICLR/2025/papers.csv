forum,title,authors,authorids,keywords,abstract,pdf,match,venue,year,type
https://openreview.net/forum?id=zxO4WuVGns,{'value': 'Inverse decision-making using neural amortized Bayesian actors'},Dominik Straub; Tobias F. Niehues; Jan Peters; Constantin A. Rothkopf,~Dominik_Straub1; ~Tobias_F._Niehues1; ~Jan_Peters3; ~Constantin_A._Rothkopf1,"{'value': ['Bayesian actor models', 'perception and action', 'cognitive science', 'Bayesian inference', 'inverse modeling']}","{'value': ""Bayesian observer and actor models have provided normative explanations for many behavioral phenomena in perception, sensorimotor control, and other areas of cognitive science and neuroscience. They attribute behavioral variability and biases to interpretable entities such as perceptual and motor uncertainty, prior beliefs, and behavioral costs. However, when extending these models to more naturalistic tasks with continuous actions, solving the Bayesian decision-making problem is often analytically intractable. Inverse decision-making, i.e. performing inference over the parameters of such models given behavioral data, is computationally even more difficult. Therefore, researchers typically constrain their models to easily tractable components, such as Gaussian distributions or quadratic cost functions, or resort to numerical approximations. To overcome these limitations, we amortize the Bayesian actor using a neural network trained on a wide range of parameter settings in an unsupervised fashion. Using the pre-trained neural network enables performing efficient gradient-based Bayesian inference of the Bayesian actor model's parameters. We show on synthetic data that the inferred posterior distributions are in close alignment with those obtained using analytical solutions where they exist. Where no analytical solution is available, we recover posterior distributions close to the ground truth. We then show how our method allows for principled model comparison and how it can be used to disentangle factors that may lead to unidentifiabilities between priors and costs. Finally, we apply our method to empirical data from three sensorimotor tasks and compare model fits with different cost functions to show that it can explain individuals' behavioral patterns.""}",https://openreview.net{'value': '/pdf/0046d112b652872ab73840e86afeae102f289d1c.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=zpDGwcmMV4,"{'value': 'Physics of Language Models: Part 2.2, How to Learn From Mistakes on Grade-School Math Problems'}",Tian Ye; Zicheng Xu; Yuanzhi Li; Zeyuan Allen-Zhu,~Tian_Ye2; ~Zicheng_Xu1; ~Yuanzhi_Li1; ~Zeyuan_Allen-Zhu1,"{'value': ['pretraining', 'language model', 'error correction', 'error detection']}","{'value': 'Language models have demonstrated remarkable performance in solving reasoning tasks; however, even the strongest models still occasionally make reasoning mistakes. Recently, there has been active research aimed at improving reasoning accuracy, particularly by using pretrained language models to ""self-correct\'\' their mistakes via multi-round prompting. In this paper, we follow this line of work but focus on understanding the usefulness of incorporating ``error-correction\'\' data directly into the pretraining stage. This data consists of erroneous solution steps immediately followed by their corrections. Using a synthetic math dataset, we show promising results: this type of pretrain data can help language models achieve higher reasoning accuracy directly (i.e., through simple auto-regression, without multi-round prompting) compared to pretraining on the same amount of error-free data. We also delve into many details, such as (1) how this approach differs from beam search, (2) how such data can be prepared, (3) whether masking is needed on the erroneous tokens, (4) the amount of error required, (5) whether such data can be deferred to the fine-tuning stage, and many others.'}",https://openreview.net{'value': '/pdf/f32bd8e22a2d6399f178aef058260798753fbe48.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=zl0HLZOJC9,{'value': 'Probabilistic Learning to Defer: Handling Missing Expert Annotations and Controlling Workload Distribution'},Cuong C. Nguyen; Thanh-Toan Do; Gustavo Carneiro,~Cuong_C._Nguyen1; ~Thanh-Toan_Do4; ~Gustavo_Carneiro1,"{'value': ['learning to defer', 'expectation - maximisation']}","{'value': ""Recent progress in machine learning research is gradually shifting its focus towards *human-AI cooperation* due to the advantages of exploiting the reliability of human experts and the efficiency of AI models. One of the promising approaches in human-AI cooperation is *learning to defer* (L2D), where the system analyses the input data and decides to make its own decision or defer to human experts. Although L2D has demonstrated state-of-the-art performance, in its standard setting, L2D entails a severe limitation: all human experts must annotate the whole training dataset of interest, resulting in a time-consuming and expensive annotation process that can subsequently influence the size and diversity of the training set. Moreover, the current L2D does not have a principled way to control workload distribution among human experts and the AI classifier, which is critical to optimise resource allocation.  We, therefore, propose a new probabilistic modelling approach inspired by the mixture-of-experts, where the Expectation - Maximisation algorithm is leverage to address the issue of missing expert's annotations. Furthermore, we introduce a constraint, which can be solved efficiently during the E-step, to control the workload distribution among human experts and the AI classifier. Empirical evaluation on synthetic and real-world datasets shows that our proposed probabilistic approach performs competitively, or surpasses previously proposed methods assessed on the same benchmarks.""}",https://openreview.net{'value': '/pdf/99251b4c1b2103aacee1810cfa93c62d3a96a120.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=zZ8fgXHkXi,{'value': 'h4rm3l: A Language for Composable Jailbreak Attack Synthesis'},Moussa Koulako Bala Doumbouya; Ananjan Nandi; Gabriel Poesia; Davide Ghilardi; Anna Goldie; Federico Bianchi; Dan Jurafsky; Christopher D Manning,~Moussa_Koulako_Bala_Doumbouya1; ~Ananjan_Nandi1; ~Gabriel_Poesia1; ~Davide_Ghilardi2; ~Anna_Goldie1; ~Federico_Bianchi1; ~Dan_Jurafsky1; ~Christopher_D_Manning1,"{'value': ['LLM safety', 'program synthesis', 'compositional modeling', 'jailbreak attacks', 'red-teaming', 'domain-specific languages', 'string transformations', 'AI safety research', 'black-box optimization', 'automated benchmarking']}","{'value': ""Despite their demonstrated valuable capabilities, state-of-the-art (SOTA) widely deployed large language models (LLMs) still have the potential to cause harm to society due to the ineffectiveness of their safety filters, which can be bypassed by prompt transformations called jailbreak attacks. Current approaches to LLM safety assessment, which employ datasets of templated prompts and benchmarking pipelines, fail to cover sufficiently large and diverse sets of jailbreak attacks, leading to the widespread deployment of unsafe LLMs. Recent research showed that novel jailbreak attacks could be derived by composition; however, a formal composable representation for jailbreak attacks, which, among other benefits, could enable the exploration of a large compositional space of jailbreak attacks through program synthesis methods, has not been previously proposed. We introduce h4rm3l, a novel approach that addresses this gap with a human-readable domain-specific language (DSL). Our framework comprises: (1) The h4rm3l DSL, which formally expresses jailbreak attacks as compositions of parameterized string transformation primitives. (2) A synthesizer with bandit algorithms that efficiently generates jailbreak attacks optimized for a target black box LLM. (3) The h4rm3l red-teaming software toolkit that employs the previous two components and an automated harmful LLM behavior classifier that is strongly aligned with human judgment. We demonstrate h4rm3l's efficacy by synthesizing a dataset of 2656 successful novel jailbreak attacks targeting 6 SOTA open-source and proprietary LLMs (GPT-3.5, GPT-4o, Claude-3-Sonnet, Claude-3-Haiku, Llama-3-8B, and Llama-3-70B), and by benchmarking those models against a subset of these synthesized attacks. Our results show that h4rm3l's synthesized attacks are diverse and more successful than existing jailbreak attacks in literature, with success rates exceeding 90% on SOTA LLMs. Warning: This paper and related research artifacts contain offensive and potentially disturbing prompts and model-generated content.""}",https://openreview.net{'value': '/pdf/f01d1902ffd58add3194362047413eaa9df0e1e1.pdf'},{'title_filter': 'Data Synthesis'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=zPHra4V5Mc,{'value': 'Feature Averaging: An Implicit Bias of Gradient Descent Leading to Non-Robustness in Neural Networks'},Binghui Li; Zhixuan Pan; Kaifeng Lyu; Jian Li,~Binghui_Li1; ~Zhixuan_Pan1; ~Kaifeng_Lyu2; ~Jian_Li2,"{'value': ['deep learning theory', 'feature learning', 'adversarial robustness', 'implicit bias']}","{'value': 'In this work, we investigate a particular implicit bias in gradient descent training, which we term “Feature Averaging,” and argue that it is one of the principal factors contributing to the non-robustness of deep neural networks. We show that, even when multiple discriminative features are present in the input data, neural networks trained by gradient descent tend to rely on an average (or a certain combination) of these features for classification, rather than distinguishing and leveraging each feature individually. Specifically, we provide a detailed theoretical analysis of the training dynamics of two-layer ReLU networks on a binary classification task, where the data distribution consists of multiple clusters with mutually orthogonal centers. We rigorously prove that gradient descent biases the network towards feature averaging, where the weights of each hidden neuron represent an average of the cluster centers (each corresponding to a distinct feature), thereby making the network vulnerable to input perturbations aligned with the negative direction of the averaged features. On the positive side, we demonstrate that this vulnerability can be mitigated through more granular supervision. In particular, we prove that a two-layer ReLU network can achieve optimal robustness when trained to classify individual features rather than merely the original binary classes. Finally, we validate our theoretical findings with experiments on synthetic datasets, MNIST, and CIFAR-10, and confirm the prevalence of feature averaging and its impact on adversarial robustness. We hope these theoretical and empirical insights deepen the understanding of how gradient descent shapes feature learning and adversarial robustness, and how more detailed supervision can enhance robustness.'}",https://openreview.net{'value': '/pdf/1078c3147df3f48a6837f1125c459222f2796511.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=zG459X3Xge,{'value': 'VisRAG: Vision-based Retrieval-augmented Generation on Multi-modality Documents'},Shi Yu; Chaoyue Tang; Bokai Xu; Junbo Cui; Junhao Ran; Yukun Yan; Zhenghao Liu; Shuo Wang; Xu Han; Zhiyuan Liu; Maosong Sun,~Shi_Yu2; ~Chaoyue_Tang3; ~Bokai_Xu1; ~Junbo_Cui1; ~Junhao_Ran1; ~Yukun_Yan2; ~Zhenghao_Liu2; ~Shuo_Wang13; ~Xu_Han2; ~Zhiyuan_Liu1; ~Maosong_Sun1,"{'value': ['Retrieval-augmented Generation', 'Vision-language Models']}","{'value': 'Retrieval-augmented generation (RAG) is an effective technique that enables large language models (LLMs) to utilize external knowledge sources for generation.  However, current RAG systems are solely based on text, rendering it impossible to utilize vision information like layout and images that play crucial roles in real-world multi-modality documents.  In this paper, we introduce VisRAG, which tackles this issue by establishing a vision-language model (VLM)-based RAG pipeline.  In this pipeline, instead of first parsing the document to obtain text, the document is directly embedded using a VLM as an image and then retrieved to enhance the generation of a VLM. Compared to traditional text-based RAG, VisRAG maximizes the retention and utilization of the data information in the original documents, eliminating the information loss introduced during the parsing process. We collect both open-source and synthetic data to train the retriever in VisRAG and explore a variety of generation methods. Experiments demonstrate that VisRAG outperforms traditional RAG in both the retrieval and generation stages, achieving a 20–40% end-to-end performance gain over traditional text-based RAG pipeline. Further analysis reveals that VisRAG is efficient in utilizing training data and demonstrates strong generalization capability, positioning it as a promising solution for RAG on multi-modality documents. Our code and data are available at https://github.com/openbmb/visrag.'}",https://openreview.net{'value': '/pdf/b13eed287ec8fb31700414fded06f07db85891cd.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=zCxGCdzreM,{'value': 'Kinetix: Investigating the Training of General Agents through Open-Ended Physics-Based Control Tasks'},Michael Matthews; Michael Beukman; Chris Lu; Jakob Nicolaus Foerster,~Michael_Matthews4; ~Michael_Beukman1; ~Chris_Lu1; ~Jakob_Nicolaus_Foerster1,"{'value': ['reinforcement learning', 'open-endedness', 'unsupervised environment design', 'automatic curriculum learning', 'benchmark']}","{'value': 'While large models trained with self-supervised learning on offline datasets have shown remarkable capabilities in text and image domains, achieving the same generalisation for agents that act in sequential decision problems remains an open challenge.\nIn this work, we take a step towards this goal by procedurally generating tens of millions of 2D physics-based tasks and using these to train a general reinforcement learning (RL) agent for physical control.\nTo this end, we introduce Kinetix: an open-ended space of physics-based RL environments that can represent tasks ranging from robotic locomotion and grasping to video games and classic RL environments, all within a unified framework.\nKinetix makes use of our novel hardware-accelerated physics engine Jax2D that allows us to cheaply simulate billions of environment steps during training.\nOur trained agent exhibits strong physical reasoning capabilities in 2D space, being able to zero-shot solve unseen human-designed environments.  Furthermore, fine-tuning this general agent on tasks of interest shows significantly stronger performance than training an RL agent *tabula rasa*.  This includes solving some environments that standard RL training completely fails at.\nWe believe this demonstrates the feasibility of large scale, mixed-quality pre-training for online RL and we hope that Kinetix will serve as a useful framework to investigate this further.'}",https://openreview.net{'value': '/pdf/1c9333bd485fcf46a3c7b3a1420dd36b55476d63.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=zBbZ2vdLzH,{'value': 'Joint Graph Rewiring and Feature Denoising via Spectral Resonance'},Jonas Linkerhägner; Cheng Shi; Ivan Dokmanić,~Jonas_Linkerhägner1; ~Cheng_Shi2; ~Ivan_Dokmanić1,"{'value': ['GNNs', 'Rewiring', 'Denoising', 'Spectral Resonance', 'cSBM']}","{'value': 'When learning from graph data, the graph and the node features both give noisy information about the node labels. In this paper we propose an algorithm to **j**ointly **d**enoise the features and **r**ewire the graph (JDR), which improves the performance of downstream node classification graph neural nets (GNNs). JDR works by aligning the leading spectral spaces of graph and feature matrices. It approximately solves the associated non-convex optimization problem in a way that handles graphs with multiple classes and different levels of homophily or heterophily. We theoretically justify JDR in a stylized setting and show that it consistently outperforms existing rewiring methods on a wide range of synthetic and real-world node classification tasks.'}",https://openreview.net{'value': '/pdf/3c176b0311a7336f62db1732263753a3c128620a.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=z8sxoCYgmd,{'value': 'LOKI: A Comprehensive Synthetic Data Detection Benchmark using Large Multimodal Models'},Junyan Ye; Baichuan Zhou; Zilong Huang; Junan Zhang; Tianyi Bai; Hengrui Kang; Jun He; Honglin Lin; Zihao Wang; Tong Wu; Zhizheng Wu; Yiping Chen; Dahua Lin; Conghui He; Weijia Li,~Junyan_Ye1; ~Baichuan_Zhou1; ~Zilong_Huang2; ~Junan_Zhang1; ~Tianyi_Bai1; ~Hengrui_Kang1; ~Jun_He7; ~Honglin_Lin2; ~Zihao_Wang37; ~Tong_Wu2; ~Zhizheng_Wu1; ~Yiping_Chen2; ~Dahua_Lin1; ~Conghui_He2; ~Weijia_Li2,{'value': ['LMMs；Deepfake；Multimodality']},"{'value': 'With the rapid development of AI-generated content, the future internet may be inundated with synthetic data, making the discrimination of authentic and credible multimodal data increasingly challenging. Synthetic data detection has thus garnered widespread attention, and the performance of large multimodal models (LMMs) in this task has attracted significant interest. LMMs can provide natural language explanations for their authenticity judgments, enhancing the explainability of synthetic content detection. Simultaneously, the task of distinguishing between real and synthetic data effectively tests the perception, knowledge, and reasoning capabilities of LMMs. In response, we introduce LOKI, a novel benchmark designed to evaluate the ability of LMMs to detect synthetic data across multiple modalities. LOKI encompasses video, image, 3D, text, and audio modalities, comprising 18K carefully curated questions across 26 subcategories with clear difficulty levels. The benchmark includes coarse-grained judgment and multiple-choice questions, as well as fine-grained anomaly selection and explanation tasks, allowing for a comprehensive analysis of LMMs. We evaluated 22 open-source LMMs and 6 closed-source models on LOKI, highlighting their potential as synthetic data detectors and also revealing some limitations in the development of LMM capabilities. More information about LOKI can be found at https://opendatalab.github.io/LOKI/.'}",https://openreview.net{'value': '/pdf/8ae883002829df5dc25bec06f6db2386768d37f9.pdf'},{'title_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=z5uVAKwmjf,{'value': 'AFlow: Automating Agentic Workflow Generation'},Jiayi Zhang; Jinyu Xiang; Zhaoyang Yu; Fengwei Teng; Xiong-Hui Chen; Jiaqi Chen; Mingchen Zhuge; Xin Cheng; Sirui Hong; Jinlin Wang; Bingnan Zheng; Bang Liu; Yuyu Luo; Chenglin Wu,~Jiayi_Zhang7; ~Jinyu_Xiang1; ~Zhaoyang_Yu4; ~Fengwei_Teng1; ~Xiong-Hui_Chen1; ~Jiaqi_Chen3; ~Mingchen_Zhuge2; ~Xin_Cheng6; ~Sirui_Hong1; ~Jinlin_Wang1; ~Bingnan_Zheng1; ~Bang_Liu1; ~Yuyu_Luo1; ~Chenglin_Wu2,{'value': ['LLM Agent; Prompt Optimization; Workflow Generation']},"{'value': ""Large language models (LLMs) have demonstrated remarkable potential in solving complex tasks across diverse domains, typically by employing agentic workflows that follow detailed instructions and operational sequences. However, constructing these workflows requires significant human effort, limiting scalability and generalizability. Recent research has sought to automate the generation and optimization of these workflows, but existing methods still rely on initial manual setup and fall short of achieving fully automated and effective workflow generation. To address this challenge, we reformulate workflow optimization as a search problem over code-represented workflows, where LLM-invoking nodes are connected by edges. We introduce AFLOW, an automated framework that efficiently explores this space using Monte Carlo Tree Search, iteratively refining workflows through code modification, tree-structured experience, and execution feedback. Empirical evaluations across six benchmark datasets demonstrate AFLOW's efficacy, yielding a 5.7% average improvement over state-of-the-art baselines. Furthermore, AFLOW enables smaller models to outperform GPT-4o on specific tasks at 4.55% of its inference cost in dollars. The code is available at https://github.com/FoundationAgents/AFlow.""}",https://openreview.net{'value': '/pdf/f74f4704961076008514f7af306d3a5e0a8fc87f.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=z2z9suDRjw,{'value': 'GOAL: A Generalist Combinatorial Optimization Agent Learner'},Darko Drakulic; Sofia Michel; Jean-Marc Andreoli,~Darko_Drakulic1; ~Sofia_Michel1; ~Jean-Marc_Andreoli2,"{'value': ['neural combinatorial optimization', 'generalist models', 'transfer learning', 'fine tuning']}","{'value': 'Machine Learning-based heuristics have recently shown impressive performance in solving a variety of hard combinatorial optimization problems (COPs). However they generally rely on a separate neural model, specialized and trained for each single problem. Any variation of a problem requires adjustment of its model and re-training from scratch. In this paper, we propose GOAL (for Generalist combinatorial Optimization Agent Learner), a generalist model capable of efficiently solving multiple COPs and which can be fine-tuned to solve new COPs. GOAL consists of a single backbone plus light-weight problem-specific adapters for input and output processing. The backbone is based on a new form of mixed-attention blocks which allows to handle problems defined on graphs with arbitrary combinations of node, edge and instance-level features. Additionally, problems which involve heterogeneous types of nodes or edges are handled through a novel multi-type transformer architecture, where the attention blocks are duplicated to attend the meaningful combinations of types while relying on the same shared parameters. We train GOAL on a set of routing, scheduling and classic graph problems and show that it is only slightly inferior to the specialized baselines while being the first multi-task model that solves a wide range of COPs. Finally we showcase the strong transfer learning capacity of GOAL by fine-tuning it on several new problems. Our code is available at https://github.com/naver/goal-co .'}",https://openreview.net{'value': '/pdf/99cd1d8f7cc0edc74d399bc4214243ee055a38b6.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=z21DkDDdgq,{'value': 'Integral Performance Approximation for Continuous-Time Reinforcement Learning Control'},Brent A. Wallace; Jennie Si,~Brent_A._Wallace1; ~Jennie_Si1,"{'value': ['Continuous-Time Reinforcement Learning (CT-RL)', 'Optimal Control', 'Integral Performance Approximation (IPA)', 'Adaptive/Approximate Dynamic Programming (ADP)', 'Flight Control', 'Hypersonic Vehicles (HSVs)']}","{'value': 'We introduce integral performance approximation (IPA), a new continuous-time reinforcement learning (CT-RL) control method. It leverages an affine nonlinear dynamic model, which partially captures the dynamics of the physical environment, alongside state-action trajectory data to enable optimal control with great data efficiency and robust control performance. Utilizing Kleinman algorithm structures allows IPA to provide theoretical guarantees of learning convergence, solution optimality, and closed-loop stability. Furthermore, we demonstrate the effectiveness of IPA on three CT-RL environments including hypersonic vehicle (HSV) control, which has additional challenges caused by unstable and nonminimum phase dynamics. As a result, we demonstrate that the IPA method leads to new, SOTA control design and performance in CT-RL.'}",https://openreview.net{'value': '/pdf/153fa1cd953ffc5241ad683e856078119438f14a.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=ywFOSIT9ik,{'value': 'Revisiting Zeroth-Order Optimization:  Minimum-Variance Two-Point Estimators and  Directionally Aligned Perturbations'},Shaocong Ma; Heng Huang,~Shaocong_Ma1; ~Heng_Huang1,"{'value': ['zeroth-order optimization', 'SGD', 'convergence analysis']}","{'value': ""In this paper, we explore the two-point zeroth-order gradient estimator and identify the distribution of random perturbations that minimizes the estimator's asymptotic variance as the perturbation stepsize tends to zero. We formulate it as a constrained functional optimization problem over the space of perturbation distributions. Our findings reveal that such desired perturbations can align directionally with the true gradient, instead of maintaining a fixed length. While existing research has largely focused on fixed-length perturbations, the potential advantages of directional alignment have been overlooked. To address this gap, we delve into the theoretical and empirical properties of the directionally aligned perturbation (DAP) scheme, which adaptively offers higher accuracy along critical directions. Additionally, we provide a convergence analysis for stochastic gradient descent using $\\delta$-unbiased random perturbations, extending existing complexity bounds to a wider range of perturbations. Through empirical evaluations on both synthetic problems and practical tasks, we demonstrate that DAPs outperform traditional methods under specific conditions.""}",https://openreview.net{'value': '/pdf/39283ec0132dc70ec96da291419e3fec623c62d3.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=yitH9xAHQs,{'value': 'Forewarned is Forearmed:  Harnessing LLMs for Data Synthesis via Failure-induced Exploration'},Qintong Li; Jiahui Gao; Sheng Wang; Renjie Pi; Xueliang Zhao; Chuan Wu; Xin Jiang; Zhenguo Li; Lingpeng Kong,~Qintong_Li1; ~Jiahui_Gao2; ~Sheng_Wang12; ~Renjie_Pi1; ~Xueliang_Zhao1; ~Chuan_Wu1; ~Xin_Jiang1; ~Zhenguo_Li1; ~Lingpeng_Kong1,"{'value': ['data synthesis', 'preference learning', 'LLM alignment']}","{'value': ""Large language models (LLMs) have significantly benefited from training on diverse, high-quality task-specific data, leading to impressive performance across a range of downstream applications. Current methods often rely on human-annotated data or predefined task templates to direct powerful LLMs in synthesizing task-relevant data for effective model training. However, this dependence on manually designed components may constrain the scope of generated data, potentially overlooking critical edge cases or novel scenarios that could challenge the model. In this paper, we present a novel approach, ReverseGen, designed to automatically generate effective training samples that expose the weaknesses of LLMs. Specifically, we introduce a dedicated proposer trained to produce queries that lead target models to generate unsatisfactory responses.  These failure-inducing queries are then used to construct training data, helping to address the models' shortcomings and improve overall performance. Our approach is flexible and can be applied to models of various scales (3B, 7B, and 8B). We evaluate ReverseGen on three key applications—safety, honesty, and math—demonstrating that our generated data is both highly effective and diverse. Models fine-tuned with ReverseGen-generated data consistently outperform those trained on human-annotated or general model-generated data, offering a new perspective on data synthesis for task-specific LLM enhancement.""}",https://openreview.net{'value': '/pdf/f6ddb5533a9baf6bdcaac50e9a3ae3f2ae5f1221.pdf'},{'title_filter': 'Data Synthesis'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=yheQRc5xWB,{'value': 'Effective and Efficient Time-Varying Counterfactual Prediction with State-Space Models'},Haotian Wang; Haoxuan Li; Hao Zou; Haoang Chi; Long Lan; Wanrong Huang; Wenjing Yang,~Haotian_Wang2; ~Haoxuan_Li6; ~Hao_Zou1; ~Haoang_Chi1; ~Long_Lan2; ~Wanrong_Huang1; ~Wenjing_Yang1,{'value': ['Time Series; State-space Models; Treatment Effect Estimation']},"{'value': 'Time-varying counterfactual prediction (TCP) from observational data supports the answer of when and how to assign multiple sequential treatments, yielding importance in various applications. Despite the progress achieved by recent advances, e.g., LSTM or Transformer based causal approaches, their capability of capturing interactions in long sequences remains to be improved in both prediction performance and running efficiency. In parallel with the development of TCP, the success of the state-space models (SSMs) has achieved remarkable progress toward long-sequence modeling with saved running time. Consequently, studying how Mamba simultaneously benefits the effectiveness and efficiency of TCP  becomes a compelling research direction. In this paper, we propose to exploit advantages of the SSMs to tackle the TCP task, by introducing a counterfactual Mamba model with Covariate-based Decorrelation towards Selective Parameters (Mamba-CDSP). Motivated by the over-balancing problem in TCP of the direct covariate balancing methods, we propose to de-correlate between the current treatment and the representation of historical covariates, treatments, and outcomes, which can mitigate the confounding bias while preserve more covariate information. In addition, we show that the overall de-correlation in TCP is equivalent to regularizing the selective parameters of Mamba over each time step, which leads our approach to be effective and lightweight. We conducted extensive experiments on both synthetic and real-world datasets, demonstrating that Mamba-CDSP not only outperforms baselines by a large margin, but also exhibits prominent running efficiency.'}",https://openreview.net{'value': '/pdf/6543649eb8bf53c6ca75c251a0032d3e63a00c35.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=ydREOIttdC,{'value': 'Federated Class-Incremental Learning: A Hybrid Approach Using Latent Exemplars and Data-Free Techniques to Address Local and Global Forgetting'},Milad Khademi Nori; IL MIN KIM; Guanghui Wang,~Milad_Khademi_Nori1; ~IL_MIN_KIM1; ~Guanghui_Wang8,"{'value': ['Class-Incremental Learning', 'Federated Learning', 'Global Forgetting', 'Local Forgetting.']}","{'value': 'Federated Class-Incremental Learning (FCIL) refers to a scenario where a dynamically changing number of clients collaboratively learn an ever-increasing number of incoming tasks. FCIL is known to suffer from local forgetting due to class imbalance at each client and global forgetting due to class imbalance across clients. We develop a mathematical framework for FCIL that formulates local and global forgetting. Then, we propose an approach called Hybrid Rehearsal (HR), which utilizes latent exemplars and data-free techniques to address local and global forgetting, respectively. HR employs a customized autoencoder designed for both data classification and the generation of synthetic data. To determine the embeddings of new tasks for all clients in the latent space of the encoder, the server uses the Lennard-Jones Potential formulations. Meanwhile, at the clients, the decoder decodes the stored low-dimensional latent space exemplars back to the high-dimensional input space, used to address local forgetting. To overcome global forgetting, the decoder generates synthetic data. Furthermore, our mathematical framework proves that our proposed approach HR can, in principle, tackle the two local and global forgetting challenges. In practice, extensive experiments demonstrate that while preserving privacy, our proposed approach outperforms the state-of-the-art baselines on multiple FCIL benchmarks with low compute and memory footprints.'}",https://openreview.net{'value': '/pdf/0bd8edd3733d5bcde75484240571a6d4bbf8ae76.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=yLhJYvkKA0,{'value': 'On the Price of Differential Privacy for Hierarchical Clustering'},Chengyuan Deng; Jie Gao; Jalaj Upadhyay; Chen Wang; Samson Zhou,~Chengyuan_Deng1; ~Jie_Gao6; ~Jalaj_Upadhyay1; ~Chen_Wang14; ~Samson_Zhou1,"{'value': ['Hierarchical clustering', 'differential privacy', 'sparsest cut']}","{'value': ""Hierarchical clustering is a fundamental unsupervised machine learning task with the aim of organizing data into a hierarchy of clusters. Many applications of hierarchical clustering involve sensitive user information, therefore motivating recent studies on differentially private hierarchical clustering under the rigorous framework of Dasgupta's objective. However, it has been shown that any privacy-preserving algorithm under edge-level differential privacy necessarily suffers a large error. To capture practical applications of this problem, we focus on the weight privacy model, where each edge of the input graph is at least unit weight. We present a novel algorithm in the weight privacy model that shows significantly better approximation than known impossibility results in the edge-level DP setting. In particular, our algorithm achieves $O(\\log^{1.5}n/\\varepsilon)$ multiplicative error for $\\varepsilon$-DP and runs in polynomial time, where $n$ is the size of the input graph, and the cost is never worse than the optimal additive error in existing work. We complement our algorithm by showing if the unit-weight constraint does not apply, the lower bound for weight-level DP hierarchical clustering is essentially the same as the edge-level DP, i.e. $\\Omega(n^2/\\varepsilon)$ additive error. As a result, we also obtain a new lower bound of $\\tilde{\\Omega}(1/\\varepsilon)$ additive error for balanced sparsest cuts in the weight-level DP model, which may be of independent interest. Finally, we evaluate our algorithm on synthetic and real-world datasets. Our experimental results show that our algorithm performs well in terms of extra cost and has good scalability to large graphs.""}",https://openreview.net{'value': '/pdf/38210298adf46e3b705b8e109c6eaaabe7b1f726.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=yIlyHJdYV3,{'value': 'A Unified Framework for Forward and Inverse Problems in Subsurface Imaging using Latent Space Translations'},Naveen Gupta; Medha Sawhney; Arka Daw; Youzuo Lin; Anuj Karpatne,~Naveen_Gupta1; ~Medha_Sawhney1; ~Arka_Daw1; ~Youzuo_Lin1; ~Anuj_Karpatne1,"{'value': ['Machine Learning', 'Inverse Problems', 'Full-Waveform Inversion', 'Seismic Imaging', 'ML4Science', 'OpenFWI']}","{'value': 'In subsurface imaging, learning the mapping from velocity maps to seismic waveforms (forward problem) and waveforms to velocity (inverse problem) is important for several applications. While traditional techniques for solving forward and inverse problems are computationally prohibitive, there is a growing interest to leverage recent advances in deep learning to learn the mapping between velocity maps and seismic waveform images directly from data. Despite the variety of architectures explored in previous works, several open questions still remain unanswered such as the effect of latent space sizes, the importance of manifold learning, the complexity of translation models, and the value of jointly solving forward and inverse problems. We propose a unified framework to systematically characterize prior research in this area termed the Generalized Forward-Inverse (GFI) framework, building on the assumption of manifolds and latent space translations. We show that GFI encompasses previous works in deep learning for subsurface imaging, which can be viewed as specific instantiations of GFI. We also propose two new model architectures within the framework of GFI: Latent U-Net and Invertible X-Net, leveraging the power of U-Nets for domain translation and the ability of IU-Nets to simultaneously learn forward and inverse translations, respectively. We show that our proposed models achieve state-of-the-art (SOTA) performance for forward and inverse problems on a wide range of synthetic datasets, and also investigate their zero-shot effectiveness on two real-world-like datasets. The code is available at https://github.com/KGML-lab/Generalized-Forward-Inverse-Framework-for-DL4SI'}",https://openreview.net{'value': '/pdf/3f96524c3a1baecbe5c67ffe2ef6be3a87a7fcc8.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=y9A2TpaGsE,{'value': 'Language Agents Meet Causality -- Bridging LLMs and Causal World Models'},John Gkountouras; Matthias Lindemann; Phillip Lippe; Efstratios Gavves; Ivan Titov,~John_Gkountouras1; ~Matthias_Lindemann1; ~Phillip_Lippe1; ~Efstratios_Gavves1; ~Ivan_Titov1,"{'value': ['Large Language Models', 'Causality', 'Causal Representation Learning', 'Language Agents', 'Planning']}","{'value': 'Large Language Models (LLMs) have recently shown great promise in planning and reasoning applications. These tasks demand robust systems, which arguably require a causal understanding of the environment. While LLMs can acquire and reflect common sense causal knowledge from their pretraining data, this information is often incomplete, incorrect, or inapplicable to a specific environment. In contrast, causal representation learning (CRL) focuses on identifying the underlying causal structure within a given environment. We propose a framework that integrates CRLs with LLMs to enable causally-aware reasoning and planning. This framework learns a causal world model, with causal variables linked to natural language expressions. This mapping provides LLMs with a flexible interface to process and generate descriptions of actions and states in text form. Effectively, the causal world model acts as a simulator that the LLM can query and interact with. We evaluate the framework on causal inference and planning tasks across temporal scales and environmental complexities. Our experiments demonstrate the effectiveness of the approach, with the causally-aware method outperforming LLM-based reasoners, especially for longer planning horizons.'}",https://openreview.net{'value': '/pdf/00f503aae18d3c78d251d2fba1dfabd0aab10547.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=y80D4IojuY,{'value': 'Agent-to-Sim: Learning Interactive Behavior Models from Casual Longitudinal Videos'},Gengshan Yang; Andrea Bajcsy; Shunsuke Saito; Angjoo Kanazawa,~Gengshan_Yang1; ~Andrea_Bajcsy1; ~Shunsuke_Saito1; ~Angjoo_Kanazawa1,{'value': ['dynamic 3d reconstruction; multi-video registration; motion generation']},"{'value': 'We present Agent-to-Sim (ATS), a framework for learning interactive behavior models of 3D agents from casual longitudinal video collections. Different from prior works that rely on marker-based tracking and multiview cameras, ATS learns natural behaviors of animal agents non-invasively through video observations recorded over a long time-span (e.g. a month) in a single environment.\nModeling 3D behavior of an agent requires persistent 3D tracking (e.g., knowing which point corresponds to which) over a long time period. To obtain such data, we develop a coarse-to-fine registration method that tracks the agent and the camera over time through a canonical 3D space, resulting in a complete and persistent spacetime 4D representation. We then train a generative model of agent behaviors using paired data of perception and motion of an agent queried from the 4D reconstruction. ATS enables real-to-sim transfer from video recordings of an agent to an interactive behavior simulator. We demonstrate results on animals given monocular RGBD videos captured by a smartphone. Project page: gengshan-y.github.io/agent2sim-www.'}",https://openreview.net{'value': '/pdf/820d935ac808829b5fa49bdd152286c2ae6c3054.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=y5einmJ0Yx,{'value': 'GOLD: Graph Out-of-Distribution Detection via Implicit Adversarial Latent Generation'},Danny Wang; Ruihong Qiu; Guangdong Bai; Zi Huang,~Danny_Wang1; ~Ruihong_Qiu1; ~Guangdong_Bai1; ~Zi_Huang1,"{'value': ['Graph Neural Network', 'Out-of-Distribution Detection']}","{'value': ""Despite graph neural networks' (GNNs) great success in modelling graph-structured data, out-of-distribution (OOD) test instances still pose a great challenge for current GNNs. One of the most effective techniques to detect OOD nodes is to expose the detector model with an additional OOD node-set, yet the extra OOD instances are often difficult to obtain in practice. Recent methods for image data address this problem using OOD data synthesis, typically relying on pre-trained generative models like Stable Diffusion. However, these approaches require vast amounts of additional data, as well as one-for-all pre-trained generative models, which are not available for graph data. Therefore, we propose the GOLD framework for graph OOD detection, an implicit adversarial learning pipeline with synthetic OOD exposure without pre-trained models. The implicit adversarial training process employs a novel alternating optimisation framework by training: (1) a latent generative model to regularly imitate the in-distribution (ID) embeddings from an evolving GNN, and (2) a GNN encoder and an OOD detector to accurately classify ID data while increasing the energy divergence between the ID embeddings and the generative model's synthetic embeddings. This novel approach implicitly transforms the synthetic embeddings into pseudo-OOD instances relative to the ID data, effectively simulating exposure to OOD scenarios without auxiliary data. Extensive OOD detection experiments are conducted on five benchmark graph datasets, verifying the superior performance of GOLD without using real OOD data compared with the state-of-the-art OOD exposure and non-exposure baselines.""}",https://openreview.net{'value': '/pdf/39eb705848ec980c91abc140e0ede0d370055dee.pdf'},{'abstract_filter': 'Data Synthesis'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=y3zswp3gek,{'value': 'HarmAug: Effective Data Augmentation for Knowledge Distillation of Safety Guard Models'},Seanie Lee; Haebin Seong; Dong Bok Lee; Minki Kang; Xiaoyin Chen; Dominik Wagner; Yoshua Bengio; Juho Lee; Sung Ju Hwang,~Seanie_Lee1; ~Haebin_Seong1; ~Dong_Bok_Lee1; ~Minki_Kang1; ~Xiaoyin_Chen1; ~Dominik_Wagner2; ~Yoshua_Bengio1; ~Juho_Lee2; ~Sung_Ju_Hwang1,"{'value': ['knowledge distillation', 'safety guard']}","{'value': 'Safety guard models that detect malicious queries aimed at large language models (LLMs) are essential for ensuring the secure and responsible deployment of LLMs in real-world applications.\nHowever, deploying existing safety guard models with billions of parameters alongside LLMs on mobile devices is impractical due to substantial memory requirements and latency.\nTo reduce this cost, we distill a large teacher safety guard model into a smaller one using a labeled dataset of instruction-response pairs with binary harmfulness labels. Due to the limited diversity of harmful instructions in  the existing labeled dataset, naively distilled models tend to underperform compared to larger models. To bridge the gap between small and large models, we propose **HarmAug**, a simple yet effective data augmentation method that involves jailbreaking an LLM and prompting it to generate harmful instructions. Given a prompt such as, ""Make a single harmful instruction prompt that would elicit offensive content"", we add an affirmative prefix (e.g., ""I have an idea for a prompt:"") to the LLM\'s response. This encourages the LLM to continue generating the rest of the response, leading to sampling harmful instructions. Another LLM generates a response to the harmful instruction, and the teacher model labels the instruction-response pair. We empirically show that our HarmAug outperforms other relevant baselines. Moreover, a 435-million-parameter safety guard model trained with HarmAug achieves an F1 score comparable to larger models  with over 7 billion parameters, and even outperforms them in AUPRC, while operating at less than 25\\% of their computational cost. Our [code](https://anonymous.4open.science/r/HarmAug/), [safety guard model](https://huggingface.co/AnonHB/HarmAug_Guard_Model_deberta_v3_large_finetuned), and  [synthetic dataset](https://huggingface.co/datasets/AnonHB/HarmAug_generated_dataset) are publicly available.'}",https://openreview.net{'value': '/pdf/5287a7158eaa6304ebe2aebf3d0d5438039c1006.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=xKDZAW0He3,{'value': 'SeCom: On Memory Construction and Retrieval for Personalized Conversational Agents'},Zhuoshi Pan; Qianhui Wu; Huiqiang Jiang; Xufang Luo; Hao Cheng; Dongsheng Li; Yuqing Yang; Chin-Yew Lin; H. Vicky Zhao; Lili Qiu; Jianfeng Gao,~Zhuoshi_Pan2; ~Qianhui_Wu1; ~Huiqiang_Jiang2; ~Xufang_Luo1; ~Hao_Cheng4; ~Dongsheng_Li2; ~Yuqing_Yang1; ~Chin-Yew_Lin1; ~H._Vicky_Zhao1; ~Lili_Qiu3; ~Jianfeng_Gao1,"{'value': ['memory management', 'conversational agent', 'RAG', 'text segmentation', 'prompt compression']}","{'value': 'To deliver coherent and personalized experiences in long-term conversations, existing approaches typically perform retrieval augmented response generation by constructing memory banks from conversation history at either the turn-level, session-level, or through summarization techniques.\nIn this paper, we explore the impact of different memory granularities and present two key findings: (1) Both turn-level and session-level memory units are suboptimal, affecting not only the quality of final responses, but also the accuracy of the retrieval process.\n(2) The redundancy in natural language introduces noise, hindering precise retrieval. We demonstrate that *LLMLingua-2*, originally designed for prompt compression to accelerate LLM inference, can serve as an effective denoising method to enhance memory retrieval accuracy.\n\nBuilding on these insights, we propose **SeCom**, a method that constructs a memory bank with topical segments by introducing a conversation **Se**gmentation model, while performing memory retrieval based on **Com**pressed memory units.\nExperimental results show that **SeCom** outperforms turn-level, session-level, and several summarization-based methods on long-term conversation benchmarks such as *LOCOMO* and *Long-MT-Bench+*. Additionally, the proposed conversation segmentation method demonstrates superior performance on dialogue segmentation datasets such as *DialSeg711*, *TIAGE*, and *SuperDialSeg*.'}",https://openreview.net{'value': '/pdf/c3fb51ba6be1adccb1010200f1546807e78f36b4.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=xByvdb3DCm,{'value': 'When Selection Meets Intervention: Additional Complexities in Causal Discovery'},Haoyue Dai; Ignavier Ng; Jianle Sun; Zeyu Tang; Gongxu Luo; Xinshuai Dong; Peter Spirtes; Kun Zhang,~Haoyue_Dai1; ~Ignavier_Ng1; ~Jianle_Sun1; ~Zeyu_Tang1; ~Gongxu_Luo1; ~Xinshuai_Dong1; ~Peter_Spirtes1; ~Kun_Zhang1,"{'value': ['causal discovery', 'selection bias', 'experiments', 'interventions']}","{'value': 'We address the common yet often-overlooked selection bias in interventional studies, where subjects are selectively enrolled into experiments. For instance, participants in a drug trial are usually patients of the relevant disease; A/B tests on mobile applications target existing users only, and gene perturbation studies typically focus on specific cell types, such as cancer cells. Ignoring this bias leads to incorrect causal discovery results. Even when recognized, the existing paradigm for interventional causal discovery still fails to address it. This is because subtle differences in _when_ and _where_ interventions happen can lead to significantly different statistical patterns. We capture this dynamic by introducing a graphical model that explicitly accounts for both the observed world (where interventions are applied) and the counterfactual world (where selection occurs while interventions have not been applied). We characterize the Markov property of the model, and propose a provably sound algorithm to identify causal relations as well as selection mechanisms up to the equivalence class, from data with soft interventions and unknown targets. Through synthetic and real-world experiments, we demonstrate that our algorithm effectively identifies true causal relations despite the presence of selection bias.'}",https://openreview.net{'value': '/pdf/7277084945a82f890a2c071e3d3f0ed7331e496e.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=x83w6yGIWb,{'value': 'Beware of Calibration Data for Pruning Large Language Models'},Yixin Ji; Yang Xiang; Juntao Li; Qingrong Xia; Ping Li; Xinyu Duan; Zhefeng Wang; Min Zhang,~Yixin_Ji2; ~Yang_Xiang6; ~Juntao_Li2; ~Qingrong_Xia1; ~Ping_Li16; ~Xinyu_Duan1; ~Zhefeng_Wang1; ~Min_Zhang9,"{'value': ['calibration data', 'post-training pruning', 'large language models']}","{'value': 'As large language models (LLMs) are widely applied across various fields, model\ncompression has become increasingly crucial for reducing costs and improving\ninference efficiency. Post-training pruning is a promising method that does not\nrequire resource-intensive iterative training and only needs a small amount of\ncalibration data to assess the importance of parameters. Recent research has enhanced post-training pruning from different aspects but few of them systematically\nexplore the effects of calibration data, and it is unclear if there exist better calibration data construction strategies. We fill this blank and surprisingly observe that\ncalibration data is also crucial to post-training pruning, especially for high sparsity. Through controlled experiments on important influence factors of calibration\ndata, including the pruning settings, the amount of data, and its similarity with\npre-training data, we observe that a small size of data is adequate, and more similar data to its pre-training stage can yield better performance. As pre-training data\nis usually inaccessible for advanced LLMs, we further provide a self-generating\ncalibration data synthesis strategy to construct feasible calibration data. Experimental results on recent strong open-source LLMs (e.g., DCLM, and LLaMA-3)\nshow that the proposed strategy can enhance the performance of strong pruning\nmethods (e.g., Wanda, DSnoT, OWL) by a large margin (up to 2.68%).'}",https://openreview.net{'value': '/pdf/75e829c0ab0ccd4d7b93f8eabc80e93e243e1ee9.pdf'},{'abstract_filter': 'Data Synthesis'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=x1Okv4kbVR,{'value': 'MACPO: Weak-to-Strong Alignment via Multi-Agent Contrastive Preference Optimization'},Yougang Lyu; Lingyong Yan; Zihan Wang; Dawei Yin; Pengjie Ren; Maarten de Rijke; Zhaochun Ren,~Yougang_Lyu1; ~Lingyong_Yan1; ~Zihan_Wang13; ~Dawei_Yin1; ~Pengjie_Ren1; ~Maarten_de_Rijke1; ~Zhaochun_Ren1,"{'value': ['weak-to-strong alignment', 'preference optimization']}","{'value': ""As large language models (LLMs) are rapidly advancing and achieving near-human capabilities on specific tasks, aligning them with human values is becoming more urgent. In scenarios where LLMs outperform humans, we face a weak-to-strong alignment problem where we need to effectively align strong student LLMs through weak supervision generated by weak teachers. Existing alignment methods mainly focus on strong-to-weak alignment and self-alignment settings, and it is impractical to adapt them to the much harder weak-to-strong alignment setting. To fill this gap, we propose a multi-agent contrastive preference optimization (MACPO) framework. MACPO facilitates weak teachers and strong students to learn from each other by iteratively reinforcing unfamiliar positive behaviors while penalizing familiar negative ones. To get this, we devise a mutual positive behavior augmentation strategy to encourage weak teachers and strong students to learn from each other's positive behavior and further provide higher quality positive behavior for the next iteration. Additionally, we propose a hard negative behavior construction strategy to induce weak teachers and strong students to generate familiar negative behavior by fine-tuning on negative behavioral data. Experimental results on the HH-RLHF and PKU-SafeRLHF datasets, evaluated using both automatic metrics and human judgments, demonstrate that MACPO simultaneously improves the alignment performance of strong students and weak teachers. Moreover, as the number of weak teachers increases, MACPO achieves better weak-to-strong alignment performance through more iteration optimization rounds.""}",https://openreview.net{'value': '/pdf/57cf5e8d20d0b8da528a8675dac3d0605a3f3467.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=ws5phQki00,{'value': 'The Power of LLM-Generated Synthetic Data for Stance Detection in Online Political Discussions'},Stefan Sylvius Wagner; Maike Behrendt; Marc Ziegele; Stefan Harmeling,~Stefan_Sylvius_Wagner1; ~Maike_Behrendt1; ~Marc_Ziegele1; ~Stefan_Harmeling1,"{'value': ['large language models', 'stance detection', 'data augmentation', 'active learning', 'online political discussions']}","{'value': 'Stance detection holds great potential to improve online political discussions through its deployment in discussion platforms for purposes such as content moderation, topic summarisation or to facilitate more balanced discussions. Typically, transformer-based models are employed directly for stance detection, requiring vast amounts of data. However, the wide variety of debate topics in online political discussions makes data collection particularly challenging. LLMs have revived stance detection, but their online deployment in online political discussions faces challenges like inconsistent outputs, biases, and vulnerability to adversarial attacks. We show how LLM-generated synthetic data can improve stance detection for online political discussions by using reliable traditional stance detection models for online deployment, while leveraging the text generation capabilities of LLMs for synthetic data generation in a secure offline environment. To achieve this, (i) we generate synthetic data for specific debate questions by prompting a Mistral-7B model and show that fine-tuning with the generated synthetic data can substantially improve the performance of stance detection, while remaining interpretable and aligned with real world data. (ii) Using the synthetic data as a reference, we can improve performance even further by identifying the most informative samples in an unlabelled dataset, i.e., those samples which the stance detection model is most uncertain about and can benefit from the most. By fine-tuning with both synthetic data and the most informative samples, we surpass the performance of the baseline model that is fine-tuned on all true labels, while labelling considerably less data.'}",https://openreview.net{'value': '/pdf/5b56a56d8a30ca36a3662831fa3394f290a4450f.pdf'},{'title_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=womU9cEwcO,{'value': 'Scaling Autonomous Agents via Automatic Reward Modeling And Planning'},Zhenfang Chen; Delin Chen; Rui Sun; Wenjun Liu; Chuang Gan,~Zhenfang_Chen1; ~Delin_Chen1; ~Rui_Sun10; ~Wenjun_Liu2; ~Chuang_Gan1,"{'value': ['agents', 'large language models', 'planning']}","{'value': ""Large language models (LLMs) have demonstrated remarkable capabilities across a range of text-generation tasks. However, LLMs still struggle with problems requiring multi-step decision-making and environmental feedback, such as online shopping, scientific reasoning, and mathematical problem-solving. Unlike pure text data, collecting large-scale decision-making data is challenging. Moreover, many powerful LLMs are only accessible through APIs, which hinders their fine-tuning for agent tasks due to cost and complexity. To address LLM agents' limitations, we propose a framework that can automatically learn a reward model from the environment without human annotations. This model can be used to evaluate the action trajectories of LLM agents and provide heuristics for task planning. Specifically, our approach involves employing one LLM-based agent to navigate an environment randomly, generating diverse action trajectories. Subsequently, a separate LLM is leveraged to assign a task intent and synthesize a negative response alongside the correct response for each trajectory. These triplets (task intent, positive response, and negative response) are then utilized as training data to optimize a reward model capable of scoring action trajectories. This reward model can be integrated with LLM-based agents and various planning algorithms to enhance task-solving performance. The effectiveness and generalizability of our framework are demonstrated through evaluations conducted on different agent benchmarks. In conclusion, our proposed framework represents a significant advancement in enhancing LLM agents' decision-making capabilities. By automating the learning of reward models, we overcome the challenges of data scarcity and API limitations, potentially revolutionizing the application of LLMs in complex and interactive environments. This research paves the way for more sophisticated AI agents capable of tackling a wide range of real-world problems requiring multi-step decision-making.""}",https://openreview.net{'value': '/pdf/2e80722accee39cc682c0533a9da38147749b8c5.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=wmV4cIbgl6,{'value': 'CausalRivers - Scaling up benchmarking of causal discovery for real-world time-series'},Gideon Stein; Maha Shadaydeh; Jan Blunk; Niklas Penzel; Joachim Denzler,~Gideon_Stein1; ~Maha_Shadaydeh1; ~Jan_Blunk1; ~Niklas_Penzel1; ~Joachim_Denzler2,"{'value': ['Causal Discovery', 'Benchmarking', 'Time-series']}","{'value': 'Causal discovery, or identifying causal relationships from observational data, is a notoriously challenging task, with numerous methods proposed to tackle it.\nDespite this, in-the-wild evaluation of these methods is still lacking, as works frequently rely on synthetic data evaluation and sparse real-world examples under critical theoretical assumptions.\nReal-world causal structures, however, are often complex, evolving over time, non-linear, and influenced by unobserved factors, making\nit hard to decide on a proper causal discovery strategy.\nTo bridge this gap, we introduce CausalRivers, the largest in-the-wild causal discovery benchmarking kit for time-series data to date.\nCausalRivers features an extensive dataset on river discharge that covers the eastern German territory (666 measurement stations) and the state of Bavaria (494  measurement stations).\nIt spans the years 2019 to 2023 with a 15-minute temporal resolution.\nFurther, we provide additional data from a flood around the Elbe River, as an event with a pronounced distributional shift.\nLeveraging multiple sources of information and time-series meta-data, we constructed two distinct causal ground truth graphs (Bavaria and eastern Germany).\nThese graphs can be sampled to generate thousands of subgraphs to benchmark causal discovery across diverse and challenging settings.\nTo demonstrate the utility of CausalRivers, we evaluate several causal discovery approaches through a set of experiments to identify areas for improvement.\nCausalRivers has the potential to facilitate robust evaluations and comparisons of causal discovery methods.\nBesides this primary purpose, we also expect that this dataset will be relevant for connected areas of research, such as time-series forecasting and anomaly detection.\nBased on this, we hope to push benchmark-driven method development that fosters advanced techniques for causal discovery, as is the case for many other areas of machine learning.'}",https://openreview.net{'value': '/pdf/9e2d78f69adc943b9678eb239ad4bb343c693b0a.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=wXSshrxlP4,{'value': 'GrabS: Generative Embodied Agent for 3D Object Segmentation without Scene Supervision'},Zihui Zhang; Yafei YANG; Hongtao Wen; Bo Yang,~Zihui_Zhang2; ~Yafei_YANG1; ~Hongtao_Wen1; ~Bo_Yang7,"{'value': ['3D scene object segmentation', 'unsupervised learning']}","{'value': 'We study the hard problem of 3D object segmentation in complex point clouds\nwithout requiring human labels of 3D scenes for supervision. By relying on the\nsimilarity of pretrained 2D features or external signals such as motion to group 3D\npoints as objects, existing unsupervised methods are usually limited to identifying\nsimple objects like cars or their segmented objects are often inferior due to the\nlack of objectness in pretrained features. In this paper, we propose a new two-\nstage pipeline called GrabS. The core concept of our method is to learn generative\nand discriminative object-centric priors as a foundation from object datasets in the\nfirst stage, and then design an embodied agent to learn to discover multiple ob-\njects by querying against the pretrained generative priors in the second stage. We\nextensively evaluate our method on two real-world datasets and a newly created\nsynthetic dataset, demonstrating remarkable segmentation performance, clearly\nsurpassing all existing unsupervised methods.'}",https://openreview.net{'value': '/pdf/7f130103b3e18b9bc5954f616187428a2d861351.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=wM2sfVgMDH,{'value': 'Diffusion-Based Planning for Autonomous Driving with Flexible Guidance'},Yinan Zheng; Ruiming Liang; Kexin ZHENG; Jinliang Zheng; Liyuan Mao; Jianxiong Li; Weihao Gu; Rui Ai; Shengbo Eben Li; Xianyuan Zhan; Jingjing Liu,~Yinan_Zheng1; ~Ruiming_Liang1; ~Kexin_ZHENG2; ~Jinliang_Zheng1; ~Liyuan_Mao2; ~Jianxiong_Li1; ~Weihao_Gu1; ~Rui_Ai2; ~Shengbo_Eben_Li2; ~Xianyuan_Zhan1; ~Jingjing_Liu2,"{'value': ['diffusion planning', 'autonomous driving']}","{'value': 'Achieving human-like driving behaviors in complex open-world environments is a critical challenge in autonomous driving. Contemporary learning-based planning approaches such as imitation learning methods often struggle to balance competing objectives and lack of safety assurance,due to limited adaptability and inadequacy in learning complex multi-modal behaviors commonly exhibited in human planning, not to mention their strong reliance on the fallback strategy with predefined rules. We propose a novel transformer-based Diffusion Planner for closed-loop planning, which can effectively model multi-modal driving behavior and ensure trajectory quality without any rule-based refinement. Our model supports joint modeling of both prediction and planning tasks under the same architecture, enabling cooperative behaviors between vehicles. Moreover, by learning the gradient of the trajectory score function and employing a flexible classifier guidance mechanism, Diffusion Planner effectively achieves safe and adaptable planning behaviors. Evaluations on the large-scale real-world autonomous planning benchmark nuPlan and our newly collected 200-hour delivery-vehicle driving dataset demonstrate that Diffusion Planner achieves state-of-the-art closed-loop performance with robust transferability in diverse driving styles.'}",https://openreview.net{'value': '/pdf/b6398cace84eddf279b77ad79b2c27e3bdf9d137.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=wLmJIs1uqG,{'value': 'LancBiO: Dynamic Lanczos-aided Bilevel Optimization via Krylov Subspace'},Yan Yang; Bin Gao; Ya-xiang Yuan,~Yan_Yang9; ~Bin_Gao6; ~Ya-xiang_Yuan1,"{'value': ['Bilevel Optimization', 'Lanczos Process', 'Krylov Subspace']}","{'value': 'Bilevel optimization, with broad applications in machine learning, has an intricate hierarchical structure. Gradient-based methods have emerged as a common approach to large-scale bilevel problems. However, the computation of the hyper-gradient, which involves a Hessian inverse vector product, confines the efficiency and is regarded as a bottleneck. To circumvent the inverse, we construct a sequence of low-dimensional approximate Krylov subspaces with the aid of the Lanczos process. As a result, the constructed subspace is able to dynamically and incrementally approximate the Hessian inverse vector product with less effort and thus leads to a favorable estimate of the hyper-gradient. Moreover, we propose a provable subspace-based framework for bilevel problems where one central step is to solve a small-size tridiagonal linear system. To the best of our knowledge, this is the first time that subspace techniques are incorporated into bilevel optimization. This successful trial not only enjoys $\\mathcal{O}(\\epsilon^{-1})$ convergence rate but also demonstrates efficiency in a synthetic problem and two deep learning tasks.'}",https://openreview.net{'value': '/pdf/47038e610785225d60962f21d5bd50e3082a0b4c.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=wHebuIb6IH,{'value': 'VLMaterial: Procedural Material Generation with Large Vision-Language Models'},Beichen Li; Rundi Wu; Armando Solar-Lezama; Changxi Zheng; Liang Shi; Bernd Bickel; Wojciech Matusik,~Beichen_Li1; ~Rundi_Wu1; ~Armando_Solar-Lezama1; ~Changxi_Zheng1; ~Liang_Shi9; ~Bernd_Bickel1; ~Wojciech_Matusik2,"{'value': ['generative model', 'procedural material', 'appearance modeling']}","{'value': 'Procedural materials, represented as functional node graphs, are ubiquitous in computer graphics for photorealistic material appearance design. They allow users to perform intuitive and precise editing to achieve desired visual appearances. However, creating a procedural material given an input image requires professional knowledge and significant effort. In this work, we leverage the ability to convert procedural materials into standard Python programs and fine-tune a large pre-trained vision-language model (VLM) to generate such programs from input images. To enable effective fine-tuning, we also contribute an open-source procedural material dataset and propose to perform program-level augmentation by prompting another pre-trained large language model (LLM). Through extensive evaluation, we show that our method outperforms previous methods on both synthetic and real-world examples.'}",https://openreview.net{'value': '/pdf/015530fec104e7e8799eb603036faefc8572e2ca.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=w5ZtXOzMeJ,{'value': 'Auto-GDA: Automatic Domain Adaptation for Efficient Grounding Verification in Retrieval-Augmented Generation'},Tobias Leemann; Periklis Petridis; Giuseppe Vietri; Dionysis Manousakas; Aaron Roth; Sergul Aydore,~Tobias_Leemann1; ~Periklis_Petridis1; ~Giuseppe_Vietri1; ~Dionysis_Manousakas1; ~Aaron_Roth1; ~Sergul_Aydore1,{'value': ['domain adaptation; NLI; RAG; document-grounded; NLP;']},"{'value': 'While retrieval-augmented generation (RAG) has been shown to enhance factuality of large language model (LLM) outputs, LLMs still suffer from hallucination, generating incorrect or irrelevant information. A common detection strategy involves prompting the LLM again to assess whether its response is grounded in the retrieved evidence, but this approach is costly. Alternatively, lightweight natural language inference (NLI) models for efficient grounding verification can be used at inference time. While existing pre-trained NLI models offer potential solutions, their performance remains subpar compared to larger models on realistic RAG inputs. RAG inputs are more complex than most datasets used for training NLI models and have characteristics specific to the underlying knowledge base, requiring adaptation of the NLI models to a specific target domain. Additionally, the lack of labeled instances in the target domain makes supervised domain adaptation, e.g., through fine-tuning, infeasible. To address these challenges, we introduce Automatic Generative Domain Adaptation (Auto-GDA). Our framework enables unsupervised domain adaptation through synthetic data generation.\nUnlike previous methods that rely on handcrafted filtering and augmentation strategies, Auto-GDA employs an iterative process to continuously improve the quality of generated samples using weak labels from less efficient teacher models and discrete optimization to select the most promising augmented samples. Experimental results demonstrate the effectiveness of our approach, with models fine-tuned on synthetic data using Auto-GDA often surpassing the performance of the teacher model and reaching the performance level of LLMs at 10% of their computational cost.'}",https://openreview.net{'value': '/pdf/eeb0e1394f036d1493a2f4478a9a3bf84733dabe.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=vyflgpwfJW,{'value': 'DiscoveryBench: Towards Data-Driven Discovery with Large Language Models'},Bodhisattwa Prasad Majumder; Harshit Surana; Dhruv Agarwal; Bhavana Dalvi Mishra; Abhijeetsingh Meena; Aryan Prakhar; Tirth Vora; Tushar Khot; Ashish Sabharwal; Peter Clark,~Bodhisattwa_Prasad_Majumder1; ~Harshit_Surana1; ~Dhruv_Agarwal2; ~Bhavana_Dalvi_Mishra2; ~Abhijeetsingh_Meena1; ~Aryan_Prakhar1; ~Tirth_Vora1; ~Tushar_Khot1; ~Ashish_Sabharwal1; ~Peter_Clark1,"{'value': ['scientific discovery', 'data-driven discovery', 'data analysis', 'large language models', 'hypothesis generation', 'hypothesis verification']}","{'value': 'Can the rapid advances in code generation, function calling, and data analysis using large language models (LLMs) help automate the search and verification of hypotheses purely from a set of provided datasets? To evaluate this question, we present DiscoveryBench, the first comprehensive benchmark that formalizes the multi-step process of data-driven discovery. The benchmark is designed to systematically assess current model capabilities in discovery tasks and provide a useful resource for improving them. Our benchmark contains 264 tasks collected across 6 diverse domains, such as sociology and engineering, by manually deriving discovery workflows from published papers to approximate the real-world challenges faced by researchers, where each task is defined by a dataset, its metadata, and a discovery goal in natural language. We additionally provide 903 synthetic tasks to conduct controlled evaluations on data-driven workflows that are not covered in the manually collected split. Furthermore, our structured formalism of data-driven discovery enables a facet-based evaluation that provides useful insights into different failure modes. We evaluate several popular LLM-based reasoning frameworks using both open and closed LLMs as baselines on DiscoveryBench and find that even the best system scores only 25%. Our benchmark, thus, illustrates the challenges in autonomous data-driven discovery and serves as a valuable resource for the community to make progress.'}",https://openreview.net{'value': '/pdf/86ad04ca338565e2886508ecd9de33292760d63b.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=vunPXOFmoi,{'value': 'Benchmarking Agentic Workflow Generation'},Shuofei Qiao; Runnan Fang; Zhisong Qiu; Xiaobin Wang; Ningyu Zhang; Yong Jiang; Pengjun Xie; Fei Huang; Huajun Chen,~Shuofei_Qiao1; ~Runnan_Fang1; ~Zhisong_Qiu1; ~Xiaobin_Wang1; ~Ningyu_Zhang1; ~Yong_Jiang1; ~Pengjun_Xie2; ~Fei_Huang2; ~Huajun_Chen1,"{'value': ['workflow generation', 'graph structured planning', 'large language model', 'agent']}","{'value': ""Large Language Models (LLMs), with their exceptional ability to handle a wide range of tasks, have driven significant advancements in tackling reasoning and planning tasks, wherein decomposing complex problems into executable workflows is a crucial step in this process. Existing workflow evaluation frameworks either focus solely on holistic performance or suffer from limitations such as restricted scenario coverage, simplistic workflow structures, and lax evaluation standards. To this end, we introduce WorfBench, a unified workflow generation benchmark with multi-faceted scenarios and intricate graph workflow structures. Additionally, we present WorfEval, a systemic evaluation protocol utilizing subsequence and subgraph matching algorithms to accurately quantify the LLM agent's workflow generation capabilities. Through comprehensive evaluations across different types of LLMs, we discover distinct gaps between the sequence planning capabilities and graph planning capabilities of LLM agents, with even GPT-4 exhibiting a gap of around 15%. We also train two open-source models and evaluate their generalization abilities on held-out tasks. Furthermore, we observe that the generated workflows can enhance downstream tasks, enabling them to achieve superior performance with less time during inference. Code and dataset are available at https://github.com/zjunlp/WorfBench.""}",https://openreview.net{'value': '/pdf/1d331e547b7dab39a01832803d3bcfd7ff5d447d.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=vodsIF3o7N,{'value': 'On the Modeling Capabilities of Large Language Models for Sequential Decision Making'},Martin Klissarov; R Devon Hjelm; Alexander T Toshev; Bogdan Mazoure,~Martin_Klissarov1; ~R_Devon_Hjelm1; ~Alexander_T_Toshev1; ~Bogdan_Mazoure1,"{'value': ['reinforcement learning', 'large language models', 'ai agents', 'preference based learning', 'reward design']}","{'value': 'Large pretrained models are showing increasingly better performance in reasoning and planning tasks across different modalities, opening the possibility to leverage them for complex sequential decision making problems. In this paper, we investigate the capabilities of Large Language Models (LLMs) for reinforcement learning (RL) across a diversity of interactive domains. We evaluate their ability to produce decision-making policies, either directly, by generating actions, or indirectly, by first generating reward models to train an agent with RL. Our results show that, even without task-specific fine-tuning, LLMs excel at reward modeling. In particular, crafting rewards through artificial intelligence (AI) feedback yields the most generally applicable approach and can enhance performance by improving credit assignment and exploration. Finally, in environments with unfamiliar dynamics, we explore how fine-tuning LLMs with synthetic data can significantly improve their reward modeling capabilities while mitigating catastrophic forgetting, further broadening their utility in sequential decision-making tasks.'}",https://openreview.net{'value': '/pdf/21bc4233891161329b1745351a8cb728e0c74b90.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=vkOFOUDLTn,{'value': 'Linear Multistep Solver Distillation for Fast Sampling of Diffusion Models'},Yuchen Liang; Xiangzhong Fang; Hanting Chen; Yunhe Wang,~Yuchen_Liang4; ~Xiangzhong_Fang2; ~Hanting_Chen1; ~Yunhe_Wang1,"{'value': ['Diffusion Probabilistic Model', 'Diffusion Sampler', 'Solver Schedule']}","{'value': 'Sampling from diffusion models can be seen as solving the corresponding \n   probability flow ordinary differential equation (ODE). \n   The solving process requires a significant number of function \n   evaluations (NFE), making it time-consuming. \n   Recently, several solver search frameworks have attempted to find \n   better-performing model-specific solvers. However, predicting the impact of \n   intermediate solving strategies on final sample quality remains challenging, \n   rendering the search process inefficient.\n   In this paper, we propose a novel method for designing \n   solving strategies. We first introduce a unified prediction formula \n   for linear multistep solvers. Subsequently, we present a solver distillation \n   framework, which enables a student solver to mimic the sampling trajectory \n   generated by a teacher solver with more steps. We utilize the mean Euclidean \n   distance between the student and teacher sampling trajectories as a metric, \n   facilitating rapid adjustment and optimization of intermediate solving strategies.\n   The design space of our framework encompasses multiple aspects, \n   including prediction coefficients, time step schedules, and time scaling \n   factors. \n   Our framework has the ability to complete a solver search \n   for Stable-Diffusion in under 12 total GPU hours.\n   Compared to previous reinforcement learning-based \n   search frameworks, \n   our approach achieves over a 10$\\times$ increase in search efficiency. \n   With just 5 NFE, we achieve FID scores of 3.23 on CIFAR10, 7.16 on ImageNet-64, \n   5.44 on LSUN-Bedroom, and 12.52 on MS-COCO, resulting in a 2$\\times$ sampling acceleration ratio \n   compared to handcrafted solvers.'}",https://openreview.net{'value': '/pdf/62b966902115d3d2cfe38b0345284ac5a55462cd.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=vgt2rSf6al,{'value': 'MindSimulator: Exploring Brain Concept Localization via Synthetic fMRI'},Guangyin Bao; Qi Zhang; Zixuan Gong; Zhuojia Wu; Duoqian Miao,~Guangyin_Bao1; ~Qi_Zhang25; ~Zixuan_Gong2; ~Zhuojia_Wu1; ~Duoqian_Miao1,"{'value': ['Neuroscience', 'fMRI encoding', 'Generative model', 'fMRI generation', 'fMRI functional localizer', 'Concept-selective voxel']}","{'value': 'Concept-selective regions within the human cerebral cortex exhibit significant activation in response to specific visual stimuli associated with particular concepts. Precisely localizing these regions stands as a crucial long-term goal in neuroscience to grasp essential brain functions and mechanisms. Conventional experiment-driven approaches hinge on manually constructed visual stimulus collections and corresponding brain activity recordings, constraining the support and coverage of concept localization. Additionally, these stimuli often consist of concept objects in unnatural contexts and are potentially biased by subjective preferences, thus prompting concerns about the validity and generalizability of the identified regions. To address these limitations, we propose a data-driven exploration approach. By synthesizing extensive brain activity recordings, we statistically localize various concept-selective regions. Our proposed MindSimulator leverages advanced generative technologies to learn the probability distribution of brain activity conditioned on concept-oriented visual stimuli. This enables the creation of simulated brain recordings that reflect real neural response patterns. Using the synthetic recordings, we successfully localize several well-studied concept-selective regions and validate them against empirical findings, achieving promising prediction accuracy. The feasibility opens avenues for exploring novel concept-selective regions and provides prior hypotheses for future neuroscience research.'}",https://openreview.net{'value': '/pdf/b292721d74b887ee8ecf8d54363b566e9aba5132.pdf'},{'title_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=vgZDcUetWS,{'value': 'Neural Approximate Mirror Maps for Constrained Diffusion Models'},Berthy Feng; Ricardo Baptista; Katherine Bouman,~Berthy_Feng1; ~Ricardo_Baptista1; ~Katherine_Bouman1,"{'value': ['generative models', 'diffusion models', 'mirror maps', 'constrained generation', 'inverse problems']}","{'value': 'Diffusion models excel at creating visually-convincing images, but they often struggle to meet subtle constraints inherent in the training data. Such constraints could be physics-based (e.g., satisfying a PDE), geometric (e.g., respecting symmetry), or semantic (e.g., including a particular number of objects). When the training data all satisfy a certain constraint, enforcing this constraint on a diffusion model makes it more reliable for generating valid synthetic data and solving constrained inverse problems. However, existing methods for constrained diffusion models are restricted in the constraints they can handle. For instance, recent work proposed to learn mirror diffusion models (MDMs), but analytical mirror maps only exist for convex constraints and can be challenging to derive. We propose *neural approximate mirror maps* (NAMMs) for general, possibly non-convex constraints. Our approach only requires a differentiable distance function from the constraint set. We learn an approximate mirror map that transforms data into an unconstrained space and a corresponding approximate inverse that maps data back to the constraint set. A generative model, such as an MDM, can then be trained in the learned mirror space and its samples restored to the constraint set by the inverse map. We validate our approach on a variety of constraints, showing that compared to an unconstrained diffusion model, a NAMM-based MDM substantially improves constraint satisfaction. We also demonstrate how existing diffusion-based inverse-problem solvers can be easily applied in the learned mirror space to solve constrained inverse problems.'}",https://openreview.net{'value': '/pdf/d2a8d57f4d7d157b60fcd1ac9f6e12713207ae4a.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=vWRwdmA3wU,{'value': 'Differentiable Optimization of Similarity Scores Between Models and Brains'},Nathan Cloos; Moufan Li; Markus Siegel; Scott L Brincat; Earl K Miller; Guangyu Robert Yang; Christopher J Cueva,~Nathan_Cloos1; ~Moufan_Li1; ~Markus_Siegel1; ~Scott_L_Brincat1; ~Earl_K_Miller1; ~Guangyu_Robert_Yang1; ~Christopher_J_Cueva1,"{'value': ['similarity measures', 'representational alignment', 'procrustes distance', 'centered kernel alignment', 'linear regression']}","{'value': 'How do we know if two systems - biological or artificial - process information in a similar way? Similarity measures such as linear regression, Centered Kernel Alignment (CKA), Normalized Bures Similarity (NBS), and angular Procrustes distance, are often used to quantify this similarity. However, it is currently unclear what drives high similarity scores and even what constitutes a ""good"" score. Here, we introduce a novel tool to investigate these questions by differentiating through similarity measures to directly maximize the score. Surprisingly, we find that high similarity scores do not guarantee encoding task-relevant information in a manner consistent with neural data; and this is particularly acute for CKA and even some variations of cross-validated and regularized linear regression. We find no consistent threshold for a good similarity score - it depends on both the measure and the dataset. In addition, synthetic datasets optimized to maximize similarity scores initially learn the highest variance principal component of the target dataset, but some methods like angular Procrustes capture lower variance dimensions much earlier than methods like CKA. To shed light on this, we mathematically derive the sensitivity of CKA, angular Procrustes, and NBS to the variance of principal component dimensions, and explain the emphasis CKA places on high variance components. Finally, by jointly optimizing multiple similarity measures, we characterize their allowable ranges and reveal that some similarity measures are more constraining than others. While current measures offer a seemingly straightforward way to quantify the similarity between neural systems, our work underscores the need for careful interpretation. We hope the tools we developed will be used by practitioners to better understand current and future similarity measures.'}",https://openreview.net{'value': '/pdf/384c9b2e9e7b5f7fd03f2c7ac42f6c216154ffbd.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=vJgJSrYPe1,{'value': 'Logic-Logit: A Logic-Based Approach to Choice Modeling'},Shuhan Zhang; Wendi Ren; Shuang Li,~Shuhan_Zhang4; ~Wendi_Ren1; ~Shuang_Li3,"{'value': ['Choice Model', 'Preference Learning', 'Interpretability', 'Rule Learning']}","{'value': 'In this study, we propose a novel rule-based interpretable choice model, {\\bf Logic-Logit}, designed to effectively learn and explain human choices. Choice models have been widely applied across various domains—such as commercial demand forecasting, recommendation systems, and consumer behavior analysis—typically categorized as parametric, nonparametric, or deep network-based. While recent innovations have favored neural network approaches for their computational power, these flexible models often involve large parameter sets and lack interpretability, limiting their effectiveness in contexts where transparency is essential.\n\nPrevious empirical evidence shows that individuals usually use {\\it heuristic decision rules} to form their consideration sets, from which they then choose. These rules are often represented as {\\it disjunctions of conjunctions} (i.e., OR-of-ANDs). These rules-driven, {\\it consider-then-choose} decision processes enable people to quickly screen numerous alternatives while reducing cognitive and search costs. Motivated by this insight, our approach leverages logic rules to elucidate human choices, providing a fresh perspective on preference modeling. We introduce a unique combination of column generation techniques and the Frank-Wolfe algorithm to facilitate efficient rule extraction for preference modeling—a process recognized as NP-hard. Our empirical evaluation, conducted on both synthetic datasets and real-world data from commercial and healthcare domains, demonstrates that Logic-Logit significantly outperforms baseline models in terms of interpretability and accuracy.'}",https://openreview.net{'value': '/pdf/b59b526c1b4cc70587f258f2659ab17efc45b9e5.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=v6iLQBoIJw,{'value': 'Does SGD really happen in tiny subspaces?'},Minhak Song; Kwangjun Ahn; Chulhee Yun,~Minhak_Song1; ~Kwangjun_Ahn2; ~Chulhee_Yun1,"{'value': ['optimization for deep networks', 'training dynamics', 'SGD', 'Hessian', 'low-rank subspace']}","{'value': 'Understanding the training dynamics of deep neural networks is challenging due to their high-dimensional nature and intricate loss landscapes. Recent studies have revealed that, along the training trajectory, the gradient approximately aligns with a low-rank top eigenspace of the training loss Hessian, referred to as the dominant subspace. Given this alignment, this paper explores whether neural networks can be trained within the dominant subspace, which, if feasible, could lead to more efficient training methods. Our primary observation is that when the SGD update is projected onto the dominant subspace, the training loss does not decrease further.\nThis suggests that the observed alignment between the gradient and the dominant subspace is spurious. Surprisingly, projecting out the dominant subspace proves to be just as effective as the original update, despite removing the majority of the original update component. We observe similar behavior across practical setups, including the large learning rate regime (also known as Edge of Stability), Sharpness-Aware Minimization, momentum, and adaptive optimizers. We discuss the main causes and implications of this spurious alignment, shedding light on the dynamics of neural network training.'}",https://openreview.net{'value': '/pdf/c8f3730235b7346811ea545a8bf2d3a6c7fa572f.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=uvHmnahyp1,{'value': 'SynFlowNet: Design of Diverse and Novel Molecules with Synthesis Constraints'},Miruna Cretu; Charles Harris; Ilia Igashov; Arne Schneuing; Marwin Segler; Bruno Correia; Julien Roy; Emmanuel Bengio; Pietro Lio,~Miruna_Cretu1; ~Charles_Harris2; ~Ilia_Igashov1; ~Arne_Schneuing1; ~Marwin_Segler2; ~Bruno_Correia1; ~Julien_Roy1; ~Emmanuel_Bengio1; ~Pietro_Lio1,"{'value': ['GFlowNets', 'de novo molecular generation', 'synthesizable molecular design']}","{'value': 'Generative models see increasing use in computer-aided drug design. However, while performing well at capturing distributions of molecular motifs, they often produce synthetically inaccessible molecules. To address this, we introduce SynFlowNet, a GFlowNet model whose action space uses chemical reactions and buyable reactants to sequentially build new molecules. By incorporating forward synthesis as an explicit constraint of the generative mechanism, we aim at bridging the gap between in silico molecular generation and real world synthesis capabilities. We evaluate our approach using synthetic accessibility scores and an independent retrosynthesis tool to assess the synthesizability of our compounds, and motivate the choice of GFlowNets through considerable improvement in sample diversity compared to baselines. Additionally, we identify challenges with reaction encodings that can complicate traversal of the MDP in the backward direction. To address this, we introduce various strategies for learning the GFlowNet backward policy and thus demonstrate how additional constraints can be integrated into the GFlowNet MDP framework. This approach enables our model to successfully identify synthesis pathways for previously unseen molecules.'}",https://openreview.net{'value': '/pdf/482fa312b4d2bfc792cce741b2c86f29db79d3b0.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=uqe5HkjbT9,{'value': 'Trajectory-Class-Aware Multi-Agent Reinforcement Learning'},Hyungho Na; Kwanghyeon Lee; Sumin Lee; Il-chul Moon,~Hyungho_Na1; ~Kwanghyeon_Lee1; ~Sumin_Lee5; ~Il-chul_Moon1,"{'value': ['trajectory clustering', 'multi-agent reinforcement learning', 'trajectory-class-aware policy', 'multi-task']}","{'value': 'In the context of multi-agent reinforcement learning, *generalization* is a challenge to solve various tasks that may require different joint policies or coordination without relying on policies specialized for each task. We refer to this type of problem as a *multi-task*, and we train agents to be versatile in this multi-task setting through a single training process. To address this challenge, we introduce TRajectory-class-Aware Multi-Agent reinforcement learning (TRAMA). In TRAMA, agents recognize a task type by identifying the class of trajectories they are experiencing through partial observations, and the agents use this trajectory awareness or prediction as additional information for action policy. To this end, we introduce three primary objectives in TRAMA: (a) constructing a quantized latent space to generate trajectory embeddings that reflect key similarities among them; (b) conducting trajectory clustering using these trajectory embeddings; and (c) building a trajectory-class-aware policy. Specifically for (c), we introduce a trajectory-class predictor that performs agent-wise predictions on the trajectory class; and we design a trajectory-class representation model for each trajectory class. Each agent takes actions based on this trajectory-class representation along with its partial observation for task-aware execution. The proposed method is evaluated on various tasks, including multi-task problems built upon StarCraft II. Empirical results show further performance improvements over state-of-the-art baselines.'}",https://openreview.net{'value': '/pdf/a543548c257abbf6aa9bb9400fe32d07129a2557.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=unDQOUah0F,{'value': 'VideoWebArena:  Evaluating Long Context Multimodal Agents with Video Understanding Web Tasks'},Lawrence Keunho Jang; Yinheng Li; Dan Zhao; Charles Ding; Justin Lin; Paul Pu Liang; Rogerio Bonatti; Kazuhito Koishida,~Lawrence_Keunho_Jang1; ~Yinheng_Li2; ~Dan_Zhao3; ~Charles_Ding1; ~Justin_Lin2; ~Paul_Pu_Liang1; ~Rogerio_Bonatti1; ~Kazuhito_Koishida1,"{'value': ['agents', 'benchmark', 'video understanding', 'multimodal agents']}","{'value': 'Videos are often used to learn or extract the necessary information to complete\ntasks in ways different than what text or static imagery can provide. However, many\nexisting agent benchmarks neglect long-context video understanding, instead focus-\ning on text or static image inputs. To bridge this gap, we introduce VideoWebArena\n(VideoWA), a benchmark for evaluating the capabilities of long-context multimodal\nagents for video understanding. VideoWA consists of 2,021 web agent tasks based\non manually crafted video tutorials, which total almost four hours of content. For\nour benchmark, we define a taxonomy of long-context video-based agent tasks with\ntwo main areas of focus: skill retention and factual retention. While skill retention\ntasks evaluate whether an agent can use a given human demonstration to complete\na task efficiently, the factual retention task evaluates whether an agent can retrieve\ninstruction-relevant information from a video to complete a task. We find that the\nbest model achieves a 13.3% success rate on factual retention tasks and 45.8% on\nfactual retention QA pairs—far below human success rates of 73.9% and 79.3%,\nrespectively. On skill retention tasks, long-context models perform worse with\ntutorials than without, exhibiting a 5% performance decrease in WebArena tasks\nand a 10.3% decrease in VisualWebArena tasks. Our work highlights performance\ngaps in the agentic abilities of long-context multimodal models and provides as a\ntestbed for the future development of long-context video agents.'}",https://openreview.net{'value': '/pdf/0665a611105a080d57247da2317726273a86a222.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=uQjySppU9x,{'value': 'SG-I2V: Self-Guided Trajectory Control in Image-to-Video Generation'},Koichi Namekata; Sherwin Bahmani; Ziyi Wu; Yash Kant; Igor Gilitschenski; David B. Lindell,~Koichi_Namekata1; ~Sherwin_Bahmani1; ~Ziyi_Wu1; ~Yash_Kant1; ~Igor_Gilitschenski1; ~David_B._Lindell1,"{'value': ['zero-shot', 'tuning-free', 'self-guided', 'image-to-video diffusion', 'trajectory control']}","{'value': 'Methods for image-to-video generation have achieved impressive, photo-realistic quality. \nHowever, adjusting specific elements in generated videos, such as object motion or camera movement, is often a tedious process of trial and error, e.g., involving re-generating videos with different random seeds. \nRecent techniques address this issue by fine-tuning a pre-trained model to follow conditioning signals, such as bounding boxes or point trajectories. \nYet, this fine-tuning procedure can be computationally expensive, and it requires datasets with annotated object motion, which can be difficult to procure. \nIn this work, we introduce SG-I2V, a framework for controllable image-to-video generation that is self-guided—offering zero-shot control by relying solely on the knowledge present in a pre-trained image-to-video diffusion model without the need for fine-tuning or external knowledge. \nOur zero-shot method outperforms unsupervised baselines while significantly narrowing down the performance gap with supervised models in terms of visual quality and motion fidelity.\nAdditional details and video results are available on our project page: https://kmcode1.github.io/Projects/SG-I2V'}",https://openreview.net{'value': '/pdf/fbc14430caa4851faaa8d400c7ba338e04015f86.pdf'},{'title_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=uNomADvF3s,{'value': 'Lift Your Molecules: Molecular Graph Generation in Latent Euclidean Space'},Mohamed Amine Ketata; Nicholas Gao; Johanna Sommer; Tom Wollschläger; Stephan Günnemann,~Mohamed_Amine_Ketata1; ~Nicholas_Gao1; ~Johanna_Sommer1; ~Tom_Wollschläger1; ~Stephan_Günnemann1,"{'value': ['Drug Design', 'Computational Biology', 'Molecule Generation', 'Graph Generation', 'Latent Diffusion Models']}","{'value': 'We introduce a new framework for 2D molecular graph generation using 3D molecule generative models. Our Synthetic Coordinate Embedding (SyCo) framework maps 2D molecular graphs to 3D Euclidean point clouds via synthetic coordinates and learns the inverse map using an E($n$)-Equivariant Graph Neural Network (EGNN). The induced point cloud-structured latent space is well-suited to apply existing 3D molecule generative models. This approach simplifies the graph generation problem into a point cloud generation problem followed by node and edge classification tasks, without relying on molecular fragments nor autoregressive decoding. Further, we propose a novel similarity-constrained optimization scheme for 3D diffusion models based on inpainting and guidance. As a concrete implementation of our framework, we develop EDM-SyCo based on the E(3) Equivariant Diffusion Model (EDM). EDM-SyCo achieves state-of-the-art performance in distribution learning of molecular graphs, outperforming the best non-autoregressive methods by more than 26\\% on ZINC250K and 16\\% on the GuacaMol dataset while improving conditional generation by up to 3.9 times.'}",https://openreview.net{'value': '/pdf/5662f920a04e4ff36756dbf43bf861ba35d69f03.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=uHLgDEgiS5,{'value': 'Capturing the Temporal Dependence of Training Data Influence'},Jiachen T. Wang; Dawn Song; James Zou; Prateek Mittal; Ruoxi Jia,~Jiachen_T._Wang1; ~Dawn_Song1; ~James_Zou1; ~Prateek_Mittal1; ~Ruoxi_Jia1,{'value': ['data attribution']},"{'value': ""Traditional data influence estimation methods, like influence function, assume that learning algorithms are permutation-invariant with respect to training data. However, modern training paradigms—especially for foundation models using stochastic algorithms and non-convergent, multi-stage curricula—are sensitive to data ordering, thus violating this assumption. This mismatch renders influence functions inadequate for answering some critical questions in current machine learning: How can we differentiate the influence of the same data contributing at different stages of training? More generally, how can we capture the dependence of data influence on the optimization trajectory during training? To address this gap, we formalize the concept of \\emph{trajectory-specific leave-one-out (LOO) influence}, which quantifies the impact of removing a data point from a specific iteration during training, accounting for the exact sequence of data encountered and the model's optimization trajectory. However, exactly evaluating the trajectory-specific LOO presents a significant computational challenge. To address this, we propose \\emph{data value embedding}, a novel technique enabling efficient approximation of trajectory-specific LOO. Specifically, we compute a training data embedding that encapsulates the cumulative interactions between data and the evolving model parameters. The LOO can then be efficiently approximated through a simple dot-product between the data value embedding and the gradient of the given test data. As data value embedding captures training data ordering, it offers valuable insights into model training dynamics. In particular, we uncover distinct phases of data influence, revealing that data points in the early and late stages of training exert a greater impact on the final model. These insights translate into actionable strategies for managing the computational overhead of data selection by strategically timing the selection process, potentially opening new avenues in data curation research.""}",https://openreview.net{'value': '/pdf/95e143e83c521810c6413f81a9119f949e089351.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=uGJxl2odR0,{'value': 'Dimension Agnostic Neural Processes'},Hyungi Lee; Chaeyun Jang; Dong Bok Lee; Juho Lee,~Hyungi_Lee1; ~Chaeyun_Jang1; ~Dong_Bok_Lee1; ~Juho_Lee2,"{'value': ['Neural Processes', 'varying dimension', 'regression', 'bayesian optimization']}","{'value': ""Meta-learning aims to train models that can generalize to new tasks with limited labeled data by extracting shared features across diverse task datasets. Additionally, it accounts for prediction uncertainty during both training and evaluation, a concept known as uncertainty-aware meta-learning. Neural Process (NP) is a well-known uncertainty-aware meta-learning method that constructs implicit stochastic processes using parametric neural networks, enabling rapid adaptation to new tasks. However, existing NP methods face challenges in accommodating diverse input dimensions and learned features, limiting their broad applicability across regression tasks. To address these limitations and advance the utility of NP models as general regressors, we introduce Dimension Agnostic Neural Process (DANP). DANP incorporates Dimension Aggregator Block (DAB) to transform input features into a fixed-dimensional space, enhancing the model's ability to handle diverse datasets. Furthermore, leveraging the Transformer architecture and latent encoding layers, DANP learns a wider range of features that are generalizable across various tasks. Through comprehensive experimentation on various synthetic and practical regression tasks, we empirically show that DANP outperforms previous NP variations, showcasing its effectiveness in overcoming the limitations of traditional NP models and its potential for broader applicability in diverse regression scenarios.""}",https://openreview.net{'value': '/pdf/c2840cd67e8d0711760d2e06ff07bd903893423c.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=uClUUJk05H,{'value': 'Compositional simulation-based inference for time series'},Manuel Gloeckler; Shoji Toyota; Kenji Fukumizu; Jakob H. Macke,~Manuel_Gloeckler1; ~Shoji_Toyota1; ~Kenji_Fukumizu1; ~Jakob_H._Macke1,"{'value': ['Simulation-based inference', 'Bayesian inference', 'time series', 'markovian simulators', 'Amortized Bayesian inference']}","{'value': 'Amortized simulation-based inference (SBI) methods train neural networks on simulated data to perform Bayesian inference. While this strategy avoids the need for tractable likelihoods, it often requires a large number of simulations and has been challenging to scale to time series data. Scientific simulators frequently emulate real-world dynamics through thousands of single-state transitions over time. We propose an SBI approach that can exploit such Markovian simulators by locally identifying parameters consistent with individual state transitions. We then compose these local results to obtain a posterior over parameters that align with the entire time series observation. We focus on applying this approach to neural posterior score estimation but also show how it can be applied, e.g., to neural likelihood (ratio) estimation. We demonstrate that our approach is more simulation-efficient than directly estimating the global posterior on several synthetic benchmark tasks and simulators used in ecology and epidemiology. Finally, we validate scalability and simulation efficiency of our approach by applying it to a high-dimensional Kolmogorov flow simulator with around one million data dimensions.'}",https://openreview.net{'value': '/pdf/1dbae3c70d8c2fc5739a83e2aa1534ecb821b10c.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=u8VOQVzduP,{'value': 'Exploring Prosocial Irrationality for LLM Agents: A Social Cognition View'},Xuan Liu; Jie ZHANG; HaoYang Shang; Song Guo; Yang Chengxu; Quanyan Zhu,~Xuan_Liu8; ~Jie_ZHANG18; ~HaoYang_Shang1; ~Song_Guo5; ~Yang_Chengxu1; ~Quanyan_Zhu1,"{'value': ['LLM for Social Science', 'Prosocial irrationality of LLM Agents', 'Cognitive AI framework']}","{'value': ""Large language models (LLMs) have been shown to face hallucination issues due to the data they trained on often containing human bias; whether this is reflected in the decision-making process of LLM agents remains under-explored. As LLM Agents are increasingly employed in intricate social environments, a pressing and natural question emerges: Can we utilize LLM Agents' systematic hallucinations to mirror human cognitive biases, thus exhibiting irrational social intelligence? In this paper, we probe the irrational behavior among contemporary LLM agents by melding practical social science experiments with theoretical insights. Specifically, we propose CogMir, an open-ended Multi-LLM Agents framework that utilizes hallucination properties to assess and enhance LLM Agents’ social intelligence through cognitive biases. Experimental results on CogMir subsets show that LLM Agents and humans exhibit high consistency in irrational and prosocial decision-making under uncertain conditions, underscoring the prosociality of LLM Agents as social entities and highlighting the significance of hallucination properties. Additionally, CogMir framework demonstrates its potential as a valuable platform for encouraging more research into the social intelligence of LLM Agents.""}",https://openreview.net{'value': '/pdf/57c070541c129f197b35e42fce0d392830ea36ee.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=u1cQYxRI1H,{'value': 'Scaling In-the-Wild Training for Diffusion-based Illumination Harmonization and Editing by Imposing Consistent Light Transport'},Lvmin Zhang; Anyi Rao; Maneesh Agrawala,~Lvmin_Zhang2; ~Anyi_Rao2; ~Maneesh_Agrawala2,"{'value': ['diffusion model', 'illumination editing', 'image editing']}","{'value': ""Diffusion-based image generators are becoming unique methods for illumination harmonization and editing. The current bottleneck in scaling up the training of diffusion-based illumination editing models is mainly in the difficulty of preserving the underlying image details and maintaining intrinsic properties, such as albedos, unchanged. Without appropriate constraints, directly training the latest large image models with complex, varied, or in-the-wild data is likely to produce a structure-guided random image generator, rather than achieving the intended goal of precise illumination manipulation. We propose Imposing Consistent Light (IC-Light) transport during training, rooted in the physical principle that the linear blending of an object's appearances under different illumination conditions is consistent with its appearance under mixed illumination. This consistency allows for stable and scalable illumination learning, uniform handling of various data sources, and facilitates a physically grounded model behavior that modifies only the illumination of images while keeping other intrinsic properties unchanged. Based on this method, we can scale up the training of diffusion-based illumination editing models to large data quantities (> 10 million), across all available data types (real light stages, rendered samples, in-the-wild synthetic augmentations, etc), and using strong backbones (SDXL, Flux, etc). We also demonstrate that this approach reduces uncertainties and mitigates artifacts such as mismatched materials or altered albedos.""}",https://openreview.net{'value': '/pdf/08c6b53400491d4d663335fe55fa7814ad3582f0.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=txoJvjfI9w,{'value': 'PEARL: Towards Permutation-Resilient LLMs'},Liang CHEN; Li Shen; Yang Deng; Xiaoyan Zhao; Bin Liang; Kam-Fai Wong,~Liang_CHEN15; ~Li_Shen1; ~Yang_Deng4; ~Xiaoyan_Zhao1; ~Bin_Liang6; ~Kam-Fai_Wong2,"{'value': ['In-Context Learning', 'Large Language Models', 'Instruction Tuning', 'Robustness', 'Attack', 'Distributionally Robust Optimization', 'Optimal Transport', 'Sinkhorn Algorithm']}","{'value': ""The in-context learning (ICL) capability of large language models (LLMs) enables them to perform challenging tasks using provided demonstrations. However, ICL is highly sensitive to the ordering of demonstrations, leading to instability in predictions. This paper shows that this vulnerability can be exploited to design a natural attack—difficult for model providers to detect—that achieves nearly 80% success rate on LLaMA-3 by simply permuting the demonstrations. Existing mitigation methods primarily rely on post-processing and fail to enhance the model's inherent robustness to input permutations, raising concerns about safety and reliability of LLMs. To address this issue, we propose Permutation-resilient learning (PEARL), a novel framework based on distributionally robust optimization (DRO), which optimizes model performance against the worst-case input permutation. Specifically, PEARL consists of a permutation-proposal network (P-Net) and the LLM. The P-Net generates the most challenging permutations by treating it as an optimal transport problem, which is solved using an entropy-constrained Sinkhorn algorithm. Through minimax optimization, the P-Net and the LLM iteratively optimize against each other, progressively improving the LLM's robustness. Experiments on synthetic pre-training and real-world instruction tuning tasks demonstrate that PEARL effectively mitigates permutation attacks and enhances performance. Notably, despite being trained on fewer shots and shorter contexts, PEARL achieves performance gains of up to 40% when scaled to many-shot and long-context scenarios, highlighting its efficiency and generalization capabilities.""}",https://openreview.net{'value': '/pdf/33d003d233dbf46e4ad6434063378356437beb62.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=txD9llAYn9,{'value': 'Model-based RL as a Minimalist Approach to Horizon-Free and Second-Order Bounds'},Zhiyong Wang; Dongruo Zhou; John C.S. Lui; Wen Sun,~Zhiyong_Wang9; ~Dongruo_Zhou1; ~John_C.S._Lui2; ~Wen_Sun1,"{'value': ['reinforcement learning theory', 'model-based reinforcement learning']}","{'value': 'Learning a transition model via Maximum Likelihood Estimation (MLE) followed by planning inside the learned model is perhaps the most standard and simplest Model-based Reinforcement Learning (RL) framework. In this work, we show that such a simple Model-based RL scheme, when equipped with optimistic and pessimistic planning procedures, achieves strong regret and sample complexity bounds in online and offline RL settings. Particularly, we demonstrate that under the conditions where the trajectory-wise reward is normalized between zero and one and the transition is time-homogenous, it achieves nearly horizon-free and second-order bounds.'}",https://openreview.net{'value': '/pdf/f9d9348f61da688390ad2b7f49c89500ee00191a.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=tnB94WQGrn,{'value': 'KGARevion: An AI Agent for Knowledge-Intensive Biomedical QA'},Xiaorui Su; Yibo Wang; Shanghua Gao; Xiaolong Liu; Valentina Giunchiglia; Djork-Arné Clevert; Marinka Zitnik,~Xiaorui_Su1; ~Yibo_Wang6; ~Shanghua_Gao1; ~Xiaolong_Liu4; ~Valentina_Giunchiglia1; ~Djork-Arné_Clevert2; ~Marinka_Zitnik1,"{'value': ['Medical Reasoning', 'Medical QA', 'Agent', 'Knowledge Graph', 'LLM']}","{'value': 'Biomedical reasoning integrates structured, codified knowledge with tacit, experience-driven insights. Depending on the context, quantity, and nature of available evidence, researchers and clinicians use diverse strategies, including rule-based, prototype-based, and case-based reasoning. Effective medical AI models must handle this complexity while ensuring reliability and adaptability. We introduce KGARevion, a knowledge graph-based agent that answers knowledge-intensive questions. Upon receiving a query, KGARevion generates relevant triplets by leveraging the latent knowledge embedded in a large language model. It then verifies these triplets against a grounded knowledge graph, filtering out errors and retaining only accurate, contextually relevant information for the final answer. This multi-step process strengthens reasoning, adapts to different models of medical inference, and outperforms retrieval-augmented generation-based approaches that lack effective verification mechanisms. Evaluations on medical QA benchmarks show that KGARevion improves accuracy by over 5.2% over 15 models in handling complex medical queries. To further assess its effectiveness, we curated three new medical QA datasets with varying levels of semantic complexity, where KGARevion improved accuracy by 10.4%. The agent integrates with different LLMs and biomedical knowledge graphs for broad applicability across knowledge-intensive tasks. We evaluated KGARevion on AfriMed-QA, a newly introduced dataset focused on African healthcare, demonstrating its strong zero-shot generalization to underrepresented medical contexts.'}",https://openreview.net{'value': '/pdf/4ebd41c60fe8172af284217f132e0b627c17340b.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=tn2mjzjSyR,{'value': 'DOTS: Learning to Reason Dynamically in LLMs via Optimal Reasoning Trajectories Search'},Murong Yue; Wenlin Yao; Haitao Mi; Dian Yu; Ziyu Yao; Dong Yu,~Murong_Yue1; ~Wenlin_Yao1; ~Haitao_Mi1; ~Dian_Yu3; ~Ziyu_Yao1; ~Dong_Yu2,"{'value': ['large language model', 'reasoning']}","{'value': 'Enhancing the capability of large language models (LLMs) in reasoning has gained significant attention in recent years. Previous studies have demonstrated the effectiveness of various prompting strategies in aiding LLMs in reasoning (called ""reasoning actions""), such as step-by-step thinking, reflecting before answering, solving with programs, and their combinations. However, these approaches often applied static, predefined reasoning actions uniformly to all questions, without considering the specific characteristics of each question or the capability of the task-solving LLM. In this paper, we propose DOTS, an approach enabling LLMs to reason Dynamically via Optimal reasoning Trajectories Search, tailored to the specific characteristics of each question and the inherent capability of the task-solving LLM. \nOur approach involves three key steps: i) defining atomic reasoning action modules that can be composed into various reasoning action trajectories; ii) searching for the optimal action trajectory for each training question through iterative exploration and evaluation for the specific task-solving LLM; and iii) using the collected optimal trajectories to train an LLM to plan for the reasoning trajectories of unseen questions. In particular, we propose two learning paradigms, i.e., fine-tuning an external LLM as a planner to guide the task-solving LLM, or directly fine-tuning the task-solving LLM with an internalized capability for reasoning actions planning. Our experiments across eight reasoning tasks show that our method consistently outperforms static reasoning techniques and the vanilla instruction tuning approach. Further analysis reveals that our method enables LLMs to adjust their computation based on problem complexity, allocating deeper thinking and reasoning to harder problems.'}",https://openreview.net{'value': '/pdf/baf58612feaf28307c5cb59509c95f929577556b.pdf'},{'title_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=tZCqSVncRf,{'value': 'MIRAGE: Evaluating and Explaining Inductive Reasoning Process in Language Models'},Jiachun Li; Pengfei Cao; Zhuoran Jin; Yubo Chen; Kang Liu; Jun Zhao,~Jiachun_Li3; ~Pengfei_Cao1; ~Zhuoran_Jin1; ~Yubo_Chen1; ~Kang_Liu1; ~Jun_Zhao4,"{'value': ['inductive reasoning', 'large language model', 'model explanation']}","{'value': ""Inductive reasoning is an essential capability for large language models (LLMs) to achieve higher intelligence, which requires the model to generalize rules from observed facts and then apply them to unseen examples. We present {\\scshape Mirage}, a synthetic dataset that addresses the limitations of previous work, specifically the lack of comprehensive evaluation and flexible test data. In it, we evaluate LLMs' capabilities in both the inductive and deductive stages, allowing for flexible variation in input distribution, task scenario, and task difficulty to analyze the factors influencing LLMs' inductive reasoning. Based on these multi-faceted evaluations, we demonstrate that the LLM is a poor rule-based reasoner. In many cases, when conducting inductive reasoning, they do not rely on a correct rule to answer the unseen case. From the perspectives of different prompting methods, observation numbers, and task forms, models tend to consistently conduct correct deduction without correct inductive rules. Besides, we find that LLMs are good neighbor-based reasoners. In the inductive reasoning process, the model tends to focus on observed facts that are close to the current test example in feature space. By leveraging these similar examples, the model maintains strong inductive capabilities within a localized region, significantly improving its deductive performance.""}",https://openreview.net{'value': '/pdf/5da4c669ff8c1f4aceeabf4256982c502c3aa571.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=tRNKe2Vgqt,{'value': 'MMWorld: Towards Multi-discipline Multi-faceted World Model Evaluation in Videos'},Xuehai He; Weixi Feng; Kaizhi Zheng; Yujie Lu; Wanrong Zhu; Jiachen Li; Yue Fan; Jianfeng Wang; Linjie Li; Zhengyuan Yang; Kevin Lin; William Yang Wang; Lijuan Wang; Xin Eric Wang,~Xuehai_He1; ~Weixi_Feng2; ~Kaizhi_Zheng1; ~Yujie_Lu1; ~Wanrong_Zhu1; ~Jiachen_Li6; ~Yue_Fan3; ~Jianfeng_Wang4; ~Linjie_Li1; ~Zhengyuan_Yang1; ~Kevin_Lin3; ~William_Yang_Wang2; ~Lijuan_Wang1; ~Xin_Eric_Wang2,"{'value': ['Video Understanding', 'Benchmark']}","{'value': 'Multimodal Language Language Models (MLLMs) demonstrate the emerging abilities of ""world models""---interpreting and reasoning about complex real-world dynamics. To assess these abilities, we posit videos are the ideal medium, as they encapsulate rich representations of real-world dynamics and causalities. To this end, we introduce MMWorld, a new benchmark for multi-discipline, multi-faceted multimodal video understanding. MMWorld distinguishes itself from previous video understanding benchmarks with two unique advantages: (1) multi-discipline, covering various disciplines that often require domain expertise for comprehensive understanding; (2) multi-faceted reasoning, including explanation, counterfactual thinking, future prediction, etc. MMWorld consists of a human-annotated dataset to evaluate MLLMs with questions about the whole videos and a synthetic dataset to analyze MLLMs within a single modality of perception. Together, MMWorld encompasses 1,910 videos across seven broad disciplines and 69 subdisciplines, complete with 6,627 question-answer pairs and associated captions. The evaluation includes 4 proprietary and 11 open-source MLLMs, which struggle on MMWorld (e.g., GPT-4o performs the best with only 62.5% accuracy), showing large room for improvement. Further ablation studies reveal other interesting findings such as models\' different skill sets from humans. We hope MMWorld can serve as an essential step towards world model evaluation in videos.'}",https://openreview.net{'value': '/pdf/6e377138997f887ef5092dd7531612eea253c8f7.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=tMG6btjBfd,{'value': 'SplineGS: Learning Smooth Trajectories in Gaussian Splatting for Dynamic Scene Reconstruction'},Jihwan Yoon; Sangbeom Han; Jaeseok Oh; Minsik Lee,~Jihwan_Yoon1; ~Sangbeom_Han1; ~Jaeseok_Oh1; ~Minsik_Lee2,"{'value': ['4D Gaussian splatting', 'Dynamic scene reconstruction', 'Novel-view synthesis for dynamic scenes']}","{'value': 'Reconstructing complex scenes with deforming objects for novel view synthesis is a challenging task. Recent works have addressed this with 3D Gaussian Splatting, which effectively reconstructs static scenes with high quality in short training time, by adding specialized modules for the deformations of Gaussian blobs. However, designing an effective deformation module that incorporates appropriate spatiotemporal inductive biases still remains unresolved. To address this issue, we propose SplineGS in this paper, which utilizes non-uniform rational B-splines (NURBS), an extension of B-spline, to represent temporally smooth deformation. A set of representative trajectories are learned based on NURBS, and the individual trajectories of Gaussian blobs are represented as linear combinations of these trajectories for spatial smoothness. The weights of the combinations are trained based on a multi-resolution hash table and an MLP, with the positions of the Gaussian blobs as the keys. Thanks to this design, the proposed method does not need any regularizers for trajectories, which enables efficient training. Experiments demonstrate that the proposed method provides competitive performance over the existing methods with much shorter training time.'}",https://openreview.net{'value': '/pdf/c42e40f7bc0a4668a40106c0a997de49f1fd9e6c.pdf'},{'title_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=tBom4xOW1H,{'value': 'Adversarial Generative Flow Network for Solving Vehicle Routing Problems'},Ni Zhang; Jingfeng Yang; Zhiguang Cao; Xu Chi,~Ni_Zhang6; ~Jingfeng_Yang5; ~Zhiguang_Cao1; ~Xu_Chi1,"{'value': ['Generative Flow Network', 'Adversarial Training', 'Vehicle Routing Problem']}","{'value': 'Recent research into solving vehicle routing problems (VRPs) has gained significant traction, particularly through the application of deep (reinforcement) learning for end-to-end solution construction. However, many current construction-based neural solvers predominantly utilize Transformer architectures, which can face scalability challenges and struggle to produce diverse solutions. To address these limitations, we introduce a novel framework beyond Transformer-based approaches, i.e., Adversarial Generative Flow Networks (AGFN). This framework integrates the generative flow network (GFlowNet)—a probabilistic model inherently adept at generating diverse solutions (routes)—with a complementary model for discriminating (or evaluating) the solutions. These models are trained alternately in an adversarial manner to improve the overall solution quality, followed by a proposed hybrid decoding method to construct the solution. We apply the AGFN framework to solve the capacitated vehicle routing problem (CVRP) and travelling salesman problem (TSP), and our experimental results demonstrate that AGFN surpasses the popular construction-based neural solvers, showcasing strong generalization capabilities on synthetic and real-world benchmark instances.'}",https://openreview.net{'value': '/pdf/7ed63f33b382b506946c4ff7ec299ff90023f804.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=t9U3LW7JVX,{'value': 'Automated Design of Agentic Systems'},Shengran Hu; Cong Lu; Jeff Clune,~Shengran_Hu2; ~Cong_Lu1; ~Jeff_Clune3,"{'value': ['LLMs', 'Language Model Agents', 'Agents', 'Agentic Systems', 'Reasoning', 'Meta Learning', 'Open-endedness']}","{'value': 'Researchers are investing substantial effort in developing powerful general-purpose agents, wherein Foundation Models are used as modules within agentic systems (e.g. Chain-of-Thought, Self-Reflection, Toolformer). However, the history of machine learning teaches us that hand-designed solutions are eventually replaced by learned solutions. We describe a newly forming research area, Automated Design of Agentic Systems (ADAS), which aims to automatically create powerful agentic system designs, including inventing novel building blocks and/or combining them in new ways. We further demonstrate that there is an unexplored yet promising approach within ADAS where agents can be defined in code and new agents can be automatically discovered by a meta agent programming ever better ones in code. Given that programming languages are Turing Complete, this approach theoretically enables the learning of any possible agentic system: including novel prompts, tool use, workflows, and combinations thereof. We present a simple yet effective algorithm named Meta Agent Search to demonstrate this idea, where a meta agent iteratively programs interesting new agents based on an ever-growing archive of previous discoveries. Through extensive experiments across multiple domains including coding, science, and math, we show that our algorithm can progressively invent agents with novel designs that greatly outperform state-of-the-art hand-designed agents. Importantly, we consistently observe the surprising result that agents invented by Meta Agent Search maintain superior performance even when transferred across domains and models, demonstrating their robustness and generality. Provided we develop it safely, our work illustrates the potential of an exciting new research direction toward automatically designing ever-more powerful agentic systems to benefit humanity.'}",https://openreview.net{'value': '/pdf/116ed45ae3d0873b16f5fdcab7f1fa4f12253e6d.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=t6QHYUOQL7,{'value': 'Breaking Mental Set to Improve Reasoning through Diverse Multi-Agent Debate'},Yexiang Liu; Jie Cao; Zekun Li; Ran He; Tieniu Tan,~Yexiang_Liu1; ~Jie_Cao2; ~Zekun_Li2; ~Ran_He1; ~Tieniu_Tan1,"{'value': ['Multi-Agent Debate', 'Large Language Models', 'Multimodal Large Language Models', 'Prompting', 'Self-Correction', 'Reasoning']}","{'value': 'Large Language Models (LLMs) have seen significant progress but continue to struggle with persistent reasoning mistakes.\nPrevious methods of *self-reflection* have been proven limited due to the models’ inherent fixed thinking patterns. \nWhile Multi-Agent Debate (MAD) attempts to mitigate this by incorporating multiple agents, it often employs the same reasoning methods, even though assigning different personas to models. This leads to a ""fixed mental set"", where models rely on homogeneous thought processes without exploring alternative perspectives.\nIn this paper, we introduce Diverse Multi-Agent Debate (DMAD), a method that encourages agents to think with distinct reasoning approaches. By leveraging diverse problem-solving strategies, each agent can gain insights from different perspectives, refining its responses through discussion and collectively arriving at the optimal solution. DMAD effectively breaks the limitations of fixed mental sets. We evaluate DMAD against various prompting techniques, including *self-reflection* and traditional MAD, across multiple benchmarks using both LLMs and Multimodal LLMs. Our experiments show that DMAD consistently outperforms other methods, delivering better results than MAD in fewer rounds. Code is available at https://github.com/MraDonkey/DMAD.'}",https://openreview.net{'value': '/pdf/d67d70de207899a21f78262107dd3b5ec2d940b6.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=stUKwWBuBm,{'value': 'Tractable Multi-Agent Reinforcement Learning through Behavioral Economics'},Eric Mazumdar; Kishan Panaganti; Laixi Shi,~Eric_Mazumdar1; ~Kishan_Panaganti1; ~Laixi_Shi1,"{'value': ['behavioral economics', 'risk-aversion', 'multi-agent reinforcement learning', 'quantal response', 'bounded rationality']}","{'value': ""A significant roadblock to the development of principled multi-agent reinforcement learning (MARL) algorithms is the fact that desired solution concepts like Nash equilibria may be intractable to compute. We show how one can overcome this obstacle by introducing concepts from behavioral economics into MARL. To do so, we imbue agents with two key features of human decision-making: risk aversion and bounded rationality. We show that introducing these two properties into games gives rise to a class of equilibria---risk-averse quantal response equilibria (RQE)---which are tractable to compute in \\emph{all} $n$-player matrix and finite-horizon Markov games.  In particular, we show that they emerge as the endpoint of no-regret learning in suitably adjusted versions of the games. Crucially, the class of computationally tractable RQE is independent of the underlying game structure and only depends on agents' degrees of risk-aversion and bounded rationality.  To validate the expressivity of this class of solution concepts we show that it captures peoples' patterns of play in a number of 2-player matrix games previously studied in experimental economics. Furthermore, we give a first analysis of the sample complexity of computing these equilibria in finite-horizon Markov games when one has access to a generative model. We validate our findings on a simple multi-agent reinforcement learning benchmark. Our results open the doors for to the principled development of new decentralized multi-agent reinforcement learning algorithms.""}",https://openreview.net{'value': '/pdf/168286ae29b41e2ede4ee3062cd5078fb64a5871.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=st7XqFgbAH,{'value': 'Better than Your Teacher: LLM Agents that learn from Privileged AI Feedback'},Sanjiban Choudhury; Paloma Sodhi,~Sanjiban_Choudhury3; ~Paloma_Sodhi1,"{'value': ['learning from AI feedback', 'imitation learning', 'privileged information']}","{'value': ""While large language models (LLMs) show impressive decision-making abilities, current methods lack a mechanism for automatic self-improvement from errors during task execution. We propose LEAP, an iterative fine-tuning framework that continually improves LLM agents using feedback from AI expert teachers. Our key insight is to equip the expert teachers with a privileged state -- information available during training but hidden at test time. This allows even weak experts to provide precise guidance, significantly improving the student agent's performance without access to privileged information at test time.\nWe evaluate LEAP on multiple decision-making benchmarks, including text-based games (ALFWorld), web navigation (WebShop), and interactive coding (Intercode Bash). Our experiments show that LEAP (1) outperforms behavior cloning and ReAct baselines (2) enables weak student models (e.g., Llama3-8B) to exceed performance of strong teacher models (GPT-4o), and (3) allows weak models to self-improve using privileged versions of themselves. \nWe provide a theoretical analysis showing that LEAP's success hinges on balancing privileged information with student’s realizability, which we empirically validate. Our code is available at \\url{https://leap-llm.github.io}.""}",https://openreview.net{'value': '/pdf/e01984cb7f0cd388c18743a0268e5640c16e8157.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=skGSOcrIj7,{'value': 'Neural Spacetimes for DAG Representation Learning'},Haitz Sáez de Ocáriz Borde; Anastasis Kratsios; Marc T. Law; Xiaowen Dong; Michael M. Bronstein,~Haitz_Sáez_de_Ocáriz_Borde1; ~Anastasis_Kratsios1; ~Marc_T._Law1; ~Xiaowen_Dong1; ~Michael_M._Bronstein1,"{'value': ['Directed Graphs', 'Quasi-metrics']}","{'value': 'We propose a class of trainable deep learning-based geometries called Neural SpaceTimes (NSTs), which can universally represent nodes in weighted Directed Acyclic Graphs (DAGs) as events in a spacetime manifold. While most works in the literature focus on undirected graph representation learning or causality embedding separately, our differentiable geometry can encode both graph edge weights in its spatial dimensions and causality in the form of edge directionality in its temporal dimensions. We use a product manifold that combines a quasi-metric (for space) and a partial order (for time). NSTs are implemented as three neural networks trained in an end-to-end manner: an embedding network, which learns to optimize the location of nodes as events in the spacetime manifold, and two other networks that optimize the space and time geometries in parallel, which we call a neural (quasi-)metric and a neural partial order, respectively. The latter two networks leverage recent ideas at the intersection of fractal geometry and deep learning to shape the geometry of the representation space in a data-driven fashion, unlike other works in the literature that use fixed spacetime manifolds such as Minkowski space or De Sitter space to embed DAGs. Our main theoretical guarantee is a universal embedding theorem, showing that any $k$-point DAG can be embedded into an NST with $1+\\mathcal{O}(\\log(k))$ distortion while exactly preserving its causal structure. The total number of parameters defining the NST is sub-cubic in $k$ and linear in the width of the DAG. If the DAG has a planar Hasse diagram, this is improved to $\\mathcal{O}(\\log(k) + 2)$ spatial and 2 temporal dimensions. We validate our framework computationally with synthetic weighted DAGs and real-world network embeddings; in both cases, the NSTs achieve lower embedding distortions than their counterparts using fixed spacetime geometries.'}",https://openreview.net{'value': '/pdf/5f09233cec442d2ce26c648029cdbb7113897875.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=semTHoVGsJ,{'value': 'Density estimation with LLMs: a geometric investigation of in-context learning trajectories'},Toni J.B. Liu; Nicolas Boulle; Raphaël Sarfati; Christopher Earls,~Toni_J.B._Liu1; ~Nicolas_Boulle1; ~Raphaël_Sarfati1; ~Christopher_Earls1,"{'value': ['Large language models', 'in-context learning', 'Intensive Principal Component Analysis', 'density estimation', 'Mechanistic  interpretations', 'High-dimensional learning dynamics', 'dimensionality reduction']}","{'value': ""Large language models (LLMs) demonstrate remarkable emergent abilities to perform in-context learning across various tasks, including time series forecasting. \nThis work investigates LLMs' ability to estimate probability density functions (PDFs) from data observed in-context; \nsuch density estimation (DE) is a fundamental task underlying many probabilistic modeling problems. \nWe leverage the Intensive Principal Component Analysis (InPCA) to visualize and analyze the in-context learning dynamics of LLaMA-2 models. \nOur main finding is that these LLMs all follow similar learning trajectories in a low-dimensional InPCA space, which are distinct from those of traditional density estimation methods like histograms and Gaussian kernel density estimation (KDE). \nWe interpret the LLaMA in-context DE process as a KDE with an adaptive kernel width and shape. \nThis custom kernel model captures a significant portion of LLaMA's behavior despite having only two parameters. \nWe further speculate on why LLaMA's kernel width and shape differs from classical algorithms, providing insights into the mechanism of in-context probabilistic reasoning in LLMs.\nOur codebase, along with a 3D visualization of an LLM's in-context learning trajectory, is publicly available at https://github.com/AntonioLiu97/LLMICL_inPCA.""}",https://openreview.net{'value': '/pdf/fe0e276c4216cc7f2766d54ade344fbd3c969fca.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=scI9307PLG,{'value': 'Bundle Neural Network for message diffusion on graphs'},Jacob Bamberger; Federico Barbero; Xiaowen Dong; Michael M. Bronstein,~Jacob_Bamberger1; ~Federico_Barbero1; ~Xiaowen_Dong1; ~Michael_M._Bronstein1,"{'value': ['graph neural network', 'sheaf neural network', 'geometric deep learning', 'algebraic topology', 'vector bundles', 'expressivity']}","{'value': 'The dominant paradigm for learning on graphs is message passing. Despite being a strong inductive bias, the local message passing mechanism faces challenges such as over-smoothing, over-squashing, and limited expressivity. To address these issues, we introduce Bundle Neural Networks (BuNNs), a novel graph neural network architecture that operates via *message diffusion* on *flat vector bundles* — geometrically inspired structures that assign to each node a vector space and an orthogonal map. A BuNN layer evolves node features through a diffusion-type partial differential equation, where its discrete form acts as a special case of the recently introduced Sheaf Neural Network (SNN), effectively alleviating over-smoothing. The continuous nature of message diffusion enables BuNNs to operate at larger scales, reducing over-squashing. We establish the universality of BuNNs in approximating feature transformations on infinite families of graphs with injective positional encodings, marking the first positive expressivity result of its kind. We support our claims with formal analysis and synthetic experiments. Empirically, BuNNs perform strongly on heterophilic and long-range tasks, which demonstrates their robustness on a diverse range of challenging real-world tasks.'}",https://openreview.net{'value': '/pdf/ff0bfe7ee5e9dc0e6c0e47a17dc9e1baed5c5817.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=sVNfWhtaJC,{'value': 'Data-adaptive Differentially Private Prompt Synthesis for In-Context Learning'},Fengyu Gao; Ruida Zhou; Tianhao Wang; Cong Shen; Jing Yang,~Fengyu_Gao1; ~Ruida_Zhou1; ~Tianhao_Wang3; ~Cong_Shen1; ~Jing_Yang3,"{'value': ['in-context learning', 'differential privacy', 'large language models']}","{'value': 'Large Language Models (LLMs) rely on the contextual information embedded in examples/demonstrations to perform in-context learning (ICL). To mitigate the risk of LLMs potentially leaking private information contained in examples in the prompt, we introduce a novel data-adaptive differentially private algorithm called **AdaDPSyn** to generate synthetic examples from the private dataset and then use these synthetic examples to perform ICL. The objective of AdaDPSyn is to adaptively adjust the noise level in the data synthesis mechanism according to the inherent statistical properties of the data, thereby preserving high ICL accuracy while maintaining formal differential privacy guarantees. A key innovation in AdaDPSyn is the *Precision-Focused Iterative Radius Reduction* technique, which dynamically refines the aggregation radius - the scope of data grouping for noise addition - based on patterns observed in data clustering, thereby minimizing the amount of additive noise. We conduct extensive experiments on standard benchmarks and compare AdaDPSyn with DP few-shot generation algorithm (Tang et al., 2023). The experiments demonstrate that AdaDPSyn not only outperforms DP few-shot generation, but also maintains high accuracy levels close to those of non-private baselines, providing an effective solution for ICL with privacy protection.'}",https://openreview.net{'value': '/pdf/433ee572bc3a318a245e87b308a6df348833a822.pdf'},{'abstract_filter': 'Data Synthesis'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=sRIU6k2TcU,{'value': 'Proactive Agent: Shifting LLM Agents from Reactive Responses to Active Assistance'},Yaxi Lu; Shenzhi Yang; Cheng Qian; Guirong Chen; Qinyu Luo; Yesai Wu; Huadong Wang; Xin Cong; Zhong Zhang; Yankai Lin; Weiwen Liu; Yasheng Wang; Zhiyuan Liu; Fangming Liu; Maosong Sun,~Yaxi_Lu1; ~Shenzhi_Yang2; ~Cheng_Qian4; ~Guirong_Chen1; ~Qinyu_Luo1; ~Yesai_Wu1; ~Huadong_Wang1; ~Xin_Cong1; ~Zhong_Zhang5; ~Yankai_Lin1; ~Weiwen_Liu1; ~Yasheng_Wang1; ~Zhiyuan_Liu1; ~Fangming_Liu1; ~Maosong_Sun1,"{'value': ['Human-Centered NLP', 'Dialogue and Interactive Systems', 'Resources and Evaluation']}","{'value': 'Agents powered by large language models have shown remarkable abilities in solving complex tasks. However, most agent systems remain reactive, limiting their effectiveness in scenarios requiring foresight and autonomous decision-making. In this paper, we tackle the challenge of developing proactive agents capable of anticipating and initiating tasks without explicit human instructions. We propose a novel data-driven approach for this problem. Firstly, we collect real-world human activities to generate proactive task predictions. These predictions are then labeled by human annotators as either accepted or rejected. The labeled data is used to train a reward model that simulates human judgment and serves as an automatic evaluator of the proactiveness of LLM agents. Building on this, we develop a comprehensive data generation pipeline to create a diverse dataset, ProactiveBench, containing 6,790 events. Finally, we demonstrate that fine-tuning models with the proposed ProactiveBench can significantly elicit the proactiveness of LLM agents. Experimental results show that our fine-tuned model achieves an F1-Score of 66.47% in proactively offering assistance, outperforming all open-source and close-source models. These results highlight the potential of our method in creating more proactive and effective agent systems, paving the way for future advancements in human-agent collaboration.'}",https://openreview.net{'value': '/pdf/ba670e591dd33509822a7a0360e6a84be1debcd5.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=sLKDbuyq99,{'value': 'Flow: Modularized Agentic Workflow Automation'},Boye Niu; Yiliao Song; Kai Lian; Yifan Shen; Yu Yao; Kun Zhang; Tongliang Liu,~Boye_Niu1; ~Yiliao_Song2; ~Kai_Lian1; ~Yifan_Shen4; ~Yu_Yao3; ~Kun_Zhang1; ~Tongliang_Liu1,{'value': ['LLMs based Multi-Agent System']},"{'value': 'Multi-agent frameworks powered by large language models (LLMs) have demonstrated great success in automated planning and task execution. However, the effective adjustment of agentic workflows during execution has not been well studied. An effective workflow adjustment is crucial in real-world scenarios, as the initial plan must adjust to unforeseen challenges and changing conditions in real time to ensure the efficient execution of complex tasks. In this paper, we define workflows as an activity-on-vertex (AOV) graph, which allows continuous workflow refinement by LLM agents through dynamic subtask allocation adjustment based on historical performance and previous AOVs. To further enhance framework performance, we emphasize modularity in workflow design based on evaluating parallelism and dependency complexity. With this design, our proposed multi-agent framework achieves efficient concurrent execution of subtasks, effective goal achievement, and enhanced error tolerance. Empirical results across various practical tasks demonstrate significant improvements in the efficiency of multi-agent frameworks through dynamic workflow refinement and modularization.'}",https://openreview.net{'value': '/pdf/883b7c240d2be5b635b144abc546885546d7fa50.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=sIE2rI3ZPs,{'value': 'Understanding Optimization in Deep Learning with Central Flows'},Jeremy Cohen; Alex Damian; Ameet Talwalkar; J Zico Kolter; Jason D. Lee,~Jeremy_Cohen1; ~Alex_Damian1; ~Ameet_Talwalkar1; ~J_Zico_Kolter1; ~Jason_D._Lee1,"{'value': ['Edge of Stability', 'Optimization Dynamics', 'Adaptive Optimizers', 'RMSProp']}","{'value': 'Optimization in deep learning remains poorly understood.  A key difficulty is that optimizers exhibit complex oscillatory dynamics, referred to as ""edge of stability,"" which cannot be captured by traditional optimization theory.  In this paper, we show that the path taken by an oscillatory optimizer can often be captured by a  _central flow_: a differential equation which directly models the time-averaged (i.e. smoothed) optimization trajectory. We empirically show that these central flows can predict long-term optimization trajectories for generic neural networks with a high degree of numerical accuracy.  By interpreting these flows, we are able to understand  how gradient descent makes progress even as the loss sometimes goes up; how adaptive optimizers ``adapt\'\' to the local loss landscape; and how adaptive optimizers implicitly seek out regions of weight space where they can take larger steps.  These insights (and others) are not apparent from the optimizers\' update rules, but are revealed by the central flows.  Therefore, we believe that central flows constitute a promising tool for reasoning about optimization in deep learning.'}",https://openreview.net{'value': '/pdf/773f40669f7e2ab92922c0023c349db48767c444.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=sAYnDWaGd5,{'value': 'Quest: Query-centric Data Synthesis Approach for Long-context Scaling of Large Language Model'},Chaochen Gao; Xing W; Qi Fu; Songlin Hu,~Chaochen_Gao1; ~Xing_W1; ~Qi_Fu2; ~Songlin_Hu2,"{'value': ['longcontext', 'pre-training', 'scaling']}","{'value': ""Recent advancements in large language models (LLMs) have highlighted the importance of extending context lengths for handling complex tasks. While traditional methods for training on long contexts often use filtered long documents, these approaches lead to domain imbalances, limiting model performance. To address this, techniques like random document concatenation (Standard) and similarity-based methods (KNN, ICLM) have been developed. However, they either sacrifice semantic coherence or diversity. To balance both aspects, we introduce Quest, a query-centric data synthesis method aggregating semantically relevant yet diverse documents. Quest uses a generative model to predict potential queries for each document, grouping documents with similar queries and keywords. Extensive experiments demonstrate Quest's superior performance on long-context tasks, achieving remarkable results with context lengths of up to 1M tokens and confirming its scalability across various model sizes.""}",https://openreview.net{'value': '/pdf/2756cbc55bcf8b00533b450650cce52020323ce5.pdf'},{'title_filter': 'Data Synthesis'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=s0Z4csHOoE,{'value': 'VCR: A Task for Pixel-Level Complex Reasoning in Vision Language Models via Restoring Occluded Text'},Tianyu Zhang; Suyuchen Wang; Lu Li; Ge Zhang; Perouz Taslakian; Sai Rajeswar; Jie Fu; Bang Liu; Yoshua Bengio,~Tianyu_Zhang6; ~Suyuchen_Wang1; ~Lu_Li6; ~Ge_Zhang5; ~Perouz_Taslakian1; ~Sai_Rajeswar2; ~Jie_Fu2; ~Bang_Liu1; ~Yoshua_Bengio1,"{'value': ['dataset', 'vision-language model', 'multimodal']}","{'value': 'We introduce Visual Caption Restoration (VCR), a novel vision-language task that challenges models to accurately restore partially obscured texts using pixel-level hints within images through complex reasoning. This task stems from the observation that text embedded in images intrinsically differs from common visual elements and text due to the need to align the modalities of vision, text, and text embedded in images. While many works incorporate text into images for visual question answering, they mostly rely on OCR or masked language modeling, reducing the task to text-based processing. However, text-based processing becomes ineffective in VCR as accurate text restoration depends on the combined information from provided images, context, and subtle cues from the tiny, exposed areas of masked texts. We develop a pipeline to generate synthetic images for the VCR task using image-caption pairs, with adjustable caption visibility to control the task difficulty. With this pipeline, we construct VCR-WIKI for VCR using Wikipedia images with captions, including 2.11M English and 346K Chinese training entities, plus 5K validation and 5K test entities in both languages, each in easy and hard configurations. We also make a hidden test set, VCR-HIDDEN, to avoid potential overfitting on VCR-WIKI. Our results reveal that current vision-language models significantly lag behind human performance in the VCR task, and merely fine-tuning the models on our dataset does not lead to notable improvements. We release VCR-WIKI and the data construction code to facilitate future research.'}",https://openreview.net{'value': '/pdf/444ea1f0a0dc5c443bea8d92ef0b179d04c9a85a.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=rx0TCew0Lj,{'value': 'Beyond the convexity assumption: Realistic tabular data generation under quantifier-free real linear constraints'},Mihaela C. Stoian; Eleonora Giunchiglia,~Mihaela_C._Stoian1; ~Eleonora_Giunchiglia1,"{'value': ['tabular data generation', 'neuro-symbolic AI', 'informed machine learning', 'safe AI']}","{'value': 'Synthetic tabular data generation has traditionally been a challenging problem due to the high complexity of the underlying distributions that characterise this type of data. Despite recent advances in deep generative models (DGMs), existing methods often fail to produce realistic datapoints that are well-aligned with available background knowledge.\nIn this paper, we address this limitation by introducing Disjunctive Refinement Layer (DRL), a novel layer designed\nto enforce the alignment of generated data with the background knowledge specified in user-defined constraints.\nDRL is the first method able to automatically make deep learning models inherently compliant with constraints as expressive as quantifier-free linear formulas, which can define non-convex and even disconnected spaces. \nOur experimental analysis shows that DRL not only guarantees constraint satisfaction but also improves efficacy in downstream tasks. Notably, when applied to DGMs that frequently violate constraints, DRL eliminates violations entirely. Further, it improves performance metrics by up to 21.4\\% in F1-score and 20.9\\% in Area Under the ROC Curve, thus demonstrating its practical impact on data generation.'}",https://openreview.net{'value': '/pdf/b2d5323c2489a0183c79ad34aaef550721f57cb7.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=rvXdGL4pCJ,{'value': 'Robust Transfer of Safety-Constrained Reinforcement Learning Agents'},Markel Zubia; Thiago D. Simão; Nils Jansen,~Markel_Zubia1; ~Thiago_D._Simão1; ~Nils_Jansen1,"{'value': ['Reinforcement Learning', 'Safe Transfer', 'Adversarial Training', 'Robustness']}","{'value': 'Reinforcement learning (RL) often relies on trial and error, which may cause undesirable outcomes. As a result, standard RL is inappropriate for safety-critical applications. To address this issue, one may train a safe agent in a controlled environment (where safety violations are allowed) and then transfer it to the real world (where safety violations may have disastrous consequences). Prior work has made this transfer safe as long as the new environment preserves the safety-related dynamics. However, in most practical applications, differences or shifts in dynamics between the two environments are inevitable, potentially leading to safety violations after the transfer. This work aims to guarantee safety even when the new environment has different (safety-related) dynamics. In other words, we aim to make the process of safe transfer robust. Our methodology (1) robustifies an agent in the controlled environment and (2) provably provides---under mild assumption---a safe transfer to new environments. The empirical evaluation shows that this method yields policies that are robust against changes in dynamics, demonstrating safety after transfer to a new environment.'}",https://openreview.net{'value': '/pdf/ab9ae531a3eb122236bf4c5ea78b65a4436bec7c.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=ruv3HdK6he,{'value': 'Online-to-Offline RL for Agent Alignment'},Xu Liu; Haobo Fu; Stefano V Albrecht; QIANG FU; Shuai Li,~Xu_Liu12; ~Haobo_Fu2; ~Stefano_V_Albrecht1; ~QIANG_FU8; ~Shuai_Li3,"{'value': ['reinforcement learning', 'agent alignment']}","{'value': 'Reinforcement learning (RL) has shown remarkable success in training agents to achieve high-performing policies, particularly in domains like Game AI where simulation environments enable efficient interactions. However, despite their success in maximizing these returns, such online-trained policies often fail to align with human preferences concerning actions, styles, and values. The challenge lies in efficiently adapting these online-trained policies to align with human preferences, given the scarcity and high cost of collecting human behavior data. In this work, we formalize the problem as *online-to-offline* RL and propose ALIGNment of Game AI to Preferences (ALIGN-GAP), an innovative approach for the alignment of well-trained game agents to human preferences. Our method features a carefully designed reward model that encodes human preferences from limited offline data and incorporates curriculum-based preference learning to align RL agents with targeted human preferences. Experiments across diverse environments and preference types demonstrate the performance of ALIGN-GAP, achieving effective alignment with human preferences.'}",https://openreview.net{'value': '/pdf/d72e229b247a351871cb1f8ead57d453d1c8238f.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=rjuZyMfLSd,{'value': 'Learning system dynamics without forgetting'},Xikun ZHANG; Dongjin Song; Yushan Jiang; Yixin Chen; Dacheng Tao,~Xikun_ZHANG2; ~Dongjin_Song2; ~Yushan_Jiang1; ~Yixin_Chen1; ~Dacheng_Tao1,"{'value': ['graph neural networks', 'AI4Science', 'physics', 'biology']}","{'value': 'Observation-based trajectory prediction for systems with unknown dynamics is essential in fields such as physics and biology. Most existing approaches are limited to learning within a single system with fixed dynamics patterns. However, many real-world applications require learning across systems with evolving dynamics patterns, a challenge that has been largely overlooked. To address this, we systematically investigate the problem of Continual Dynamics Learning (CDL), examining task configurations and evaluating the applicability of existing techniques, while identifying key challenges. In response, we propose the Mode-switching Graph ODE (MS-GODE) model, which integrates the strengths LG-ODE and sub-network learning with a mode-switching module, enabling efficient learning over varying dynamics. Moreover, we construct a novel benchmark of biological dynamic systems for CDL, Bio-CDL, featuring diverse systems with disparate dynamics and significantly enriching the research field of machine learning for dynamic systems. Our code available at \\url{https://github.com/QueuQ/MS-GODE}.'}",https://openreview.net{'value': '/pdf/8b9997d033bdff7036078fb93a16025cc578eb8b.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=riieAeQBJm,{'value': 'UIFace: Unleashing Inherent Model Capabilities to Enhance Intra-Class Diversity in Synthetic Face Recognition'},Xiao Lin; Yuge Huang; Jianqing Xu; Yuxi Mi; Shuigeng Zhou; Shouhong Ding,~Xiao_Lin15; ~Yuge_Huang1; ~Jianqing_Xu1; ~Yuxi_Mi1; ~Shuigeng_Zhou1; ~Shouhong_Ding3,"{'value': ['face recognition', 'face image synthesis', 'diffusion model']}","{'value': ""Face recognition (FR) stands as one of the most crucial applications in computer vision. The accuracy of FR models has significantly improved in recent years due to the availability of large-scale human face datasets. However, directly using these datasets can inevitably lead to privacy and legal problems. Generating synthetic data to train FR models is a feasible solution to circumvent these issues. While existing synthetic-based face recognition methods have made significant progress in generating identity-preserving images, they are severely plagued by context overfitting, resulting in a lack of intra-class diversity of generated images and poor face recognition performance. In this paper, we propose a framework to $\\textbf{U}$nleash model $\\textbf{I}$nherent capabilities to enhance intra-class diversity for synthetic face recognition, shorted as $\\textbf{UIFace}$. Our framework first train a diffusion model that can perform denoising conditioned on either identity contexts or a learnable empty context. The former generates identity-preserving images but lacks variations, while the latter exploits the model's intrinsic ability to synthesize intra-class-diversified images but with random identities. Then we adopt a novel two-stage denoising strategy to fully leverage the strengths of both type of contexts, resulting in images that are diverse as well as identity-preserving. Moreover, an attention injection module is introduced to further augment the intra-class variations by utilizing attention maps from the empty context to guide the denoising process in ID-conditioned generation. Experiments show that our method significantly surpasses previous approaches with even less training data and half the size of synthetic dataset. More surprisingly, the proposed $\\textbf{UIFace}$ even achieves comparable performance of FR models trained on real datasets when we increase the number of synthetic identities.""}",https://openreview.net{'value': '/pdf/a245a6406f015c0ce9e6ab946189d6a8fc5850ba.pdf'},{'title_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=rhhQjGj09A,{'value': 'Optimal Protocols for Continual Learning via Statistical Physics and Control Theory'},Francesco Mori; Stefano Sarao Mannelli; Francesca Mignacco,~Francesco_Mori1; ~Stefano_Sarao_Mannelli1; ~Francesca_Mignacco1,"{'value': ['machine learning theory', 'statistical physics', 'online learning', 'continual learning', 'optimal control theory']}","{'value': 'Artificial neural networks often struggle with _catastrophic forgetting_ when learning multiple tasks sequentially, as training on new tasks degrades the performance on previously learned tasks. Recent theoretical work has addressed this issue by analysing learning curves in synthetic frameworks under predefined training protocols. However, these protocols relied on heuristics and lacked a solid theoretical foundation assessing their optimality. In this paper, we fill this gap by combining exact equations for training dynamics, derived using statistical physics techniques, with optimal control methods. We apply this approach to teacher-student models for continual learning and multi-task problems, obtaining a theory for task-selection protocols maximising performance while minimising forgetting. Our theoretical analysis offers non-trivial yet interpretable strategies for mitigating catastrophic forgetting, shedding light on how optimal learning protocols modulate established effects, such as the influence of task similarity on forgetting. Finally, we validate our theoretical findings with experiments on real-world data.'}",https://openreview.net{'value': '/pdf/fc8906565869a5db2dff20baaae05782eff0226d.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=rWQDzq3O5c,{'value': 'Graph Transformers Dream of Electric Flow'},Xiang Cheng; Lawrence Carin; Suvrit Sra,~Xiang_Cheng1; ~Lawrence_Carin2; ~Suvrit_Sra1,"{'value': ['Transformer', 'Graph Neural Network']}","{'value': ""We show theoretically and empirically that the linear Transformer, when applied to graph data, can implement algorithms that solve canonical problems such as electric flow and eigenvector decomposition. The Transformer has access to information on the input graph only via the graph's incidence matrix. We present explicit weight configurations for implementing each algorithm, and we bound the constructed Transformers' errors by the errors of the underlying algorithms. Our theoretical findings are corroborated by experiments on synthetic data. Additionally, on a real-world molecular regression task, we observe that the linear Transformer is capable of learning a more effective positional encoding than the default one based on Laplacian eigenvectors. Our work is an initial step towards elucidating the inner-workings of the Transformer for graph data. Code is available at https://github.com/chengxiang/LinearGraphTransformer""}",https://openreview.net{'value': '/pdf/c9d44d6a9f5d9c86f152f023f18b30bf570c8c90.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=rUxr9Ll5FQ,{'value': '$InterLCM$: Low-Quality Images as Intermediate States of Latent Consistency Models for Effective Blind Face Restoration'},Senmao Li; Kai Wang; Joost van de Weijer; Fahad Shahbaz Khan; Chun-Le Guo; Shiqi Yang; Yaxing Wang; jian Yang; Ming-Ming Cheng,~Senmao_Li2; ~Kai_Wang7; ~Joost_van_de_Weijer5; ~Fahad_Shahbaz_Khan1; ~Chun-Le_Guo1; ~Shiqi_Yang1; ~Yaxing_Wang3; ~jian_Yang14; ~Ming-Ming_Cheng3,"{'value': ['diffusion model', 'face restoration']}","{'value': 'Diffusion priors have been used for blind face restoration (BFR) by fine-tuning diffusion models (DMs) on restoration datasets to recover low-quality images. However, the naive application of DMs presents several key limitations. \n(i) The diffusion prior has inferior semantic consistency (e.g., ID, structure and color.),  increasing the difficulty of optimizing the BFR model;\n(ii) reliance on hundreds of denoising iterations, preventing the effective cooperation with perceptual losses, which is crucial for faithful restoration.\nObserving that the latent consistency model (LCM) learns consistency noise-to-data mappings on the ODE-trajectory and therefore shows more semantic consistency in the subject identity, structural information and color preservation, \nwe propose $\\textit{InterLCM}$ to leverage the LCM for its superior semantic consistency and efficiency to counter the above issues. \nTreating low-quality images as the intermediate state of LCM, $\\textit{InterLCM}$ achieves a balance between fidelity and quality by starting from earlier LCM steps. \nLCM also allows the integration of perceptual loss during training, leading to improved restoration quality, particularly in real-world scenarios.\nTo mitigate structural and semantic uncertainties, $\\textit{InterLCM}$ incorporates a Visual Module to extract visual features and a Spatial Encoder to capture spatial details, enhancing the fidelity of restored images.\nExtensive experiments demonstrate that $\\textit{InterLCM}$ outperforms existing approaches in both synthetic and real-world datasets while also achieving faster inference speed. Code and models will be publicly available.'}",https://openreview.net{'value': '/pdf/37e3e33897d915a9ae4fa47463c65a280d85a587.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=rUvCIvI4eB,"{'value': 'Towards Realistic UAV Vision-Language Navigation: Platform, Benchmark, and Methodology'}",Xiangyu Wang; Donglin Yang; Ziqin Wang; Hohin Kwan; Jinyu Chen; Wenjun Wu; Hongsheng Li; Yue Liao; Si Liu,~Xiangyu_Wang5; ~Donglin_Yang3; ~Ziqin_Wang2; ~Hohin_Kwan1; ~Jinyu_Chen2; ~Wenjun_Wu2; ~Hongsheng_Li3; ~Yue_Liao1; ~Si_Liu5,"{'value': ['Unmanned Aerial Vehicle', 'Drone', 'Vision-Language Navigation']}","{'value': 'Developing agents capable of navigating to a target location based on language instructions and visual information, known as vision-language navigation (VLN), has attracted widespread interest. Most research has focused on ground-based agents, while UAV-based VLN remains relatively underexplored. Recent efforts in UAV vision-language navigation predominantly adopt ground-based VLN settings, relying on predefined discrete action spaces and neglecting the inherent disparities in agent movement dynamics and the complexity of navigation tasks between ground and aerial environments. To address these disparities and challenges, we propose solutions from three perspectives: platform, benchmark, and methodology. To enable realistic UAV trajectory simulation in VLN tasks, we propose the OpenUAV platform,  which features diverse environments, realistic flight control, and extensive algorithmic support. We further construct a target-oriented VLN dataset consisting of approximately 12k trajectories on this platform, serving as the first dataset specifically designed for realistic UAV VLN tasks. To tackle the challenges posed by complex aerial environments, we propose an assistant-guided UAV object search benchmark called UAV-Need-Help, which provides varying levels of guidance information to help UAVs better accomplish realistic VLN tasks. We also propose a UAV navigation LLM that, given multi-view images, task descriptions, and assistant instructions, leverages the multimodal understanding capabilities of the MLLM to jointly process visual and textual information, and performs hierarchical trajectory generation. The evaluation results of our method significantly outperform the baseline models, while there remains a considerable gap between our results and those achieved by human operators, underscoring the challenge presented by the UAV-Need-Help task.'}",https://openreview.net{'value': '/pdf/f6dd1708c5bea6d1e7af5637983d1beb4f8f025b.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=rQ7fz9NO7f,{'value': 'Multimodal Large Language Models for Inverse Molecular Design with Retrosynthetic Planning'},Gang Liu; Michael Sun; Wojciech Matusik; Meng Jiang; Jie Chen,~Gang_Liu6; ~Michael_Sun1; ~Wojciech_Matusik2; ~Meng_Jiang3; ~Jie_Chen1,"{'value': ['Multimodal Large Languge Models', 'Large Languge Models', 'Graph Diffusion Models', 'Inverse Molecular Design', 'Retrosynthesis']}","{'value': 'While large language models (LLMs) have integrated images, adapting them to graphs remains challenging, limiting their applications in materials and drug design. This difficulty stems from the need for coherent autoregressive generation across texts and graphs. To address this, we introduce Llamole, the first multimodal LLM capable of interleaved text and graph generation, enabling molecular inverse design with retrosynthetic planning. Llamole integrates a base LLM with the Graph Diffusion Transformer and Graph Neural Networks for multi-conditional molecular generation and reaction inference within texts, while the LLM, with enhanced molecular understanding, flexibly controls activation among the different graph modules. Additionally, Llamole integrates A* search with LLM-based cost functions for efficient retrosynthetic planning. We create benchmarking datasets and conduct extensive experiments to evaluate Llamole against in-context learning and supervised fine-tuning. Llamole significantly outperforms 14 adapted LLMs across 12 metrics for controllable molecular design and retrosynthetic planning. Code and model at https://github.com/liugangcode/Llamole.'}",https://openreview.net{'value': '/pdf/5255ae28630fb2c9d7ee9be9ef1dadd310dbc318.pdf'},{'title_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=rDLgnYLM5b,{'value': 'Interleaved Scene Graphs for Interleaved Text-and-Image Generation Assessment'},Dongping Chen; Ruoxi Chen; Shu Pu; Zhaoyi Liu; Yanru Wu; Caixi Chen; Benlin Liu; Yue Huang; Yao Wan; Pan Zhou; Ranjay Krishna,~Dongping_Chen1; ~Ruoxi_Chen1; ~Shu_Pu1; ~Zhaoyi_Liu1; ~Yanru_Wu2; ~Caixi_Chen1; ~Benlin_Liu1; ~Yue_Huang9; ~Yao_Wan2; ~Pan_Zhou5; ~Ranjay_Krishna1,"{'value': ['Interleaved Text-and-Image Generation', 'Generative Models', 'Multimodal Large Language Model', 'Scene Graphs', 'Automatic Evaluation', 'Benchmark']}","{'value': 'Many real-world user queries (e.g. *""How do to make egg fried rice?""*) could benefit from systems capable of generating responses with both textual steps with accompanying images, similar to a cookbook.\nModels designed to generate interleaved text and images face challenges in ensuring consistency within and across these modalities.\nTo address these challenges, we present ISG, a comprehensive evaluation framework for interleaved text-and-image generation. ISG leverages a scene graph structure to capture relationships between text and image blocks, evaluating responses on four levels of granularity: holistic, structural, block-level, and image-specific. This multi-tiered evaluation allows for a nuanced assessment of consistency, coherence, and accuracy, and provides interpretable question-answer feedback.\nIn conjunction with ISG, we introduce a benchmark, ISG-Bench, encompassing 1,150 samples across 8 categories and 21 subcategories. This benchmark dataset includes complex language-vision dependencies and golden answers to evaluate models effectively on vision-centric tasks such as style transfer, a challenging area for current models. \nUsing ISG-Bench, we demonstrate that recent unified vision-language models perform poorly on generating interleaved content. While compositional approaches that combine separate language and image models show a 111% improvement over unified models at the holistic level, their performance remains suboptimal at both block and image levels.\nTo facilitate future work, we develop ISG-Agent, a baseline agent employing a *""plan-execute-refine""* pipeline to invoke tools, achieving a 122% performance improvement.'}",https://openreview.net{'value': '/pdf/ef41bb7265de5ddb2c2cd3f9069830dde50257dc.pdf'},{'abstract_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=rDIf6NA5mj,{'value': 'Exposure Bracketing Is All You Need For A High-Quality Image'},Zhilu Zhang; Shuohao Zhang; Renlong Wu; Zifei Yan; Wangmeng Zuo,~Zhilu_Zhang2; ~Shuohao_Zhang2; ~Renlong_Wu2; ~Zifei_Yan2; ~Wangmeng_Zuo2,"{'value': ['Exposure Bracketing', 'Image Restoration and Enhancement']}","{'value': 'It is highly desired but challenging to acquire high-quality photos with clear content in low-light environments. Although multi-image processing methods (using burst, dual-exposure, or multi-exposure images) have made significant progress in addressing this issue, they typically focus on specific restoration or enhancement problems, and do not fully explore the potential of utilizing multiple images. Motivated by the fact that multi-exposure images are complementary in denoising, deblurring, high dynamic range imaging, and super-resolution, we propose to utilize exposure bracketing photography to get a high-quality image by combining these tasks in this work. Due to the difficulty in collecting real-world pairs, we suggest a solution that first pre-trains the model with synthetic paired data and then adapts it to real-world unlabeled images. In particular, a temporally modulated recurrent network (TMRNet) and self-supervised adaptation method are proposed. Moreover, we construct a data simulation pipeline to synthesize pairs and collect real-world images from 200 nighttime scenarios. Experiments on both datasets show that our method performs favorably against the state-of-the-art multi-image processing ones. Code and datasets are available at https://github.com/cszhilu1998/BracketIRE.'}",https://openreview.net{'value': '/pdf/fa5cc0a8903c361e8169d28847d61017e5a99c0a.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=rCX9l4OTCT,{'value': 'Semi-Supervised Vision-Centric 3D Occupancy World Model for Autonomous Driving'},Xiang Li; Pengfei Li; Yupeng Zheng; Wei Sun; Yan Wang; yilun chen,~Xiang_Li88; ~Pengfei_Li6; ~Yupeng_Zheng1; ~Wei_Sun23; ~Yan_Wang12; ~yilun_chen4,{'value': ['Autonomous Driving; Occupancy; World Model']},"{'value': 'Understanding world dynamics is crucial for planning in autonomous driving. Recent methods attempt to achieve this by learning a 3D occupancy world model that forecasts future surrounding scenes based on current observation. However, 3D occupancy labels are still required to produce promising results. Considering the high annotation cost for 3D outdoor scenes, we propose a semi-supervised vision-centric 3D occupancy world model, **PreWorld**, to leverage the potential of 2D labels through a novel two-stage training paradigm: the self-supervised pre-training stage and the fully-supervised fine-tuning stage. Specifically, during the pre-training stage, we utilize an attribute projection head to generate different attribute fields of a scene (e.g., RGB, density, semantic), thus enabling temporal supervision from 2D labels via volume rendering techniques. Furthermore, we introduce a simple yet effective state-conditioned forecasting module to recursively forecast future occupancy and ego trajectory in a direct manner. Extensive experiments on the nuScenes dataset validate the effectiveness and scalability of our method, and demonstrate that PreWorld achieves competitive performance across 3D occupancy prediction, 4D occupancy forecasting and motion planning tasks.'}",https://openreview.net{'value': '/pdf/1ebadb32648593e11d17c7b03031ce84fe8eb3ae.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=r3cEOVj7Ze,{'value': 'Neuralized Markov Random Field for Interaction-Aware Stochastic Human Trajectory Prediction'},Zilin Fang; David Hsu; Gim Hee Lee,~Zilin_Fang1; ~David_Hsu1; ~Gim_Hee_Lee1,"{'value': ['human trajectory prediction', 'interaction modeling']}","{'value': ""Interactive human motions and the continuously changing nature of intentions pose significant challenges for human trajectory prediction. In this paper, we present a neuralized Markov random field (MRF)-based motion evolution method for probabilistic interaction-aware human trajectory prediction. We use MRF to model each agent's motion and the resulting crowd interactions over time, hence is robust against noisy observations and enables group reasoning. We approximate the modeled distribution using two conditional variational autoencoders (CVAEs) for efficient learning and inference. Our proposed method achieves state-of-the-art performance on ADE/FDE metrics across two dataset categories: overhead datasets ETH/UCY, SDD, and NBA, and ego-centric JRDB. Furthermore, our approach allows for real-time stochastic inference in bustling environments, making it well-suited for a 30FPS video setting. We open-source our codes at: https://github.com/AdaCompNUS/NMRF_TrajectoryPrediction.git""}",https://openreview.net{'value': '/pdf/1088e156ba1ce45e32169e6b2eb0c0b2bc920e30.pdf'},{'title_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=r1KcapkzCt,{'value': 'Monte Carlo Planning with Large Language Model for Text-Based Game Agents'},Zijing Shi; Meng Fang; Ling Chen,~Zijing_Shi1; ~Meng_Fang1; ~Ling_Chen5,"{'value': ['Large language model', 'Monte Carlo tree search', 'Text-based games']}","{'value': 'Text-based games provide valuable environments for language-based autonomous agents. However, planning-then-learning paradigms, such as those combining Monte Carlo Tree Search (MCTS) and reinforcement learning (RL), are notably time-consuming due to extensive iterations. Additionally, these algorithms perform uncertainty-driven exploration but lack language understanding and reasoning abilities.\nIn this paper, we introduce the Monte Carlo planning with Dynamic Memory-guided Large language model (MC-DML) algorithm. MC-DML leverages the language understanding and reasoning capabilities of Large Language Models (LLMs) alongside the exploratory advantages of tree search algorithms. Specifically, we enhance LLMs with in-trial and cross-trial memory mechanisms, enabling them to learn from past experiences and dynamically adjust action evaluations during planning. We conduct experiments on a series of text-based games from the Jericho benchmark. Our results demonstrate that the MC-DML algorithm significantly enhances performance across various games at the initial planning phase, outperforming strong contemporary methods that require multiple iterations. This demonstrates the effectiveness of our algorithm, paving the way for more efficient language-grounded planning in complex environments.'}",https://openreview.net{'value': '/pdf/ae71224eabd75b46858af897797ca42c6e25d161.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=qnlG3zPQUy,"{'value': 'ILLUSION: Unveiling Truth with a Comprehensive Multi-Modal, Multi-Lingual Deepfake Dataset'}",Kartik Thakral; Rishabh Ranjan; Akanksha Singh; Akshat Jain; Mayank Vatsa; Richa Singh,~Kartik_Thakral1; ~Rishabh_Ranjan4; ~Akanksha_Singh1; ~Akshat_Jain2; ~Mayank_Vatsa1; ~Richa_Singh1,"{'value': ['Multi-modal', 'Multi-Lingual', 'Deepfake', 'AIGC']}","{'value': 'The proliferation of deepfakes and AI-generated content has led to a surge in media forgeries and misinformation, necessitating robust detection systems. However, current datasets lack diversity across modalities, languages, and real-world scenarios. To address this gap, we present ILLUSION (Integration of Life-Like Unique Synthetic Identities and Objects from Neural Networks), a large-scale, multi-modal\ndeepfake dataset comprising 1.3 million samples spanning audio-visual forgeries, 26 languages, challenging noisy environments, and various manipulation protocols. Generated using 28 state-of-the-art generative techniques, ILLUSION includes\nfaceswaps, audio spoofing, synchronized audio-video manipulations, and synthetic media while ensuring a balanced representation of gender and skin tone for unbiased evaluation. Using Jaccard Index and UpSet plot analysis, we demonstrate ILLUSION’s distinctiveness and minimal overlap with existing datasets, emphasizing its novel generative coverage. We benchmarked image, audio, video, and multi-modal detection models, revealing key challenges such as performance degradation in multilingual and multi-modal contexts, vulnerability to real-world distortions, and limited generalization to zero-day attacks. By bridging synthetic and real-world complexities, ILLUSION provides a challenging yet essential platform for advancing deepfake detection research. The dataset is publicly available at https://www.iab-rubric.org/illusion-database.'}",https://openreview.net{'value': '/pdf/b4b0f39d84d66fbd58c0ce677e7f47db34c37ab8.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=qn9tBYQHGi,{'value': 'Do LLM Agents  Have Regret? A Case Study in Online Learning and Games'},Chanwoo Park; Xiangyu Liu; Asuman E. Ozdaglar; Kaiqing Zhang,~Chanwoo_Park2; ~Xiangyu_Liu4; ~Asuman_E._Ozdaglar1; ~Kaiqing_Zhang3,"{'value': ['LLM agents', 'online learning', 'repeated games']}","{'value': 'Large language models (LLMs) have been increasingly employed for (interactive) decision-making, via the development of LLM-based autonomous agents. Despite their emerging successes, the performance of LLM agents in decision-making has not been fully investigated through quantitative metrics, especially in the multi-agent setting when they interact with each other, a typical scenario in real-world LLM-agent applications. To better understand the limits of LLM agents in these interactive environments, we propose to study their interactions in benchmark decision-making settings in online learning and game theory, through the performance metric of regret. We first empirically study the no-regret behaviors of LLMs in canonical non-stochastic online learning problems, as well as the emergence of equilibria when LLM agents interact through playing repeated games. We then provide some theoretical insights into the no-regret behaviors of LLM agents, under certain assumptions on the supervised pre-training and the rationality model of human decision-makers who generate the data. Notably, we also identify (simple) cases where advanced LLMs such as GPT-4 fail to be no-regret. To further promote the no-regret behaviors, we propose a novel unsupervised training loss of regret-loss, which, in contrast to the supervised pre-training loss, does not require the labels of (optimal) actions. Finally, we establish the statistical guarantee of generalization bound for regret-loss minimization, and more importantly, the optimization guarantee that minimizing such a loss may automatically lead to known no-regret learning algorithms, when single-layer self-attention models are used. Our further experiments demonstrate the effectiveness of our regret-loss, especially in addressing the above “regrettable” cases.'}",https://openreview.net{'value': '/pdf/88d130b2e887a122503575d02928071c8af55f61.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=qG0WCAhZE0,{'value': 'Multi-Perspective Data Augmentation for Few-shot Object Detection'},Anh Khoa Nguyen Vu; Truong Quoc Truong; Vinh-Tiep Nguyen; Thanh Duc Ngo; Thanh-Toan Do; Tam V. Nguyen,~Anh_Khoa_Nguyen_Vu1; ~Truong_Quoc_Truong1; ~Vinh-Tiep_Nguyen3; ~Thanh_Duc_Ngo1; ~Thanh-Toan_Do4; ~Tam_V._Nguyen2,"{'value': ['few-shot object detection', 'controllable diffusion', 'data augmentation']}","{'value': 'Recent few-shot object detection (FSOD) methods have focused on  augmenting synthetic samples for novel classes, show promising results  to the rise of diffusion models. However, the diversity of such datasets is often limited in representativeness because they lack awareness of typical and hard samples, especially in the context of foreground and background relationships. To tackle this issue, we propose a Multi-Perspective Data Augmentation (MPAD) framework. In terms of foreground-foreground relationships, we propose in-context learning for object synthesis (ICOS) with bounding box adjustments to enhance the detail and spatial information of synthetic samples. Inspired by the large margin principle, support samples play a vital role in defining class boundaries. Therefore, we design a Harmonic Prompt Aggregation Scheduler (HPAS) to mix prompt embeddings at each time step of the generation process in diffusion models, producing hard novel samples. For foreground-background relationships, we introduce a Background Proposal method (BAP) to sample typical and hard backgrounds. Extensive experiments on multiple FSOD benchmarks demonstrate the effectiveness of our approach. Our framework significantly outperforms traditional methods, achieving an average increase of $17.5\\%$ in nAP50 over the baseline on PASCAL VOC.'}",https://openreview.net{'value': '/pdf/693104c88898215aac68d442b8f5e0d9f74ff68c.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=peX9zpWgg4,{'value': 'Adaptive Shrinkage Estimation for Personalized Deep Kernel Regression in Modeling Brain Trajectories'},Vasiliki Tassopoulou; Haochang Shou; Christos Davatzikos,~Vasiliki_Tassopoulou1; ~Haochang_Shou1; ~Christos_Davatzikos1,"{'value': ['Deep Kernel Regression', 'Personalization', 'Posterior Correction', 'Longitudinal Biomarker Prediction']}","{'value': 'Longitudinal biomedical studies monitor individuals over time to capture dynamics in brain development, disease progression, and treatment effects. However, estimating trajectories of brain biomarkers is challenging due to biological variability, inconsistencies in measurement protocols (e.g., differences in MRI scanners) as well as scarcity and irregularity in longitudinal measurements. Herein,\nwe introduce a novel personalized deep kernel regression framework for forecasting brain biomarkers, with application to regional volumetric measurements. Our approach integrates two key components: a population model that captures brain trajectories from a large and diverse cohort, and a subject-specific model that captures individual trajectories. To optimally combine these, we propose Adaptive Shrinkage Estimation, which effectively balances population and subject-specific models. We assess our model’s performance through predictive accuracy metrics, uncertainty quantification, and validation against external clinical studies. Benchmarking against state-of-the-art statistical and machine learning models—including linear mixed effects models, generalized additive models, and deep learning methods—demonstrates the superior predictive performance of our approach. Additionally, we apply our method to predict trajectories of composite neuroimaging biomarkers, which highlights the versatility of our approach in modeling the progression of longitudinal neuroimaging biomarkers. Furthermore, validation on three external neuroimaging studies confirms the robustness of our method across different clinical contexts. We make the code available at https://github.com/vatass/AdaptiveShrinkageDKGP.'}",https://openreview.net{'value': '/pdf/bf8e15523ef08c9b2f455cc5358e8affa4a9b874.pdf'},{'title_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=pSdE7PIA64,{'value': 'Leveraging Flatness to Improve Information-Theoretic Generalization Bounds for SGD'},Ze Peng; Jian Zhang; Yisen Wang; Lei Qi; Yinghuan Shi; Yang Gao,~Ze_Peng1; ~Jian_Zhang21; ~Yisen_Wang1; ~Lei_Qi1; ~Yinghuan_Shi3; ~Yang_Gao3,{'value': ['information theory; implicit bias; deep learning theory; convex optimization; learning theory']},"{'value': 'Information-theoretic (IT) generalization bounds have been used to study the generalization of learning algorithms. These bounds are intrinsically data- and algorithm-dependent so that one can exploit the properties of data and algorithm to derive tighter bounds. However, we observe that although the flatness bias is crucial for SGD’s generalization, these bounds fail to capture the improved generalization under better flatness and are also numerically loose. This is caused by the inadequate leverage of SGD\'s flatness bias in existing IT bounds. This paper derives a more flatness-leveraging IT bound for the flatness-favoring SGD. The bound indicates the learned models generalize better if the large-variance directions of the final weight covariance have small local curvatures in the loss landscape. Experiments on deep neural networks show our bound not only correctly reflects the better generalization when flatness is improved, but is also numerically much tighter. This is achieved by a flexible technique called ""omniscient trajectory"". When applied to Gradient Descent’s minimax excess risk on convex-Lipschitz-Bounded problems, it improves representative IT bounds’ $\\Omega(1)$ rates to $O(1/\\sqrt{n})$. It also implies a by-pass of memorization-generalization trade-offs. Codes are available at [https://github.com/peng-ze/omniscient-bounds](https://github.com/peng-ze/omniscient-bounds).'}",https://openreview.net{'value': '/pdf/08a28cf7e4f32e16c8e87b60285f8a2813f9c22d.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=pDDODPtpx9,{'value': 'Distribution-Free Data Uncertainty for Neural Network Regression'},Domokos M. Kelen; Ádám Jung; Péter Kersch; Andras A Benczur,~Domokos_M._Kelen1; ~Ádám_Jung1; ~Péter_Kersch1; ~Andras_A_Benczur1,"{'value': ['deep learning', 'uncertainty quantification', 'regression uncertainty', 'aleatoric uncertainty', 'scoring rules', 'continuous ranked probability score']}","{'value': ""Quantifying uncertainty is an essential part of predictive modeling, especially in the context of high-stakes decision-making. While classification output includes data uncertainty by design in the form of class probabilities, the regression task generally aims only to predict the expected value of the target variable. Probabilistic extensions often assume parametric distributions around the expected value, optimizing the likelihood over the resulting explicit densities. However, using parametric distributions can limit practical applicability, making it difficult for models to capture skewed, multi-modal, or otherwise complex distributions. In this paper, we propose optimizing a novel nondeterministic neural network regression architecture for loss functions derived from a sample-based approximation of the continuous ranked probability score (CRPS), enabling a truly distribution-free approach by learning to sample from the target's aleatoric distribution, rather than predicting explicit densities. Our approach allows the model to learn well-calibrated, arbitrary uni- and multivariate output distributions. We evaluate the method on a variety of synthetic and real-world tasks, including uni- and multivariate problems, function inverse approximation, and standard regression uncertainty benchmarks. Finally, we make all experiment code publicly available.""}",https://openreview.net{'value': '/pdf/763c2430cbe272fedf9975b8a70e6635341bdd56.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=pCj2sLNoJq,{'value': 'A Generalist Hanabi Agent'},Arjun V Sudhakar; Hadi Nekoei; Mathieu Reymond; Miao Liu; Janarthanan Rajendran; Sarath Chandar,~Arjun_V_Sudhakar2; ~Hadi_Nekoei1; ~Mathieu_Reymond1; ~Miao_Liu1; ~Janarthanan_Rajendran1; ~Sarath_Chandar1,"{'value': ['Multi-Agent Reinforcement Learning (MARL)', 'Cooperative game', 'Multi Agent Text-based game']}","{'value': 'Traditional multi-agent reinforcement learning (MARL) systems can develop cooperative strategies through repeated interactions. However, these systems are unable to perform well on any other setting than the one they have been trained on, and struggle to successfully cooperate with unfamiliar collaborators. This is particularly visible in the Hanabi benchmark, a popular 2-to-5 player cooperative card-game which requires complex reasoning and precise assistance to other agents. Current MARL agents for Hanabi can only learn one specific game-setting (e.g., 2-player games), and play with the same algorithmic agents. This is in stark contrast to humans, who can quickly adjust their strategies to work with unfamiliar partners or situations. In this paper, we introduce Recurrent Replay Relevance Distributed DQN (R3D2), a generalist agent for Hanabi, designed to overcome these limitations. We reformulate the task using text, as language has been shown to improve transfer. We then propose a distributed MARL algorithm that copes with the resulting dynamic observation- and action-space. In doing so, our agent is the first that can play all game settings concurrently, and extend strategies learned from one setting to other ones. As a consequence, our agent also demonstrates the ability to collaborate with different algorithmic agents ---agents that are themselves unable to do so.'}",https://openreview.net{'value': '/pdf/4dcaf7b53587ec743c88b18b24bd2edf6ba34bfc.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=pB1XSj2y4X,{'value': 'Generative Flows on Synthetic Pathway for Drug Design'},Seonghwan Seo; Minsu Kim; Tony Shen; Martin Ester; Jinkyoo Park; Sungsoo Ahn; Woo Youn Kim,~Seonghwan_Seo1; ~Minsu_Kim2; ~Tony_Shen1; ~Martin_Ester1; ~Jinkyoo_Park1; ~Sungsoo_Ahn1; ~Woo_Youn_Kim1,"{'value': ['GFlowNet', 'synthesizability', 'structure-based drug design', 'molecule optimization']}","{'value': 'Generative models in drug discovery have recently gained attention as efficient alternatives to brute-force virtual screening. However, most existing models do not account for synthesizability, limiting their practical use in real-world scenarios. In this paper, we propose RxnFlow, which sequentially assembles molecules using predefined molecular building blocks and chemical reaction templates to constrain the synthetic chemical pathway. We then train on this sequential generating process with the objective of generative flow networks (GFlowNets) to generate both highly rewarded and diverse molecules. To mitigate the large action space of synthetic pathways in GFlowNets, we implement a novel action space subsampling method. This enables RxnFlow to learn generative flows over extensive action spaces comprising combinations of 1.2 million building blocks and 71 reaction templates without significant computational overhead. Additionally, RxnFlow can employ modified or expanded action spaces for generation without retraining, allowing for the introduction of additional objectives or the incorporation of newly discovered building blocks. We experimentally demonstrate that RxnFlow outperforms existing reaction-based and fragment-based models in pocket-specific optimization across various target pockets. Furthermore, RxnFlow achieves state-of-the-art performance on CrossDocked2020 for pocket-conditional generation, with an average Vina score of –8.85 kcal/mol and 34.8% synthesizability. Code is available at https://github.com/SeonghwanSeo/RxnFlow.'}",https://openreview.net{'value': '/pdf/912111ec0cbaaf49ebf601cfa5816e4a247dbfd1.pdf'},{'title_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=owP2mymrTD,{'value': 'Facilitating Multi-turn Function Calling for LLMs via Compositional Instruction Tuning'},Mingyang Chen; sunhaoze; Tianpeng Li; Fan Yang; Hao Liang; KeerLu; Bin CUI; Wentao Zhang; Zenan Zhou; weipeng chen,~Mingyang_Chen3; ~sunhaoze1; ~Tianpeng_Li1; ~Fan_Yang81; ~Hao_Liang7; ~KeerLu1; ~Bin_CUI2; ~Wentao_Zhang1; ~Zenan_Zhou1; ~weipeng_chen2,"{'value': ['large language model', 'function calling', 'instruction tuning', 'synthetic data']}","{'value': 'Large Language Models (LLMs) have exhibited significant potential in performing diverse tasks, including the ability to call functions or use external tools to enhance their performance. While current research on function calling by LLMs primarily focuses on single-turn interactions, this paper addresses the overlooked necessity for LLMs to engage in multi-turn function calling—critical for handling compositional, real-world queries that require planning with functions but not only use functions. To facilitate this, we introduce an approach, BUTTON, which generates synthetic compositional instruction tuning data via bottom-up instruction construction and top-down trajectory generation. In the bottom-up phase, we generate simple atomic tasks based on real-world scenarios and build compositional tasks using heuristic strategies based on atomic tasks. Corresponding function definitions are then synthesized for these compositional tasks. The top-down phase features a multi-agent environment where interactions among simulated humans, assistants, and tools are utilized to gather multi-turn function calling trajectories. This approach ensures task compositionality and allows for effective function and trajectory generation by examining atomic tasks within compositional tasks. We produce a dataset BUTTONInstruct comprising 8k data points and demonstrate its effectiveness through extensive experiments across various LLMs.'}",https://openreview.net{'value': '/pdf/bddc07777716e293010f1c92044e3f7cc25fb4aa.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=otW0TJOUYF,{'value': 'Hypothetical Minds: Scaffolding Theory of Mind for Multi-Agent Tasks with Large Language Models'},Logan Cross; Violet Xiang; Agam Bhatia; Daniel LK Yamins; Nick Haber,~Logan_Cross1; ~Violet_Xiang1; ~Agam_Bhatia1; ~Daniel_LK_Yamins1; ~Nick_Haber1,"{'value': ['LLM agents', 'language agents', 'theory of mind', 'multi-agent']}","{'value': ""Multi-agent reinforcement learning (MARL) methods struggle with the non-stationarity of multi-agent systems and fail to adaptively learn online when tested with novel agents. Here, we leverage large language models (LLMs) to create an autonomous agent that can handle these challenges. Our agent, Hypothetical Minds, consists of a cognitively-inspired architecture, featuring modular components for perception, memory, and hierarchical planning over two levels of abstraction. We introduce the Theory of Mind module that scaffolds the high-level planning process by generating hypotheses about other agents' strategies in natural language. It then evaluates and iteratively refines these hypotheses by reinforcing hypotheses that make correct predictions about the other agents' behavior. Hypothetical Minds significantly improves performance over previous LLM-agent and RL baselines on a range of competitive, mixed motive, and collaborative domains in the Melting Pot benchmark, including both dyadic and population-based environments. Additionally, comparisons against LLM-agent baselines and ablations reveal the importance of hypothesis evaluation and refinement for succeeding on complex scenarios.""}",https://openreview.net{'value': '/pdf/b85a375d8c5672bb041b204393e3cab2f1552cac.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=oc4yw7zX9T,{'value': 'Minimax Optimal Two-Stage Algorithm For Moment Estimation Under Covariate Shift'},Zhen Zhang; Xin Liu; Shaoli Wang; Jiaye Teng,~Zhen_Zhang17; ~Xin_Liu15; ~Shaoli_Wang1; ~Jiaye_Teng2,"{'value': ['covariate shift', 'minimax optimal', 'two-stage algorithm', 'double robustness']}","{'value': ""Covariate shift occurs when the distribution of input features differs between the training and testing phases.  In covariate shift, estimating an unknown function's moment is a classical problem that remains under-explored, despite its common occurrence in real-world scenarios. In this paper, we investigate the minimax lower bound of the problem when the source and target distributions are known. To achieve the minimax optimal bound (up to a logarithmic factor), we propose a two-stage algorithm. Specifically, it first trains an optimal estimator for the function under the source distribution, and then uses a likelihood ratio reweighting procedure to calibrate the moment estimator. In practice, the source and target distributions are typically unknown, and estimating the likelihood ratio may be unstable. To solve this problem, we propose a truncated version of the estimator that ensures double robustness and provide the corresponding upper bound. Extensive numerical studies on synthetic examples confirm our theoretical findings and further illustrate the effectiveness of our proposed method.""}",https://openreview.net{'value': '/pdf/5691ab2a1df384f1311df1e6190b3da8ab248e52.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=oYemKnlIrO,{'value': 'Do Mice Grok? Glimpses of Hidden Progress in Sensory Cortex'},Tanishq Kumar; Blake Bordelon; Cengiz Pehlevan; Venkatesh N Murthy; Samuel J. Gershman,~Tanishq_Kumar1; ~Blake_Bordelon1; ~Cengiz_Pehlevan2; ~Venkatesh_N_Murthy1; ~Samuel_J._Gershman1,{'value': ['neuroscience; representation learning; grokking; overtraining; cortex']},"{'value': 'Does learning of task-relevant representations stop when behavior stops changing? Motivated by recent work in machine learning and the intuitive observation that human experts continue to learn after mastery, we hypothesize that task-specific representation learning in cortex can continue, even when behavior saturates. In a novel reanalysis of recently published neural data, we find evidence for such learning in posterior piriform cortex of mice following continued training on a task, long after behavior saturates at near-ceiling performance (""overtraining""). We demonstrate that class representations in cortex continue to separate during overtraining, so that examples that were incorrectly classified at the beginning of overtraining can abruptly be correctly classified later on, despite no changes in behavior during that time. We hypothesize this hidden learning takes the form of approximate margin maximization; we validate this and other predictions in the neural data, as well as build and interpret a simple synthetic model that recapitulates these phenomena. We conclude by demonstrating how this model of late-time feature learning implies an explanation for the empirical puzzle of overtraining reversal in animal learning, where task-specific representations are more robust to particular task changes because the learned features can be reused.'}",https://openreview.net{'value': '/pdf/15e2e994612304f9f45ff7d8fd95c6acdfa41bc9.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=oWdzUpOlkX,{'value': 'AgentOccam: A Simple Yet Strong Baseline for LLM-Based Web Agents'},Ke Yang; Yao Liu; Sapana Chaudhary; Rasool Fakoor; Pratik Chaudhari; George Karypis; Huzefa Rangwala,~Ke_Yang7; ~Yao_Liu1; ~Sapana_Chaudhary1; ~Rasool_Fakoor1; ~Pratik_Chaudhari1; ~George_Karypis1; ~Huzefa_Rangwala2,"{'value': ['LLM', 'Agent', 'LLM-based Agent', 'Web Agent', 'Web Navigation']}","{'value': ""Autonomy via agents based on large language models (LLMs) that can carry out personalized yet standardized tasks presents a significant opportunity to drive human efficiency. There is an emerging need and interest in automating web tasks  (e.g., booking a hotel for a given date within a budget). Being a practical use case itself, the web agent also serves as an important proof-of-concept example for various agent grounding scenarios, with its success promising advancements in many future applications. Meanwhile, much prior research focuses on handcrafting their web agent strategies (e.g., agent's prompting templates, reflective workflow, role-play and multi-agent systems, search or sampling methods, etc.) and the corresponding in-context examples. However, these custom strategies often struggle with generalizability across all potential real-world applications. On the other hand, there has been limited study on the misalignment between a web agent's observation and action representation, and the data on which the agent's underlying LLM has been pre-trained. This discrepancy is especially notable when LLMs are primarily trained for language completion rather than tasks involving embodied navigation actions and symbolic web elements. In our study, we enhance an LLM-based web agent by simply refining its observation and action space, aligning these more closely with the LLM's capabilities. This approach enables our base agent to significantly outperform previous methods on a wide variety of web tasks. Specifically, on WebArena, a benchmark featuring general-purpose web interaction tasks, our agent AgentOccam surpasses the previous state-of-the-art and concurrent work by 9.8 (+29.4%) and 5.9 (+15.8%) absolute points respectively, and boosts the success rate by 26.6 points (+161%) over similar plain web agents with its observation and action space alignment. Furthermore, on WebVoyager benchmark comprising tasks defined on real-world websites, AgentOccam exceeds the former best agent by 2.4 points (+4.6%) on tasks with deterministic answers. We achieve this without using in-context examples, new agent roles, online feedback or search strategies. AgentOccam's simple design highlights LLMs' impressive zero-shot performance on web tasks, and underlines the critical role of carefully tuning observation and action spaces for LLM-based agents.""}",https://openreview.net{'value': '/pdf/d378f87ead0bfa73dce1fb6cfec99e4b7095acb5.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=oVKEAFjEqv,{'value': 'WebRL: Training LLM Web Agents via Self-Evolving Online Curriculum Reinforcement Learning'},Zehan Qi; Xiao Liu; Iat Long Iong; Hanyu Lai; Xueqiao Sun; Jiadai Sun; Xinyue Yang; Yu Yang; Shuntian Yao; Wei Xu; Jie Tang; Yuxiao Dong,~Zehan_Qi2; ~Xiao_Liu15; ~Iat_Long_Iong1; ~Hanyu_Lai2; ~Xueqiao_Sun1; ~Jiadai_Sun2; ~Xinyue_Yang2; ~Yu_Yang26; ~Shuntian_Yao1; ~Wei_Xu14; ~Jie_Tang1; ~Yuxiao_Dong1,"{'value': ['Web Agent', 'LLM Agent', 'Curriculum RL Learning', 'Online Learning']}","{'value': ""Large language models (LLMs) have shown remarkable potential as autonomous agents, particularly in web-based tasks. \nHowever, existing LLM web agents face significant limitations: high-performing agents rely on expensive proprietary LLM APIs, while open LLMs lack the necessary decision-making capabilities. \nThis paper introduces WebRL, a novel self-evolving online curriculum reinforcement learning framework designed to train high-performance web agents using open LLMs. \nOur approach addresses key challenges in this domain, including the scarcity of training tasks, sparse feedback signals, and policy distribution drift in online learning. \nWebRL incorporates a self-evolving curriculum that generates new tasks from unsuccessful attempts, a robust outcome-supervised reward model (ORM), and adaptive reinforcement learning strategies to ensure consistent improvement. \nWe apply WebRL to transform Llama-3.1 models into proficient web agents, achieving remarkable results on the WebArena-Lite benchmark. \nOur Llama-3.1-8B agent improves from an initial 4.8\\% success rate to 42.4\\%, while the Llama-3.1-70B agent achieves a 47.3\\% success rate across five diverse websites. \nThese results surpass the performance of GPT-4-Turbo (17.6\\%) by over 160\\% relatively and significantly outperform previous state-of-the-art web agents trained on open LLMs (AutoWebGLM, 18.2\\%). \nOur findings demonstrate WebRL's effectiveness in bridging the gap between open and proprietary LLM-based web agents, paving the way for more accessible and powerful autonomous web interaction systems.""}",https://openreview.net{'value': '/pdf/2970fd3dfac12fd402a00cdffe2910c669f35c76.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=oI5tZaWkF9,{'value': 'Not All LLM-Generated Data Are Equal: Rethinking Data Weighting in Text Classification'},Hsun-Yu Kuo; Yin-Hsiang Liao; Yu-Chieh Chao; Wei-Yun Ma; Pu-Jen Cheng,~Hsun-Yu_Kuo1; ~Yin-Hsiang_Liao1; ~Yu-Chieh_Chao2; ~Wei-Yun_Ma1; ~Pu-Jen_Cheng1,"{'value': ['data weighing', 'data augmentation', 'distillation', 'data-efficient training', 'NLP in resource-constrained settings', 'fine-tuning', 'weighted loss']}","{'value': 'Synthetic data augmentation via Large Language Models (LLMs) allows researchers to leverage additional training data, thus enhancing the performance of downstream tasks, especially when real-world data is scarce. However, the generated data can deviate from the real-world data, and this misalignment can bring about deficient results while applying the trained model to applications. Therefore, we proposed efficient weighted-loss approaches to align synthetic data with real-world distribution by emphasizing high-quality and diversified data generated by LLMs using merely a tiny amount of real-world data. We empirically assessed the effectiveness of our methods on multiple text classification tasks, and the results showed that leveraging our approaches on a BERT-level model robustly outperformed standard cross-entropy and other data weighting approaches, providing potential solutions to effectively leveraging synthetic data from any suitable data generator.'}",https://openreview.net{'value': '/pdf/578361f82d18e8e1eaaf15d78304802977abbe58.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=oDbiL9CLoS,"{'value': 'Physics of Language Models: Part 3.2, Knowledge Manipulation'}",Zeyuan Allen-Zhu; Yuanzhi Li,~Zeyuan_Allen-Zhu1; ~Yuanzhi_Li1,"{'value': ['knowledge manipulation', 'language models', 'generative models', 'reversal curse']}","{'value': 'Language models can store vast factual knowledge, yet their ability to flexibly use this knowledge for downstream tasks (e.g., via instruction finetuning) remains questionable. This paper investigates four fundamental knowledge manipulation tasks: \\textbf{retrieval} (e.g., ""What is person A\'s attribute X?""), \\textbf{classification} (e.g., ""Is A\'s attribute X even or odd?""), \\textbf{comparison} (e.g., ""Is A greater than B in attribute X?""), and \\textbf{inverse search} (e.g., ""Which person\'s attribute X equals T?"").\n\nWe show that language models excel in knowledge retrieval but struggle even in the simplest classification or comparison tasks unless Chain of Thoughts (CoTs) are employed during both training and inference. Moreover, their performance in inverse knowledge search is virtually 0\\%, regardless of the prompts.\nOur primary contribution is a \\emph{controlled, synthetic experiment} that confirms these weaknesses are \\emph{inherent} to language models: they cannot efficiently manipulate knowledge from pre-training data, even when such knowledge is perfectly stored in the models, despite adequate training and sufficient model size. Our findings also apply to modern pretrained language models such as GPT-4, thus giving rise to many Turing tests to distinguish Humans from contemporary AIs.'}",https://openreview.net{'value': '/pdf/6097941da7c6577acb02e468ee39ff27979fe359.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=o1Et3MogPw,{'value': 'Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence'},Weize Chen; Ziming You; Ran Li; yitong guan; Chen Qian; Chenyang Zhao; Cheng Yang; Ruobing Xie; Zhiyuan Liu; Maosong Sun,~Weize_Chen1; ~Ziming_You1; ~Ran_Li6; ~yitong_guan1; ~Chen_Qian8; ~Chenyang_Zhao6; ~Cheng_Yang6; ~Ruobing_Xie2; ~Zhiyuan_Liu1; ~Maosong_Sun1,"{'value': ['llm agent', 'multi-agent']}","{'value': 'The rapid advancement of large language models (LLMs) has paved the way for the development of highly capable autonomous agents. However, existing multi-agent frameworks often struggle with integrating diverse capable third-party agents due to reliance on agents defined within their own ecosystems. They also face challenges in simulating distributed environments, as most frameworks are limited to single-device setups. Furthermore, these frameworks often rely on hard-coded communication pipelines, limiting their adaptability to dynamic task requirements. Inspired by the concept of the Internet, we propose the Internet of Agents (IoA), a novel framework that addresses these limitations by providing a flexible and scalable platform for LLM-based multi-agent collaboration. IoA introduces an agent integration protocol, an instant-messaging-like architecture design, and dynamic mechanisms for agent teaming and conversation flow control. Through extensive experiments on general assistant tasks, embodied AI tasks, and retrieval-augmented generation benchmarks, we demonstrate that IoA consistently outperforms state-of-the-art baselines, showcasing its ability to facilitate effective collaboration among heterogeneous agents. IoA represents a step towards linking diverse agents in an Internet-like environment, where agents can seamlessly collaborate to achieve greater intelligence and capabilities. We will release our code to facilitate further research.'}",https://openreview.net{'value': '/pdf/1006483e763807a740f78d0096898fc8d8a8424b.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=nfKfAzkiez,{'value': 'ACC-Collab: An Actor-Critic Approach to Multi-Agent LLM Collaboration'},Andrew Estornell; Jean-Francois Ton; Yuanshun Yao; Yang Liu,~Andrew_Estornell1; ~Jean-Francois_Ton2; ~Yuanshun_Yao2; ~Yang_Liu3,"{'value': ['Multi-Agent Collaboration', 'LLM Agents', 'Preference Optimization']}","{'value': 'Large language models (LLMs) have demonstrated a remarkable ability to serve as general-purpose tools for various language-based tasks. \n  Recent works have demonstrated that the efficacy of such models can be improved through iterative dialog between multiple models.\n  While these \n  paradigms show promise \n  in\n  improving model efficacy, most works in this area treat collaboration as an emergent behavior, rather than a learned behavior. \n  In doing so, current multi-agent frameworks rely on collaborative behaviors to have been sufficiently trained into off-the-shelf models. \n  To address this limitation, we propose ACC-Collab, an **A**ctor-**C**riti**c** based learning framework to produce a two-agent team (an actor-agent and a critic-agent) specialized in collaboration.\n  We demonstrate that ACC-Collab outperforms SotA multi-agent techniques on a wide array of benchmarks.'}",https://openreview.net{'value': '/pdf/8a3b2842348cfd4559cafe483c35e5cc89ca6da8.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=ncCuiD3KJQ,{'value': 'Visual Agents as Fast and Slow Thinkers'},Guangyan Sun; Mingyu Jin; Zhenting Wang; Cheng-Long Wang; Siqi Ma; Qifan Wang; Tong Geng; Ying Nian Wu; Yongfeng Zhang; Dongfang Liu,~Guangyan_Sun1; ~Mingyu_Jin1; ~Zhenting_Wang1; ~Cheng-Long_Wang1; ~Siqi_Ma2; ~Qifan_Wang2; ~Tong_Geng1; ~Ying_Nian_Wu1; ~Yongfeng_Zhang1; ~Dongfang_Liu1,"{'value': ['Multimodal Large Language Model', 'System2 Thinking', 'Language Agent']}","{'value': ""Achieving human-level intelligence requires refining cognitive distinctions between \\textit{System 1} and \\textit{System 2} thinking. While contemporary AI, driven by large language models, demonstrates human-like traits, it falls short of genuine cognition. Transitioning from structured benchmarks to real-world scenarios presents challenges for visual agents, often leading to inaccurate and overly confident responses. To address the challenge, we introduce \\textbf{\\textsc{FaST}}, which incorporates the \\textbf{Fa}st and \\textbf{S}low \\textbf{T}hinking mechanism into visual agents. \\textsc{FaST} employs a switch adapter to dynamically select between \\textit{System 1/2} modes, tailoring the problem-solving approach to different task complexity. It tackles uncertain and unseen objects by adjusting model confidence and integrating new contextual data. With this novel design, we advocate a \\textit{flexible system}, \\textit{hierarchical reasoning} capabilities, and a \\textit{transparent decision-making} pipeline, all of which contribute to its ability to emulate human-like cognitive processes in visual intelligence. Empirical results demonstrate that \\textsc{FaST} outperforms various well-known baselines, achieving 80.8\\% accuracy over $VQA^{v2}$ for visual question answering and 48.7\\% $GIoU$ score over ReasonSeg for reasoning segmentation, demonstrate \\textsc{FaST}'s superior performance. Extensive testing validates the efficacy and robustness of \\textsc{FaST}'s core components, showcasing its potential to advance the development of cognitive visual agents in AI systems.""}",https://openreview.net{'value': '/pdf/26f794c4b1811cb215c5a3952cd97e527f53e8c5.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=nCrJD7qPJN,{'value': 'Distilling Dataset into Neural Field'},Donghyeok Shin; HeeSun Bae; Gyuwon Sim; Wanmo Kang; Il-chul Moon,~Donghyeok_Shin2; ~HeeSun_Bae1; ~Gyuwon_Sim1; ~Wanmo_Kang1; ~Il-chul_Moon1,"{'value': ['Dataset distillation', 'Dataset condensation', 'Neural field']}","{'value': 'Utilizing a large-scale dataset is essential for training high-performance deep learning models, but it also comes with substantial computation and storage costs. To overcome these challenges, dataset distillation has emerged as a promising solution by compressing the large-scale dataset into a smaller synthetic dataset that retains the essential information needed for training. This paper proposes a novel parameterization framework for dataset distillation, coined Distilling Dataset into Neural Field (DDiF), which leverages the neural field to store the necessary information of the large-scale dataset. Due to the unique nature of the neural field, which takes coordinates as input and output quantity, DDiF effectively preserves the information and easily generates various shapes of data. We theoretically confirm that DDiF exhibits greater expressiveness than some previous literature when the utilized budget for a single synthetic instance is the same. Through extensive experiments, we demonstrate that DDiF achieves superior performance on several benchmark datasets, extending beyond the image domain to include video, audio, and 3D voxel. We release the code at \\url{https://github.com/aailab-kaist/DDiF}.'}",https://openreview.net{'value': '/pdf/6e92b5dd21f95a8dcae9d1d51a427c09da5b2e4b.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=n9PDaFNi8t,{'value': 'OS-ATLAS: Foundation Action Model for Generalist GUI Agents'},Zhiyong Wu; Zhenyu Wu; Fangzhi Xu; Yian Wang; Qiushi Sun; Chengyou Jia; Kanzhi Cheng; Zichen Ding; Liheng Chen; Paul Pu Liang; Yu Qiao,~Zhiyong_Wu3; ~Zhenyu_Wu7; ~Fangzhi_Xu1; ~Yian_Wang3; ~Qiushi_Sun1; ~Chengyou_Jia1; ~Kanzhi_Cheng1; ~Zichen_Ding1; ~Liheng_Chen2; ~Paul_Pu_Liang1; ~Yu_Qiao1,"{'value': ['GUI agent', 'language agent', 'GUI grounding', 'executable language grounding']}","{'value': 'Existing efforts in building GUI agents heavily rely on the availability of robust commercial Vision-Language Models (VLMs) such as GPT-4o and GeminiProVision. Practitioners are often reluctant to use open-source VLMs due to their significant performance lag compared to their closed-source counterparts, particularly in GUI grounding and Out-Of-Distribution (OOD) scenarios. To facilitate future research in this area, we developed OS-Atlas—a foundational GUI action model that excels at GUI grounding and OOD agentic tasks through innovations in both data and modeling.\nWe have invested significant engineering effort in developing an open-source toolkit for synthesizing GUI grounding data across multiple platforms, including Windows, Linux, MacOS, Android, and the web. Leveraging this toolkit, we are releasing the largest open-source cross-platform GUI grounding corpus to date, which contains over 13 million GUI elements. This dataset, combined with innovations in model training, provides a solid foundation for OS-Atlas to understand GUI screenshots and generalize to unseen interfaces.\nThrough extensive evaluation across six benchmarks spanning three different platforms (mobile, desktop, and web), OS-Atlas demonstrates significant performance improvements over previous state-of-the-art models. Our evaluation also uncovers valuable insights into continuously improving and scaling the agentic capabilities of open-source VLMs.'}",https://openreview.net{'value': '/pdf/72d73bde86282b902aafc4aa5cf09bf6c092f1b4.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=n8O0trhost,{'value': 'cryoSPHERE: Single-Particle HEterogeneous REconstruction from cryo EM'},Gabriel Ducrocq; Lukas Grunewald; Sebastian Westenhoff; Fredrik Lindsten,~Gabriel_Ducrocq1; ~Lukas_Grunewald1; ~Sebastian_Westenhoff1; ~Fredrik_Lindsten1,{'value': ['cryoEM; protein structure; Deep Learning; Machine Learning; generative modelling']},"{'value': 'The three-dimensional structure of proteins plays a crucial role in determining their function. Protein structure prediction methods, like AlphaFold, offer rapid access to a protein’s structure. However, large protein complexes cannot be reliably predicted, and proteins are dynamic, making it important to resolve their full conformational distribution. Single-particle cryo-electron microscopy (cryo-EM) is a powerful tool for determining the structures of large protein complexes. Importantly, the numerous images of a given protein contain underutilized information about conformational heterogeneity. These images are very noisy projections of the protein, and traditional methods for cryo-EM reconstruction are limited to recovering only one or a few consensus conformations.\n\nIn this paper, we introduce cryoSPHERE, which is a deep learning method that uses a nominal protein structure (e.g., from AlphaFold) as input, learns how to divide it into segments, and moves these segments as approximately rigid bodies to fit the different conformations present in the cryo-EM dataset. This approach provides enough constraints to enable meaningful reconstructions of single protein structural ensembles. We demonstrate this with two synthetic datasets featuring varying levels of noise, as well as two real dataset. We show that cryoSPHERE is very resilient to the high levels of noise typically encountered in experiments, where we see consistent improvements over the current state-of-the-art for heterogeneous reconstruction.'}",https://openreview.net{'value': '/pdf/163d36d8fca66ce222b0573dd64990b56f824d6e.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=n5PrId7pk5,{'value': 'Linear combinations of latents in generative models: subspaces and beyond'},Erik Bodin; Alexandru I. Stere; Dragos D Margineantu; Carl Henrik Ek; Henry Moss,~Erik_Bodin1; ~Alexandru_I._Stere1; ~Dragos_D_Margineantu1; ~Carl_Henrik_Ek1; ~Henry_Moss1,"{'value': ['generative models', 'diffusion models', 'latent space interpolation', 'latent subspaces', 'latent representations', 'flow matching', 'vae']}","{'value': 'Sampling from generative models has become a crucial tool for applications like data synthesis and augmentation. Diffusion, Flow Matching and Continuous Normalising Flows have shown effectiveness across various modalities, and rely on latent variables for generation. For experimental design or creative applications that require more control over the generation process, it has become common to manipulate the latent variable directly. However, existing approaches for performing such manipulations (e.g. interpolation or forming low-dimensional representations) only work well in special cases or are network or data-modality specific. \nWe propose Latent Optimal Linear combinations (LOL) as a general-purpose method to form linear combinations of latent variables that adhere to the assumptions of the generative model. As LOL is easy to implement and naturally addresses the broader task of forming any linear combinations, e.g. the construction of subspaces of the latent space, LOL dramatically simplifies the creation of expressive low-dimensional representations of high-dimensional objects.'}",https://openreview.net{'value': '/pdf/7d1ba6d760c90abe680c3281092660124660c0c6.pdf'},{'abstract_filter': 'Data Synthesis'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=moWiYJuSGF,{'value': 'Web Agents with World Models: Learning and Leveraging Environment Dynamics in Web Navigation'},Hyungjoo Chae; Namyoung Kim; Kai Tzu-iunn Ong; Minju Gwak; Gwanwoo Song; Jihoon Kim; Sunghwan Kim; Dongha Lee; Jinyoung Yeo,~Hyungjoo_Chae1; ~Namyoung_Kim1; ~Kai_Tzu-iunn_Ong1; ~Minju_Gwak1; ~Gwanwoo_Song1; ~Jihoon_Kim9; ~Sunghwan_Kim3; ~Dongha_Lee1; ~Jinyoung_Yeo1,"{'value': ['Web Agent', 'World Model', 'Digital Agent', 'Planning', 'LLM']}","{'value': 'Large language models (LLMs) have recently gained much attention in building autonomous agents. However, performance of current LLM-based web agents in long-horizon tasks is far from optimal, often yielding errors such as repeatedly buying a non-refundable flight ticket. By contrast, humans can avoid such an irreversible mistake, as we have an awareness of the potential outcomes (e.g., losing money) of our actions, also known as the ""world model"". Motivated by this, our study first starts with preliminary analyses, confirming the absence of world models in current LLMs (e.g., GPT-4o, Claude-3.5-Sonnet, etc.). Then, we present a World-model-augmented (WMA) web agent, which simulates the outcomes of its actions for better decision-making. To overcome the challenges in training LLMs as world models predicting next observations, such as repeated elements across observations and long HTML inputs, we propose a transition-focused observation abstraction, where the prediction objectives are free-form natural language descriptions exclusively highlighting important state differences between time steps. Experiments on WebArena and Mind2Web show that our world models improve agents\' policy selection without training and demonstrate our agents\' cost- and time-efficiency compared to recent tree-search-based agents.'}",https://openreview.net{'value': '/pdf/f707cdce9564aa4399e705eb27b4f3681c601ad8.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=mUbYof5MKp,{'value': 'A General Framework for Off-Policy Learning with Partially-Observed Reward'},Rikiya Takehi; Masahiro Asami; Kosuke Kawakami; Yuta Saito,~Rikiya_Takehi1; ~Masahiro_Asami1; ~Kosuke_Kawakami1; ~Yuta_Saito1,"{'value': ['off-policy learning', 'partially-observed rewards', 'contextual bandits']}","{'value': 'Off-policy learning (OPL) in contextual bandits aims to learn a decision-making policy that maximizes the target rewards by using only historical interaction data collected under previously developed policies. Unfortunately, when rewards are only partially observed, the effectiveness of OPL degrades severely. Well-known examples of such partial rewards include explicit ratings in content recommendations, conversion signals on e-commerce platforms that are partial due to delay, and the issue of censoring in medical problems. One possible solution to deal with such partial rewards is to use secondary rewards, such as dwelling time, clicks, and medical indicators, which are more densely observed. However, relying solely on such secondary rewards can also lead to poor policy learning since they may not align with the target reward. Thus, this work studies a new and general problem of OPL where the goal is to learn a policy that maximizes the expected target reward by leveraging densely observed secondary rewards as supplemental data. We then propose a new method called Hybrid Policy Optimization for Partially-Observed Reward (HyPeR), which effectively uses the secondary rewards in addition to the partially observed target reward to achieve effective OPL despite the challenging scenario. We also discuss a case where we aim to optimize not only the expected target reward but also the expected secondary rewards to some extent; counter-intuitively, we will show that leveraging the two objectives is in fact advantageous also for the optimization of only the target reward. Along with statistical analysis of our proposed methods, empirical evaluations on both synthetic and real-world data show that HyPeR outperforms existing methods in various scenarios.'}",https://openreview.net{'value': '/pdf/33a2c57cac6a50191e0271dee46421e6d7868ab2.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=mTCbq2QssD,{'value': 'OpenMathInstruct-2: Accelerating AI for Math with Massive Open-Source Instruction Data'},Shubham Toshniwal; Wei Du; Ivan Moshkov; Branislav Kisacanin; Alexan Ayrapetyan; Igor Gitman,~Shubham_Toshniwal1; ~Wei_Du3; ~Ivan_Moshkov1; ~Branislav_Kisacanin1; ~Alexan_Ayrapetyan1; ~Igor_Gitman2,"{'value': ['Math Reasoning', 'Synthetic Data']}","{'value': 'Mathematical reasoning continues to be a critical challenge in large language model (LLM) development with significant interest. However, most of the cutting-edge progress in mathematical reasoning with LLMs has become closed-source due to lack of access to training data. This lack of data access limits researchers from understanding the impact of different choices for synthesizing and utilizing the data. With the goal of creating a high-quality finetuning (SFT) dataset for math reasoning, we conduct careful ablation experiments on data synthesis using the recently released Llama3.1 family of models. Our experiments show that: (a) solution format matters, with excessively verbose solutions proving detrimental to SFT performance, (b) data generated by a strong teacher outperforms on-policy data generated by a weak student model, (c) SFT is robust to low-quality solutions, allowing for imprecise data filtering, and (d) question diversity is crucial for achieving data scaling gains. Based on these insights, we create the OpenMathInstruct-2 dataset which consists of 14M question-solution pairs (≈ 600K unique questions), making it nearly eight times larger than the previous largest open-source math reasoning dataset. Finetuning the Llama-3.1-8B-Base using OpenMathInstruct-2 outperforms Llama3.1-8B-Instruct on MATH by an absolute 15.9% (51.9% → 67.8%). Finally, to accelerate the open-source efforts, we release the code, the finetuned models, and the OpenMathInstruct-2 dataset under a commercially permissive license.'}",https://openreview.net{'value': '/pdf/8baaeb390ad66462822bfe3d8f5728a9435f7679.pdf'},{'abstract_filter': 'Data Synthesis'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=mPdmDYIQ7f,{'value': 'AgentSquare: Automatic LLM Agent Search in Modular Design Space'},Yu Shang; Yu Li; Keyu Zhao; Likai Ma; Jiahe Liu; Fengli Xu; Yong Li,~Yu_Shang1; ~Yu_Li31; ~Keyu_Zhao1; ~Likai_Ma1; ~Jiahe_Liu4; ~Fengli_Xu1; ~Yong_Li7,"{'value': ['LLM agent', 'Modular design space', 'Agent search', 'AutoML']}","{'value': 'Recent advancements in Large Language Models (LLMs) have led to a rapid growth of agentic systems capable of handling a wide range of complex tasks. However, current research largely relies on manual, task-specific design, limiting their adaptability to novel tasks. In this paper, we introduce a new research problem: Modularized LLM Agent Search (MoLAS). We propose a modular design space that abstracts existing LLM agent designs into four fundamental modules with uniform IO interface: Planning, Reasoning, Tool Use, and Memory. Building on this design space, we present a novel LLM agent search framework called AgentSquare, which introduces two core mechanisms, i.e., module evolution and recombination, to efficiently search for optimized LLM agents. To further accelerate the process, we design a performance predictor that uses in-context surrogate models to skip unpromising agent designs. Extensive experiments across six benchmarks, covering the diverse scenarios of web, embodied, tool use and game applications, show that AgentSquare substantially outperforms hand-crafted agents, achieving an average performance gain of 17.2% against best-known human designs. Moreover, AgentSquare can generate interpretable design insights, enabling a deeper understanding of agentic architecture and its impact on task performance. We believe that the modular design space and AgentSquare search framework offer a platform for fully exploiting the potential of prior successful designs and consolidate the collective efforts of research community. Code repo is available at https://github.com/tsinghua-fib-lab/AgentSquare.'}",https://openreview.net{'value': '/pdf/c06588c16619cd2e27dd12043d72f687442e36c5.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=mP7uV59iJM,{'value': 'GS-CPR: Efficient Camera Pose Refinement via 3D Gaussian Splatting'},Changkun Liu; Shuai Chen; Yash Sanjay Bhalgat; Siyan HU; Ming Cheng; Zirui Wang; Victor Adrian Prisacariu; Tristan Braud,~Changkun_Liu2; ~Shuai_Chen9; ~Yash_Sanjay_Bhalgat1; ~Siyan_HU1; ~Ming_Cheng6; ~Zirui_Wang3; ~Victor_Adrian_Prisacariu1; ~Tristan_Braud1,"{'value': ['Visual Localization', 'Camera Pose Estimation', '3D Gaussian Splatting']}","{'value': 'We leverage 3D Gaussian Splatting (3DGS) as a scene representation and propose a novel test-time camera pose refinement (CPR) framework, GS-CPR. This framework enhances the localization accuracy of state-of-the-art absolute pose regression and scene coordinate regression methods. The 3DGS model renders high-quality synthetic images and depth maps to facilitate the establishment of 2D-3D correspondences. GS-CPR obviates the need for training feature extractors or descriptors by operating directly on RGB images, utilizing the 3D foundation model, MASt3R, for precise 2D matching. To improve the robustness of our model in challenging outdoor environments, we incorporate an exposure-adaptive module within the 3DGS framework. Consequently, GS-CPR enables efficient one-shot pose refinement given a single RGB query and a coarse initial pose estimation. Our proposed approach surpasses leading NeRF-based optimization methods in both accuracy and runtime across indoor and outdoor visual localization benchmarks, achieving new state-of-the-art accuracy on two indoor datasets.'}",https://openreview.net{'value': '/pdf/ced70dbded36bfc4fa86927be0cbc1e7e75180e9.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=m4eXBo0VNc,{'value': 'An Engorgio Prompt Makes Large Language Model Babble on'},Jianshuo Dong; Ziyuan Zhang; Qingjie Zhang; Tianwei Zhang; Hao Wang; Hewu Li; Qi Li; Chao Zhang; Ke Xu; Han Qiu,~Jianshuo_Dong1; ~Ziyuan_Zhang2; ~Qingjie_Zhang2; ~Tianwei_Zhang1; ~Hao_Wang41; ~Hewu_Li1; ~Qi_Li12; ~Chao_Zhang18; ~Ke_Xu9; ~Han_Qiu3,"{'value': ['Large language model', 'attack', 'inference cost']}","{'value': ""Auto-regressive large language models (LLMs) have yielded impressive performance in many real-world tasks. \nHowever, the new paradigm of these LLMs also exposes novel threats. \nIn this paper, we explore their vulnerability to inference cost attacks, where a malicious user crafts Engorgio prompts to intentionally increase the computation cost and latency of the inference process. We design Engorgio, a novel methodology, to efficiently generate adversarial Engorgio prompts to affect the target LLM's service availability. Engorgio has the following two technical contributions. \n(1) We employ a parameterized distribution to track LLMs' prediction trajectory. (2) Targeting the auto-regressive nature of LLMs' inference process, we propose novel loss functions to stably suppress the appearance of the <EOS> token, whose occurrence will interrupt the LLM's generation process. \nWe conduct extensive experiments on 13 open-sourced LLMs with parameters ranging from 125M to 30B. \nThe results show that Engorgio prompts can successfully induce LLMs to generate abnormally long outputs (i.e., roughly 2-13$\\times$ longer to reach 90\\%+ of the output length limit)\nin a white-box scenario and our real-world experiment demonstrates Engergio's threat to LLM service with limited computing resources.\nThe code is released at https://github.com/jianshuod/Engorgio-prompt.""}",https://openreview.net{'value': '/pdf/3965e2e1bc4e3063c0278f8dda6363c3f6e59192.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=m08aK3xxdJ,{'value': 'CATCH: Channel-Aware Multivariate Time Series Anomaly Detection via Frequency Patching'},Xingjian Wu; Xiangfei Qiu; Zhengyu Li; Yihang Wang; Jilin Hu; Chenjuan Guo; Hui Xiong; Bin Yang,~Xingjian_Wu1; ~Xiangfei_Qiu1; ~Zhengyu_Li9; ~Yihang_Wang2; ~Jilin_Hu1; ~Chenjuan_Guo1; ~Hui_Xiong1; ~Bin_Yang4,"{'value': ['Multivariate Time Series', 'Anomaly Detection']}","{'value': 'Anomaly detection in multivariate time series is challenging as heterogeneous subsequence anomalies may occur. Reconstruction-based methods, which focus on learning normal patterns in the frequency domain to detect diverse abnormal subsequences, achieve promising results, while still falling short on capturing fine-grained frequency characteristics and channel correlations. To contend with the limitations, we introduce CATCH, a framework based on frequency patching. We propose to patchify the frequency domain into frequency bands, which enhances its ability to capture fine-grained frequency characteristics. To perceive appropriate channel correlations, we propose a Channel Fusion Module (CFM), which features a patch-wise mask generator and a masked-attention mechanism. Driven by a bi-level multi-objective optimization algorithm, the CFM is encouraged to iteratively discover appropriate patch-wise channel correlations, and to cluster relevant channels while isolating adverse effects from irrelevant channels. Extensive experiments on 10 real-world datasets and 12 synthetic datasets demonstrate that CATCH achieves state-of-the-art performance. We make our code and datasets available at https://github.com/decisionintelligence/CATCH.'}",https://openreview.net{'value': '/pdf/5b2fa326392dd55c12a1ba7e8590eb57e241b0b3.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=lgsyLSsDRe,{'value': 'NV-Embed: Improved Techniques for Training LLMs as Generalist Embedding Models'},Chankyu Lee; Rajarshi Roy; Mengyao Xu; Jonathan Raiman; Mohammad Shoeybi; Bryan Catanzaro; Wei Ping,~Chankyu_Lee1; ~Rajarshi_Roy1; ~Mengyao_Xu1; ~Jonathan_Raiman1; ~Mohammad_Shoeybi1; ~Bryan_Catanzaro1; ~Wei_Ping1,"{'value': ['LLM', 'embedding model', 'retriever']}","{'value': 'Decoder-only large language model (LLM)-based embedding models are beginning to outperform BERT or T5-based embedding models in general-purpose text embedding tasks, including dense vector-based retrieval. In this work, we introduce the NV-Embed model, incorporating architectural designs, training procedures, and curated datasets to significantly enhance the performance of LLM as a versatile embedding model, while maintaining its simplicity and reproducibility.For model architecture, we propose a latent attention layer to obtain pooled embeddings, which consistently improves retrieval and downstream task accuracy compared to mean pooling or using the last <EOS> token embedding from LLMs. To enhance representation learning, we remove the causal attention mask of LLMs during contrastive training. For training algorithm, we introduce a two-stage contrastive instruction-tuning method. It first applies contrastive training with instructions on retrieval datasets, utilizing in-batch negatives and curated hard negative examples. At stage-2, it blends various non-retrieval into instruction tuning, which not only enhances non-retrieval task accuracy but also improves retrieval performance. For training data, we utilize the hard-negative mining, synthetic data generation and existing public available datasets to boost the performance of embedding model. By combining these techniques, our NV-Embed- v1 model secured the No.1 position on the Massive Text Embedding Benchmark (MTEB) (as of May 24, 2024), across 56 embedding tasks. NV-Embed-v2 has reclaimed and maintained the top spot on MTEB since August 30, 2024, demonstrating the sustained effectiveness of the proposed methods over time.  Also, it achieved the highest scores in the Long Doc section and the second-highest scores in the QA section of the AIR Benchmark, which covers a range of out-of-domain information retrieval topics beyond those in MTEB.  We further provide the analysis of model compression techniques for generalist embedding models.  We open-source the model at: https://huggingface.co/nvidia/NV-Embed-v2 .'}",https://openreview.net{'value': '/pdf/c434fd3b97c510f119236ba297f1a58550ab5295.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=lIVRgt4nLv,{'value': 'Agent S: An Open Agentic Framework that Uses Computers Like a Human'},Saaket Agashe; Jiuzhou Han; Shuyu Gan; Jiachen Yang; Ang Li; Xin Eric Wang,~Saaket_Agashe1; ~Jiuzhou_Han1; ~Shuyu_Gan1; ~Jiachen_Yang1; ~Ang_Li1; ~Xin_Eric_Wang2,"{'value': ['Large Vision and Language Model', 'Agents', 'Retrieval Augmented Generation', 'GUI', 'Large Language Models', 'Agent Computer Interface']}","{'value': 'We present Agent S, an open agentic framework that enables autonomous interaction with computers through Graphical User Interface (GUI), aimed at transforming human-computer interaction by automating complex, multi-step tasks. Agent S addresses three key challenges in automating computer tasks: acquiring domain-specific knowledge, planning over long task horizons, and handling dynamic, non-uniform interfaces. To this end, Agent S introduces experience-augmented hierarchical planning, which learns from external knowledge search and internal experience retrieval at multiple levels, facilitating efficient task planning and subtask execution. \nIn addition, it employs an Agent-Computer Interface (ACI) to better elicit the reasoning and control capabilities of GUI agents based on Multimodal Large Language Models (MLLMs). Evaluation on the OSWorld benchmark shows that Agent S outperforms the baseline by 9.37\\% on success rate (an 83.6\\% relative improvement) and achieves a new state-of-the-art. Comprehensive analysis highlights the effectiveness of individual components and provides insights for future improvements. Furthermore, Agent S demonstrates broad generalizability to different operating systems on a newly-released WindowsAgentArena benchmark. Code available at https://github.com/simular-ai/Agent-S.'}",https://openreview.net{'value': '/pdf/5c0a5b17c744fe619f72841610ad18eb2216c723.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=lHbLpwbEyt,{'value': 'Enhancing Cognition and Explainability of Multimodal Foundation Models with Self-Synthesized Data'},Yucheng Shi; Quanzheng Li; Jin Sun; Xiang Li; Ninghao Liu,~Yucheng_Shi2; ~Quanzheng_Li1; ~Jin_Sun2; ~Xiang_Li14; ~Ninghao_Liu2,"{'value': ['Multimodal Foundation Models', 'Synthetic Data', 'Explainability', 'Visual Reasoning', 'Fine-grained Visual Categorization', 'Rejection Sampling']}","{'value': ""Large Multimodal Models (LMMs), or Vision-Language Models (VLMs), have shown impressive capabilities in a wide range of visual tasks. However, they often struggle with fine-grained visual reasoning, failing to identify domain-specific objectives and provide justifiable explanations for their predictions. To address the above challenge, we propose a novel visual rejection sampling framework to improve the cognition and explainability of LMMs using self-synthesized data. Specifically, visual fine-tuning requires images, queries, and target answers. Our approach begins by synthesizing interpretable answers that include human-verifiable visual features. These features are based on expert-defined concepts, and carefully selected based on their alignment with the image content. After each round of fine-tuning, we apply a reward model-free filtering mechanism to select the highest-quality interpretable answers for the next round of tuning. This iterative process of synthetic data generation and fine-tuning progressively improves the model's ability to generate accurate and reasonable explanations. Experimental results demonstrate the effectiveness of our method in improving both the accuracy and explainability of specialized visual classification tasks.""}",https://openreview.net{'value': '/pdf/6f14aa5355e60b2d57a4634a82693e97c6885f56.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=lBB3eSn6fY,{'value': 'Gaussian Mixture Counterfactual Generator'},Jong-Hoon Ahn; Akshay Vashist,~Jong-Hoon_Ahn1; ~Akshay_Vashist1,"{'value': ['Gaussian mixture model', 'synthetic data generation', 'clinical trial', 'individual treatment effect', 'counterfactual generation']}","{'value': 'We address the individualized treatment effect (ITE) estimation problem, focusing on continuous, multidimensional, and time-dependent treatments for precision medicine. The central challenge lies in modeling these complex treatment scenarios while capturing dynamic patient responses and minimizing reliance on control data. We propose the Gaussian Mixture Counterfactual Generator (GMCG), a generative model that transforms the Gaussian mixture model—traditionally a tool for clustering and density estimation—into a new tool explicitly geared toward causal inference. This approach generates robust counterfactuals by effectively handling continuous and multidimensional treatment spaces. We evaluate GMCG on synthetic crossover trial data and simulated datasets, demonstrating its superior performance over existing methods, particularly in scenarios with limited control data. GMCG derives its effectiveness from modeling the joint distribution of covariates, treatments, and outcomes using a latent state vector while employing a conditional distribution of the state vector to suppress confounding and isolate treatment-outcome relationships.'}",https://openreview.net{'value': '/pdf/30017eabc8c565ff03b436edf8e67d38da5c835e.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=l6QnSQizmN,{'value': 'Online Reinforcement Learning in Non-Stationary Context-Driven Environments'},Pouya Hamadanian; Arash Nasr-Esfahany; Malte Schwarzkopf; Siddhartha Sen; Mohammad Alizadeh,~Pouya_Hamadanian1; ~Arash_Nasr-Esfahany1; ~Malte_Schwarzkopf1; ~Siddhartha_Sen1; ~Mohammad_Alizadeh1,"{'value': ['catastrophic forgetting', 'reinforcement learning', 'context-driven MDP', 'online learning', 'non-stationary']}","{'value': 'We study online reinforcement learning (RL) in non-stationary environments, where a time-varying exogenous context process affects the environment dynamics. Online RL is challenging in such environments due to ""catastrophic forgetting"" (CF). The agent tends to forget prior knowledge as it trains on new experiences. Prior approaches to mitigate this issue assume task labels (which are often not available in practice), employ brittle regularization heuristics, or use off-policy methods that suffer from instability and poor performance.\n\nWe present Locally Constrained Policy Optimization (LCPO), an online RL approach that combats CF by anchoring policy outputs on old experiences while optimizing the return on current experiences. To perform this anchoring, LCPO locally constrains policy optimization using samples from experiences that lie outside of the current context distribution. We evaluate LCPO in Mujoco, classic control and computer systems environments with a variety of synthetic and real context traces, and find that it outperforms a variety of baselines in the non-stationary setting, while achieving results on-par with a ""prescient"" agent trained offline across all context traces.\n\nLCPO\'s source code is available at https://github.com/pouyahmdn/LCPO.'}",https://openreview.net{'value': '/pdf/2d424145948035bb22771991d3024411b2817d1d.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=l11DZY5Nxu,{'value': 'Robust Root Cause Diagnosis using In-Distribution Interventions'},Lokesh Nagalapatti; Ashutosh Srivastava; Sunita Sarawagi; Amit Sharma,~Lokesh_Nagalapatti1; ~Ashutosh_Srivastava2; ~Sunita_Sarawagi1; ~Amit_Sharma3,"{'value': ['Root Cause Diagnosis', 'Causal Inference', 'Interventional RCD']}","{'value': 'Diagnosing the root cause of an anomaly in a complex interconnected system is\na pressing problem in today’s cloud services and industrial operations. We propose In-Distribution Interventions (IDI), a novel algorithm that predicts root cause\nas nodes that meet two criteria: 1) Anomaly: root cause nodes should take on\nanomalous values; 2) Fix: had the root cause nodes assumed usual values, the\ntarget node would not have been anomalous. Prior methods of assessing the fix\ncondition rely on counterfactuals inferred from a Structural Causal Model (SCM)\ntrained on historical data. But since anomalies are rare and fall outside the training distribution, the fitted SCMs yield unreliable counterfactual estimates. IDI\novercomes this by relying on interventional estimates obtained by solely probing the fitted SCM at in-distribution inputs. We present a theoretical analysis\ncomparing and bounding the errors in assessing the fix condition using interventional and counterfactual estimates. We then conduct experiments by systematically varying the SCM’s complexity to demonstrate the cases where IDI’s interventional approach outperforms the counterfactual approach and vice versa.\nExperiments on both synthetic and PetShop RCD benchmark datasets demonstrate that IDI consistently identifies true root causes more accurately and robustly than nine existing state-of-the-art RCD baselines. Code will be released\nat https://github.com/nlokeshiisc/IDI_release.'}",https://openreview.net{'value': '/pdf/704fab6788807803612ad2b12344cc35a2a74913.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=kxnoqaisCT,{'value': 'Navigating the Digital World as Humans Do: Universal Visual Grounding for GUI Agents'},Boyu Gou; Ruohan Wang; Boyuan Zheng; Yanan Xie; Cheng Chang; Yiheng Shu; Huan Sun; Yu Su,~Boyu_Gou1; ~Ruohan_Wang6; ~Boyuan_Zheng1; ~Yanan_Xie2; ~Cheng_Chang5; ~Yiheng_Shu1; ~Huan_Sun1; ~Yu_Su2,"{'value': ['GUI Agents', 'Visual Grounding', 'Multimodal Large Language Models', 'GUI Grounding', 'Large Language Model']}","{'value': 'Multimodal large language models (MLLMs) are transforming the capabilities of graphical user interface (GUI) agents, facilitating their transition from controlled simulations to complex, real-world applications across various platforms. However, the effectiveness of these agents hinges on the robustness of their grounding capability. Current GUI agents predominantly utilize text-based representations such as HTML or accessibility trees, which, despite their utility, often introduce noise, incompleteness, and increased computational overhead. In this paper, we advocate a human-like embodiment for GUI agents that perceive the environment entirely visually and directly perform pixel-level operations on the GUI. The key is visual grounding models that can accurately map diverse referring expressions of GUI elements to their coordinates on the GUI across different platforms. We show that a simple recipe, which includes web-based synthetic data and slight adaptation of the LLaVA architecture, is surprisingly effective for training such visual grounding models. We collect the largest dataset for GUI visual grounding so far, containing 10M GUI elements and their referring expressions over 1.3M screenshots, and use it to train UGround, a strong universal visual grounding model for GUI agents. Empirical results on six benchmarks spanning three categories (grounding, offline agent, and online agent) show that 1) UGround substantially outperforms existing visual grounding models for GUI agents, by up to 20\\% absolute, and 2) agents with UGround outperform state-of-the-art agents, despite the fact that existing agents use additional text-based input while ours only uses visual perception. These results provide strong support for the feasibility and promises of GUI agents that navigate the digital world as humans do.'}",https://openreview.net{'value': '/pdf/95aed445520365d65a41dbae1857828585e0dac5.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=kxD2LlPr40,{'value': 'INS: Interaction-aware Synthesis to Enhance Offline Multi-agent Reinforcement Learning'},Yuqian Fu; Yuanheng Zhu; Jian Zhao; Jiajun Chai; Dongbin Zhao,~Yuqian_Fu3; ~Yuanheng_Zhu1; ~Jian_Zhao7; ~Jiajun_Chai1; ~Dongbin_Zhao1,"{'value': ['Multi-agent reinforcement learning', 'Offline reinforcement learning', 'Diffusion models']}","{'value': 'Data scarcity in offline multi-agent reinforcement learning (MARL) is a key challenge for real-world applications. Recent advances in offline single-agent reinforcement learning (RL) demonstrate the potential of data synthesis to mitigate this issue.\nHowever, in multi-agent systems, interactions between agents introduce additional challenges. These interactions complicate the synthesis of multi-agent datasets, leading to data distortion when inter-agent interactions are neglected. Furthermore, the quality of the synthetic dataset is often constrained by the original dataset. To address these challenges, we propose **INteraction-aware Synthesis (INS)**, which synthesizes high-quality multi-agent datasets using diffusion models. Recognizing the sparsity of inter-agent interactions, INS employs a sparse attention mechanism to capture these interactions, ensuring that the synthetic dataset reflects the underlying agent dynamics. To overcome the limitation of diffusion models requiring continuous variables, INS implements a bit action module, enabling compatibility with both discrete and continuous action spaces. Additionally, we incorporate a select mechanism to prioritize transitions with higher estimated values, further enhancing the dataset quality. Experimental results across multiple datasets in MPE and SMAC environments demonstrate that INS consistently outperforms existing methods, resulting in improved downstream policy performance and superior dataset metrics. Notably, INS can synthesize high-quality data using only 10% of the original dataset, highlighting its efficiency in data-limited scenarios.'}",https://openreview.net{'value': '/pdf/11d051ce1688032d6996243a8e0744a655b2b8e8.pdf'},{'abstract_filter': 'Data Synthesis'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=kuhIqeVg0e,{'value': 'ChemAgent: Self-updating Memories in Large Language Models Improves Chemical Reasoning'},Xiangru Tang; Tianyu Hu; Muyang Ye; Yanjun Shao; Xunjian Yin; Siru Ouyang; Wangchunshu Zhou; Pan Lu; Zhuosheng Zhang; Yilun Zhao; Arman Cohan; Mark Gerstein,~Xiangru_Tang2; ~Tianyu_Hu3; ~Muyang_Ye2; ~Yanjun_Shao1; ~Xunjian_Yin1; ~Siru_Ouyang1; ~Wangchunshu_Zhou1; ~Pan_Lu2; ~Zhuosheng_Zhang1; ~Yilun_Zhao1; ~Arman_Cohan1; ~Mark_Gerstein2,"{'value': ['Chemical Reasoning', 'Large Language Models', 'Agent']}","{'value': 'Chemical reasoning usually involves complex, multi-step processes that demand precise calculations, where even minor errors can lead to cascading failures. Furthermore, large language models (LLMs) encounter difficulties handling domain-specific formulas, executing reasoning steps accurately, and integrating code ef- effectively when tackling chemical reasoning tasks. To address these challenges, we present ChemAgent, a novel framework designed to improve the performance of LLMs through a dynamic, self-updating library. This library is developed by decomposing chemical tasks into sub-tasks and compiling these sub-tasks into a structured collection that can be referenced for future queries. Then, when presented with a new problem, ChemAgent retrieves and refines pertinent information from the library, which we call memory, facilitating effective task decomposition and the generation of solutions. Our method designs three types of memory and a library-enhanced reasoning component, enabling LLMs to improve over time through experience. Experimental results on four chemical reasoning datasets from SciBench demonstrate that ChemAgent achieves performance gains of up to 46% (GPT-4), significantly outperforming existing methods. Our findings suggest substantial potential for future applications, including tasks such as drug discovery and materials science. Our code can be found at https://github.com/gersteinlab/ChemAgent.'}",https://openreview.net{'value': '/pdf/f072f5a9e65a8bb918caeaa9fdf7a78732984cba.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=kpnW12Lm9p,{'value': 'Circuit Transformer: A Transformer That Preserves Logical Equivalence'},Xihan Li; Xing Li; Lei Chen; Xing Zhang; Mingxuan Yuan; Jun Wang,~Xihan_Li1; ~Xing_Li6; ~Lei_Chen26; ~Xing_Zhang6; ~Mingxuan_Yuan1; ~Jun_Wang2,"{'value': ['Transformer', 'Logic', 'EDA', 'Circuit', 'Logic Synthesis']}","{'value': 'Implementing Boolean functions with circuits consisting of logic gates is fundamental in digital computer design. However, the implemented circuit must be exactly equivalent, which hinders generative neural approaches on this task due to their occasionally wrong predictions. In this study, we introduce a generative neural model, the “Circuit Transformer”, which eliminates such wrong predictions and produces logic circuits strictly equivalent to given Boolean functions. The main idea is a carefully designed decoding mechanism that builds a circuit step-by-step by generating tokens, which has beneficial “cutoff properties” that block a candidate token once it invalidate equivalence. In such a way, the proposed model works similar to typical LLMs while logical equivalence is strictly preserved. A Markov decision process formulation is also proposed for optimizing certain objectives of circuits. Experimentally, we trained an 88-million-parameter Circuit Transformer to generate equivalent yet more compact forms of input circuits, outperforming existing neural approaches on both synthetic and real world benchmarks, without any violation of equivalence constraints.\n\nCode: https://github.com/snowkylin/circuit-transformer'}",https://openreview.net{'value': '/pdf/32df8d1861d87c45a5a89e2ea8b2238e79a8c8b5.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=klpdEThT8q,{'value': 'MA$^2$E: Addressing Partial Observability in Multi-Agent Reinforcement Learning with Masked Auto-Encoder'},Sehyeok Kang; Yongsik Lee; Gahee Kim; Song Chong; Se-Young Yun,~Sehyeok_Kang1; ~Yongsik_Lee1; ~Gahee_Kim1; ~Song_Chong2; ~Se-Young_Yun1,"{'value': ['multi-agent reinforcement learning', 'partial observability', 'masked autoencoder']}","{'value': 'Centralized Training and Decentralized Execution (CTDE) is a widely adopted paradigm to solve cooperative multi-agent reinforcement learning (MARL) problems. Despite the successes achieved with CTDE, partial observability still limits cooperation among agents. While previous studies have attempted to overcome this challenge through communication, direct information exchanges could be restricted and introduce additional constraints. Alternatively, if an agent can infer the global information solely from local observations, it can obtain a global view without the need for communication. To this end, we propose the Multi-Agent Masked Auto-Encoder (MA$^2$E), which utilizes the masked auto-encoder architecture to infer the information of other agents from partial observations. By employing masking to learn to reconstruct global information, MA$^2$E serves as an inference module for individual agents within the CTDE framework. MA$^2$E can be easily integrated into existing MARL algorithms and has been experimentally proven to be effective across a wide range of environments and algorithms.'}",https://openreview.net{'value': '/pdf/f1003e4a4c27ff01ffd8c6d85329beb14007771f.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=kam84eEmub,{'value': 'LayerDAG: A Layerwise Autoregressive Diffusion Model for Directed Acyclic Graph Generation'},Mufei Li; Viraj Shitole; Eli Chien; Changhai Man; Zhaodong Wang; Srinivas; Ying Zhang; Tushar Krishna; Pan Li,~Mufei_Li2; ~Viraj_Shitole1; ~Eli_Chien1; ~Changhai_Man1; ~Zhaodong_Wang3; ~Srinivas1; ~Ying_Zhang19; ~Tushar_Krishna1; ~Pan_Li2,"{'value': ['directed acyclic graphs', 'graph generation', 'discrete diffusion', 'autoregressive model']}","{'value': 'Directed acyclic graphs (DAGs) serve as crucial data representations in domains such as hardware synthesis and compiler/program optimization for computing systems. DAG generative models facilitate the creation of synthetic DAGs, which can be used for benchmarking computing systems while preserving intellectual property. However, generating realistic DAGs is challenging due to their inherent directional and logical dependencies. This paper introduces LayerDAG, an autoregressive diffusion model, to address these challenges. LayerDAG decouples the strong node dependencies into manageable units that can be processed sequentially. By interpreting the partial order of nodes as a sequence of bipartite graphs, LayerDAG leverages autoregressive generation to model directional dependencies and employs diffusion models to capture logical dependencies within each bipartite graph. Comparative analyses demonstrate that LayerDAG outperforms existing DAG generative models in both expressiveness and generalization, particularly for generating large-scale DAGs with up to 400 nodes—a critical scenario for system benchmarking. Extensive experiments on both synthetic and real-world flow graphs from various computing platforms show that LayerDAG generates valid DAGs with superior statistical properties and benchmarking performance. The synthetic DAGs generated by LayerDAG enhance the training of ML-based surrogate models, resulting in improved accuracy in predicting performance metrics of real-world DAGs across diverse computing platforms.'}",https://openreview.net{'value': '/pdf/66a662fa95878eda1f09c2ebe75a87bbf1204027.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=kQ5s9Yh0WI,"{'value': 'LongWriter: Unleashing 10,000+ Word Generation from Long Context LLMs'}",Yushi Bai; Jiajie Zhang; Xin Lv; Linzhi Zheng; Siqi Zhu; Lei Hou; Yuxiao Dong; Jie Tang; Juanzi Li,~Yushi_Bai1; ~Jiajie_Zhang2; ~Xin_Lv1; ~Linzhi_Zheng1; ~Siqi_Zhu1; ~Lei_Hou2; ~Yuxiao_Dong1; ~Jie_Tang1; ~Juanzi_Li1,"{'value': ['long context', 'large language model', 'long-form generation']}","{'value': ""Current long context large language models (LLMs) can process inputs up to 100,000 tokens, yet struggle to generate outputs exceeding even a modest length of 2,000 words. Through controlled experiments, we find that the model's effective generation length is inherently bounded by the sample it has seen during supervised fine-tuning (SFT). In other words, their output limitation is due to the scarcity of long-output examples in existing SFT datasets. To address this, we introduce AgentWrite, an agent-based pipeline that decomposes ultra-long generation tasks into subtasks, enabling off-the-shelf LLMs to generate coherent outputs exceeding 20,000 words. Leveraging AgentWrite, we construct LongWriter-6k, a dataset containing 6,000 SFT data with output lengths ranging from 2k to 32k words. By incorporating this dataset into model training, we successfully scale the output length of existing models to over 10,000 words while maintaining output quality. We also develop LongBench-Write, a comprehensive benchmark for evaluating ultra-long generation capabilities. Our 9B parameter model, further improved through DPO, achieves state-of-the-art performance on this benchmark, surpassing even much larger proprietary models. In general, our work demonstrates that existing long context LLM already possesses the potential for a larger output window--all you need is data with extended output during model alignment to unlock this capability.""}",https://openreview.net{'value': '/pdf/3585d0277a5d6af1baad6ff352efb796eba9bbf7.pdf'},{'abstract_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=kKILfPkhSz,{'value': 'ShortcutsBench: A Large-Scale Real-world Benchmark for API-based Agents'},Haiyang SHEN; Yue Li; Desong Meng; Dongqi Cai; Sheng Qi; Li Zhang; Mengwei Xu; Yun Ma,~Haiyang_SHEN1; ~Yue_Li24; ~Desong_Meng1; ~Dongqi_Cai3; ~Sheng_Qi1; ~Li_Zhang33; ~Mengwei_Xu1; ~Yun_Ma1,"{'value': ['Benchmark', 'Agent', 'LLM', 'Shortcuts']}","{'value': 'Recent advancements in integrating large language models (LLMs) with application programming interfaces (APIs) have gained significant interest in both academia and industry. Recent work demonstrates that these API-based agents exhibit relatively strong autonomy and planning capabilities. However, their ability to handle multi-dimensional difficulty levels, diverse task types, and real-world demands remains unknown. \nIn this paper, we introduce \\textsc{ShortcutsBench}, a large-scale benchmark for the comprehensive evaluation of API-based agents in solving real-world complex tasks. \\textsc{ShortcutsBench} includes a wealth of real APIs from Apple Inc., refined user queries, human-annotated \nhigh-quality action sequences, detailed parameter filling values, and parameters requesting necessary input from the system or user. We revealed how existing benchmarks~/~datasets struggle to accommodate the advanced reasoning capabilities of existing more intelligent LLMs. Moreover, our extensive evaluation of agents built with $5$ leading open-source (size $\\geq$ 57B) and $5$ closed-source LLMs (e.g. Gemini-1.5-Pro and GPT-4o-mini) with varying intelligence level reveals significant limitations of existing API-based agents in the whole process of handling complex queries related to API selection, parameter filling, and requesting necessary input from the system and the user. These findings highlight the great challenges that API-based agents face in effectively fulfilling real and complex user queries. All datasets, code, experimental logs, and results are available at https://github.com/EachSheep/ShortcutsBench'}",https://openreview.net{'value': '/pdf/abdf2c119c553756b7397764104c68428d8fcbb9.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=k38Th3x4d9,{'value': 'Root Cause Analysis of Anomalies in Multivariate Time Series through Granger Causal Discovery'},Xiao Han; Saima Absar; Lu Zhang; Shuhan Yuan,~Xiao_Han19; ~Saima_Absar1; ~Lu_Zhang3; ~Shuhan_Yuan2,"{'value': ['root cause analysis', 'Granger causality', 'multivariate time series']}","{'value': 'Identifying the root causes of anomalies in multivariate time series is challenging due to the complex dependencies among the series. In this paper, we propose a comprehensive approach called AERCA that inherently integrates Granger causal discovery with root cause analysis. By defining anomalies as interventions on the exogenous variables of time series, AERCA not only learns the Granger causality among time series but also explicitly models the distributions of exogenous variables under normal conditions. AERCA then identifies the root causes of anomalies by highlighting exogenous variables that significantly deviate from their normal states. Experiments on multiple synthetic and real-world datasets demonstrate that AERCA can accurately capture the causal relationships among time series and effectively identify the root causes of anomalies.'}",https://openreview.net{'value': '/pdf/51e1c859bf45ee7d553fc7cba491e8de815a67cb.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=jw7P4MHLWw,{'value': 'Personalized Representation from Personalized Generation'},Shobhita Sundaram; Julia Chae; Yonglong Tian; Sara Beery; Phillip Isola,~Shobhita_Sundaram1; ~Julia_Chae1; ~Yonglong_Tian1; ~Sara_Beery1; ~Phillip_Isola1,"{'value': ['Synthetic data', 'personalization', 'diffusion models', 'data augmentation', 'representation learning']}","{'value': 'Modern vision models excel at general purpose downstream tasks. It is unclear, however, how they may be used for personalized vision tasks, which are both fine-grained and data-scarce. Recent works have successfully applied synthetic data to general-purpose representation learning, while advances in T2I diffusion models have enabled the generation of personalized images from just a few real examples. Here, we explore a potential connection between these ideas, and formalize the challenge of using personalized synthetic data to learn personalized representations, which encode knowledge about an object of interest and may be flexibly applied to any downstream task relating to the target object. We introduce an evaluation suite for this challenge, including reformulations of two existing datasets and a novel dataset explicitly constructed for this purpose, and propose a contrastive learning approach that makes creative use of image generators. We show that our method improves personalized representation learning for diverse downstream tasks, from recognition to segmentation, and analyze characteristics of image generation approaches that are key to this gain.'}",https://openreview.net{'value': '/pdf/6f6f06358f97eec34188ed5a46e9464c7a1a09f6.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=jsBhmOCKYs,{'value': 'Denoising as Adaptation: Noise-Space Domain Adaptation for Image Restoration'},Kang Liao; Zongsheng Yue; Zhouxia Wang; Chen Change Loy,~Kang_Liao1; ~Zongsheng_Yue1; ~Zhouxia_Wang2; ~Chen_Change_Loy2,"{'value': ['Image Restoration', 'Domain Adaptation', 'Diffusion Loss']}","{'value': 'Although learning-based image restoration methods have made significant progress, they still struggle with limited generalization to real-world scenarios due to the substantial domain gap caused by training on synthetic data. Existing methods address this issue by improving data synthesis pipelines, estimating degradation kernels, employing deep internal learning, and performing domain adaptation and regularization. Previous domain adaptation methods have sought to bridge the domain gap by learning domain-invariant knowledge in either feature or pixel space. However, these techniques often struggle to extend to low-level vision tasks within a stable and compact framework. In this paper, we show that it is possible to perform domain adaptation via the noise space using diffusion models. In particular, by leveraging the unique property of how auxiliary conditional inputs influence the multi-step denoising process, we derive a meaningful *diffusion loss* that guides the restoration model in progressively aligning both restored synthetic and real-world outputs with a target clean distribution. We refer to this method as *denoising as adaptation*. To prevent shortcuts during joint training, we present crucial strategies such as channel-shuffling layer and residual-swapping contrastive learning in the diffusion model. They implicitly blur the boundaries between conditioned synthetic and real data and prevent the reliance of the model on easily distinguishable features. Experimental results on three classical image restoration tasks, namely denoising, deblurring, and deraining, demonstrate the effectiveness of the proposed method.'}",https://openreview.net{'value': '/pdf/f174652c645b26eedfd056da547b3e4c622509ec.pdf'},{'abstract_filter': 'Data Synthesis'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=jmN1zXMq0O,{'value': 'To Clip or not to Clip: the Dynamics of SGD with Gradient Clipping in High-Dimensions'},Noah Marshall; Ke Liang Xiao; Atish Agarwala; Elliot Paquette,~Noah_Marshall1; ~Ke_Liang_Xiao1; ~Atish_Agarwala1; ~Elliot_Paquette1,"{'value': ['gradient clipping', 'high-dimensional probability', 'stochastic optimization', 'deep learning theory']}","{'value': 'The success of modern machine learning is due in part to the adaptive optimization methods that have been developed to deal with the difficulties of training large models over complex datasets. One such method is gradient clipping: a practical procedure with limited theoretical underpinnings. In this work, we study clipping in a least squares problem under streaming SGD. We develop a theoretical analysis of the learning dynamics in the limit of large intrinsic dimension—a model and dataset dependent notion of dimensionality. In this limit we find a deterministic equation that describes the evolution of the loss and demonstrate that this equation predicts the path of clipped SGD on synthetic, CIFAR10, and Wikitext2 data. We show that with Gaussian noise clipping cannot improve SGD performance. Yet, in other noisy settings, clipping can provide benefits with tuning of the clipping threshold. We propose a simple heuristic for near optimal scheduling of the clipping threshold which requires the tuning of only one hyperparameter. We conclude with a discussion about the links between high-dimensional clipping and neural network training.'}",https://openreview.net{'value': '/pdf/43128b26ab4cea11b37f26d573ade0241f26313b.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=jki6EFsZLw,{'value': 'OmnixR: Evaluating Omni-modality Language Models on Reasoning across Modalities'},Lichang Chen; Hexiang Hu; Mingda Zhang; Yiwen Chen; Zifeng Wang; YANDONG LI; Pranav Shyam; Tianyi Zhou; Heng Huang; Ming-Hsuan Yang; Boqing Gong,~Lichang_Chen2; ~Hexiang_Hu1; ~Mingda_Zhang1; ~Yiwen_Chen6; ~Zifeng_Wang1; ~YANDONG_LI1; ~Pranav_Shyam1; ~Tianyi_Zhou1; ~Heng_Huang1; ~Ming-Hsuan_Yang1; ~Boqing_Gong1,{'value': ['Omni-modality Language Model; Omni-Eval; Omni-Reasoning']},"{'value': 'We introduce \\textbf{OmnixR}, an evaluation suite designed to benchmark state-of-the-art Omni-modality Language Models (OLMs), such as GPT-4o and Gemini. \nEvaluating OLMs, which integrate multiple modalities such as text, vision, and audio, presents unique challenges. \nParticularly, the user message might often consist of multiple modalities, such that OLMs have to establish holistic understanding and reasoning across modalities to accomplish the task.\nExisting benchmarks are limited to single-modality or dual-modality tasks (e.g., image+text or video+text), overlooking comprehensive multi-modal assessments of model reasoning.\nTo address this, OmnixR offers two evaluation variants: (1) OmnixR-synth: a synthetic dataset generated automatically by translating text into multiple modalities—audio, images, video, and hybrids Omnify!. (2) OmnixR-real: a real-world dataset, manually curated and annotated by experts, for evaluating cross-modal reasoning in natural settings. \nOmnixR  presents a unique evaluation towards assessing OLMs over a diverse mix of modalities, such as a question that involves video, audio, and text, providing a rigorous cross-modal reasoning testbed than any existing benchmarks.\nOur experiments find that all state-of-the-art OLMs struggles with OmnixR questions that require integrating information from multiple modalities to answer. \nFurther analysis highlight differences in reasoning behavior and underscoring the challenges of omni-modal AI alignment.'}",https://openreview.net{'value': '/pdf/a8f5792b167b7d40c9acb6a680d0c8c51c2d13a0.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=jDsmB4o5S0,{'value': 'Dual Process Learning: Controlling Use of In-Context vs. In-Weights Strategies with Weight Forgetting'},Suraj Anand; Michael A. Lepori; Jack Merullo; Ellie Pavlick,~Suraj_Anand1; ~Michael_A._Lepori1; ~Jack_Merullo2; ~Ellie_Pavlick1,"{'value': ['Natural Language Processing', 'In-Context Learning', 'In-Weights Learning', 'Active Forgetting']}","{'value': ""Language models have the ability to perform in-context learning (ICL), allowing them to flexibly adapt their behavior based on context. This contrasts with in-weights learning (IWL), where memorized information is  encoded in model parameters after iterated observations of data. An ideal model should be able to flexibly deploy both of these abilities. Despite their apparent ability to learn in-context, language models are known to struggle when faced with unseen or rarely seen tokens  (Land & Bartolo, 2024). Hence, we study $\\textbf{structural in-context learning}$, which we define as the ability of a model to execute in-context learning on arbitrary novel tokens -- so called because the model must generalize on the basis of e.g. sentence structure or task structure, rather than content encoded in token embeddings. We study structural in-context algorithms on both synthetic and naturalistic tasks using toy models, masked language models, and autoregressive language models. We find that structural ICL appears before quickly disappearing early in LM pretraining. While it has been shown that ICL can diminish during training (Singh et al., 2023), we find that prior work does not account for structural ICL. Building on Chen et al. (2024) 's active forgetting method, we introduce pretraining and finetuning methods that can modulate the preference for structural ICL and IWL. Importantly, this allows us to induce a $\\textit{dual process strategy}$ where in-context and in-weights solutions coexist within a single model.""}",https://openreview.net{'value': '/pdf/1087c7df76febd5f1fe81e56140325cca7834c5f.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=jBYQAtzp5Z,{'value': 'Competitive Fair Scheduling with Predictions'},Tianming Zhao; Chunqiu xia; Xiaomin Chang; Chunhao Li; Wei Li; Albert Zomaya,~Tianming_Zhao1; ~Chunqiu_xia2; ~Xiaomin_Chang1; ~Chunhao_Li1; ~Wei_Li68; ~Albert_Zomaya1,"{'value': ['Learning-augmented Algorithms', 'Scheduling', 'Competitive analysis', 'Fairness', 'Predictions']}","{'value': 'Beyond the worst-case analysis of algorithms, the learning-augmented framework considers that an algorithm can leverage possibly imperfect predictions about the unknown variables to have guarantees tied to the prediction quality. We consider online non-clairvoyant scheduling to minimize the max-stretch under this framework, where the scheduler can access job size predictions. We present a family of algorithms: Relaxed-Greedy (RG) with an $O(\\eta^3 \\cdot \\sqrt{P})$ competitive ratio, where $\\eta$ denotes the prediction error for job sizes and $P$ the maximum job size ratio; Adaptive Relaxed-Greedy with an $O(\\lambda^{0.5} \\cdot \\eta^{2.5} \\cdot \\sqrt{P})$ competitive ratio, where $\\lambda$ denotes the error for the minimum job size; Predictive Relaxed-Greedy with an $O(\\lambda^{0.5} \\cdot \\varphi^{0.5} \\cdot \\eta \\cdot \\max \\\\\\{ \\eta, \\varphi \\\\\\} \\cdot \\sqrt{P})$ competitive ratio, where $\\varphi$ denotes the error for the maximum job size. We also present *${RG}^x$*, an algorithm that represents a trade-off between consistency and smoothness, with an $O(\\eta^{2+2x} \\cdot P^{1-x})$ competitive ratio. We introduce a general method using resource augmentation to bound robustness, resulting in *RR*-augmented *RG*, with a $(1 + \\epsilon)$-speed $O(\\min \\\\\\{ \\eta^3 \\sqrt{P}, \\frac{n}{\\epsilon} \\\\\\})$ competitive ratio. Finally, we conduct simulations on synthetic and real-world datasets to evaluate the practical performance of these algorithms.'}",https://openreview.net{'value': '/pdf/baed30d7cd7250f246a5107b105cf9721ccd723f.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=j9VVzueEbG,{'value': 'ZETA: Leveraging $Z$-order Curves for Efficient Top-$k$ Attention'},QIUHAO Zeng; Jerry Huang; Peng Lu; Gezheng Xu; Boxing Chen; Charles Ling; Boyu Wang,~QIUHAO_Zeng1; ~Jerry_Huang1; ~Peng_Lu6; ~Gezheng_Xu2; ~Boxing_Chen1; ~Charles_Ling1; ~Boyu_Wang3,"{'value': ['Transformer', 'In-context learning', 'Long Context', 'long-range Transformer', 'Efficient Transformer']}","{'value': 'Over recent years, the Transformer has become a fundamental building block for sequence modeling architectures. Yet at its core is the use of self-attention, whose memory and computational cost grow quadratically with the sequence length $N$, rendering it prohibitively expensive for long sequences. A promising approach is top-$k$ attention, which selects only the $k$ most relevant tokens and achieves performance comparable to vanilla self-attention while significantly reducing space and computational demands. However, causal masks require the current query token to only attend to past tokens, preventing existing top-$k$ attention methods from efficiently searching for the most relevant tokens in parallel, thereby limiting training efficiency. In this work, we propose ZETA, leveraging Z-Order Curves for Efficient Top-k Attention, to enable parallel querying of past tokens for entire sequences. We first theoretically show that the choice of key and query dimensions involves a trade-off between the curse of dimensionality and the preservation of relative distances after projection. In light of this insight, we propose reducing the dimensionality of keys and queries in contrast to values and further leveraging Z-order curves to map low-dimensional keys and queries into one-dimensional space, which permits parallel sorting, thereby largely improving the efficiency for top-$k$ token selection. Experimental results demonstrate that ZETA~matches the performance of standard attention on synthetic tasks Associative Recall and outperforms attention and its variants on Long-Range Arena and WikiText-103 language modeling.'}",https://openreview.net{'value': '/pdf/d9ca9819d5ebfa1bec70a7800c567e5289b1364c.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=ix2yRWarPn,{'value': 'Building Interactable Replicas of Complex Articulated Objects via Gaussian Splatting'},Yu Liu; Baoxiong Jia; Ruijie Lu; Junfeng Ni; Song-Chun Zhu; Siyuan Huang,~Yu_Liu26; ~Baoxiong_Jia1; ~Ruijie_Lu1; ~Junfeng_Ni1; ~Song-Chun_Zhu1; ~Siyuan_Huang2,{'value': ['articulated object modeling']},"{'value': 'Building interactable replicas of articulated objects is a key challenge in computer vision. Existing methods often fail to effectively integrate information across different object states, limiting the accuracy of part-mesh reconstruction and part dynamics modeling, particularly for complex multi-part articulated objects. We introduce ArtGS, a novel approach that leverages 3D Gaussians as a flexible and efficient representation to address these issues. Our method incorporates canonical Gaussians with coarse-to-fine initialization and updates for aligning articulated part information across different object states, and employs a skinning-inspired part dynamics modeling module to improve both part-mesh reconstruction and articulation learning. Extensive experiments on both synthetic and real-world datasets, including a new benchmark for complex multi-part objects, demonstrate that ArtGS achieves state-of-the-art performance in joint parameter estimation and part mesh reconstruction. Our approach significantly improves reconstruction quality and efficiency, especially for multi-part articulated objects. Additionally, we provide comprehensive analyses of our design choices, validating the effectiveness of each component to highlight potential areas for future improvement.'}",https://openreview.net{'value': '/pdf/3fe69922b46a4e1bd18b6ad0008d7883edeb7684.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=ispjankYab,{'value': 'Action abstractions for amortized sampling'},Oussama Boussif; Lena Nehale Ezzine; Joseph D Viviano; Michał Koziarski; Moksh Jain; Nikolay Malkin; Emmanuel Bengio; Rim Assouel; Yoshua Bengio,~Oussama_Boussif1; ~Lena_Nehale_Ezzine1; ~Joseph_D_Viviano1; ~Michał_Koziarski1; ~Moksh_Jain1; ~Nikolay_Malkin1; ~Emmanuel_Bengio1; ~Rim_Assouel1; ~Yoshua_Bengio1,"{'value': ['GFlowNets', 'amortized samplers', 'hierarchical planning', 'abstractions', 'macro-actions']}","{'value': ""As trajectories sampled by policies used by reinforcement learning (RL) and generative flow networks (GFlowNets) grow longer, credit assignment and exploration become more challenging, and the long planning horizon hinders mode discovery and generalization.\nThe challenge is particularly pronounced in entropy-seeking RL methods, such as generative flow networks, where the agent must learn to sample from a structured distribution and discover multiple high-reward states, each of which take many steps to reach.\nTo tackle this challenge, we propose an approach to incorporate the discovery of action abstractions, or high-level actions, into the policy optimization process.\nOur approach involves iteratively extracting action subsequences commonly used across many high-reward trajectories and `chunking' them into a single action that is added to the action space.\nIn empirical evaluation on synthetic and real-world environments, our approach demonstrates improved sample efficiency performance in discovering diverse high-reward objects, especially on harder exploration problems.\nWe also observe that the abstracted high-order actions are potentially interpretable, capturing the latent structure of the reward landscape of the action space.\nThis work provides a cognitively motivated approach to action abstraction in RL and is the first demonstration of hierarchical planning in amortized sequential sampling.""}",https://openreview.net{'value': '/pdf/b25eca478a19053a86fcd73d32c55b929cd5c66a.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=inOwd7hZC1,{'value': 'M^3PC: Test-time Model Predictive Control using Pretrained Masked Trajectory Model'},Kehan Wen; Yutong Hu; Yao Mu; Lei Ke,~Kehan_Wen1; ~Yutong_Hu6; ~Yao_Mu1; ~Lei_Ke1,"{'value': ['Offline-to-Online Reinforcement Learning', 'Model-based Reinforcement Learning', 'Masked Autoencoding', 'Robot Learning']}","{'value': ""Recent work in Offline Reinforcement Learning (RL) has shown that  a unified transformer trained under a masked auto-encoding objective can effectively capture the relationships between different modalities (e.g., states, actions, rewards) within given trajectory datasets. However, this information has not been fully exploited during the inference phase, where the agent needs to generate an optimal policy instead of just reconstructing masked components from unmasked. Given that a pretrained trajectory model can act as both a Policy Model and a World Model with appropriate mask patterns, we propose using Model Predictive Control (MPC) at test time to leverage the model's own predictive capacity to guide its action selection. Empirical results on D4RL and RoboMimic show that our inference-phase MPC significantly improves the decision-making performance of a pretrained trajectory model without any additional parameter training. Furthermore, our framework can be adapted to Offline to Online (O2O) RL and Goal Reaching RL, resulting in more substantial performance gains when an additional online interaction budget is given, and better generalization capabilities when different task targets are specified. Code is available: \\href{https://github.com/wkh923/m3pc}{\\texttt{https://github.com/wkh923/m3pc}}.""}",https://openreview.net{'value': '/pdf/d82891202728fac4e3c8f00b0f082d8d6bc2f510.pdf'},{'title_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=il5yUQsrjC,{'value': 'AndroidWorld: A Dynamic Benchmarking Environment for Autonomous Agents'},Christopher Rawles; Sarah Clinckemaillie; Yifan Chang; Jonathan Waltz; Gabrielle Lau; Marybeth Fair; Alice Li; William E Bishop; Wei Li; Folawiyo Campbell-Ajala; Daniel Kenji Toyama; Robert James Berry; Divya Tyamagundlu; Timothy P Lillicrap; Oriana Riva,~Christopher_Rawles1; ~Sarah_Clinckemaillie1; ~Yifan_Chang2; ~Jonathan_Waltz1; ~Gabrielle_Lau1; ~Marybeth_Fair1; ~Alice_Li2; ~William_E_Bishop1; ~Wei_Li91; ~Folawiyo_Campbell-Ajala1; ~Daniel_Kenji_Toyama1; ~Robert_James_Berry1; ~Divya_Tyamagundlu1; ~Timothy_P_Lillicrap1; ~Oriana_Riva3,"{'value': ['Computer Control', 'Autonomous Agents', 'LLMs', 'Multimodal']}","{'value': ""Autonomous agents that execute human tasks by controlling computers can enhance human productivity and application accessibility. However, progress in this field will be driven by realistic and reproducible benchmarks. We present AndroidWorld, a fully functional Android environment that provides reward signals for 116 programmatic tasks across 20 real-world Android apps. Unlike existing interactive environments, which provide a static test set, AndroidWorld dynamically constructs tasks that are parameterized and expressed in natural language in unlimited ways, thus enabling testing on a much larger and more realistic suite of tasks. To ensure reproducibility, each task includes dedicated initialization, success-checking, and tear-down logic, which modifies and inspects the device’s system state.\n\nWe experiment with baseline agents to test AndroidWorld and provide initial results on the benchmark. Our best agent can complete 30.6% of AndroidWorld's tasks, leaving ample room for future work. Furthermore, we adapt a popular desktop web agent to work on Android, which we find to be less effective on mobile, suggesting future research is needed to achieve universal, cross-platform agents. Finally, we also conduct a robustness analysis, showing that task variations can significantly affect agent performance, demonstrating that without such testing, agent performance metrics may not fully reflect practical challenges. AndroidWorld and the experiments in this paper are available at https://github.com/google-research/android_world.""}",https://openreview.net{'value': '/pdf/47ef762908227ecf3c9f07aea77ea162a772b501.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=ijbA5swmoK,{'value': 'Second-Order Min-Max Optimization with Lazy Hessians'},Lesi Chen; Chengchang Liu; Jingzhao Zhang,~Lesi_Chen1; ~Chengchang_Liu1; ~Jingzhao_Zhang2,{'value': ['min-max optimization; second-order methods; computational complexity']},"{'value': 'This paper studies second-order methods for convex-concave minimax optimization.  \nMonteiro & Svaiter (2012)  proposed a method to solve the problem with an optimal iteration complexity of \n$\\mathcal{O}(\\epsilon^{-3/2})$ to find an $\\epsilon$-saddle point.  However, it is unclear whether the\ncomputational complexity, $\\mathcal{O}((N+ d^2) d \\epsilon^{-2/3})$, can be improved. In the above, we follow  Doikov et al. (2023) and assume the complexity of obtaining a first-order oracle as $N$ and the complexity of obtaining a second-order oracle as $dN$. \nIn this paper, we show that the computation cost can be reduced by reusing Hessian across iterations. Our methods take the overall computational complexity of $\\tilde{\\mathcal{O}}( (N+d^2)(d+ d^{2/3}\\epsilon^{-2/3}))$, which improves those of previous methods by a factor of $d^{1/3}$. \nFurthermore, we generalize our method to strongly-convex-strongly-concave minimax problems and establish the complexity of $\\tilde{\\mathcal{O}}((N+d^2) (d + d^{2/3} \\kappa^{2/3}) )$ when the condition number of the problem is $\\kappa$, enjoying a similar speedup upon the state-of-the-art method. \nNumerical experiments on both real and synthetic datasets also verify the efficiency of our method.'}",https://openreview.net{'value': '/pdf/9a2b539742a9d0817dac56ed6929684bd8c09c15.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=iZl0VqEdxa,{'value': 'Uncertainty modeling for fine-tuned implicit functions'},Anna Susmelj; Mael Macuglia; Natasa Tagasovska; Reto Sutter; Sebastiano Caprara; Jean-Philippe Thiran; Ender Konukoglu,~Anna_Susmelj1; ~Mael_Macuglia1; ~Natasa_Tagasovska2; ~Reto_Sutter1; ~Sebastiano_Caprara1; ~Jean-Philippe_Thiran1; ~Ender_Konukoglu1,"{'value': ['uncertainty', 'implicit functions', '3D reconstruction', 'occupancy networks']}","{'value': 'Implicit functions such as Neural Radiance Fields (NeRFs), occupancy networks, and signed distance functions (SDFs) have become pivotal in computer vision for reconstructing detailed object shapes from sparse views. Achieving optimal performance with these models can be challenging due to the extreme sparsity of inputs and distribution shifts induced by data corruptions. To this end, large, noise-free synthetic datasets can serve as shape priors to help models fill in gaps, but the resulting reconstructions must be approached with caution. Uncertainty estimation is crucial for assessing the quality of these reconstructions, particularly in identifying areas where the model is uncertain about the parts it has inferred from the prior. In this paper, we introduce Dropsembles, a novel method for uncertainty estimation in tuned implicit functions. We demonstrate the efficacy of our approach through a series of experiments, starting with toy examples and progressing to a real-world scenario. Specifically, we train a Convolutional Occupancy Network on synthetic anatomical data and test it on low-resolution MRI segmentations of the lumbar spine. Our results show that Dropsembles achieve the accuracy and calibration levels of deep ensembles but with significantly less computational cost.'}",https://openreview.net{'value': '/pdf/44c285caeafc140fc8929f938d9496a4ae75bee2.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=iXbUquaWbl,{'value': 'End-to-end Learning of Gaussian Mixture Priors for Diffusion Sampler'},Denis Blessing; Xiaogang Jia; Gerhard Neumann,~Denis_Blessing1; ~Xiaogang_Jia1; ~Gerhard_Neumann2,"{'value': ['Variational Inference', 'Sampling', 'Diffusion Models', 'Mixture Models']}","{'value': 'Diffusion models optimized via variational inference (VI) have emerged as a promising tool for generating samples from unnormalized target densities. These models create samples by simulating a stochastic differential equation, starting from a simple, tractable prior, typically a Gaussian distribution. However, when the support of this prior differs greatly from that of the target distribution, diffusion models often struggle to explore effectively or suffer from large discretization errors. Moreover, learning the prior distribution can lead to mode-collapse, exacerbated by the mode-seeking nature of reverse Kullback-Leibler divergence commonly used in VI.\nTo address these challenges, we propose end-to-end learnable Gaussian mixture priors (GMPs). GMPs offer improved control over exploration, adaptability to target support, and increased expressiveness to counteract mode collapse. We further leverage the structure of mixture models by proposing a strategy to iteratively refine the model through the addition of mixture components during training. Our experimental results demonstrate significant performance improvements across a diverse range of real-world and synthetic benchmark problems when using GMPs without requiring additional target evaluations.'}",https://openreview.net{'value': '/pdf/6f707322d6cfe6b93cfb5ad9b9af267d5e2fa424.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=iAmR7FfMmq,{'value': 'Improving Graph Neural Networks by Learning Continuous Edge Directions'},Seong Ho Pahng; Sahand Hormoz,~Seong_Ho_Pahng1; ~Sahand_Hormoz1,"{'value': ['Graph Neural Networks', 'Directed Graphs', 'Graph Laplacian', 'Continuous Edge Directions', 'Graph Ensemble Data']}","{'value': 'Graph Neural Networks (GNNs) traditionally employ a message-passing mechanism that resembles diffusion over undirected graphs, which often leads to homogenization of node features and reduced discriminative power in tasks such as node classification. Our key insight for addressing this limitation is to assign fuzzy edge directions---that can vary continuously from node $i$ pointing to node $j$ to vice versa---to the edges of a graph so that features can preferentially flow in one direction between nodes to enable long-range information transmission across the graph. We also introduce a novel complex-valued Laplacian for directed graphs with fuzzy edges where the real and imaginary parts represent information flow in opposite directions. Using this Laplacian, we propose a general framework, called Continuous Edge Direction (CoED) GNN, for learning on graphs with fuzzy edges and prove its expressivity limits using a generalization of the Weisfeiler-Leman (WL) graph isomorphism test for directed graphs with fuzzy edges. Our architecture aggregates neighbor features scaled by the learned edge directions and processes the aggregated messages from in-neighbors and out-neighbors separately alongside the self-features of the nodes. Since continuous edge directions are differentiable, they can be learned jointly with the GNN weights via gradient-based optimization. CoED GNN is particularly well-suited for graph ensemble data where the graph structure remains fixed but multiple realizations of node features are available, such as in gene regulatory networks, web connectivity graphs, and power grids. We demonstrate through extensive experiments on both synthetic and real graph ensemble datasets that learning continuous edge directions significantly improves performance both for undirected and directed graphs compared with existing methods.'}",https://openreview.net{'value': '/pdf/ae2ce11f1dc2e0ca948c791bda5f723d0a39f7b6.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=i8dYPGdB1C,{'value': 'Near-Optimal Online Learning for Multi-Agent Submodular Coordination: Tight Approximation and Communication Efficiency'},Qixin Zhang; Zongqi Wan; Yu Yang; Li Shen; Dacheng Tao,~Qixin_Zhang1; ~Zongqi_Wan1; ~Yu_Yang9; ~Li_Shen1; ~Dacheng_Tao1,"{'value': ['Online Learning', 'Submodular Maximization', 'Surrogate Gradient', 'Multi-Agent']}","{'value': 'Coordinating multiple agents to collaboratively maximize submodular functions in unpredictable environments is a critical task with numerous applications in machine learning, robot planning and control. The existing approaches, such as the OSG algorithm,  are often hindered by their poor approximation guarantees and the rigid requirement for a fully connected communication graph. To address these challenges, we firstly present a $\\textbf{MA-OSMA}$ algorithm, which employs the multi-linear extension to transfer the discrete submodular maximization problem into a continuous optimization, thereby allowing us to reduce the strict dependence on a complete graph through consensus techniques. Moreover, $\\textbf{MA-OSMA}$ leverages a novel surrogate gradient to avoid sub-optimal stationary points. To eliminate the computationally intensive projection operations in $\\textbf{MA-OSMA}$, we also introduce a projection-free $\\textbf{MA-OSEA}$ algorithm, which effectively utilizes the KL divergence by mixing a uniform distribution. Theoretically, we confirm that both algorithms achieve a regret bound of $\\widetilde{O}(\\sqrt{\\frac{C_{T}T}{1-\\beta}})$ against a\xa0 $(\\frac{1-e^{-c}}{c})$-approximation to the best comparator in hindsight, where $C_{T}$ is the deviation of maximizer sequence, $\\beta$ is the spectral gap of the network and $c$ is the joint curvature of submodular objectives. This result significantly improves the $(\\frac{1}{1+c})$-approximation provided by the state-of-the-art OSG algorithm. Finally, we demonstrate the effectiveness of our proposed algorithms through simulation-based multi-target tracking.'}",https://openreview.net{'value': '/pdf/cf46dc3f49864e5412fc5ac973a0fb658c1f6f90.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=i2r7LDjba3,{'value': 'ECHOPulse: ECG Controlled Echocardio-gram Video Generation'},Yiwei Li; Sekeun Kim; Zihao Wu; Hanqi Jiang; Yi Pan; Pengfei Jin; Sifan Song; Yucheng Shi; Xiaowei Yu; Tianze Yang; Tianming Liu; Quanzheng Li; Xiang Li,~Yiwei_Li2; ~Sekeun_Kim1; ~Zihao_Wu1; ~Hanqi_Jiang2; ~Yi_Pan6; ~Pengfei_Jin1; ~Sifan_Song1; ~Yucheng_Shi2; ~Xiaowei_Yu1; ~Tianze_Yang2; ~Tianming_Liu3; ~Quanzheng_Li1; ~Xiang_Li14,"{'value': ['Medical video generation', 'ECHO synthesis', 'Multimodality', 'Wearable device', 'Medical foundation model']}","{'value': ""Echocardiography (ECHO) is essential for cardiac assessments, but its video quality and interpretation heavily relies on manual expertise, leading to inconsistent results from clinical and portable devices. ECHO video generation offers a solution by improving automated monitoring through synthetic data and generating high-quality videos from routine health data. However, existing models often face high computational costs, slow inference, and rely on complex conditional prompts that require experts' annotations. To address these challenges, we propose ECHOPulse, an ECG-conditioned ECHO video generation model. ECHOPulse introduces two key advancements: (1) it accelerates ECHO video generation by leveraging VQ-VAE tokenization and masked visual token modeling for fast decoding, and (2) it conditions on readily accessible ECG signals, which are highly coherent with ECHO videos, bypassing complex conditional prompts. To the best of our knowledge, this is the first work to use time-series prompts like ECG signals for ECHO video generation. ECHOPulse not only enables controllable synthetic ECHO data generation but also provides updated cardiac function information for disease monitoring and prediction beyond ECG alone. Evaluations on three public and private datasets demonstrate state-of-the-art performance in ECHO video generation across both qualitative and quantitative measures. Additionally, ECHOPulse can be easily generalized to other modality generation tasks, such as cardiac MRI, fMRI, and 3D CT generation. We will make the synthetic ECHO dataset, along with the code and model, publicly available upon acceptance.""}",https://openreview.net{'value': '/pdf/bb51df8d53a0dc570603952a85c0a1572d2a85ee.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=hwnObmOTrV,{'value': 'Modeling Complex System Dynamics with Flow Matching Across Time and Conditions'},Martin Rohbeck; Edward De Brouwer; Charlotte Bunne; Jan-Christian Huetter; Anne Biton; Kelvin Y. Chen; Aviv Regev; Romain Lopez,~Martin_Rohbeck2; ~Edward_De_Brouwer1; ~Charlotte_Bunne1; ~Jan-Christian_Huetter1; ~Anne_Biton1; ~Kelvin_Y._Chen1; ~Aviv_Regev1; ~Romain_Lopez1,"{'value': ['Flow Matching', 'dynamical systems']}","{'value': 'Modeling the dynamics of complex real-world systems from temporal snapshot data is crucial for understanding phenomena such as gene regulation, climate change, and financial market fluctuations. Researchers have recently proposed a few methods based either on the Schroedinger Bridge or Flow Matching to tackle this problem, but these approaches remain limited in their ability to effectively combine data from multiple time points and different experimental settings. This integration is essential in real-world scenarios where observations from certain combinations of time points and experimental conditions are missing, either because of experimental costs or sensory failure. To address this challenge, we propose a novel method named Multi-Marginal Flow Matching (MMFM). MMFM first constructs a flow using smooth spline-based interpolation across time points and conditions and regresses it with a neural network using the classifier-free guided Flow Matching framework. This framework allows for the sharing of contextual information about the dynamics across multiple trajectories. We demonstrate the effectiveness of our method on both synthetic and real-world datasets, including a recent single-cell genomics data set with around a hundred chemical perturbations across time points. Our results show that MMFM significantly outperforms existing methods at imputing data at missing time points.'}",https://openreview.net{'value': '/pdf/b4f31bda4dbafe237f158f9eed6e210802a325a9.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=hwSmPOAmhk,{'value': 'Understanding Factual Recall in Transformers via Associative Memories'},Eshaan Nichani; Jason D. Lee; Alberto Bietti,~Eshaan_Nichani1; ~Jason_D._Lee1; ~Alberto_Bietti1,"{'value': ['transformers', 'associative memories', 'factual recall', 'storage capacity', 'training dynamics']}","{'value': 'Large language models have demonstrated an impressive ability to perform factual recall. Prior work has found that transformers trained on factual recall tasks can store information at a rate proportional to their parameter count. In our work, we show that shallow transformers can use a combination of associative memories to obtain such near optimal storage capacity. We begin by proving that the storage capacities of both linear and MLP associative memories scale linearly with parameter count. We next introduce a synthetic factual recall task, and prove that a transformer with a single layer of self-attention followed by an MLP can obtain 100\\% accuracy on the task whenever either the total number of self-attention parameters or MLP parameters scales (up to log factors) linearly with the number of facts. In particular, the transformer can trade off between using the value matrices or the MLP as an associative memory to store the dataset of facts. We complement these expressivity results with an analysis of the gradient flow trajectory of a simplified linear attention model trained on our factual recall task, where we show that the model exhibits sequential learning behavior.'}",https://openreview.net{'value': '/pdf/a253a0bfa2c993f4c183b20a8af218977f3fbbe5.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=hoYFLRNbhc,{'value': 'DelTA: An Online Document-Level Translation Agent Based on Multi-Level Memory'},Yutong Wang; Jiali Zeng; Xuebo Liu; Derek F. Wong; Fandong Meng; Jie Zhou; Min Zhang,~Yutong_Wang11; ~Jiali_Zeng1; ~Xuebo_Liu1; ~Derek_F._Wong1; ~Fandong_Meng3; ~Jie_Zhou8; ~Min_Zhang9,"{'value': ['Document-Level Translation', 'Large Language Models', 'Autonomous Agents', 'Natural Language Processing']}","{'value': 'Large language models (LLMs) have achieved reasonable quality improvements in machine translation (MT).\nHowever, most current research on MT-LLMs still faces significant challenges in maintaining translation consistency and accuracy when processing entire documents.\nIn this paper, we introduce DelTA, a Document-levEL Translation Agent designed to overcome these limitations.\nDelTA features a multi-level memory structure that stores information across various granularities and spans, including Proper Noun Records, Bilingual Summary, Long-Term Memory, and Short-Term Memory, which are continuously retrieved and updated by auxiliary LLM-based components.\nExperimental results indicate that DelTA significantly outperforms strong baselines in terms of translation consistency and quality across four open/closed-source LLMs and two representative document translation datasets, achieving an increase in consistency scores by up to 4.58 percentage points and in COMET scores by up to 3.16 points on average.\nDelTA employs a sentence-by-sentence translation strategy, ensuring no sentence omissions and offering a memory-efficient solution compared to the mainstream method.\nFurthermore, DelTA improves pronoun and context-dependent translation accuracy, and the summary component of the agent also shows promise as a tool for query-based summarization tasks.\nThe code and data of our approach are released at https://github.com/YutongWang1216/DocMTAgent.'}",https://openreview.net{'value': '/pdf/46c09c6621cdb1818c886adb57ebecfae7302a2d.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=hjROBHstZ3,{'value': 'Causal Representation Learning from Multimodal Biomedical Observations'},Yuewen Sun; Lingjing Kong; Guangyi Chen; Loka Li; Gongxu Luo; Zijian Li; Yixuan Zhang; Yujia Zheng; Mengyue Yang; Petar Stojanov; Eran Segal; Eric P. Xing; Kun Zhang,~Yuewen_Sun1; ~Lingjing_Kong1; ~Guangyi_Chen1; ~Loka_Li1; ~Gongxu_Luo1; ~Zijian_Li1; ~Yixuan_Zhang4; ~Yujia_Zheng1; ~Mengyue_Yang1; ~Petar_Stojanov2; ~Eran_Segal1; ~Eric_Xing1; ~Kun_Zhang1,"{'value': ['multimodal observations', 'identifiability', 'causal representation learning']}","{'value': 'Prevalent in biomedical applications (e.g., human phenotype research), multimodal datasets can provide valuable insights into the underlying physiological mechanisms. However, current machine learning (ML) models designed to analyze these datasets often lack interpretability and identifiability guarantees, which are essential for biomedical research. Recent advances in causal representation learning have shown promise in identifying interpretable latent causal variables with formal theoretical guarantees. Unfortunately, most current work on multimodal distributions either relies on restrictive parametric assumptions or yields only coarse identification results, limiting their applicability to biomedical research that favors a detailed understanding of the mechanisms.\n\nIn this work, we aim to develop flexible identification conditions for multimodal data and principled methods to facilitate the understanding of biomedical datasets. Theoretically, we consider a nonparametric latent distribution (c.f., parametric assumptions in previous work) that allows for causal relationships across potentially different modalities. We establish identifiability guarantees for each latent component, extending the subspace identification results from previous work. Our key theoretical contribution is the structural sparsity of causal connections between modalities, which, as we will discuss, is natural for a large collection of biomedical systems.\nEmpirically, we present a practical framework to instantiate our theoretical insights. We demonstrate the effectiveness of our approach through extensive experiments on both numerical and synthetic datasets. Results on a real-world human phenotype dataset are consistent with established biomedical research, validating our theoretical and methodological framework.'}",https://openreview.net{'value': '/pdf/7d1d1b2a9a23f95606ff3ca0fb997ca541be953b.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=hTphfqtafO,{'value': 'Large Language Models are Interpretable Learners'},Ruochen Wang; Si Si; Felix Yu; Dorothea Wiesmann Rothuizen; Cho-Jui Hsieh; Inderjit S Dhillon,~Ruochen_Wang2; ~Si_Si1; ~Felix_Yu1; ~Dorothea_Wiesmann_Rothuizen1; ~Cho-Jui_Hsieh1; ~Inderjit_S_Dhillon1,"{'value': ['Interpretability', 'Explainable AI', 'LLMs', 'VLMs', 'MLLMs', 'Symbolic Learning', 'Prompting']}","{'value': ""The trade-off between expressiveness and interpretability remains a core challenge when building human-centric models for classification and decision-making. While symbolic rules offer interpretability, they often lack expressiveness, whereas neural networks excel in performance but are known for being black boxes. This paper shows a combination of Large Language Models (LLMs) and symbolic programs can bridge this gap. In the proposed LLM-based Symbolic Programs (LSPs), the pretrained LLM with natural language prompts provides a massive set of interpretable modules that can transform raw input into natural language concepts. Symbolic programs then integrate these modules into interpretable decision rules. To train LSPs, we develop a divide-and-conquer approach to incrementally build the program from scratch, where the learning process of each step is guided by LLMs. To evaluate the effectiveness of LSPs in extracting interpretable and accurate knowledge from data, we introduce IL-Bench, a collection of diverse tasks, including both synthetic and real-world scenarios across different modalities. Empirical results demonstrate LSP's superior performance compared to traditional neurosymbolic programs and vanilla automatic prompt tuning methods. Moreover, as the knowledge learned by LSP is a combination of natural language descriptions and symbolic rules, it is easily transferable to humans (interpretable), and other LLMs, and generalizes well to out-of-distribution samples. Our code and benchmark will be released for future research.""}",https://openreview.net{'value': '/pdf/e08bd0933acf1d9f2e050ed494042a4e0c772ddf.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=h7aQxzKbq6,{'value': 'HAMSTER: Hierarchical Action Models for Open-World Robot Manipulation'},Yi Li; Yuquan Deng; Jesse Zhang; Joel Jang; Marius Memmel; Caelan Reed Garrett; Fabio Ramos; Dieter Fox; Anqi Li; Abhishek Gupta; Ankit Goyal,~Yi_Li9; ~Yuquan_Deng1; ~Jesse_Zhang3; ~Joel_Jang1; ~Marius_Memmel1; ~Caelan_Reed_Garrett1; ~Fabio_Ramos1; ~Dieter_Fox1; ~Anqi_Li1; ~Abhishek_Gupta1; ~Ankit_Goyal1,{'value': ['vision language model; cross-domain generalization; sim-to-real transfer; robot manipulation; vision language action model']},"{'value': ""Large foundation models have shown strong open-world generalization to complex problems in vision and language, but similar levels of generalization have yet to be achieved in robotics. One fundamental challenge is the lack of robotic data, which are typically obtained through expensive on-robot operation. A promising remedy is to leverage cheaper, *off-domain* data such as action-free videos, hand-drawn sketches, or simulation data. In this work, we posit that *hierarchical* vision-language-action (VLA) models can be more effective in utilizing off-domain data than standard monolithic VLA models that directly finetune vision-language models (VLMs) to predict actions.\nIn particular, we study a class of hierarchical VLA models, where the high-level VLM is finetuned to produce a coarse 2D path indicating the desired robot end-effector trajectory given an RGB image and a task description. The intermediate 2D path prediction is then served as guidance to the low-level, 3D-aware control policy capable of precise manipulation. Doing so alleviates the high-level VLM from fine-grained action prediction, while reducing the low-level policy's burden on complex task-level reasoning.\nWe show that, with the hierarchical design, the high-level VLM can transfer across significant domain gaps between the off-domain finetuning data and real-robot testing scenarios, including differences in embodiments, dynamics, visual appearances, and task semantics, etc.\nIn the real-robot experiments, we observe an average of 20% improvement in success rate across seven different axes of generalization over OpenVLA, representing a 50% relative gain.\nVisual results are provided at: [https://hamster-robot.github.io/](https://hamster-robot.github.io/)""}",https://openreview.net{'value': '/pdf/eafdc79dd4a2aa8bac8cced6ed84a72b790f2bcd.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=h3wbI8Uk1Z,{'value': 'RNNs are not Transformers (Yet):  The Key Bottleneck on In-Context Retrieval'},Kaiyue Wen; Xingyu Dang; Kaifeng Lyu,~Kaiyue_Wen1; ~Xingyu_Dang2; ~Kaifeng_Lyu2,"{'value': ['rnn', 'cot', 'representation theory']}","{'value': 'This paper investigates the gap in representation powers of Transformers and Recurrent Neural Networks (RNNs), which are more memory efficient than Transformers. We aim to understand whether RNNs can match the performance of Transformers, particularly when enhanced with Chain-of-Thought (CoT) prompting. Our theoretical analysis reveals that CoT improves RNNs but is insufficient to close the gap with Transformers. A key bottleneck lies in the inability of RNNs to perfectly retrieve information from the context, even with CoT: \nfor several tasks that explicitly or implicitly require this capability, such as associative recall and determining if a graph is a tree, we prove that RNNs are not expressive enough to solve the tasks while Transformers can solve them with ease.\nConversely, we prove that adopting techniques to enhance the in-context retrieval capability of RNNs, including Retrieval-Augmented Generation (RAG) and adding a single Transformer layer, can elevate RNNs to be capable of solving all polynomial-time solvable problems with CoT, hence closing the representation gap with Transformers. We validate our theory on synthetic and natural language experiments.'}",https://openreview.net{'value': '/pdf/9cd87a7fcca4b8336c6449ef6317a3319d4ab40f.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=h0ZfDIrj7T,{'value': 'Mixture-of-Agents Enhances Large Language Model Capabilities'},Junlin Wang; Jue WANG; Ben Athiwaratkun; Ce Zhang; James Zou,~Junlin_Wang1; ~Jue_WANG1; ~Ben_Athiwaratkun1; ~Ce_Zhang1; ~James_Zou1,"{'value': ['Multi-Agent Inference', 'Large Language Model']}","{'value': 'Recent advances in large language models (LLMs) demonstrate substantial capabilities in natural language understanding and generation tasks. With the growing number of LLMs, how to harness the collective expertise of multiple LLMs is an exciting open direction. Toward this goal, we propose a new approach that leverages the collective strengths of multiple LLMs through a Mixture-of-Agents (MoA) methodology. In our approach, we construct a layered MoA architecture wherein each layer comprises multiple LLM agents. Each agent takes all the outputs from agents in the previous layer as auxiliary information in generating its response. MoA models achieves state-of-art performance on AlpacaEval 2.0, Arena-Hard, MT-Bench, and FLASK, surpassing GPT-4 Omni. For example, our MoA using only open-source LLMs achieves a score of 65.1% on AlpacaEval 2.0 compared to 57.5% by GPT-4 Omni.'}",https://openreview.net{'value': '/pdf/6ec35d5989095ecc687734c8a3549468e2ce33d9.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=gyvYKLEm8t,{'value': 'Learning to Select Nodes in Branch and Bound with Sufficient Tree Representation'},Sijia Zhang; Shuli Zeng; Shaoang Li; Feng Wu; Xiangyang Li,~Sijia_Zhang2; ~Shuli_Zeng1; ~Shaoang_Li1; ~Feng_Wu3; ~Xiangyang_Li4,{'value': ['branch and bound; mixed integer linear programming']},"{'value': 'Branch-and-bound methods are pivotal in solving Mixed Integer Linear Programming (MILP), where the challenge of node selection arises, necessitating the prioritization of different regions of the space for subsequent exploration. While machine learning techniques have been proposed to address this, two crucial problems concerning \\textbf{(P1)} how to sufficiently extract features from the branch-and-bound tree, and \\textbf{(P2)} how to assess the node quality comprehensively based on the features remain open. To tackle these challenges, we propose to tackle the node selection problem employing a novel Tripartite graph representation and Reinforcement learning with a Graph Neural Network model (TRGNN). The tripartite graph is theoretically proved to encompass sufficient information for tree representation in information theory. We learn node selection via reinforcement learning for learning delay rewards and give more comprehensive node metrics. Experiments show that TRGNN significantly improves the efficiency of solving MILPs compared to human-designed and learning-based node selection methods on both synthetic and large-scale real-world MILPs. Moreover, experiments demonstrate that TRGNN well generalizes to MILPs that are significantly larger than those seen during training.'}",https://openreview.net{'value': '/pdf/714d8abcb0d5e8cc40d59ff0183d125187dac202.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=goFpCuJalN,{'value': 'ClimaQA: An Automated Evaluation Framework for Climate Question Answering Models'},Veeramakali Vignesh Manivannan; Yasaman Jafari; Srikar Eranky; Spencer Ho; Rose Yu; Duncan Watson-Parris; Yian Ma; Leon Bergen; Taylor Berg-Kirkpatrick,~Veeramakali_Vignesh_Manivannan1; ~Yasaman_Jafari1; ~Srikar_Eranky1; ~Spencer_Ho1; ~Rose_Yu1; ~Duncan_Watson-Parris1; ~Yian_Ma1; ~Leon_Bergen1; ~Taylor_Berg-Kirkpatrick1,"{'value': ['Climate Benchmark', 'Scientific Foundation Models', 'Scientific Question Answering', 'Large Language Models', 'Automated QA generation']}","{'value': 'The use of Large Language Models (LLMs) in climate science has recently gained significant attention. However, a critical issue remains: the lack of a comprehensive evaluation framework capable of assessing the quality and scientific validity of model outputs. To address this issue, we develop *ClimaGen* (Climate QA Generator), an adaptive learning framework that generates question-answer pairs from graduate textbooks with climate scientists in the loop. As a result, we present *ClimaQA-Gold*, an expert-annotated benchmark dataset alongside *ClimaQA-Silver*, a large-scale, comprehensive synthetic QA dataset for climate science. Finally, we develop evaluation strategies and compare different LLMs on our benchmarks. Our results offer novel insights into various approaches used to enhance knowledge of climate LLMs. ClimaQA’s source code is publicly available at https://github.com/Rose-STL-Lab/genie-climaqa'}",https://openreview.net{'value': '/pdf/12d9d230be9a00d88b49530132f1bea909bf330f.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=gjwhDHeAsz,"{'value': 'Score Forgetting Distillation: A Swift, Data-Free Method for Machine Unlearning in Diffusion Models'}",Tianqi Chen; Shujian Zhang; Mingyuan Zhou,~Tianqi_Chen2; ~Shujian_Zhang1; ~Mingyuan_Zhou1,"{'value': ['machine unlearning', 'diffusion models', 'generative modeling', 'trustworthy machine learning']}","{'value': 'The machine learning community is increasingly recognizing the importance of fostering trust and safety in modern generative AI (GenAI) models. We posit machine unlearning (MU) as a crucial foundation for developing safe, secure, and trustworthy GenAI models. Traditional MU methods often rely on stringent assumptions and require access to real data. This paper introduces Score Forgetting Distillation (SFD), an innovative MU approach that promotes the forgetting of undesirable information in diffusion models by aligning the conditional scores of ""unsafe"" classes or concepts with those of ""safe"" ones. To eliminate the need for real data, our SFD framework incorporates a score-based MU loss into the score distillation objective of a pretrained diffusion model. This serves as a regularization term that preserves desired generation capabilities while enabling the production of synthetic data through a one-step generator. Our experiments on pretrained label-conditional and text-to-image diffusion models demonstrate that our method effectively accelerates the forgetting of target classes or concepts during generation, while preserving the quality of other classes or concepts. This unlearned and distilled diffusion not only pioneers a novel concept in MU but also accelerates the generation speed of diffusion models. Our experiments and studies on a range of diffusion models and datasets confirm that our approach is generalizable, effective, and advantageous for MU in diffusion models. Code is available at [https://github.com/tqch/score-forgetting-distillation](https://github.com/tqch/score-forgetting-distillation). (**Warning:** This paper contains sexually explicit imagery, discussions of pornography, racially-charged terminology, and other content that some readers may find disturbing, distressing, and/or offensive.)'}",https://openreview.net{'value': '/pdf/884ec6768181662f6e75461aba1b6f7df5d654b5.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=gWqFbnKsqR,{'value': 'Depth Any Video with Scalable Synthetic Data'},Honghui Yang; Di Huang; Wei Yin; Chunhua Shen; Haifeng Liu; Xiaofei He; Binbin Lin; Wanli Ouyang; Tong He,~Honghui_Yang1; ~Di_Huang6; ~Wei_Yin2; ~Chunhua_Shen2; ~Haifeng_Liu5; ~Xiaofei_He2; ~Binbin_Lin3; ~Wanli_Ouyang1; ~Tong_He2,"{'value': ['Video Depth Estimation', 'Synthetic Game Data']}","{'value': 'Video depth estimation has long been hindered by the scarcity of consistent and scalable ground truth data, leading to inconsistent and unreliable results. In this paper, we introduce Depth Any Video, a model that tackles the challenge through two key innovations. First, we develop a scalable synthetic data pipeline, capturing real-time video depth data from diverse virtual environments, yielding 40,000 video clips of 5-second duration, each with precise depth annotations. Second, we leverage the powerful priors of generative video diffusion models to handle real-world videos effectively, integrating advanced techniques such as rotary position encoding and flow matching to further enhance flexibility and efficiency. Unlike previous models, which are limited to fixed-length video sequences, our approach introduces a novel mixed-duration training strategy that handles videos of varying lengths and performs robustly across different frame rates—even on single frames. At inference, we propose a depth interpolation method that enables our model to infer high-resolution video depth across sequences of up to 150 frames. Our model outperforms all previous generative depth models in terms of spatial accuracy and temporal consistency. The code and model weights are open-sourced.'}",https://openreview.net{'value': '/pdf/9c0bbd2d3c0402019bfab20a96485dbbc37964fb.pdf'},{'title_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=gRmWtOnTLK,{'value': 'RFWave: Multi-band Rectified Flow for Audio Waveform Reconstruction'},Peng Liu; Dongyang Dai; Zhiyong Wu,~Peng_Liu6; ~Dongyang_Dai1; ~Zhiyong_Wu2,"{'value': ['Rectified Flow', 'Audio Waveform Reconstruction', 'Multi-band audio generation，Real-time diffusion  Vocoder']}","{'value': 'Recent advancements in generative modeling have significantly enhanced the reconstruction of audio waveforms from various representations. While diffusion models are adept at this task, they are hindered by latency issues due to their operation at the individual sample point level and the need for numerous sampling steps. In this study, we introduce RFWave, a cutting-edge multi-band Rectified Flow approach designed to reconstruct high-fidelity audio waveforms from Mel-spectrograms or discrete acoustic tokens. RFWave uniquely generates complex spectrograms and operates at the frame level, processing all subbands simultaneously to boost efficiency. Leveraging Rectified Flow, which targets a straight transport trajectory, RFWave achieves reconstruction with just 10 sampling steps. Our empirical evaluations show that RFWave not only provides outstanding reconstruction quality but also offers vastly superior computational efficiency, enabling audio generation at speeds up to 160 times faster than real-time on a GPU. Both an online demonstration and the source code are accessible.'}",https://openreview.net{'value': '/pdf/de2a6fb0ba085d2774982d87e713d94533f62bab.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=gQlxd3Mtru,{'value': 'Learning stochastic dynamics from snapshots through regularized unbalanced optimal transport'},Zhenyi Zhang; Tiejun Li; Peijie Zhou,~Zhenyi_Zhang1; ~Tiejun_Li2; ~Peijie_Zhou1,"{'value': ['optimal transport', 'Schrödinger bridge', 'trajectory inference', 'single-cell']}","{'value': 'Reconstructing dynamics using samples from sparsely time-resolved snapshots is an important problem in both natural sciences and machine learning. Here, we introduce a new deep learning approach for solving regularized unbalanced optimal transport (RUOT) and inferring continuous unbalanced stochastic dynamics from observed snapshots. Based on the RUOT form, our method models these dynamics without requiring prior knowledge of growth and death processes or additional information, allowing them to be learned directly from data.  Theoretically, we explore the connections between the RUOT and Schrödinger bridge problem and discuss the key challenges and potential solutions. The effectiveness of our method is demonstrated with a synthetic gene regulatory network, high-dimensional Gaussian Mixture Model, and single-cell RNA-seq data from blood development. Compared with other methods, our approach accurately identifies growth and transition patterns, eliminates false transitions, and constructs the Waddington developmental landscape. Our code is available at: [https://github.com/zhenyiizhang/DeepRUOT](https://github.com/zhenyiizhang/DeepRUOT).'}",https://openreview.net{'value': '/pdf/4786dc0925ed70c350ca28065e4ca424d449334b.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=gK1rl98VRp,{'value': 'Towards Auto-Regressive Next-Token Prediction: In-context Learning Emerges from Generalization'},Zixuan Gong; Xiaolin Hu; Huayi Tang; Yong Liu,~Zixuan_Gong1; ~Xiaolin_Hu6; ~Huayi_Tang1; ~Yong_Liu7,"{'value': ['In-context learning', 'Auto-regressive next-token prediction', 'Generalization performance', 'PAC-Bayesian']}","{'value': 'Large language models (LLMs) have demonstrated remarkable in-context learning (ICL) abilities. However, existing theoretical analysis of ICL primarily exhibits two limitations: \\textbf{(a) Limited \\textit{i.i.d.} Setting.} Most studies focus on supervised function learning tasks where prompts are constructed with \\textit{i.i.d.} input-label pairs. This \\textit{i.i.d.} assumption diverges significantly from real language learning scenarios where prompt tokens are interdependent. \\textbf{(b) Lack of Emergence Explanation.} Most literature answers \\textbf{\\textit{what}} ICL does from an implicit optimization perspective but falls short in elucidating \\textbf{\\textit{how}} ICL emerges and the impact of pre-training phase on ICL. In our paper, to extend (a), we adopt a more practical paradigm, \\textbf{\\textit{auto-regressive next-token prediction (AR-NTP)}}, which closely aligns with the actual training of language models. Specifically, within AR-NTP, we emphasize prompt token-dependency, which involves predicting each subsequent token based on the preceding sequence. To address (b), we formalize a systematic pre-training and ICL framework, highlighting the layer-wise structure of sequences and topics, alongside a two-level expectation. In conclusion, we present data-dependent, topic-dependent and optimization-dependent PAC-Bayesian generalization bounds for pre-trained LLMs, investigating that \\textbf{\\textit{ICL emerges from the generalization of sequences and topics}}. Our theory is supported by experiments on numerical linear dynamic systems, synthetic GINC and real-world language datasets.'}",https://openreview.net{'value': '/pdf/51093c4c47c281e78f492bae809d9bad6f9af6a8.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=fsDZwS49uY,{'value': 'OptiBench Meets ReSocratic: Measure and Improve LLMs for Optimization Modeling'},Zhicheng Yang; Yiwei Wang; Yinya Huang; Zhijiang Guo; Wei Shi; Xiongwei Han; Liang Feng; Linqi Song; Xiaodan Liang; Jing Tang,~Zhicheng_Yang4; ~Yiwei_Wang2; ~Yinya_Huang1; ~Zhijiang_Guo2; ~Wei_Shi15; ~Xiongwei_Han1; ~Liang_Feng3; ~Linqi_Song1; ~Xiaodan_Liang2; ~Jing_Tang5,{'value': ['large language models; optimization problem; data synthesis']},"{'value': ""Large language models (LLMs) have exhibited their problem-solving abilities in mathematical reasoning. Solving realistic optimization (OPT) problems in application scenarios requires advanced and applied mathematics ability. However, current OPT benchmarks that merely solve linear programming are far from complex realistic situations. In this work, we propose **OptiBench**, a benchmark for End-to-end optimization problem-solving with human-readable inputs and outputs. **OptiBench** contains rich optimization problems, including linear and nonlinear programming with or without tabular data, which can comprehensively evaluate LLMs' solving ability. In our benchmark, LLMs are required to call a code solver to provide precise numerical answers.\nFurthermore, to alleviate the data scarcity for optimization problems, and to bridge the gap between open-source LLMs on a small scale (e.g., Llama-3-8b) and closed-source LLMs (e.g., GPT-4), we further propose a data synthesis method namely ***ReSocratic***. Unlike general data synthesis methods that proceed from questions to answers, \\ReSocratic first incrementally synthesizes formatted optimization demonstration with mathematical formulations step by step and then back-translates the generated demonstrations into questions. Based on this, we synthesize the ***ReSocratic-29k*** dataset. We further conduct supervised fine-tuning with ***ReSocratic-29k*** on multiple open-source models. Experimental results show that ***ReSocratic-29k*** significantly improves the performance of open-source models.""}",https://openreview.net{'value': '/pdf/0683800be1c5625e5b3e5b677f67094e514c6858.pdf'},{'abstract_filter': 'Data Synthesis'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=fp6t3F669F,{'value': 'BALROG: Benchmarking Agentic LLM and VLM Reasoning On Games'},Davide Paglieri; Bartłomiej Cupiał; Samuel Coward; Ulyana Piterbarg; Maciej Wolczyk; Akbir Khan; Eduardo Pignatelli; Łukasz Kuciński; Lerrel Pinto; Rob Fergus; Jakob Nicolaus Foerster; Jack Parker-Holder; Tim Rocktäschel,~Davide_Paglieri1; ~Bartłomiej_Cupiał1; ~Samuel_Coward1; ~Ulyana_Piterbarg1; ~Maciej_Wolczyk1; ~Akbir_Khan1; ~Eduardo_Pignatelli1; ~Łukasz_Kuciński1; ~Lerrel_Pinto1; ~Rob_Fergus1; ~Jakob_Nicolaus_Foerster1; ~Jack_Parker-Holder1; ~Tim_Rocktäschel1,"{'value': ['LLM', 'VLM', 'Agents', 'Benchmark', 'RL', 'Reasoning', 'Games']}","{'value': 'Large Language Models (LLMs) and Vision Language Models (VLMs) possess extensive knowledge and exhibit promising reasoning abilities, however, they still struggle to perform well in complex, dynamic environments. Real-world tasks require handling intricate interactions, advanced spatial reasoning, long-term planning, and continuous exploration of new strategies—areas in which we lack effective methodologies for comprehensively evaluating these capabilities. To address this gap, we introduce BALROG, a novel benchmark designed to assess the agentic capabilities of LLMs and VLMs through a diverse set of challenging games. Our benchmark incorporates a range of existing reinforcement learning environments with varying levels of difficulty, including tasks that are solvable by non-expert humans in seconds to extremely challenging ones that may take years to master (e.g., the NetHack Learning Environment). \nWe devise fine-grained metrics to measure performance and conduct an extensive evaluation of several popular open-source and closed-source LLMs and VLMs. Our findings indicate that while current models achieve partial success in the easier games, they struggle significantly with more challenging tasks. Notably, we observe severe deficiencies in vision-based decision-making, as several models perform worse when visual representations of the environments are provided. We release BALROG as an open and user-friendly benchmark to facilitate future research and development in the agentic community. Code and Leaderboard at balrogai.com'}",https://openreview.net{'value': '/pdf/35b37f490670a7fbcbd3500720ae9ca23a44f468.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=fd2u60ryG0,{'value': 'Enhancing End-to-End Autonomous Driving with Latent World Model'},Yingyan Li; Lue Fan; Jiawei He; Yuqi Wang; Yuntao Chen; Zhaoxiang Zhang; Tieniu Tan,~Yingyan_Li1; ~Lue_Fan1; ~Jiawei_He2; ~Yuqi_Wang3; ~Yuntao_Chen1; ~Zhaoxiang_Zhang3; ~Tieniu_Tan1,"{'value': ['end-to-end autonomous driving', 'world model', 'self-supervised learning']}","{'value': 'In autonomous driving, end-to-end planners directly utilize raw sensor data, enabling them to extract richer scene features and reduce information loss compared to traditional planners. This raises a crucial research question: how can we develop better scene feature representations to fully leverage sensor data in end-to-end driving? Self-supervised learning methods show great success in learning rich feature representations in NLP and computer vision. Inspired by this, we propose a novel self-supervised learning approach using the LAtent World model (LAW) for end-to-end driving. LAW predicts future latent scene features based on current features and ego trajectories. This self-supervised task can be seamlessly integrated into perception-free and perception-based frameworks, improving scene feature learning while optimizing trajectory prediction. LAW achieves state-of-the-art performance across multiple benchmarks, including real-world open-loop benchmark nuScenes, NAVSIM, and simulator-based closed-loop benchmark CARLA. The code will be released.'}",https://openreview.net{'value': '/pdf/c1d18f8ba7a7204d3d393e46f0ced521ace04749.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=faDMOmnsjx,{'value': 'Statistical Advantages of Perturbing Cosine Router in Mixture of Experts'},Huy Nguyen; Pedram Akbarian; Huyen Trang Pham; Thien Trang Nguyen Vu; Shujian Zhang; Nhat Ho,~Huy_Nguyen5; ~Pedram_Akbarian1; ~Huyen_Trang_Pham2; ~Thien_Trang_Nguyen_Vu1; ~Shujian_Zhang1; ~Nhat_Ho1,"{'value': ['mixture of experts', 'cosine router', 'perturbation']}","{'value': 'The cosine router in Mixture of Experts (MoE) has recently emerged as an attractive alternative to the conventional linear router. Indeed, the cosine router demonstrates favorable performance in image and language tasks and exhibits better ability to mitigate the representation collapse issue, which often leads to parameter redundancy and limited representation potentials. Despite its empirical success, a comprehensive analysis of the cosine router in MoE has been lacking. Considering the least square estimation of the cosine routing MoE, we demonstrate that due to the intrinsic interaction of the model parameters in the cosine router via some partial differential equations, regardless of the structures of the experts, the estimation rates of experts and model parameters can be as slow as $\\mathcal{O}(1/\\log^{\\tau}(n))$ where $\\tau > 0$ is some constant and $n$ is the sample size. Surprisingly, these pessimistic non-polynomial convergence rates can be circumvented by the widely used technique in practice to stabilize the cosine router --- simply adding noises to the $\\ell^2$-norms in the cosine router, which we refer to as *perturbed cosine router*. Under the strongly identifiable settings of the expert functions, we prove that the estimation rates for both the experts and model parameters under the perturbed cosine routing MoE are significantly improved to polynomial rates. Finally, we conduct extensive simulation studies in both synthetic and real data settings to empirically validate our theoretical results.'}",https://openreview.net{'value': '/pdf/771b0e06531133d13a2c309548d4b56c4f7e82ae.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=fMbLszVO1H,"{'value': ""LongMamba: Enhancing Mamba's Long-Context Capabilities via Training-Free Receptive Field Enlargement""}",Zhifan Ye; Kejing Xia; Yonggan Fu; Xin Dong; Jihoon Hong; Xiangchi Yuan; Shizhe Diao; Jan Kautz; Pavlo Molchanov; Yingyan Celine Lin,~Zhifan_Ye1; ~Kejing_Xia1; ~Yonggan_Fu1; ~Xin_Dong1; ~Jihoon_Hong1; ~Xiangchi_Yuan1; ~Shizhe_Diao2; ~Jan_Kautz1; ~Pavlo_Molchanov1; ~Yingyan_Celine_Lin1,"{'value': ['Large Language Models', 'State Space Models', 'Long Context Understanding']}","{'value': 'State space models (SSMs) have emerged as an efficient alternative to Transformer models for language modeling, offering linear computational complexity and constant memory usage as context length increases. However, despite their efficiency in handling long contexts, recent studies have shown that SSMs, such as Mamba models, generally underperform compared to Transformers in long-context understanding tasks. To address this significant shortfall and achieve both efficient and accurate long-context understanding, we propose LongMamba, a training-free technique that significantly enhances the long-context capabilities of Mamba models. LongMamba builds on our discovery that the hidden channels in Mamba can be categorized into local and global channels based on their receptive field lengths, with global channels primarily responsible for long-context capability. These global channels can become the key bottleneck as the input context lengthens. Specifically, when input lengths largely exceed the training sequence length, global channels exhibit limitations in adaptively extend their receptive fields, leading to Mamba’s poor long-context performance. The key idea of LongMamba is to mitigate the hidden state memory decay in these global channels by preventing the accumulation of unimportant tokens in their memory. This is achieved by first identifying critical tokens in the global channels and then applying token filtering to accumulate only those critical tokens. Through extensive benchmarking across synthetic and real-world long-context scenarios, LongMamba sets a new standard for Mamba’s long-context performance, significantly extending its operational range without requiring additional training. Our code is available at https://github.com/GATECH-EIC/LongMamba.'}",https://openreview.net{'value': '/pdf/066062c0673cfc50aeafa9e3c96d0cf7a33fc3ca.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=exgLs4snap,{'value': 'Parameter Expanded Stochastic Gradient Markov Chain Monte Carlo'},Hyunsu Kim; Giung Nam; Chulhee Yun; Hongseok Yang; Juho Lee,~Hyunsu_Kim2; ~Giung_Nam1; ~Chulhee_Yun1; ~Hongseok_Yang2; ~Juho_Lee2,"{'value': ['SGMCMC', 'Bayesian Neural Network', 'Parameter Expansion']}","{'value': 'Bayesian Neural Networks (BNNs) provide a promising framework for modeling predictive uncertainty and enhancing out-of-distribution robustness (OOD) by estimating the posterior distribution of network parameters. Stochastic Gradient Markov Chain Monte Carlo (SGMCMC) is one of the most powerful methods for scalable posterior sampling in BNNs, achieving efficiency by combining stochastic gradient descent with second-order Langevin dynamics. However, SGMCMC often suffers from limited sample diversity in practice, which affects uncertainty estimation and model performance. We propose a simple yet effective approach to enhance sample diversity in SGMCMC without the need for tempering or running multiple chains. Our approach reparameterizes the neural network by decomposing each of its weight matrices into a product of matrices, resulting in a sampling trajectory that better explores the target parameter space. This approach produces a more diverse set of samples, allowing faster mixing within the same computational budget. Notably, our sampler achieves these improvements without increasing the inference cost compared to the standard SGMCMC. Extensive experiments on image classification tasks, including OOD robustness, diversity, loss surface analyses, and a comparative study with Hamiltonian Monte Carlo, demonstrate the superiority of the proposed approach.'}",https://openreview.net{'value': '/pdf/caa782ba6b8081e4224455d2ba79db20f6eb72ab.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=et5l9qPUhm,{'value': 'Strong Model Collapse'},Elvis Dohmatob; Yunzhen Feng; Arjun Subramonian; Julia Kempe,~Elvis_Dohmatob1; ~Yunzhen_Feng1; ~Arjun_Subramonian1; ~Julia_Kempe1,"{'value': ['Model Collapse', 'Regression', 'High dimensional asymptotics', 'Synthetic Data', 'Scaling Laws']}","{'value': 'Within the scaling laws paradigm, which underpins the training of large neural networks like ChatGPT and Llama, we consider a supervised regression setting and establish a strong form of the model collapse phenomenon, a critical performance degradation due to synthetic data in the training corpus. Our results show that even the smallest fraction of synthetic data (e.g., as little as 1 per 1000) can still lead to model collapse: larger and larger training sets do not enhance performance.  We further investigate whether increasing model size, an approach aligned with current trends in training large language models, exacerbates or mitigates model collapse. In a simplified regime where neural networks are approximated via random projections of tunable size, we both theoretically and empirically show that larger models can amplify model collapse. Interestingly, our theory also indicates that, beyond the interpolation threshold (which can be extremely high for very large datasets), larger models may mitigate the collapse, although they do not entirely prevent it. Our theoretical findings are empirically verified through experiments on language models and neural networks for images.'}",https://openreview.net{'value': '/pdf/fa8996fc4f1c020a70a9fe4a83d571b95ba2c2d6.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=erWwBoR59l,{'value': 'TD-Paint: Faster Diffusion Inpainting Through Time-Aware Pixel Conditioning'},Tsiry Mayet; Pourya Shamsolmoali; Simon Bernard; Eric Granger; Romain HÉRAULT; Clement Chatelain,~Tsiry_Mayet2; ~Pourya_Shamsolmoali1; ~Simon_Bernard1; ~Eric_Granger1; ~Romain_HÉRAULT2; ~Clement_Chatelain1,"{'value': ['Diffusion model', 'Inpainting']}","{'value': 'Diffusion models have emerged as highly effective techniques for inpainting, however, they remain constrained by slow sampling rates. While recent advances have enhanced generation quality, they have also increased sampling time, thereby limiting scalability in real-world applications. We investigate the generative sampling process of diffusion-based inpainting models and observe that these models make minimal use of the input condition during the initial sampling steps. As a result, the sampling trajectory deviates from the data manifold, requiring complex synchronization mechanisms to realign the generation process. To address this, we propose Time-aware Diffusion Paint (TD-Paint), a novel approach that adapts the diffusion process by modeling variable noise levels at the pixel level. This technique allows the model to efficiently use known pixel values from the start, guiding the generation process toward the target manifold. By embedding this information early in the diffusion process, TD-Paint significantly accelerates sampling without compromising image quality. Unlike conventional diffusion-based inpainting models, which require a dedicated architecture or an expensive generation loop, TD-Paint achieves faster sampling times without architectural modifications. Experimental results across three datasets show that TD-Paint outperforms state-of-the-art diffusion models while maintaining lower complexity.'}",https://openreview.net{'value': '/pdf/4dbed0c94a65b47289a2f0828716c1889ec01997.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=emMMa4q0qw,{'value': 'Vision CNNs trained to estimate spatial latents learned similar ventral-stream-aligned representations'},Yudi Xie; Weichen Huang; Esther Alter; Jeremy Schwartz; Joshua B. Tenenbaum; James J. DiCarlo,~Yudi_Xie1; ~Weichen_Huang3; ~Esther_Alter1; ~Jeremy_Schwartz2; ~Joshua_B._Tenenbaum1; ~James_J._DiCarlo1,"{'value': ['Vision', 'Convolutional Neural Networks', 'Representation Learning', 'Neural Data Alignment', 'Ventral Visual Stream', 'Computational Neuroscience']}","{'value': 'Studies of the functional role of the primate ventral visual stream have traditionally focused on object categorization, often ignoring -- despite much prior evidence -- its role in estimating ""spatial"" latents such as object position and pose. Most leading ventral stream models are derived by optimizing networks for object categorization, which seems to imply that the ventral stream is also derived under such an objective. Here, we explore an alternative hypothesis: Might the ventral stream be optimized for estimating spatial latents? And a closely related question: How different -- if at all -- are representations learned from spatial latent estimation compared to categorization? To ask these questions, we leveraged synthetic image datasets generated by a 3D graphic engine and trained convolutional neural networks (CNNs) to estimate different combinations of spatial and category latents. We found that models trained to estimate just a few spatial latents achieve neural alignment scores comparable to those trained on hundreds of categories, and the spatial latent performance of models strongly correlates with their neural alignment. Spatial latent and category-trained models have very similar -- but not identical -- internal representations, especially in their early and middle layers. We provide evidence that this convergence is partly driven by non-target latent variability in the training data, which facilitates the implicit learning of representations of those non-target latents. Taken together, these results suggest that many training objectives, such as spatial latents, can lead to similar models aligned neurally with the ventral stream. Thus, one should not assume that the ventral stream is optimized for object categorization only. As a field, we need to continue to sharpen our measures of comparing models to brains to better understand the functional roles of the ventral stream.'}",https://openreview.net{'value': '/pdf/a61901333d22af62e25bf26f2b5aec436ba45a8e.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=ei3qCntB66,{'value': 'BadRobot: Jailbreaking Embodied LLM Agents in the Physical World'},Hangtao Zhang; Chenyu Zhu; Xianlong Wang; Ziqi Zhou; Changgan Yin; Minghui Li; Lulu Xue; Yichen Wang; Shengshan Hu; Aishan Liu; Peijin Guo; Leo Yu Zhang,~Hangtao_Zhang1; ~Chenyu_Zhu1; ~Xianlong_Wang1; ~Ziqi_Zhou2; ~Changgan_Yin1; ~Minghui_Li2; ~Lulu_Xue1; ~Yichen_Wang8; ~Shengshan_Hu1; ~Aishan_Liu1; ~Peijin_Guo2; ~Leo_Yu_Zhang1,"{'value': ['Robotics', 'Safety Risks', 'Embodied AI', 'LLM', 'Multimodal', 'Agent', 'Jailbreak attack']}","{'value': ""Embodied AI represents systems where AI is integrated into physical entities. Multimodal Large Language Model (LLM), which exhibits powerful language understanding abilities, has been extensively employed in embodied AI by facilitating sophisticated task planning. However, a critical safety issue remains overlooked: could these embodied LLMs perpetrate harmful behaviors? In response, we introduce BadRobot, the first attack paradigm designed to jailbreak robotic manipulation, making embodied LLMs violate safety and ethical constraints through typical voice-based user-system interactions. Specifically, three vulnerabilities are exploited to achieve this type of attack: (i) manipulation of LLMs within robotic systems, (ii) misalignment between linguistic outputs and physical actions, and \n(iii) unintentional hazardous behaviors caused by world knowledge's flaws. Furthermore, we construct a benchmark of various malicious physical action queries to evaluate BadRobot's attack performance. Based on this benchmark, extensive experiments against existing prominent embodied LLM frameworks (e.g., Voxposer, Code as Policies, and ProgPrompt) demonstrate the effectiveness of our BadRobot. We emphasize that addressing this emerging vulnerability is crucial for the secure deployment of LLMs in robotics.\n\nWarning: This paper contains harmful AI-generated language and aggressive actions.""}",https://openreview.net{'value': '/pdf/76383d1a08361f293726479351318ef9a63c5d74.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=eLLBILFRsA,{'value': 'UniDetox: Universal Detoxification of Large Language Models via Dataset Distillation'},Huimin LU; Masaru Isonuma; Junichiro Mori; Ichiro Sakata,~Huimin_LU4; ~Masaru_Isonuma1; ~Junichiro_Mori2; ~Ichiro_Sakata1,"{'value': ['Large Language Models', 'Detoxification', 'Safety', 'Fairness']}","{'value': 'We present UniDetox, a universally applicable method designed to mitigate toxicity across various large language models (LLMs).\nPrevious detoxification methods are typically model-specific, addressing only individual models or model families, and require careful hyperparameter tuning due to the trade-off between detoxification efficacy and language modeling performance. \nIn contrast, UniDetox provides a detoxification technique that can be universally applied to a wide range of LLMs without the need for separate model-specific tuning. \nSpecifically, we propose a novel and efficient dataset distillation technique for detoxification using contrastive decoding. \nThis approach distills detoxifying representations in the form of synthetic text data, enabling universal detoxification of any LLM through fine-tuning with the distilled text. \nOur experiments demonstrate that the detoxifying text distilled from GPT-2 can effectively detoxify larger models, including OPT, Falcon, and LLaMA-2. \nFurthermore, UniDetox eliminates the need for separate hyperparameter tuning for each model, as a single hyperparameter configuration can be seamlessly applied across different models. \nAdditionally, analysis of the detoxifying text reveals a reduction in politically biased content, providing insights into the attributes necessary for effective detoxification of LLMs.'}",https://openreview.net{'value': '/pdf/e74fc74e3070796515524557aff0f01d4aed0181.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=dkrEoT68by,{'value': 'Gaussian Splatting Lucas-Kanade'},Liuyue Xie; Joel Julin; Koichiro Niinuma; Laszlo Attila Jeni,~Liuyue_Xie1; ~Joel_Julin1; ~Koichiro_Niinuma1; ~Laszlo_Attila_Jeni1,"{'value': ['Gaussian Splatting', 'regularization', 'novel view synthesis']}","{'value': 'Gaussian Splatting and its dynamic extensions are effective for reconstructing 3D scenes from 2D images when there is significant camera movement to facilitate motion parallax and when scene objects remain relatively static. However, in many real-world scenarios, these conditions are not met. As a consequence, data-driven semantic and geometric priors have been favored as regularizers, despite their bias toward training data and their neglect of broader movement dynamics.\n\nDeparting from this practice, we propose a novel analytical approach that adapts the classical Lucas-Kanade method to dynamic Gaussian splatting. By leveraging the intrinsic properties of the forward warp field network, we derive an analytical velocity field that, through time integration, facilitates accurate scene flow computation. This enables the precise enforcement of motion constraints on warp fields, thus constraining both 2D motion and 3D positions of the Gaussians. Our method excels in reconstructing highly dynamic scenes with minimal camera movement, as demonstrated through experiments on both synthetic and real-world scenes.'}",https://openreview.net{'value': '/pdf/19ea9a22fe4265812b4e511fa756c93c90696cdb.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=din0lGfZFd,{'value': 'Reasoning with Latent Thoughts: On the Power of Looped Transformers'},Nikunj Saunshi; Nishanth Dikkala; Zhiyuan Li; Sanjiv Kumar; Sashank J. Reddi,~Nikunj_Saunshi1; ~Nishanth_Dikkala1; ~Zhiyuan_Li2; ~Sanjiv_Kumar1; ~Sashank_J._Reddi1,"{'value': ['looped models', 'reasoning', 'language model', 'iterative algorithm', 'inductive bias', 'scaling']}","{'value': 'Large language models have shown remarkable reasoning abilities and scaling laws suggest that large parameter count, especially along the depth axis, is the primary driver. In this work, we make a stronger claim --- many reasoning problems require a large depth but not necessarily many parameters. This unlocks a novel application of looped models for reasoning. Firstly, we show that for many synthetic reasoning problems like addition, $p$-hop induction, and math problems, a $k$-layer transformer looped $L$ times nearly matches the performance of a $kL$-layer non-looped model, and is significantly better than a $k$-layer model. This is further corroborated by theoretical results showing that many such reasoning problems can be solved via iterative algorithms, and thus, can be solved effectively using looped models with nearly optimal depth. Perhaps surprisingly, these benefits also translate to practical settings of language modeling --- on many downstream reasoning tasks, a language model with $k$-layers looped $L$ times can be competitive to, if not better than, a $kL$-layer language model. In fact, our empirical analysis reveals an intriguing phenomenon: looped and non-looped models exhibit scaling behavior that depends on their effective depth, akin to the inference-time scaling of chain-of-thought (CoT) reasoning. We further elucidate the connection to CoT reasoning by proving that looped models implicitly generate latent thoughts and can simulate $T$ steps of CoT with $T$ loops. Inspired by these findings, we also present an interesting dichotomy between reasoning and memorization, and design a looping-based regularization that is effective on both fronts.'}",https://openreview.net{'value': '/pdf/3b6624b631e0aa8b60e9db8890eda637165a01fa.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=dWsdJAXjQD,{'value': 'ImProver: Agent-Based Automated Proof Optimization'},Riyaz Ahuja; Jeremy Avigad; Prasad Tetali; Sean Welleck,~Riyaz_Ahuja1; ~Jeremy_Avigad1; ~Prasad_Tetali1; ~Sean_Welleck1,"{'value': ['Automated Proof Optimization', 'Neural Theorem Proving', 'Formal Mathematics', 'Lean Theorem Prover', 'Proof Generation', 'Large Language Models', 'Symbolic Reasoning', 'Interactive Theorem Proving']}","{'value': 'Large language models (LLMs) have been used to generate formal proofs of mathematical theorems in proofs assistants such as Lean.\nHowever, we often want to optimize a formal proof with respect to various criteria, depending on its downstream use.\nFor example, we may want a proof to adhere to a certain style, be declaratively structured, or concise. Having suitably optimized proofs is also important for learning tasks, especially since human-written proofs may not optimal for that purpose.\nTo this end, we study a new problem of automated proof optimization: rewriting a proof so that it is correct and optimizes for an arbitrary criterion, such as length or declarativity.\nAs a first method for automated proof optimization, we present ImProver, a large-language-model agent that rewrites proofs to optimize arbitrary user-defined metrics in Lean.\nWe find that naively applying LLMs to proof optimization falls short, and we incorporate various improvements into ImProver, such as the use of symbolic Lean context in a novel Chain-of-States technique, as well as error-correction and retrieval. We test ImProver on rewriting real-world undergraduate, competition, and research-level mathematics theorems, finding that ImProver is capable of rewriting proofs so that they are substantially shorter and more declarative in structure.'}",https://openreview.net{'value': '/pdf/edb7bb825647dda807602ae0dde350b1869b571b.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=dTGH9vUVdf,{'value': 'FreeVS: Generative View Synthesis on Free Driving Trajectory'},Qitai Wang; Lue Fan; Yuqi Wang; Yuntao Chen; Zhaoxiang Zhang,~Qitai_Wang1; ~Lue_Fan1; ~Yuqi_Wang3; ~Yuntao_Chen1; ~Zhaoxiang_Zhang3,"{'value': ['Novel View Synthesis', 'Driving Scene', 'Free Trajectory', 'Image Generation']}","{'value': 'Existing reconstruction-based novel view synthesis methods for driving scenes focus on synthesizing camera views along the recorded trajectory of the ego vehicle. \nTheir image rendering performance will severely degrade on viewpoints falling out of the recorded trajectory, where camera rays are untrained.\nWe propose FreeVS, a novel fully generative approach that can synthesize camera views on free new trajectories in real driving scenes. \nTo control the generation results to be 3D consistent with the real scenes and accurate in viewpoint pose, we propose the pseudo-image representation of view priors to control the generation process.\nViewpoint translation simulation is applied on pseudo-images to simulate camera movement in each direction.\nOnce trained, FreeVS can be applied to any validation sequences without reconstruction process and synthesis views on novel trajectories.\nMoreover, we propose two new challenging benchmarks tailored to driving scenes, which are novel camera synthesis and novel trajectory synthesis, emphasizing the freedom of viewpoints.\nGiven that no ground truth images are available on novel trajectories, we also propose to evaluate the consistency of images synthesized on novel trajectories with 3D perception models.\nExperiments on the Waymo Open Dataset show that FreeVS has a strong image synthesis performance on both the recorded trajectories and novel trajectories. \nThe code is released. Project page: https://freevs24.github.io/.'}",https://openreview.net{'value': '/pdf/46ade79dd78eabbde12d2e14f36d694f531efaa9.pdf'},{'title_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=d8cnezVcaW,{'value': 'MallowsPO: Fine-Tune Your LLM with Preference Dispersions'},Haoxian Chen; Hanyang Zhao; Henry Lam; David Yao; Wenpin Tang,~Haoxian_Chen2; ~Hanyang_Zhao1; ~Henry_Lam1; ~David_Yao1; ~Wenpin_Tang1,"{'value': ['Language Models fine-tuning', 'learning from human feedback', 'Mallows ranking model', 'human preference dispersions']}","{'value': ""Direct Preference Optimization (DPO) has recently emerged as a popular approach to improve reinforcement learning from human feedback (RLHF), leading to better techniques to fine-tune large language models (LLM). A weakness of DPO, however, lies in its lack of capability to characterize the diversity of human preferences. Inspired by Mallows' theory of preference ranking, we develop in this paper a new approach, the *MallowsPO*. A distinct feature of this approach is a  *dispersion index*, which reflects the dispersion of human preference to prompts. We show that existing DPO models can be reduced to special cases of this dispersion index, thus unified with MallowsPO. More importantly, we demonstrate empirically how to use this dispersion index to enhance the performance of DPO in a broad array of benchmark tasks, from synthetic bandit selection to controllable generation and dialogues, while maintaining great generalization capabilities. MallowsPO is also compatible with other SOTA offline preference optimization methods, boosting nearly 2\\% extra LC win rate when used as a plugin for fine-tuning Llama3-Instruct.""}",https://openreview.net{'value': '/pdf/a2e9d614ab04dfa3bcc205fc2b2ebcd40c512be3.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=cyPMEXdqQ2,{'value': 'Overcoming Lower-Level Constraints in Bilevel Optimization: A Novel Approach with Regularized Gap Functions'},Wei Yao; Haian Yin; Shangzhi Zeng; Jin Zhang,~Wei_Yao3; ~Haian_Yin1; ~Shangzhi_Zeng1; ~Jin_Zhang8,"{'value': ['bilevel optimization', 'constrained optimization', 'gap function', 'single-loop', 'Hessian-free', 'convergence analysis']}","{'value': 'Constrained bilevel optimization tackles nested structures present in constrained learning tasks like constrained meta-learning, adversarial learning, and distributed bilevel optimization. \nHowever, existing bilevel optimization methods mostly are typically restricted to specific constraint settings, such as linear lower-level constraints. \nIn this work, we overcome this limitation and develop a new single-loop, Hessian-free constrained bilevel algorithm capable of handling more general lower-level constraints. \nWe achieve this by employing a doubly regularized gap function tailored to the constrained lower-level problem, transforming constrained bilevel optimization into an equivalent single-level optimization problem with a single smooth constraint. \nWe rigorously establish the non-asymptotic convergence analysis of the proposed algorithm under the convexity of lower-level problem, avoiding the need for strong convexity assumptions on the lower-level objective or coupling convexity assumptions on lower-level constraints found in existing literature. \nAdditionally, the generality of our method allows for its extension to bilevel optimization with minimax lower-level problem. \nWe evaluate the effectiveness and efficiency of our algorithm on various synthetic problems, typical hyperparameter learning tasks, and generative adversarial network.'}",https://openreview.net{'value': '/pdf/d3722791c92607647c4f56c69ec691e1bf105029.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=cmfyMV45XO,{'value': 'Feedback Favors the Generalization of Neural ODEs'},Jindou Jia; Zihan Yang; Meng Wang; Kexin Guo; Jianfei Yang; Xiang Yu; Lei Guo,~Jindou_Jia1; ~Zihan_Yang2; ~Meng_Wang36; ~Kexin_Guo1; ~Jianfei_Yang4; ~Xiang_Yu7; ~Lei_Guo8,"{'value': ['Neural ODEs', 'feedback', 'generalization', 'learning dynamical systems', 'model predictive control']}","{'value': 'The well-known generalization problem hinders the application of artificial neural networks in continuous-time prediction tasks with varying latent dynamics. In sharp contrast, biological systems can neatly adapt to evolving environments benefiting from real-time feedback mechanisms. Inspired by the feedback philosophy, we present feedback neural networks, showing that a feedback loop can flexibly correct the learned latent dynamics of neural ordinary differential equations (neural ODEs), leading to a prominent generalization improvement. The feedback neural network is a novel two-DOF neural network, which possesses robust performance in unseen scenarios with no loss of accuracy performance on previous tasks. A linear feedback form is presented to correct the learned latent dynamics firstly, with a convergence guarantee. Then, domain randomization is utilized to learn a nonlinear neural feedback form. Finally, extensive tests including trajectory prediction of a real irregular object and model predictive control of a quadrotor with various uncertainties, are implemented, indicating significant improvements over state-of-the-art model-based and learning-based methods.'}",https://openreview.net{'value': '/pdf/0a30b391cbaf2c1c5b4c75e5008fba260568920e.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=cmYScmfu4Q,{'value': 'Zeroth-Order Policy Gradient for Reinforcement Learning from Human Feedback without Reward Inference'},Qining Zhang; Lei Ying,~Qining_Zhang2; ~Lei_Ying1,"{'value': ['reinforcement learning theory', 'human feedback', 'zeroth-order optimization']}","{'value': 'Reward inference (learning a reward model from human preferences) is a critical intermediate step in the Reinforcement Learning from Human Feedback (RLHF) pipeline for fine-tuning Large Language Models (LLMs). In practice, RLHF faces fundamental challenges such as distribution shift, reward model overfitting, and problem misspecification. An alternative approach is direct policy optimization without reward inference, such as Direct Preference Optimization (DPO), which provides a much simpler pipeline and has shown empirical success in LLM applications. However, DPO utilizes the closed-form expression between the optimal policy and the reward function, which is only suitable under the bandit setting or deterministic MDPs. This paper develops two RLHF algorithms without reward inference for general RL problems beyond bandits and deterministic MDPs, and general preference models beyond the Bradley-Terry model. The key idea is to estimate the local value function difference from human preferences and then approximate the policy gradient with a zeroth-order gradient approximator. For both algorithms, we establish polynomial convergence rates in terms of the number of policy gradient iterations, the number of trajectory samples, and human preference queries per iteration. Numerical experiments in stochastic environments validate the performance of our proposed algorithms, outperforming popular RLHF baselines such as DPO and PPO. Our paper shows there exist provably efficient methods to solve general RLHF problems without reward inference.'}",https://openreview.net{'value': '/pdf/420c80e7c7bef257b8b85ab8dc6421a909d695d6.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=cfGpIcOIa5,{'value': 'GeoILP: A Synthetic Dataset to Guide Large-Scale Rule Induction'},Si Chen; Richong Zhang; Xu Zhang,~Si_Chen8; ~Richong_Zhang1; ~Xu_Zhang35,"{'value': ['dataset', 'inductive logic programming', 'rule induction', 'neuro-symbolic methods']}","{'value': 'Inductive logic programming (ILP) is a machine learning approach aiming to learn explanatory rules from data.\n    While existing ILP systems can successfully solve small-scale tasks, large-scale applications with various language biases are rarely explored.\n    Besides, it is crucial for a large majority of current ILP systems to require expert-defined language bias, which hampers the development of ILP towards broader utilizations.\n    In this paper, we introduce GeoILP, a large-scale synthetic dataset of diverse ILP tasks involving numerous aspects of language bias.\n    These tasks are built from geometry problems, at the level from textbook exercise to regional International Mathematical Olympiad (IMO), with the help of a deduction engine.\n    These problems are elaborately selected to cover all challenging language biases, such as recursion, predicate invention, and high arity.\n    Experimental results show that no existing method can solve GeoILP tasks.\n    In addition, along with classic symbolic-form data, we provide image-form data to boost the development of the joint learning of neural perception and symbolic rule induction.'}",https://openreview.net{'value': '/pdf/53bc535911abf6a7ae17654a8aacafcabeb32f0d.pdf'},{'title_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=cR5GTis5II,{'value': 'eQMARL: Entangled Quantum Multi-Agent Reinforcement Learning for Distributed Cooperation over Quantum Channels'},Alexander DeRieux; Walid Saad,~Alexander_DeRieux1; ~Walid_Saad1,"{'value': ['quantum machine learning', 'multi-agent reinforcement learning', 'quantum entanglement']}","{'value': 'Collaboration is a key challenge in distributed multi-agent reinforcement learning (MARL) environments. Learning frameworks for these decentralized systems must weigh the benefits of explicit player coordination against the communication overhead and computational cost of sharing local observations and environmental data. Quantum computing has sparked a potential synergy between quantum entanglement and cooperation in multi-agent environments, which could enable more efficient distributed collaboration with minimal information sharing. This relationship is largely unexplored, however, as current state-of-the-art quantum MARL (QMARL) implementations rely on classical information sharing rather than entanglement over a quantum channel as a coordination medium. In contrast, in this paper, a novel framework dubbed entangled QMARL (eQMARL) is proposed. The proposed eQMARL is a distributed actor-critic framework that facilitates cooperation over a quantum channel and eliminates local observation sharing via a quantum entangled split critic. Introducing a quantum critic uniquely spread across the agents allows coupling of local observation encoders through entangled input qubits over a quantum channel, which requires no explicit sharing of local observations and reduces classical communication overhead. Further, agent policies are tuned through joint observation-value function estimation via joint quantum measurements, thereby reducing the centralized computational burden. Experimental results show that eQMARL with $\\Psi^{+}$ entanglement converges to a cooperative strategy up to $17.8\\\\%$ faster and with a higher overall score compared to split classical and fully centralized classical and quantum baselines. The results also show that eQMARL achieves this performance with a constant factor of $25$-times fewer centralized parameters compared to the split classical baseline.'}",https://openreview.net{'value': '/pdf/4d098c7453d6f8dfd85d1329104f4b7135073b86.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=cKlzKs3Nnb,{'value': 'Diversity Empowers Intelligence: Integrating Expertise of Software Engineering Agents'},Kexun Zhang; Weiran Yao; Zuxin Liu; Yihao Feng; Zhiwei Liu; Rithesh R N; Tian Lan; Lei Li; Renze Lou; Jiacheng Xu; Bo Pang; Yingbo Zhou; Shelby Heinecke; Silvio Savarese; Huan Wang; Caiming Xiong,~Kexun_Zhang1; ~Weiran_Yao1; ~Zuxin_Liu1; ~Yihao_Feng1; ~Zhiwei_Liu3; ~Rithesh_R_N1; ~Tian_Lan13; ~Lei_Li11; ~Renze_Lou1; ~Jiacheng_Xu2; ~Bo_Pang4; ~Yingbo_Zhou1; ~Shelby_Heinecke1; ~Silvio_Savarese1; ~Huan_Wang1; ~Caiming_Xiong1,"{'value': ['large language models', 'LLM agents', 'software engineering']}","{'value': ""Large language model (LLM) agents have shown great potential in solving real-world software engineering (SWE) problems. The most advanced open-source SWE agent can resolve over 27% of real GitHub issues in SWE-Bench Lite. However, these sophisticated agent frameworks exhibit varying strengths, excelling in certain tasks while underperforming in others. To fully harness the diversity of these agents, we propose DEI (Diversity Empowered Intelligence), a framework that leverages their unique expertise. DEI functions as a meta-module atop existing SWE agent frameworks, managing agent collectives for enhanced problem-solving. Experimental results show that a DEI-guided committee of agents is able to surpass the best individual agent's performance by a large margin. For instance, a group of open-source SWE agents, with a maximum individual resolve rate of 27.3% on SWE-Bench Lite, can achieve a 34.3% resolve rate with DEI, making a 25% improvement and beating most closed-source solutions. Our best-performing group excels with a 55% resolve rate, securing the highest ranking on SWE-Bench Lite. Our findings contribute to the growing body of research on collaborative AI systems and their potential to solve complex software engineering challenges.""}",https://openreview.net{'value': '/pdf/f7f17e493bc7d4c9983d9ae83c6beae7a477c168.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=cH65nS5sOz,{'value': 'Subgraph Federated Learning for Local Generalization'},Sungwon Kim; Yoonho Lee; Yunhak Oh; Namkyeong Lee; Sukwon Yun; Junseok Lee; Sein Kim; Carl Yang; Chanyoung Park,~Sungwon_Kim3; ~Yoonho_Lee2; ~Yunhak_Oh1; ~Namkyeong_Lee1; ~Sukwon_Yun1; ~Junseok_Lee1; ~Sein_Kim1; ~Carl_Yang1; ~Chanyoung_Park1,"{'value': ['Graph Neural Networks', 'Graph Federated Learning']}","{'value': ""Federated Learning (FL) on graphs enables collaborative model training to enhance performance without compromising the privacy of each client. However, existing methods often overlook the mutable nature of graph data, which frequently introduces new nodes and leads to shifts in label distribution. Since they focus solely on performing well on each client's local data, they are prone to overfitting to their local distributions (i.e., local overfitting), which hinders their ability to generalize to unseen data with diverse label distributions. In contrast, our proposed method, FedLoG, effectively tackles this issue by mitigating local overfitting. Our model generates global synthetic data by condensing the reliable information from each class representation and its structural information across clients. Using these synthetic data as a training set, we alleviate the local overfitting problem by adaptively generalizing the absent knowledge within each local dataset. This enhances the generalization capabilities of local models, enabling them to handle unseen data effectively. Our model outperforms baselines in our proposed experimental settings, which are designed to measure generalization power to unseen data in practical scenarios. \nOur code is available at https://github.com/sung-won-kim/FedLoG""}",https://openreview.net{'value': '/pdf/fae13ae6104a2c066d21e5a78b83d3d50f3dc0d0.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=cFu7ze7xUm,{'value': 'DuoAttention: Efficient Long-Context LLM Inference with Retrieval and Streaming Heads'},Guangxuan Xiao; Jiaming Tang; Jingwei Zuo; junxian guo; Shang Yang; Haotian Tang; Yao Fu; Song Han,~Guangxuan_Xiao1; ~Jiaming_Tang1; ~Jingwei_Zuo2; ~junxian_guo1; ~Shang_Yang1; ~Haotian_Tang1; ~Yao_Fu3; ~Song_Han5,{'value': ['Large Language Models; Long Context; Efficiency;']},"{'value': ""Deploying long-context large language models (LLMs) is essential but poses significant computational and memory challenges.\nCaching all Key and Value (KV) states across all attention heads consumes substantial memory.\nExisting KV cache pruning methods either damage the long-context capabilities of LLMs or offer only limited efficiency improvements.\nIn this paper, we identify that only a fraction of attention heads, a.k.a, Retrieval Heads, are critical for processing long contexts and require full attention across all tokens.\nIn contrast, all other heads, which primarily focus on recent tokens and attention sinks—referred to as Streaming Heads—do not require full attention.\nBased on this insight, we introduce DuoAttention, a framework that only applies a full KV cache to retrieval heads while using a light-weight, constant-length KV cache for streaming heads, which reduces both LLM's decoding and pre-filling memory and latency without compromising its long-context abilities.\nDuoAttention uses a lightweight, optimization-based algorithm with synthetic data to identify retrieval heads accurately.\nOur method significantly reduces long-context inference memory by up to 2.55$\\times$ for MHA and 1.67$\\times$ for GQA models while speeding up decoding by up to 2.18$\\times$ and 1.50$\\times$ and accelerating pre-filling by up to 1.73$\\times$ and 1.63$\\times$ for MHA and GQA models, respectively, with minimal accuracy loss compared to full attention.\nNotably, combined with quantization, DuoAttention enables Llama-3-8B decoding with 3.33 million context length measured on a single A100 GPU. Code is provided in https://github.com/mit-han-lab/duo-attention.""}",https://openreview.net{'value': '/pdf/5723b4f3ab2bb241158f3f35ad3ac5b22b62192e.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=cCl10IU836,{'value': 'Interaction Asymmetry: A General Principle for Learning Composable Abstractions'},Jack Brady; Julius von Kügelgen; Sebastien Lachapelle; Simon Buchholz; Thomas Kipf; Wieland Brendel,~Jack_Brady1; ~Julius_von_Kügelgen2; ~Sebastien_Lachapelle1; ~Simon_Buchholz1; ~Thomas_Kipf2; ~Wieland_Brendel1,"{'value': ['disentanglement', 'compositional generalization', 'representation learning', 'object-centric learning', 'identifiability', 'unsupervised learning', 'out-of-domain generalization']}","{'value': 'Learning disentangled representations of concepts and re-composing them in unseen ways is crucial for generalizing to out-of-domain situations. However, the underlying properties of concepts that enable such disentanglement and compositional generalization remain poorly understood. In this work, we propose the principle of interaction asymmetry which states: ""Parts of the same concept have more complex interactions than parts of different concepts"". We formalize this via block diagonality conditions on the $(n+1)$th order derivatives of the generator mapping concepts to observed data, where different orders of ""complexity"" correspond to different $n$. Using this formalism, we prove that interaction asymmetry enables both disentanglement and compositional generalization. Our results unify recent theoretical results for learning concepts of objects, which we show are recovered as special cases with $n=0$ or $1$. We provide results for up to $n=2$, thus extending these prior works to more flexible generator functions, and conjecture that the same proof strategies generalize to larger $n$. Practically, our theory suggests that, to disentangle concepts, an autoencoder should penalize its latent capacity and the interactions between concepts during decoding. We propose an implementation of these criteria using a flexible Transformer-based VAE, with a novel regularizer on the attention weights of the decoder. On synthetic image datasets consisting of objects, we provide evidence that this model can achieve comparable object disentanglement to existing models that use more explicit object-centric priors.'}",https://openreview.net{'value': '/pdf/01aac914ffd3d03f5dc9c35d32d54d3964a8c625.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=c61unr33XA,{'value': 'Dataset Distillation via Knowledge Distillation: Towards Efficient Self-Supervised Pre-training of Deep Networks'},Siddharth Joshi; Jiayi Ni; Baharan Mirzasoleiman,~Siddharth_Joshi1; ~Jiayi_Ni1; ~Baharan_Mirzasoleiman1,"{'value': ['dataset distillation', 'self-supervised learning']}","{'value': 'Dataset distillation (DD) generates small synthetic datasets that can efficiently train deep networks with a limited amount of memory and compute. Despite the success of DD methods for supervised learning, DD for self-supervised pre-training of deep models has remained unaddressed. Pre-training on unlabeled data is crucial for efficiently generalizing to downstream tasks with limited labeled data. In this work, we propose the first effective DD method for SSL pre-training. First, we show, theoretically and empirically, that naiive application of supervised DD methods to SSL fails, due to the high variance of the SSL gradient. Then, we address this issue by relying on insights from knowledge distillation (KD) literature. Specifically, we train a small student model to match the representations of a larger teacher model trained with SSL. Then, we generate a small synthetic dataset by matching the training trajectories of the student models. As the KD objective has considerably lower variance than SSL, our approach can generate synthetic datasets that can successfully pre-train high-quality encoders. Through extensive experiments, we show that our distilled sets lead to up to 13% higher accuracy than prior work, on a variety of downstream tasks, in the presence of limited labeled data. Code at https://github.com/BigML-CS-UCLA/MKDT.'}",https://openreview.net{'value': '/pdf/db2cd602e83be66d337cf9e9fea9e5a1a7f8f218.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=bwhI6bCGY1,{'value': 'ReMatching Dynamic Reconstruction Flow'},Sara Oblak; Despoina Paschalidou; Sanja Fidler; Matan Atzmon,~Sara_Oblak1; ~Despoina_Paschalidou1; ~Sanja_Fidler1; ~Matan_Atzmon1,"{'value': ['Dynamic Reconstruction', 'Flow Modeling', 'Gaussian Splatting', 'Novel view synthesis']}","{'value': 'Reconstructing a dynamic scene from image inputs is a fundamental computer\nvision task with many downstream applications. Despite recent advancements, existing approaches still struggle to achieve high-quality reconstructions from unseen viewpoints and timestamps. This work introduces the ReMatching framework, designed to improve reconstruction quality by incorporating deformation priors into dynamic reconstruction models. Our approach advocates for velocity-field based priors, for which we suggest a matching procedure that can seamlessly supplement existing dynamic reconstruction pipelines. The framework is highly adaptable and can be applied to various dynamic representations. Moreover, it supports integrating multiple types of model priors and enables combining simpler ones to create more complex classes. Our evaluations on popular benchmarks involving both synthetic and real-world dynamic scenes demonstrate that augmenting current state-of-the-art methods with our approach leads to a clear improvement in reconstruction accuracy.'}",https://openreview.net{'value': '/pdf/4f7782b721c23efbd060cb8c4012496b7fae11dd.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=bnJgzAQjWf,{'value': 'Selective Induction Heads: How Transformers Select Causal Structures in Context'},Francesco D'Angelo; Francesco Croce; Nicolas Flammarion,~Francesco_D'Angelo1; ~Francesco_Croce1; ~Nicolas_Flammarion1,"{'value': ['Transformers', 'Markov chain', 'interpretability', 'attention', 'in-context learning']}","{'value': 'Transformers have exhibited exceptional capabilities in sequence modelling tasks, leveraging self-attention and in-context learning. Critical to this success are induction heads, attention circuits that enable copying tokens based on their previous occurrences. In this work, we introduce a novel synthetic framework designed to enable the theoretical analysis of transformers’ ability to dynamically handle causal structures. Existing works rely on Markov Chains to study the formation of induction heads, revealing how transformers capture causal dependencies and learn transition probabilities in-context. However, they rely on a fixed causal structure that fails to capture the complexity of natural languages, where the relationship between tokens dynamically changes with context.  To this end, our framework varies the causal structure through interleaved Markov chains with different lags while keeping the transition probabilities fixed. This setting unveils the formation of Selective Induction Heads, a new circuit that endows transformers with the ability to select the correct causal structure in-context. We empirically demonstrate that attention-only transformers learn this mechanism to predict the next token by identifying the correct lag and copying the corresponding token from the past. We provide a detailed construction of a 3-layer transformer to implement the selective induction head, and a theoretical analysis proving that this mechanism asymptotically converges to the maximum likelihood solution. Our findings advance the theoretical understanding of how transformers select causal structures, providing new insights into their functioning and interpretability.'}",https://openreview.net{'value': '/pdf/9f92fb305be889d87fa49a7b60d757809d59fe81.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=bhK7U37VW8,{'value': 'AutoDAN-Turbo: A Lifelong Agent for Strategy Self-Exploration to Jailbreak LLMs'},Xiaogeng Liu; Peiran Li; G. Edward Suh; Yevgeniy Vorobeychik; Zhuoqing Mao; Somesh Jha; Patrick McDaniel; Huan Sun; Bo Li; Chaowei Xiao,~Xiaogeng_Liu1; ~Peiran_Li1; ~G._Edward_Suh2; ~Yevgeniy_Vorobeychik1; ~Zhuoqing_Mao1; ~Somesh_Jha1; ~Patrick_McDaniel1; ~Huan_Sun1; ~Bo_Li19; ~Chaowei_Xiao2,"{'value': ['Large Language Model', 'Jailbreak Attack', 'LLM Agent']}","{'value': 'Jailbreak attacks serve as essential red-teaming tools, proactively assessing whether LLMs can behave responsibly and safely in adversarial environments. Despite diverse strategies (e.g., cipher, low-resource language, persuasions, and so on) that have been proposed and shown success, these strategies are still manually designed, limiting their scope and effectiveness as a red-teaming tool. In this paper, we propose AutoDAN-Turbo, a black-box jailbreak method that can automatically discover as many jailbreak strategies as possible from scratch, without any human intervention or predefined scopes (e.g., specified candidate strategies), and use them for red-teaming. As a result, AutoDAN-Turbo can significantly outperform baseline methods, achieving a 74.3% higher average attack success rate on public benchmarks. Notably, AutoDAN-Turbo achieves an 88.5 attack success rate on GPT-4-1106-turbo. In addition, AutoDAN-Turbo is a unified framework that can incorporate existing human-designed jailbreak strategies in a plug-and-play manner. By integrating human-designed strategies, AutoDAN-Turbo can even achieve a higher attack success rate of 93.4 on GPT-4-1106-turbo.'}",https://openreview.net{'value': '/pdf/a37630b8dfc70f59120e3aa59fc8a10a7de89340.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=bgpNJBD6Va,{'value': 'No Preference Left Behind: Group Distributional Preference Optimization'},Binwei Yao; Zefan Cai; Yun-Shiuan Chuang; Shanglin Yang; Ming Jiang; Diyi Yang; Junjie Hu,~Binwei_Yao1; ~Zefan_Cai1; ~Yun-Shiuan_Chuang1; ~Shanglin_Yang1; ~Ming_Jiang6; ~Diyi_Yang2; ~Junjie_Hu2,{'value': ['preference alignment; large language model; fairness; group preferences']},"{'value': ""Preferences within a group of people are not uniform but follow a distribution. While existing alignment methods like Direct Preference Optimization (DPO) attempt to steer models to reflect human preferences, they struggle to capture the distributional pluralistic preferences within a group. These methods often skew toward dominant preferences, overlooking the diversity of opinions, especially when conflicting preferences arise. To address this issue, we propose Group Distributional Preference Optimization (GDPO), a novel framework that aligns language models with the distribution of preferences within a group by incorporating the concept of beliefs that shape individual preferences. GDPO calibrates a language model using statistical estimation of the group's belief distribution and aligns the model with belief-conditioned preferences, offering a more inclusive alignment framework than traditional methods. In experiments using both synthetic controllable opinion generation and real-world movie review datasets, we show that DPO fails to align with the targeted belief distributions, while GDPO consistently reduces this alignment gap during training. Additionally, our evaluation metrics demonstrate that GDPO outperforms existing approaches in aligning with group distributional preferences, marking a significant advance in pluralistic alignment.""}",https://openreview.net{'value': '/pdf/6a97a75f830cfa76a1e56a22dc79655861112103.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=bSq0XGS3kW,{'value': 'On the Transfer of Object-Centric Representation Learning'},Aniket Rajiv Didolkar; Andrii Zadaianchuk; Anirudh Goyal; Michael Curtis Mozer; Yoshua Bengio; Georg Martius; Maximilian Seitzer,~Aniket_Rajiv_Didolkar1; ~Andrii_Zadaianchuk1; ~Anirudh_Goyal1; ~Michael_Curtis_Mozer1; ~Yoshua_Bengio1; ~Georg_Martius1; ~Maximilian_Seitzer1,"{'value': ['representation learning', 'object-centric learning', 'object-centric representation learning', 'unsupervised learning', 'transfer', 'zero-shot', 'generalization']}","{'value': 'The goal of object-centric representation learning is to decompose visual scenes into a structured representation that isolates the entities into individual vectors. Recent successes have shown that object-centric representation learning can be scaled to real-world scenes by utilizing features from pre-trained foundation models like DINO. However, so far, these object-centric methods have mostly been applied in-distribution, with models trained and evaluated on the same dataset. This is in contrast to the underlying foundation models, which have been shown to be applicable to a wide range of data and tasks. Thus, in this work, we answer the question of whether current real-world capable object-centric methods exhibit similar levels of transferability by introducing a benchmark comprising seven different synthetic and real-world datasets. We analyze the factors influencing performance under transfer and find that training on diverse real-world images improves generalization to unseen scenarios. Furthermore, inspired by the success of task-specific fine-tuning in foundation models, we introduce a novel fine-tuning strategy to adapt pre-trained vision encoders for the task of object discovery. We find that the proposed approach results in state-of-the-art performance for unsupervised object discovery, exhibiting strong zero-shot transfer to unseen datasets.'}",https://openreview.net{'value': '/pdf/ffb4a17baa29fde13353886aa06898a63796db6e.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=bRqaHn3J5I,{'value': 'Prototype antithesis for biological few-shot class-incremental learning'},Binghao Liu; Han Yang; Fang Wan; Fei Gu,~Binghao_Liu1; ~Han_Yang14; ~Fang_Wan1; ~Fei_Gu1,{'value': ['Biological Recognition; Few-Shot Learning; Class-Incremental Learning; Prototype Antithesis']},"{'value': 'Deep learning has become essential in the biological species recognition task. However, a significant challenge is the ability to continuously learn new or mutated species with limited annotated samples. Since species within the same family typically share similar traits, distinguishing between new and existing (old) species during incremental learning often faces the issue of species confusion. This can result in ""catastrophic forgetting"" of old species and poor learning of new ones. To address this issue, we propose a Prototype Antithesis (PA) method, which leverages the hierarchical structures in biological taxa to reduce confusion between new and old species. PA operates in two steps: Residual Prototype Learning (RPL) and Residual Prototype Mixing (RPM). RPL enables the model to learn unique prototypes for each species alongside residual prototypes representing shared traits within families. RPM generates synthetic samples by blending features of new species with residual prototypes of old species, encouraging the model to focus on species-unique traits and minimize species confusion. By integrating RPL and RPM, the proposed PA method mitigates ""catastrophic forgetting"" while improving generalization to new species. Extensive experiments on CUB200, PlantVillage, and Tree-of-Life datasets demonstrate that PA significantly reduces inter-species confusion and achieves state-of-the-art performance, highlighting its potential for deep learning in biological data analysis.'}",https://openreview.net{'value': '/pdf/ea5ccdaf12f069910341ac647c3225c910083755.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=bR1J7SpzrD,{'value': 'Synthio: Augmenting Small-Scale Audio Classification Datasets with Synthetic Data'},Sreyan Ghosh; Sonal Kumar; Zhifeng Kong; Rafael Valle; Bryan Catanzaro; Dinesh Manocha,~Sreyan_Ghosh1; ~Sonal_Kumar1; ~Zhifeng_Kong1; ~Rafael_Valle1; ~Bryan_Catanzaro1; ~Dinesh_Manocha3,"{'value': ['audio classification', 'synthetic data', 'data-efficient learning']}","{'value': 'We present Synthio, a novel approach for augmenting small-scale audio classification datasets with synthetic data. Our goal is to improve audio classification accuracy with limited labeled data. Traditional data augmentation techniques, which apply artificial transformations (e.g., adding random noise or masking segments), struggle to create data that captures the true diversity present in real-world audios. To address this shortcoming, we propose to augment the dataset with synthetic audio generated from text-to-audio (T2A) diffusion models. However, synthesizing effective augmentations is challenging because not only should the generated data be acoustically consistent with the underlying small-scale dataset, but they should also have sufficient compositional diversity. To overcome the first challenge, we align the generations of the T2A model with the small-scale dataset using preference optimization. This ensures that the acoustic characteristics of the generated data remain consistent with the small-scale dataset. To address the second challenge, we propose a novel caption generation technique that leverages the reasoning capabilities of Large Language Models to (1) generate diverse and meaningful audio captions and (2) iteratively refine their quality. The generated captions are then used to prompt the aligned T2A model. We extensively evaluate Synthio on ten datasets and four simulated limited-data settings. Results indicate our method consistently outperforms all baselines by 0.1%-39% using a T2A model trained only on weakly-captioned AudioSet.'}",https://openreview.net{'value': '/pdf/c207b0a8ba4d412ccf2aa36d69fb4177e94af5a8.pdf'},{'title_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=axUf8BOjnH,{'value': 'AgentStudio: A Toolkit for Building General Virtual Agents'},Longtao Zheng; Zhiyuan Huang; Zhenghai Xue; Xinrun Wang; Bo An; Shuicheng YAN,~Longtao_Zheng1; ~Zhiyuan_Huang4; ~Zhenghai_Xue1; ~Xinrun_Wang1; ~Bo_An2; ~Shuicheng_YAN3,"{'value': ['Environment', 'Benchmark', 'Agent', 'Digital Automation']}","{'value': 'General virtual agents need to handle multimodal observations, master complex action spaces, and self-improve in dynamic, open-domain environments. However, existing environments are often domain-specific and require complex setups, which limits agent development and evaluation in real-world settings. As a result, current evaluations lack in-depth analyses that decompose fundamental agent capabilities. We introduce AgentStudio, a trinity of environments, tools, and benchmarks to address these issues. AgentStudio provides a lightweight, interactive environment with highly generic observation and action spaces, e.g., video observations and GUI/API actions. It integrates tools for creating online benchmark tasks, annotating GUI elements, and labeling actions in videos. Based on our environment and tools, we curate an online task suite that benchmarks both GUI interactions and function calling with efficient auto-evaluation. We also reorganize existing datasets and collect new ones using our tools to establish three datasets: GroundUI, IDMBench, and CriticBench. These datasets evaluate fundamental agent abilities, including GUI grounding, learning from videos, and success detection, pointing to the desiderata for robust, general, and open-ended virtual agents.'}",https://openreview.net{'value': '/pdf/474fb13c084ca1d640c138556e983c3c43addabb.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=aueXfY0Clv,{'value': 'Depth Pro: Sharp Monocular Metric Depth in Less Than a Second'},Alexey Bochkovskiy; Amaël Delaunoy; Hugo Germain; Marcel Santos; Yichao Zhou; Stephan Richter; Vladlen Koltun,~Alexey_Bochkovskiy1; ~Amaël_Delaunoy1; ~Hugo_Germain2; ~Marcel_Santos1; ~Yichao_Zhou1; ~Stephan_R._Richter1; ~Vladlen_Koltun1,"{'value': ['depth estimation', 'computer vision']}","{'value': 'We present a foundation model for zero-shot metric monocular depth estimation. Our model, Depth Pro, synthesizes high-resolution depth maps with unparalleled sharpness and high-frequency details. The predictions are metric, with absolute scale, without relying on the availability of metadata such as camera intrinsics. And the model is fast, producing a 2.25-megapixel depth map in 0.3 seconds on a standard GPU. These characteristics are enabled by a number of technical contributions, including an efficient multi-scale vision transformer for dense prediction, a training protocol that combines real and synthetic datasets to achieve high metric accuracy alongside fine boundary tracing, dedicated evaluation metrics for boundary accuracy in estimated depth maps, and state-of-the-art focal length estimation from a single image. Extensive experiments analyze specific design choices and demonstrate that Depth Pro outperforms prior work along multiple dimensions. We release code & weights at https://github.com/apple/ml-depth-pro'}",https://openreview.net{'value': '/pdf/2313c69543c424d5dd1279e35cdb1ab0e8fd22dc.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=amDkNPVWcn,{'value': 'Denoising Autoregressive Transformers for Scalable Text-to-Image Generation'},Jiatao Gu; Yuyang Wang; Yizhe Zhang; Qihang Zhang; Dinghuai Zhang; Navdeep Jaitly; Joshua M. Susskind; Shuangfei Zhai,~Jiatao_Gu1; ~Yuyang_Wang3; ~Yizhe_Zhang2; ~Qihang_Zhang1; ~Dinghuai_Zhang1; ~Navdeep_Jaitly1; ~Joshua_M._Susskind1; ~Shuangfei_Zhai3,"{'value': ['diffusion models', 'autoregressive models', 'Transformer']}","{'value': 'Diffusion models have become the dominant approach for visual generation. They are trained by denoising a Markovian process which gradually adds noise to the input. We argue that the Markovian property limits the model’s ability to fully utilize the generation trajectory, leading to inefficiencies during training and inference. In this paper, we propose DART, a transformer-based model that unifies autoregressive (AR) and diffusion within a non-Markovian framework.  DART iteratively denoises image patches spatially and spectrally using an AR model that has the same architecture as standard language models. DART does not rely on image quantization, which enables more effective image modeling while maintaining flexibility. Furthermore, DART seamlessly trains with both text and image data in a unified model. Our approach demonstrates competitive performance on class-conditioned and text-to-image generation tasks, offering a scalable, efficient alternative to traditional diffusion models. Through this unified framework, DART sets a new benchmark for scalable, high-quality image synthesis.'}",https://openreview.net{'value': '/pdf/0909986352fa7e95e172d0a34cb552f3f3ed9b0e.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=ajSmXqgS24,{'value': 'DexTrack: Towards Generalizable Neural Tracking Control for Dexterous Manipulation from Human References'},Xueyi Liu; Jianibieke Adalibieke; Qianwei Han; Yuzhe Qin; Li Yi,~Xueyi_Liu1; ~Jianibieke_Adalibieke1; ~Qianwei_Han1; ~Yuzhe_Qin1; ~Li_Yi2,"{'value': ['Dexterous Manipulation', 'Neural Tracking Control', 'Homotopy Optimization']}","{'value': ""We address the challenge of developing a generalizable neural tracking controller for dexterous manipulation from human references. This controller aims to manage a dexterous robot hand to manipulate diverse objects for various purposes defined by kinematic human-object interactions. Developing such a controller is complicated by the intricate contact dynamics of dexterous manipulation and the need for adaptivity, generalizability, and robustness. Current reinforcement learning and trajectory optimization methods often fall short due to their dependence on task-specific rewards or precise system models. We introduce an approach that curates large-scale successful robot tracking demonstrations, comprising pairs of human references and robot actions, to train a neural controller. Utilizing a data flywheel, we iteratively enhance the controller's performance, as well as the number and quality of successful tracking demonstrations. We exploit available tracking demonstrations and carefully integrate reinforcement learning and imitation learning to boost the controller's performance in dynamic environments. At the same time, to obtain high-quality tracking demonstrations, we individually optimize per-trajectory tracking by leveraging the learned tracking controller in a homotopy optimization method. The homotopy optimization, mimicking chain-of-thought, aids in solving challenging trajectory tracking problems to increase demonstration diversity. We showcase our success by training a generalizable neural controller and evaluating it in both simulation and real world. Our method achieves over a 10% improvement in success rates compared to leading baselines. The project website with animated results is available at  [DexTrack](https://meowuu7.github.io/DexTrack/).""}",https://openreview.net{'value': '/pdf/01470325ec04e8892dfee49b08d62be10f92f3c2.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=aZ1gNJu8wO,{'value': 'A Geometric Framework for Understanding Memorization in Generative Models'},Brendan Leigh Ross; Hamidreza Kamkari; Tongzi Wu; Rasa Hosseinzadeh; Zhaoyan Liu; George Stein; Jesse C. Cresswell; Gabriel Loaiza-Ganem,~Brendan_Leigh_Ross1; ~Hamidreza_Kamkari1; ~Tongzi_Wu1; ~Rasa_Hosseinzadeh2; ~Zhaoyan_Liu1; ~George_Stein1; ~Jesse_C._Cresswell1; ~Gabriel_Loaiza-Ganem1,"{'value': ['deep generative modelling', 'generative models', 'memorization', 'data copying', 'privacy', 'diffusion', 'diffusion models', 'GANs', 'manifold hypothesis', 'local intrinsic dimension', 'lid', 'lid estimation', 'geometry']}","{'value': 'As deep generative models have progressed, recent work has shown them to be capable of memorizing and reproducing training datapoints when deployed. These findings call into question the usability of generative models, especially in light of the legal and privacy risks brought about by memorization. To better understand this phenomenon, we propose the *manifold memorization hypothesis* (MMH), a geometric framework which leverages the manifold hypothesis into a clear language in which to reason about memorization. We propose to analyze memorization in terms of the relationship between the dimensionalities of $(i)$ the ground truth data manifold and $(ii)$ the manifold learned by the model. This framework provides a formal standard for ""how memorized"" a datapoint is and systematically categorizes memorized data into two types: memorization driven by overfitting and memorization driven by the underlying data distribution. By analyzing prior work in the context of the MMH, we explain and unify assorted observations in the literature. We empirically validate the MMH using synthetic data and image datasets up to the scale of Stable Diffusion, developing new tools for detecting and preventing generation of memorized samples in the process.'}",https://openreview.net{'value': '/pdf/bd648077f2597fde8e0f0f34a741fab086b710df.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=aXuWowhIYt,{'value': 'Standardizing Structural Causal Models'},Weronika Ormaniec; Scott Sussex; Lars Lorch; Bernhard Schölkopf; Andreas Krause,~Weronika_Ormaniec1; ~Scott_Sussex1; ~Lars_Lorch1; ~Bernhard_Schölkopf1; ~Andreas_Krause1,"{'value': ['Causality', 'Causal Discovery', 'Structural Causal Model', 'Standardized Structural Causal Model', 'Variance Artifact', 'Covariance Artifact', 'Simulation', 'Benchmark']}","{'value': 'Synthetic datasets generated by structural causal models (SCMs) are commonly used for benchmarking causal structure learning algorithms. However, the variances and pairwise correlations in SCM data tend to increase along the causal ordering. Several popular algorithms exploit these artifacts, possibly leading to conclusions that do not generalize to real-world settings. Existing metrics like $\\operatorname{Var}$-sortability and $\\operatorname{R^2}$-sortability quantify these patterns, but they do not provide tools to remedy them. To address this, we propose internally-standardized structural causal models (iSCMs), a modification of SCMs that introduces a standardization operation at each variable during the generative process. By construction, iSCMs are not $\\operatorname{Var}$-sortable. We also find empirical evidence that they are mostly not $\\operatorname{R^2}$-sortable for commonly-used graph families. Moreover, contrary to the post-hoc standardization of data generated by standard SCMs, we prove that linear iSCMs are less identifiable from prior knowledge on the weights and do not collapse to deterministic relationships in large systems, which may make iSCMs a useful model in causal inference beyond the benchmarking problem studied here. Our code is publicly available at: https://github.com/werkaaa/iscm.'}",https://openreview.net{'value': '/pdf/48f4a8fa885d3a93e377ebf75b1b30da3de86271.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=Zy2XgaGpDw,{'value': 'TLDR: Token-Level Detective Reward Model for Large Vision Language Models'},Deqing Fu; Tong Xiao; Rui Wang; Wang Zhu; Pengchuan Zhang; Guan Pang; Robin Jia; Lawrence Chen,~Deqing_Fu1; ~Tong_Xiao2; ~Rui_Wang13; ~Wang_Zhu1; ~Pengchuan_Zhang1; ~Guan_Pang2; ~Robin_Jia1; ~Lawrence_Chen1,"{'value': ['vision language model', 'multimodal', 'reward model']}","{'value': ""Although reward models have been successful in improving multimodal large language models, the reward models themselves remain brutal and contain minimal information. Notably, existing reward models only mimic human annotations by assigning only one feedback to any text, no matter how long the text is. In the realm of multimodal language models, where models are required to process both images and texts, a naive reward model may learn implicit biases toward texts and become less grounded in images. In this paper, we propose a **T**oken-**L**evel **D**etective **R**eward Model (**TLDR**) to provide fine-grained annotations to each text token. We first introduce a perturbation-based method to generate synthetic hard negatives and their token-level labels to train TLDR models. Then we show the rich usefulness of TLDR models both in assisting off-the-shelf models to self-correct their generations, and in serving as a hallucination evaluation tool. We show that TLDR automatically trains a token-level likelihood optimization, and can improve the base model's performance significantly. Finally, we show that TLDR models can significantly speed up human annotation by 3 times to acquire a broader range of high-quality vision language data.""}",https://openreview.net{'value': '/pdf/06fbc51bce2e92ebcd1b2e3bbd9d287e3bdc8b2c.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=ZsP3YbYeE9,{'value': 'Enhancing Language Model Agents using Diversity of Thoughts'},Vijay Lingam; Behrooz Omidvar Tehrani; Sujay Sanghavi; Gaurav Gupta; Sayan Ghosh; Linbo Liu; Jun Huan; Anoop Deoras,~Vijay_Lingam1; ~Behrooz_Omidvar_Tehrani1; ~Sujay_Sanghavi2; ~Gaurav_Gupta2; ~Sayan_Ghosh2; ~Linbo_Liu1; ~Jun_Huan3; ~Anoop_Deoras1,"{'value': ['Large Language Models', 'Reasoning', 'Programming']}","{'value': 'A popular approach to building agents using Language Models (LMs) involves iteratively prompting the LM, reflecting on its outputs, and updating the input prompts until the desired task is achieved. However, our analysis reveals two key shortcomings in the existing methods: $(i)$ limited exploration of the decision space due to repetitive reflections, which result in redundant inputs, and $(ii)$ an inability to leverage insights from previously solved tasks. To address these issues, we introduce DoT (Diversity of Thoughts), a novel framework that a) explicitly reduces redundant reflections to enhance decision-space exploration, and b) incorporates a task-agnostic memory component to enable knowledge retrieval from previously solved tasks—unlike current approaches that operate in isolation for each task. Through extensive experiments on a suite of programming benchmarks (HumanEval, MBPP, and LeetCodeHardGym) using a variety of LMs, DoT demonstrates up to a $\\textbf{10}$% improvement in Pass@1 while maintaining cost-effectiveness. Furthermore, DoT is modular by design. For instance, when the diverse reflection module of DoT is integrated with existing methods like Tree of Thoughts (ToT), we observe a significant $\\textbf{13}$% improvement on Game of 24 (one of the main benchmarks of ToT), highlighting the broad applicability and impact of our contributions across various reasoning tasks.'}",https://openreview.net{'value': '/pdf/1c07a548b9ae0ce549c97e386760ed7ba68aa26c.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=Zjv38dg1Hb,{'value': 'Generalized Consistency Trajectory Models for Image Manipulation'},Beomsu Kim; Jaemin Kim; Jeongsol Kim; Jong Chul Ye,~Beomsu_Kim1; ~Jaemin_Kim2; ~Jeongsol_Kim1; ~Jong_Chul_Ye1,"{'value': ['Consistency Models', 'Image Manipulation']}","{'value': 'Diffusion-based generative models excel in unconditional generation, as well as on applied tasks such as image editing and restoration. The success of diffusion models lies in the iterative nature of diffusion: diffusion breaks down the complex process of mapping noise to data into a sequence of simple denoising tasks. Moreover, we are able to exert fine-grained control over the generation process by injecting guidance terms into each denoising step. However, the iterative process is also computationally intensive, often taking from tens up to thousands of function evaluations. Although consistency trajectory models (CTMs) enable traversal between any time points along the probability flow ODE (PFODE) and score inference with a single function evaluation, CTMs only allow translation from Gaussian noise to data. Thus, this work aims to unlock the full potential of CTMs by proposing generalized CTMs (GCTMs), which translate between arbitrary distributions via ODEs. We discuss the design space of GCTMs and demonstrate their efficacy in various image manipulation tasks such as image-to-image translation, restoration, and editing. Code is available at https://github.com/1202kbs/GCTM.'}",https://openreview.net{'value': '/pdf/9f9f4962fee65c3470f9167815ed43cb0387418c.pdf'},{'title_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=ZW4MRZrmSA,{'value': 'A Policy-Gradient Approach to Solving Imperfect-Information Games with Best-Iterate Convergence'},Mingyang Liu; Gabriele Farina; Asuman E. Ozdaglar,~Mingyang_Liu1; ~Gabriele_Farina1; ~Asuman_E._Ozdaglar1,"{'value': ['Game Theory', 'Reinforcement Learning']}","{'value': 'Policy gradient methods have become a staple of any single-agent reinforcement learning toolbox, due to their combination of desirable properties: iterate convergence, efficient use of stochastic trajectory feedback, and theoretically-sound avoidance of importance sampling corrections. In multi-agent imperfect-information settings (extensive-form games), however, it is still unknown whether the same desiderata can be guaranteed while retaining theoretical guarantees. Instead, sound methods for extensive-form games rely on approximating \\emph{counterfactual} values (as opposed to Q values), which are incompatible with policy gradient methodologies. In this paper, we investigate whether policy gradient can be safely used in two-player zero-sum imperfect-information extensive-form games (EFGs). We establish positive results, showing for the first time that a policy gradient method leads to provable best-iterate convergence to a regularized Nash equilibrium in self-play.'}",https://openreview.net{'value': '/pdf/39e30a8e2c33326b8186c09f579b382606788813.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=ZNnmcddaB3,{'value': 'Robust System Identification: Finite-sample Guarantees and Connection to Regularization'},Hyuk Park; Grani A. Hanasusanto; Yingying Li,~Hyuk_Park1; ~Grani_A._Hanasusanto1; ~Yingying_Li3,"{'value': ['dynamical system', 'time series', 'system identification', 'optimization']}","{'value': ""We consider the problem of learning nonlinear dynamical systems from a single sample trajectory. While the least squares estimate (LSE) is commonly used for this task, it suffers from poor identification errors when the sample size is small or the model fails to capture the system's true dynamics. To overcome these limitations, we propose a robust LSE framework, which incorporates robust optimization techniques, and prove that it is equivalent to regularizing LSE using general Schatten $p$-norms. We provide non-asymptotic performance guarantees for linear systems, achieving an error rate of $\\widetilde{\\mathcal{O}}(1/\\sqrt{T})$, and show that it avoids the curse of dimensionality, unlike state-of-the-art Wasserstein robust optimization models. Empirical results demonstrate substantial improvements in real-world system identification and online control tasks, outperforming existing methods.""}",https://openreview.net{'value': '/pdf/31d036c32c214995d6aaf212c5f88c5cb6c1b096.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=ZJo6Radbqq,{'value': 'Needle In A Video Haystack: A Scalable  Synthetic Evaluator for Video MLLMs'},Zijia Zhao; Haoyu Lu; Yuqi Huo; Yifan Du; Tongtian Yue; Longteng Guo; Bingning Wang; weipeng chen; Jing Liu,~Zijia_Zhao1; ~Haoyu_Lu1; ~Yuqi_Huo1; ~Yifan_Du1; ~Tongtian_Yue1; ~Longteng_Guo1; ~Bingning_Wang3; ~weipeng_chen2; ~Jing_Liu1,{'value': ['video MLLM']},"{'value': ""Video understanding is a crucial next step for multimodal large language models (MLLMs).\nVarious benchmarks are introduced for better evaluating the MLLMs.\nNevertheless, current video benchmarks are still inefficient for evaluating video models during iterative development due to the high cost of constructing datasets and the difficulty in isolating specific skills.\nIn this paper, we propose VideoNIAH (Video Needle in A Haystack), a benchmark construction framework through synthetic video generation. \nVideoNIAH decouples video content from their query-responses by inserting unrelated visual 'needles' into original videos. \nThe framework automates the generation of query-response pairs using predefined rules, minimizing manual labor.  The queries focus on specific aspects of video understanding, enabling more skill-specific evaluations. The separation between video content and the queries also allow for increased video variety and evaluations across different lengths.\nUtilizing VideoNIAH, we compile a video benchmark, VNBench, which includes tasks such as retrieval, ordering, and counting to evaluate three key aspects of video understanding: temporal perception, chronological ordering, and spatio-temporal coherence. We conduct a comprehensive evaluation of both proprietary and open-source models, uncovering significant differences in their video understanding capabilities across various tasks. Additionally, we perform an in-depth analysis of the test results and model configurations. Based on these findings, we provide some advice for improving video MLLM training, offering valuable insights to guide future research and model development.""}",https://openreview.net{'value': '/pdf/875d019fb5070873ce0564e8a175d24d3df4dc3f.pdf'},{'title_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=ZGqd0cbBvm,{'value': 'InsightBench: Evaluating Business Analytics Agents Through Multi-Step Insight Generation'},Gaurav Sahu; Abhay Puri; Juan A. Rodriguez; Amirhossein Abaskohi; Mohammad Chegini; Alexandre Drouin; Perouz Taslakian; Valentina Zantedeschi; Alexandre Lacoste; David Vazquez; Nicolas Chapados; Christopher Pal; Sai Rajeswar; Issam H. Laradji,~Gaurav_Sahu2; ~Abhay_Puri1; ~Juan_A._Rodriguez1; ~Amirhossein_Abaskohi1; ~Mohammad_Chegini1; ~Alexandre_Drouin2; ~Perouz_Taslakian1; ~Valentina_Zantedeschi2; ~Alexandre_Lacoste1; ~David_Vazquez1; ~Nicolas_Chapados1; ~Christopher_Pal1; ~Sai_Rajeswar2; ~Issam_H._Laradji1,"{'value': ['Automated Data Analysis', 'Data Analytics Benchmark', 'LLM agents', 'Code Generation', 'LLM Evaluation']}","{'value': 'Data analytics is essential for extracting valuable insights from data that can assist organizations in making effective decisions. We introduce InsightBench, a benchmark dataset with three key features. First, it consists of 100 datasets representing diverse business use cases such as finance and incident management, each accompanied by a carefully curated set of insights planted in the datasets. Second, unlike existing benchmarks focusing on answering single queries, InsightBench evaluates agents based on their ability to perform end-to-end data analytics, including formulating questions, interpreting answers, and generating a summary of insights and actionable steps. Third, we conducted comprehensive quality assurance to ensure that each dataset in the benchmark had clear goals and included relevant and meaningful questions and analysis. Furthermore, we implement a two-way evaluation mechanism using LLaMA-3 as an effective, open-source evaluator to assess agents’ ability to extract insights. We also propose AgentPoirot, our baseline data analysis agent capable of performing end-to-end data analytics. Our evaluation on InsightBench shows that AgentPoirot outperforms existing approaches (such as Pandas Agent) that focus on resolving single queries. We also compare the performance of open- and closed-source LLMs and various evaluation strategies. Overall, this benchmark serves as a testbed to motivate further development in comprehensive automated data analytics and can be accessed here: https://github.com/ServiceNow/insight-bench.'}",https://openreview.net{'value': '/pdf/be19956312bdbfe85a7b95921ff9bf089650fc68.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=ZFxpclrCCf,{'value': 'Glad: A Streaming Scene Generator for Autonomous Driving'},Bin Xie; Yingfei Liu; Tiancai Wang; Jiale Cao; Xiangyu Zhang,~Bin_Xie2; ~Yingfei_Liu1; ~Tiancai_Wang1; ~Jiale_Cao2; ~Xiangyu_Zhang1,{'value': ['Video Generation; Autonomous Driving']},"{'value': 'The generation and simulation of diverse real-world scenes have significant application value in the field of autonomous driving, especially for the corner cases. Recently, researchers have explored employing neural radiance fields or diffusion models to generate novel views or synthetic data under driving scenes. However, these approaches suffer from unseen scenes or restricted video length, thus lacking sufficient adaptability for data generation and simulation. To address these issues, we propose a simple yet effective framework, named Glad, to generate video data in a frame-by-frame style. To ensure the temporal consistency of synthetic video, we introduce a latent variable propagation module, which views the latent features of previous frame as noise prior and injects it into the latent features of current frame. In addition, we design a streaming data sampler to orderly sample the original image in a video clip at continuous iterations. Given the reference frame, our Glad can be viewed as a streaming simulator by generating the videos for specific scenes. Extensive experiments are performed on the widely-used nuScenes dataset. Experimental results demonstrate that our proposed Glad achieves promising performance, serving as a strong baseline for online video generation. We will release the source code and models publicly.'}",https://openreview.net{'value': '/pdf/e0e405397e20720c9b0df6d2f19e268a53ff3def.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=Z4evOUYrk7,{'value': 'CameraCtrl: Enabling Camera Control for Video Diffusion Models'},Hao He; Yinghao Xu; Yuwei Guo; Gordon Wetzstein; Bo Dai; Hongsheng Li; Ceyuan Yang,~Hao_He7; ~Yinghao_Xu1; ~Yuwei_Guo1; ~Gordon_Wetzstein3; ~Bo_Dai2; ~Hongsheng_Li3; ~Ceyuan_Yang2,{'value': ['camera viewpoints control in Video Generation']},"{'value': 'Controllability plays a crucial role in video generation, as it allows users to create and edit content more precisely. Existing models, however, lack control of camera pose that serves as a cinematic language to express deeper narrative nuances. To alleviate this issue, we introduce \\method, enabling accurate camera pose control for video diffusion models. Our approach explores effective camera trajectory parameterization along with a plug-and-play camera pose control module that is trained on top of a video diffusion model, leaving other modules of the base model untouched. Moreover, a comprehensive study on the effect of various training datasets is conducted, suggesting that videos with diverse camera distributions and similar appearance to the base model indeed enhance controllability and generalization. Experimental results demonstrate the effectiveness of \\method in achieving precise camera control with different video generation models, marking a step forward in the pursuit of dynamic and customized video storytelling from textual and camera pose inputs.'}",https://openreview.net{'value': '/pdf/681b7a0b97770cc7f4f6d567ad538ce599d0a8a6.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=YvKJGYL4j7,{'value': 'Toward Efficient Multi-Agent Exploration With Trajectory Entropy Maximization'},Tianxu Li; Kun Zhu,~Tianxu_Li1; ~Kun_Zhu1,"{'value': ['Multi-Agent Reinforcement Learning', 'Exploration', 'Cooperation', 'Trajectory Entropy Maximization']}","{'value': ""Recent works have increasingly focused on learning decentralized policies for agents as a solution to the scalability challenges in Multi-Agent Reinforcement Learning (MARL), where agents typically share the parameters of a policy network to make action decisions. However, this parameter sharing can impede efficient exploration, as it may lead to similar behaviors among agents. Different from previous mutual information-based methods that promote multi-agent diversity, we introduce a novel multi-agent exploration method called Trajectory Entropy Exploration (TEE). Our method employs a particle-based entropy estimator to maximize the entropy of different agents' trajectories in a contrastive trajectory representation space, resulting in diverse trajectories and efficient exploration. This entropy estimator avoids challenging density modeling and scales effectively in high-dimensional multi-agent settings. We integrate our method with MARL algorithms by deploying an intrinsic reward for each agent to encourage entropy maximization. To validate the effectiveness of our method, we test our method in challenging multi-agent tasks from several MARL benchmarks. The results demonstrate that our method consistently outperforms existing state-of-the-art methods.""}",https://openreview.net{'value': '/pdf/dd89f301bd928d0b44b44bf9d4d9a194fe80f1e4.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=YhfrKB3Ah7,{'value': 'PABBO: Preferential Amortized Black-Box Optimization'},Xinyu Zhang; Daolang Huang; Samuel Kaski; Julien Martinelli,~Xinyu_Zhang41; ~Daolang_Huang1; ~Samuel_Kaski1; ~Julien_Martinelli1,"{'value': ['Bayesian optimization', 'preference learning', 'amortized inference', 'neural processes']}","{'value': 'Preferential Bayesian Optimization (PBO) is a sample-efficient method to learn latent user utilities from preferential feedback over a pair of designs. It relies on a statistical surrogate model for the latent function, usually a Gaussian process, and an acquisition strategy to select the next candidate pair to get user feedback on. Due to the non-conjugacy of the associated likelihood, every PBO step requires a significant amount of computations with various approximate inference techniques. This computational overhead is incompatible with the way humans interact with computers, hindering the use of PBO in real-world cases. Building on the recent advances of amortized BO, we propose to circumvent this issue by fully amortizing PBO, meta-learning both the surrogate and the acquisition function. Our method comprises a novel transformer neural process architecture, trained using reinforcement learning and tailored auxiliary losses.\nOn a benchmark composed of synthetic and real-world datasets, our method is several orders of magnitude faster than the usual Gaussian process-based strategies and often outperforms them in accuracy.'}",https://openreview.net{'value': '/pdf/04e061a1004f115511ef7b510ca66c193e89a39d.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=YauQYh2k1g,{'value': 'Dissecting Adversarial Robustness of Multimodal LM Agents'},Chen Henry Wu; Rishi Rajesh Shah; Jing Yu Koh; Russ Salakhutdinov; Daniel Fried; Aditi Raghunathan,~Chen_Henry_Wu1; ~Rishi_Rajesh_Shah1; ~Jing_Yu_Koh2; ~Russ_Salakhutdinov1; ~Daniel_Fried1; ~Aditi_Raghunathan1,"{'value': ['LM agents', 'multimodal agents', 'safety', 'adversarial robustness']}","{'value': 'As language models (LMs) are used to build autonomous agents in real environments, ensuring their adversarial robustness becomes a critical challenge. Unlike chatbots, agents are compound systems with multiple components taking actions, which existing LMs safety evaluations do not adequately address. To bridge this gap, we manually create 200 targeted adversarial tasks and evaluation scripts in a realistic threat model on top of VisualWebArena, a real environment for web agents. To systematically examine the robustness of agents, we propose the Agent Robustness Evaluation (ARE) framework. ARE views the agent as a graph showing the flow of intermediate outputs between components and decomposes robustness as the flow of adversarial information on the graph. We find that we can successfully break latest agents that use black-box frontier LMs, including those that perform reflection and tree search. With imperceptible perturbations to a single image (less than 5% of total web page pixels), an attacker can hijack these agents to execute targeted adversarial goals with success rates up to 67%. We also use ARE to rigorously evaluate how the robustness changes as new components are added. We find that inference-time compute that typically improves benign performance can open up new vulnerabilities and harm robustness. An attacker can compromise the evaluator used by the reflexion agent and the value function of the tree search agent, which increases the attack success relatively by 15% and 20%. Our data and code for attacks, defenses, and evaluation are at https://github.com/ChenWu98/agent-attack'}",https://openreview.net{'value': '/pdf/548630d0bac8dce0df74f275d26ca8ee4e835ed8.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=YXRyYkb1im,{'value': 'COMBO: Compositional World Models for Embodied Multi-Agent Cooperation'},Hongxin Zhang; Zeyuan Wang; Qiushi Lyu; Zheyuan Zhang; Sunli Chen; Tianmin Shu; Behzad Dariush; Kwonjoon Lee; Yilun Du; Chuang Gan,~Hongxin_Zhang1; ~Zeyuan_Wang6; ~Qiushi_Lyu1; ~Zheyuan_Zhang4; ~Sunli_Chen1; ~Tianmin_Shu1; ~Behzad_Dariush2; ~Kwonjoon_Lee1; ~Yilun_Du1; ~Chuang_Gan1,{'value': ['Embodied AI; Multi-agent Planning; Compositional World Model']},"{'value': ""In this paper, we investigate the problem of embodied multi-agent cooperation, where decentralized agents must cooperate given only egocentric views of the world. To effectively plan in this setting, in contrast to learning world dynamics in a single-agent scenario, we must simulate world dynamics conditioned on an arbitrary number of agents' actions given only partial egocentric visual observations of the world. To address this issue of partial observability, we first train generative models to estimate the overall world state given partial egocentric observations. To enable accurate simulation of multiple sets of actions on this world state, we then propose to learn a compositional world model for multi-agent cooperation by factorizing the naturally composable joint actions of multiple agents and compositionally generating the video conditioned on the world state. By leveraging this compositional world model, in combination with Vision Language Models to infer the actions of other agents, we can use a tree search procedure to integrate these modules and facilitate online cooperative planning. We evaluate our methods on three challenging benchmarks with 2-4 agents. The results show our compositional world model is effective and the framework enables the embodied agents to cooperate efficiently with different agents across various tasks and an arbitrary number of agents, showing the promising future of our proposed methods. More videos can be found at https://umass-embodied-agi.github.io/COMBO""}",https://openreview.net{'value': '/pdf/54baa5d646fd9a8bbe3d264abfa7e975492da99d.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=YUYJsHOf3c,{'value': 'ReGenesis: LLMs can Grow into Reasoning Generalists via Self-Improvement'},XIANGYU PENG; Congying Xia; Xinyi Yang; Caiming Xiong; Chien-Sheng Wu; Chen Xing,~XIANGYU_PENG1; ~Congying_Xia1; ~Xinyi_Yang2; ~Caiming_Xiong1; ~Chien-Sheng_Wu1; ~Chen_Xing2,"{'value': ['LLM', 'reasoning', 'generalization', 'self-improvement']}","{'value': 'Post-training Large Language Models (LLMs) with explicit reasoning trajectories can enhance their reasoning abilities. However, acquiring such high-quality trajectory data typically demands meticulous supervision from humans or superior models, which can be either expensive or license-constrained. In this paper, we explore how far an LLM can improve its reasoning by self-synthesizing reasoning paths as training data without any additional supervision. Existing self-synthesizing methods, such as STaR, suffer from poor generalization to out-of-domain (OOD) reasoning tasks. We hypothesize it is due to that their self-synthesized reasoning paths are too task-specific, lacking general task-agnostic reasoning guidance. To address this, we propose **Reasoning Generalist via Self-Improvement (ReGenesis)**, a method to *self-synthesize reasoning paths as post-training data by progressing from abstract to concrete*. More specifically, ReGenesis self-synthesizes reasoning paths by converting general reasoning guidelines into task-specific ones, generating reasoning structures, and subsequently transforming these structures into reasoning paths, without the need for human-designed task-specific examples used in existing methods. We show that ReGenesis achieves superior performance on all in-domain and OOD settings tested compared to existing methods. For six OOD tasks specifically, while previous methods exhibited an average performance decrease of approximately 4.6% after post training, ReGenesis delivers around 6.1% performance improvement. We also conduct an in-depth analysis of our framework and show ReGenesis is effective across various language models and design choices.'}",https://openreview.net{'value': '/pdf/0f5acd1a57d199942a7ac8efc3dc19df441efaf2.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=Y8L5RB4GWb,{'value': 'Reconstruction-Guided Policy: Enhancing Decision-Making through Agent-Wise State Consistency'},Liang Qifan; Yixiang Shan; Haipeng Liu; Zhengbang Zhu; Ting Long; Weinan Zhang; Yuan Tian,~Liang_Qifan1; ~Yixiang_Shan1; ~Haipeng_Liu3; ~Zhengbang_Zhu1; ~Ting_Long1; ~Weinan_Zhang1; ~Yuan_Tian6,"{'value': ['multi-agent reinforcement learning', 'partial observability', 'cooperation', 'centralized training distributed execution', 'global state']}","{'value': 'An important challenge in multi-agent reinforcement learning is partial observability, where agents cannot access the global state of the environment during execution and can only receive observations within their field of view. To address this issue, previous works typically use the dimensional-wise state, which is obtained by applying MLP or dimensional-based attention on the global state, for decision-making during training and relying on a reconstructed dimensional-wise state during execution. However, dimensional-wise states tend to divert agent attention to specific features, neglecting potential dependencies between agents, making it difficult to make optimal decisions. Moreover, the inconsistency between the states used in training and execution further increases additional errors. To resolve these issues, we propose a method called Reconstruction-Guided Policy (RGP) to reconstruct the agent-wise state, which represents the information of inter-agent relationships, as input for decision-making during both training and execution. This not only preserves the potential dependencies between agents but also ensures consistency between the states used in training and execution. We conducted extensive experiments on both discrete and continuous action environments to evaluate RGP, and the results demonstrates its superior effectiveness. Our code is public in https://anonymous.4open.science/r/RGP-9F79'}",https://openreview.net{'value': '/pdf/93889fa7a9600b0947adac903f86072a53ee146f.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=Y8KK9kjgIK,{'value': 'SigDiffusions: Score-Based Diffusion Models for Time Series via Log-Signature Embeddings'},Barbora Barancikova; Zhuoyue Huang; Cristopher Salvi,~Barbora_Barancikova1; ~Zhuoyue_Huang1; ~Cristopher_Salvi1,"{'value': ['diffusion models', 'path signatures', 'time series']}","{'value': 'Score-based diffusion models have recently emerged as state-of-the-art generative\nmodels for a variety of data modalities. Nonetheless, it remains unclear how to\nadapt these models to generate long multivariate time series. Viewing a time\nseries as the discretisation of an underlying continuous process, we introduce\nSigDiffusion, a novel diffusion model operating on log-signature embeddings\nof the data. The forward and backward processes gradually perturb and denoise\nlog-signatures while preserving their algebraic structure. To recover a signal from\nits log-signature, we provide new closed-form inversion formulae expressing the\ncoefficients obtained by expanding the signal in a given basis (e.g. Fourier or\northogonal polynomials) as explicit polynomial functions of the log-signature.\nFinally, we show that combining SigDiffusions with these inversion formulae\nresults in high-quality long time series generation, competitive with the current\nstate-of-the-art on various datasets of synthetic and real-world examples.'}",https://openreview.net{'value': '/pdf/ca7f04ad77a41817b6b31fef35e6fb4c90285030.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=XoulHHQGFi,{'value': 'IntersectionZoo: Eco-driving for Benchmarking Multi-Agent Contextual Reinforcement Learning'},Vindula Jayawardana; Baptiste Freydt; Ao Qu; Cameron Hickert; Zhongxia Yan; Cathy Wu,~Vindula_Jayawardana1; ~Baptiste_Freydt1; ~Ao_Qu1; ~Cameron_Hickert1; ~Zhongxia_Yan1; ~Cathy_Wu1,"{'value': ['reinforcement learning', 'generalization', 'benchmarking', 'eco-driving']}","{'value': 'Despite the popularity of multi-agent reinforcement learning (RL) in simulated and two-player applications, its success in messy real-world applications has been limited. A key challenge lies in its generalizability across problem variations, a common necessity for many real-world problems. Contextual reinforcement learning (CRL) formalizes learning policies that generalize across problem variations. However, the lack of standardized benchmarks for multi-agent CRL has hindered progress in the field. Such benchmarks are desired to be based on real-world applications to naturally capture the many open challenges of real-world problems that affect generalization. To bridge this gap, we propose IntersectionZoo, a comprehensive benchmark suite for multi-agent CRL through the real-world application of cooperative eco-driving in urban road networks. The task of cooperative eco-driving is to control a fleet of vehicles to reduce fleet-level vehicular emissions. By grounding IntersectionZoo in a real-world application, we naturally capture real-world problem characteristics, such as partial observability and multiple competing objectives. IntersectionZoo is built on data-informed simulations of 16,334 signalized intersections derived from 10 major US cities, modeled in an open-source industry-grade microscopic traffic simulator. By modeling factors affecting vehicular exhaust emissions (e.g., temperature, road conditions, travel demand), IntersectionZoo provides one million data-driven traffic scenarios. Using these traffic scenarios, we benchmark popular multi-agent RL and human-like driving algorithms and demonstrate that the popular multi-agent RL algorithms struggle to generalize in CRL settings.'}",https://openreview.net{'value': '/pdf/a5755be074036a2b8b2c406d877735d28896ba68.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=Xmh5gdMfRJ,{'value': 'TSC-Net: Prediction of Pedestrian Trajectories by Trajectory-Scene-Cell Classification'},BO HU; Tat-Jen Cham,~BO_HU12; ~Tat-Jen_Cham1,"{'value': ['Trajectory-Scene-Cell', 'Trajectory Prediction', 'Attention']}","{'value': 'To predict future trajectories of pedestrians, scene is as important as the history trajectory since i) scene reflects the position of possible goals of the pedestrian ii) trajectories are affected by the semantic information of the scene. It requires the model to capture scene information and learn the relation between scenes and trajectories. However, existing methods either apply Convolutional Neural Networks (CNNs) to summarize the scene to a feature vector, which raises the feature misalignment issue, or convert trajectory to heatmaps to align with the scene map, which ignores the interactions among different pedestrians. In this work, we introduce the trajectory-scene-cell feature to represent both trajectories and scenes in one feature space. By decoupling the trajectory in temporal domain and the scene in spatial domain, trajectory feature and scene feature are re-organized in different types of cell feature, which well aligns trajectory and scene, and allows the framework to model both human-human and human-scene interactions. Moreover, the Trajectory-Scene-Cell Network (TSC-Net) with new trajectory prediction manner is proposed, where both goal and intermediate positions of the trajectory are predict by cell classification and offset regression. Comparative experiments show that TSC-Net achieves the SOTA performance on several datasets with most of the metrics. Especially for the goal estimation, TSC-Net is demonstrated better on predicting goals for trajectories with irregular speed.'}",https://openreview.net{'value': '/pdf/1a03072108b130f11cfc1287567fbf1bbe0892f7.pdf'},{'title_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=Xj66fkrlTk,{'value': 'Optimizing Backward Policies in GFlowNets via Trajectory Likelihood Maximization'},Timofei Gritsaev; Nikita Morozov; Sergey Samsonov; Daniil Tiapkin,~Timofei_Gritsaev1; ~Nikita_Morozov1; ~Sergey_Samsonov1; ~Daniil_Tiapkin1,"{'value': ['generative flow networks', 'gflownets', 'reinforcement learning', 'sampling', 'generative models']}","{'value': 'Generative Flow Networks (GFlowNets) are a family of generative models that learn to sample objects with probabilities proportional to a given reward function. The key concept behind GFlowNets is the use of two stochastic policies: a forward policy, which incrementally constructs compositional objects, and a backward policy, which sequentially deconstructs them. Recent results show a close relationship between GFlowNet training and entropy-regularized reinforcement learning (RL) problems with a particular reward design. However, this connection applies only in the setting of a fixed backward policy, which might be a significant limitation. As a remedy to this problem, we introduce a simple backward policy optimization algorithm that involves direct maximization of the value function in an entropy-regularized Markov Decision Process (MDP) over intermediate rewards. We provide an extensive experimental evaluation of the proposed approach across various benchmarks in combination with both RL and GFlowNet algorithms and demonstrate its faster convergence and mode discovery in complex environments.'}",https://openreview.net{'value': '/pdf/b0e339482327cbaf4e100e1576962cdb7c4be7b4.pdf'},{'title_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=XgH1wfHSX8,{'value': 'Competition Dynamics Shape Algorithmic Phases of In-Context Learning'},Core Francisco Park; Ekdeep Singh Lubana; Hidenori Tanaka,~Core_Francisco_Park1; ~Ekdeep_Singh_Lubana1; ~Hidenori_Tanaka1,"{'value': ['In-Context Learning', 'Circuit Competition', 'Markov Chains', 'Training Dynamics', 'Generalization']}","{'value': 'In-Context Learning (ICL) has significantly expanded the general-purpose nature of large language models, allowing them to adapt to novel tasks using merely the inputted context. This has motivated a series of papers that analyze tractable synthetic domains and postulate precise mechanisms that may underlie ICL. However, the use of relatively distinct setups that often lack a sequence modeling nature to them makes it unclear how general the reported insights from such studies are. Motivated by this, we propose a synthetic sequence modeling task that involves learning to simulate a finite mixture of Markov chains. As we show, models trained on this task reproduce most well-known results on ICL, hence offering a unified setting for studying the concept. Building on this setup, we demonstrate we can explain a model’s behavior by decomposing it into four broad algorithms that combine a fuzzy retrieval vs. inference approach with either unigram or bigram statistics of the context. These algorithms engage in a competitive dynamics to dominate model behavior, with the precise experimental conditions dictating which algorithm ends up superseding others: e.g., we find merely varying context size or amount of training yields (at times sharp) transitions between which algorithm dictates the model behavior, revealing a mechanism that explains the transient nature of ICL. In this sense, we argue ICL is best thought of as a mixture of different algorithms, each with its own peculiarities, instead of a monolithic capability. This also implies that making general claims about ICL that hold universally across all settings may be infeasible.'}",https://openreview.net{'value': '/pdf/7b36616ba9974b20a298d44d2a315d9c5918e6cb.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=XRtyVELwr6,{'value': 'Contrastive Learning from Synthetic Audio Doppelgängers'},Manuel Cherep; Nikhil Singh,~Manuel_Cherep1; ~Nikhil_Singh2,"{'value': ['synthetic data', 'audio', 'contrastive learning', 'representation learning']}","{'value': 'Learning robust audio representations currently demands extensive datasets of real-world sound recordings. By applying artificial transformations to these recordings, models can learn to recognize similarities despite subtle variations through techniques like contrastive learning. However, these transformations are only approximations of the true diversity found in real-world sounds, which are generated by complex interactions of physical processes, from vocal cord vibrations to the resonance of musical instruments. We propose a solution to both the data scale and transformation limitations, leveraging synthetic audio. By randomly perturbing the parameters of a sound synthesizer, we generate audio doppelgängers—synthetic positive pairs with causally manipulated variations in timbre, pitch, and temporal envelopes. These variations, difficult to achieve through augmentations of existing audio, provide a rich source of contrastive information. Despite the shift to randomly generated synthetic data, our method produces strong representations, outperforming real data on several standard audio classification tasks. Notably, our approach is lightweight, requires no data storage, and has only a single hyperparameter, which we extensively analyze. We offer this method as a complement to existing strategies for contrastive learning in audio, using synthesized sounds to reduce the data burden on practitioners.'}",https://openreview.net{'value': '/pdf/98cb3265f238b6c3c789e82df6118a1b68284cf3.pdf'},{'title_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=XMOaOigOQo,{'value': 'ContraDiff: Planning Towards High Return States via Contrastive Learning'},Yixiang Shan; Zhengbang Zhu; Ting Long; Liang Qifan; Yi Chang; Weinan Zhang; Liang Yin,~Yixiang_Shan1; ~Zhengbang_Zhu1; ~Ting_Long1; ~Liang_Qifan1; ~Yi_Chang4; ~Weinan_Zhang1; ~Liang_Yin2,"{'value': ['Offline Reinforcement Learning', 'Decision Making', 'Diffusion Models', 'Machine Learning']}","{'value': ""The performance of offline reinforcement learning (RL) is sensitive to the proportion of high-return trajectories in the offline dataset. However, in many simulation environments and real-world scenarios, there are large ratios of low-return trajectories rather than high-return trajectories, which makes learning an efficient policy challenging. In this paper, we propose a method called Contrastive Diffuser (ContraDiff) to make full use of low-return trajectories and improve the performance of offline RL algorithms. Specifically, ContraDiff groups the states of trajectories in the offline dataset into high-return states and low-return states and treats them as positive and negative samples correspondingly. Then, it designs a contrastive mechanism to pull the planned trajectory of an agent toward high-return states and push them away from low-return states. Through the contrast mechanism, trajectories with low returns can serve as negative examples for policy learning, guiding the agent to avoid areas associated with low returns and achieve better performance. Through the contrast mechanism, trajectories with low returns provide a ``counteracting force'' guides the agent to avoid areas associated with low returns and achieve better performance.\nExperiments on 27 sub-optimal datasets demonstrate the effectiveness of our proposed method. Our code is publicly available at https://github.com/Looomo/contradiff.""}",https://openreview.net{'value': '/pdf/467bd6f1fc750f52777613a067d0c91bd852574b.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=XHTirKsQV6,{'value': 'ProtoSnap: Prototype Alignment For Cuneiform Signs'},Rachel Mikulinsky; Morris Alper; Shai Gordin; Enrique Jiménez; Yoram Cohen; Hadar Averbuch-Elor,~Rachel_Mikulinsky1; ~Morris_Alper1; ~Shai_Gordin1; ~Enrique_Jiménez1; ~Yoram_Cohen2; ~Hadar_Averbuch-Elor2,"{'value': ['Machine learning for social sciences', 'Ancient character recognition', 'generative models']}","{'value': 'The cuneiform writing system served as the medium for transmitting knowledge\nin the ancient Near East for a period of over three thousand years. Cuneiform\nsigns have a complex internal structure which is the subject of expert paleographic\nanalysis, as variations in sign shapes bear witness to historical developments and\ntransmission of writing and culture over time. However, prior automated techniques\nmostly treat sign types as categorical and do not explicitly model their highly varied\ninternal configurations. In this work, we present an unsupervised approach for\nrecovering the fine-grained internal configuration of cuneiform signs by leveraging\npowerful generative models and the appearance and structure of prototype font\nimages as priors. Our approach, ProtoSnap, enforces structural consistency on\nmatches found with deep image features to estimate the diverse configurations\nof cuneiform characters, snapping a skeleton-based template to photographed\ncuneiform signs. We provide a new benchmark of expert annotations and evaluate\nour method on this task. Our evaluation shows that our approach succeeds in\naligning prototype skeletons to a wide variety of cuneiform signs. Moreover, we\nshow that conditioning on structures produced by our method allows for generating\nsynthetic data with correct structural configurations, significantly boosting the\nperformance of cuneiform sign recognition beyond existing techniques, in particular\nover rare signs. Our code, data, and trained models are available at the project page:\nhttps://tau-vailab.github.io/ProtoSnap/'}",https://openreview.net{'value': '/pdf/04b8a3ab120ccf71beef6d56212341664e56758b.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=XAN8G0rvoB,{'value': 'A Statistical Approach for Controlled Training Data Detection'},Zirui Hu; Yingjie Wang; Zheng Zhang; Hong Chen; Dacheng Tao,~Zirui_Hu1; ~Yingjie_Wang1; ~Zheng_Zhang20; ~Hong_Chen1; ~Dacheng_Tao1,"{'value': ['Large language models', 'Training data detection', 'Knockoffs']}","{'value': ""Detecting training data for large language models (LLMs) is receiving growing attention, especially in applications requiring high reliability. While numerous efforts have been made to address this issue, they typically focus on accuracy without ensuring controllable results.\nTo fill this gap, we propose **K**nockoff Inference-based **T**raining data **D**etector (KTD), a novel method that achieves rigorous false discovery rate (FDR) control in training data detection. Specifically, KTD generates synthetic knockoff samples that seamlessly replace original data points without compromising contextual integrity. A novel knockoff statistic, which incorporates multiple knockoff draws, is then calculated to ensure FDR control while maintaining high power. \nOur theoretical analysis demonstrates KTD's asymptotic optimality in terms of FDR control and power. Empirical experiments on real-world datasets such as WikiMIA, XSum and Real Time BBC News further validate KTD's superior performance compared to existing methods.""}",https://openreview.net{'value': '/pdf/25fbf881c9d986a971aebf375cb79f2b3193b1db.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=X0CxfByJog,{'value': 'Breaking Class Barriers: Efficient Dataset Distillation via Inter-Class Feature Compensator'},Xin Zhang; Jiawei Du; Ping Liu; Joey Tianyi Zhou,~Xin_Zhang29; ~Jiawei_Du1; ~Ping_Liu1; ~Joey_Tianyi_Zhou1,"{'value': ['Dataset distillation', 'inter-class feature compensator (INFER)']}","{'value': 'Dataset distillation has emerged as a technique aiming to condense informative features from large, natural datasets into a compact and synthetic form. While recent advancements have refined this technique, its performance is bottlenecked by the prevailing class-specific synthesis paradigm. Under this paradigm, synthetic data is optimized exclusively for a pre-assigned one-hot label, creating an implicit class barrier in feature condensation. This leads to inefficient utilization of the distillation budget and oversight of inter-class feature distributions, which ultimately limits the effectiveness and efficiency, as demonstrated in our analysis.\nTo overcome these constraints, this paper presents the Inter-class Feature Compensator (INFER), an innovative distillation approach that transcends the class-specific data-label framework widely utilized in current dataset distillation methods. Specifically, INFER leverages a Universal Feature Compensator (UFC) to enhance feature integration across classes, enabling the generation of multiple additional synthetic instances from a single UFC input. This significantly improves the efficiency of the distillation budget.\nMoreover, INFER enriches inter-class interactions during the distillation, thereby enhancing the effectiveness and generalizability of the distilled data. By allowing for the linear interpolation of labels similar to those in the original dataset, INFER meticulously optimizes the synthetic data and dramatically reduces the size of soft labels in the synthetic dataset to almost zero, establishing a new benchmark for efficiency and effectiveness in dataset distillation. In practice, INFER demonstrates state-of-the-art performance across benchmark datasets. For instance, in the $\\texttt{ipc} = 50$ setting on ImageNet-1k with the same compression level, it outperforms SRe2L by 34.5\\% using ResNet18. Codes are available at https://github.com/zhangxin-xd/UFC.'}",https://openreview.net{'value': '/pdf/e42b697ce8692ed7226cfb12099c862744933ddf.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=WzCEiBILHu,{'value': 'Topological Schrödinger Bridge Matching'},Maosheng Yang,~Maosheng_Yang1,"{'value': ['Schrödinger Bridge', 'Topological Signal Distribution Matching', 'Topological Stochastic Dynamics', 'Topological Generative Models']}","{'value': 'Given two boundary distributions, the \\emph{Schrödinger Bridge} (SB) problem seeks the “most likely” random evolution between them with respect to a reference process. It has revealed rich connections to recent machine learning methods for generative modeling and distribution matching. While these methods perform well in Euclidean domains, they are not directly applicable to topological domains such as graphs and simplicial complexes, which are crucial for data defined over network entities, such as node signals and edge flows. In this work, we propose the \\emph{Topological Schrödinger Bridge problem} ($\\mathcal{T}$SBP) for matching signal distributions on a topological domain. We set the reference process to follow some linear tractable \\emph{topology-aware} stochastic dynamics such as topological heat diffusion. For the case of Gaussian boundary distributions, we derive a \\emph{closed-form} topological SB ($\\mathcal{T}$SB) in terms of its time-marginal and stochastic differential. In the general case, leveraging the well-known result, we show that the optimal process follows the forward-backward topological dynamics governed by some unknowns. Building on these results, we develop $\\mathcal{T}$SB-based models for matching topological signals by parameterizing the unknowns in the optimal process as \\emph{(topological) neural networks} and learning them through \\emph{likelihood training}. We validate the theoretical results and demonstrate the practical applications of $\\mathcal{T}$SB-based models on both synthetic and real-world networks, emphasizing the role of topology. Additionally, we discuss the connections of $\\mathcal{T}$SB-based models to other emerging models, and outline future directions for topological signal matching.'}",https://openreview.net{'value': '/pdf/2cd33735864bd860bf7ddbbc2e8e8b1b5a059a04.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=WttfQGwpES,{'value': 'A Theoretical Perspective: How to Prevent Model Collapse in Self-consuming Training Loops'},Shi Fu; Yingjie Wang; Yuzhu Chen; Xinmei Tian; Dacheng Tao,~Shi_Fu1; ~Yingjie_Wang1; ~Yuzhu_Chen1; ~Xinmei_Tian1; ~Dacheng_Tao1,"{'value': ['Generative Models', 'Synthetic Data', 'Transformer', 'Generalization Error', 'Learning Theory']}","{'value': 'High-quality data is essential for training large generative models, yet the vast reservoir of real data available online has become nearly depleted. Consequently, models increasingly generate their own data for further training, forming Self-consuming Training Loops (STLs). However, the empirical results have been strikingly inconsistent: some models degrade or even collapse, while others successfully avoid these failures, leaving a significant gap in theoretical understanding to explain this discrepancy. This paper introduces the intriguing notion of *recursive stability* and presents the first theoretical generalization analysis, revealing how both model architecture and the proportion between real and synthetic data influence the success of STLs. We further extend this analysis to transformers in in-context learning, showing that even a constant-sized proportion of real data ensures convergence, while also providing insights into optimal synthetic data sizing.'}",https://openreview.net{'value': '/pdf/909858bef4cf368514084b6eaa0257e6c9a5d326.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=WpZyPk79Fu,{'value': 'Anyprefer: An Agentic Framework for Preference Data Synthesis'},Yiyang Zhou; Zhaoyang Wang; Tianle Wang; Shangyu Xing; Peng Xia; Bo Li; Kaiyuan Zheng; Zijian Zhang; Zhaorun Chen; Wenhao Zheng; Xuchao Zhang; Chetan Bansal; Weitong Zhang; Ying Wei; Mohit Bansal; Huaxiu Yao,~Yiyang_Zhou1; ~Zhaoyang_Wang1; ~Tianle_Wang1; ~Shangyu_Xing1; ~Peng_Xia1; ~Bo_Li58; ~Kaiyuan_Zheng1; ~Zijian_Zhang13; ~Zhaorun_Chen1; ~Wenhao_Zheng4; ~Xuchao_Zhang1; ~Chetan_Bansal1; ~Weitong_Zhang2; ~Ying_Wei1; ~Mohit_Bansal2; ~Huaxiu_Yao1,{'value': ['synthetic preference data generation; preference fine-tuning; agent']},"{'value': 'High-quality preference data is essential for aligning foundation models with human values through preference learning. However, manual annotation of such data is often time-consuming and costly. Recent methods often adopt a self-rewarding approach, where the target model generates and annotates its own preference data, but this can lead to inaccuracies since the reward model shares weights with the target model, thereby amplifying inherent biases. To address these issues, we propose Anyprefer, a framework designed to synthesize high-quality preference data for aligning the target model. Anyprefer frames the data synthesis process as a cooperative two-player Markov Game, where the target model and the judge model collaborate together. Here, a series of external tools are introduced to assist the judge model in accurately rewarding the target model’s responses, mitigating biases in the rewarding process. In addition, a feedback mechanism is introduced to optimize prompts for both models, enhancing collaboration and improving data quality. \nThe synthesized data is compiled into a new preference dataset, Anyprefer-V1, consisting of 58K high-quality preference pairs. \nExtensive experiments show that Anyprefer significantly improves model alignment performance across four main applications, covering 21 datasets, achieving average improvements of 18.55% in five natural language generation datasets, 3.66% in nine vision-language understanding datasets, 30.05% in three medical image analysis datasets, and 16.00% in four visuo-motor control tasks.'}",https://openreview.net{'value': '/pdf/7e6847efb457be8c950ed204503568e70f8c0302.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=WoGnnggVCZ,{'value': 'GenDataAgent: On-the-fly Dataset Augmentation with Synthetic Data'},Zhiteng Li; Lele Chen; Jerone Andrews; Yunhao Ba; Yulun Zhang; Alice Xiang,~Zhiteng_Li2; ~Lele_Chen1; ~Jerone_Andrews1; ~Yunhao_Ba1; ~Yulun_Zhang1; ~Alice_Xiang1,"{'value': ['supervised learning', 'classification', 'computer vision', 'synthetic data', 'generative AI', 'responsible AI', 'fairness']}","{'value': 'We propose a generative agent that augments training datasets with synthetic data for model fine-tuning. Unlike prior work, which uniformly samples synthetic data, our agent iteratively generates relevant samples on-the-fly, aligning with the target distribution. It prioritizes synthetic data that complements difficult training samples, focusing on those with high variance in gradient updates. Experiments across several image classification tasks demonstrate the effectiveness of our approach.'}",https://openreview.net{'value': '/pdf/16fca7d6b6c8df64c8d160f42001d5022d2a6949.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=WjKea8bGFF,{'value': 'Building Math Agents with Multi-Turn Iterative Preference Learning'},Wei Xiong; Chengshuai Shi; Jiaming Shen; Aviv Rosenberg; Zhen Qin; Daniele Calandriello; Misha Khalman; Rishabh Joshi; Bilal Piot; Mohammad Saleh; Chi Jin; Tong Zhang; Tianqi Liu,~Wei_Xiong9; ~Chengshuai_Shi1; ~Jiaming_Shen1; ~Aviv_Rosenberg1; ~Zhen_Qin5; ~Daniele_Calandriello1; ~Misha_Khalman1; ~Rishabh_Joshi1; ~Bilal_Piot1; ~Mohammad_Saleh1; ~Chi_Jin1; ~Tong_Zhang2; ~Tianqi_Liu1,"{'value': ['large language model', 'RLHF', 'math']}","{'value': ""Recent studies have shown that large language models' (LLMs) mathematical problem-solving capabilities can be enhanced by integrating external tools, such as code interpreters, and employing multi-turn Chain-of-Thought (CoT) reasoning. While current methods focus on synthetic data generation and Supervised Fine-Tuning (SFT), this paper studies the complementary direct preference learning approach to further improve model performance. However, existing direct preference learning algorithms are originally designed for the single-turn chat task, and do not fully address the complexities of multi-turn reasoning and external tool integration required for tool-integrated mathematical reasoning tasks. To fill in this gap, we introduce a multi-turn direct preference learning framework, tailored for this context, that leverages feedback from code interpreters and optimizes trajectory-level preferences. This framework includes multi-turn DPO and multi-turn KTO as specific implementations. The effectiveness of our framework is validated through training of various language models using an augmented prompt set from the GSM8K and MATH datasets. Our results demonstrate substantial improvements: a supervised fine-tuned Gemma-1.1-it-7B model's performance increased from 77.5% to 83.9% on GSM8K and from 46.1% to 51.2% on MATH. Similarly, a Gemma-2-it-9B model improved from 84.1% to 86.3% on GSM8K and from 51.0% to 54.5% on MATH.""}",https://openreview.net{'value': '/pdf/2bba315bddc50c3b687b5f775be3826268ade812.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=WjDjem8mWE,{'value': 'DyCAST: Learning Dynamic Causal Structure from Time Series'},Yue Cheng; Bochen Lyu; Weiwei Xing; Zhanxing Zhu,~Yue_Cheng3; ~Bochen_Lyu1; ~Weiwei_Xing1; ~Zhanxing_Zhu1,{'value': ['dynamic causal discovery; time series']},"{'value': 'Understanding the dynamics of causal structures is crucial for uncovering the underlying processes in time series data. Previous approaches rely on static assumptions, where contemporaneous and time-lagged dependencies are assumed to have invariant topological structures. However, these models fail to capture the evolving causal relationship between variables when the underlying process exhibits such dynamics. To address this limitation, we propose DyCAST, a novel framework designed to learn dynamic causal structures in time series using Neural Ordinary Differential Equations (Neural ODEs). The key innovation lies in modeling the temporal dynamics of the contemporaneous structure, drawing inspiration from recent advances in Neural ODEs on constrained manifolds. We reformulate the task of learning causal structures at each time step as solving the solution trajectory of a Neural ODE on the directed acyclic graph (DAG) manifold. To accommodate high-dimensional causal structures, we extend DyCAST by learning the temporal dynamics of the hidden state for contemporaneous causal structure. Experiments on both synthetic and real-world datasets demonstrate that DyCAST achieves superior or comparable performance compared to existing causal discovery models.'}",https://openreview.net{'value': '/pdf/d730581bb91a5a36eb5bd48c02251200f651a12d.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=Wh4SE2S7Mo,{'value': 'Three Mechanisms of Feature Learning in a Linear Network'},Yizhou Xu; Liu Ziyin,~Yizhou_Xu2; ~Liu_Ziyin1,"{'value': ['solvable model', 'feature learning', 'neural tangent kernel']}","{'value': 'Understanding the dynamics of neural networks in different width regimes is crucial for improving their training and performance. We present an exact solution for the learning dynamics of a one-hidden-layer linear network, with one-dimensional data, across any finite width, uniquely exhibiting both kernel and feature learning phases. This study marks a technical advancement by enabling the analysis of the training trajectory from any initialization and a detailed phase diagram under varying common hyperparameters such as width, layer-wise learning rates, and scales of output and initialization. We identify three novel prototype mechanisms specific to the feature learning regime: (1) learning by alignment, (2) learning by disalignment, and (3) learning by rescaling, which contrast starkly with the dynamics observed in the kernel regime. Our theoretical findings are substantiated with empirical evidence showing that these mechanisms also manifest in deep nonlinear networks handling real-world tasks, enhancing our understanding of neural network training dynamics and guiding the design of more effective learning strategies.'}",https://openreview.net{'value': '/pdf/34994a77a488b47afdf475fe9193e63fe689a7f8.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=WfxPVtYRlL,{'value': 'Graph Neural Networks Gone Hogwild'},Olga Solodova; Nick Richardson; Deniz Oktay; Ryan P Adams,~Olga_Solodova1; ~Nick_Richardson1; ~Deniz_Oktay2; ~Ryan_P_Adams1,"{'value': ['graph neural networks', 'multi-agent', 'asynchronous', 'decentralized']}","{'value': ""Graph neural networks (GNNs) appear to be powerful tools to learn state representations for agents in distributed, decentralized multi-agent systems, but generate catastrophically incorrect predictions when nodes update asynchronously during inference.\n  This failure under asynchrony effectively excludes these architectures from many potential applications where synchrony is difficult or impossible to enforce, e.g., robotic swarms or sensor networks.\n  In this work we identify ''implicitly-defined'' GNNs as a class of architectures which is provably robust to asynchronous ''hogwild'' inference, adapting convergence guarantees from work in asynchronous and distributed optimization. \n  We then propose a novel implicitly-defined GNN architecture, which we call an energy GNN. \n  We show that this architecture outperforms other GNNs from this class on a variety of synthetic tasks inspired by multi-agent systems.""}",https://openreview.net{'value': '/pdf/e8bd1d55ad9f030a6e0db669b9e72967f01edacb.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=We5z3UEnUY,{'value': 'Stable Hadamard Memory: Revitalizing Memory-Augmented Agents for Reinforcement Learning'},Hung Le; Dung Nguyen; Kien Do; Sunil Gupta; Svetha Venkatesh,~Hung_Le1; ~Dung_Nguyen1; ~Kien_Do1; ~Sunil_Gupta2; ~Svetha_Venkatesh1,"{'value': ['Reinforcement Learning', 'Memory', 'POMDP']}","{'value': 'Effective decision-making in partially observable environments demands robust memory management. Despite their success in supervised learning, current deep-learning memory models struggle in reinforcement learning environments that are partially observable and long-term. They fail to efficiently capture relevant past information, adapt flexibly to changing observations, and maintain stable updates over long episodes. We theoretically analyze the limitations of existing memory models within a unified framework and introduce the Stable Hadamard Memory, a novel memory model for reinforcement learning agents. Our model dynamically adjusts memory by erasing no longer needed experiences and reinforcing crucial ones computationally efficiently. To this end, we leverage the Hadamard product for calibrating and updating memory, specifically designed to enhance memory capacity while mitigating numerical and learning challenges. Our approach significantly outperforms state-of-the-art memory-based methods on challenging partially observable benchmarks, such as meta-reinforcement learning, long-horizon credit assignment, and POPGym, demonstrating superior performance in handling long-term and evolving contexts.'}",https://openreview.net{'value': '/pdf/a19c94ed1d1c833ed6000adc82a8ba6671d79e30.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=WQV9kB1qSU,{'value': 'Transition Path Sampling with Improved Off-Policy Training of Diffusion Path Samplers'},Kiyoung Seong; Seonghyun Park; Seonghwan Kim; Woo Youn Kim; Sungsoo Ahn,~Kiyoung_Seong2; ~Seonghyun_Park1; ~Seonghwan_Kim6; ~Woo_Youn_Kim1; ~Sungsoo_Ahn1,"{'value': ['molecular dynamics', 'transition path sampling']}","{'value': 'Understanding transition pathways between two meta-stable states of a molecular system is crucial to advance drug discovery and material design. However, unbiased molecular dynamics (MD) simulations are computationally infeasible because of the high energy barriers that separate these states. Although recent machine learning techniques are proposed to sample rare events, they are often limited to simple systems and rely on collective variables (CVs) derived from costly domain expertise. In this paper, we introduce a novel approach that trains diffusion path samplers (DPS) to address the transition path sampling (TPS) problem without requiring CVs. We reformulate the problem as an amortized sampling from the transition path distribution by minimizing the log-variance divergence between the path distribution induced by DPS and the transition path distribution. Based on the log-variance divergence, we propose learnable control variates to reduce the variance of gradient estimators and the off-policy training objective with replay buffers and simulated annealing techniques to improve sample efficiency and diversity. We also propose a scale-based equivariant parameterization of the bias forces to ensure scalability for large systems. We extensively evaluate our approach, termed TPS-DPS, on a synthetic system, small peptide, and challenging fast-folding proteins, demonstrating that it produces more realistic and diverse transition pathways than existing baselines. We also provide links to [project page](https://kiyoung98.github.io/tps-dps/) and [code](https://github.com/kiyoung98/tps-dps).'}",https://openreview.net{'value': '/pdf/fd1880cec156f8225f9631bf02b8c18d28a71fbe.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=WCVMqRHWW5,{'value': 'Distributional Associations vs In-Context Reasoning: A Study of Feed-forward and Attention Layers'},Lei Chen; Joan Bruna; Alberto Bietti,~Lei_Chen4; ~Joan_Bruna1; ~Alberto_Bietti1,"{'value': ['reasoning', 'in-context learning', 'associative memory', 'transformers', 'distribution shift']}","{'value': 'Large language models have been successful at tasks involving basic forms of in-context reasoning, such as generating coherent language, as well as storing vast amounts of knowledge. At the core of the Transformer architecture behind such models are feed-forward and attention layers, which are often associated to knowledge and reasoning, respectively. In this paper, we study this distinction empirically and theoretically in a controlled synthetic setting where certain next-token predictions involve both distributional and in-context information. We find that feed-forward layers tend to learn simple distributional associations such as bigrams, while attention layers focus on in-context reasoning. Our theoretical analysis identifies the noise in the gradients as a key factor behind this discrepancy. Finally, we illustrate how similar disparities emerge in pre-trained models through ablations on the Pythia model family on simple reasoning tasks.'}",https://openreview.net{'value': '/pdf/7d5d330b640e6e3659657de14511a7380b9bb2af.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=VvDEuyVXkG,{'value': 'Benchmarking Multimodal Retrieval Augmented Generation with Dynamic VQA Dataset and Self-adaptive Planning Agent'},Yangning Li; Yinghui Li; Xinyu Wang; Yong Jiang; Zhen Zhang; Xinran Zheng; Hui Wang; Hai-Tao Zheng; Fei Huang; Jingren Zhou; Philip S. Yu,~Yangning_Li1; ~Yinghui_Li1; ~Xinyu_Wang3; ~Yong_Jiang1; ~Zhen_Zhang30; ~Xinran_Zheng1; ~Hui_Wang13; ~Hai-Tao_Zheng2; ~Fei_Huang2; ~Jingren_Zhou1; ~Philip_S._Yu1,"{'value': ['Large Language Model', 'Multimodal Retrieval Augmented Generation', 'Knowledge Enhancement']}","{'value': ""Multimodal Retrieval Augmented Generation (mRAG) plays an important role in mitigating the “hallucination” issue inherent in multimodal large language models (MLLMs). Although promising, existing heuristic mRAGs typically predefined fixed retrieval processes, which causes two issues: (1) Non-adaptive Retrieval Queries. (2) Overloaded Retrieval Queries. However, these flaws cannot be adequately reflected by current knowledge-seeking visual question answering (VQA) datasets, since the most required knowledge can be readily obtained with a standard two-step retrieval. To bridge the dataset gap, we first construct Dyn-VQA dataset, consisting of three types of ``dynamic'' questions, which require complex knowledge retrieval strategies variable in query, tool, and time: (1) Questions with rapidly changing answers. (2) Questions requiring multi-modal knowledge. (3) Multi-hop questions. Experiments on Dyn-VQA reveal that existing heuristic mRAGs struggle to provide sufficient and precisely relevant knowledge for dynamic questions due to their rigid retrieval processes. Hence, we further propose the first self-adaptive planning agent for multimodal retrieval, **OmniSearch**. The underlying idea is to emulate the human behavior in question solution which dynamically decomposes complex multimodal questions into sub-question chains with retrieval action. Extensive experiments prove the effectiveness of our OmniSearch, also provide direction for advancing mRAG. Code and dataset will be open-sourced.""}",https://openreview.net{'value': '/pdf/eee01c8c432497836abefdb4ade1f97acec2b965.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=VoI4d6uhdr,{'value': 'An Effective Theory of Bias Amplification'},Arjun Subramonian; Samuel Bell; Levent Sagun; Elvis Dohmatob,~Arjun_Subramonian1; ~Samuel_Bell1; ~Levent_Sagun1; ~Elvis_Dohmatob1,"{'value': ['fairness', 'algorithmic bias', 'machine learning theory', 'random matrix theory']}","{'value': 'Machine learning models can capture and amplify biases present in data, leading to disparate test performance across social groups. To better understand, evaluate, and mitigate these biases, a deeper theoretical understanding of how model design choices and data distribution properties contribute to bias is needed. In this work, we contribute a precise analytical theory in the context of ridge regression, both with and without random projections, where the former models feedforward neural networks in a simplified regime. Our theory offers a unified and rigorous explanation of machine learning bias, providing insights into phenomena such as bias amplification and minority-group bias in various feature and parameter regimes. For example, we observe that there may be an optimal regularization penalty or training time to avoid bias amplification, and there can be differences in test error between groups that are not alleviated with increased parameterization. Importantly, our theoretical predictions align with  empirical observations reported in the literature on machine learning bias. We extensively empirically validate our theory on synthetic and semi-synthetic datasets.'}",https://openreview.net{'value': '/pdf/e8926be833113ac40637858b1abdc9d9f49404f5.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=VELhv9BBfn,{'value': 'Neural Dueling Bandits: Preference-Based Optimization with Human Feedback'},Arun Verma; Zhongxiang Dai; Xiaoqiang Lin; Patrick Jaillet; Bryan Kian Hsiang Low,~Arun_Verma1; ~Zhongxiang_Dai1; ~Xiaoqiang_Lin1; ~Patrick_Jaillet1; ~Bryan_Kian_Hsiang_Low1,"{'value': ['Contextual Dueling Bandits', 'Preferences Learning', 'Human Feedback', 'Neural Bandits', 'Thompson Sampling']}","{'value': ""Contextual dueling bandit is used to model the bandit problems, where a learner's goal is to find the best arm for a given context using observed noisy human preference feedback over the selected arms for the past contexts. However, existing algorithms assume the reward function is linear, which can be complex and non-linear in many real-life applications like online recommendations or ranking web search results. To overcome this challenge, we use a neural network to estimate the reward function using preference feedback for the previously selected arms. We propose upper confidence bound- and Thompson sampling-based algorithms with sub-linear regret guarantees that efficiently select arms in each round. We also extend our theoretical results to contextual bandit problems with binary feedback, which is in itself a non-trivial contribution. Experimental results on the problem instances derived from synthetic datasets corroborate our theoretical results.""}",https://openreview.net{'value': '/pdf/875613f857a562bc6de9f80ec0421b5e179060b8.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=V4y0CpX4hK,{'value': 'Agent Security Bench (ASB): Formalizing and Benchmarking Attacks and Defenses in LLM-based Agents'},Hanrong Zhang; Jingyuan Huang; Kai Mei; Yifei Yao; Zhenting Wang; Chenlu Zhan; Hongwei Wang; Yongfeng Zhang,~Hanrong_Zhang1; ~Jingyuan_Huang4; ~Kai_Mei1; ~Yifei_Yao2; ~Zhenting_Wang1; ~Chenlu_Zhan1; ~Hongwei_Wang6; ~Yongfeng_Zhang1,{'value': ['AI agents; Large Language Model; Benchmark; Prompt Injection Attacks; Backdoor Attack; Defenses']},"{'value': ""Although LLM-based agents, powered by Large Language Models (LLMs), can use external tools and memory mechanisms to solve complex real-world tasks, they may also introduce critical security vulnerabilities. However, the existing literature does not comprehensively evaluate attacks and defenses against LLM-based agents. To address this, we introduce Agent Security Bench (ASB), a comprehensive framework designed to formalize, benchmark, and evaluate the attacks and defenses of LLM-based agents, including 10 scenarios (e.g., e-commerce, autonomous driving, finance), 10 agents targeting the scenarios, over 400 tools, 27 different types of attack/defense methods, and 7 evaluation metrics. Based on ASB, we benchmark 10 prompt injection attacks, a memory poisoning attack, a novel Plan-of-Thought backdoor attack, 4 mixed attacks, and 11 corresponding defenses across 13 LLM backbones. Our benchmark results reveal critical vulnerabilities in different stages of agent operation, including system prompt, user prompt handling, tool usage, and memory retrieval, with the highest average attack success rate of 84.30\\%, but limited effectiveness shown in current defenses, unveiling important works to be done in terms of agent security for the community. We also introduce a new metric to evaluate the agents' capability to balance utility and security. Our code can be found at \nhttps://github.com/agiresearch/ASB.""}",https://openreview.net{'value': '/pdf/dad15b18ea37cf4dce69eadb247b9f9c8cc9d045.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=UyU8ETswPg,{'value': 'Fictitious Synthetic Data Can Improve LLM Factuality via Prerequisite Learning'},Yujian Liu; Shiyu Chang; Tommi Jaakkola; Yang Zhang,~Yujian_Liu1; ~Shiyu_Chang2; ~Tommi_S._Jaakkola1; ~Yang_Zhang3,"{'value': ['Hallucinations', 'instruction-tuning']}","{'value': ""Recent studies have identified one aggravating factor of LLM hallucinations as the knowledge inconsistency between pre-training and fine-tuning, where unfamiliar fine-tuning data mislead the LLM to fabricate plausible but wrong outputs. In this paper, we propose a novel fine-tuning strategy called Prereq-Tune to address this knowledge inconsistency and reduce hallucinations. Fundamentally, Prereq-Tune disentangles the learning of skills and knowledge, so the model learns only the task skills without being impacted by the knowledge inconsistency. To achieve this, Prereq-Tune introduces an additional prerequisite learning stage to learn the necessary knowledge for SFT, allowing subsequent SFT to focus only on task skills. Prereq-Tune can also be combined with fictitious synthetic data to enhance the grounding of LLM outputs to their internal knowledge. Experiments show that Prereq-Tune outperforms existing baselines in improving LLM's factuality across short QA and long-form generation tasks. It also opens new possibilities for knowledge-controlled generation in LLMs. Our code is available at https://github.com/UCSB-NLP-Chang/Prereq_tune.git.""}",https://openreview.net{'value': '/pdf/83aac0a31698d52d2dae0c2f5c529951cfebd614.pdf'},{'title_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=UxkznlcnHf,{'value': 'Towards a Theoretical Understanding of Synthetic Data in LLM Post-Training: A Reverse-Bottleneck Perspective'},Zeyu Gan; Yong Liu,~Zeyu_Gan1; ~Yong_Liu7,{'value': ['large language models; synthetic data; information bottleneck']},"{'value': 'Synthetic data has become a pivotal resource in post-training tasks for large language models (LLMs) due to the scarcity of high-quality, specific data. While various methods have been developed to generate synthetic data, there remains a discernible gap between the practical effects of synthetic data and our theoretical comprehension. To address this challenge, we commence by presenting a detailed modeling of the prevalent synthetic data generation process. Building upon this modeling, we demonstrate that the generalization capability of the post-trained model is critically determined by the information gain derived from the generative model, as analyzed from a novel reverse-bottleneck perspective. Moreover, we introduce the concept of Generalization Gain via Mutual Information (GGMI) and elucidate the relationship between generalization gain and information gain. This analysis serves as a theoretical foundation for synthetic data generation and further highlights its connection with the generalization capability of post-trained models, offering an understanding about the design of synthetic data generation techniques and the optimization of the post-training process. We open-source our code at https://github.com/ZyGan1999/Towards-a-Theoretical-Understanding-of-Synthetic-Data-in-LLM-Post-Training.'}",https://openreview.net{'value': '/pdf/127d76775eb769452b3e1f3cffc5359d9e886a32.pdf'},{'title_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=UwcZEoNP19,{'value': 'Triples as the Key: Structuring Makes Decomposition and Verification Easier in LLM-based TableQA'},Zhen Yang; Ziwei Du; Minghan Zhang; Wei Du; Jie Chen; Zhen Duan; Shu Zhao,~Zhen_Yang14; ~Ziwei_Du1; ~Minghan_Zhang1; ~Wei_Du11; ~Jie_Chen35; ~Zhen_Duan1; ~Shu_Zhao4,"{'value': ['TableQA', 'Triples']}","{'value': ""As the mainstream approach, LLMs have been widely applied and researched in TableQA tasks. Currently, the core of LLM-based TableQA methods typically include three phases: question decomposition, sub-question TableQA reasoning, and answer verification. However, several challenges remain in this process: i) Sub-questions generated by these methods often exhibit significant gaps with the original question due to critical information overlooked during the LLM's direct decomposition; ii) Verification of answers is typically challenging because LLMs tend to generate optimal responses during self-correct. To address these challenges, we propose a Triple-Inspired Decomposition and vErification (TIDE) strategy, which leverages the structural properties of triples to assist in decomposition and verification in TableQA. The inherent structure of triples (head entity, relation, tail entity) requires the LLM to extract as many entities and relations from the question as possible. Unlike direct decomposition methods that may overlook key information, our transformed sub-questions using triples encompass more critical details. Additionally, this explicit structure facilitates verification. By comparing the triples derived from the answers with those from the question decomposition, we can achieve easier and more straightforward validation than when relying on the LLM's self-correct tendencies. By employing triples alongside established LLM modes, Direct Prompting and Agent modes, TIDE achieves state-of-the-art performance across multiple TableQA datasets, demonstrating the effectiveness of our method.""}",https://openreview.net{'value': '/pdf/09724c54c881e55065b0e40b6cfbc3d892d2b348.pdf'},{'abstract_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=Uo4EHT4ZZ8,{'value': 'LeanAgent: Lifelong Learning for Formal Theorem Proving'},Adarsh Kumarappan; Mo Tiwari; Peiyang Song; Robert Joseph George; Chaowei Xiao; Anima Anandkumar,~Adarsh_Kumarappan2; ~Mo_Tiwari1; ~Peiyang_Song1; ~Robert_Joseph_George1; ~Chaowei_Xiao2; ~Anima_Anandkumar1,"{'value': ['Theorem Proving', 'Formal Theorem Proving', 'Neural Theorem Proving', 'Lifelong Learning', 'Formal Mathematics', 'Large Language Models', 'LLMs', 'Curriculum Learning', 'Proof Search']}","{'value': ""Large Language Models (LLMs) have been successful in mathematical reasoning tasks such as formal theorem proving when integrated with interactive proof assistants like Lean. Existing approaches involve training or fine-tuning an LLM on a specific dataset to perform well on particular domains, such as undergraduate-level mathematics. These methods struggle with generalizability to advanced mathematics. A fundamental limitation is that these approaches operate on static domains, failing to capture how mathematicians often work across multiple domains and projects simultaneously or cyclically. We present LeanAgent, a novel lifelong learning framework for formal theorem proving that continuously generalizes to and improves on ever-expanding mathematical knowledge without forgetting previously learned knowledge. LeanAgent introduces several key innovations, including a curriculum learning strategy that optimizes the learning trajectory in terms of mathematical difficulty, a dynamic database for efficient management of evolving mathematical knowledge, and progressive training to balance stability and plasticity. LeanAgent successfully generates formal proofs for 155 theorems across 23 diverse Lean repositories where formal proofs were previously missing, many from advanced mathematics. It performs significantly better than the static LLM baseline, proving challenging theorems in domains like abstract algebra and algebraic topology while showcasing a clear progression of learning from basic concepts to advanced topics. In addition, we analyze LeanAgent's superior performance on key lifelong learning metrics. LeanAgent achieves exceptional scores in stability and backward transfer, where learning new tasks improves performance on previously learned tasks. This emphasizes LeanAgent's continuous generalizability and improvement, explaining its superior theorem-proving performance.""}",https://openreview.net{'value': '/pdf/c4bbf8256507953aff546765903d08e3fe6d16a4.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=UnCKU8pZVe,{'value': 'BOFormer: Learning to Solve Multi-Objective Bayesian Optimization via Non-Markovian RL'},Yu Heng Hung; Kai-Jie Lin; Yu-Heng Lin; Chien-Yi Wang; Cheng Sun; Ping-Chun Hsieh,~Yu_Heng_Hung1; ~Kai-Jie_Lin1; ~Yu-Heng_Lin1; ~Chien-Yi_Wang1; ~Cheng_Sun3; ~Ping-Chun_Hsieh1,"{'value': ['Multi-Objective Bayesian Optimization', 'Transformers', 'Hyperparameter Optimization', 'Reinforcement Learning', 'Acquisition Function']}","{'value': 'Bayesian optimization (BO) offers an efficient pipeline for optimizing black-box functions with the help of a Gaussian process prior and an acquisition function (AF). Recently, in the context of single-objective BO, learning-based AFs witnessed promising empirical results given its favorable non-myopic nature. Despite this, the direct extension of these approaches to multi-objective Bayesian optimization (MOBO) suffer from the hypervolume identifiability issue, which results from the non-Markovian nature of MOBO problems. To tackle this, inspired by the non-Markovian RL literature and the success of Transformers in language modeling, we present a generalized deep Q-learning framework and propose BOFormer, which substantiates this framework for MOBO via sequence modeling. Through extensive evaluation, we demonstrate that BOFormer constantly achieves better performance than the benchmark rule-based and learning-based algorithms in various synthetic MOBO and real-world multi-objective hyperparameter optimization problems.'}",https://openreview.net{'value': '/pdf/bfae3e8b68b9efcc8436bed52f40a74057a1ea58.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=UmdotAAVDe,{'value': 'Combining Induction and Transduction for Abstract Reasoning'},Wen-Ding Li; Keya Hu; Carter Larsen; Yuqing Wu; Simon Alford; Caleb Woo; Spencer M. Dunn; Hao Tang; Wei-Long Zheng; Yewen Pu; Kevin Ellis,~Wen-Ding_Li1; ~Keya_Hu1; ~Carter_Larsen1; ~Yuqing_Wu2; ~Simon_Alford2; ~Caleb_Woo1; ~Spencer_M._Dunn1; ~Hao_Tang5; ~Wei-Long_Zheng1; ~Yewen_Pu1; ~Kevin_Ellis1,"{'value': ['Abstract Reasoning', 'Visual Reasoning', 'Program Synthesis', 'Induction', 'Transduction']}","{'value': 'When learning an input-output mapping from very few examples, is it better to first infer a latent function that explains the examples, or is it better to directly predict new test outputs, e.g. using a neural network? We study this question on ARC by training neural models for \\emph{induction} (inferring latent functions) and \\emph{transduction} (directly predicting the test output for a given test input). We train \non synthetically generated variations of Python programs that solve ARC training tasks. We find inductive and transductive models solve different kinds of test problems, despite having the same training problems and sharing the same neural architecture: Inductive program synthesis excels at precise computations, and at composing multiple concepts, while transduction succeeds on fuzzier perceptual concepts. Ensembling them approaches human-level performance on ARC.'}",https://openreview.net{'value': '/pdf/a53e248e943d28f22b7a38f38bc90f74a5f0016b.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=Uh5GRmLlvt,{'value': 'On Rollouts in Model-Based Reinforcement Learning'},Bernd Frauenknecht; Devdutt Subhasish; Friedrich Solowjow; Sebastian Trimpe,~Bernd_Frauenknecht1; ~Devdutt_Subhasish1; ~Friedrich_Solowjow1; ~Sebastian_Trimpe1,"{'value': ['Model-Based Reinforcement Learning', 'Model Rollouts', 'Uncertainty Quantification']}","{'value': 'Model-based reinforcement learning (MBRL) seeks to enhance data efficiency by learning a model of the environment and generating synthetic rollouts from it. However, accumulated model errors during these rollouts can distort the data distribution, negatively impacting policy learning and hindering long-term planning. Thus, the accumulation of model errors is a key bottleneck in current MBRL methods. We propose Infoprop, a model-based rollout mechanism that separates aleatoric from epistemic model uncertainty and reduces the influence of the latter on the data distribution. Further, Infoprop keeps track of accumulated model errors along a model rollout and provides termination criteria to limit data corruption. We demonstrate the capabilities of Infoprop in the Infoprop-Dyna algorithm, reporting state-of-the-art performance in Dyna-style MBRL on common MuJoCo benchmark tasks while substantially increasing rollout length and data quality.'}",https://openreview.net{'value': '/pdf/465cc42026a8c5de92e9400e38e206ccf8aad543.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=Ugs2W5XFFo,{'value': 'Information Theoretic Text-to-Image Alignment'},CHAO WANG; Giulio Franzese; Alessandro Finamore; Massimo Gallo; Pietro Michiardi,~CHAO_WANG49; ~Giulio_Franzese1; ~Alessandro_Finamore1; ~Massimo_Gallo1; ~Pietro_Michiardi1,"{'value': ['Diffusion model', 'Text-image alignment', 'Mutual information']}","{'value': 'Diffusion models for Text-to-Image (T2I) conditional generation have recently achieved\ntremendous success. Yet, aligning these models with user’s intentions still involves a\nlaborious trial-and-error process, and this challenging alignment problem has attracted\nconsiderable attention from the research community. In this work, instead of relying on\nfine-grained linguistic analyses of prompts, human annotation, or auxiliary vision-language\nmodels, we use Mutual Information (MI) to guide model alignment. In brief, our method\nuses self-supervised fine-tuning and relies on a point-wise MI estimation between prompts\nand images to create a synthetic fine-tuning set for improving model alignment. Our\nanalysis indicates that our method is superior to the state-of-the-art, yet it only requires\nthe pre-trained denoising network of the T2I model itself to estimate MI, and a simple\nfine-tuning strategy that improves alignment while maintaining image quality. Code available at https://github.com/Chao0511/mitune.'}",https://openreview.net{'value': '/pdf/2ffbeca2cd434d01d4b2588db2cc93ddaac63dce.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=UapxTvxB3N,{'value': 'Trajectory-LLM: A Language-based Data Generator for Trajectory Prediction in Autonomous Driving'},Kairui Yang; Zihao Guo; Gengjie Lin; Haotian Dong; Zhao Huang; Yipeng Wu; Die Zuo; Jibin Peng; Ziyuan Zhong; Xin WANG; Qing Guo; Xiaosong Jia; Junchi Yan; Di Lin,~Kairui_Yang1; ~Zihao_Guo3; ~Gengjie_Lin1; ~Haotian_Dong1; ~Zhao_Huang1; ~Yipeng_Wu1; ~Die_Zuo1; ~Jibin_Peng1; ~Ziyuan_Zhong1; ~Xin_WANG32; ~Qing_Guo3; ~Xiaosong_Jia1; ~Junchi_Yan2; ~Di_Lin3,"{'value': ['Trajectory Prediction', 'Large Language Model', 'Autonomous Driving']}","{'value': 'Vehicle trajectory prediction is a crucial aspect of autonomous driving, which requires extensive trajectory data to train prediction models to understand the complex, varied, and unpredictable patterns of vehicular interactions. However, acquiring real-world data is expensive, so we advocate using Large Language Models (LLMs) to generate abundant and realistic trajectories of interacting vehicles efficiently. These models rely on textual descriptions of vehicle-to-vehicle interactions on a map to produce the trajectories. We introduce Trajectory-LLM (Traj-LLM), a new approach that takes brief descriptions of vehicular interactions as input and generates corresponding trajectories. Unlike language-based approaches that translate text directly to trajectories, Traj-LLM uses reasonable driving behaviors to align the vehicle trajectories with the text. This results in an ""interaction-behavior-trajectory"" translation process. We have also created a new dataset, Language-to-Trajectory (L2T), which includes 240K textual descriptions of vehicle interactions and behaviors, each paired with corresponding map topologies and vehicle trajectory segments. By leveraging the L2T dataset, Traj-LLM can adapt interactive trajectories to diverse map topologies. Furthermore, Traj-LLM generates additional data that enhances downstream prediction models, leading to consistent performance improvements across public benchmarks. The source code is released at https://github.com/TJU-IDVLab/Traj-LLM.'}",https://openreview.net{'value': '/pdf/090261c3be3b491ad5569bb1ba8b1991e67225be.pdf'},{'title_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=Tv36j85SqR,{'value': 'Approaching Rate-Distortion Limits in Neural Compression with Lattice Transform Coding'},Eric Lei; Hamed Hassani; Shirin Saeedi Bidokhti,~Eric_Lei2; ~Hamed_Hassani2; ~Shirin_Saeedi_Bidokhti1,"{'value': ['Neural compression', 'vector quantization', 'lattice quantization', 'nonlinear transform coding']}","{'value': 'Neural compression has brought tremendous progress in designing lossy compressors with good rate-distortion (RD) performance at low complexity. Thus far, neural compression design involves transforming the source to a latent vector, which is then rounded to integers and entropy coded. While this approach has been shown to be optimal on a few specific sources, we show that it can be highly sub-optimal on synthetic sources whose intrinsic dimensionality is greater than one. With integer rounding in the latent space, the quantization regions induced by neural transformations, remain square-like and fail to match those of optimal vector quantization. We demonstrate that this phenomenon is due to the choice of scalar quantization in the latent space, and not the transform design. By employing lattice quantization instead, we propose  Lattice Transform Coding (LTC) and show that it approximately recovers optimal vector quantization at reasonable complexity. On real-world sources, LTC improves upon standard neural compressors. LTC also provides a framework that can integrate structurally (near) optimal information-theoretic designs into lossy compression; examples include block coding, which yields coding gain over optimal one-shot coding and approaches the asymptotically-achievable rate-distortion function, as well as nested lattice quantization for low complexity fixed-rate coding.'}",https://openreview.net{'value': '/pdf/4e66c9cd73660937ad8c2b2a539768b5df59e395.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=TuOTSAiHDn,{'value': 'MIND: Math Informed syNthetic Dialogues for Pretraining LLMs'},Syeda Nahida Akter; Shrimai Prabhumoye; John Kamalu; Sanjeev Satheesh; Eric Nyberg; Mostofa Patwary; Mohammad Shoeybi; Bryan Catanzaro,~Syeda_Nahida_Akter1; ~Shrimai_Prabhumoye1; ~John_Kamalu1; ~Sanjeev_Satheesh3; ~Eric_Nyberg1; ~Mostofa_Patwary1; ~Mohammad_Shoeybi1; ~Bryan_Catanzaro1,"{'value': ['pretraining', 'mathematical reasoning', 'synthetic dialogue', 'LLM', 'reasoning']}","{'value': 'The utility of synthetic data to enhance pretraining data quality and hence to improve downstream task accuracy has been widely explored in recent large language models (LLMs). Yet, these approaches fall inadequate in complex, multi-hop and mathematical reasoning tasks as the synthetic data typically fails to add complementary knowledge to the existing raw corpus. In this work, we propose a novel large-scale and diverse Math Informed syNthetic Dialogue (MIND) generation method that improves the mathematical reasoning ability of LLMs. Specifically, using MIND, we generate synthetic conversations based on OpenWebMath (OWM), resulting in a new math corpus, MIND-OWM. Our experiments with different conversational settings reveal that incorporating knowledge gaps between dialog participants is essential for generating high-quality math data. We further identify an effective way to format and integrate synthetic and raw data during pretraining to maximize the gain in mathematical reasoning, emphasizing the need to restructure raw data rather than use it as-is. Compared to pretraining just on raw data, a model pretrained on MIND-OWM shows significant boost in mathematical reasoning (GSM8K: +13.42%, MATH: +2.30%), including superior performance in specialized knowledge (MMLU: +4.55%, MMLU-STEM: +4.28%) and general\npurpose reasoning tasks (GENERAL REASONING: +2.51%).'}",https://openreview.net{'value': '/pdf/5313c64ed4eed9b848e009dd9d70799be396e7f8.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=TjP1d8PP8l,{'value': 'Discriminator-Guided Embodied Planning for LLM Agent'},Haofu Qian; Chenjia Bai; Jiatao Zhang; Fei Wu; Wei Song; Xuelong Li,~Haofu_Qian1; ~Chenjia_Bai2; ~Jiatao_Zhang1; ~Fei_Wu1; ~Wei_Song8; ~Xuelong_Li2,"{'value': ['LLM Agent', 'Embodied Planning', 'Discriminator', 'Critic-Regularized Optimization']}","{'value': 'Large Language Models (LLMs) have showcased remarkable reasoning capabilities in various domains, yet face challenges in complex embodied tasks due to the need for a coherent long-term policy and context-sensitive environmental understanding. Previous work performed LLM refinement relying on outcome-supervised feedback, which can be costly and ineffective. In this work, we introduce a novel framework, Discriminator-Guided Action Optimization (DGAP), for facilitating the optimization of LLM action plans via step-wise signals. Specifically, we employ a limited set of demonstrations to enable the discriminator to learn a score function, which assesses the alignment between LLM-generated actions and the underlying optimal ones at every step. Based on the discriminator, LLMs are prompted to generate actions that maximize the score, utilizing historical action-score pair trajectories as guidance. Under mild conditions, DGAP resembles critic-regularized optimization and has been demonstrated to achieve a stronger policy than the LLM planner. In experiments across different LLMs (GPT-4, Llama3-70B) in ScienceWorld and VirtualHome, our method achieves superior performance and better efficiency than previous methods.'}",https://openreview.net{'value': '/pdf/a58cc964b477fed43b6add777ff28e4989ea5a5e.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=TbTJJNjumY,{'value': 'Boosting Neural Combinatorial Optimization for Large-Scale Vehicle Routing Problems'},Fu Luo; Xi Lin; Yaoxin Wu; Zhenkun Wang; Tong Xialiang; Mingxuan Yuan; Qingfu Zhang,~Fu_Luo1; ~Xi_Lin2; ~Yaoxin_Wu2; ~Zhenkun_Wang1; ~Tong_Xialiang2; ~Mingxuan_Yuan1; ~Qingfu_Zhang1,"{'value': ['Neural Combinatorial Optimization', 'Large-Scale Vehicle Routing Problem']}","{'value': 'Neural Combinatorial Optimization (NCO) methods have exhibited promising performance in solving Vehicle Routing Problems (VRPs). However, most NCO methods rely on the conventional self-attention mechanism that induces excessive computational complexity, thereby struggling to contend with large-scale VRPs and hindering their practical applicability. In this paper, we propose a lightweight cross-attention mechanism with linear complexity, by which a Transformer network is developed to learn efficient and favorable solutions for large-scale VRPs. We also propose a Self-Improved Training (SIT) algorithm that enables direct model training on large-scale VRP instances, bypassing extensive computational overhead for attaining labels. By iterating solution reconstruction, the Transformer network itself can generate improved partial solutions as pseudo-labels to guide the model training. Experimental results on the Travelling Salesman Problem (TSP) and the Capacitated Vehicle Routing Problem (CVRP) with up to 100K nodes indicate that our method consistently achieves superior performance for synthetic and real-world benchmarks, significantly boosting the scalability of NCO methods.'}",https://openreview.net{'value': '/pdf/ba45c4b0897675dfcbfb88a538bcd7c390375a89.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=TWnUgSAWNw,{'value': 'Revisit Large-Scale Image-Caption Data in Pre-training Multimodal Foundation Models'},Zhengfeng Lai; Vasileios Saveris; Chen Chen; Hong-You Chen; Haotian Zhang; Bowen Zhang; Wenze Hu; Juan Lao Tebar; Zhe Gan; Peter Grasch; Meng Cao; Yinfei Yang,~Zhengfeng_Lai1; ~Vasileios_Saveris1; ~Chen_Chen38; ~Hong-You_Chen1; ~Haotian_Zhang3; ~Bowen_Zhang2; ~Wenze_Hu4; ~Juan_Lao_Tebar1; ~Zhe_Gan1; ~Peter_Grasch1; ~Meng_Cao2; ~Yinfei_Yang1,"{'value': ['Multimodal', 'pre-training', 'image-text data']}","{'value': 'Recent advancements in multimodal models highlight the value of rewritten captions for improving performance, yet key challenges remain. For example, while synthetic captions often provide superior quality and image-text alignment, it is not clear whether they can fully replace AltTexts: the role of synthetic captions and their interaction with original web-crawled AltTexts in pre-training is still not well understood. Moreover, different multimodal foundation models may have unique preferences for specific caption formats, but efforts to identify the optimal captions for each model remain limited. In this work, we propose a novel, controllable, and scalable captioning pipeline designed to generate diverse caption formats tailored to various multimodal models. By examining short synthetic captions (SSC) and descriptive synthetic captions (DSC) as case studies, we systematically explore their effects and interactions with AltTexts across models such as CLIP, multimodal LLMs, and diffusion models. Our findings reveal that a hybrid approach that keeps both synthetic captions and AltTexts can outperform the use of synthetic captions alone, improving both alignment and performance, with each model demonstrating preferences for particular caption formats. This comprehensive analysis provides valuable insights into optimizing captioning strategies, thereby advancing the pre-training of multimodal foundation models.'}",https://openreview.net{'value': '/pdf/6d5565251a0f4c5dfbeaa98a8c7c4c22c520d450.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=TVQLu34bdw,{'value': 'Proteina: Scaling Flow-based Protein Structure Generative Models'},Tomas Geffner; Kieran Didi; Zuobai Zhang; Danny Reidenbach; Zhonglin Cao; Jason Yim; Mario Geiger; Christian Dallago; Emine Kucukbenli; Arash Vahdat; Karsten Kreis,~Tomas_Geffner1; ~Kieran_Didi1; ~Zuobai_Zhang1; ~Danny_Reidenbach1; ~Zhonglin_Cao1; ~Jason_Yim1; ~Mario_Geiger1; ~Christian_Dallago1; ~Emine_Kucukbenli1; ~Arash_Vahdat3; ~Karsten_Kreis1,"{'value': ['protein structure generation', 'de novo protein design', 'flow matching', 'fold class conditioning']}","{'value': 'Recently, diffusion- and flow-based generative models of protein structures have emerged as a powerful tool for de novo protein design. Here, we develop *Proteina*, a new large-scale flow-based protein backbone generator that utilizes hierarchical fold class labels for conditioning and relies on a tailored scalable transformer architecture with up to $5\\times$ as many parameters as previous models. To meaningfully quantify performance, we introduce a new set of metrics that directly measure the distributional similarity of generated proteins with reference sets, complementing existing metrics. We further explore scaling training data to millions of synthetic protein structures and explore improved training and sampling recipes adapted to protein backbone generation. This includes fine-tuning strategies like LoRA for protein backbones, new guidance methods like classifier-free guidance and autoguidance for protein backbones, and new adjusted training objectives. Proteina achieves state-of-the-art performance on de novo protein backbone design and produces diverse and designable proteins at unprecedented length, up to 800 residues. The hierarchical conditioning offers novel control, enabling high-level secondary-structure guidance as well as low-level fold-specific generation.'}",https://openreview.net{'value': '/pdf/4b7a263bc7986c92ded70f173e7809c3153445a2.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=Syt4fWwVm1,{'value': 'SpaceGNN: Multi-Space Graph Neural Network for Node Anomaly Detection with Extremely Limited Labels'},Xiangyu Dong; Xingyi Zhang; Lei Chen; Mingxuan Yuan; Sibo Wang,~Xiangyu_Dong2; ~Xingyi_Zhang1; ~Lei_Chen26; ~Mingxuan_Yuan1; ~Sibo_Wang3,"{'value': ['Node Anomaly Detection', 'Graph Neural Network', 'Multiple Spaces']}","{'value': 'Node Anomaly Detection (NAD) has gained significant attention in the deep learning community due to its diverse applications in real-world scenarios. \nExisting NAD methods primarily embed graphs within a single Euclidean space, while overlooking the potential of non-Euclidean spaces. \nBesides, to address the prevalent issue of limited supervision in real NAD tasks, previous methods tend to leverage synthetic data to collect auxiliary information, which is not an effective solution as shown in our experiments.\nTo overcome these challenges, we introduce a novel SpaceGNN model designed for NAD tasks with extremely limited labels. \nSpecifically, we provide deeper insights into a task-relevant framework by empirically analyzing the benefits of different spaces for node representations, based on which, we design a Learnable Space Projection function that effectively encodes nodes into suitable spaces.\nBesides, we introduce the concept of weighted homogeneity, which we empirically and theoretically validate as an effective coefficient during information propagation. This concept inspires the design of the Distance Aware Propagation module. \nFurthermore, we propose the Multiple Space Ensemble module, which extracts comprehensive information for NAD under conditions of extremely limited supervision. Our findings indicate that this module is more beneficial than data augmentation techniques for NAD. Extensive experiments conducted on 9 real datasets confirm the superiority of SpaceGNN, which outperforms the best rival by an average of 8.55% in AUC and 4.31% in F1 scores. Our code is available at https://github.com/xydong127/SpaceGNN.'}",https://openreview.net{'value': '/pdf/69da455b1d233568be17b889dd5a87151a7b9291.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=Sr5XaZzirA,{'value': 'Fast Training of Sinusoidal Neural Fields via Scaling Initialization'},Taesun Yeom; Sangyoon Lee; Jaeho Lee,~Taesun_Yeom1; ~Sangyoon_Lee1; ~Jaeho_Lee3,"{'value': ['sinusoidal neural fields', 'fast training', 'initializations']}","{'value': 'Neural fields are an emerging paradigm that represent data as continuous functions parameterized by neural networks. Despite many advantages, neural fields often have a high training cost, which prevents a broader adoption. In this paper, we focus on a popular family of neural fields, called sinusoidal neural fields (SNFs), and study how it should be initialized to maximize the training speed. We find that the standard initialization scheme for SNFs---designed based on the signal propagation principle---is suboptimal. In particular, we show that by simply multiplying each weight (except for the last layer) by a constant, we can accelerate SNF training by 10$\\times$. This method, coined _weight scaling_, consistently provides a significant speedup over various data domains, allowing the SNFs to train faster than more recently proposed architectures. To understand why the weight scaling works well, we conduct extensive theoretical and empirical analyses which reveal that the weight scaling not only resolves the spectral bias quite effectively but also enjoys a well-conditioned optimization trajectory.'}",https://openreview.net{'value': '/pdf/6ee75f4ad9bb5d19b274ae2c9f041e90239d39b3.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=SoUwcVplq4,{'value': 'ComPC: Completing a 3D Point Cloud with 2D Diffusion Priors'},Tianxin Huang; Zhiwen Yan; Yuyang Zhao; Gim Hee Lee,~Tianxin_Huang1; ~Zhiwen_Yan1; ~Yuyang_Zhao1; ~Gim_Hee_Lee1,"{'value': ['Gaussian Splatting', 'Diffusion Model', 'Point Cloud Completion']}","{'value': '3D point clouds directly collected from objects through sensors are often incomplete due to self-occlusion. Conventional methods for completing these partial point clouds rely on manually organized training sets and are usually limited to object categories seen during training. In this work, we propose a test-time framework for completing partial point clouds across unseen categories without any requirement for training. Leveraging point rendering via Gaussian Splatting, we develop techniques of Partial Gaussian Initialization, Zero-shot Fractal Completion, and Point Cloud Extraction that utilize priors from pre-trained 2D diffusion models to infer missing regions and extract uniform completed point clouds. Experimental results on both synthetic and real-world scanned point clouds demonstrate that our approach outperforms existing methods in completing a variety of objects. Our project page is at \\url{https://tianxinhuang.github.io/projects/ComPC/}.'}",https://openreview.net{'value': '/pdf/07e0e163b5ab2a3918ebbccd045080a0decea42e.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=Sh4FOyZRpv,{'value': 'CTSyn: A Foundation Model for Cross Tabular Data Generation'},Xiaofeng Lin; Chenheng Xu; Matthew Yang; Guang Cheng,~Xiaofeng_Lin1; ~Chenheng_Xu1; ~Matthew_Yang2; ~Guang_Cheng1,"{'value': ['Foundation Model', 'Tabular Data', 'Synthetic Data Generation']}","{'value': 'Generative Foundation Models (GFMs) have achieved remarkable success in producing high-quality synthetic data for images and text. However, their application to tabular data presents significant challenges due to the heterogeneous nature of table features. Current cross-table learning frameworks struggle because they lack a generative model backbone and an effective mechanism to decode heterogeneous feature values. To address these challenges, we propose the Cross-Table Synthesizer (CTSyn), a diffusion-based generative foundation model for tabular data generation. CTSyn comprises two key components. The first is an autoencoder network that consolidates diverse tables into a unified latent space. It dynamically reconstructs table values using a table schema embedding, allowing adaptation to heterogeneous datasets. The second is a conditional latent diffusion model that generates samples from the learned latent space, conditioned on the table schema. Through large-scale pre-training, CTSyn outperforms existing table synthesizers on standard benchmarks in both utility and diversity.  These results position CTSyn as a promising framework for synthetic table generation and lay the groundwork for developing large-scale tabular foundation models.'}",https://openreview.net{'value': '/pdf/dc3e48bf77bb9c090fad224d07460057ca3c6afc.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=SRpq5OBpED,{'value': 'Meta-Dynamical State Space Models for Integrative Neural Data Analysis'},Ayesha Vermani; Josue Nassar; Hyungju Jeon; Matthew Dowling; Il Memming Park,~Ayesha_Vermani1; ~Josue_Nassar1; ~Hyungju_Jeon1; ~Matthew_Dowling2; ~Il_Memming_Park1,"{'value': ['neural dynamics', 'state-space model', 'meta learning']}","{'value': 'Learning shared structure across environments facilitates rapid learning and adaptive behavior in neural systems. This has been widely demonstrated and applied in machine learning to train models that are capable of generalizing to novel settings. However, there has been limited work exploiting the shared structure in neural activity during similar tasks for learning latent dynamics from neural recordings.\nExisting approaches are designed to infer dynamics from a single dataset and cannot be readily adapted to account for statistical heterogeneities across recordings. In this work, we hypothesize that similar tasks admit a corresponding family of\nrelated solutions and propose a novel approach for meta-learning this solution space from task-related neural activity of trained animals. Specifically, we capture the variabilities across recordings on a low-dimensional manifold which concisely parametrizes this family of dynamics, thereby facilitating rapid learning of latent dynamics given new recordings. We demonstrate the efficacy of our approach on\nfew-shot reconstruction and forecasting of synthetic dynamical systems, and neural recordings from the motor cortex during different arm reaching tasks.'}",https://openreview.net{'value': '/pdf/81ce4ee397bbbb2731e5e32563e21df0e7698078.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=SRghq20nGU,{'value': 'Learning the Optimal Stopping for Early Classification within Finite Horizons via Sequential Probability Ratio Test'},Akinori F. Ebihara; Taiki Miyagawa; Kazuyuki Sakurai; Hitoshi Imaoka,~Akinori_F._Ebihara1; ~Taiki_Miyagawa1; ~Kazuyuki_Sakurai1; ~Hitoshi_Imaoka1,"{'value': ['Early Classification of Time Series', 'Sequential Probability Ratio Test']}","{'value': 'Time-sensitive machine learning benefits from Sequential Probability Ratio Test (SPRT), which provides an optimal stopping time for early classification of time series. However, in *finite horizon* scenarios, where input lengths are finite, determining the optimal stopping rule becomes computationally intensive due to the need for *backward induction*, limiting practical applicability. We thus introduce FIRMBOUND, an SPRT-based framework that efficiently estimates the solution to backward induction from training data, bridging the gap between optimal stopping theory and real-world deployment. It employs *density ratio estimation* and *convex function learning* to provide statistically consistent estimators for sufficient statistic and conditional expectation, both essential for solving backward induction; consequently, FIRMBOUND minimizes Bayes risk to reach optimality. Additionally, we present a faster alternative using Gaussian process regression, which significantly reduces training time while retaining low deployment overhead, albeit with potential compromise in statistical consistency. Experiments across independent and identically distributed (i.i.d.), non-i.i.d., binary, multiclass, synthetic, and real-world datasets show that FIRMBOUND achieves optimalities in the sense of Bayes risk and speed-accuracy tradeoff. Furthermore, it advances the tradeoff boundary toward optimality when possible and reduces decision-time variance, ensuring reliable decision-making. Code is included in the supplementary materials.'}",https://openreview.net{'value': '/pdf/a6e2ef3d7cf16b90ec908246b6d41652379c0825.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=SPS6HzVzyt,{'value': 'Context-Parametric Inversion: Why Instruction Finetuning May Not Actually Improve Context Reliance'},Sachin Goyal; Christina Baek; J Zico Kolter; Aditi Raghunathan,~Sachin_Goyal1; ~Christina_Baek2; ~J_Zico_Kolter1; ~Aditi_Raghunathan1,"{'value': ['Instruction finetuning', 'context-vs-parametric reliance']}","{'value': ""Large Language Model's are instruction-finetuned to enhance their ability to follow user instructions and better comprehend input context. Still, they often struggle to follow the input context, especially when it contradicts model's parametric knowledge. This manifests as various failures, such as hallucinations where a model inserts outdated or unwarranted facts into its response. In this work, we observe an intriguing phenomenon: the context reliance of the model decreases as instruction finetuning progresses, $\\textit{despite an initial expected increase}$. We call this phenomenon as the $\\textbf{context-parametric inversion}$. This is surprising, as one would expect instruction tuning to improve the model's ability to follow input instructions.  We observe this behavior on multiple general purpose instruction tuning datasets such as TULU, Alpaca and Ultrachat, across multiple model families like Llama, Mistral and Pythia.  We perform various controlled studies to eliminate some simple hypothesis for this observed behavior and isolate what datapoints cause this counter-intuitive behavior. We then analyze the phenomenon theoretically, to explain why context reliance varies across the trajectory of finetuning. \nWe tie the observed context-parametric inversion to the properties of the finetuning data, which provides us with some potential mitigation strategies that provide limited but insightful gains.""}",https://openreview.net{'value': '/pdf/ed25c0b835eafb8e203ed7104f2e961b7b44c049.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=SOWZ59UyNc,{'value': 'Lean-STaR: Learning to Interleave Thinking and Proving'},Haohan Lin; Zhiqing Sun; Sean Welleck; Yiming Yang,~Haohan_Lin1; ~Zhiqing_Sun1; ~Sean_Welleck1; ~Yiming_Yang1,"{'value': ['Automated Theorem Proving', 'Chain-of-Thought', 'Reinforcement Learning', 'Reasoning']}","{'value': ""Traditional language model-based theorem proving assumes that by training on a sufficient amount of formal proof data, a model will learn to prove theorems. Our key observation is that a wealth of informal information that is not present in formal proofs can be useful for learning to prove theorems. For instance, humans think through steps of a proof, but this thought process is not visible in the resulting code. We present Lean-STaR, a framework for training language models to produce informal thoughts prior to each step of a proof, thereby boosting the model's theorem-proving capabilities. Lean-STaR uses retrospective ground-truth tactics to generate synthetic thoughts for training the language model. At inference time, the trained model directly generates the thoughts prior to the prediction of the tactics in each proof step. Building on the self-taught reasoner framework, we then apply expert iteration to further fine-tune the model on the correct proofs it samples and verifies using the Lean solver. Lean-STaR significantly outperform base models (43.4% → 46.3%, Pass@64). We also analyze the impact of the augmented thoughts on various aspects of the theorem proving process, providing insights into their effectiveness.""}",https://openreview.net{'value': '/pdf/96fac5c0dcd239e7cb127f16caa0f06de24680cd.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=S9GyQUXzee,{'value': 'GROOT-2: Weakly Supervised Multimodal Instruction Following Agents'},Shaofei Cai; Bowei Zhang; Zihao Wang; Haowei Lin; Xiaojian Ma; Anji Liu; Yitao Liang,~Shaofei_Cai2; ~Bowei_Zhang2; ~Zihao_Wang23; ~Haowei_Lin1; ~Xiaojian_Ma1; ~Anji_Liu1; ~Yitao_Liang1,"{'value': ['Reinforcement Learning', 'Open-world Agent', 'Weakly Supervised Learning', 'Goal-Conditioned Policy']}","{'value': 'Developing agents that can follow multimodal instructions remains a fundamental challenge in robotics and AI. Although large-scale pre-training on unlabeled datasets has enabled agents to learn diverse behaviors, these agents often struggle with following instructions. While augmenting the dataset with instruction labels can mitigate this issue, acquiring such high-quality annotations at scale is impractical. \nTo address this issue, we frame the problem as a semi-supervised learning task and introduce \\agent, a multimodal instructable agent trained using a novel approach that combines weak supervision with latent variable models. Our method consists of two key components: constrained self-imitating, which utilizes large amounts of unlabeled demonstrations to enable the policy to learn diverse behaviors, and human intention alignment, which uses a smaller set of labeled demonstrations to ensure the latent space reflects human intentions. \\agent’s effectiveness is validated across four diverse environments, ranging from video games to robotic manipulation, demonstrating its robust multimodal instruction-following capabilities.'}",https://openreview.net{'value': '/pdf/1535226a0ab0823a790f6e0174241d5e6c727dcd.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=S1Bv3068Xt,{'value': 'Can We Trust Embodied Agents? Exploring Backdoor Attacks against Embodied LLM-Based Decision-Making Systems'},Ruochen Jiao; Shaoyuan Xie; Justin Yue; TAKAMI SATO; Lixu Wang; Yixuan Wang; Qi Alfred Chen; Qi Zhu,~Ruochen_Jiao1; ~Shaoyuan_Xie1; ~Justin_Yue1; ~TAKAMI_SATO1; ~Lixu_Wang1; ~Yixuan_Wang1; ~Qi_Alfred_Chen1; ~Qi_Zhu2,"{'value': ['Backdoor attacks', 'Large language models', 'Autonomous agents', 'Robotics']}","{'value': 'Large Language Models (LLMs) have shown significant promise in real-world decision-making tasks for embodied artificial intelligence, especially when fine-tuned to leverage their inherent common sense and reasoning abilities while being tailored to specific applications. However, this fine-tuning process introduces considerable safety and security vulnerabilities, especially in safety-critical cyber-physical systems. In this work, we propose the first comprehensive framework for **B**ackdoor **A**ttacks against **L**LM-based **D**ecision-making systems (BALD) in embodied AI, systematically exploring the attack surfaces and trigger mechanisms. Specifically, we propose three distinct attack mechanisms: *word injection*, *scenario manipulation*, and *knowledge injection*, targeting various components in the LLM-based decision-making pipeline. We perform extensive experiments on representative LLMs (GPT-3.5, LLaMA2, PaLM2) in autonomous driving and home robot tasks, demonstrating the effectiveness and stealthiness of our backdoor triggers across various attack channels, with cases like vehicles accelerating toward obstacles and robots placing knives on beds. Our word and knowledge injection attacks achieve nearly 100\\% success rate across multiple models and datasets while requiring only limited access to the system. Our scenario manipulation attack yields success rates exceeding 65\\%, reaching up to 90\\%, and does not require any runtime system intrusion. We also assess the robustness of these attacks against defenses, revealing their resilience. Our findings highlight critical security vulnerabilities in embodied LLM systems and emphasize the urgent need for safeguarding these systems to mitigate potential risks.'}",https://openreview.net{'value': '/pdf/a1e8d4e52767d3833631f38d6c0ab28da802dd5f.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=RyWypcIMiE,{'value': 'Reframing Structure-Based Drug Design Model Evaluation via Metrics Correlated to Practical Needs'},Bowen Gao; Haichuan Tan; Yanwen Huang; Minsi Ren; Xiao Huang; Wei-Ying Ma; Ya-Qin Zhang; Yanyan Lan,~Bowen_Gao1; ~Haichuan_Tan1; ~Yanwen_Huang2; ~Minsi_Ren1; ~Xiao_Huang4; ~Wei-Ying_Ma2; ~Ya-Qin_Zhang1; ~Yanyan_Lan2,"{'value': ['Stucture-Based Drug Design', 'Model Evaluation', 'Benchmark']}","{'value': 'Recent advances in structure-based drug design (SBDD) have produced surprising results, with models often generating molecules that achieve better Vina docking scores than actual ligands. However, these results are frequently overly optimistic due to the limitations of docking score accuracy and the challenges of wet-lab validation. While generated molecules may demonstrate high QED (drug-likeness) and SA (synthetic accessibility) scores, they often lack true drug-like properties or synthesizability. To address these limitations, we propose a model-level evaluation framework that emphasizes practical metrics aligned with real-world applications. Inspired by recent findings on the utility of generated molecules in ligand-based virtual screening, our framework evaluates SBDD models by their ability to produce molecules that effectively retrieve active compounds from chemical libraries via similarity-based searches. This approach provides a direct indication of therapeutic potential, bridging the gap between theoretical performance and real-world utility. Our experiments reveal that while SBDD models may excel in theoretical metrics like Vina scores, they often fall short in these practical metrics. By introducing this new evaluation strategy, we aim to enhance the relevance and impact of SBDD models for pharmaceutical research and development.'}",https://openreview.net{'value': '/pdf/b3c2d082d95e81dede7b561630da03b24b3bc62b.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=RoN6NnHjn4,{'value': 'Vec2Face: Scaling Face Dataset Generation with Loosely Constrained Vectors'},Haiyu Wu; Jaskirat Singh; Sicong Tian; Liang Zheng; Kevin Bowyer,~Haiyu_Wu1; ~Jaskirat_Singh1; ~Sicong_Tian1; ~Liang_Zheng4; ~Kevin_Bowyer1,"{'value': ['Identity privacy', 'Synthetic face dataset generation', 'Face recognition', 'Image generation']}","{'value': 'This paper studies how to synthesize face images of non-existent persons, to create a dataset that allows effective training of face recognition (FR) models. Besides generating realistic face images, two other important goals are: 1) the ability to generate a large number of distinct identities (inter-class separation), and 2) a proper variation in appearance of the images for each identity (intra-class variation).\nHowever, existing works 1) are typically limited in how many well-separated identities can be generated and 2) either neglect or use an external model for attribute augmentation. We propose Vec2Face, a holistic model that uses only a sampled vector as input and can flexibly generate and control the identity of face images and their attributes. Composed of a feature masked autoencoder and an image decoder, Vec2Face is supervised by face image reconstruction and can be conveniently used in inference. Using vectors with low similarity among themselves as inputs, Vec2Face generates well-separated identities. Randomly perturbing an input identity vector within a small range allows Vec2Face to generate faces of the same identity with proper variation in face attributes. It is also possible to generate images with designated attributes by adjusting vector values with a gradient descent method. Vec2Face has efficiently synthesized as many as 300K identities, whereas 60K is the largest number of identities created in the previous works. As for performance, FR models trained with the generated HSFace datasets, from 10k to 300k identities, achieve state-of-the-art accuracy, from 92\\% to 93.52\\%, on five real-world test sets (\\emph{i.e.}, LFW, CFP-FP, AgeDB-30, CALFW, and CPLFW). For the first time, the FR model trained using our synthetic training set achieves higher accuracy than that trained using a same-scale training set of real face images on the CALFW, IJBB, and IJBC test sets.'}",https://openreview.net{'value': '/pdf/db5c511e99e53aad633050ddf13c87c39a59dfd8.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=RKOAU5ti1y,{'value': 'A Distributional Approach to Uncertainty-Aware Preference Alignment Using Offline Demonstrations'},Sheng Xu; Bo Yue; Hongyuan Zha; Guiliang Liu,~Sheng_Xu8; ~Bo_Yue1; ~Hongyuan_Zha1; ~Guiliang_Liu1,"{'value': ['Preference-based Reinforcement Learning', 'Distributional Reinforcement Learning', 'Uncertainty Awareness']}","{'value': 'Designing reward functions in Reinforcement Learning (RL) often demands significant task-specific expertise. Offline Preference-based Reinforcement Learning (PbRL) provides an effective alternative to address the complexity of reward design by learning policies from offline datasets that contain human preferences between trajectory pairs. Existing offline PbRL studies typically model a reward function by maximizing its likelihood of generating the observed human preferences. However, due to the varying number of samples within the limited dataset, less frequently compared trajectories exhibit greater uncertainty, which potentially leads to unreliable behaviors during reward and policy updates. To solve this issue, in this work, we introduce Uncertainty-Aware PbRL (UA-PbRL) to learn a distributional reward model and a risk-sensitive policy from an offline preference dataset. Our approach employs a Maximum A Posteriori (MAP) objective to update trajectory rewards and incorporates an informative prior to account for the uncertainties. Building upon this reward update, we propose a generative reward model to capture the reward distribution, utilizing the offline distributional Bellman operator and the Conditional Value-at-Risk (CVaR) metric to train a risk-sensitive policy. Experimental results demonstrate that UA-PbRL effectively identifies and avoids states with high uncertainty, facilitating risk-averse behaviors across various tasks, including robot control and language model alignment. The code is available at https://github.com/Jasonxu1225/UA-PbRL.'}",https://openreview.net{'value': '/pdf/f4365795ea0137f11a349b0d5895dd8c92af43e8.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=QowsEic1sc,{'value': 'Linear Combination of Saved Checkpoints Makes Consistency and Diffusion Models Better'},Enshu Liu; Junyi Zhu; Zinan Lin; Xuefei Ning; Shuaiqi Wang; Matthew B. Blaschko; Sergey Yekhanin; Shengen Yan; Guohao Dai; Huazhong Yang; Yu Wang,~Enshu_Liu1; ~Junyi_Zhu1; ~Zinan_Lin1; ~Xuefei_Ning1; ~Shuaiqi_Wang1; ~Matthew_B._Blaschko1; ~Sergey_Yekhanin1; ~Shengen_Yan1; ~Guohao_Dai4; ~Huazhong_Yang2; ~Yu_Wang3,"{'value': ['Model merging', 'consistency model', 'diffusion model']}","{'value': 'Diffusion Models (DM) and Consistency Models (CM) are two types of popular generative models with good generation quality on various tasks. When training DM and CM, intermediate weight checkpoints are not fully utilized and only the last converged checkpoint is used. In this work, we find proper checkpoint merging can significantly improve the training convergence and final performance. Specifically, we propose LCSC, a simple but effective and efficient method to enhance the performance of DM and CM, by combining checkpoints along the training trajectory with coefficients deduced from evolutionary search. We demonstrate the value of LCSC through two use cases: (a) Reducing training cost. With LCSC, we only need to train DM/CM with fewer number of iterations and/or lower batch sizes to obtain comparable sample quality with the fully trained model. For example, LCSC achieves considerable training speedups for CM (23$\\times$ on CIFAR-10 and 15$\\times$ on ImageNet-64). (b) Enhancing pre-trained models. When full training is already done, LCSC can further improve the generation quality or efficiency of the final converged models. For example,  LCSC achieves better FID using 1 number of function evaluation (NFE) than the base model with 2 NFE on consistency distillation, and decreases the NFE of DM from 15 to 9 while maintaining the generation quality. Applying LCSC to large text-to-image models, we also observe clearly enhanced generation quality.'}",https://openreview.net{'value': '/pdf/82a0843d3ed7cae6e97134f3e8e07cee363312d9.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=Qj1KwBZaEI,{'value': 'Intrinsic Dimension Correlation: uncovering nonlinear connections in multimodal representations'},Lorenzo Basile; Santiago Acevedo; Luca Bortolussi; Fabio Anselmi; Alex Rodriguez,~Lorenzo_Basile1; ~Santiago_Acevedo1; ~Luca_Bortolussi1; ~Fabio_Anselmi1; ~Alex_Rodriguez1,"{'value': ['intrinsic dimension', 'nonlinear correlation', 'multimodal representations', 'representation similarity']}","{'value': 'To gain insight into the mechanisms behind machine learning methods, it is crucial to establish connections among the features describing data points. However, these correlations often exhibit a high-dimensional and strongly nonlinear nature, which makes them challenging to detect using standard methods. This paper exploits the entanglement between intrinsic dimensionality and correlation to propose a metric that quantifies the (potentially nonlinear) correlation between high-dimensional manifolds. We first validate our method on synthetic data in controlled environments, showcasing its advantages and drawbacks compared to existing techniques. Subsequently, we extend our analysis to large-scale applications in neural network representations. Specifically, we focus on latent representations of multimodal data, uncovering clear correlations between paired visual and textual embeddings, whereas existing methods struggle significantly in detecting similarity. Our results indicate the presence of highly nonlinear correlation patterns between latent manifolds.'}",https://openreview.net{'value': '/pdf/b58a7f1bb5b50304a81761c3ce8d182fe0eb2c8e.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=QFgbJOYJSE,{'value': 'State Space Models are Provably Comparable to Transformers in Dynamic Token Selection'},Naoki Nishikawa; Taiji Suzuki,~Naoki_Nishikawa1; ~Taiji_Suzuki1,"{'value': ['State Space Model', 'Transformer', 'Nonparametric regression']}","{'value': 'Deep neural networks based on state space models (SSMs) are attracting significant attention in sequence modeling since their computational cost is much smaller than that of Transformers. While the capabilities of SSMs have been demonstrated through experiments in various tasks, theoretical understanding of SSMs is still limited. In particular, most theoretical studies discuss the capabilities of SSM layers without nonlinear layers, and there is a lack of discussion on their combination with nonlinear layers. In this paper, we explore the capabilities of SSMs combined with fully connected neural networks, and show that they are comparable to Transformers in extracting the essential tokens depending on the input. As concrete examples, we consider two synthetic tasks, which are challenging for a single SSM layer, and demonstrate that SSMs combined with nonlinear layers can efficiently solve these tasks.  Furthermore, we study the nonparametric regression task, and prove that the ability of SSMs is equivalent to that of Transformers in estimating functions belonging to a certain class.'}",https://openreview.net{'value': '/pdf/7955d5853157c68ef049e331bb8268ff810d6fd7.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=Q6a9W6kzv5,{'value': 'PhysBench: Benchmarking and Enhancing Vision-Language Models for Physical World Understanding'},Wei Chow; Jiageng Mao; Boyi Li; Daniel Seita; Vitor Campagnolo Guizilini; Yue Wang,~Wei_Chow1; ~Jiageng_Mao1; ~Boyi_Li1; ~Daniel_Seita1; ~Vitor_Campagnolo_Guizilini2; ~Yue_Wang2,"{'value': ['vision-language', 'multi-modal understanding']}","{'value': ""Understanding the physical world is a fundamental challenge in embodied AI, critical for enabling agents to perform complex tasks and operate safely in real-world environments. While Vision-Language Models (VLMs) have shown great promise in reasoning and task planning for embodied agents, their ability to comprehend physical phenomena remains extremely limited.\nTo close this gap, we introduce PhysBench, a comprehensive benchmark designed to evaluate VLMs' physical world understanding capability across a diverse set of tasks. \nPhysBench contains 10,002 entries of interleaved video-image-text data, categorized into four major domains: physical object properties, physical object relationships, physical scene understanding, and physics-based dynamics, further divided into 19 subclasses and 8 distinct capability dimensions.\nOur extensive experiments, conducted on 75 representative VLMs, reveal that while these models excel in common-sense reasoning, they struggle with understanding the physical world---likely due to the absence of physical knowledge in their training data and the lack of embedded physical priors.\nTo tackle the shortfall, we introduce PhysAgent, a novel framework that combines the generalization strengths of VLMs with the specialized expertise of vision models, significantly enhancing VLMs' physical understanding across a variety of tasks, including an 18.4\\% improvement on GPT-4o.\nFurthermore, our results demonstrate that enhancing VLMs' physical world understanding capabilities can help embodied agents such as MOKA.\nWe believe that PhysBench and PhysAgent offer valuable insights and contribute to bridging the gap between VLMs and physical world understanding. [Project Page is here](https://physbench.github.io/)""}",https://openreview.net{'value': '/pdf/03d740bded99ee328106bfc84811201a1dae6c32.pdf'},{'abstract_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=Q1kPHLUbhi,{'value': 'Towards Self-Supervised Covariance Estimation in Deep Heteroscedastic Regression'},Megh Shukla; Aziz Shameem; Mathieu Salzmann; Alexandre Alahi,~Megh_Shukla1; ~Aziz_Shameem1; ~Mathieu_Salzmann1; ~Alexandre_Alahi3,"{'value': ['deep regression', 'heteroscedastic', 'uncertainty', '2-Wasserstein', 'KL-Divergence', 'Negative Log-Likelihood']}","{'value': 'Deep heteroscedastic regression models the mean and covariance of the target distribution through neural networks. The challenge arises from heteroscedasticity, which implies that the covariance is sample dependent and is often unknown. Consequently, recent methods learn the covariance through unsupervised frameworks, which unfortunately yield a trade-off between computational complexity and accuracy. While this trade-off could be alleviated through supervision, obtaining labels for the covariance is non-trivial.\nHere, we study self-supervised covariance estimation in deep heteroscedastic regression. We address two questions: (1) How should we supervise the covariance assuming ground truth is available? (2) How can we obtain pseudo labels in the absence of the ground-truth? We address (1) by analysing two popular measures: the KL Divergence and the 2-Wasserstein distance. Subsequently, we derive an upper bound on the 2-Wasserstein distance between normal distributions with non-commutative covariances that is stable to optimize. We address (2) through a simple neighborhood based heuristic algorithm which results in surprisingly effective pseudo labels for the covariance. Our experiments over a wide range of synthetic and real datasets demonstrate that the proposed 2-Wasserstein bound coupled with pseudo label annotations results in a computationally cheaper yet accurate deep heteroscedastic regression.'}",https://openreview.net{'value': '/pdf/d8c57b3404d90a6681d8c4293f83c6935ad162c6.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=Pz9zFea4MQ,{'value': 'Scalable Benchmarking and Robust Learning for Noise-Free Ego-Motion and 3D Reconstruction from Noisy Video'},Xiaohao Xu; Tianyi Zhang; Shibo Zhao; Xiang Li; Sibo Wang; Yongqi Chen; Ye Li; Bhiksha Raj; Matthew Johnson-Roberson; Sebastian Scherer; Xiaonan Huang,~Xiaohao_Xu1; ~Tianyi_Zhang14; ~Shibo_Zhao1; ~Xiang_Li35; ~Sibo_Wang5; ~Yongqi_Chen3; ~Ye_Li8; ~Bhiksha_Raj1; ~Matthew_Johnson-Roberson3; ~Sebastian_Scherer1; ~Xiaonan_Huang1,"{'value': ['Benchmarking', 'Robustness', 'Neural 3D Reconstruction', 'Ego-Motion Estimation', 'SLAM']}","{'value': 'We aim to redefine robust ego-motion estimation and photorealistic 3D reconstruction by addressing a critical limitation: the reliance on noise-free data in existing models. While such sanitized conditions simplify evaluation, they fail to capture the unpredictable, noisy complexities of real-world environments. Dynamic motion, sensor imperfections, and synchronization perturbations lead to sharp performance declines when these models are deployed in practice, revealing an urgent need for frameworks that embrace and excel under real-world noise.\nTo bridge this gap, we tackle three core challenges: scalable data generation, comprehensive benchmarking, and model robustness enhancement. First, we introduce a scalable noisy data synthesis pipeline that generates diverse datasets simulating complex motion, sensor imperfections, and synchronization errors. Second, we leverage this pipeline to create Robust-Ego3D, a benchmark rigorously designed to expose noise-induced performance degradation, highlighting the limitations of current learning-based methods in ego-motion accuracy and 3D reconstruction quality. Third, we propose Correspondence-guided Gaussian Splatting (CorrGS), a novel method that progressively refines an internal clean 3D representation by aligning noisy observations with rendered RGB-D frames from clean 3D map, enhancing geometric alignment and appearance restoration through visual correspondence.\nExtensive experiments on synthetic and real-world data demonstrate that CorrGS consistently outperforms prior state-of-the-art methods, particularly in scenarios involving rapid motion and dynamic illumination. We will release our code and benchmark to advance robust 3D vision, setting a new standard for ego-motion estimation and high-fidelity reconstruction in noisy environments.'}",https://openreview.net{'value': '/pdf/697a950319cb8d6106329f759a750f08b41d01c3.pdf'},{'abstract_filter': 'Data Synthesis'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=Pnk7vMbznK,{'value': 'Magpie: Alignment Data Synthesis from Scratch by Prompting Aligned LLMs with Nothing'},Zhangchen Xu; Fengqing Jiang; Luyao Niu; Yuntian Deng; Radha Poovendran; Yejin Choi; Bill Yuchen Lin,~Zhangchen_Xu1; ~Fengqing_Jiang1; ~Luyao_Niu1; ~Yuntian_Deng2; ~Radha_Poovendran1; ~Yejin_Choi1; ~Bill_Yuchen_Lin1,"{'value': ['Dataset', 'LLM', 'alignment', 'synthetic', 'supervised fine-tuning']}","{'value': 'High-quality instruction data is critical for aligning large language models (LLMs). Although some models, such as Llama-3-Instruct, have open weights, their alignment data remain private, which hinders the democratization of AI. High human labor costs and a limited, predefined scope for prompting prevent existing open-source data creation methods from scaling effectively, potentially limiting the diversity and quality of public alignment datasets. Is it possible to synthesize high-quality instruction data at scale by extracting it directly from an aligned LLM? We present a self-synthesis method for generating large-scale alignment data named Magpie.  Our key observation is that aligned LLMs like Llama-3-Instruct can generate a user query when we input only the pre-query templates up to the position reserved for user messages, thanks to their auto-regressive nature.  We use this method to prompt Llama-3-Instruct and generate 4 million instructions along with their corresponding responses. We further introduce extensions of Magpie for filtering, generating multi-turn, preference optimization, domain-specific and multilingual datasets. We perform a comprehensive analysis of the Magpie-generated data. To compare Magpie-generated data with other public instruction datasets (e.g., ShareGPT, WildChat, Evol-Instruct, UltraChat, OpenHermes, Tulu-V2-Mix, GenQA), we fine-tune Llama-3-8B-Base with each dataset and evaluate the performance of the fine-tuned models. Our results indicate that using Magpie for supervised fine-tuning (SFT) solely can surpass the performance of previous public datasets utilized for both SFT and preference optimization, such as direct preference optimization with UltraFeedback. We also show that in some tasks, models supervised fine-tuned with Magpie perform comparably to the official Llama-3-8B-Instruct, despite the latter being enhanced with 10 million data points through SFT and subsequent preference optimization. This advantage is evident on alignment benchmarks such as AlpacaEval, ArenaHard, and WildBench.'}",https://openreview.net{'value': '/pdf/50a05182d0e7d75436c8ae66195c7473443b2dd2.pdf'},{'title_filter': 'Data Synthesis'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=PY7KSh29Z8,{'value': 'SONICS: Synthetic Or Not - Identifying Counterfeit Songs'},Md Awsafur Rahman; Zaber Ibn Abdul Hakim; Najibul Haque Sarker; Bishmoy Paul; Shaikh Anowarul Fattah,~Md_Awsafur_Rahman1; ~Zaber_Ibn_Abdul_Hakim1; ~Najibul_Haque_Sarker1; ~Bishmoy_Paul1; ~Shaikh_Anowarul_Fattah1,"{'value': ['deepfake detection', 'fake song detection', 'synthetic song detection', 'efficient model', 'dataset', 'audio processing']}","{'value': 'The recent surge in AI-generated songs presents exciting possibilities and challenges. These innovations necessitate the ability to distinguish between human-composed and synthetic songs to safeguard artistic integrity and protect human musical artistry. Existing research and datasets in fake song detection only focus on singing voice deepfake detection (SVDD), where the vocals are AI-generated but the instrumental music is sourced from real songs. However, these approaches are inadequate for detecting contemporary end-to-end artificial songs where all components (vocals, music, lyrics, and style) could be AI-generated. Additionally, existing datasets lack music-lyrics diversity, long-duration songs, and open-access fake songs. To address these gaps, we introduce SONICS, a novel dataset for end-to-end Synthetic Song Detection (SSD), comprising over 97k songs (4,751 hours) with over 49k synthetic songs from popular platforms like Suno and Udio. Furthermore, we highlight the importance of modeling long-range temporal dependencies in songs for effective authenticity detection, an aspect entirely overlooked in existing methods. To utilize long-range patterns, we introduce SpecTTTra, a novel architecture that significantly improves time and memory efficiency over conventional CNN and Transformer-based models. For long songs, our top-performing variant outperforms ViT by 8% in F1 score, is 38% faster, and uses 26% less memory, while also surpassing ConvNeXt with a 1% F1 score gain, 20% speed boost, and 67% memory reduction.'}",https://openreview.net{'value': '/pdf/ce9f579d7ecfa91b33c5e4a6d7cdb4f9f52c9f8d.pdf'},{'title_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=PJNhZoCjLh,{'value': 'Generalization and Distributed Learning of GFlowNets'},Tiago Silva; Amauri H Souza; Omar Rivasplata; Vikas Garg; Samuel Kaski; Diego Mesquita,~Tiago_Silva4; ~Amauri_H_Souza1; ~Omar_Rivasplata1; ~Vikas_Garg2; ~Samuel_Kaski1; ~Diego_Mesquita1,{'value': ['GFlowNets']},"{'value': 'Conventional wisdom attributes the success of Generative Flow Networks (GFlowNets) to their ability to exploit the compositional structure of the sample space for learning generalizable flow functions (Bengio et al., 2021). Despite the abundance of empirical evidence, formalizing this belief with verifiable non-vacuous statistical guarantees has remained elusive. We address this issue with the first data-dependent generalization bounds for GFlowNets. We also elucidate the negative impact of the state space size on the generalization performance of these models via Azuma-Hoeffding-type oracle PAC-Bayesian inequalities. We leverage our theoretical insights to design a novel distributed learning algorithm for GFlowNets, which we call *Subgraph Asynchronous Learning* (SAL). In a nutshell, SAL utilizes a divide-and-conquer strategy: multiple GFlowNets are trained in parallel on smaller subnetworks of the flow network, and then aggregated with an additional GFlowNet that allocates appropriate flow to each subnetwork.  Our experiments with synthetic and real-world problems demonstrate the benefits of SAL over centralized training in terms of mode coverage and distribution matching.'}",https://openreview.net{'value': '/pdf/f2429f6ecf18246edbff1b53835ba4245331c433.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=P7t2niLbvw,{'value': 'Swift Hydra:  Self-Reinforcing Generative Framework for Anomaly Detection with Multiple Mamba Models'},Nguyen Hoang Khoi Do; Truc Nguyen; Malik Hassanaly; raed alharbi; Jung Taek Seo; My T. Thai,~Nguyen_Hoang_Khoi_Do1; ~Truc_Nguyen1; ~Malik_Hassanaly1; ~raed_alharbi3; ~Jung_Taek_Seo1; ~My_T._Thai2,"{'value': ['Anomaly detection', 'Reinforcement learning', 'Generative AI']}","{'value': 'Despite a plethora of anomaly detection models developed over the years, their ability to generalize to unseen anomalies remains an issue, particularly in critical systems. This paper aims to address this challenge by introducing Swift Hydra, a new framework for training an anomaly detection method based on generative AI and reinforcement learning (RL). Through featuring an RL policy that operates on the latent variables of a generative model, the framework synthesizes novel and diverse anomaly samples that are capable of bypassing a detection model. These generated synthetic samples are, in turn, used to augment the detection model, further improving its ability to handle challenging anomalies. Swift Hydra also incorporates Mamba models structured as a Mixture of Experts (MoE) to enable scalable adaptation of the number of Mamba experts based on data complexity, effectively capturing diverse feature distributions without increasing the model’s inference time. Empirical evaluations on ADBench benchmark demonstrate that Swift Hydra  outperforms other state-of-the-art anomaly detection models while maintaining a relatively short inference time. From these results, our research highlights a new and auspicious paradigm of integrating RL and generative AI for advancing anomaly detection.'}",https://openreview.net{'value': '/pdf/51a3dc18f5194a0572d189f7b73f15a60259abae.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=Ouu3HnIVBc,{'value': 'ADAM: An Embodied Causal Agent in Open-World Environments'},Shu Yu; Chaochao Lu,~Shu_Yu1; ~Chaochao_Lu1,"{'value': ['embodied agent', 'causality', 'large language model', 'interpretability', 'vision language navigation', 'cross-modal application', 'cross-modal information extraction', 'multimodality']}","{'value': 'In open-world environments like Minecraft, existing agents face challenges in continuously learning structured knowledge, particularly causality. These challenges stem from the opacity inherent in black-box models and an excessive reliance on prior knowledge during training, which impair their interpretability and generalization capability. To this end, we introduce ADAM, An emboDied causal Agent in Minecraft, which can autonomously navigate the open world, perceive multimodal context, learn causal world knowledge, and tackle complex tasks through lifelong learning. ADAM is empowered by four key components: 1) an interaction module, enabling the agent to execute actions while recording the interaction processes; 2) a causal model module, tasked with constructing an ever-growing causal graph from scratch, which enhances interpretability and reduces reliance on prior knowledge; 3) a controller module, comprising a planner, an actor, and a memory pool, using the learned causal graph to accomplish tasks; 4) a perception module, powered by multimodal large language models, enabling ADAM to perceive like a human player. Extensive experiments show that ADAM constructs a nearly perfect causal graph from scratch, enabling efficient task decomposition and execution with strong interpretability. Notably, in the modified Minecraft game where no prior knowledge is available, ADAM excels with remarkable robustness and generalization capability. ADAM pioneers a novel paradigm that integrates causal methods and embodied agents synergistically. Our project page is at https://opencausalab.github.io/ADAM.'}",https://openreview.net{'value': '/pdf/6bfe0db3cb5fbdacb1827ee3bab9bd4a55628238.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=OheAR2xrtb,{'value': 'ET-SEED: EFFICIENT TRAJECTORY-LEVEL SE(3) EQUIVARIANT DIFFUSION POLICY'},Chenrui Tie; Yue Chen; Ruihai Wu; Boxuan Dong; Zeyi Li; Chongkai Gao; Hao Dong,~Chenrui_Tie1; ~Yue_Chen8; ~Ruihai_Wu1; ~Boxuan_Dong1; ~Zeyi_Li2; ~Chongkai_Gao1; ~Hao_Dong3,{'value': ['Robotics; Manipulation; Equivariance']},"{'value': 'Imitation learning, e.g., diffusion policy, has been proven effective in various robotic manipulation tasks.\nHowever, extensive demonstrations are required for policy robustness and generalization.\nTo reduce the demonstration reliance, we leverage spatial symmetry and propose ET-SEED, an efficient trajectory-level SE(3) equivariant diffusion model for generating action sequences in complex robot manipulation tasks.\nFurther, previous equivariant diffusion models require the per-step equivariance in the Markov process, making it difficult to learn policy under such strong constraints.\nWe theoretically extend equivariant Markov kernels and simplify the condition of equivariant diffusion process, thereby significantly improving training efficiency for trajectory-level SE(3) equivariant diffusion policy in an end-to-end manner.\nWe evaluate ET-SEED on representative robotic manipulation tasks, involving rigid body, articulated and deformable object.\nExperiments demonstrate superior data efficiency and manipulation proficiency of our proposed method,\nas well as its ability to generalize to unseen configurations with only a few demonstrations. Website: https://et-seed.github.io/'}",https://openreview.net{'value': '/pdf/535efee901d9f09d3414dca14891f72fc7bf7df8.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=OhUoTMxFIH,{'value': 'Robotouille: An Asynchronous Planning Benchmark for LLM Agents'},Gonzalo Gonzalez-Pumariega; Leong Su Yean; Neha Sunkara; Sanjiban Choudhury,~Gonzalo_Gonzalez-Pumariega1; ~Leong_Su_Yean1; ~Neha_Sunkara1; ~Sanjiban_Choudhury3,"{'value': ['benchmark', 'llm', 'agents', 'planning']}","{'value': ""Effective asynchronous planning, or the ability to efficiently reason and plan over states and actions that must happen in parallel or sequentially, is essential for agents that must account for time delays, reason over diverse long-horizon tasks, and collaborate with other agents. While large language model (LLM) agents show promise in high-level task planning, current benchmarks focus primarily on short-horizon tasks and do not evaluate such asynchronous planning capabilities. We introduce Robotouille, a challenging benchmark environment designed to test LLM agents' ability to handle long-horizon asynchronous scenarios. Our synchronous and asynchronous datasets capture increasingly complex planning challenges that go beyond existing benchmarks, requiring agents to manage over-\nlapping tasks and interruptions Our results show that ReAct (gpt-4o) achieves 47% on synchronous tasks but only 11% on asynchronous tasks, highlighting significant room for improvement. We further analyze failure modes, demonstrating the need for LLM agents to better incorporate long-horizon feedback and self-audit their reasoning during task execution.""}",https://openreview.net{'value': '/pdf/f01d2a760117148d4e987620e37e53a26ccdd860.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=Oeb0I3JcVc,{'value': 'Geometry-Aware Approaches for Balancing Performance and Theoretical Guarantees in Linear Bandits'},Yuwei Luo; Mohsen Bayati,~Yuwei_Luo1; ~Mohsen_Bayati1,"{'value': ['Linear bandit', 'Thompson sampling', 'Greedy', 'Data-driven exploration']}","{'value': 'This paper is motivated by recent research in the $d$-dimensional stochastic linear bandit literature, which has revealed an unsettling discrepancy: algorithms like Thompson sampling and Greedy demonstrate promising empirical performance, yet this contrasts with their pessimistic theoretical regret bounds. The challenge arises from the fact that while these algorithms may perform poorly in certain problem instances, they generally excel in typical instances. To address this, we propose a new data-driven technique that tracks the geometric properties of the uncertainty ellipsoid around the main problem parameter. This methodology enables us to formulate a data-driven frequentist regret bound, which incorporates the geometric information, for a broad class of base algorithms, including Greedy, OFUL, and Thompson sampling. This result allows us to identify and ``course-correct"" problem instances in which the base algorithms perform poorly. The course-corrected algorithms achieve the minimax optimal regret of order $\\tilde{\\mathcal{O}}(d\\sqrt{T})$ for a $T$-period decision-making scenario, effectively maintaining the desirable attributes of the base algorithms, including their empirical efficacy. We present simulation results to validate our findings using synthetic and real data.'}",https://openreview.net{'value': '/pdf/83b325bb45438add11efd2a65fabbbb887598945.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=OaoDVZntGe,{'value': 'Inverse Attention Agents for Multi-Agent Systems'},Qian Long; Ruoyan Li; Minglu Zhao; Tao Gao; Demetri Terzopoulos,~Qian_Long1; ~Ruoyan_Li1; ~Minglu_Zhao1; ~Tao_Gao1; ~Demetri_Terzopoulos1,"{'value': ['multi-agent system', 'Theory of mind agent']}","{'value': ""A major challenge for Multi-Agent Systems (MAS) is enabling agents to adapt dynamically to diverse environments in which opponents and teammates may continually change. Agents trained using conventional methods tend to excel only within the confines of their training cohorts; their performance drops significantly when confronting unfamiliar agents. To address this shortcoming, we introduce Inverse Attention Agents that adopt concepts from the Theory of Mind (ToM) implemented algorithmically using an attention mechanism trained in an end-to-end manner. Crucial to determining the final actions of these agents, the weights in their attention model explicitly represent attention to different goals. We furthermore propose an inverse attention network that deduces the ToM of agents based on observations and prior actions. The network infers the attentional states of other agents, thereby refining the attention weights to adjust the agent's final action. We conduct experiments in a continuous environment, tackling demanding tasks encompassing cooperation, competition, and a blend of both. They demonstrate that the inverse attention network successfully infers the attention of other agents, and that this information improves agent performance. Additional human experiments show that, compared to baseline agent models, our inverse attention agents exhibit superior cooperation with humans and better emulate human behaviors.""}",https://openreview.net{'value': '/pdf/3a5cba611f316d02e2767025a0b698800b6c4e75.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=OZbFRNhpwr,{'value': 'SPA-BENCH: A COMPREHENSIVE BENCHMARK FOR SMARTPHONE AGENT EVALUATION'},Jingxuan Chen; Derek Yuen; Bin Xie; Yuhao Yang; Gongwei Chen; Zhihao Wu; Li Yixing; Xurui Zhou; Weiwen Liu; Shuai Wang; Kaiwen Zhou; Rui Shao; Liqiang Nie; Yasheng Wang; Jianye HAO; Jun Wang; Kun Shao,~Jingxuan_Chen2; ~Derek_Yuen1; ~Bin_Xie3; ~Yuhao_Yang5; ~Gongwei_Chen1; ~Zhihao_Wu7; ~Li_Yixing2; ~Xurui_Zhou1; ~Weiwen_Liu1; ~Shuai_Wang34; ~Kaiwen_Zhou2; ~Rui_Shao1; ~Liqiang_Nie2; ~Yasheng_Wang1; ~Jianye_HAO1; ~Jun_Wang2; ~Kun_Shao1,"{'value': ['AI Agent', 'LLM', 'MLLM', 'Benchmark', 'Smartphone Control']}","{'value': 'Smartphone agents are increasingly important for helping users control devices efficiently, with (Multimodal) Large Language Model (MLLM)-based approaches emerging as key contenders. Fairly comparing these agents is essential but challenging, requiring a varied task scope, the integration of agents with different implementations, and a generalisable evaluation pipeline to assess their strengths and weaknesses. In this paper, we present SPA-Bench, a comprehensive SmartPhone Agent Benchmark designed to evaluate (M)LLM-based agents in an interactive environment that simulates real-world conditions. SPA-Bench offers three key contributions: (1) A diverse set of tasks covering system and third-party apps in both English and Chinese, focusing on features commonly used in daily routines; (2) A plug-and-play framework enabling real-time agent interaction with Android devices, integrating over ten agents with the flexibility to add more; (3) A novel evaluation pipeline that automatically assesses agent performance across multiple dimensions, encompassing seven metrics related to task completion and resource consumption. Our extensive experiments across tasks and agents reveal challenges like interpreting mobile user interfaces, action grounding, memory retention, and execution costs. We propose future research directions to ease these difficulties, moving closer to real-world smartphone agent applications.'}",https://openreview.net{'value': '/pdf/d6e724ea54d8555e1cf78adf21853e302b21f716.pdf'},{'abstract_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=OUuhwVsk9Z,{'value': 'Bootstrapping Language-Guided Navigation Learning with Self-Refining Data Flywheel'},Zun Wang; Jialu Li; Yicong Hong; Songze Li; Kunchang Li; Shoubin Yu; Yi Wang; Yu Qiao; Yali Wang; Mohit Bansal; Limin Wang,~Zun_Wang1; ~Jialu_Li2; ~Yicong_Hong1; ~Songze_Li4; ~Kunchang_Li1; ~Shoubin_Yu1; ~Yi_Wang19; ~Yu_Qiao1; ~Yali_Wang1; ~Mohit_Bansal2; ~Limin_Wang1,"{'value': ['vision-and-language navigation', 'data flywheel', 'dataset curation']}","{'value': 'Creating high-quality data for training robust language-instructed agents is a long-lasting challenge in embodied AI. In this paper, we introduce a Self-Refining Data Flywheel (SRDF) that generates high-quality and large-scale navigational instruction-trajectory pairs by iteratively refining the data pool through the collaboration between two models, the instruction generator and the navigator, without any human-in-the-loop annotation. \nSpecifically, SRDF starts with using a base generator to create an initial data pool for training a base navigator, followed by applying the trained navigator to filter the data pool. This leads to higher-fidelity data to train a better generator, which can, in turn, produce higher-quality data for training the next-round navigator. Such a flywheel establishes a data self-refining process, yielding a continuously improved and highly effective dataset for large-scale language-guided navigation learning. Our experiments demonstrate that after several flywheel rounds, the navigator elevates the performance boundary from 70\\% to 78\\% SPL on the classic R2R test set, surpassing human performance (76\\%) for the first time. \nMeanwhile, this process results in a superior generator, evidenced by a SPICE increase from 23.5 to 26.2, better than all previous VLN instruction generation methods. Finally, we demonstrate the scalability of our method through increasing environment and instruction diversity, and\nthe generalization ability of our pre-trained navigator across various downstream navigation tasks, surpassing state-of-the-art methods by a large margin in all cases.'}",https://openreview.net{'value': '/pdf/e41310e1909e7cb381027db8c646088385e62597.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=OTFKVkxSlL,{'value': 'DoF: A Diffusion Factorization Framework for Offline Multi-Agent Reinforcement Learning'},Chao Li; Ziwei Deng; Chenxing Lin; Wenqi Chen; Yongquan Fu; Weiquan Liu; Chenglu Wen; Cheng Wang; Siqi Shen,~Chao_Li29; ~Ziwei_Deng2; ~Chenxing_Lin1; ~Wenqi_Chen5; ~Yongquan_Fu2; ~Weiquan_Liu1; ~Chenglu_Wen1; ~Cheng_Wang2; ~Siqi_Shen5,{'value': ['multi-agent reinforcement learning; Diffusion Models;   Offline reinforcement learning']},"{'value': 'Diffusion models have been widely adopted in image and language generation and are now being applied to reinforcement learning. However, the application of diffusion models in offline cooperative Multi-Agent Reinforcement Learning (MARL) remains limited. Although existing studies explore this direction, they suffer from scalability or poor cooperation issues due to the lack of design principles for diffusion-based MARL. The Individual-Global-Max (IGM) principle is a popular design principle for cooperative MARL. By satisfying this principle, MARL algorithms achieve remarkable performance with good scalability. In this work, we extend the IGM principle to the Individual-Global-identically-Distributed (IGD) principle. This principle stipulates that the generated outcome of a multi-agent diffusion model should be identically distributed as the collective outcomes from multiple individual-agent diffusion models. We propose DoF, a diffusion factorization framework for Offline MARL. It uses noise factorization function to factorize a centralized diffusion model into multiple diffusion models. We theoretically show that the noise factorization functions satisfy the IGD principle. Furthermore, DoF uses data factorization function to model the complex relationship among data generated by multiple diffusion models. Through extensive experiments, we demonstrate the effectiveness of DoF.  The source code is available at [https://github.com/xmu-rl-3dv/DoF](https://github.com/xmu-rl-3dv/DoF).'}",https://openreview.net{'value': '/pdf/8e0439c926a047e42ccdd76c5172608e3516c4df.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=OQqNieeivq,{'value': 'KaSA: Knowledge-Aware Singular-Value Adaptation of Large Language Models'},Fan Wang; Juyong Jiang; Chansung Park; Sunghun Kim; Jing Tang,~Fan_Wang20; ~Juyong_Jiang3; ~Chansung_Park1; ~Sunghun_Kim1; ~Jing_Tang5,"{'value': ['Large Language Models', 'Parameter-efficient Fine-tuning', 'Singular Value Decomposition']}","{'value': ""The increasing sizes of large language models (LLMs) result in significant computational overhead and memory usage when adapting these models to specific tasks or domains. Various parameter-efficient fine-tuning (PEFT) methods have been devised to mitigate these challenges by training a small set of parameters for the task-specific updates of the model weights. Among PEFT methods, LoRA stands out for its simplicity and efficiency, inspiring the development of a series of variants. However, LoRA and its successors disregard the knowledge that is noisy or irrelevant to the targeted task, detrimentally impacting model performance and leading to suboptimality. To address this limitation, we introduce Knowledge-aware Singular-value Adaptation (KaSA), a PEFT method that leverages singular value decomposition (SVD) with knowledge-aware singular values to dynamically activate knowledge based on its relevance to the task at hand. We conduct extensive experiments across a range of LLMs on tasks spanning natural language understanding (NLU), generation (NLG), instruction following, and commonsense reasoning. The experimental results demonstrate that KaSA consistently outperforms FFT and 14 popular PEFT baselines across 16 benchmarks and 4 synthetic datasets, underscoring our method's efficacy and adaptability. The source code of our method is available at https://github.com/juyongjiang/KaSA.""}",https://openreview.net{'value': '/pdf/b2eb4cdfc0bad2bb2e790450def3b099049688b2.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=OJd3ayDDoF,{'value': 'OpenHands: An Open Platform for AI Software Developers as Generalist Agents'},Xingyao Wang; Boxuan Li; Yufan Song; Frank F. Xu; Xiangru Tang; Mingchen Zhuge; Jiayi Pan; Yueqi Song; Bowen Li; Jaskirat Singh; Hoang H. Tran; Fuqiang Li; Ren Ma; Mingzhang Zheng; Bill Qian; Yanjun Shao; Niklas Muennighoff; Yizhe Zhang; Binyuan Hui; Junyang Lin; Robert Brennan; Hao Peng; Heng Ji; Graham Neubig,~Xingyao_Wang1; ~Boxuan_Li3; ~Yufan_Song2; ~Frank_F._Xu1; ~Xiangru_Tang2; ~Mingchen_Zhuge2; ~Jiayi_Pan1; ~Yueqi_Song1; ~Bowen_Li8; ~Jaskirat_Singh1; ~Hoang_H._Tran1; ~Fuqiang_Li1; ~Ren_Ma1; ~Mingzhang_Zheng2; ~Bill_Qian1; ~Yanjun_Shao1; ~Niklas_Muennighoff1; ~Yizhe_Zhang2; ~Binyuan_Hui1; ~Junyang_Lin1; ~Robert_Brennan1; ~Hao_Peng4; ~Heng_Ji3; ~Graham_Neubig1,"{'value': ['AI agents', 'evaluation', 'infrastructure', 'benchmark']}","{'value': 'Software is one of the most powerful tools that we humans have at our disposal; it allows a skilled programmer to interact with the world in complex and profound ways. At the same time, thanks to improvements in large language models (LLMs), there has also been a rapid development in AI agents that interact with and effect change in their surrounding environments. In this paper, we introduce OpenHands, a platform for the development of powerful and flexible AI agents that interact with the world in similar ways to a human developer: by writing code, interacting with a command line, and browsing the web. We describe how the platform allows for the implementation of new agents, utilization of various LLMs, safe interaction with sandboxed environments for code execution, and incorporation of evaluation benchmarks. Based on our currently incorporated benchmarks, we perform an evaluation of agents over 13 challenging tasks, including software engineering (e.g., SWE-Bench) and web browsing (e.g., WebArena), amongst others. Released under the permissive MIT license, OpenHands is a community project spanning academia and industry with more than 2K contributions from over 186 contributors in less than six months of development, and will improve going forward.'}",https://openreview.net{'value': '/pdf/95990590797cff8b93c33af989ecf4ac58bde9bb.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=OGfyzExd69,{'value': 'Procedural Synthesis of Synthesizable Molecules'},Michael Sun; Alston Lo; Minghao Guo; Jie Chen; Connor W. Coley; Wojciech Matusik,~Michael_Sun1; ~Alston_Lo1; ~Minghao_Guo1; ~Jie_Chen1; ~Connor_W._Coley1; ~Wojciech_Matusik2,"{'value': ['molecular design', 'synthesis planning', 'tree generation', 'graph generation']}","{'value': ""Designing synthetically accessible molecules and recommending analogs to unsynthesizable molecules are important problems for accelerating molecular discovery. We reconceptualize both problems using ideas from program synthesis. Drawing inspiration from syntax-guided synthesis approaches, we decouple the syntactic skeleton from the semantics of a synthetic tree to create a bilevel framework for reasoning about the combinatorial space of synthesis pathways. Given a molecule we aim to generate analogs for, we iteratively refine its skeletal characteristics via Markov Chain Monte Carlo simulations over the space of syntactic skeletons. Given a black-box oracle to optimize, we formulate a joint design space over syntactic templates and molecular descriptors and introduce evolutionary algorithms that optimize both syntactic and semantic dimensions synergistically. Our key insight is that once the syntactic skeleton is set, we can amortize over the search complexity of deriving the program's semantics by training policies to fully utilize the fixed horizon Markov Decision Process imposed by the syntactic template. We demonstrate performance advantages of our bilevel framework for synthesizable analog generation and synthesizable molecule design. Notably, our approach offers the user explicit control over the resources required to perform synthesis and biases the design space towards simpler solutions, making it particularly promising for autonomous synthesis platforms. Supporting code is at https://github.com/shiningsunnyday/SynthesisNet.""}",https://openreview.net{'value': '/pdf/e5c3a0b2b9a2bf66514d43d18cd1a4cb5e4467d4.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=O0sQ9CPzai,{'value': 'TPO: Aligning Large Language Models with Multi-branch & Multi-step Preference Trees'},Weibin Liao; Xu Chu; Yasha Wang,~Weibin_Liao1; ~Xu_Chu1; ~Yasha_Wang3,"{'value': ['Reinforcement Learning from Human Feedback', 'Language Models', 'Preferences Learning']}","{'value': 'In the domain of complex reasoning tasks, such as mathematical reasoning, recent advancements have proposed the use of Direct Preference Optimization (DPO) to suppress output of dispreferred responses, thereby enhancing the long-chain reasoning capabilities of large language models (LLMs). To this end, these studies employed LLMs to generate preference trees via Tree-of-thoughts (ToT) and sample the paired preference responses required by the DPO algorithm. However, the DPO algorithm based on binary preference optimization is unable to learn multiple responses with varying degrees of preference/dispreference that provided by the preference trees, resulting in incomplete preference learning. In this work, we introduce Tree Preference Optimization (TPO), that does not sample paired preference responses from the preference tree; instead, it directly learns from the entire preference tree during the fine-tuning. Specifically, TPO formulates the language model alignment as a Preference List Ranking problem, where the policy can potentially learn more effectively from a ranked preference list of responses given the prompt.  In addition, to further assist LLMs in identifying discriminative steps within long-chain reasoning and increase the relative reward margin in the preference list, TPO utilizes Adaptive Step Reward to adjust the reward values of each step in trajectory for performing fine-grained preference optimization. We carry out extensive experiments on mathematical reasoning tasks to evaluate TPO. The experimental results indicate that TPO consistently outperforms DPO across five public large language models on four datasets.'}",https://openreview.net{'value': '/pdf/bb61dae7d0705d0846f3bdec2ed9bec9752f7a21.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=NxyfSW6mLK,{'value': 'REGENT: A Retrieval-Augmented Generalist Agent That Can Act In-Context in New Environments'},Kaustubh Sridhar; Souradeep Dutta; Dinesh Jayaraman; Insup Lee,~Kaustubh_Sridhar1; ~Souradeep_Dutta2; ~Dinesh_Jayaraman2; ~Insup_Lee1,"{'value': ['Generalist Agent', 'Retrieval', 'In-Context Learning', 'VLA', 'Imitation Learning', 'Reinforcement Learning']}","{'value': ""Building generalist agents that can rapidly adapt to new environments is a key challenge for deploying AI in the digital and real worlds. Is scaling current agent architectures the most effective way to build generalist agents? We propose a novel approach to pre-train relatively small policies on relatively small datasets and adapt them to unseen environments via in-context learning, without any finetuning. Our key idea is that retrieval offers a powerful bias for fast adaptation. Indeed, we demonstrate that even a simple retrieval-based 1-nearest neighbor agent offers a surprisingly strong baseline for today's state-of-the-art generalist agents. From this starting point, we construct a semi-parametric agent, REGENT, that trains a transformer-based policy on sequences of queries and retrieved neighbors. REGENT can generalize to unseen robotics and game-playing environments via retrieval augmentation and in-context learning, achieving this with up to 3x fewer parameters and up to an order-of-magnitude fewer pre-training datapoints, significantly outperforming today's state-of-the-art generalist agents.""}",https://openreview.net{'value': '/pdf/7de864552f0638515d915497f208b6f5185bb64b.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=Nvw2szDdmI,{'value': 'Direct Distributional Optimization for Provable Alignment of Diffusion Models'},Ryotaro Kawata; Kazusato Oko; Atsushi Nitanda; Taiji Suzuki,~Ryotaro_Kawata1; ~Kazusato_Oko1; ~Atsushi_Nitanda1; ~Taiji_Suzuki1,"{'value': ['Diffusion models', 'Optimization']}","{'value': ""We introduce a novel alignment method for diffusion models from distribution optimization perspectives while providing rigorous convergence guarantees.\nWe first formulate the problem as a generic regularized loss minimization over probability distributions and directly optimize the distribution using the Dual Averaging method.\nNext, we enable sampling from the learned distribution by approximating its score function via Doob's $h$-transform technique.\nThe proposed framework is supported by rigorous convergence guarantees and an end-to-end bound on the sampling error, which imply that when the original distribution's score is known accurately, the complexity of sampling from shifted distributions is independent of isoperimetric conditions.\nThis framework is broadly applicable to general distribution optimization problems, including alignment tasks in Reinforcement Learning with Human Feedback (RLHF), Direct Preference Optimization (DPO), and Kahneman-Tversky Optimization (KTO). We empirically validate its performance on synthetic and image datasets using the DPO objective.""}",https://openreview.net{'value': '/pdf/5f0520601f52191296fff972498931a757fbe5ef.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=NvDRvtrGLo,{'value': 'TRENDy: Temporal Regression of Effective Nonlinear Dynamics'},Matt Ricci; Guy Pelc; Zoe Piran; Noa Moriel; Mor Nitzan,~Matt_Ricci1; ~Guy_Pelc1; ~Zoe_Piran1; ~Noa_Moriel1; ~Mor_Nitzan1,"{'value': ['dynamical systems; neural ODEs', 'representation learning']}","{'value': ""Spatiotemporal dynamics pervade the natural sciences, from the morphogen dynamics underlying patterning in animal pigmentation to the protein waves controlling cell division. A central challenge lies in understanding how controllable parameters induce qualitative changes in system behavior called bifurcations. This endeavor is particularly difficult in realistic settings where governing partial differential equations (PDEs) are unknown and data is limited and noisy. To address this challenge, we propose TRENDy (Temporal Regression of Effective Nonlinear Dynamics), an equation-free approach to learning low-dimensional, predictive models of spatiotemporal dynamics. TRENDy first maps input data to a low-dimensional space of effective dynamics through a cascade of multiscale filtering operations. Our key insight is the recognition that these effective dynamics can be fit by a neural ordinary differential equation (NODE) having the same parameter space as the input PDE. The preceding filtering operations strongly regularize the phase space of the NODE, making TRENDy significantly more robust to noise compared to existing methods. We train TRENDy to predict the effective dynamics of synthetic and real data representing dynamics from across the physical and life sciences. We then demonstrate how we can automatically locate both Turing and Hopf bifurcations in unseen regions of parameter space. We finally apply our method to the analysis of spatial patterning of the ocellated lizard through development. We found that TRENDy's predicted effective state not only accurately predicts spatial changes over time but also identifies distinct pattern features unique to different anatomical regions, such as the tail, neck, and body--an insight that highlights the potential influence of surface geometry on reaction-diffusion mechanisms and their role in driving spatially varying pattern dynamics.""}",https://openreview.net{'value': '/pdf/79bb2478098db04bc2f1d00a919f80e55d70bc9d.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=NsFZZU9gvk,{'value': 'Aligned LLMs Are Not Aligned Browser Agents'},Priyanshu Kumar; Elaine Lau; Saranya Vijayakumar; Tu Trinh; Elaine T Chang; Vaughn Robinson; Shuyan Zhou; Matt Fredrikson; Sean M. Hendryx; Summer Yue; Zifan Wang,~Priyanshu_Kumar1; ~Elaine_Lau1; ~Saranya_Vijayakumar1; ~Tu_Trinh1; ~Elaine_T_Chang1; ~Vaughn_Robinson1; ~Shuyan_Zhou1; ~Matt_Fredrikson1; ~Sean_M._Hendryx1; ~Summer_Yue2; ~Zifan_Wang1,"{'value': ['LLM', 'agents', 'red teaming', 'safety', 'adversarial robustness', 'alignment', 'jailbreak']}","{'value': 'For safety reasons, large language models (LLMs) are trained to refuse harmful user instructions, such as assisting dangerous activities. We study an open question in this work: does the desired safety refusal, typically enforced in chat contexts, generalize to non-chat and agentic use cases? Unlike chatbots, LLM agents equipped with general-purpose tools, such as web browsers and mobile devices, can directly influence the real world, making it even more crucial to refuse harmful instructions. In this work, we primarily focus on red-teaming browser\nagents – LLMs that leverage information via web browsers. To this end, we introduce Browser Agent Red teaming Toolkit (BrowserART), a comprehensive test suite designed specifically for red-teaming browser agents. BrowserART consists of 100 diverse browser-related harmful behaviors (including original behaviors and ones sourced from HarmBench (Mazeika et al., 2024) and AirBench 2024 (Zeng et al., 2024b)) across both synthetic and real websites. Our empirical study on state-of-the-art browser agents reveals that while the backbone LLM refuses harmful instructions as a chatbot, the corresponding agent does not. Moreover, attack methods designed to jailbreak refusal-trained LLMs in the chat settings transfer effectively to browser agents. With human rewrites, GPT-4o and o1-preview -based browser agents pursued 98 and 63 harmful behaviors (out of 100), respectively. Therefore, simply ensuring LLM’s refusal to harmful instruc-\ntions in chats is not sufficient to ensure that the downstream agents are safe. We publicly release BrowserART and call on LLM developers, policymakers, and agent developers to collaborate on improving agent safety.'}",https://openreview.net{'value': '/pdf/6fc1bb1bbec779396441520dc8eed960fc3db5a1.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=NiNIthntx7,{'value': 'RefactorBench: Evaluating Stateful Reasoning in Language Agents Through Code'},Dhruv Gautam; Spandan Garg; Jinu Jang; Neel Sundaresan; Roshanak Zilouchian Moghaddam,~Dhruv_Gautam1; ~Spandan_Garg1; ~Jinu_Jang1; ~Neel_Sundaresan3; ~Roshanak_Zilouchian_Moghaddam1,"{'value': ['Language Agents', 'Benchmarks', 'Code Generation', 'Reasoning', 'State-Awareness', 'Refactoring', 'Long-Horizon Tasks', 'Knowledge Representation']}","{'value': 'Recent advances in language model (LM) agents and function calling have enabled autonomous, feedback-driven systems to solve problems across various digital domains. To better understand the unique limitations of LM agents, we introduce RefactorBench, a benchmark consisting of 100 large handcrafted multi-file refactoring tasks in popular open-source repositories. Solving tasks within RefactorBench requires thorough exploration of dependencies across multiple files and strong adherence to relevant instructions. Every task is defined by 3 natural language instructions of varying specificity and is mutually exclusive, allowing for the creation of longer combined tasks on the same repository. Baselines on RefactorBench reveal that current LM agents struggle with simple compositional tasks, solving only 22\\% of tasks with base instructions, in contrast to a human developer with short time constraints solving 87\\%. Through trajectory analysis, we identify various unique failure modes of LM agents, and further explore the failure mode of tracking past actions. By adapting a baseline agent to condition on representations of state, we achieve a 43.9\\% improvement in solving RefactorBench tasks. We further extend our state-aware approach to encompass entire digital environments and outline potential directions for future research. RefactorBench aims to support the study of LM agents by providing a set of real-world, multi-hop tasks within the realm of code.'}",https://openreview.net{'value': '/pdf/a0d0ffeac97aadde5bf047355b9feb5991316d6b.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=NfCEVihkdC,{'value': 'Measuring And Improving Persuasiveness Of Large Language Models'},Somesh Kumar Singh; Yaman Kumar Singla; Harini S I; Balaji Krishnamurthy,~Somesh_Kumar_Singh2; ~Yaman_Kumar_Singla1; ~Harini_S_I1; ~Balaji_Krishnamurthy1,"{'value': ['llm', 'transsuasion', 'persuasion', 'PersuasionArena', 'PersuasionBench', 'advertising', 'marketing', 'behavioral science', 'behavior in the wild']}","{'value': ""Large Language Models (LLMs) are increasingly being used in workflows involving generating content to be consumed by humans (*e.g.,* marketing) and also in directly interacting with humans (*e.g.,* through chatbots). The development of such systems that are capable of generating verifiably persuasive messages presents both opportunities and challenges for society. On the one hand, such systems could positively impact domains like advertising and social good, such as addressing drug addiction, and on the other, they could be misused for spreading misinformation and shaping political opinions. To channel LLMs' impact on society, we need to develop systems to measure and benchmark their persuasiveness. With this motivation, we introduce **PersuasionBench** and **PersuasionArena**, the first large-scale benchmark and arena containing a battery of tasks to automatically measure the simulative and generative persuasion abilities of large language models. We introduce **transsuasion** (trans = carrying across, suasion = the act of persuading), a novel task of transforming non-persuasive language into persuasive content while preserving other factors determining persuasiveness (sender, receiver, time, and channel). Our findings indicate that the simulative persuasion capabilities of LLMs are barely above random; however, their generative persuasion capabilities are much better. For instance, GPT-4o loses only 36% of the time when playing against the best human persuader. Further, we find that LLMs' persuasiveness correlates positively with model size, but smaller models can also be made to have a higher persuasiveness than much larger models. Notably, targeted training using synthetic and natural datasets significantly enhances smaller models' persuasive capabilities, challenging scale-dependent assumptions. Our findings carry key implications for both model developers and policymakers. For instance, while the EU AI Act and California's SB-1047 aim to regulate AI models based on the number of floating point operations, we demonstrate that simple metrics like this alone fail to capture the full scope of AI's societal impact. We invite the community to explore and contribute to PersuasionArena and PersuasionBench, available at [behavior-in-the-wild.github.io/measure-persuasion](https://behavior-in-the-wild.github.io/measure-persuasion), to advance our understanding of AI-driven persuasion and its societal implications.""}",https://openreview.net{'value': '/pdf/2c183eaa96bc41fbe46d1228a7dfa063568e2bb1.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=NY7aEek0mi,{'value': 'On the Expressive Power of Sparse Geometric MPNNs'},Yonatan Sverdlov; Nadav Dym,~Yonatan_Sverdlov1; ~Nadav_Dym1,"{'value': ['WL', 'GWL', 'GNNS', 'geometric GNNS', 'point clouds', 'completness']}","{'value': 'Motivated by applications in chemistry and other sciences, we study the expressive\npower of message-passing neural networks for geometric graphs, whose node\nfeatures correspond to 3-dimensional positions. Recent work has shown that such\nmodels can separate generic pairs of non-isomorphic geometric graphs, though they\nmay fail to separate some rare and complicated instances. However, these results\nassume a fully connected graph, where each node possesses complete knowledge\nof all other nodes. In contrast, often, in application, every node only possesses\nknowledge of a small number of nearest neighbors.\nThis paper shows that generic pairs of non-isomorphic geometric graphs can\nbe separated by message-passing networks with rotation equivariant features as\nlong as the underlying graph is connected. When only invariant intermediate\nfeatures are allowed, generic separation is guaranteed for generically globally\nrigid graphs. We introduce a simple architecture, EGENNET, which achieves our\ntheoretical guarantees and compares favorably with alternative architecture on\nsynthetic and chemical benchmarks'}",https://openreview.net{'value': '/pdf/1bcb29bda5432b26905d60507bfcbe18985efaa7.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=NPSZ7V1CCY,{'value': 'Zero-shot Imputation with Foundation Inference Models for Dynamical Systems'},Patrick Seifner; Kostadin Cvejoski; Antonia Körner; Ramses J Sanchez,~Patrick_Seifner1; ~Kostadin_Cvejoski1; ~Antonia_Körner1; ~Ramses_J_Sanchez1,"{'value': ['Zero-shot imputation', 'foundation models', 'time series imputation', 'dynamical systems', 'amortized inference', 'zero-shot interpolation', 'foundation models for time series']}","{'value': 'Dynamical systems governed by ordinary differential equations (ODEs) serve as models for a vast number of natural and social phenomena. In this work, we offer a fresh perspective on the classical problem of imputing missing time series data, whose underlying dynamics are assumed to be determined by ODEs. Specifically, we revisit ideas from amortized inference and neural operators, and propose a novel supervised learning framework for *zero-shot time series imputation*, through parametric functions satisfying some (hidden) ODEs. Our proposal consists of two components. First, a broad probability distribution over the space of ODE solutions, observation times and noise mechanisms, with which we generate a large, synthetic dataset of (hidden) ODE solutions, along with their noisy and sparse observations. Second, a neural recognition model that is trained *offline*, to map the generated time series onto the spaces of initial conditions and time derivatives of the (hidden) ODE solutions, which we then integrate to impute the missing data. We empirically demonstrate that *one and the same* (pretrained) recognition model can perform zero-shot imputation across 63 distinct time series with missing values, each sampled from widely different dynamical systems. Likewise, we demonstrate that it can perform zero-shot imputation of missing high-dimensional data in 10 vastly different settings, spanning human motion, air quality, traffic and electricity studies, as well as Navier-Stokes simulations — *without requiring any fine-tuning*. What is more, our proposal often outperforms state-of-the-art methods, which are trained on the target datasets.\n\nOur pretrained model, repository and tutorials are available online.'}",https://openreview.net{'value': '/pdf/29abfc8d61477edf7b2143bbcf7e60742531b413.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=NGB6YNnO5o,{'value': 'Generalization in VAE and Diffusion Models: A Unified Information-Theoretic Analysis'},Qi CHEN; Jierui Zhu; Florian Shkurti,~Qi_CHEN6; ~Jierui_Zhu1; ~Florian_Shkurti1,{'value': ['Generalization bounds; information theory; generative models; VAE; diffusion models;']},"{'value': ""Despite the empirical success of Diffusion Models (DMs) and Variational Autoencoders (VAEs), their generalization performance remains theoretically underexplored, especially lacking a full consideration of the shared encoder-generator structure. Leveraging recent information-theoretic tools, we propose a unified theoretical framework that provides guarantees for the generalization of both the encoder and generator by treating them as randomized mappings. This framework further enables (1) a refined analysis for VAEs, accounting for the generator's generalization, which was previously overlooked; (2) illustrating an explicit trade-off in generalization terms for DMs that depends on the diffusion time $T$; and (3) providing computable bounds for DMs based solely on the training data, allowing the selection of the optimal $T$ and the integration of such bounds into the optimization process to improve model performance. Empirical results on both synthetic and real datasets illustrate the validity of the proposed theory.""}",https://openreview.net{'value': '/pdf/16e6ae78b81529b0a005e160aa22c3e889edc9c0.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=N4rYbQowE3,{'value': 'Learning-Augmented Search Data Structures'},Chunkai Fu; Brandon G. Nguyen; Jung Hoon Seo; Ryan S. Zesch; Samson Zhou,~Chunkai_Fu1; ~Brandon_G._Nguyen1; ~Jung_Hoon_Seo1; ~Ryan_S._Zesch1; ~Samson_Zhou1,"{'value': ['learning-augmented algorithms', 'data structures']}","{'value': 'We study the integration of machine learning advice to improve upon traditional data structure designed for efficient search queries. Although there has been recent effort in improving the performance of binary search trees using machine learning advice, e.g., Lin et. al.  (ICML 2022), the resulting constructions nevertheless suffer from inherent weaknesses of binary search trees, such as complexity of maintaining balance across multiple updates and the inability to handle partially-ordered or high-dimensional datasets. For these reasons, we focus on skip lists and KD trees in this work. Given access to a possibly erroneous oracle that outputs estimated fractional frequencies for search queries on a set of items, we construct skip lists and KD trees that provably provides the optimal expected search time, within nearly a factor of two. In fact, our learning-augmented skip lists and KD trees are still optimal up to a constant factor, even if the oracle is only accurate within a constant factor. We also demonstrate robustness by showing that our data structures achieves an expected search time that is within a constant factor of an oblivious skip list/KD tree construction even when the predictions are arbitrarily incorrect. Finally, we empirically show that our learning-augmented search data structures outperforms their corresponding traditional analogs on both synthetic and real-world datasets.'}",https://openreview.net{'value': '/pdf/c37bc70635e78d7a1a65618a200a46ea1db5f285.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=N4NhVN30ph,{'value': 'TOP-ERL: Transformer-based Off-Policy Episodic Reinforcement Learning'},Ge Li; Dong Tian; Hongyi Zhou; Xinkai Jiang; Rudolf Lioutikov; Gerhard Neumann,~Ge_Li3; ~Dong_Tian2; ~Hongyi_Zhou1; ~Xinkai_Jiang1; ~Rudolf_Lioutikov1; ~Gerhard_Neumann2,"{'value': ['Value of sequences of actions', 'Reinforcement Learning', 'Transformer', 'Robot Manipulation', 'Movement Primitives.']}","{'value': 'This work introduces Transformer-based Off-Policy Episodic Reinforcement Learning (TOP-ERL), a novel algorithm that enables off-policy updates in the ERL framework. In ERL, policies predict entire action trajectories over multiple time steps instead of single actions at every time step. These trajectories are typically parameterized by trajectory generators such as  Movement Primitives (MP), allowing for smooth and efficient exploration over long horizons while capturing high-level temporal correlations. However, ERL methods are often constrained to on-policy frameworks due to the difficulty of evaluating state-action values for entire action sequences, limiting their sample efficiency and preventing the use of more efficient off-policy architectures. TOP-ERL addresses this shortcoming by segmenting long action sequences and estimating the state-action values for each segment using a transformer-based critic architecture alongside an n-step return estimation. These contributions result in efficient and stable training that is reflected in the empirical results conducted on sophisticated robot learning environments. TOP-ERL significantly outperforms state-of-the-art RL methods. Thorough ablation studies additionally show the impact of key design choices on the model performance.'}",https://openreview.net{'value': '/pdf/d28331c2e26076b8268acef8c2ad376d8be45219.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=MxALfOAnXv,{'value': 'Continuity-Preserving  Convolutional Autoencoders for Learning Continuous Latent Dynamical Models from Images'},Aiqing Zhu; Yuting Pan; Qianxiao Li,~Aiqing_Zhu1; ~Yuting_Pan1; ~Qianxiao_Li1,"{'value': ['Latent dynamical system', 'Autoencoders', 'Learning dynamics', 'Continuity-preserving']}","{'value': 'Continuous dynamical systems are cornerstones of many scientific and engineering disciplines.\nWhile machine learning offers powerful tools to model these systems from trajectory data, challenges arise when these trajectories are captured as images, resulting in pixel-level observations that are discrete in nature.\nConsequently, a naive application of a convolutional autoencoder can result in latent coordinates that are discontinuous in time.\nTo resolve this, we propose continuity-preserving convolutional autoencoders (CpAEs) to learn continuous latent states and their corresponding continuous latent dynamical models from discrete image frames. \nWe present a mathematical formulation for learning dynamics from image frames, which illustrates issues with previous approaches and motivates our methodology based on promoting the continuity of convolution filters, thereby preserving the continuity of the latent states.\nThis approach enables CpAEs to produce latent states that evolve continuously with the underlying dynamics, leading to more accurate latent dynamical models.\nExtensive experiments across various scenarios demonstrate the effectiveness of CpAEs.'}",https://openreview.net{'value': '/pdf/c9690e3abfc98adbd8fa75852018e7403c0db2a8.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=MtDd7rWok1,{'value': 'Anti-Exposure Bias in Diffusion Models'},Junyu Zhang; Daochang Liu; Eunbyung Park; Shichao Zhang; Chang Xu,~Junyu_Zhang2; ~Daochang_Liu1; ~Eunbyung_Park1; ~Shichao_Zhang3; ~Chang_Xu4,"{'value': ['Diffusion Models', 'Exposure Bias', 'Prompt Learning', 'Sampling Trajectory']}","{'value': 'Diffusion models (DMs) have achieved record-breaking performance in image generation tasks.\nNevertheless, in practice, the training-sampling discrepancy, caused by score estimation error and discretization error, limits the modeling ability of DMs, a phenomenon known as exposure bias.\nTo alleviate such exposure bias and further improve the generative performance, we put forward a prompt learning framework built upon a lightweight prompt prediction model.\nConcretely, our model learns an anti-bias prompt for the generated sample at each sampling step, aiming to compensate for the exposure bias that arises.\nFollowing this design philosophy, our framework rectifies the sampling trajectory to match the training trajectory, thereby reducing the divergence between the target data distribution and the modeling distribution.\nTo train the prompt prediction model, we simulate exposure bias by constructing training data and introduce a time-dependent weighting function for optimization.\nEmpirical results on various DMs demonstrate the superiority of our prompt learning framework across three benchmark datasets.\nImportantly, the optimized prompt prediction model effectively improves image quality with only a 5\\% increase in sampling overhead, which remains negligible.'}",https://openreview.net{'value': '/pdf/128c1e549a2d2c3c776a6fc24b5ae7efd6a4441d.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=MeGDmZjUXy,{'value': 'Moral Alignment for LLM Agents'},Elizaveta Tennant; Stephen Hailes; Mirco Musolesi,~Elizaveta_Tennant1; ~Stephen_Hailes1; ~Mirco_Musolesi2,"{'value': ['AI alignment', 'LLM fine-tuning', 'moral decision-making', 'social dilemmas']}","{'value': ""Decision-making agents based on pre-trained Large Language Models (LLMs) are increasingly being deployed across various domains of human activity. While their applications are currently rather specialized, several research efforts are underway to develop more generalist agents. As LLM-based systems become more agentic, their influence on human activity will grow and their transparency will decrease. Consequently, developing effective methods for aligning them to human values is vital. \n\nThe prevailing practice in alignment often relies on human preference data (e.g., in RLHF or DPO), in which values are implicit, opaque and are essentially deduced from relative preferences over different model outputs. In this work, instead of relying on human feedback, we introduce the design of reward functions that explicitly and transparently encode core human values for Reinforcement Learning-based fine-tuning of foundation agent models. Specifically, we use intrinsic rewards for the moral alignment of LLM agents. \n\nWe evaluate our approach using the traditional philosophical frameworks of Deontological Ethics and Utilitarianism, quantifying moral rewards for agents in terms of actions and consequences on the Iterated Prisoner's Dilemma (IPD) environment. We also show how moral fine-tuning can be deployed to enable an agent to unlearn a previously developed selfish strategy. Finally, we find that certain moral strategies learned on the IPD game generalize to several other matrix game environments. In summary, we demonstrate that fine-tuning with intrinsic rewards is a promising general solution for aligning LLM agents to human values, and it might represent a more transparent and cost-effective alternative to currently predominant alignment techniques.""}",https://openreview.net{'value': '/pdf/ee16dae74379d9ead7d7bc72bc9d06a27cc2b256.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=MbX0t1rUlp,{'value': 'MLPs Learn In-Context on Regression and Classification Tasks'},William Lingxiao Tong; Cengiz Pehlevan,~William_Lingxiao_Tong1; ~Cengiz_Pehlevan2,"{'value': ['In-context learning', 'relational reasoning', 'synthetic tasks', 'MLP', 'MLP-Mixer', 'Transformer']}","{'value': ""In-context learning (ICL), the remarkable ability to solve a task from only input exemplars, is often assumed to be a unique hallmark of Transformer models. By examining commonly employed synthetic ICL tasks, we demonstrate that multi-layer perceptrons (MLPs) can also learn in-context. Moreover, MLPs, and the closely related MLP-Mixer models, learn in-context comparably with Transformers under the same compute budget in this setting. We further show that MLPs outperform Transformers on a series of classical tasks from psychology designed to test relational reasoning, which are closely related to in-context classification. These results underscore a need for studying in-context learning beyond attention-based architectures, while also challenging prior arguments against MLPs' ability to solve relational tasks. Altogether, our results highlight the unexpected competence of MLPs in a synthetic setting, and support the growing interest in all-MLP alternatives to Transformer architectures. It remains unclear how MLPs perform against Transformers at scale on real-world tasks, and where a performance gap may originate. We encourage further exploration of these architectures in more complex settings to better understand the potential comparative advantage of attention-based schemes.""}",https://openreview.net{'value': '/pdf/13cb6a3404468e0575bca172720e7ed9f428dfbc.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=MRYyOaNxh3,{'value': 'FlickerFusion: Intra-trajectory Domain Generalizing Multi-agent Reinforcement Learning'},Woosung Koh; Wonbeen Oh; Siyeol Kim; Suhin Shin; Hyeongjin Kim; Jaein Jang; Junghyun Lee; Se-Young Yun,~Woosung_Koh1; ~Wonbeen_Oh1; ~Siyeol_Kim1; ~Suhin_Shin1; ~Hyeongjin_Kim2; ~Jaein_Jang1; ~Junghyun_Lee1; ~Se-Young_Yun1,"{'value': ['Domain Generalization', 'Multi-agent Reinforcement Learning', 'Reliability', 'Safety']}","{'value': 'Multi-agent reinforcement learning has demonstrated significant potential in addressing complex cooperative tasks across various real-world applications. However, existing MARL approaches often rely on the restrictive assumption that the number of entities (e.g., agents, obstacles) remains constant between training and inference. This overlooks scenarios where entities are dynamically removed or $\\textit{added}$ $\\textit{during}$ the inference trajectory—a common occurrence in real-world environments like search and rescue missions and dynamic combat situations. In this paper, we tackle the challenge of intra-trajectory dynamic entity composition under zero-shot out-of-domain (OOD) generalization, where such dynamic changes cannot be anticipated beforehand. Our empirical studies reveal that existing MARL methods suffer $\\textit{significant}$ performance degradation and increased uncertainty in these scenarios. In response, we propose FlickerFusion, a novel OOD generalization method that acts as a $\\textit{universally}$ applicable augmentation technique for MARL backbone methods. FlickerFusion stochastically drops out parts of the observation space, emulating being in-domain when inferenced OOD. The results show that FlickerFusion not only achieves superior inference rewards but also $\\textit{uniquely}$ reduces uncertainty vis-à-vis the backbone, compared to existing methods. Benchmarks, implementations, and  model weights are organized and open-sourced at $\\texttt{\\href{flickerfusion305.github.io}{\\textbf{flickerfusion305.github.io}}}$, accompanied by ample demo video renderings.'}",https://openreview.net{'value': '/pdf/2967188815daed9df1c0d1dc55c40445a96ceb35.pdf'},{'title_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=MPJ4SMnScw,{'value': 'Re-Aligning Language to Visual Objects with an Agentic Workflow'},Yuming Chen; Jiangyan Feng; Haodong Zhang; Lijun GONG; Feng Zhu; Rui Zhao; Qibin Hou; Ming-Ming Cheng; Yibing Song,~Yuming_Chen1; ~Jiangyan_Feng2; ~Haodong_Zhang2; ~Lijun_GONG2; ~Feng_Zhu1; ~Rui_Zhao6; ~Qibin_Hou1; ~Ming-Ming_Cheng3; ~Yibing_Song1,"{'value': ['agentic workflow', 'language-based object detection']}","{'value': 'Language-based object detection (LOD) aims to align visual objects with language expressions. A large amount of paired data is utilized to improve LOD model generalizations. During the training process, recent studies leverage vision-language models (VLMs) to automatically generate human-like expressions for visual objects, facilitating training data scaling up. In this process, we observe that VLM hallucinations bring inaccurate object descriptions (e.g., object name, color, and shape) to deteriorate VL alignment quality. To reduce VLM hallucinations, we propose an agentic workflow controlled by an LLM to re-align language to visual objects via adaptively adjusting image and text prompts. We name this workflow Real-LOD, which includes planning, tool use, and reflection steps. Given an image with detected objects and VLM raw language expressions, Real-LOD reasons its state automatically and arranges action based on our neural symbolic designs (i.e., planning). The action will adaptively adjust the image and text prompts and send them to VLMs for object re-description (i.e., tool use). Then, we use another LLM to analyze these refined expressions for feedback (i.e., reflection). These steps are conducted in a cyclic form to gradually improve language descriptions for re-aligning to visual objects. We construct a dataset that contains a tiny amount of 0.18M images with re-aligned language expression and train a prevalent LOD model to surpass existing LOD methods by around 50% on the standard benchmarks. Our Real-LOD workflow, with automatic VL refinement, reveals a potential to preserve data quality along with scaling up data quantity, which further improves LOD performance from a data-alignment perspective.'}",https://openreview.net{'value': '/pdf/1650e2e0aafb94caaa4ad25e1d8f4290dfa55cbb.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=MMwaQEVsAg,{'value': 'Commit0: Library Generation from Scratch'},Wenting Zhao; Nan Jiang; Celine Lee; Justin T Chiu; Claire Cardie; Matthias Gallé; Alexander M Rush,~Wenting_Zhao1; ~Nan_Jiang11; ~Celine_Lee1; ~Justin_T_Chiu1; ~Claire_Cardie1; ~Matthias_Gallé1; ~Alexander_M_Rush1,"{'value': ['code generation', 'language model', 'evaluation', 'feedback']}","{'value': 'With the goal of benchmarking generative systems beyond expert software development ability, we introduce Commit0, a benchmark that challenges AI agents to write libraries from scratch. Agents are provided with a specification document outlining the library’s API as well as a suite of interactive unit tests, with the goal of producing an implementation of this API accordingly. The implementation is validated through running these unit tests. As a benchmark, Commit0 is designed to move beyond static one-shot code generation towards agents that must process long-form natural language specifications, adapt to multi-stage feedback, and generate code with complex dependencies. Commit0 also offers an interactive environment where models receive static analysis and execution feedback on the code they generate. Our experiments demonstrate that while current agents can pass some unit tests, none can yet fully reproduce full libraries. Results also show that interactive feedback is quite useful for models to generate code that passes more unit tests, validating the benchmarks that facilitate its use. We publicly release the benchmark, the interactive environment, and the leaderboard.'}",https://openreview.net{'value': '/pdf/eac394467fdb6e21e6f9614275191328ae410b11.pdf'},{'abstract_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=M7KyLjuN0A,{'value': 'DynamicCity: Large-Scale 4D Occupancy Generation from Dynamic Scenes'},Hengwei Bian; Lingdong Kong; Haozhe Xie; Liang Pan; Yu Qiao; Ziwei Liu,~Hengwei_Bian1; ~Lingdong_Kong1; ~Haozhe_Xie1; ~Liang_Pan2; ~Yu_Qiao1; ~Ziwei_Liu1,"{'value': ['LiDAR Generation', 'Dynamic Scenes', '4D Generation']}","{'value': 'Urban scene generation has been developing rapidly recently. However, existing methods primarily focus on generating static and single-frame scenes, overlooking the inherently dynamic nature of real-world driving environments. In this work, we introduce DynamicCity, a novel 4D occupancy generation framework capable of generating large-scale, high-quality dynamic 4D scenes with semantics. DynamicCity mainly consists of two key models. **1)** A VAE model for learning HexPlane as the compact 4D representation. Instead of using naive averaging operations, DynamicCity employs a novel **Projection Module** to effectively compress 4D features into six 2D feature maps for HexPlane construction, which significantly enhances HexPlane fitting quality (up to **12.56** mIoU gain). Furthermore, we utilize an **Expansion & Squeeze Strategy** to reconstruct 3D feature volumes in parallel, which improves both network training efficiency and reconstruction accuracy than naively querying each 3D point (up to **7.05** mIoU gain, **2.06x** training speedup, and **70.84\\%** memory reduction). **2)** A DiT-based diffusion model for HexPlane generation. To make HexPlane feasible for DiT generation, a **Padded Rollout Operation** is proposed to reorganize all six feature planes of the HexPlane as a squared 2D feature map. In particular, various conditions could be introduced in the diffusion or sampling process, supporting **versatile 4D generation applications**, such as trajectory- and command-driven generation, inpainting, and layout-conditioned generation. Extensive experiments on the CarlaSC and Waymo datasets demonstrate that DynamicCity significantly outperforms existing state-of-the-art 4D occupancy generation methods across multiple metrics. The code and models have been released to facilitate future research.'}",https://openreview.net{'value': '/pdf/6bd7934befbdfc3d017210aa31c91af9e423ee82.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=LqTz13JS2P,{'value': 'Generalized Principal-Agent Problem with a Learning Agent'},Tao Lin; Yiling Chen,~Tao_Lin2; ~Yiling_Chen1,"{'value': ['principal-agent problems', 'Bayesian persuasion', 'no-regret learning', 'no-swap-regret']}","{'value': ""Generalized principal-agent problems, including Stackelberg games, contract design, and Bayesian persuasion, are a class of economic problems where an agent best responds to a principal's committed strategy. \nWe study repeated generalized principal-agent problems under the assumption that the principal does not have commitment power and the agent uses algorithms to learn to respond to the principal. We reduce this problem to a one-shot generalized principal-agent problem where the agent approximately best responds. Using this reduction, we show that: (1) if the agent uses contextual no-regret learning algorithms with regret $\\mathrm{Reg}(T)$, then the principal can guarantee utility at least $U^* - \\Theta\\big(\\sqrt{\\tfrac{\\mathrm{Reg}(T)}{T}}\\big)$, where $U^*$ is the principal's optimal utility in the classic model with a best-responding agent.\n(2) If the agent uses contextual no-swap-regret learning algorithms with swap-regret $\\mathrm{SReg}(T)$, then the principal cannot obtain utility more than $U^* + O(\\frac{\\mathrm{SReg(T)}}{T})$. \nBut (3) if the agent uses mean-based learning algorithms (which can be no-regret but not no-swap-regret), then the principal can sometimes do significantly better than $U^*$.\nThese results not only refine previous results in Stackelberg games and contract design, but also lead to new results for Bayesian persuasion with a learning agent and all generalized principal-agent problems where the agent does not have private information.""}",https://openreview.net{'value': '/pdf/92b80d57a058af51a5e7c6250487b66e450886d1.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=Lp40Z40N07,{'value': 'Framer: Interactive Frame Interpolation'},Wen Wang; Qiuyu Wang; Kecheng Zheng; Hao OUYANG; Zhekai Chen; Biao Gong; Hao Chen; Yujun Shen; Chunhua Shen,~Wen_Wang7; ~Qiuyu_Wang1; ~Kecheng_Zheng2; ~Hao_OUYANG1; ~Zhekai_Chen1; ~Biao_Gong1; ~Hao_Chen17; ~Yujun_Shen1; ~Chunhua_Shen2,{'value': ['Video Frame Interpolation; Interactive; Diffusion Model; Correspondence Modeling']},"{'value': 'We propose Framer for interactive frame interpolation, which targets producing smoothly transitioning frames between two images as per user creativity. Concretely, besides taking the start and end frames as inputs, our approach supports customizing the transition process by tailoring the trajectory of some selected keypoints. Such a design enjoys two clear benefits. First, incorporating human interaction mitigates the issue arising from numerous possibilities of transforming one image to another, and in turn enables finer control of local motions. Second, as the most basic form of interaction, keypoints help establish the correspondence across frames, enhancing the model to handle challenging cases (e.g., objects on the start and end frames are of different shapes and styles). It is noteworthy that our system also offers an ""autopilot"" mode, where we introduce a module to estimate the keypoints and refine the trajectory automatically, to simplify the usage in practice. Extensive experimental results demonstrate the appealing performance of Framer on various applications, such as image morphing, time-lapse video generation, cartoon interpolation, etc. The code, model, and interface are publicly accessible at https://github.com/aim-uofa/Framer.'}",https://openreview.net{'value': '/pdf/2fd0d833fdb7f478586f60f4021b34f400a0eee8.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=LkzuPorQ5L,{'value': 'Cut the Crap: An Economical Communication Pipeline for LLM-based Multi-Agent Systems'},Guibin Zhang; Yanwei Yue; Zhixun Li; Sukwon Yun; Guancheng Wan; Kun Wang; Dawei Cheng; Jeffrey Xu Yu; Tianlong Chen,~Guibin_Zhang1; ~Yanwei_Yue1; ~Zhixun_Li1; ~Sukwon_Yun1; ~Guancheng_Wan1; ~Kun_Wang15; ~Dawei_Cheng1; ~Jeffrey_Xu_Yu1; ~Tianlong_Chen1,"{'value': ['Multi-agent collaboration', 'sparsification', 'LLM agents']}","{'value': 'Recent advancements in large language model (LLM)-powered agents have shown that collective intelligence can significantly outperform individual capabilities, largely attributed to the meticulously designed inter-agent communication topologies. Though impressive in performance, existing multi-agent pipelines inherently introduce substantial token overhead, as well as increased economic costs, which pose challenges for their large-scale deployments. In response to this challenge, we propose an economical, simple, and robust multi-agent communication framework, termed $\\texttt{AgentPrune}$, which can seamlessly integrate into mainstream multi-agent systems and prunes redundant or even malicious communication messages. Technically, $\\texttt{AgentPrune}$ is the first to identify and formally define the $\\textit{Communication Redundancy}$ issue present in current LLM-based multi-agent pipelines, and efficiently performs one-shot pruning on the spatial-temporal message-passing graph, yielding a token-economic and high-performing communication topology.\nExtensive experiments across six benchmarks demonstrate that $\\texttt{AgentPrune}$ $\\textbf{(I)}$ achieves comparable results as state-of-the-art topologies at merely $\\\\$5.6$ cost compared to their $\\\\$43.7$, $\\textbf{(II)}$ integrates seamlessly into existing multi-agent frameworks with $28.1\\\\%\\sim72.8\\\\%\\downarrow$ token reduction, and $\\textbf{(III)}$ successfully defend against two types of agent-based adversarial attacks with $3.5\\\\%\\sim10.8\\\\%\\uparrow$ performance boost. The source code is available at \\url{https://github.com/yanweiyue/AgentPrune}.'}",https://openreview.net{'value': '/pdf/490fff420d6359d82b48829601ac0ed820e335b4.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=LfekK1E0QE,{'value': 'Policy Optimization under Imperfect Human Interactions with Agent-Gated Shared Autonomy'},Zhenghai Xue; Bo An; Shuicheng YAN,~Zhenghai_Xue1; ~Bo_An2; ~Shuicheng_YAN3,"{'value': ['Reinforcement Learning', 'Human-in-the-loop Learning', 'Imperfect Human Interaction', 'Human Feedback']}","{'value': 'We introduce AGSA, an Agent-Gated Shared Autonomy framework that learns from high-level human feedback to tackle the challenges of reward-free training, safe exploration, and imperfect low-level human control. Recent human-in-the loop learning methods enable human participants to intervene a learning agent’s control and provide online demonstrations. Nonetheless, these methods rely heavily on perfect human interactions, including accurate human-monitored intervention decisions and near-optimal human demonstrations. AGSA employs a dedicated gating agent to determine when to switch control, thereby reducing the need of constant human monitoring. To obtain a precise and foreseeable gating agent, AGSA trains a long-term gating value function from human evaluative feedback on the gating agent’s intervention requests and preference feedback on pairs of human intervention trajectories. Instead of relying on potentially suboptimal human demonstrations, the learning agent is trained using control-switching signals from the gating agent. We provide theoretical insights on performance bounds that respectively describe the ability of the two agents. Experiments are conducted with both simulated and real human participants at different skill levels in challenging continuous control environments. Comparative results highlight that AGSA achieves significant improvements over previous human-in-the-loop learning methods in terms of training safety, policy performance, and user-friendliness.'}",https://openreview.net{'value': '/pdf/36c0096687133cea19f2722b657cdab526a4afa3.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=LbEWwJOufy,{'value': 'TANGO: Co-Speech Gesture Video Reenactment with Hierarchical Audio Motion Embedding and Diffusion Interpolation'},Haiyang Liu; Xingchao Yang; Tomoya Akiyama; Yuantian Huang; Qiaoge Li; Shigeru Kuriyama; Takafumi Taketomi,~Haiyang_Liu1; ~Xingchao_Yang2; ~Tomoya_Akiyama1; ~Yuantian_Huang1; ~Qiaoge_Li1; ~Shigeru_Kuriyama1; ~Takafumi_Taketomi1,"{'value': ['co-speech video generation', 'cross-modal retrieval', 'audio repsentation learning', 'motion repsentation learning', 'video frame interpolation']}","{'value': 'We present TANGO, a framework for generating co-speech body-gesture videos. Given a few-minute, single-speaker reference video and target speech audio, TANGO produces high-fidelity videos with synchronized body gestures. TANGO builds on Gesture Video Reenactment (GVR), which splits and retrieves video clips using a directed graph structure - representing video frames as nodes and valid transitions as edges. We address two key limitations of GVR: audio-motion misalignment and visual artifacts in GAN-generated transition frames. In particular, i) we propose retrieving gestures using latent feature distance to improve cross-modal alignment. To ensure the latent features could effectively model the relationship between speech audio and gesture motion, we implement a hierarchical joint embedding space (AuMoClip); ii) we introduce the diffusion-based model to generate high-quality transition frames. Our diffusion model, Appearance Consistent Interpolation (ACInterp), is built upon AnimateAnyone and includes a reference motion module and homography background flow to preserve appearance consistency between generated and reference videos. By integrating these components into the graph-based retrieval framework, TANGO reliably produces realistic, audio-synchronized videos and outperforms all existing generative and retrieval methods. Our code, pretrained models, and datasets are publicly available at https://github.com/CyberAgentAILab/TANGO.'}",https://openreview.net{'value': '/pdf/7c9baec954e8dce002fefe0dfa17b057b6ef9c68.pdf'},{'abstract_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=LPG8pPSfQD,{'value': 'DistRL: An Asynchronous Distributed Reinforcement Learning Framework for On-Device Control Agent'},Taiyi Wang; Zhihao Wu; Jianheng Liu; Jianye HAO; Jun Wang; Kun Shao,~Taiyi_Wang1; ~Zhihao_Wu7; ~Jianheng_Liu1; ~Jianye_HAO1; ~Jun_Wang2; ~Kun_Shao1,"{'value': ['Mobile Agent', 'LLM', 'Reinforcement Learning', 'Fine Tuning', 'Distributed Training']}","{'value': ""On-device control agents, especially on mobile devices, are responsible for operating mobile devices to fulfill users' requests, enabling seamless and intuitive interactions. Integrating Multimodal Large Language Models (MLLMs) into these agents enhances their ability to understand and execute complex commands, thereby improving user experience. However, fine-tuning MLLMs for on-device control presents significant challenges due to limited data availability and inefficient online training processes. This paper introduces DistRL, a novel framework designed to enhance the efficiency of online RL fine-tuning for mobile device control agents. DistRL employs centralized training and decentralized data acquisition to ensure efficient fine-tuning in the context of dynamic online interactions. Additionally, the framework is backed by our tailor-made RL algorithm, which effectively balances exploration with the prioritized utilization of collected data to ensure stable and robust training. Our experiments show that, on average, DistRL delivers a 3$\\times$ improvement in training efficiency and enables training data collection 2.4$\\times$ faster than the leading synchronous multi-machine methods. Notably, after training, DistRL achieves a 20\\% relative improvement in success rate compared to state-of-the-art methods on general Android tasks from an open benchmark, significantly outperforming existing approaches while maintaining the same training time. These results validate DistRL as a scalable and efficient solution, offering substantial improvements in both training efficiency and agent performance for real-world, in-the-wild device control tasks.""}",https://openreview.net{'value': '/pdf/b0ac68a1bdcdb9b6e72ee52644ecbb6103901c0a.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=LLWj8on4Rv,{'value': 'Leveraging Driver Field-of-View for Multimodal Ego-Trajectory Prediction'},M. Eren Akbiyik; Nedko Savov; Danda Pani Paudel; Nikola Popovic; Christian Vater; Otmar Hilliges; Luc Van Gool; Xi Wang,~M._Eren_Akbiyik1; ~Nedko_Savov1; ~Danda_Pani_Paudel3; ~Nikola_Popovic1; ~Christian_Vater1; ~Otmar_Hilliges1; ~Luc_Van_Gool1; ~Xi_Wang10,"{'value': ['Ego-trajectory prediction', 'driver attention', 'multimodal learning', 'field-of-view', 'gaze fixations', 'deep learning', 'autonomous driving', 'driver behavior modeling', 'dataset creation']}","{'value': ""Understanding drivers’ decision-making is crucial for road safety. Although predicting the ego-vehicle’s path is valuable for driver-assistance systems, existing methods mainly focus on external factors like other vehicles’ motions, often neglecting the driver’s attention and intent. To address this gap, we infer the ego-trajectory by integrating the driver’s gaze and the surrounding scene. We introduce RouteFormer, a novel multimodal ego-trajectory prediction network combining GPS data, environmental context, and the driver's field-of-view—comprising first-person video and gaze fixations. We also present the Path Complexity Index (PCI), a new metric for trajectory complexity that enables a more nuanced evaluation of challenging scenarios. To tackle data scarcity and enhance diversity, we introduce GEM, a comprehensive dataset of urban driving scenarios enriched with synchronized driver field-of-view and gaze data. Extensive evaluations on GEM and DR(eye)VE demonstrate that RouteFormer significantly outperforms state-of-the-art methods, achieving notable improvements in prediction accuracy across diverse conditions. Ablation studies reveal that incorporating driver field-of-view data yields significantly better average displacement error, especially in challenging scenarios with high PCI scores, underscoring the importance of modeling driver attention. All data and code are available at meakbiyik.github.io/routeformer.""}",https://openreview.net{'value': '/pdf/cfe97758d768e257643b57eafa9be9b500852e0d.pdf'},{'title_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=LGafQ1g2D2,{'value': 'Can LLMs Understand Time Series Anomalies?'},Zihao Zhou; Rose Yu,~Zihao_Zhou1; ~Rose_Yu1,"{'value': ['Large Language Models (LLMs)', 'Time Series Analysis', 'Anomaly Detection', 'Multimodal Learning']}","{'value': ""Large Language Models (LLMs) have gained popularity in time series forecasting, but their potential for anomaly detection remains largely unexplored. Our study investigates whether LLMs can understand and detect anomalies in time series data, focusing on zero-shot and few-shot scenarios. Inspired by conjectures about LLMs' behavior from time series forecasting research, we formulate key hypotheses about LLMs' capabilities in time series anomaly detection. We design and conduct principled experiments to test each of these hypotheses. Our investigation reveals several surprising findings about LLMs for time series: (1) LLMs understand time series better as *images* rather than as text, (2) LLMs do not demonstrate enhanced performance when prompted to engage in *explicit reasoning* about time series analysis. (3) Contrary to common beliefs, LLMs' understanding of time series *do not* stem from their repetition biases or arithmetic abilities. (4) LLMs' behaviors and performance in time series analysis *vary significantly* across different models. This study provides the first comprehensive analysis of contemporary LLM capabilities in time series anomaly detection. Our results suggest that while LLMs can understand trivial time series anomalies (we have no evidence that they can understand more subtle real-world anomalies), many common conjectures based on their reasoning capabilities do not hold. All synthetic dataset generators, final prompts, and evaluation scripts have been made available in https://github.com/rose-stl-lab/anomllm.""}",https://openreview.net{'value': '/pdf/eb82b57bd465658bfadf92f18b3368a1041dfec4.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=L66G39JrM4,{'value': 'Discrete Latent Plans via Semantic Skill Abstractions'},Haobin Jiang; Jiangxing Wang; Zongqing Lu,~Haobin_Jiang1; ~Jiangxing_Wang2; ~Zongqing_Lu2,"{'value': ['Hierarchical Learning', 'Skill Learning', 'Imitation Learning']}","{'value': 'Skill learning from language instructions is a critical challenge in developing intelligent agents that can generalize across diverse tasks and follow complex human instructions. Hierarchical methods address this by decomposing the learning problem into multiple levels, where the high-level and low-level policies are mediated through a latent plan space. Effective modeling and learning of this latent plan space are key to enabling robust and interpretable skill learning. In this paper, we introduce LADS, a hierarchical approach that learns language-conditioned discrete latent plans through semantic skill abstractions. Our method decouples the learning of the latent plan space from the language-conditioned high-level policy to improve training stability. First, we incorporate a trajectory encoder to learn a discrete latent space with the low-level policy, regularized by language instructions. Next, we model the high-level policy as a categorical distribution over these discrete latent plans to capture the multi-modality of the dataset. Through experiments in simulated control environments, we demonstrate that LADS outperforms state-of-the-art methods in both skill learning and compositional generalization.'}",https://openreview.net{'value': '/pdf/36818adcef58f07f8e1b490caeb4027c37134d28.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=Kvdh12wGC0,{'value': 'Agent Skill Acquisition for Large Language Models via CycleQD'},So Kuroki; Taishi Nakamura; Takuya Akiba; Yujin Tang,~So_Kuroki1; ~Taishi_Nakamura1; ~Takuya_Akiba2; ~Yujin_Tang1,"{'value': ['Large Language Models', 'Skill Acquisition', 'Quality Diversity']}","{'value': 'Training large language models to acquire specific skills remains a challenging endeavor. Conventional training approaches often struggle with data distribution imbalances and inadequacies in objective functions that do not align well with task-specific performance. To address these challenges, we introduce CycleQD, a novel approach that leverages the Quality Diversity framework through a cyclic adaptation of the algorithm, along with a model merging based crossover and an SVD-based mutation. In CycleQD, each task’s performance metric is alternated as the quality measure while the others serve as the behavioral characteristics. This cyclic focus on individual tasks allows for concentrated effort on one task at a time, eliminating the need for data ratio tuning and simplifying the design of the objective function. Empirical results from AgentBench indicate that applying CycleQD to LLAMA3-8B-INSTRUCT based models not only enables them to surpass traditional fine-tuning methods in coding, operating systems, and database tasks, but also achieves performance on par with GPT-3.5-TURBO, which potentially contains much more parameters, across these domains. Crucially, this enhanced performance is achieved while retaining robust language capabilities, as evidenced by its performance on widely adopted language benchmark tasks. We highlight the key design choices in CycleQD, detailing how these contribute to its effectiveness. Furthermore, our method is general and can be applied to image segmentation models, highlighting its applicability across different domains.'}",https://openreview.net{'value': '/pdf/25fd77cddd80639a7294b32efcede58ac6d2ffed.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=KrK6zXbjfO,{'value': 'SoundCTM: Unifying Score-based and Consistency Models for Full-band Text-to-Sound Generation'},Koichi Saito; Dongjun Kim; Takashi Shibuya; Chieh-Hsin Lai; Zhi Zhong; Yuhta Takida; Yuki Mitsufuji,~Koichi_Saito1; ~Dongjun_Kim1; ~Takashi_Shibuya1; ~Chieh-Hsin_Lai2; ~Zhi_Zhong2; ~Yuhta_Takida1; ~Yuki_Mitsufuji1,"{'value': ['text-to-sound generation', 'distillation models', 'text-to-audio diffusion models', 'generative models for sound']}","{'value': 'Sound content creation, essential for multimedia works such as video games and films, often involves extensive trial-and-error, enabling creators to semantically reflect their artistic ideas and inspirations, which evolve throughout the creation process, into the sound.\nRecent high-quality diffusion-based Text-to-Sound (T2S) generative models provide valuable tools for creators. However, these models often suffer from slow inference speeds, imposing an undesirable burden that hinders the trial-and-error process.\nWhile existing T2S distillation models address this limitation through $1$-step generation, the sample quality of $1$-step generation remains insufficient for production use.\nAdditionally, while multi-step sampling in those distillation models improves sample quality itself, the semantic content changes due to their lack of deterministic sampling capabilities.\nThus, developing a T2S generative model that allows creators to efficiently conduct trial-and-error while producing high-quality sound remains a key challenge.\nTo address these issues, we introduce Sound Consistency Trajectory Models (SoundCTM), which allow flexible transitions between high-quality $1$-step sound generation and superior sound quality through multi-step deterministic sampling. \nThis allows creators to efficiently conduct trial-and-error with $1$-step generation to semantically align samples with their intention, and subsequently refine sample quality with preserving semantic content through deterministic multi-step sampling.\nTo develop SoundCTM, we reframe the CTM training framework, originally proposed in computer vision, and introduce a novel feature distance using the teacher network for a distillation loss. \nAdditionally, while distilling classifier-free guided trajectories, we introduce a $\\nu$-sampling, a new algorithm that offers another source of quality improvement. For the $\\nu$-sampling, we simultaneously train both conditional and unconditional student models.\nFor production-level generation, we scale up our model to 1B trainable parameters, making SoundCTM-DiT-1B the first large-scale distillation model in the sound community to achieve both promising high-quality $1$-step and multi-step full-band (44.1kHz) generation.\nAudio samples are available at \\url{https://anonymus-soundctm.github.io/soundctm_iclr/}.'}",https://openreview.net{'value': '/pdf/ba2174871a7fcd54d45ef2402a1613d1ef06f050.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=KmmNb7631I,{'value': 'Learning to Plan Before Answering: Self-Teaching LLMs to Learn Abstract Plans for Problem Solving'},Jin Zhang; Flood Sung; Zhilin Yang; Yang Gao; Chongjie Zhang,~Jin_Zhang6; ~Flood_Sung1; ~Zhilin_Yang2; ~Yang_Gao1; ~Chongjie_Zhang1,"{'value': ['LLM', 'self-training', 'high-level abstraction', 'self-reflection', 'meta learning', 'anticipatory plans']}","{'value': 'In the field of large language model (LLM) post-training, the effectiveness of utilizing synthetic data generated by the LLM itself has been well-presented. However, a key question remains unaddressed: what essential information should such self-generated data encapsulate? Existing approaches only produce step-by-step problem solutions, and fail to capture the abstract meta-knowledge necessary for generalization across similar problems. Drawing insights from cognitive science, where humans employ high-level abstraction to simplify complex problems before delving into specifics, we introduce a novel self-training algorithm: LEarning to Plan before Answering (LEPA). LEPA trains the LLM to formulate anticipatory plans, which serve as abstract meta-knowledge for problem-solving, before engaging with the intricacies of problems. This approach not only outlines the solution generation path but also shields the LLM from the distraction of irrelevant details. During data generation, LEPA first crafts an anticipatory plan based on the problem, and then generates a solution that aligns with both the plan and the problem. LEPA refines the plan through self-reflection, aiming to acquire plans that are instrumental in yielding correct solutions. During model optimization, the LLM is trained to predict both the refined plans and the corresponding solutions. By efficiently extracting and utilizing the anticipatory plans, LEPA demonstrates remarkable superiority over conventional algorithms on various challenging natural language reasoning benchmarks.'}",https://openreview.net{'value': '/pdf/d10a3627ee1fb1caf6b1f6034a478d1e4954df51.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=KTgQGXz5xj,{'value': 'Federated Granger Causality Learning For Interdependent Clients With State Space Representation'},Ayush Mohanty; Nazal Mohamed; Paritosh Ramanan; Nagi Gebraeel,~Ayush_Mohanty1; ~Nazal_Mohamed1; ~Paritosh_Ramanan1; ~Nagi_Gebraeel1,"{'value': ['State Space', 'Federated Learning', 'Granger Causality', 'Interdependencies']}","{'value': 'Advanced sensors and IoT devices have improved the monitoring and control of complex industrial enterprises. They have also created an interdependent fabric of geographically distributed process operations (clients) across these enterprises. Granger causality is an effective approach to detect and quantify interdependencies by examining how the state of one client affects the states of others over time. Understanding these interdependencies helps capture how localized events, such as faults and disruptions, can propagate throughout the system, potentially leading to widespread operational impacts. However, the large volume and complexity of industrial data present significant challenges in effectively modeling these interdependencies. This paper develops a federated approach to learning Granger causality. We utilize a linear state space system framework that leverages low-dimensional state estimates to analyze interdependencies. This helps address bandwidth limitations and the computational burden commonly associated with centralized data processing. We propose augmenting the client models with the Granger causality information learned by the server through a Machine\nLearning (ML) function. We examine the co-dependence between the augmented client and server models and reformulate the framework as a standalone ML algorithm providing conditions for its sublinear and linear convergence rates. We also study the convergence of the framework to a centralized oracle model. Moreover, we include a differential privacy analysis to ensure data security while preserving causal insights. Using synthetic data, we conduct comprehensive experiments to demonstrate the robustness of our approach to perturbations in causality, the scalability to the size of communication, number of clients, and the dimensions of raw data. We also evaluate the performance on two real-world industrial control system datasets by reporting the volume of data saved by decentralization.'}",https://openreview.net{'value': '/pdf/36d9c0bf372f47e198aa68f4fe042dcff44b2dab.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=KRv9NubipP,{'value': 'CaPo: Cooperative Plan Optimization for Efficient Embodied Multi-Agent Cooperation'},Jie Liu; Pan Zhou; Yingjun Du; Ah-Hwee Tan; Cees G. M. Snoek; Jan-Jakob Sonke; Efstratios Gavves,~Jie_Liu21; ~Pan_Zhou3; ~Yingjun_Du1; ~Ah-Hwee_Tan2; ~Cees_G._M._Snoek1; ~Jan-Jakob_Sonke2; ~Efstratios_Gavves1,"{'value': ['Embodied AI', 'multi-agent cooperation', 'LLM']}","{'value': ""In this work, we address the cooperation problem among large language model (LLM) based embodied agents, where agents must cooperate to achieve a common goal. Previous methods often execute actions extemporaneously and incoherently, without long-term  strategic and cooperative planning, leading to redundant steps, failures, and even serious repercussions in complex tasks like search-and-rescue missions where discussion and cooperative plan are crucial.  To solve this issue, we propose Cooperative Plan Optimization (CaPo) to enhance the cooperation efficiency of LLM-based embodied agents. Inspired by human cooperation schemes, CaPo improves cooperation efficiency with two  phases: 1) meta plan generation, and 2) progress-adaptive meta plan and execution. In the first phase, all agents analyze the task, discuss, and cooperatively create a meta-plan that decomposes the task into subtasks with detailed steps, ensuring a long-term strategic and coherent plan for efficient coordination.  In the second phase, agents execute tasks according to the meta-plan and dynamically adjust it based on their latest progress (e.g., discovering a target object) through multi-turn discussions.  This progress-based adaptation eliminates redundant actions, improving the overall cooperation efficiency of agents. Experimental results on the ThreeDworld Multi-Agent Transport and Communicative Watch-And-Help tasks demonstrate CaPo's much higher task completion rate and efficiency compared with  state-of-the-arts. The code is released at https://github.com/jliu4ai/CaPo.""}",https://openreview.net{'value': '/pdf/58310c0a0043720fb0a50f8c2c38c08e8a5904d5.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=KEUPk0wXXe,{'value': 'From GNNs to Trees: Multi-Granular Interpretability for Graph Neural Networks'},Jie Yang; Yuwen Wang; Kaixuan Chen; Tongya Zheng; Yihe Zhou; Zhenbang Xiao; Ji Cao; Mingli Song; Shunyu Liu,~Jie_Yang41; ~Yuwen_Wang2; ~Kaixuan_Chen2; ~Tongya_Zheng1; ~Yihe_Zhou1; ~Zhenbang_Xiao1; ~Ji_Cao1; ~Mingli_Song1; ~Shunyu_Liu1,"{'value': ['Graph Neural Networks', 'Multi-Granular Interpretability', 'Graph Classification']}","{'value': 'Interpretable Graph Neural Networks (GNNs) aim to reveal the underlying reasoning behind model predictions, attributing their decisions to specific subgraphs that are informative. However, existing subgraph-based interpretable methods suffer from an overemphasis on local structure, potentially overlooking long-range dependencies within the entire graphs. Although recent efforts that rely on graph coarsening have proven beneficial for global interpretability, they inevitably reduce the graphs to a fixed granularity. Such an inflexible way can only capture graph connectivity at a specific level, whereas real-world graph tasks often exhibit relationships at varying granularities (e.g., relevant interactions in proteins span from functional groups, to amino acids, and up to protein domains). In this paper, we introduce a novel Tree-like Interpretable Framework (TIF) for graph classification, where plain GNNs are transformed into hierarchical trees, with each level featuring coarsened graphs of different granularity as tree nodes. Specifically, TIF iteratively adopts a graph coarsening module to compress original graphs  (i.e., root nodes of trees) into increasingly coarser ones (i.e., child nodes of trees), while preserving diversity among tree nodes within different branches through a dedicated graph perturbation module. Finally, we propose an adaptive routing module to identify the most informative root-to-leaf paths, providing not only the final prediction but also the multi-granular interpretability for the decision-making process. Extensive experiments on the graph classification benchmarks with both synthetic and real-world datasets demonstrate the superiority of TIF in interpretability, while also delivering a competitive prediction performance akin to the state-of-the-art counterparts.'}",https://openreview.net{'value': '/pdf/f008f287d22c36a49d41a83d00631338000e4178.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=K5yeB4dTtS,{'value': 'MLLM as Retriever: Interactively Learning Multimodal Retrieval for Embodied Agents'},Junpeng Yue; Xinrun Xu; Börje F. Karlsson; Zongqing Lu,~Junpeng_Yue1; ~Xinrun_Xu1; ~Börje_F._Karlsson1; ~Zongqing_Lu2,"{'value': ['multimodal retrieval', 'interactive learning', 'MLLM embodied agent']}","{'value': ""MLLM agents demonstrate potential for complex embodied tasks by retrieving multimodal task-relevant trajectory data. However, current retrieval methods primarily focus on surface-level similarities of textual or visual cues in trajectories, neglecting their effectiveness for the specific task at hand. To address this issue, we propose a novel method, MART, which enhances the performance of embodied agents by utilizing interaction data to fine-tune an MLLM retriever based on preference learning, such that the retriever fully considers the effectiveness of trajectories and prioritize them for unseen tasks. We also introduce Trajectory Abstraction, a mechanism that leverages MLLMs' summarization capabilities to represent trajectories with fewer tokens while preserving key information, enabling agents to better comprehend milestones in the trajectory. Experimental results across various environments demonstrate our method significantly improves task success rates in unseen scenes compared to baseline methods. This work presents a new paradigm for multimodal retrieval in embodied agents, by fine-tuning a general-purpose MLLM as the retriever to assess trajectory effectiveness. All the code for benchmark tasks, simulator modifications and the MLLM retriever is available at https://github.com/PKU-RL/MART.""}",https://openreview.net{'value': '/pdf/1682dac5606689ac86e6ce0527a24c01f9f70f8d.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=K3n5jPkrU6,{'value': 'Scaling Large Language Model-based Multi-Agent Collaboration'},Chen Qian; Zihao Xie; YiFei Wang; Wei Liu; Kunlun Zhu; Hanchen Xia; Yufan Dang; Zhuoyun Du; Weize Chen; Cheng Yang; Zhiyuan Liu; Maosong Sun,~Chen_Qian8; ~Zihao_Xie1; ~YiFei_Wang13; ~Wei_Liu40; ~Kunlun_Zhu1; ~Hanchen_Xia1; ~Yufan_Dang1; ~Zhuoyun_Du1; ~Weize_Chen1; ~Cheng_Yang6; ~Zhiyuan_Liu1; ~Maosong_Sun1,"{'value': ['Large Language Model', 'Autonomous Agent', 'Multi-Agent Collaboration', 'Interactive Reasoning']}","{'value': 'Recent breakthroughs in large language model-driven autonomous agents have revealed that multi-agent collaboration often surpasses each individual through collective reasoning. Inspired by the neural scaling law—increasing neurons enhances performance, this study explores whether the continuous addition of collaborative agents can yield similar benefits. Technically, we utilize directed acyclic graphs to organize agents into a multi-agent collaboration network (MacNet), upon which their interactive reasoning is topologically orchestrated for autonomous task solving. Extensive evaluations reveal that it effectively supports collaboration among over a thousand agents, with irregular topologies outperforming regular ones. We also identify a collaborative scaling law—the overall performance follows a logistic growth pattern as agents scale, with collaborative emergence occurring earlier than traditional neural emergence. We speculate this may be because scaling agents catalyzes their multidimensional considerations during interactive reflection and refinement, thereby producing more comprehensive artifacts. The code is available at https://github.com/OpenBMB/ChatDev/tree/macnet.'}",https://openreview.net{'value': '/pdf/ae4a2f1ceb38887964f97458f71ef3306ae433cb.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=JtGPIZpOrz,{'value': 'Multiagent Finetuning: Self Improvement with Diverse Reasoning Chains'},Vighnesh Subramaniam; Yilun Du; Joshua B. Tenenbaum; Antonio Torralba; Shuang Li; Igor Mordatch,~Vighnesh_Subramaniam1; ~Yilun_Du1; ~Joshua_B._Tenenbaum1; ~Antonio_Torralba1; ~Shuang_Li5; ~Igor_Mordatch4,"{'value': ['Language Models', 'Multi-agent Interaction', 'Self Improvement']}","{'value': 'Large language models (LLMs) have achieved remarkable performance in recent years but are fundamentally limited by the underlying training data. To improve models beyond the training data, recent works have explored how LLMs can be used to generate synthetic data for autonomous self-improvement. However, successive steps of self-improvement can reach a point of diminishing returns. In this work, we propose a complementary approach towards self-improvement where finetuning is applied to a multiagent society of language models. A group of language models, all starting from the same base model, are independently specialized by updating each one using data generated through multiagent interactions among the models. By training each model on independent sets of data, we illustrate how this approach enables specialization across models and diversification over the set of models. As a result, our overall system is able to preserve diverse reasoning chains and autonomously improve over many more rounds of fine-tuning than single-agent self-improvement methods. We quantitatively illustrate the efficacy of the approach across a wide suite of reasoning tasks.'}",https://openreview.net{'value': '/pdf/2df12554b353f4c99981918b614fa32dd8d0239c.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=JsVIGVntnQ,{'value': 'Empowering LLM Agents with Zero-Shot Optimal Decision-Making through Q-learning'},Jiajun Chai; Sicheng Li; Yuqian Fu; Dongbin Zhao; Yuanheng Zhu,~Jiajun_Chai1; ~Sicheng_Li5; ~Yuqian_Fu3; ~Dongbin_Zhao1; ~Yuanheng_Zhu1,"{'value': ['Large language models', 'Agent', 'Optimal decision-making']}","{'value': 'Large language models (LLMs) are trained on extensive text data to gain general comprehension capability. Current LLM agents leverage this ability to make zero- or few-shot decisions without reinforcement learning (RL) but fail in making optimal decisions, as LLMs inherently perform next-token prediction rather than maximizing rewards. In contrast, agents trained via RL could make optimal decisions but require extensive environmental interaction. In this work, we develop an algorithm that combines the zero-shot capabilities of LLMs with the optimal decision-making of RL, referred to as the Model-based LLM Agent with Q-Learning (MLAQ). MLAQ employs Q-learning to derive optimal policies from transitions within memory. However, unlike RL agents that collect data from environmental interactions, MLAQ constructs an imagination space fully based on LLM to perform imaginary interactions for deriving zero-shot policies. Our proposed UCB variant generates high-quality imaginary data through interactions with the LLM-based world model, balancing exploration and exploitation while ensuring a sub-linear regret bound. Additionally, MLAQ incorporates a mixed-examination mechanism to filter out incorrect data. We evaluate MLAQ in benchmarks that present significant challenges for existing LLM agents. Results show that MLAQ achieves a optimal rate of over 90\\% in tasks where other methods struggle to succeed. Additional experiments are conducted to reach the conclusion that introducing model-based RL into LLM agents shows significant potential to improve optimal decision-making ability. Our interactive website is available at http://mlaq.site.'}",https://openreview.net{'value': '/pdf/19a6013acbd870d276019cfc942ecc9eaeeaa320.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=JjdU6ysnCr,{'value': 'On the Feature Learning in Diffusion Models'},Andi Han; Wei Huang; Yuan Cao; Difan Zou,~Andi_Han1; ~Wei_Huang6; ~Yuan_Cao1; ~Difan_Zou1,"{'value': ['Diffusion model', 'Feature learning']}","{'value': 'The predominant success of diffusion models in generative modeling has spurred significant interest in understanding their theoretical foundations. In this work, we propose a feature learning framework aimed at analyzing and comparing the training dynamics of diffusion models with those of traditional classification models. Our theoretical analysis demonstrates that diffusion models, due to the denoising objective, are encouraged to learn more balanced and comprehensive representations of the data. In contrast, neural networks with a similar architecture trained for classification tend to prioritize learning specific patterns in the data, often focusing on easy-to-learn components. To support these theoretical insights, we conduct several experiments on both synthetic and real-world datasets, which empirically validate our findings and highlight the distinct feature learning dynamics in diffusion models compared to classification.'}",https://openreview.net{'value': '/pdf/10fb224afd499e79a829104b49190fc58a594a15.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=JY6P45sFDS,{'value': 'The Directionality of Optimization Trajectories in Neural Networks'},Sidak Pal Singh; Bobby He; Thomas Hofmann; Bernhard Schölkopf,~Sidak_Pal_Singh1; ~Bobby_He1; ~Thomas_Hofmann1; ~Bernhard_Schölkopf1,"{'value': ['optimization', 'trajectory', 'redundancy', 'LLMs', 'neural networks']}","{'value': ""The regularity or implicit bias in neural network optimization has been typically studied via the parameter norms or the landscape curvature, often overlooking the trajectory leading to these parameters. However, properties of the trajectory --- particularly its directionality --- capture critical aspects of how gradient descent navigates the landscape to converge to a solution. In this work, we introduce the notion of a Trajectory Map and derive natural complexity measures that highlight the directional characteristics of optimization trajectories. Our comprehensive analysis across vision and language modeling tasks reveals that (a) the trajectory's directionality at the macro-level saturates by the initial phase of training, wherein weight decay and momentum play a crucial but understated role; and (b) in subsequent training, trajectory directionality manifests in micro-level behaviors, such as oscillations, for which we also provide a theoretical analysis. This implies that neural optimization trajectories have, overall, a more linear form than zig-zaggy, as evident by high directional similarity, especially towards the end. To further hone this point, we show that when the trajectory direction gathers such an inertia, optimization proceeds largely unaltered even if the network is severely decapacitated (by freezing >99% of the parameters), --- thereby demonstrating the potential for significant computational and resource savings without compromising performance.""}",https://openreview.net{'value': '/pdf/172dcd9e04c7b1010945c96f6e42a7e5268de85d.pdf'},{'title_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=JXKFPJe0NU,{'value': 'BaB-ND: Long-Horizon Motion Planning with Branch-and-Bound and Neural Dynamics'},Keyi Shen; Jiangwei Yu; Jose Barreiros; Huan Zhang; Yunzhu Li,~Keyi_Shen1; ~Jiangwei_Yu1; ~Jose_Barreiros1; ~Huan_Zhang1; ~Yunzhu_Li1,"{'value': ['Robotic Manipulation', 'Model-Based Planning', 'Neural Dynamics', 'Branch-and-Bound Method']}","{'value': 'Neural-network-based dynamics models learned from observational data have shown strong predictive capabilities for scene dynamics in robotic manipulation tasks. However, their inherent non-linearity presents significant challenges for effective planning. Current planning methods, often dependent on extensive sampling or local gradient descent, struggle with long-horizon motion planning tasks involving complex contact events.\nIn this paper, we present a GPU-accelerated branch-and-bound (BaB) framework for motion planning in manipulation tasks that require trajectory optimization over neural dynamics models. Our approach employs a specialized branching heuristic to divide the search space into sub-domains and applies a modified bound propagation method, inspired by the state-of-the-art neural network verifier $\\alpha,\\beta$-CROWN, to efficiently estimate objective bounds within these sub-domains. The branching process guides planning effectively, while the bounding process strategically reduces the search space.\nOur framework achieves superior planning performance, generating high-quality state-action trajectories and surpassing existing methods in challenging, contact-rich manipulation tasks such as non-prehensile planar pushing with obstacles, object sorting, and rope routing in both simulated and real-world settings. Furthermore, our framework supports various neural network architectures, ranging from simple multilayer perceptrons to advanced graph neural dynamics models, and scales efficiently with different model sizes.'}",https://openreview.net{'value': '/pdf/68b7efa9aa2f788926de548383c2e66e69bd0d93.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=JVkdSi7Ekg,{'value': 'AHA: A Vision-Language-Model for Detecting and Reasoning Over Failures in Robotic Manipulation'},Jiafei Duan; Wilbert Pumacay; Nishanth Kumar; Yi Ru Wang; Shulin Tian; Wentao Yuan; Ranjay Krishna; Dieter Fox; Ajay Mandlekar; Yijie Guo,~Jiafei_Duan1; ~Wilbert_Pumacay1; ~Nishanth_Kumar1; ~Yi_Ru_Wang1; ~Shulin_Tian1; ~Wentao_Yuan1; ~Ranjay_Krishna1; ~Dieter_Fox1; ~Ajay_Mandlekar1; ~Yijie_Guo1,{'value': ['Robotic Manipulation; Data Generation; Vision-Language-Model; Failure Reasoning; Failure Detection']},"{'value': ""Robotic manipulation in open-world settings requires not only task execution but also the ability to detect and learn from failures. While recent advances in vision-language models (VLMs) and large language models (LLMs) have improved robots' spatial reasoning and problem-solving abilities, they still struggle with failure recognition, limiting their real-world applicability. We introduce AHA, an open-source VLM designed to detect and reason about failures in robotic manipulation using natural language. By framing failure detection as a free-form reasoning task, AHA identifies failures and provides detailed, adaptable explanations across different robots, tasks, and environments. We fine-tuned AHA using FailGen, a scalable framework that generates the first large-scale dataset of robotic failure trajectories, the AHA dataset. FailGen achieves this by procedurally perturbing successful demonstrations from simulation. Despite being trained solely on the AHA dataset, AHA generalizes effectively to real-world failure datasets, robotic systems, and unseen tasks. It surpasses the second-best model (GPT-4o in-context learning) by 10.3% and exceeds the average performance of six compared models including five state-of-the-art VLMs by 35.3% across multiple metrics and datasets. We integrate AHA into three manipulation frameworks that utilize LLMs/VLMs for reinforcement learning, task and motion planning, and zero-shot trajectory generation. AHA’s failure feedback enhances these policies' performances by refining dense reward functions, optimizing task planning, and improving sub-task verification, boosting task success rates by an average of 21.4% across all three tasks compared to GPT-4 models. Project page: https://aha-vlm.github.io""}",https://openreview.net{'value': '/pdf/baa69f167306f963174767be4974c69528aa6379.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=J6e4hurEKd,{'value': 'RetroInText: A Multimodal Large Language Model Enhanced Framework for Retrosynthetic Planning via In-Context Representation Learning'},Chenglong Kang; Xiaoyi Liu; Fei Guo,~Chenglong_Kang2; ~Xiaoyi_Liu6; ~Fei_Guo4,"{'value': ['Retrosynthetic Planning', 'Route Evaluation', 'In-Context Learning', 'Large Language Model']}","{'value': 'Development of robust and effective strategies for retrosynthetic planning requires a deep understanding of the synthesis process. A critical step in achieving this goal is accurately identifying synthetic intermediates. Current machine learning-based methods often overlook the valuable context from the overall route, focusing only on predicting reactants from the product, requiring cost annotations for every reaction step, and ignoring the multi-faced nature of molecular, resulting in inaccurate synthetic route predictions. Therefore, we introduce RetroInText, an advanced end-to-end framework based on a multimodal Large Language Model (LLM), featuring in-context learning with TEXT descriptions of synthetic routes. First, RetroInText including ChatGPT presents detailed descriptions of the reaction procedure. It learns the distinct compound representations in parallel with corresponding molecule encoders to extract multi-modal representations including 3D features. Subsequently, we propose an attention-based mechanism that offers a fusion module to complement these multi-modal representations with in-context learning and a fine-tuned language model for a single-step model. As a result, RetroInText accurately represents and effectively captures the complex relationship between molecules and the synthetic route. In experiments on the USPTO pathways dataset RetroBench, RetroInText outperforms state-of-the-art methods, achieving up to a 5% improvement in Top-1 test accuracy, particularly for long synthetic routes. These results demonstrate the superiority of RetroInText by integrating with context information over routes. They also demonstrate its potential for advancing pathway design and facilitating the development of organic chemistry. Code is available at https://github.com/guofei-tju/RetroInText.'}",https://openreview.net{'value': '/pdf/2fc6a0d94412416c48a54d7210044cbda915fee1.pdf'},{'title_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=J0qTpmbSbh,{'value': 'GenARM: Reward Guided Generation with Autoregressive Reward Model for Test-Time Alignment'},Yuancheng Xu; Udari Madhushani Sehwag; Alec Koppel; Sicheng Zhu; Bang An; Furong Huang; Sumitra Ganesh,~Yuancheng_Xu1; ~Udari_Madhushani_Sehwag1; ~Alec_Koppel1; ~Sicheng_Zhu1; ~Bang_An1; ~Furong_Huang1; ~Sumitra_Ganesh1,{'value': ['large language model alignment; controlled decoding;']},"{'value': 'Large Language Models (LLMs) exhibit impressive capabilities but require careful alignment with human preferences. Traditional training-time methods finetune LLMs using human preference datasets but incur significant training costs and require repeated training to handle diverse user preferences. Test-time alignment methods address this by using reward models (RMs) to guide frozen LLMs without retraining. However, existing test-time approaches rely on trajectory-level RMs which are designed to evaluate complete responses, making them unsuitable for autoregressive text generation that requires computing next-token rewards from partial responses. To address this, we introduce GenARM, a test-time alignment approach that leverages the Autoregressive Reward Model—a novel reward parametrization designed to predict next-token rewards for efficient and effective autoregressive generation. Theoretically, we demonstrate that this parametrization can provably guide frozen LLMs toward any distribution achievable by traditional RMs within the KL-regularized reinforcement learning framework. Experimental results show that GenARM significantly outperforms prior test-time alignment baselines and matches the performance of training-time methods. Additionally, GenARM enables efficient weak-to-strong guidance, aligning larger LLMs with smaller RMs without the high costs of training larger models. Furthermore, GenARM supports multi-objective alignment, allowing real-time trade-offs between preference dimensions and catering to diverse user preferences without retraining. Our project page is available at: https://genarm.github.io.'}",https://openreview.net{'value': '/pdf/d97d435fe568c3703c3ee8d9f029ef4f55e5c188.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=IzYczpPqKq,{'value': 'Learning to Steer Markovian Agents under Model Uncertainty'},Jiawei Huang; Vinzenz Thoma; Zebang Shen; Heinrich H. Nax; Niao He,~Jiawei_Huang3; ~Vinzenz_Thoma1; ~Zebang_Shen1; ~Heinrich_H._Nax1; ~Niao_He3,"{'value': ['Steering Learning Dynamics', 'Reinforcement Learning', 'Markov Games', 'Mechanism Design']}","{'value': ""Designing incentives for an adapting population is a ubiquitous problem in a wide array of economic applications and beyond. In this work, we study how to design additional rewards to steer multi-agent systems towards desired policies \\emph{without} prior knowledge of the agents' underlying learning dynamics. Motivated by the limitation of existing works, we consider a new and general category of learning dynamics called \\emph{Markovian agents}. We introduce a model-based non-episodic Reinforcement Learning (RL) formulation for our steering problem. Importantly, we focus on learning a \\emph{history-dependent} steering strategy to handle the inherent model uncertainty about the agents' learning dynamics. We introduce a novel objective function to encode the desiderata of achieving a good steering outcome with reasonable cost. Theoretically, we identify conditions for the existence of steering strategies to guide agents to the desired policies. Complementing our theoretical contributions, we provide empirical algorithms to approximately solve our objective, which effectively tackles the challenge in learning history-dependent strategies. We demonstrate the efficacy of our algorithms through empirical evaluations.""}",https://openreview.net{'value': '/pdf/f8bbe9141d97b72cc3211aea444c561cbedb0aa1.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=IXyfbaGlps,{'value': 'Learning Color Equivariant Representations'},Yulong Yang; Felix O'Mahony; Christine Allen-Blanchette,~Yulong_Yang2; ~Felix_O'Mahony1; ~Christine_Allen-Blanchette1,"{'value': ['Equivariant Neural Network', 'Geometric Deep Learning', 'Group Convolution']}","{'value': 'In this paper, we introduce group convolutional neural networks (GCNNs) equivariant to color variation. GCNNs have been designed for a variety of geometric transformations from 2D and 3D rotation groups, to semi-groups such as scale. Despite the improved interpretability, accuracy and generalizability of these architectures, GCNNs have seen limited application in the context of perceptual quantities. Notably, the recent CEConv network uses a GCNN to achieve equivariance to hue transformations by convolving input images with a hue rotated RGB filter. However, this approach leads to invalid RGB values which break equivariance and degrade performance. We resolve these issues with a lifting layer that transforms the input image directly, thereby circumventing the issue of invalid RGB values and improving equivariance error by over three orders of magnitude. Moreover, we extend the notion of color equivariance to include equivariance to saturation and luminance shift. Our hue-, saturation-, luminance- and color-equivariant networks achieve strong generalization to out-of-distribution perceptual variations and improved sample efficiency over conventional architectures. We demonstrate the utility of our approach on synthetic and real world datasets where we consistently outperform competitive baselines.'}",https://openreview.net{'value': '/pdf/e0e4b28779d288fc3480d8601b69062069db5776.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=INyi7qUdjZ,{'value': 'Differential learning kinetics govern the transition from memorization to generalization during in-context learning'},Alex Nguyen; Gautam Reddy,~Alex_Nguyen1; ~Gautam_Reddy1,"{'value': ['in-context learning', 'mechanistic interpretability', 'small transformers', 'memorization']}","{'value': ""Transformers exhibit in-context learning (ICL): the ability to use novel information presented in the context without additional weight updates. Recent work shows that ICL emerges when models are trained on a sufficiently diverse set of tasks and the transition from memorization to generalization is sharp with increasing task diversity. One interpretation is that a network's limited capacity to memorize favors generalization. Here, we examine the mechanistic underpinnings of this transition using a small transformer applied to a synthetic ICL task. Using theory and experiment, we show that the sub-circuits that memorize and generalize can be viewed as largely independent. The relative *rates* at which these sub-circuits learn explains the transition from memorization to generalization, rather than capacity constraints. We uncover a memorization scaling law, which determines the task diversity threshold at which the network generalizes. The theory quantitatively explains a variety of other ICL-related phenomena, including the long-tailed distribution of when ICL is acquired, the bimodal behavior of solutions close to the task diversity threshold, the influence of contextual and data distributional statistics on ICL, and the transient nature of ICL.""}",https://openreview.net{'value': '/pdf/1bcd142565ff269e8f530cf13dcc4c7a54ddf06a.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=INe4otjryz,{'value': 'Can In-context Learning Really Generalize to Out-of-distribution Tasks?'},Qixun Wang; Yifei Wang; Xianghua Ying; Yisen Wang,~Qixun_Wang1; ~Yifei_Wang1; ~Xianghua_Ying3; ~Yisen_Wang1,"{'value': ['Large language models', 'In-context Learning', 'Out-of-distribution Generalization']}","{'value': ""In this work, we explore the mechanism of in-context learning (ICL) on out-of-distribution (OOD) tasks that were not encountered during training. To achieve this, we conduct synthetic experiments where the objective is to learn OOD mathematical functions through ICL using a GPT-2 model. We reveal that Transformers may struggle to learn OOD task functions through ICL. Specifically, ICL performance resembles implementing a function within the pretraining hypothesis space and optimizing it with gradient descent based on the in-context examples. Additionally, we investigate ICL's well-documented ability to learn unseen abstract labels in context. We demonstrate that such ability only manifests in the scenarios without distributional shifts and, therefore, may not serve as evidence of new-task-learning ability. Furthermore, we assess ICL's performance on OOD tasks when the model is pretrained on multiple tasks. Both empirical and theoretical analyses demonstrate the existence of the \\textbf{low-test-error preference} of ICL, where it tends to implement the pretraining function that yields low test error in the testing context. We validate this through numerical experiments. This new theoretical result, combined with our empirical findings, elucidates the mechanism of ICL in addressing OOD tasks.""}",https://openreview.net{'value': '/pdf/3db3231ac3dd1da1190b4ca417cee99dbc392431.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=IEMmEd5Jgm,{'value': 'X-Drive: Cross-modality Consistent Multi-Sensor Data Synthesis for Driving Scenarios'},Yichen Xie; Chenfeng Xu; Chensheng Peng; Shuqi Zhao; Nhat Ho; Alexander T. Pham; Mingyu Ding; Masayoshi Tomizuka; Wei Zhan,~Yichen_Xie1; ~Chenfeng_Xu1; ~Chensheng_Peng1; ~Shuqi_Zhao1; ~Nhat_Ho1; ~Alexander_T._Pham1; ~Mingyu_Ding1; ~Masayoshi_Tomizuka2; ~Wei_Zhan2,{'value': ['diffusion models; multi-modality data; autonomous driving']},"{'value': 'Recent advancements have exploited diffusion models for the synthesis of either LiDAR point clouds or camera image data in driving scenarios. Despite their success in modeling single-modality data marginal distribution, there is an under- exploration in the mutual reliance between different modalities to describe com- plex driving scenes. To fill in this gap, we propose a novel framework, X-DRIVE, to model the joint distribution of point clouds and multi-view images via a dual- branch latent diffusion model architecture. Considering the distinct geometrical spaces of the two modalities, X-DRIVE conditions the synthesis of each modality on the corresponding local regions from the other modality, ensuring better alignment and realism. To further handle the spatial ambiguity during denoising, we design the cross-modality condition module based on epipolar lines to adaptively learn the cross-modality local correspondence. Besides, X-DRIVE allows for controllable generation through multi-level input conditions, including text, bounding box, image, and point clouds. Extensive results demonstrate the high-fidelity synthetic results of X-DRIVE for both point clouds and multi-view images, adhering to input conditions while ensuring reliable cross-modality consistency. Our code will be made publicly available at https://github.com/yichen928/X-Drive.'}",https://openreview.net{'value': '/pdf/8c1c5b2821051706aa8cd8c06722f123ee1be711.pdf'},{'title_filter': 'Data Synthesis'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=IDJUscOjM3,{'value': 'Self-MoE: Towards Compositional Large Language Models with Self-Specialized Experts'},Junmo Kang; Leonid Karlinsky; Hongyin Luo; Zhen Wang; Jacob A Hansen; James R. Glass; David Daniel Cox; Rameswar Panda; Rogerio Feris; Alan Ritter,~Junmo_Kang1; ~Leonid_Karlinsky3; ~Hongyin_Luo1; ~Zhen_Wang6; ~Jacob_A_Hansen1; ~James_R._Glass1; ~David_Daniel_Cox1; ~Rameswar_Panda1; ~Rogerio_Feris1; ~Alan_Ritter1,"{'value': ['Efficient Specialization of LLMs', 'Self-Improving', 'Mixture of Experts']}","{'value': 'We present Self-MoE, an approach that transforms a monolithic LLM into a compositional, modular system of self-specialized experts, named MiXSE (MiXture of Self-specialized Experts). Our approach leverages self-specialization, which constructs expert modules using self-generated synthetic data, each equipping a shared base LLM with distinct domain-specific capabilities, activated via self-optimized routing. This allows for dynamic and capability-specific handling of various target tasks, enhancing overall capabilities, without extensive human-labeled data and added parameters. Our empirical results reveal that specializing LLMs may exhibit potential trade-offs in performances on non-specialized tasks. On the other hand, our Self-MoE demonstrates substantial improvements (6.5%p on average) over the base LLM across diverse benchmarks such as knowledge, reasoning, math, and coding. It also consistently outperforms other methods, including instance merging and weight merging, while offering better flexibility and interpretability by design with semantic experts and routing. Our findings highlight the critical role of modularity, the applicability of Self-MoE to multiple base LLMs, and the potential of self-improvement in achieving efficient, scalable, and adaptable systems.'}",https://openreview.net{'value': '/pdf/e99a2ed2cb4ba438185b0e6ba703170c2c90e88e.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=I9Dsq0cVo9,{'value': 'Maximizing the Potential of Synthetic Data: Insights from Random Matrix Theory'},Aymane El Firdoussi; Mohamed El Amine Seddik; Soufiane Hayou; Reda ALAMI; Ahmed Alzubaidi; Hakim Hacid,~Aymane_El_Firdoussi1; ~Mohamed_El_Amine_Seddik1; ~Soufiane_Hayou1; ~Reda_ALAMI1; ~Ahmed_Alzubaidi2; ~Hakim_Hacid2,"{'value': ['Synthetic Data', 'RLHF', 'Generative Models', 'Statistical Models', 'Random Matrices']}","{'value': 'Synthetic data has gained attention for training large language models, but poor-quality data can harm performance (see, e.g., Shumailov et al. (2023); Seddik et al. (2024)). A potential solution is data pruning, which retains only high-quality data based on a score function (human or machine feedback). Previous work Feng et al. (2024) analyzed models trained on synthetic data as sample size increases. We extend this by using random matrix theory to derive the performance of a binary classifier trained on a mix of real and pruned synthetic data in a high dimensional setting. Our findings identify conditions where synthetic data could improve performance, focusing on the quality of the generative model and verification strategy. We also show a smooth phase transition in synthetic label noise, contrasting with prior sharp behavior in infinite sample limits. Experiments with toy models and large language models validate our theoretical results.'}",https://openreview.net{'value': '/pdf/87cbb206626a1ea6110b73b42bb63372af033ad3.pdf'},{'title_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=Hx2ADQLi8M,{'value': 'SonicSim: A customizable simulation platform for speech processing in moving sound source scenarios'},Kai Li; Wendi Sang; Chang Zeng; Runxuan Yang; Guo Chen; Xiaolin Hu,~Kai_Li15; ~Wendi_Sang1; ~Chang_Zeng1; ~Runxuan_Yang1; ~Guo_Chen7; ~Xiaolin_Hu1,"{'value': ['Moving audio toolkit', 'moving audio dataset', 'speech separation', 'speech enhancement']}","{'value': 'Systematic evaluation of speech separation and enhancement models under moving sound source conditions requires extensive and diverse data. However, real-world datasets often lack sufficient data for training and evaluation, and synthetic datasets, while larger, lack acoustic realism. Consequently, neither effectively meets practical needs. To address this issue, we introduce SonicSim, a synthetic toolkit based on the embodied AI simulation platform Habitat-sim, designed to generate highly customizable data for moving sound sources. SonicSim supports multi-level adjustments—including scene-level, microphone-level, and source-level—enabling the creation of more diverse synthetic data. Leveraging SonicSim, we constructed a benchmark dataset called SonicSet, utilizing LibriSpeech, Freesound Dataset 50k (FSD50K), Free Music Archive (FMA), and 90 scenes from Matterport3D to evaluate speech separation and enhancement models. Additionally, to investigate the differences between synthetic and real-world data, we selected 5 hours of raw, non-reverberant data from the SonicSet validation set and recorded a real-world speech separation dataset, providing a reference for comparing SonicSet with other synthetic datasets. For speech enhancement, we utilized the real-world dataset RealMAN to validate the acoustic gap between SonicSet and existing synthetic datasets. The results indicate that models trained on SonicSet generalize better to real-world scenarios compared to other synthetic datasets. Code is publicly available at ***https://cslikai.cn/SonicSim/***.'}",https://openreview.net{'value': '/pdf/f19532957446c720a4bea7cb4af8fb3008198079.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=HfWcFs7XLR,"{'value': ""Agents' Room:  Narrative Generation through Multi-step Collaboration""}",Fantine Huot; Reinald Kim Amplayo; Jennimaria Palomaki; Alice Shoshana Jakobovits; Elizabeth Clark; Mirella Lapata,~Fantine_Huot1; ~Reinald_Kim_Amplayo2; ~Jennimaria_Palomaki1; ~Alice_Shoshana_Jakobovits2; ~Elizabeth_Clark2; ~Mirella_Lapata1,"{'value': ['fiction', 'creative writing', 'long-form generation', 'LLMs', 'agent', 'collaboration', 'multi-agent', 'dataset', 'evaluation']}","{'value': ""Writing compelling fiction is a multifaceted process combining elements such as crafting a plot, developing interesting characters, and using evocative language. While large language models (LLMs) show promise for story writing, they currently rely heavily on intricate prompting, which limits their use. We propose Agents' Room, a generation framework inspired by narrative theory, that decomposes narrative writing into subtasks tackled by specialized agents. To illustrate our method, we introduce Tell Me A Story, a high-quality dataset of complex writing prompts and human-written stories, and a novel evaluation framework designed specifically for assessing long narratives. We show that Agents' Room generates stories that are preferred by expert evaluators over those produced by baseline systems by leveraging collaboration and specialization to decompose the complex story writing task into tractable components. We provide extensive analysis with automated and human-based metrics of the generated output.""}",https://openreview.net{'value': '/pdf/28c4bdc08fd7e4c2b2b7308c42d0447cbf1a0620.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=HZgZrtIreg,{'value': 'Generalizing Weisfeiler-Lehman Kernels to Subgraphs'},Dongkwan Kim; Alice Oh,~Dongkwan_Kim1; ~Alice_Oh1,"{'value': ['Graph Neural Networks', 'Graph Kernels', 'Subgraphs']}","{'value': 'Subgraph representation learning has been effective in solving various real-world problems. However, current graph neural networks (GNNs) produce suboptimal results for subgraph-level tasks due to their inability to capture complex interactions within and between subgraphs. To provide a more expressive and efficient alternative, we propose WLKS, a Weisfeiler-Lehman (WL) kernel generalized for subgraphs by applying the WL algorithm on induced $k$-hop neighborhoods. We combine kernels across different $k$-hop levels to capture richer structural information that is not fully encoded in existing models. Our approach can balance expressiveness and efficiency by eliminating the need for neighborhood sampling. In experiments on eight real-world and synthetic benchmarks, WLKS significantly outperforms leading approaches on five datasets while reducing training time, ranging from 0.01x to 0.25x compared to the state-of-the-art.'}",https://openreview.net{'value': '/pdf/70073ec99127e3230194e999eacd312fb18d66e3.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=HVtu26XDAA,"{'value': 'MM1.5: Methods, Analysis & Insights from Multimodal LLM Fine-tuning'}",Haotian Zhang; Mingfei Gao; Zhe Gan; Philipp Dufter; Nina Wenzel; Forrest Huang; Dhruti Shah; Xianzhi Du; Bowen Zhang; Yanghao Li; Sam Dodge; Keen You; Zhen Yang; Aleksei Timofeev; Mingze Xu; Hong-You Chen; Jean-Philippe Fauconnier; Zhengfeng Lai; Haoxuan You; Zirui Wang; Afshin Dehghan; Peter Grasch; Yinfei Yang,~Haotian_Zhang3; ~Mingfei_Gao1; ~Zhe_Gan1; ~Philipp_Dufter1; ~Nina_Wenzel1; ~Forrest_Huang1; ~Dhruti_Shah1; ~Xianzhi_Du4; ~Bowen_Zhang2; ~Yanghao_Li1; ~Sam_Dodge1; ~Keen_You1; ~Zhen_Yang22; ~Aleksei_Timofeev1; ~Mingze_Xu2; ~Hong-You_Chen1; ~Jean-Philippe_Fauconnier1; ~Zhengfeng_Lai1; ~Haoxuan_You1; ~Zirui_Wang1; ~Afshin_Dehghan5; ~Peter_Grasch1; ~Yinfei_Yang1,{'value': ['Multimodal LLM']},"{'value': 'We present MM1.5, a new family of multimodal large language models (MLLMs) designed to enhance capabilities in text-rich image understanding, visual referring and grounding, and multi-image reasoning. Building upon the MM1 architecture, MM1.5 adopts a data-centric approach to model training, systematically exploring the impact of diverse data mixtures across the entire model training lifecycle. This includes high-quality OCR data and synthetic captions for continual pre-training, as well as an optimized visual instruction-tuning data mixture for supervised fine-tuning. Our models range from 1B to 30B parameters, encompassing both dense and mixture-of-experts (MoE) variants, and demonstrate that careful data curation and training strategies can yield strong performance even at small scales (1B and 3B). Additionally, we introduce two specialized variants: MM1.5-Video, designed for video understanding, and MM1.5-UI, tailored for mobile UI understanding. Through extensive empirical studies and ablations, we provide detailed insights into the training processes and decisions that inform our final designs, offering valuable guidance for future research in MLLM development.'}",https://openreview.net{'value': '/pdf/c50cf3b81572b6d30be36d8a34d830b59d99cbf4.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=HR1ujVR0ig,{'value': 'Learning Generalizable Skills from Offline Multi-Task Data for Multi-Agent Cooperation'},Sicong Liu; Yang Shu; Chenjuan Guo; Bin Yang,~Sicong_Liu2; ~Yang_Shu1; ~Chenjuan_Guo1; ~Bin_Yang4,"{'value': ['Reinforcement Learning', 'Multi-Agent Reinforcemenr Learning']}","{'value': 'Learning cooperative multi-agent policy from offline multi-task data that can generalize to unseen tasks with varying numbers of agents and targets is an attractive problem in many scenarios. Although aggregating general behavior patterns among multiple tasks as skills to improve policy transfer is a promising approach, two primary challenges hinder the further advancement of skill learning in offline multi-task MARL. Firstly, extracting general cooperative behaviors from various action sequences as common skills lacks bringing cooperative temporal knowledge into them. Secondly, existing works only involve common skills and can not adaptively choose independent knowledge as task-specific skills in each task for fine-grained action execution. To tackle these challenges, we propose Hierarchical and Separate Skill Discovery (HiSSD), a novel approach for generalizable offline multi-task MARL through skill learning. HiSSD leverages a hierarchical framework that jointly learns common and task-specific skills. The common skills learn cooperative temporal knowledge and enable in-sample exploitation for offline multi-task MARL. The task-specific skills represent the priors of each task and achieve a task-guided fine-grained action execution. To verify the advancement of our method, we conduct experiments on multi-agent MuJoCo and SMAC benchmarks. After training the policy using HiSSD on offline multi-task data, the empirical results show that HiSSD assigns effective cooperative behaviors and obtains superior performance in unseen tasks.'}",https://openreview.net{'value': '/pdf/55f839f286be8391e060e5db2d8229fb8bf6402a.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=HMVDiaWMwM,{'value': 'Guided Score identity Distillation for Data-Free One-Step Text-to-Image Generation'},Mingyuan Zhou; Zhendong Wang; Huangjie Zheng; Hai Huang,~Mingyuan_Zhou1; ~Zhendong_Wang1; ~Huangjie_Zheng1; ~Hai_Huang5,"{'value': ['stable diffusion', 'data-free distillation', 'single-step generation', 'classifier-free guidance']}","{'value': 'Diffusion-based text-to-image generation models trained on extensive text-image pairs have demonstrated the ability to produce photorealistic images aligned with textual descriptions. However, a significant limitation of these models is their slow sample generation process, which requires iterative refinement through the same network. To overcome this, we introduce a data-free guided distillation method that enables the efficient distillation of pretrained Stable Diffusion models without access to the real training data, often restricted due to legal, privacy, or cost concerns. This method enhances Score identity Distillation (SiD) with Long and Short Classifier-Free Guidance (LSG), an innovative strategy that applies Classifier-Free Guidance (CFG) not only to the evaluation of the pretrained diffusion model but also to the training and evaluation of the fake score network. We optimize a model-based explicit score matching loss using a score-identity-based approximation alongside our proposed guidance strategies for practical computation. By exclusively training with synthetic images generated by its one-step generator, our data-free distillation method rapidly improves FID and CLIP scores, achieving state-of-the-art FID performance while maintaining a competitive CLIP score. Notably, the one-step distillation of Stable Diffusion 1.5 achieves an FID of **8.15** on the COCO-2014 validation set, a record low value under the data-free setting.  Our code and checkpoints are available at https://github.com/mingyuanzhou/SiD-LSG.'}",https://openreview.net{'value': '/pdf/455edc90594a360f48dc075128308a031f2c32a8.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=HH4KWP8RP5,{'value': 'Towards Improving Exploration through Sibling Augmented GFlowNets'},Kanika Madan; Alex Lamb; Emmanuel Bengio; Glen Berseth; Yoshua Bengio,~Kanika_Madan3; ~Alex_Lamb1; ~Emmanuel_Bengio1; ~Glen_Berseth1; ~Yoshua_Bengio1,"{'value': ['Generative Models', 'Generative Flow Networks', 'Exploration']}","{'value': ""Exploration is a key factor for the success of an active learning agent, especially when dealing with sparse extrinsic terminal rewards and long trajectories. We introduce Sibling Augmented Generative Flow Networks (SA-GFN), a novel framework designed to enhance exploration and training efficiency of Generative Flow Networks (GFlowNets). SA-GFN uses a decoupled dual network architecture, comprising of a main Behavior Network and an exploratory Sibling Network, to enable a diverse exploration of the underlying distribution using intrinsic rewards. Inspired by the ideas on exploration from reinforcement learning, SA-GFN provides a general-purpose exploration and learning paradigm that integrates with multiple GFlowNet training objectives and is especially helpful for exploration over a wide range of sparse or low reward distributions and task structures. An extensive set of experiments across a diverse range of tasks, reward structures and trajectory lengths, along with a thorough set of ablations, demonstrate the superior performance of SA-GFN in terms of exploration efficacy and convergence speed as compared to the existing methods. In addition, SA-GFN's versatility and compatibility with different GFlowNet training objectives and intrinsic reward methods underscores its broad applicability in various problem domains.""}",https://openreview.net{'value': '/pdf/fafb3b9a21b7d4f8611d49487a900cd95d7921b9.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=HAwZGLcye3,{'value': 'BioDiscoveryAgent: An AI Agent for Designing Genetic Perturbation Experiments'},Yusuf H Roohani; Andrew H. Lee; Qian Huang; Jian Vora; Zachary Steinhart; Kexin Huang; Alexander Marson; Percy Liang; Jure Leskovec,~Yusuf_H_Roohani1; ~Andrew_H._Lee1; ~Qian_Huang2; ~Jian_Vora1; ~Zachary_Steinhart1; ~Kexin_Huang1; ~Alexander_Marson1; ~Percy_Liang1; ~Jure_Leskovec1,"{'value': ['large language models', 'agents', 'computational biology', 'genomics', 'AI for scientific discovery']}","{'value': ""Agents based on large language models have shown great potential in accelerating scientific discovery by leveraging their rich background knowledge and reasoning capabilities. In this paper, we introduce BioDiscoveryAgent, an agent that designs new experiments, reasons about their outcomes, and efficiently navigates the hypothesis space to reach desired solutions. We demonstrate our agent on the problem of designing genetic perturbation experiments, where the aim is to find a small subset out of many possible genes that, when perturbed, result in a specific phenotype (e.g., cell growth). Utilizing its biological knowledge, BioDiscoveryAgent can uniquely design new experiments without the need to train a machine learning model or explicitly design an acquisition function as in Bayesian optimization. Moreover, BioDiscoveryAgent using Claude 3.5 Sonnet achieves an average of 21% improvement in predicting relevant genetic perturbations across six datasets, and a 46% improvement in the harder task of non-essential gene perturbation, compared to existing Bayesian optimization baselines specifically trained for this task. Our evaluation includes one dataset that is unpublished, ensuring it is not part of the language model's training data. Additionally, BioDiscoveryAgent predicts gene combinations to perturb more than twice as accurately as a random baseline, a task so far not explored in the context of closed-loop experiment design. The agent also has access to tools for searching the biomedical literature, executing code to analyze biological datasets, and prompting another agent to critically evaluate its predictions. Overall, BioDiscoveryAgent is interpretable at every stage, representing an accessible new paradigm in the computational design of biological experiments with the potential to augment scientists' efficacy.""}",https://openreview.net{'value': '/pdf/dcfab1feaba7d38761a21e709247e9d97d4b98e2.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=H8hO3T3DYe,{'value': 'Partially Observed Trajectory Inference using Optimal Transport and a Dynamics Prior'},Anming Gu; Edward Chien; Kristjan Greenewald,~Anming_Gu1; ~Edward_Chien1; ~Kristjan_Greenewald1,"{'value': ['optimal transport', 'trajectory inference', 'stochastic calculus', 'optimization', 'Langevin dynamics']}","{'value': 'Trajectory inference seeks to recover the temporal dynamics of a population from snapshots of its (uncoupled) temporal marginals, i.e. where observed particles are \\emph{not} tracked over time. Prior works addressed this challenging problem under a stochastic differential equation (SDE) model with a gradient-driven drift in the observed space, introducing a minimum entropy estimator relative to the Wiener measure and a practical grid-free mean-field Langevin (MFL) algorithm using Schr\\""odinger bridges. Motivated by the success of observable state space models in the traditional paired trajectory inference problem (e.g. target tracking), we extend the above framework to a class of latent SDEs in the form of \\emph{observable state space models}.    \n In this setting, we use partial observations to infer trajectories in the latent space under a specified dynamics model (e.g. the constant velocity/acceleration models from target tracking). We introduce the PO-MFL algorithm to solve this latent trajectory inference problem and provide theoretical guarantees to the partially observed setting. Experiments validate the robustness of our method and the exponential convergence of the MFL dynamics, and demonstrate significant outperformance over the latent-free baseline in key scenarios.'}",https://openreview.net{'value': '/pdf/8fb34e8acd9aab5f87245526587427ee3abbbb93.pdf'},{'title_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=Gx04TnVjee,{'value': '3DTrajMaster: Mastering 3D Trajectory for Multi-Entity Motion in Video Generation'},Xiao FU; Xian Liu; Xintao Wang; Sida Peng; Menghan Xia; Xiaoyu Shi; Ziyang Yuan; Pengfei Wan; Di ZHANG; Dahua Lin,~Xiao_FU4; ~Xian_Liu1; ~Xintao_Wang1; ~Sida_Peng1; ~Menghan_Xia1; ~Xiaoyu_Shi1; ~Ziyang_Yuan1; ~Pengfei_Wan1; ~Di_ZHANG3; ~Dahua_Lin1,"{'value': ['Controllable Video Generation', '3D Motion Control', 'Multi-Entity Motion']}","{'value': 'This paper aims to manipulate multi-entity 3D motions in video generation. Previous methods on controllable video generation primarily leverage 2D control signals to manipulate object motions and have achieved remarkable synthesis results. However, 2D control signals are inherently limited in expressing the 3D nature of object motions. To overcome this problem, we introduce 3DTrajMaster, a robust controller that regulates multi-entity dynamics in 3D space, given user-desired 6DoF pose (location and rotation) sequences of entities. At the core of our approach is a plug-and-play 3D-motion grounded object injector that fuses multiple input entities with their respective 3D trajectories through a gated self-attention mechanism. In addition, we exploit an injector architecture to preserve the video diffusion prior, which is crucial for generalization ability. To mitigate video quality degradation, we introduce a domain adaptor during training and employ an annealed sampling strategy during inference. To address the lack of suitable training data, we construct a 360-Motion Dataset, which first correlates collected 3D human and animal assets with GPT-generated trajectory and then captures their motion with 12 evenly-surround cameras on diverse 3D UE platforms. Extensive experiments show that 3DTrajMaster sets a new state-of-the-art in both accuracy and generalization for controlling multi-entity 3D motions. Project page: http://fuxiao0719.github.io/projects/3dtrajmaster'}",https://openreview.net{'value': '/pdf/60dde1b47cfe7353ee58885f718d9a96c920bacd.pdf'},{'title_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=GtpubstM1D,"{'value': 'Advancing Mathematical Reasoning in Language Models: The Impact of Problem-Solving Data, Data Synthesis Methods, and Training Stages'}",Zui Chen; Tianqiao Liu; Tongqing; Mi Tian; Weiqi Luo; Zitao Liu,~Zui_Chen2; ~Tianqiao_Liu1; ~Tongqing1; ~Mi_Tian2; ~Weiqi_Luo1; ~Zitao_Liu1,{'value': ['LLM continue pretrain;math problem solving;data synthesis']},"{'value': ""Mathematical reasoning remains a challenging area for large language models (LLMs), prompting the development of math-specific LLMs such as LLEMMA, DeepSeekMath, and Qwen2-Math, among others. These models typically follow a two-stage training paradigm: pre-training with math-related corpora and post-training with problem datasets for supervised fine-tuning (SFT). Despite these efforts, the improvements in mathematical reasoning achieved through continued pre-training (CPT) are often less significant compared to those obtained via SFT. This study addresses this discrepancy by exploring alternative strategies during the pre-training phase, focusing on the use of problem-solving data over general mathematical corpora.\nWe investigate three primary research questions: (1) Can problem-solving data enhance the model's mathematical reasoning capabilities more effectively than general mathematical corpora during CPT? (2) Are synthetic data from the same source equally effective, and which synthesis methods are most efficient? (3) How do the capabilities developed from the same problem-solving data differ between the CPT and SFT stages, and what factors contribute to these differences?\nOur findings indicate that problem-solving data significantly enhances the model's mathematical capabilities compared to general mathematical corpora. We also identify effective data synthesis methods, demonstrating that the tutorship amplification synthesis method achieves the best performance. Furthermore, while SFT facilitates instruction-following abilities, it underperforms compared to CPT with the same data, which can be partially attributed to its poor learning capacity for more challenging problem-solving data. These insights provide valuable guidance for optimizing the mathematical reasoning capabilities of LLMs, culminating in our development of a powerful mathematical base model called MathGPT-8B.""}",https://openreview.net{'value': '/pdf/28bf6c5c9aadcf0b235efae5a422de20b0ad5c9c.pdf'},{'title_filter': 'Data Synthesis'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=GtHRhpgpzB,{'value': 'Learning Gain Map for Inverse Tone Mapping'},Yinuo Liao; Yuanshen Guan; Ruikang Xu; Jiacheng Li; Shida Sun; Zhiwei Xiong,~Yinuo_Liao1; ~Yuanshen_Guan1; ~Ruikang_Xu2; ~Jiacheng_Li5; ~Shida_Sun1; ~Zhiwei_Xiong1,"{'value': ['Computational Photography', 'Inverse Tone Mapping', 'Gain Map']}","{'value': 'For a more compatible and consistent high dynamic range (HDR) viewing experience, a new image format with a double-layer structure has been developed recently, which incorporates an auxiliary Gain Map (GM) within a standard dynamic range (SDR) image for adaptive HDR display. This new format motivates us to introduce a new task termed Gain Map-based Inverse Tone Mapping (GM-ITM), which focuses on learning the corresponding GM of an SDR image instead of directly estimating its HDR counterpart, thereby enabling a more effective up-conversion by leveraging the advantages of GM. The main challenge in this task, however, is to accurately estimate regional intensity variation with the fluctuating peak value. To this end, we propose a dual-branch network named GMNet, consisting of a Local Contrast Restoration (LCR) branch and a Global Luminance Estimation (GLE) branch to capture pixel-wise and image-wise information for GM estimation. Moreover, to facilitate the future research of the GM-ITM task, we build both synthetic and real-world datasets for comprehensive evaluations: synthetic SDR-GM pairs are generated from existing HDR resources, and real-world SDR-GM pairs are captured by mobile devices. Extensive experiments on these datasets demonstrate the superiority of our proposed GMNet over existing HDR-related methods both quantitatively and qualitatively. The codes and datasets are available at https://github.com/qtlark/GMNet.'}",https://openreview.net{'value': '/pdf/1111ac14e61aa23e0d90e549ffe63a08f8f2c844.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=GpUv1FvZi1,{'value': 'Towards counterfactual fairness through auxiliary variables'},Bowei Tian; Ziyao Wang; Shwai He; Wanghao Ye; Guoheng Sun; Yucong Dai; Yongkai Wu; Ang Li,~Bowei_Tian1; ~Ziyao_Wang2; ~Shwai_He1; ~Wanghao_Ye2; ~Guoheng_Sun1; ~Yucong_Dai1; ~Yongkai_Wu1; ~Ang_Li6,"{'value': ['Counterfactual', 'Fairness', 'Auxiliary variables']}","{'value': ""The challenge of balancing fairness and predictive accuracy in machine learning models, especially when sensitive attributes such as race, gender, or age are considered, has motivated substantial research in recent years. Counterfactual fairness ensures that predictions remain consistent across counterfactual variations of sensitive attributes, which is a crucial concept in addressing societal biases. \nHowever, existing counterfactual fairness approaches usually overlook intrinsic information about sensitive features, limiting their ability to achieve fairness while simultaneously maintaining performance. To tackle this challenge, we introduce EXOgenous Causal reasoning (EXOC), a novel causal reasoning framework motivated by exogenous variables. It leverages auxiliary variables to uncover intrinsic properties that give rise to sensitive attributes. Our framework explicitly defines an auxiliary node and a control node that contribute to counterfactual fairness and control the information flow within the model. Our evaluation, conducted on synthetic and real-world datasets, validates EXOC's superiority, showing that it outperforms state-of-the-art approaches in achieving counterfactual fairness without sacrificing accuracy. Our code is available at https://github.com/CASE-Lab-UMD/counterfactual_fairness_2025.""}",https://openreview.net{'value': '/pdf/ff6f04aebc48400e7d040f01b7a7306d9b00073b.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=GR0y0F3Ipd,{'value': 'MAPS: Advancing Multi-Modal Reasoning in Expert-Level Physical Science'},Erle Zhu; Yadi Liu; Zhe Zhang; Xujun Li; JinZhou; Xinjie Yu; Minlie Huang; Hongning Wang,~Erle_Zhu1; ~Yadi_Liu1; ~Zhe_Zhang24; ~Xujun_Li2; ~JinZhou1; ~Xinjie_Yu1; ~Minlie_Huang1; ~Hongning_Wang1,"{'value': ['multi-modal reasoning', 'scientific reasoning', 'physical simulation']}","{'value': 'Pre-trained on extensive text and image corpora, current Multi-Modal Large Language Models (MLLM) have shown strong capabilities in general visual reasoning tasks. \nHowever, their performance is still lacking in physical domains that require understanding diagrams with complex physical structures and quantitative analysis based on multi-modal information. \nTo address this, we develop a new framework, named **M**ulti-Modal Scientific Re**A**soning with **P**hysics Perception and **S**imulation (**MAPS**) based on an MLLM. \nMAPS decomposes expert-level multi-modal reasoning task into physical diagram understanding via a Physical Perception Model (PPM) and reasoning with physical knowledge via a simulator. \nThe PPM module is obtained by fine-tuning a visual language model using carefully designed synthetic data with paired physical diagrams and corresponding simulation language descriptions. \nAt the inference stage, MAPS integrates the simulation language description of the input diagram provided by PPM and results obtained through a Chain-of-Simulation process with MLLM to derive the underlying rationale and the final answer. \nValidated using our collected college-level circuit analysis problems, MAPS significantly improves reasoning accuracy of MLLM and outperforms all existing models. \nThe results confirm MAPS offers a promising direction for enhancing multi-modal scientific reasoning ability of MLLMs. \nWe will release our code, model and dataset used for our experiments upon publishing of this paper.'}",https://openreview.net{'value': '/pdf/c84516a8e4b9a68b710453218bcaa36dee327176.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=GEBkyKZOc4,{'value': 'Rational Decision-Making Agent with Learning Internal Utility Judgment'},Yining Ye; Xin Cong; Shizuo Tian; Yujia Qin; Chong Liu; Yankai Lin; Zhiyuan Liu; Maosong Sun,~Yining_Ye1; ~Xin_Cong1; ~Shizuo_Tian1; ~Yujia_Qin1; ~Chong_Liu5; ~Yankai_Lin1; ~Zhiyuan_Liu1; ~Maosong_Sun1,"{'value': ['Decision Making', 'Autonomous Agent', 'Large Lanugage Model', 'Elo Rating']}","{'value': 'With remarkable advancements, large language models (LLMs) have attracted significant efforts to develop LLM-based agents capable of executing intricate multi-step decision-making tasks. Existing approaches predominantly build upon the external performance measure to guide the decision-making process but the reliance on the external performance measure as prior is problematic in real-world scenarios, where such prior may be unavailable, flawed, or even erroneous. For genuine autonomous decision-making for LLM-based agents, it is imperative to develop rationality from their posterior experiences to judge the utility of each decision independently. In this work, we propose RaDAgent (Rational Decision-Making Agent), which fosters the development of its rationality through an iterative framework involving Experience Exploration and Utility Learning. Within this framework, Elo-based Utility Learning is devised to assign Elo scores to individual decision steps to judge their utilities via pairwise comparisons. Consequently, these Elo scores guide the decision-making process to derive optimal outcomes. Experimental results on the Game of 24, WebShop, ToolBench and RestBench datasets demonstrate RaDAgent’s superiority over baselines, achieving about 7.8% improvement on average. Besides, RaDAgent also can reduce costs (ChatGPT API calls), highlighting its effectiveness and efficiency.'}",https://openreview.net{'value': '/pdf/b89ee2bc76d6ed0cbbcdc73844bdd1a1e0b8abdb.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=GBIUbwW9D8,{'value': 'ExACT: Teaching AI Agents to Explore with Reflective-MCTS and Exploratory Learning'},Xiao Yu; Baolin Peng; Vineeth Vajipey; Hao Cheng; Michel Galley; Jianfeng Gao; Zhou Yu,~Xiao_Yu4; ~Baolin_Peng2; ~Vineeth_Vajipey1; ~Hao_Cheng4; ~Michel_Galley1; ~Jianfeng_Gao1; ~Zhou_Yu1,"{'value': ['AI agent', 'tree search', 'self-improvement']}","{'value': ""Autonomous agents have demonstrated significant potential in automating complex multistep decision-making tasks. However, even state-of-the-art vision-language models (VLMs), such as GPT-4o, still fall short of human-level performance, particularly in intricate web environments and long-horizon planning tasks. To address these limitations, we introduce Reflective Monte Carlo Tree Search (R-MCTS), a novel test-time algorithm designed to enhance the ability of AI agents, e.g., powered by GPT-4o, to explore decision space on the fly.\nR-MCTS extends traditional MCTS by 1) incorporating contrastive reflection, allowing agents to learn from past interactions and dynamically improve their search efficiency; and 2) using multi-agent debate to provide reliable state evaluation. Moreover, we improve the agent's performance by fine-tuning GPT-4o through self-learning, using R-MCTS generated tree traversals without any human-provided labels. On the challenging VisualWebArena benchmark, our GPT-4o-based R-MCTS agent achieves a 6% to 30% relative improvement across various tasks compared to the previous state-of-the-art. Additionally, we show that the knowledge gained from test-time search can be effectively transferred back to GPT-4o via fine-tuning. The fine-tuned GPT-4o matches 97\\% of R-MCTS's performance while reducing compute usage by a factor of four at test time. Furthermore, qualitative results reveal that the fine-tuned GPT-4o model demonstrates the ability to explore the environment, evaluate a state, and backtrack to viable ones when it detects that the current state cannot lead to success. Moreover, our work demonstrates the compute scaling properties in both training - data collection with R-MCTS - and testing time. These results suggest a promising research direction to enhance VLMs' reasoning and planning capabilities for agentic applications via test-time search and self-learning.""}",https://openreview.net{'value': '/pdf/ea99959076e5e7a18347780d5bc686da9e19040b.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=G7sIFXugTX,{'value': 'SWE-Search: Enhancing Software Agents with Monte Carlo Tree Search and Iterative Refinement'},Antonis Antoniades; Albert Örwall; Kexun Zhang; Yuxi Xie; Anirudh Goyal; William Yang Wang,~Antonis_Antoniades1; ~Albert_Örwall1; ~Kexun_Zhang1; ~Yuxi_Xie1; ~Anirudh_Goyal1; ~William_Yang_Wang2,"{'value': ['agents', 'LLM', 'SWE-agents', 'SWE-bench', 'search', 'planning', 'reasoning', 'self-improvement', 'open-ended']}","{'value': ""Software engineers operating in complex and dynamic environments must continuously adapt to evolving requirements, learn iteratively from experience, and reconsider their approaches based on new insights. However, current large language model (LLM)-based software agents often follow linear, sequential processes that prevent backtracking and exploration of alternative solutions, limiting their ability to rethink their strategies when initial approaches prove ineffective. To address these challenges, we propose SWE-Search, a multi-agent framework that integrates Monte Carlo Tree Search (MCTS) with a self-improvement mechanism to enhance software agents' performance on repository-level software tasks. SWE-Search extends traditional MCTS by incorporating a hybrid value function that leverages LLMs for both numerical value estimation and qualitative evaluation. This enables self-feedback loops where agents iteratively refine their strategies based on both quantitative numerical evaluations and qualitative natural language assessments of pursued trajectories. The framework includes a SWE-Agent for adaptive exploration, a Value Agent for iterative feedback, and a Discriminator Agent that facilitates multi-agent debate for collaborative decision-making. Applied to the SWE-bench benchmark, our approach demonstrates a 23% relative improvement in performance across five models compared to standard open-source agents without MCTS. Our analysis reveals how performance scales with increased inference-time compute through deeper search, providing a pathway to improve software agents without requiring larger models or additional training data. This highlights the potential of self-evaluation driven search techniques in complex software engineering environments.""}",https://openreview.net{'value': '/pdf/fd21b53183d7f37c46833653eed82df55976adf4.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=G6dMvRuhFr,{'value': 'Grounding Video Models to Actions through Goal Conditioned Exploration'},Yunhao Luo; Yilun Du,~Yunhao_Luo1; ~Yilun_Du1,"{'value': ['Embodied AI', 'Decision Making', 'Robotics', 'Video Model']}","{'value': 'Large video models, pretrained on massive quantities of amount of Internet video,  provide a rich source of physical knowledge about the dynamics and motions of objects and tasks.\nHowever, video models are not grounded in the embodiment of an agent, and do not describe how to actuate the world to reach the visual states depicted in a video.\nTo tackle this problem, current methods use a separate vision-based inverse dynamic model trained on embodiment-specific data to map image states to actions. \nGathering data to train such a model is often expensive and challenging, and this model is limited to visual settings similar to the ones in which data is available.\nIn this paper, we investigate how to directly  ground video models to continuous actions through self-exploration in the embodied environment -- using generated video states as visual goals for exploration.\nWe propose a framework that uses trajectory level action generation in combination with video guidance to\nenable an agent to solve complex tasks without any external supervision, e.g., rewards, action labels, or segmentation masks.\nWe validate the proposed approach on 8 tasks in Libero, 6 tasks in MetaWorld, 4 tasks in Calvin, and 12 tasks in iThor Visual Navigation. \nWe show how our approach is on par with or even surpasses multiple behavior cloning baselines trained on expert demonstrations while without requiring any action annotations.'}",https://openreview.net{'value': '/pdf/a77c12830cd182e6da53c94da81de0ab869ce943.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=G6aJyS0ZV0,{'value': '3D StreetUnveiler with Semantic-aware 2DGS - a simple baseline'},Jingwei Xu; Yikai Wang; Yiqun Zhao; Yanwei Fu; Shenghua Gao,~Jingwei_Xu4; ~Yikai_Wang1; ~Yiqun_Zhao1; ~Yanwei_Fu2; ~Shenghua_Gao1,"{'value': ['3D inpainting', 'Empty Street Reconstruction']}","{'value': 'Unveiling an empty street from crowded observations captured by in-car cameras is crucial for autonomous driving. However, removing all temporarily static objects, such as stopped vehicles and standing pedestrians, presents a significant challenge. Unlike object-centric 3D inpainting, which relies on thorough observation in a small scene, street scene cases involve long trajectories that differ from previous 3D inpainting tasks. The camera-centric moving environment of captured videos further complicates the task due to the limited degree and time duration of object observation. To address these obstacles, we introduce StreetUnveiler to reconstruct an empty street. StreetUnveiler learns a 3D representation of the empty street from crowded observations. Our representation is based on the hard-label semantic 2D Gaussian Splatting (2DGS) for its scalability and ability to identify Gaussians to be removed. We inpaint rendered image after removing unwanted Gaussians to provide pseudo-labels and subsequently re-optimize the 2DGS. Given its temporal continuous movement, we divide the empty street scene into observed, partial-observed, and unobserved regions, which we propose to locate through a rendered alpha map. This decomposition helps us to minimize the regions that need to be inpainted. To enhance the temporal consistency of the inpainting, we introduce a novel time-reversal framework to inpaint frames in reverse order and use later frames as references for earlier frames to fully utilize the long-trajectory observations. Our experiments conducted on the street scene dataset successfully reconstructed a 3D representation of the empty street. The mesh representation of the empty street can be extracted for further applications.'}",https://openreview.net{'value': '/pdf/8aceaac31241af412c07cac40c3adcbbecc699fd.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=G5DziesYxL,"{'value': 'Bridging the Data Provenance Gap Across Text, Speech, and Video'}",Shayne Longpre; Nikhil Singh; Manuel Cherep; Kushagra Tiwary; Joanna Materzynska; William Brannon; Robert Mahari; Naana Obeng-Marnu; Manan Dey; Mohammed Hamdy; Nayan Saxena; Ahmad Mustafa Anis; Emad A. Alghamdi; Vu Minh Chien; Da Yin; Kun Qian; Yizhi LI; Minnie Liang; An Dinh; Shrestha Mohanty; Deividas Mataciunas; Tobin South; Jianguo Zhang; Ariel N. Lee; Campbell S. Lund; Christopher Klamm; Damien Sileo; Diganta Misra; Enrico Shippole; Kevin Klyman; Lester James Validad Miranda; Niklas Muennighoff; Seonghyeon Ye; Seungone Kim; Vipul Gupta; Vivek Sharma; Xuhui Zhou; Caiming Xiong; Luis Villa; Stella Biderman; Alex Pentland; Sara Hooker; Jad Kabbara,~Shayne_Longpre1; ~Nikhil_Singh2; ~Manuel_Cherep1; ~Kushagra_Tiwary1; ~Joanna_Materzynska1; ~William_Brannon1; ~Robert_Mahari1; ~Naana_Obeng-Marnu1; ~Manan_Dey2; ~Mohammed_Hamdy1; ~Nayan_Saxena1; ~Ahmad_Mustafa_Anis1; ~Emad_A._Alghamdi1; ~Vu_Minh_Chien1; ~Da_Yin2; ~Kun_Qian2; ~Yizhi_LI1; ~Minnie_Liang1; ~An_Dinh1; ~Shrestha_Mohanty1; ~Deividas_Mataciunas1; ~Tobin_South1; ~Jianguo_Zhang3; ~Ariel_N._Lee1; ~Campbell_S._Lund1; ~Christopher_Klamm1; ~Damien_Sileo2; ~Diganta_Misra1; ~Enrico_Shippole1; ~Kevin_Klyman1; ~Lester_James_Validad_Miranda1; ~Niklas_Muennighoff1; ~Seonghyeon_Ye1; ~Seungone_Kim1; ~Vipul_Gupta3; ~Vivek_Sharma1; ~Xuhui_Zhou1; ~Caiming_Xiong1; ~Luis_Villa1; ~Stella_Biderman1; ~Alex_Pentland1; ~Sara_Hooker2; ~Jad_Kabbara1,"{'value': ['training data', 'audit', 'speech', 'video', 'text']}","{'value': 'Progress in AI is driven largely by the scale and quality of training data. Despite this, there is a deficit of empirical analysis examining the attributes of well-established datasets beyond text. In this work we conduct the largest and first-of-its-kind longitudinal audit across modalities --- popular text, speech, and video datasets --- from their detailed sourcing trends and use restrictions to their geographical and linguistic representation. Our manual analysis covers nearly 4000 public datasets between 1990-2024, spanning 608 languages, 798 sources, 659 organizations, and 67 countries. We find that multimodal machine learning applications have overwhelmingly turned to web-crawled, synthetic, and social media platforms, such as YouTube, for their training sets, eclipsing all other sources since 2019. Secondly, tracing the chain of dataset derivations we find that while less than 33% of datasets are restrictively licensed, over 80% of the source content in widely-used text, speech, and video datasets, carry non-commercial restrictions. Finally, counter to the rising number of languages and geographies represented in public AI training datasets, our audit demonstrates measures of relative geographical and multilingual representation have failed to significantly improve their coverage since 2013. We believe the breadth of our audit enables us to empirically examine trends in data sourcing, restrictions, and Western-centricity at an ecosystem-level, and that visibility into these questions are essential to progress in responsible AI. As a contribution to ongoing improvements in dataset transparency and responsible use, we release our entire multimodal audit, allowing practitioners to trace data provenance across text, speech, and video.'}",https://openreview.net{'value': '/pdf/fc66de1134c9c93d4dc162d692f75b71f0a43ae1.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=G1r2rBkUdu,{'value': 'Synergy Between Sufficient Changes and Sparse Mixing Procedure for Disentangled Representation Learning'},Zijian Li; Shunxing Fan; Yujia Zheng; Ignavier Ng; Shaoan Xie; Guangyi Chen; Xinshuai Dong; Ruichu Cai; Kun Zhang,~Zijian_Li1; ~Shunxing_Fan1; ~Yujia_Zheng1; ~Ignavier_Ng1; ~Shaoan_Xie4; ~Guangyi_Chen1; ~Xinshuai_Dong1; ~Ruichu_Cai1; ~Kun_Zhang1,"{'value': ['Disentangled Representation Learning', 'Identifiability']}","{'value': 'Disentangled representation learning aims to uncover the latent variables underlying observed data, yet identifying these variables under mild assumptions remains challenging. Some methods rely on sufficient changes in the distribution of latent variables indicated by auxiliary variables, such as domain indices, but acquiring enough domains is often impractical. Alternative approaches exploit the structural sparsity assumption on mixing processes, but this constraint may not hold in practice. Interestingly, we find that these two seemingly unrelated assumptions can actually complement each other. Specifically, when conditioned on auxiliary variables, the sparse mixing process induces independence between latent and observed variables, which simplifies the mapping from estimated to true latent variables and hence compensates for deficiencies of auxiliary variables. Building on this insight, we propose an identifiability theory with less restrictive constraints regarding the auxiliary variables and the sparse mixing process, enhancing applicability to real-world scenarios. Additionally, we develop a generative model framework incorporating a domain encoding network and a sparse mixing constraint and provide two implementations based on variational autoencoders and generative adversarial networks. Experiment results on synthetic and real-world datasets support our theoretical results.'}",https://openreview.net{'value': '/pdf/152c4cf151ec62cf263bbc0b9da92581098240cd.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=FoF5RaA3ug,{'value': 'GIFT: Unlocking Full Potential of Labels in Distilled Dataset at Near-zero Cost'},Xinyi Shang; Peng Sun; Tao Lin,~Xinyi_Shang2; ~Peng_Sun13; ~Tao_Lin1,"{'value': ['Dataset Distillation', 'Soft Label']}","{'value': 'Recent advancements in dataset distillation have demonstrated the significant benefits of employing soft labels generated by pre-trained teacher models.\n    In this paper, we introduce a novel perspective by emphasizing the full utilization of labels.\n    We first conduct a comprehensive comparison of various loss functions for soft label utilization in dataset distillation, revealing that the model trained on the synthetic dataset exhibits high sensitivity to the choice of loss function for soft label utilization.\n    This finding highlights the necessity of a universal loss function for training models on synthetic datasets.\n    Building on these insights, we introduce an extremely simple yet surprisingly effective plug-and-play approach, GIFT, which encompasses soft label refinement and a cosine similarity-based loss function to efficiently leverage full label information. \n    Extensive experiments indicate that GIFT consistently enhances state-of-the-art dataset distillation methods across various dataset scales without incurring additional computational costs.\n    Importantly, GIFT significantly enhances cross-optimizer generalization, an area previously overlooked.\n    For instance, on ImageNet-1K with IPC = 10, GIFT enhances the state-of-the-art method RDED by 30.8% in cross-optimizer generalization. Our code is available at https://github.com/LINs-lab/GIFT.'}",https://openreview.net{'value': '/pdf/21b1f50a6031f94da74a1987176dee6c24e66b95.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=FQhDIGuaJ4,{'value': 'Wavelet Diffusion Neural Operator'},Peiyan Hu; Rui Wang; Xiang Zheng; Tao Zhang; Haodong Feng; Ruiqi Feng; Long Wei; Yue Wang; Zhi-Ming Ma; Tailin Wu,~Peiyan_Hu1; ~Rui_Wang56; ~Xiang_Zheng5; ~Tao_Zhang34; ~Haodong_Feng1; ~Ruiqi_Feng1; ~Long_Wei1; ~Yue_Wang15; ~Zhi-Ming_Ma1; ~Tailin_Wu1,"{'value': ['PDE', 'physics', 'simulation', 'control', 'diffusion model', 'wavelet', 'abrupt changes', 'multi-resolution']}","{'value': ""Simulating and controlling physical systems described by partial differential equations (PDEs) are crucial tasks across science and engineering. Recently, diffusion generative models have emerged as a competitive class of methods for these tasks due to their ability to capture long-term dependencies and model high-dimensional states. However, diffusion models typically struggle with handling system states with abrupt changes and generalizing to higher resolutions. In this work, we propose Wavelet Diffusion Neural Operator (WDNO), a novel PDE simulation and control framework that enhances the handling of these complexities. WDNO comprises two key innovations. Firstly, WDNO performs diffusion-based generative modeling in the wavelet domain for the entire trajectory to handle abrupt changes and long-term dependencies effectively. Secondly, to address the issue of poor generalization across different resolutions, which is one of the fundamental tasks in modeling physical systems, we introduce multi-resolution training. We validate WDNO on five physical systems, including 1D advection equation, three challenging physical systems with abrupt changes (1D Burgers' equation, 1D compressible Navier-Stokes equation and 2D incompressible fluid), and a real-world dataset ERA5, which demonstrates superior performance on both simulation and control tasks over state-of-the-art methods, with significant improvements in long-term and detail prediction accuracy. Remarkably, in the challenging context of the 2D high-dimensional and indirect control task aimed at reducing smoke leakage, WDNO reduces the leakage by 78% compared to the second-best baseline. The code can be found at https://github.com/AI4Science-WestlakeU/wdno.git.""}",https://openreview.net{'value': '/pdf/d1bcdbd80bc38ce1a64a951e90ba3946f403fcd1.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=FGSgsefE0Y,{'value': 'MMRole: A Comprehensive Framework for Developing and Evaluating Multimodal Role-Playing Agents'},Yanqi Dai; Huanran Hu; Lei Wang; Shengjie Jin; Xu Chen; Zhiwu Lu,~Yanqi_Dai1; ~Huanran_Hu1; ~Lei_Wang46; ~Shengjie_Jin1; ~Xu_Chen13; ~Zhiwu_Lu1,"{'value': ['Multimodal Role-Playing Agents', 'Large Multimodal Models']}","{'value': ""Recently, Role-Playing Agents (RPAs) have garnered increasing attention for their potential to deliver emotional value and facilitate sociological research.\nHowever, existing studies are primarily confined to the textual modality, unable to simulate humans' multimodal perceptual capabilities.\nTo bridge this gap, we introduce the concept of Multimodal Role-Playing Agents (MRPAs), and propose a comprehensive framework, MMRole, for their development and evaluation, which comprises a personalized multimodal dataset and a robust evaluation approach.\nSpecifically, we construct a large-scale, high-quality dataset, MMRole-Data, consisting of 85 characters, 11K images, and 14K single or multi-turn dialogues.\nAdditionally, we present a robust evaluation approach, MMRole-Eval, encompassing eight metrics across three dimensions, where a reward model is designed to score MRPAs with the constructed ground-truth data for comparison.\nMoreover, we develop the first specialized MRPA, MMRole-Agent.\nExtensive evaluation results demonstrate the improved performance of MMRole-Agent and highlight the primary challenges in developing MRPAs, emphasizing the need for enhanced multimodal understanding and role-playing consistency.\nThe data, code, and models are all available at https://github.com/YanqiDai/MMRole.""}",https://openreview.net{'value': '/pdf/6ea2631589425d5cf3de283aed71b80c80b56b62.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=FEpAUnS7f7,{'value': 'Empowering Users in Digital Privacy Management through Interactive LLM-Based Agents'},BOLUN SUN; Yifan Zhou; Haiyun Jiang,~BOLUN_SUN1; ~Yifan_Zhou15; ~Haiyun_Jiang1,"{'value': ['LLM', 'Agent', 'Usable Privacy Policies', 'Benchmarking', 'HCI']}","{'value': 'This paper presents a novel application of large language models (LLMs) to enhance user comprehension of privacy policies through an interactive dialogue agent. We demonstrate that LLMs significantly outperform traditional models in tasks like Data Practice Identification, Choice Identification, Policy Summarization, and Privacy Question Answering, setting new benchmarks in privacy policy analysis. Building on these findings, we introduce an innovative LLM-based agent that functions as an expert system for processing website privacy policies, guiding users through complex legal language without requiring them to pose specific questions. A user study with 100 participants showed that users assisted by the agent had higher comprehension levels (mean score of 2.6 out of 3 vs. 1.8 in the control group), reduced cognitive load (task difficulty ratings of 3.2 out of 10 vs. 7.8), increased confidence in managing privacy, and completed tasks in less time (5.5 minutes vs. 15.8 minutes). This work highlights the potential of LLM-based agents to transform user interaction with privacy policies, leading to more informed consent and empowering users in the digital services landscape.'}",https://openreview.net{'value': '/pdf/2f83bab5b07b38f251127189d612ea11eaa96b53.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=FDimWzmcWn,{'value': 'AgentRefine: Enhancing Agent Generalization through Refinement Tuning'},Dayuan Fu; Keqing He; Yejie Wang; Wentao Hong; Zhuoma GongQue; Weihao Zeng; Wei Wang; Jingang Wang; Xunliang Cai; Weiran Xu,~Dayuan_Fu2; ~Keqing_He1; ~Yejie_Wang1; ~Wentao_Hong1; ~Zhuoma_GongQue1; ~Weihao_Zeng2; ~Wei_Wang41; ~Jingang_Wang1; ~Xunliang_Cai1; ~Weiran_Xu1,"{'value': ['agent', 'self-refine', 'diversity', 'generalization', 'data synthesis']}","{'value': 'Large Language Model (LLM) based agents have proved their ability to perform complex tasks like humans. However, there is still a large gap between open-sourced LLMs and commercial models like the GPT series. In this paper, we focus on improving the agent generalization capabilities of LLMs via instruction tuning. We first observe that the existing agent training corpus exhibits satisfactory results on held-in evaluation sets but fails to generalize to held-out sets. These agent-tuning works face severe formatting errors and are frequently stuck in the same mistake for a long while. We analyze that the poor generalization ability comes from overfitting to several manual agent environments and a lack of adaptation to new situations. They struggle with the wrong action steps and can not learn from the experience but just memorize existing observation-action relations. Inspired by the insight, we propose a novel AgentRefine framework for agent-tuning. The core idea is to enable the model to learn to correct its mistakes via observation in the trajectory. Specifically, we propose an agent synthesis framework to encompass a diverse array of environments and tasks and prompt a strong LLM to refine its error action according to the environment feedback. AgentRefine significantly outperforms state-of-the-art agent-tuning work in terms of generalization ability on diverse agent tasks. It also has better robustness facing perturbation and can generate diversified thought in inference. Our findings establish the correlation between agent generalization and self-refinement and provide a new paradigm for future research.'}",https://openreview.net{'value': '/pdf/ed23bb725e8e83d171ff039e600322fa09ee6de9.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=F5R0lG74Tu,{'value': 'DataGen: Unified Synthetic Dataset Generation via Large Language Models'},Yue Huang; Siyuan Wu; Chujie Gao; Dongping Chen; Qihui Zhang; Yao Wan; Tianyi Zhou; Chaowei Xiao; Jianfeng Gao; Lichao Sun; Xiangliang Zhang,~Yue_Huang9; ~Siyuan_Wu6; ~Chujie_Gao1; ~Dongping_Chen1; ~Qihui_Zhang1; ~Yao_Wan2; ~Tianyi_Zhou1; ~Chaowei_Xiao2; ~Jianfeng_Gao1; ~Lichao_Sun1; ~Xiangliang_Zhang1,"{'value': ['large language model', 'evaluation', 'synthetic data']}","{'value': 'Large Language Models (LLMs) such as GPT-4 and Llama3 have significantly impacted various fields by enabling high-quality synthetic data generation and reducing dependence on expensive human-generated datasets. \nDespite this, challenges remain in the areas of generalization, controllability, diversity, and truthfulness within the existing generative frameworks. To address these challenges, this paper presents DataGen, a comprehensive LLM-powered framework designed to produce diverse, accurate, and highly controllable datasets. DataGen is adaptable, supporting all types of text datasets and enhancing the generative process through innovative mechanisms. To augment data diversity, DataGen incorporates an attribute-guided generation module and a group checking feature. For accuracy, it employs a code-based mathematical assessment for label verification alongside a retrieval-augmented generation technique for factual validation. The framework also allows for user-specified constraints, enabling customization of the data generation process to suit particular requirements. Extensive experiments demonstrate the superior quality of data generated by DataGen, and each module within DataGen plays a critical role in this enhancement. Additionally, DataGen is applied in two practical scenarios: benchmarking LLMs and data augmentation. The results indicate that DataGen effectively supports dynamic and evolving benchmarking and that data augmentation improves LLM capabilities in various domains, including agent-oriented abilities and reasoning skills.'}",https://openreview.net{'value': '/pdf/d44bd033016a8a10c4ba10b872a9df703bbce9e8.pdf'},{'title_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=Ey8KcabBpB,{'value': 'EMOS: Embodiment-aware Heterogeneous Multi-robot Operating System with LLM Agents'},Junting Chen; Checheng Yu; Xunzhe Zhou; Tianqi Xu; Yao Mu; Mengkang Hu; Wenqi Shao; Yikai Wang; Guohao Li; Lin Shao,~Junting_Chen2; ~Checheng_Yu1; ~Xunzhe_Zhou1; ~Tianqi_Xu1; ~Yao_Mu1; ~Mengkang_Hu1; ~Wenqi_Shao2; ~Yikai_Wang2; ~Guohao_Li1; ~Lin_Shao2,"{'value': ['Embodied Artificial Intelligence', 'LLM Multi-agent System', 'Multi-robot System', 'Task Planning']}","{'value': 'Heterogeneous multi-robot systems (HMRS) have emerged as a powerful ap-\nproach for tackling complex tasks that single robots cannot manage alone. Current\nlarge-language-model-based multi-agent systems (LLM-based MAS) have shown\nsuccess in areas like software development and operating systems, but applying\nthese systems to robot control presents unique challenges. In particular, the ca-\npabilities of each agent in a multi-robot system are inherently tied to the physical\ncomposition of the robots, rather than predefined roles. To address this issue,\nwe introduce a novel multi-agent framework designed to enable effective collab-\noration among heterogeneous robots with varying embodiments and capabilities,\nalong with a new benchmark named Habitat-MAS. One of our key designs is\nRobot Resume: Instead of adopting human-designed role play, we propose a self-\nprompted approach, where agents comprehend robot URDF files and call robot\nkinematics tools to generate descriptions of their physics capabilities to guide\ntheir behavior in task planning and action execution. The Habitat-MAS bench-\nmark is designed to assess how a multi-agent framework handles tasks that require\nembodiment-aware reasoning, which includes 1) manipulation, 2) perception, 3)\nnavigation, and 4) comprehensive multi-floor object rearrangement. The experi-\nmental results indicate that the robot’s resume and the hierarchical design of our\nmulti-agent system are essential for the effective operation of the heterogeneous\nmulti-robot system within this intricate problem context.'}",https://openreview.net{'value': '/pdf/4bb1e48853d7189b88d1e952850f6d577f85b849.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=EqcLAU6gyU,{'value': 'Agent-Oriented Planning in Multi-Agent Systems'},Ao Li; Yuexiang Xie; Songze Li; Fugee Tsung; Bolin Ding; Yaliang Li,~Ao_Li2; ~Yuexiang_Xie1; ~Songze_Li1; ~Fugee_Tsung1; ~Bolin_Ding3; ~Yaliang_Li1,{'value': ['Multi-Agent System; Planning']},"{'value': 'Through the collaboration of multiple LLM-empowered agents possessing diverse expertise and tools, multi-agent systems achieve impressive progress in solving real-world problems. Given the user queries, the meta-agents, serving as the brain within multi-agent systems, are required to decompose the queries into multiple sub-tasks that can be allocated to suitable agents capable of solving them, so-called agent-oriented planning. In this study, we identify three critical design principles of agent-oriented planning, including solvability, completeness, and non-redundancy, to ensure that each sub-task can be effectively resolved, resulting in satisfactory responses to user queries. These principles further inspire us to propose AOP, a novel framework for agent-oriented planning in multi-agent systems, leveraging a fast task decomposition and allocation process followed by an effective and efficient evaluation via a reward model. According to the evaluation results, the meta-agent is also responsible for promptly making necessary adjustments to sub-tasks and scheduling. Besides, we integrate a feedback loop into AOP to further enhance the effectiveness and robustness of such a problem-solving process. Extensive experiments demonstrate the advancement of AOP in solving real-world problems compared to both single-agent systems and existing planning strategies for multi-agent systems. The source code is available at https://github.com/lalaliat/Agent-Oriented-Planning'}",https://openreview.net{'value': '/pdf/82bac503b8ff6352c48f82986a318160a941b2a4.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=EpnZEzYDUT,{'value': 'Efficient Multi-agent Offline Coordination via Diffusion-based Trajectory Stitching'},Lei Yuan; Yuqi Bian; Lihe Li; Ziqian Zhang; Cong Guan; Yang Yu,~Lei_Yuan2; ~Yuqi_Bian1; ~Lihe_Li1; ~Ziqian_Zhang2; ~Cong_Guan1; ~Yang_Yu5,"{'value': ['Multi-agent Reinforcement Learning', 'Offline MARL', 'Diffusion based Reinforcement Learning', 'Trajectory Stitching']}","{'value': 'Learning from offline data without interacting with the environment is a promising way to fully leverage the intelligent decision-making capabilities of multi-agent reinforcement learning (MARL). Previous approaches have primarily focused on developing learning techniques, such as conservative methods tailored to MARL using limited offline data. However, these methods often overlook the temporal relationships across different timesteps and spatial relationships between teammates, resulting in low learning efficiency in imbalanced data scenarios. To comprehensively explore the data structure of MARL and enhance learning efficiency, we propose Multi-Agent offline coordination via Diffusion-based Trajectory Stitching (MADiTS), a novel diffusion-based data augmentation pipeline that systematically generates trajectories by stitching high-quality coordination segments together. MADiTS first generates trajectory segments using a trained diffusion model, followed by applying a bidirectional dynamics constraint to ensure that the trajectories align with environmental dynamics. Additionally, we develop an offline credit assignment technique to identify and optimize the behavior of underperforming agents in the generated segments. This iterative procedure continues until a satisfactory augmented episode trajectory is generated within the predefined limit or is discarded otherwise. Empirical results on imbalanced datasets of multiple benchmarks demonstrate that MADiTS significantly improves MARL performance.'}",https://openreview.net{'value': '/pdf/45b94ad7d2c57f4e2e4c441d3076d7e697042240.pdf'},{'title_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=EpgoFFUM2q,{'value': 'Matcha: Mitigating Graph Structure Shifts with Test-Time Adaptation'},Wenxuan Bao; Zhichen Zeng; Zhining Liu; Hanghang Tong; Jingrui He,~Wenxuan_Bao1; ~Zhichen_Zeng1; ~Zhining_Liu1; ~Hanghang_Tong3; ~Jingrui_He1,"{'value': ['test-time adaptation', 'distribution shifts', 'structure shifts', 'graph neural networks']}","{'value': 'Powerful as they are, graph neural networks (GNNs) are known to be vulnerable to distribution shifts. Recently, test-time adaptation (TTA) has attracted attention due to its ability to adapt a pre-trained model to a target domain, without re-accessing the source domain. However, existing TTA algorithms are primarily designed for attribute shifts in vision tasks, where samples are independent. These methods perform poorly on graph data that experience structure shifts, where node connectivity differs between source and target graphs. We attribute this performance gap to the distinct impact of node attribute shifts versus graph structure shifts: the latter significantly degrades the quality of node representations and blurs the boundaries between different node categories. To address structure shifts in graphs, we propose Matcha, an innovative framework designed for effective and efficient adaptation to structure shifts by adjusting the htop-aggregation parameters in GNNs. To enhance the representation quality, we design a prediction-informed clustering loss to encourage the formation of distinct clusters for different node categories. Additionally, Matcha seamlessly integrates with existing TTA algorithms, allowing it to handle attribute shifts effectively while improving overall performance under combined structure and attribute shifts. We validate the effectiveness of Matcha on both synthetic and real-world datasets, demonstrating its robustness across various combinations of structure and attribute shifts. Our code\nis available at https://github.com/baowenxuan/Matcha.'}",https://openreview.net{'value': '/pdf/780833feb0c75e21a8172549f00dd490148ef842.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=EcrdmRT99M,{'value': 'The Effectiveness of Curvature-Based Rewiring and the Role of Hyperparameters in GNNs Revisited'},Floriano Tori; Vincent Holst; Vincent Ginis,~Floriano_Tori1; ~Vincent_Holst1; ~Vincent_Ginis1,"{'value': ['Geometric deep learning', 'Graph Neural Networks', 'Graph Rewiring', 'Curvature']}","{'value': 'Message passing is the dominant paradigm in Graph Neural Networks (GNNs). The efficiency of message passing, however, can be limited by the topology of the graph. This happens when information is lost during propagation due to being oversquashed when travelling through bottlenecks. To remedy this, recent efforts have focused on graph rewiring techniques, which disconnect the input graph originating from the data and the computational graph, on which message passing is performed. A prominent approach for this is to use discrete graph curvature measures, of which several variants have been proposed, to identify and rewire around bottlenecks, facilitating information propagation. While oversquashing has been demonstrated in synthetic datasets, in this work we reevaluate the performance gains that curvature-based rewiring brings to real-world datasets. We show that in these datasets, edges selected during the rewiring process are not in line with theoretical criteria identifying bottlenecks. This implies they do not necessarily oversquash information during message passing. Subsequently, we demonstrate that SOTA accuracies on these datasets are outliers originating from sweeps of hyperparameters—both the ones for training and dedicated ones related to the rewiring algorithm—instead of consistent performance gains. In conclusion, our analysis nuances the effectiveness of curvature-based rewiring in real-world datasets and brings a new perspective on the methods to evaluate GNN accuracy improvements.'}",https://openreview.net{'value': '/pdf/761199640d968068620d35645753f0870de7c809.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=EbCUbPZjM1,{'value': 'ReGen: Generative Robot Simulation via Inverse Design'},Phat Tan Nguyen; Tsun-Hsuan Wang; Zhang-Wei Hong; Erfan Aasi; Andrew Silva; Guy Rosman; Sertac Karaman; Daniela Rus,~Phat_Tan_Nguyen1; ~Tsun-Hsuan_Wang2; ~Zhang-Wei_Hong1; ~Erfan_Aasi1; ~Andrew_Silva1; ~Guy_Rosman2; ~Sertac_Karaman1; ~Daniela_Rus1,"{'value': ['generative simulation', 'robot', 'autonomous driving', 'large language model', 'inverse design']}","{'value': ""Simulation plays a key role in scaling robot learning and validating policies, but constructing simulations remains labor-intensive. In this paper, we introduce ReGen, a generative simulation framework that automates this process using inverse design. Given an agent's behavior (such as a motion trajectory or objective function) and its textual description, we infer the underlying scenarios and environments that could have caused the behavior.\nOur approach leverages large language models to construct and expand a graph that captures cause-and-effect relationships and relevant entities with properties in the environment, which is then processed to configure a robot simulation environment. Our approach supports (i) augmenting simulations based on ego-agent behaviors, (ii) controllable, counterfactual scenario generation, (iii) reasoning about agent cognition and mental states, and (iv) reasoning with distinct sensing modalities, such as braking due to faulty GPS signals. \nWe demonstrate our method in autonomous driving and robot manipulation tasks, generating more diverse, complex simulated environments compared to existing simulations with high success rates, and enabling controllable generation for corner cases. This approach enhances the validation of robot policies and supports data or simulation augmentation, advancing scalable robot learning for improved generalization and robustness.""}",https://openreview.net{'value': '/pdf/05a68cd66fa775acbad6a246f7a68930250738e5.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=EEgYUccwsV,{'value': 'AgentTrek: Agent Trajectory Synthesis via Guiding Replay with Web Tutorials'},Yiheng Xu; Dunjie Lu; Zhennan Shen; Junli Wang; Zekun Wang; Yuchen Mao; Caiming Xiong; Tao Yu,~Yiheng_Xu1; ~Dunjie_Lu1; ~Zhennan_Shen1; ~Junli_Wang3; ~Zekun_Wang1; ~Yuchen_Mao1; ~Caiming_Xiong1; ~Tao_Yu5,"{'value': ['Data Synthesis', 'GUI Agent', 'Large Language Model']}","{'value': 'Graphical User Interface (GUI) agents hold great potential for automating complex tasks across diverse digital environments, from web applications to desktop software. However, the development of such agents is hindered by the lack of high-quality, multi-step trajectory data required for effective training. Existing approaches rely on expensive and labor-intensive human annotation, making them unsustainable at scale. To address this challenge, we propose AgentTrek, a scalable data synthesis pipeline that generates high-quality web agent trajectories by leveraging web tutorials. Our method automatically gathers tutorial-like texts from the internet, transforms them into task goals with step-by-step instructions, and employs a visual-language model (VLM) agent to simulate their execution in a real digital environment. A VLM-based evaluator ensures the correctness of the generated trajectories. We demonstrate that training GUI agents with these synthesized trajectories significantly improves their grounding and planning performance over the current models. Moreover, our approach is more cost-efficient compared to traditional human annotation methods. This work underscores the potential of guided replay with web tutorials as a viable strategy for large-scale GUI agent training, paving the way for more capable and autonomous digital agents.'}",https://openreview.net{'value': '/pdf/e95d923ccea15b1bab268aeeb8b3845547e3dafe.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=E2PFv7ad3p,{'value': 'Have the VLMs Lost Confidence? A Study of Sycophancy in VLMs'},Shuo Li; Tao Ji; Xiaoran Fan; Linsheng Lu; Leyi Yang; Yuming Yang; Zhiheng Xi; Rui Zheng; Yuran Wang; xh.zhao; Tao Gui; Qi Zhang; Xuanjing Huang,~Shuo_Li12; ~Tao_Ji1; ~Xiaoran_Fan3; ~Linsheng_Lu1; ~Leyi_Yang1; ~Yuming_Yang1; ~Zhiheng_Xi1; ~Rui_Zheng1; ~Yuran_Wang3; ~xh.zhao1; ~Tao_Gui1; ~Qi_Zhang8; ~Xuanjing_Huang1,"{'value': ['Multi-modal Model', 'Visual-Language Model', 'Sycophancy', 'Hallucination']}","{'value': ""In the study of LLMs, sycophancy represents a prevalent hallucination that poses significant challenges to these models. Specifically, LLMs often fail to adhere to original correct responses, instead blindly agreeing with users' opinions, even when those opinions are incorrect or malicious. However, research on sycophancy in visual language models (VLMs) has been scarce. In this work, we extend the exploration of sycophancy from LLMs to VLMs, introducing the MM-SY benchmark to evaluate this phenomenon. We present evaluation results from multiple representative models, addressing the gap in sycophancy research for VLMs. To mitigate sycophancy, we propose a synthetic dataset for training and employ methods based on prompts, supervised fine-tuning, and DPO. Our experiments demonstrate that these methods effectively alleviate sycophancy in VLMs. Additionally, we probe VLMs to assess the semantic impact of sycophancy and analyze the attention distribution of visual tokens. Our findings indicate that the ability to prevent sycophancy is predominantly observed in higher layers of the model. The lack of attention to image knowledge in these higher layers may contribute to sycophancy, and enhancing image attention at high layers proves beneficial in mitigating this issue.""}",https://openreview.net{'value': '/pdf/ef8171cb556dccdb2b6ff62235d32e8af31cccc3.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=E1m5yGMOiV,{'value': 'KinPFN: Bayesian Approximation of RNA Folding Kinetics using Prior-Data Fitted Networks'},Dominik Scheuer; Frederic Runge; Jörg K.H. Franke; Michael T. Wolfinger; Christoph Flamm; Frank Hutter,~Dominik_Scheuer1; ~Frederic_Runge1; ~Jörg_K.H._Franke1; ~Michael_T._Wolfinger1; ~Christoph_Flamm1; ~Frank_Hutter1,"{'value': ['RNA Folding Kinetics', 'Prior-Data Fitted Networks', 'Deep Learning', 'Synthetic Data', 'Transformer', 'Bayesian Inference']}","{'value': 'RNA is a dynamic biomolecule crucial for cellular regulation, with its function largely determined by its folding into complex structures, while misfolding can lead to multifaceted biological sequelae. During the folding process, RNA traverses through a series of intermediate structural states, with each transition occurring at variable rates that collectively influence the time required to reach the functional form. Understanding these folding kinetics is vital for predicting RNA behavior and optimizing applications in synthetic biology and drug discovery. While in silico kinetic RNA folding simulators are often computationally intensive and time-consuming, accurate approximations of the folding times can already be very informative to assess the efficiency of the folding process. In this work, we present KinPFN, a novel approach that leverages prior-data fitted networks to directly model the posterior predictive distribution of RNA folding times. By training on synthetic data representing arbitrary prior folding times, KinPFN efficiently approximates the cumulative distribution function of RNA folding times in a single forward pass, given only a few initial folding time examples. Our method offers a modular extension to existing RNA kinetics algorithms, promising significant computational speed-ups orders of magnitude faster, while achieving comparable results. We showcase the effectiveness of KinPFN through extensive evaluations and real-world case studies, demonstrating its potential for RNA folding kinetics analysis, its practical relevance, and generalization to other biological data.'}",https://openreview.net{'value': '/pdf/77ae32b7ffaa23bcf3d27080b8cc95f81c01f191.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=DugT77rRhW,{'value': 'Unposed Sparse Views Room Layout Reconstruction in the Age of Pretrain Model'},Yaxuan Huang; Xili Dai; Jianan Wang; Xianbiao Qi; Yixing Yuan; Xiangyu Yue,~Yaxuan_Huang1; ~Xili_Dai2; ~Jianan_Wang2; ~Xianbiao_Qi2; ~Yixing_Yuan1; ~Xiangyu_Yue1,"{'value': ['layout reconstruction', 'holistic 3D representation', 'large 3D model.']}","{'value': 'Room layout estimation from multiple-perspective images is poorly investigated due to the complexities that emerge from multi-view geometry, which requires muti-step solutions such as camera intrinsic and extrinsic estimation, image matching, and triangulation. However, in 3D reconstruction, the advancement of recent 3D foundation models such as DUSt3R has shifted the paradigm from the traditional multi-step structure-from-motion process to an end-to-end single-step approach.\nTo this end, we introduce Plane-DUSt3R, a novel method for multi-view room layout estimation leveraging the 3D foundation model DUSt3R. Plane-DUSt3R incorporates the DUSt3R framework and fine-tunes on a room layout dataset (Structure3D) with a modified objective to estimate structural planes. By generating uniform and parsimonious results, Plane-DUSt3R enables room layout estimation with only a single post-processing step and 2D detection results. \nUnlike previous methods that rely on single-perspective or panorama image, Plane-DUSt3R extends the setting to handle multiple-perspective images. Moreover, it offers a streamlined, end-to-end solution that simplifies the process and reduces error accumulation.\nExperimental results demonstrate that Plane-DUSt3R not only outperforms state-of-the-art methods on the synthetic dataset but also proves robust and effective on in the wild data with different image styles such as cartoon. Our code is available at: https://github.com/justacar/Plane-DUSt3R'}",https://openreview.net{'value': '/pdf/d2f32e6f968f5846fd88fcb0c2bc201ac9c7e66c.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=DtFCIfvAFc,{'value': 'Gaussian-Det: Learning Closed-Surface Gaussians for 3D Object Detection'},Hongru Yan; Yu Zheng; Yueqi Duan,~Hongru_Yan1; ~Yu_Zheng4; ~Yueqi_Duan1,"{'value': ['3D Gaussian Splatting', '3D Object Detection', 'Surface Closure']}","{'value': 'Skins wrapping around our bodies, leathers covering over the sofa, sheet metal coating the car – it suggests that objects are enclosed by a series of continuous surfaces, which provides us with informative geometry prior for objectness deduction. In this paper, we propose Gaussian-Det which leverages Gaussian Splatting as surface representation for multi-view based 3D object detection. Unlike existing monocular or NeRF-based methods which depict the objects via discrete positional data, Gaussian-Det models the objects in a continuous manner by formulating the input Gaussians as feature descriptors on a mass of partial surfaces. Furthermore, to address the numerous outliers inherently introduced by Gaussian splatting, we accordingly devise a Closure Inferring Module (CIM) for the comprehensive surface-based objectness deduction. CIM firstly estimates the probabilistic feature residuals for partial surfaces given the underdetermined nature of Gaussian Splatting, which are then coalesced into a holistic representation on the overall surface closure of the object proposal. In this way, the surface information Gaussian-Det exploits serves as the prior on the quality and reliability of objectness and the information basis of proposal refinement. Experiments on both synthetic and real-world datasets demonstrate that Gaussian-Det outperforms various existing approaches, in terms of both average precision and recall.'}",https://openreview.net{'value': '/pdf/5bcf65f41f5e17117dbbef292f8eb63cb7a351d9.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=DmEHmZ89iB,"{'value': 'Single Teacher, Multiple Perspectives: Teacher Knowledge Augmentation for Enhanced Knowledge Distillation'}",Md Imtiaz Hossain; Sharmen Akhter; Choong Seon Hong; Eui-Nam Huh,~Md_Imtiaz_Hossain1; ~Sharmen_Akhter2; ~Choong_Seon_Hong1; ~Eui-Nam_Huh1,"{'value': ['TeKAP', 'Teacher Knowledge Augmentation', 'Teacher Knowledge Perturbation', 'Single Teacher Multiple Perspectives', 'Synthetic Teacher', 'Knowledge Distillation', 'Ensemble Learning', 'Knowledge Transfer']}","{'value': 'Do diverse perspectives help students learn better? Multi-teacher knowledge distillation, which is a more effective technique than traditional single-teacher methods, supervises the student from different perspectives (i.e., teacher). While effective, multi-teacher, teacher ensemble, or teaching assistant-based approaches are computationally expensive and resource-intensive, as they require training multiple teacher networks. These concerns raise a question: can we supervise the student with diverse perspectives using only a single teacher? We, as the pioneer, demonstrate TeKAP, a novel teacher knowledge augmentation technique that generates multiple synthetic teacher knowledge by perturbing the knowledge of a single pretrained teacher i.e., Teacher Knowledge Augmentation via Perturbation, at both the feature and logit levels. These multiple augmented teachers simulate an ensemble of models together. The student model is trained on both the actual and augmented teacher knowledge, benefiting from the diversity of an ensemble without the need to train multiple teachers. TeKAP significantly reduces training time and computational resources, making it feasible for large-scale applications and easily manageable. Experimental results demonstrate that our proposed method helps existing state-of-the-art knowledge distillation techniques achieve better performance, highlighting its potential as a cost-effective alternative. The source code can be found in the supplementary.'}",https://openreview.net{'value': '/pdf/0a3e534b1c7d3e4cc993ff7afd515051c9024167.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=Dl6nkKKvlX,{'value': 'Balancing Act: Diversity and Consistency in Large Language Model Ensembles'},Ahmed Abdulaal; Chen Jin; Nina Montaña-Brown; Aryo Pradipta Gema; Daniel C. Castro; Daniel C. Alexander; Philip Alexander Teare; Tom Diethe; Dino Oglic; Amrutha Saseendran,~Ahmed_Abdulaal1; ~Chen_Jin3; ~Nina_Montaña-Brown1; ~Aryo_Pradipta_Gema1; ~Daniel_C._Castro1; ~Daniel_C._Alexander1; ~Philip_Alexander_Teare1; ~Tom_Diethe1; ~Dino_Oglic1; ~Amrutha_Saseendran1,"{'value': ['LLM', 'ensembling', 'diversity', 'consistency', 'mixture of agents', 'self decoding']}","{'value': 'Ensembling strategies for Large Language Models (LLMs) have demonstrated significant potential in improving performance across various tasks by combining the strengths of individual models. However, identifying the most effective ensembling method remains an open challenge, as neither maximizing output consistency through self-consistency decoding nor enhancing model diversity via frameworks like ""Mixture of Agents"" has proven universally optimal.  Motivated by this, we propose a unified framework to examine the trade-offs between task performance, model diversity, and output consistency in ensembles. More specifically, we introduce a consistency score that defines a gating mechanism for mixtures of agents and an algorithm for mixture refinement to investigate these trade-offs at the semantic and model levels, respectively. We incorporate our insights into a novel inference-time LLM ensembling strategy called the Dynamic Mixture of Agents (DMoA) and demonstrate that it achieves a new state-of-the-art result in the challenging Big Bench Hard mixed evaluations benchmark. Our analysis reveals that cross-validation bias can enhance performance, contingent on the expertise of the constituent models. We further demonstrate that distinct reasoning tasks—such as arithmetic reasoning, commonsense reasoning, and instruction following—require different model capabilities, leading to inherent task-dependent trade-offs that DMoA balances effectively.'}",https://openreview.net{'value': '/pdf/c1631b605d093a00fc9304e41cf634c7e3c2824a.pdf'},{'abstract_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=DcZpQhVpp9,{'value': 'ADMM for Structured Fractional Minimization'},Ganzhao Yuan,~Ganzhao_Yuan1,"{'value': ['Fractional Minimization', 'Nonconvex Optimization', 'Proximal Linearized ADMM', 'Nonsmooth Optimization', 'Convergence Analysis']}","{'value': ""This paper considers a class of structured fractional minimization problems. The numerator consists of a differentiable function, a simple nonconvex nonsmooth function, a concave nonsmooth function, and a convex nonsmooth function composed with a linear operator. The denominator is a continuous function that is either weakly convex or has a weakly convex square root. These problems are prevalent in various important applications in machine learning and data science. Existing methods, primarily based on subgradient methods and smoothing proximal gradient methods, often suffer from slow convergence and numerical stability issues. In this paper, we introduce {\\sf FADMM}, the first Alternating Direction Method of Multipliers tailored for this class of problems. {\\sf FADMM} decouples the original problem into linearized proximal subproblems, featuring two variants: one using Dinkelbach's parametric method ({\\sf FADMM-D}) and the other using the quadratic transform method ({\\sf FADMM-Q}). By introducing a novel Lyapunov function, we establish that {\\sf FADMM} converges to $\\epsilon$-approximate critical points of the problem within an oracle complexity of $\\mathcal{O}(1/\\epsilon^{3})$. Extensive experiments on synthetic and real-world datasets, including sparse Fisher discriminant analysis, robust Sharpe ratio minimization, and robust sparse recovery, demonstrate the effectiveness of our approach.""}",https://openreview.net{'value': '/pdf/9c090c0c1ddf87b28e4509498f044e87b5319beb.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=DaA0wAcTY7,{'value': 'TIPS: Text-Image Pretraining with Spatial awareness'},Kevis-kokitsi Maninis; Kaifeng Chen; Soham Ghosh; Arjun Karpur; Koert Chen; Ye Xia; Bingyi Cao; Daniel Salz; Guangxing Han; Jan Dlabal; Dan Gnanapragasam; Mojtaba Seyedhosseini; Howard Zhou; Andre Araujo,~Kevis-kokitsi_Maninis1; ~Kaifeng_Chen2; ~Soham_Ghosh1; ~Arjun_Karpur1; ~Koert_Chen1; ~Ye_Xia2; ~Bingyi_Cao1; ~Daniel_Salz1; ~Guangxing_Han1; ~Jan_Dlabal1; ~Dan_Gnanapragasam1; ~Mojtaba_Seyedhosseini2; ~Howard_Zhou1; ~Andre_Araujo1,"{'value': ['image representations', 'image-text', 'vision-language', 'dense understanding', 'computer vision']}","{'value': 'While image-text representation learning has become very popular in recent years, existing models tend to lack spatial awareness and have limited direct applicability for dense understanding tasks.\nFor this reason, self-supervised image-only pretraining is still the go-to method for many dense vision applications (e.g. depth estimation, semantic segmentation), despite the lack of explicit supervisory signals.\nIn this paper, we close this gap between image-text and self-supervised learning, by proposing a novel  general-purpose image-text model, which can be effectively used off the shelf for dense and global vision tasks.\nOur method, which we refer to as Text-Image Pretraining with Spatial awareness (TIPS), leverages two simple and effective insights.\nFirst, on textual supervision: we reveal that replacing noisy web image captions by synthetically generated textual descriptions boosts dense understanding performance significantly, due to a much richer signal for learning spatially aware representations.\nWe propose an adapted training method that combines noisy and synthetic captions, resulting in improvements across both dense and global understanding tasks.\nSecond, on the learning technique: we propose to combine contrastive image-text learning with self-supervised masked image modeling, to encourage spatial coherence, unlocking substantial enhancements for downstream applications.\nBuilding on these two ideas, we scale our model using the transformer architecture, trained on a curated set of public images.\nOur experiments are conducted on $8$ tasks involving $16$ datasets in total, demonstrating strong off-the-shelf performance on both dense and global understanding, for several image-only and image-text tasks.\nCode and models are released at https://github.com/google-deepmind/tips .'}",https://openreview.net{'value': '/pdf/f2e3fce86592274fc3d8117149f7447ce4271668.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=DSsSPr0RZJ,{'value': 'DSBench: How Far Are Data Science Agents from Becoming Data Science Experts?'},Liqiang Jing; Zhehui Huang; Xiaoyang Wang; Wenlin Yao; Wenhao Yu; Kaixin Ma; Hongming Zhang; Xinya Du; Dong Yu,~Liqiang_Jing1; ~Zhehui_Huang1; ~Xiaoyang_Wang1; ~Wenlin_Yao1; ~Wenhao_Yu2; ~Kaixin_Ma1; ~Hongming_Zhang2; ~Xinya_Du1; ~Dong_Yu2,"{'value': ['data science', 'agent', 'benchmark', 'llm']}","{'value': 'Large Language Models (LLMs) and Large Vision-Language Models (LVLMs) have demonstrated impressive language/vision reasoning abilities, igniting the recent trend of building agents for targeted applications such as shopping assistants or AI software engineers. Recently, many data science benchmarks have been proposed to investigate their performance in the data science domain. However, existing data science benchmarks still fall short when compared to real-world data science applications due to their simplified settings. To bridge this gap, we introduce DSBench, a comprehensive benchmark designed to evaluate data science agents with realistic tasks. This benchmark includes 466 data analysis tasks and 74 data modeling tasks, sourced from Eloquence and Kaggle competitions. DSBench offers a realistic setting by encompassing long contexts, multimodal task backgrounds, reasoning with large data files and multi-table structures, and performing end-to-end data modeling tasks. Our evaluation of state-of-the-art LLMs, LVLMs, and agents shows that they struggle with most tasks, with the best agent solving only 34.12% of data analysis tasks and achieving a 34.74% Relative Performance Gap (RPG). These findings underscore the need for further advancements in developing more practical, intelligent, and autonomous data science agents.'}",https://openreview.net{'value': '/pdf/c7598f99c29d589965e824c0fc1c1d64fc079c1e.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=DI4gW8viB6,{'value': 'Competing Large Language Models in Multi-Agent Gaming Environments'},Jen-tse Huang; Eric John Li; Man Ho LAM; Tian Liang; Wenxuan Wang; Youliang Yuan; Wenxiang Jiao; Xing Wang; Zhaopeng Tu; Michael Lyu,~Jen-tse_Huang1; ~Eric_John_Li1; ~Man_Ho_LAM1; ~Tian_Liang4; ~Wenxuan_Wang2; ~Youliang_Yuan1; ~Wenxiang_Jiao1; ~Xing_Wang1; ~Zhaopeng_Tu1; ~Michael_Lyu1,"{'value': ['Large Language Models', 'Games', 'Reasoning', 'Evaluation']}","{'value': ""Decision-making is a complex process requiring diverse abilities, making it an excellent framework for evaluating Large Language Models (LLMs). Researchers have examined LLMs' decision-making through the lens of Game Theory. However, existing evaluation mainly focus on two-player scenarios where an LLM competes against another. Additionally, previous benchmarks suffer from test set leakage due to their static design. We introduce GAMA($\\gamma$)-Bench, a new framework for evaluating LLMs' Gaming Ability in Multi-Agent environments. It includes eight classical game theory scenarios and a dynamic scoring scheme specially designed to quantitatively assess LLMs' performance. $\\gamma$-Bench allows flexible game settings and adapts the scoring system to different game parameters, enabling comprehensive evaluation of robustness, generalizability, and strategies for improvement. Our results indicate that GPT-3.5 demonstrates strong robustness but limited generalizability, which can be enhanced using methods like Chain-of-Thought. We also evaluate 13 LLMs from 6 model families, including GPT-3.5, GPT-4, Gemini, LLaMA-3.1, Mixtral, and Qwen-2. Gemini-1.5-Pro outperforms others, scoring of $69.8$ out of $100$, followed by LLaMA-3.1-70B ($65.9$) and Mixtral-8x22B ($62.4$). Our code and experimental results are publicly available at https://github.com/CUHK-ARISE/GAMABench.""}",https://openreview.net{'value': '/pdf/417bd7ffdc85996b563ee3eda3caa2e3258a7921.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=DD11okKg13,{'value': 'Exploring the Effectiveness of Object-Centric Representations in Visual Question Answering: Comparative Insights with Foundation Models'},Amir Mohammad Karimi Mamaghan; Samuele Papa; Karl Henrik Johansson; Stefan Bauer; Andrea Dittadi,~Amir_Mohammad_Karimi_Mamaghan1; ~Samuele_Papa1; ~Karl_Henrik_Johansson1; ~Stefan_Bauer1; ~Andrea_Dittadi1,"{'value': ['Object-centric Learning', 'Foundation Models']}","{'value': 'Object-centric (OC) representations, which model visual scenes as compositions of discrete objects, have the potential to be used in various downstream tasks to achieve systematic compositional generalization and facilitate reasoning. However, these claims have yet to be thoroughly validated empirically.\nRecently, foundation models have demonstrated unparalleled capabilities across diverse domains, from language to computer vision, positioning them as a potential cornerstone of future research for a wide range of computational tasks.\nIn this paper, we conduct an extensive empirical study on representation learning for downstream Visual Question Answering (VQA), which requires an accurate compositional understanding of the scene. \nWe thoroughly investigate the benefits and trade-offs of OC models and alternative approaches including large pre-trained foundation models on both synthetic and real-world data, ultimately identifying a promising path to leverage the strengths of both paradigms. \nThe extensiveness of our study, encompassing over 600 downstream VQA models and 15 different types of upstream representations, also provides several additional insights that we believe will be of interest to the community at large.'}",https://openreview.net{'value': '/pdf/2e2244e35587572061d96363bdadffc136df5aaf.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=DCpukR83sw,{'value': 'Interactive Adjustment for Human Trajectory Prediction with Individual Feedback'},Jianhua Sun; Yuxuan Li; Liang Chai; Cewu Lu,~Jianhua_Sun1; ~Yuxuan_Li2; ~Liang_Chai1; ~Cewu_Lu3,{'value': ['Human Trajectory Prediction']},"{'value': ""Human trajectory prediction is fundamental for autonomous driving and service robot. The research community has studied various important aspects of this task and made remarkable progress recently. However, there is an essential perspective which is not well exploited in previous research all along, namely individual feedback. Individual feedback exists in the sequential nature of trajectory prediction, where earlier predictions of a target can be verified over time by his ground-truth trajectories to obtain feedback which provides valuable experience for subsequent predictions on the same agent. In this paper, we show such feedback can reveal the strengths and weaknesses of the model's predictions on a specific target and heuristically guide to deliver better predictions on him. We present an interactive adjustment network to effectively model and leverage the feedback. This network first exploits the feedback from previous predictions to dynamically generate an adjuster which then interactively makes appropriate adjustments to current predictions for more accurate ones. We raise a novel displacement expectation loss to train this interactive architecture. Through experiments on representative prediction methods and widely-used benchmarks, we demonstrate the great value of individual feedback and the superior effectiveness of proposed interactive adjustment network.""}",https://openreview.net{'value': '/pdf/b6328df89249a76db86e956f596a2b8684d3af13.pdf'},{'title_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=D6zn6ozJs7,{'value': 'MMFakeBench: A Mixed-Source Multimodal Misinformation Detection Benchmark for LVLMs'},Xuannan Liu; Zekun Li; Pei Pei Li; Huaibo Huang; Shuhan Xia; Xing Cui; Linzhi Huang; Weihong Deng; Zhaofeng He,~Xuannan_Liu1; ~Zekun_Li2; ~Pei_Pei_Li2; ~Huaibo_Huang1; ~Shuhan_Xia1; ~Xing_Cui1; ~Linzhi_Huang1; ~Weihong_Deng1; ~Zhaofeng_He1,"{'value': ['multimodal misinformation detection', 'large vision language models']}","{'value': 'Current multimodal misinformation detection (MMD) methods often assume a single source and type of forgery for each sample, which is insufficient for real-world scenarios where multiple forgery sources coexist. The lack of a benchmark for mixed-source misinformation has hindered progress in this field. To address this, we introduce MMFakeBench, the first comprehensive benchmark for mixed-source MMD. MMFakeBench includes 3 critical sources: textual veracity distortion, visual veracity distortion, and cross-modal consistency distortion, along with 12 sub-categories of misinformation forgery types. We further conduct an extensive evaluation of 6 prevalent detection methods and 15 Large Vision-Language Models (LVLMs) on MMFakeBench under a zero-shot setting. The results indicate that current methods struggle under this challenging and realistic mixed-source MMD setting. Additionally, we propose MMD-Agent, a novel approach to integrate the reasoning, action, and tool-use capabilities of LVLM agents, significantly enhancing accuracy and generalization. We believe this study will catalyze future research into more realistic mixed-source multimodal misinformation and provide a fair evaluation of misinformation detection methods.'}",https://openreview.net{'value': '/pdf/832023fb982dafc707dd5695440b0f2e05267d7b.pdf'},{'abstract_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=CvGqMD5OtX,{'value': 'CHASE-SQL: Multi-Path Reasoning and Preference Optimized Candidate Selection in Text-to-SQL'},Mohammadreza Pourreza; Hailong Li; Ruoxi Sun; Yeounoh Chung; Shayan Talaei; Gaurav Tarlok Kakkar; Yu Gan; Amin Saberi; Fatma Ozcan; Sercan O Arik,~Mohammadreza_Pourreza1; ~Hailong_Li2; ~Ruoxi_Sun2; ~Yeounoh_Chung1; ~Shayan_Talaei1; ~Gaurav_Tarlok_Kakkar1; ~Yu_Gan2; ~Amin_Saberi1; ~Fatma_Ozcan1; ~Sercan_O_Arik1,"{'value': ['Text-to-SQL', 'LLM', 'Databases']}","{'value': 'We present CHASE-SQL, a novel framework addressing large language model (LLM) performance challenges for Text-to-SQL tasks by leveraging multi-agent modeling and test-time compute for improved candidate generation and selection. CHASE-SQL uses LLMs to generate diverse SQL candidates with: (1) a divide-and-conquer approach to break down complex queries, (2) chain-of-thought reasoning based on query execution plans, and (3) instance-aware synthetic example generation for tailored few-shot demonstrations. A selection agent ranks candidates via pairwise comparisons using a fine-tuned binary selection LLM, offering robust performance. This framework improves SQL query quality and diversity, achieving state-of-the-art execution accuracy of 73.0% on the BIRD Text-to-SQL benchmark test set, topping the leaderboard at the time of submission.'}",https://openreview.net{'value': '/pdf/90701f4590b2bb9d5eae256526b68fef82c1d905.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=Cnwz9jONi5,{'value': 'Rethinking Reward Model Evaluation: Are We Barking up the Wrong Tree?'},Xueru Wen; Jie Lou; Yaojie Lu; Hongyu Lin; XingYu; Xinyu Lu; Ben He; Xianpei Han; Debing Zhang; Le Sun,~Xueru_Wen1; ~Jie_Lou2; ~Yaojie_Lu1; ~Hongyu_Lin1; ~XingYu2; ~Xinyu_Lu1; ~Ben_He1; ~Xianpei_Han1; ~Debing_Zhang1; ~Le_Sun1,{'value': ['Reinforcement Learning from Human Feedback; Reward Model;']},"{'value': 'Reward Models (RMs) are crucial for aligning language models with human preferences. \nCurrently, the evaluation of RMs depends on measuring accuracy against a validation set of manually annotated preference data.\nAlthough this method is straightforward and widely adopted, the relationship between RM accuracy and downstream policy performance remains under-explored.\nIn this work, we conduct experiments in a synthetic setting to investigate how differences in RM measured by accuracy translate into gaps in optimized policy performance.\nOur findings reveal that while there is a weak positive correlation between accuracy and downstream performance, policies optimized towards RMs with similar accuracy can exhibit quite different performance.\nMoreover, we discover that the way of measuring accuracy significantly impacts its ability to predict the final policy performance. \nThrough the lens of the Regressional Goodhart effect, we recognize that accuracy, when used for measuring RM quality, can fail to fully capture the potential RM overoptimization.\nThis underscores the inadequacy of relying solely on accuracy to reflect their impact on policy optimization.'}",https://openreview.net{'value': '/pdf/7aa9cdaa8ae2a1fe57278fed0f70bed213ce9381.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=CkKEuLmRnr,{'value': 'How Do Large Language Models Understand Graph Patterns? A Benchmark for Graph Pattern Comprehension'},Xinnan Dai; Haohao Qu; Yifei Shen; Bohang Zhang; Qihao Wen; Wenqi Fan; Dongsheng Li; Jiliang Tang; Caihua Shan,~Xinnan_Dai1; ~Haohao_Qu1; ~Yifei_Shen1; ~Bohang_Zhang1; ~Qihao_Wen1; ~Wenqi_Fan1; ~Dongsheng_Li2; ~Jiliang_Tang1; ~Caihua_Shan1,"{'value': ['Large language models', 'graph pattern', 'graph mining']}","{'value': ""Benchmarking the capabilities and limitations of large language models (LLMs) in graph-related tasks is becoming an increasingly popular and crucial area of research. Recent studies have shown that LLMs exhibit a preliminary ability to understand graph structures and node features. However, the potential of LLMs in graph pattern mining remains largely unexplored. This is a key component in fields such as computational chemistry, biology, and social network analysis. To bridge this gap, this work introduces a comprehensive benchmark to assess LLMs' capabilities in graph pattern tasks. We have developed a benchmark that evaluates whether LLMs can understand graph patterns based on either terminological or topological descriptions. Additionally, our benchmark tests the LLMs' capacity to autonomously discover graph patterns from data. The benchmark encompasses both synthetic and real datasets, and a variety of models, with a total of 11 tasks and 7 models. Our experimental framework is designed for easy expansion to accommodate new models and datasets. Our findings reveal that: (1) LLMs have preliminary abilities to understand graph patterns, with O1-mini outperforming in the majority of tasks; (2) Formatting input graph data to align with the knowledge acquired during pretraining can enhance performance; (3) LLMs employ diverse\npotential algorithms to solve one task, with performance varying based on their execution capabilities.""}",https://openreview.net{'value': '/pdf/5a1a8d07e54e42518b837d6a314934d6a5b769b4.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=CjfQssZtAb,{'value': 'Digi-Q: Learning VLM Q-Value Functions for Training Device-Control Agents'},Hao Bai; Yifei Zhou; Li Erran Li; Sergey Levine; Aviral Kumar,~Hao_Bai1; ~Yifei_Zhou1; ~Li_Erran_Li1; ~Sergey_Levine1; ~Aviral_Kumar2,"{'value': ['Reinforcement learning', 'device control', 'digital agents', 'foundation models']}","{'value': 'While a number of existing approaches for building foundation model agents rely on prompting or fine-tuning with human demonstrations, it is not sufficient in dynamic environments (e.g., mobile device control). On-policy reinforcement learning (RL) should address these limitations, but collecting actual rollouts in an environment is often undesirable in truly open-ended agentic problems such as mobile device control or interacting with humans, where each unit of interaction is associated with a cost. In such scenarios, a method for policy learning that can utilize off-policy experience by learning a trained action-value function is much more effective. In this paper, we develop an approach, called Digi-Q, to train VLM-based action-value Q-functions which are then used to extract the agent policy. We study our approach in the mobile device control setting. Digi-Q trains the Q-function using offline temporal-difference (TD) learning, on top of frozen, intermediate-layer features of a VLM. Compared to fine-tuning the whole VLM, this approach saves us compute and enhances scalability. To make the VLM features amenable for representing the Q-function, we need to employ an initial phase of fine-tuning to amplify coverage over actionable information needed for value function. Once trained, we use this Q-function via a Best-of-N policy extraction operator that imitates the best action out of multiple candidate actions from the current policy as ranked by the value function, enabling policy improvement without environment interaction. Digi-Q outperforms several prior methods on user-scale device control tasks in Android-in-the-Wild, attaining 21.2% improvement over prior best-performing method. In some cases, our Digi-Q ap-\nproach already matches state-of-the-art RL methods that require interaction. The project is open-sourced at https://github.com/DigiRL-agent/digiq'}",https://openreview.net{'value': '/pdf/d6565f7372a86552f16d861c9fe4fedde5378037.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=CjXaMI2kUH,{'value': 'MrSteve: Instruction-Following Agents in Minecraft with What-Where-When Memory'},Junyeong Park; Junmo Cho; Sungjin Ahn,~Junyeong_Park1; ~Junmo_Cho1; ~Sungjin_Ahn1,"{'value': ['Generalist Agents', 'Minecraft', 'Place Event Memory']}","{'value': 'Significant advances have been made in developing general-purpose embodied AI in environments like Minecraft through the adoption of LLM-augmented hierarchical approaches. While these approaches, which combine high-level planners with low-level controllers, show promise, low-level controllers frequently become performance bottlenecks due to repeated failures. In this paper, we argue that the primary cause of failure in many low-level controllers is the absence of an episodic memory system. To address this, we introduce MrSteve (Memory Recall Steve), a novel low-level controller equipped with Place Event Memory (PEM), a form of episodic memory that captures what, where, and when information from episodes. This directly addresses the main limitation of the popular low-level controller, Steve-1. Unlike previous models that rely on short-term memory, PEM organizes spatial and event-based data, enabling efficient recall and navigation in long-horizon tasks. Additionally, we propose an Exploration Strategy and a Memory-Augmented Task Solving Framework, allowing agents to alternate between exploration and task-solving based on recalled events. Our approach significantly improves task-solving and exploration efficiency compared to existing methods. We will release our code and demos on the project page: https://sites.google.com/view/mr-steve.'}",https://openreview.net{'value': '/pdf/9812fe85d096855db342c62bcb1b1cd0c42e6bd5.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=CfZPzH7ftt,{'value': 'Improving Neural Optimal Transport via Displacement Interpolation'},Jaemoo Choi; Yongxin Chen; Jaewoong Choi,~Jaemoo_Choi1; ~Yongxin_Chen1; ~Jaewoong_Choi1,"{'value': ['Optimal Transport', 'Displacement Interpolation', 'Image-to-image Translation']}","{'value': 'Optimal Transport (OT) theory investigates the cost-minimizing transport map that moves a source distribution to a target distribution. Recently, several approaches have emerged for learning the optimal transport map for a given cost function using neural networks. We refer to these approaches as the OT Map. OT Map provides a powerful tool for diverse machine learning tasks, such as generative modeling and unpaired image-to-image translation. However, existing methods that utilize max-min optimization often experience training instability and sensitivity to hyperparameters. In this paper, we propose a novel method to improve stability and achieve a better approximation of the OT Map by exploiting displacement interpolation, dubbed Displacement Interpolation Optimal Transport Model (DIOTM). We derive the dual formulation of displacement interpolation at specific time $t$ and prove how these dual problems are related across time. This result allows us to utilize the entire trajectory of displacement interpolation in learning the OT Map. Our method improves the training stability and achieves superior results in estimating optimal transport maps. We demonstrate that DIOTM outperforms existing OT-based models on image-to-image translation tasks.'}",https://openreview.net{'value': '/pdf/f219b38de9cd4365314aaa4b047ac70c8d07fb19.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=Ccwp4tFEtE,{'value': 'Generative Verifiers: Reward Modeling as Next-Token Prediction'},Lunjun Zhang; Arian Hosseini; Hritik Bansal; Mehran Kazemi; Aviral Kumar; Rishabh Agarwal,~Lunjun_Zhang1; ~Arian_Hosseini1; ~Hritik_Bansal2; ~Mehran_Kazemi1; ~Aviral_Kumar2; ~Rishabh_Agarwal2,"{'value': ['LLM reasoning', 'reward models', 'verifiers']}","{'value': 'Verifiers or reward models are often used to enhance the reasoning performance of large language models (LLMs). A common approach is the Best-of-N method, where N candidate solutions generated by the LLM are ranked by a verifier, and the best one is selected. While LLM-based verifiers are typically trained as discriminative classifiers to score solutions, they do not utilize the text generation capabilities of pretrained LLMs. To overcome this limitation, we instead propose training verifiers using the ubiquitous next-token prediction objective, jointly on verification and solution generation. Compared to standard verifiers, such generative verifiers (GenRM) can benefit from several advantages of LLMs: they integrate seamlessly with instruction tuning, enable chain-of-thought reasoning, and can utilize additional test-time compute via majority voting for better verification. We demonstrate that GenRM outperforms discriminative, DPO verifiers, and LLM-as-a-Judge, resulting in large performance gains with Best-of-N, namely 5% → 45.3% on algorithmic tasks, 73% → 93.4% on GSM8K, and 28% →44.6% on easy-to-hard generalization on MATH. Furthermore, we find that training GenRM with synthetic verification rationales is sufficient to pick out subtle errors on math problems. Finally, we demonstrate that generative verifiers scale favorably with model size and inference-time compute.'}",https://openreview.net{'value': '/pdf/b1d84910d45ea689f1c089639edb67b49797c70c.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=CL3U0GxFRD,{'value': 'Exponential Topology-enabled Scalable Communication in Multi-agent Reinforcement Learning'},Xinran Li; Xiaolu Wang; Chenjia Bai; Jun Zhang,~Xinran_Li3; ~Xiaolu_Wang1; ~Chenjia_Bai2; ~Jun_Zhang25,"{'value': ['multi-agent reinforcement learning', 'communication']}","{'value': 'In cooperative multi-agent reinforcement learning (MARL), well-designed communication protocols can effectively facilitate consensus among agents, thereby enhancing task performance. Moreover, in large-scale multi-agent systems commonly found in real-world applications, effective communication plays an even more critical role due to the escalated challenge of partial observability compared to smaller-scale setups. In this work, we endeavor to develop a scalable communication protocol for MARL. Unlike previous methods that focus on selecting optimal pairwise communication links—a task that becomes increasingly complex as the number of agents grows—we adopt a global perspective on communication topology design. Specifically, we propose utilizing the exponential topology to enable rapid information dissemination among agents by leveraging its small-diameter and small-size properties. This approach leads to a scalable communication protocol, named ExpoComm. To fully unlock the potential of exponential graphs as communication topologies, we employ memory-based message processors and auxiliary tasks to ground messages, ensuring that they reflect global information and benefit decision-making. Extensive experiments on large-scale cooperative benchmarks, including MAgent and Infrastructure Management Planning, demonstrate the superior performance and robust zero-shot transferability of ExpoComm compared to existing communication strategies. The\ncode is publicly available at [https://github.com/LXXXXR/ExpoComm](https://github.com/LXXXXR/ExpoComm).'}",https://openreview.net{'value': '/pdf/099ca577bb4201168ce2fb973ae5e94e0a9074cd.pdf'},{'abstract_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=CKXul9iX77,{'value': 'A Deep Generative Learning Approach for Two-stage Adaptive Robust Optimization'},Aron Brenner; Rahman Khorramfar; Jennifer Z Sun; Saurabh Amin,~Aron_Brenner1; ~Rahman_Khorramfar1; ~Jennifer_Z_Sun1; ~Saurabh_Amin1,"{'value': ['robust optimization', 'stochastic optimization', 'discrete optimization', 'deep learning', 'unsupervised learning']}","{'value': 'Two-stage adaptive robust optimization (ARO) is a powerful approach for planning under uncertainty, balancing first-stage decisions with recourse decisions made after uncertainty is realized. To account for uncertainty, modelers typically define a simple uncertainty set over which potential outcomes are considered. However, classical methods for defining these sets unintentionally capture a wide range of unrealistic outcomes, resulting in overly-conservative and costly planning in anticipation of unlikely contingencies. In this work, we introduce AGRO, a solution algorithm that performs adversarial generation for two-stage adaptive robust optimization using a variational autoencoder. AGRO generates high-dimensional contingencies that are simultaneously adversarial and realistic, improving the robustness of first-stage decisions at a lower planning cost than standard methods. To ensure generated contingencies lie in high-density regions of the uncertainty distribution, AGRO defines a tight uncertainty set as the image of ""latent"" uncertainty sets under the VAE decoding transformation. Projected gradient ascent is then used to maximize recourse costs over the latent uncertainty sets by leveraging differentiable optimization methods. We demonstrate the cost-efficiency of AGRO by applying it to both a synthetic production-distribution problem and a real-world power system expansion setting. We show that AGRO outperforms the standard column-and-constraint algorithm by up to 1.8% in production-distribution planning and up to 8% in power system expansion.'}",https://openreview.net{'value': '/pdf/f091fc3dd4c5fd25cfcbee291e0b2ca5fd5f544c.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=CAssIgPN4I,{'value': 'Real2Code: Reconstruct Articulated Objects via Code Generation'},Zhao Mandi; Yijia Weng; Dominik Bauer; Shuran Song,~Zhao_Mandi1; ~Yijia_Weng1; ~Dominik_Bauer1; ~Shuran_Song3,"{'value': ['articulated objects', 'code generation LLMs', 'foundation models']}","{'value': ""We present Real2Code, a novel approach to reconstructing articulated objects via code generation. Given visual observations of an object, we first reconstruct its part geometry using image segmentation and shape completion. We represent these object parts with oriented bounding boxes, from which a fine-tuned large language model (LLM) predicts joint articulation as code. By leveraging pre-trained vision and language models, our approach scales elegantly with the number of articulated parts, and generalizes from synthetic training data to real world objects in unstructured environments. Experimental results demonstrate that Real2Code significantly outperforms the previous state-of-the-art in terms of reconstruction accuracy, and is the first approach to extrapolate beyond objects' structural complexity in the training set, as we show for objects with up to 10 articulated parts. When incorporated with a stereo reconstruction model, Real2Code moreover generalizes to real-world objects, given only a handful of multi-view RGB images and without the need for depth or camera information.""}",https://openreview.net{'value': '/pdf/c1cbf533af266d4e285c48b9630eb5ea3ff16cab.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=C8niXBHjfO,{'value': 'Does Training with Synthetic Data Truly Protect Privacy?'},Yunpeng Zhao; Jie Zhang,~Yunpeng_Zhao2; ~Jie_Zhang14,"{'value': ['ML privacy', 'membership inference']}","{'value': 'As synthetic data becomes increasingly popular in machine learning tasks, numerous methods---without formal differential privacy guarantees---use synthetic data for training. These methods often claim, either explicitly or implicitly, to protect the privacy of the original training data.\nIn this work, we explore four different training paradigms: coreset selection, dataset distillation, data-free knowledge distillation, and synthetic data generated from diffusion models. While all these methods utilize synthetic data for training, they lead to vastly different conclusions regarding privacy preservation. We caution that empirical approaches to preserving data privacy require careful and rigorous evaluation; otherwise, they risk providing a false sense of privacy.'}",https://openreview.net{'value': '/pdf/1a75577d2e1d1f3d2d69d02202f1c3559d7d8f3e.pdf'},{'title_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=C8jXEugWkq,{'value': 'EqNIO: Subequivariant Neural Inertial Odometry'},Royina Karegoudra Jayanth; Yinshuang Xu; Ziyun Wang; Evangelos Chatzipantazis; Kostas Daniilidis; Daniel Gehrig,~Royina_Karegoudra_Jayanth1; ~Yinshuang_Xu1; ~Ziyun_Wang3; ~Evangelos_Chatzipantazis1; ~Kostas_Daniilidis1; ~Daniel_Gehrig1,"{'value': ['equivariance', 'inertial odometry', 'subequivariance']}","{'value': ""Neural network-based odometry using accelerometer and gyroscope readings from a single IMU can achieve robust, and low-drift localization capabilities, through the use of _neural displacement priors (NDPs)_. These priors learn to produce denoised displacement measurements but need to ignore data variations due to specific IMU mount orientation and motion directions, hindering generalization.\nThis work introduces EqNIO, which addresses this challenge with _canonical displacement priors_, i.e., priors that are invariant to the orientation of the gravity-aligned frame in which the IMU data is expressed. We train such priors on IMU measurements, that are mapped into a learnable canonical frame, which is uniquely defined via three axes: the first is gravity, making the frame gravity aligned, while the second and third are predicted from IMU data.  The outputs (displacement and covariance) are mapped back to the original gravity-aligned frame. To maximize generalization, we find that these learnable frames must transform equivariantly with global gravity-preserving roto-reflections from the subgroup $O_g(3)\\subset O(3)$, acting on the trajectory, rendering the NDP $O(3)$-_subequivariant_. We tailor specific linear, convolutional, and non-linear layers that commute with the actions of the group. Moreover, we introduce a bijective decomposition of angular rates into vectors that transform similarly to accelerations, allowing us to leverage both measurement types. Natively, angular rates would need to be inverted upon reflection, unlike acceleration, which hinders their joint processing. We highlight EqNIO's flexibility and generalization capabilities by applying it to both filter-based (TLIO), and end-to-end (RONIN) architectures, and outperforming existing methods that use _soft equivariance from auxiliary losses or data augmentation on various datasets. We believe this work paves the way for low-drift and generalizable neural inertial odometry on edge devices. The project details and code can be found at [https://github.com/RoyinaJayanth/EqNIO](https://github.com/RoyinaJayanth/EqNIO).""}",https://openreview.net{'value': '/pdf/f27e602a2cfec2b9b3b3123106803d1038c0a27f.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=C45YqeBDUM,{'value': 'The KoLMogorov Test: Compression by Code Generation'},Ori Yoran; Kunhao Zheng; Fabian Gloeckle; Jonas Gehring; Gabriel Synnaeve; Taco Cohen,~Ori_Yoran1; ~Kunhao_Zheng1; ~Fabian_Gloeckle1; ~Jonas_Gehring1; ~Gabriel_Synnaeve1; ~Taco_Cohen1,"{'value': ['Code generation', 'code', 'compression', 'LLM', 'dataset', 'benchmark']}","{'value': 'Compression is at the heart of intelligence. A theoretically optimal way to compress any sequence of data is to find the shortest program that outputs that sequence and then halts. However, such Kolmogorov compression is uncomputable, and code generating LLMs struggle to approximate this theoretical ideal, as it requires reasoning, planning and search capabilities beyond those of current models. In this work, we introduce the *KoLMogorov-Test* (KT), a compression-as-intelligence intelligence test for code generation LLMs. In KT a model is presented with a sequence of data at inference time, and asked to generate the shortest program that produces the sequence. We identify several benefits of KT for both evaluation and training: an essentially infinite number of problem instances of varying difficulty is readily available, strong baselines already exist, the evaluation metric (compression) cannot be gamed, and pretraining data contamination is highly unlikely. To evaluate current models, we use audio, text, and DNA data, as well as sequences produced by random synthetic programs. Current flagship models perform poorly - both GPT4-o and  Llama-3.1-405B struggle on our natural and synthetic sequences. On our synthetic distribution, we are able to train code generation models with lower compression rates than previous approaches. Moreover, we show that gains on synthetic data generalize poorly to real data, suggesting that new innovations are necessary for additional gains on KT.'}",https://openreview.net{'value': '/pdf/4834224b8cfe9255d6fe7861ae1522ea924af9d0.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=BwR8t91yqh,{'value': 'Interactive Speculative Planning: Enhance Agent Efficiency through Co-design of System and User Interface'},Wenyue Hua; Mengting Wan; JAGANNATH SHASHANK SUBRAMANYA SAI VADREVU; Ryan Nadel; Yongfeng Zhang; Chi Wang,~Wenyue_Hua1; ~Mengting_Wan1; ~JAGANNATH_SHASHANK_SUBRAMANYA_SAI_VADREVU1; ~Ryan_Nadel1; ~Yongfeng_Zhang1; ~Chi_Wang3,"{'value': ['large language model', 'agent', 'efficiency', 'human-computer interaction']}","{'value': 'Agents, as user-centric tools, are increasingly deployed for human task delegation, assisting with a broad spectrum of requests by generating thoughts, engaging with user proxies, and producing action plans. However, agents based on large language models often face substantial planning latency due to two primary factors: the efficiency limitations of the underlying LLMs due to their large size and high demand, and the structural complexity of the agents due to the extensive generation of intermediate steps to produce the final output. Given that inefficiency in service provision can undermine the value of automation for users, this paper presents a human-centered efficient agent planning method – Interactive Speculative Planning – aiming at enhancing the efficiency of agent planning through both system design and user interaction. Our approach advocates for the co-design of the agent system and user interface, underscoring the importance of an agent system that can fluidly manage user interactions and interruptions. By integrating human interruptions as a fundamental component of the system, we not only make it more user-centric but also expedite the entire process by leveraging human-in-the-loop interactions to provide accurate intermediate steps.'}",https://openreview.net{'value': '/pdf/d0bfc62889cc4dd6dd559f11e0eefe99ed67a5a2.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=Bt1vnCnAVS,{'value': 'Leave-One-Out Stable Conformal Prediction'},Kiljae Lee; Yuan Zhang,~Kiljae_Lee1; ~Yuan_Zhang18,"{'value': ['Conformal Prediction', 'Algorithmic Stability', 'Regularized Loss Minimization', 'Stochastic Gradient Descent']}","{'value': 'Conformal prediction (CP) is an important tool for distribution-free predictive uncertainty quantification.\nYet, a major challenge is to balance computational efficiency and prediction accuracy, particularly for multiple predictions.\nWe propose **L**eave-**O**ne-**O**ut **Stab**le **C**onformal **P**rediction (LOO-StabCP), a novel method to speed up full conformal using algorithmic stability without sample splitting.\nBy leveraging *leave-one-out* stability, our method is much faster in handling a large number of prediction requests compared to existing method RO-StabCP based on *replace-one* stability.\nWe derived stability bounds for several popular machine learning tools: regularized loss minimization (RLM) and stochastic gradient descent (SGD), as well as kernel method, neural networks and bagging.\nOur method is theoretically justified and demonstrates superior numerical performance on synthetic and real-world data.\nWe applied our method to a screening problem, where its effective exploitation of training data led to improved test power compared to state-of-the-art method based on split conformal.'}",https://openreview.net{'value': '/pdf/b78c36a947738545a7d2a50845a38cb3685ba60b.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=Bl3e8HV9xW,{'value': 'Leveraging Variable Sparsity to Refine Pareto Stationarity in Multi-Objective Optimization'},Zeou Hu; Yaoliang Yu,~Zeou_Hu1; ~Yaoliang_Yu1,"{'value': ['Multi-Objective Optimization', 'Machine Learning', 'Deep Learning', 'Multi-task Learning', 'Gradient-Based Optimization']}","{'value': 'Gradient-based multi-objective optimization (MOO) is essential in modern machine learning, with applications in e.g., multi-task learning, federated learning,  algorithmic fairness and reinforcement learning. In this work, we first reveal some limitations of Pareto stationarity, a widely accepted first-order condition for Pareto optimality, in the presence of sparse function-variable structures. Next, to account for such sparsity, we propose a novel solution concept termed Refined Pareto Stationarity (RPS), which we prove is always sandwiched between Pareto optimality and Pareto stationarity. We give an efficient partitioning algorithm to automatically mine the function-variable dependency and substantially trim non-optimal Pareto stationary solutions. Then, we show that gradient-based descent algorithms in MOO can be enhanced with our refined partitioning. In particular, we propose Multiple Gradient Descent Algorithm with Refined Partition (RP-MGDA) as an example method that converges to RPS, while still enjoying a similar per-step complexity and convergence rate. Lastly, we validate our approach through experiments on both synthetic examples and realistic application scenarios where distinct function-variable dependency structures appear. Our results highlight the importance of exploiting function-variable structure in gradient-based MOO, and provide a seamless enhancement to existing approaches.'}",https://openreview.net{'value': '/pdf/9dcd6b39316157884b8d31e2f900c668f0ad7f09.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=BkwCrIsTbR,{'value': 'Scaling Instruction-tuned LLMs to Million-token Contexts via Hierarchical Synthetic Data Generation'},Linda He; Jue WANG; Maurice Weber; Shang Zhu; Ben Athiwaratkun; Ce Zhang,~Linda_He1; ~Jue_WANG1; ~Maurice_Weber1; ~Shang_Zhu1; ~Ben_Athiwaratkun1; ~Ce_Zhang1,"{'value': ['Large Language Models', 'Long Context', 'Instruction-Tuning Data']}","{'value': 'Large Language Models (LLMs) struggle with long-context reasoning, not only due to the quadratic scaling of computational complexity with sequence length but also because of the scarcity and expense of annotating long-context data. There has been barely any open-source work that systematically ablates long-context data, nor is there any openly available instruction tuning dataset with contexts surpassing 100K tokens. To bridge this gap, we introduce a novel post-training synthetic data generation strategy designed to efficiently extend the context window of LLMs while preserving their general task performance. Our approach scalably extends to arbitrarily long context lengths, unconstrained by the length of available real-world data, which effectively addresses the scarcity of raw long-context data. \nThrough a step-by-step rotary position embedding (RoPE) scaling training strategy, we demonstrate that our model, with a context length of up to 1M tokens, performs well on the RULER benchmark and InfiniteBench and maintains robust performance on general language tasks.'}",https://openreview.net{'value': '/pdf/d27ba793e6e10160b5544a0bc16a6636bf85e79b.pdf'},{'title_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=BdmVgLMvaf,{'value': 'Adaptive teachers for amortized samplers'},Minsu Kim; Sanghyeok Choi; Taeyoung Yun; Emmanuel Bengio; Leo Feng; Jarrid Rector-Brooks; Sungsoo Ahn; Jinkyoo Park; Nikolay Malkin; Yoshua Bengio,~Minsu_Kim2; ~Sanghyeok_Choi1; ~Taeyoung_Yun1; ~Emmanuel_Bengio1; ~Leo_Feng1; ~Jarrid_Rector-Brooks2; ~Sungsoo_Ahn1; ~Jinkyoo_Park1; ~Nikolay_Malkin1; ~Yoshua_Bengio1,"{'value': ['amortized inference', 'generative models', 'reinforcement learning', 'GFlowNets']}","{'value': 'Amortized inference is the task of training a parametric model, such as a neural network, to approximate a distribution with a given unnormalized density where exact sampling is intractable. When sampling is modeled as a sequential decision-making process, reinforcement learning (RL) methods, such as generative flow networks, can be used to train the sampling policy. Off-policy RL training facilitates the discovery of diverse, high-reward candidates, but existing methods still face challenges in efficient exploration. We propose to use an adaptive training distribution (the Teacher) to guide the training of the primary amortized sampler (the Student). The  Teacher, an auxiliary behavior model, is trained to sample high-loss regions of the Student and can generalize across unexplored modes, thereby enhancing mode coverage by providing an efficient training curriculum. We validate the effectiveness of this approach in a synthetic environment designed to present an exploration challenge, two diffusion-based sampling tasks, and four biochemical discovery tasks demonstrating its ability to improve sample efficiency and mode coverage. Source code is available at https://github.com/alstn12088/adaptive-teacher.'}",https://openreview.net{'value': '/pdf/8eb3222e3aae1428c6496b80b529aa4ff4efbcec.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=BCP5nAHXqs,{'value': 'Human Simulacra: Benchmarking the Personification of Large Language Models'},Qiujie Xie; Qiming Feng; Tianqi Zhang; Qingqiu Li; Linyi Yang; Yuejie Zhang; Rui Feng; Liang He; Shang Gao; Yue Zhang,~Qiujie_Xie1; ~Qiming_Feng1; ~Tianqi_Zhang2; ~Qingqiu_Li1; ~Linyi_Yang1; ~Yuejie_Zhang2; ~Rui_Feng2; ~Liang_He2; ~Shang_Gao5; ~Yue_Zhang7,"{'value': ['Large Language Models', 'Human simulation']}","{'value': ""Large Language Models (LLMs) are recognized as systems that closely mimic aspects of human intelligence. This capability has attracted the attention of the social science community, who see the potential in leveraging LLMs to replace human participants in experiments, thereby reducing research costs and complexity. In this paper, we introduce a benchmark for LLMs personification, including a strategy for constructing virtual characters' life stories from the ground up, a Multi-Agent Cognitive Mechanism capable of simulating human cognitive processes, and a psychology-guided evaluation method to assess human simulations from both self and observational perspectives. Experimental results demonstrate that our constructed simulacra can produce personified responses that align with their target characters.  We hope this work will serve as a benchmark in the field of human simulation, paving the way for future research.""}",https://openreview.net{'value': '/pdf/3834694dcd9d87ff5219773c802877eeaddc1297.pdf'},{'abstract_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=BAglD6NGy0,{'value': 'ROUTE: Robust Multitask Tuning and Collaboration for Text-to-SQL'},Yang Qin; Chao Chen; Zhihang Fu; Ze Chen; Dezhong Peng; Peng Hu; Jieping Ye,~Yang_Qin4; ~Chao_Chen19; ~Zhihang_Fu1; ~Ze_Chen3; ~Dezhong_Peng1; ~Peng_Hu2; ~Jieping_Ye4,"{'value': ['Text-to-SQL', 'LLMs']}","{'value': ""Despite the significant advancements in Text-to-SQL (Text2SQL) facilitated by large language models (LLMs), the latest state-of-the-art techniques are still trapped in the in-context learning of closed-source LLMs (e.g., GPT-4), which limits their applicability in open scenarios. \nTo address this challenge, we propose a novel RObust mUltitask Tuning and collaboration mEthod (ROUTE) to improve the comprehensive capabilities of open-source LLMs for Text2SQL, thereby providing a more practical solution.  Our approach begins with multi-task supervised fine-tuning (SFT) using various synthetic training data related to SQL generation.  Unlike existing SFT-based  Text2SQL methods, we introduced several additional SFT tasks, including schema linking, noise correction, and continuation writing.  Engaging in a variety of SQL generation tasks enhances the model's understanding of SQL syntax and improves its ability to generate high-quality SQL queries. Additionally, inspired by the collaborative modes of LLM agents, we introduce a Multitask Collaboration Prompting (MCP) strategy.  This strategy leverages collaboration across several SQL-related tasks to reduce hallucinations during SQL generation, thereby maximizing the potential of enhancing Text2SQL performance through explicit multitask capabilities. Extensive experiments and in-depth analyses have been performed on eight open-source LLMs and five widely-used benchmarks. The results demonstrate that our proposal outperforms the latest Text2SQL methods and yields leading performance.""}",https://openreview.net{'value': '/pdf/4cbe1d371c70ee1d447b1d5b57cdfb2579c0a0f4.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=B5PbOsJqt3,{'value': 'TopoGaussian: Inferring Internal Topology Structures from Visual Clues'},Xiaoyu Xiong; Changyu Hu; Chunru Lin; Pingchuan Ma; Chuang Gan; Tao Du,~Xiaoyu_Xiong1; ~Changyu_Hu2; ~Chunru_Lin1; ~Pingchuan_Ma3; ~Chuang_Gan1; ~Tao_Du1,"{'value': ['Gaussian Splatting', 'Differential Simulation', 'Topology Optimization', 'Neural Implicit Surface']}","{'value': 'We present TopoGaussian, a holistic, particle-based pipeline for inferring the interior structure of an opaque object from easily accessible photos and videos as input. Traditional mesh-based approaches require tedious and error-prone mesh filling and fixing process, while typically output rough boundary surface. Our pipeline combines Gaussian Splatting with a novel, versatile particle-based differentiable simulator that simultaneously accommodates constitutive model, actuator, and collision, without interference with mesh. Based on the gradients from this simulator, we provide flexible choice of topology representation for optimization, including particle, neural implicit surface, and quadratic surface. The resultant pipeline takes easily accessible photos and videos as input and outputs the topology that matches the physical characteristics of the input. We demonstrate the efficacy of our pipeline on a synthetic dataset and four real-world tasks with 3D-printed prototypes. Compared with existing mesh-based method, our pipeline is 5.26x faster on average with improved shape quality. These results highlight the potential of our pipeline in 3D vision, soft robotics, and manufacturing applications.'}",https://openreview.net{'value': '/pdf/d667b5f6dda3ebd4f6c62124b8081d4278173384.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=AvOhBgsE5R,{'value': 'Motion-Agent: A Conversational Framework for Human Motion Generation with LLMs'},Qi Wu; Yubo Zhao; Yifan Wang; Xinhang Liu; Yu-Wing Tai; Chi-Keung Tang,~Qi_Wu18; ~Yubo_Zhao1; ~Yifan_Wang47; ~Xinhang_Liu1; ~Yu-Wing_Tai2; ~Chi-Keung_Tang1,"{'value': ['3D human motion', 'multimodal LLM', 'motion generation', 'conversational AI']}","{'value': ""While previous approaches to 3D human motion generation have achieved notable success, they often rely on extensive training and are limited to specific tasks. To address these challenges, we introduce **Motion-Agent**, an efficient conversational framework designed for general human motion generation, editing, and understanding. \nMotion-Agent employs an open-source pre-trained language model to develop a generative agent, **MotionLLM**, that bridges the gap between motion and text. This is accomplished by encoding and quantizing motions into discrete tokens that align with the language model's vocabulary. With only 1-3% of the model's parameters fine-tuned using adapters, MotionLLM delivers performance on par with diffusion models and other transformer-based methods trained from scratch. By integrating MotionLLM with GPT-4 without additional training, Motion-Agent is able to generate highly complex motion sequences through multi-turn conversations, a capability that previous models have struggled to achieve.\nMotion-Agent supports a wide range of motion-language tasks, offering versatile capabilities for generating and customizing human motion through interactive conversational exchanges.""}",https://openreview.net{'value': '/pdf/e41844545df6db49250582c62b32d716c8bd302c.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=AqfUa08PCH,{'value': 'Training Language Models on Synthetic Edit Sequences Improves Code Synthesis'},Ulyana Piterbarg; Lerrel Pinto; Rob Fergus,~Ulyana_Piterbarg1; ~Lerrel_Pinto1; ~Rob_Fergus1,"{'value': ['language model', 'code synthesis', 'reasoning', 'synthetic data']}","{'value': 'Software engineers mainly write code by editing existing programs. In contrast, language models (LMs) autoregressively synthesize programs in a single pass. One explanation for this is the scarcity of sequential edit data. While high-quality instruction data for code synthesis is scarce, edit data for synthesis is even scarcer. To fill this gap, we develop a synthetic data generation algorithm called LintSeq. This algorithm refactors programs into sequences of synthetic edits by using a linter to procedurally sample across interdependent lines of source code. Synthetic edits sampled with LintSeq reflect the syntax and semantics of their programming language. To test the algorithm, we use it to refactor a dataset of instruction + program pairs into instruction + program-diff-sequence tuples. Then, we fine-tune a series of smaller LMs ranging from 2.6B to 14B parameters on both the re-factored and original versions of this dataset. We perform comprehensive evaluations comparing edit sequence code LMs against baselines on HumanEval, MBPP(+), CodeContests, DS-1000, and BigCodeBench. We show that models fine-tuned to iteratively synthesize code match or outperform baselines on pass@1, and exhibit better scaling across higher pass@k as a function of total test-time FLOPs. Finally, we also pretrain our own tiny LMs for code understanding. We show that fine-tuning these models to synthesize code edit-by-edit results in strong performance on HumanEval and MBPP(+) compared to existing code language models of similar scale such as CodeT5+, AlphaCode, and Codex.'}",https://openreview.net{'value': '/pdf/4468145c73d3d15430a167e8486e5937fc2ea266.pdf'},{'title_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=AmEgWDhmTr,{'value': 'From Sparse Dependence to Sparse Attention: Unveiling How Chain-of-Thought Enhances Transformer Sample Efficiency'},Kaiyue Wen; Huaqing Zhang; Hongzhou Lin; Jingzhao Zhang,~Kaiyue_Wen1; ~Huaqing_Zhang2; ~Hongzhou_Lin1; ~Jingzhao_Zhang2,"{'value': ['chain of thoughts', 'sample complexity', 'sparsity', 'sample efficiency', 'parity learning']}","{'value': 'Chain-of-thought (CoT)  significantly enhances the reasoning performance of large language models (LLM). While current theoretical studies often attribute this improvement to increased expressiveness and computational capacity, we argue that expressiveness is not the primary limitation in the LLM regime, as current large models will fail on simple tasks. Using a parity-learning setup, we demonstrate that CoT can substantially improve sample efficiency even when the representation power is sufficient. Specifically, with CoT, a transformer can learn the function within polynomial samples, whereas without CoT, the required sample size is exponential. Additionally, we show that CoT simplifies the learning process by introducing sparse sequential dependencies among input tokens, and leads to a sparse and interpretable attention. We validate our theoretical analysis with both synthetic and real-world experiments, confirming that sparsity in attention layers is a key factor of the improvement induced by CoT.'}",https://openreview.net{'value': '/pdf/dd3b24a50bd06b7618a6bd5f8d2ef9811d4d000f.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=AcAD4VEgCX,{'value': 'I2VControl-Camera: Precise Video Camera Control with Adjustable Motion Strength'},Wanquan Feng; Jiawei Liu; Pengqi Tu; Tianhao Qi; Mingzhen Sun; Tianxiang Ma; Songtao Zhao; SiYu Zhou; Qian HE,~Wanquan_Feng1; ~Jiawei_Liu6; ~Pengqi_Tu1; ~Tianhao_Qi1; ~Mingzhen_Sun1; ~Tianxiang_Ma1; ~Songtao_Zhao1; ~SiYu_Zhou3; ~Qian_HE3,"{'value': ['Video Generation', 'Camera Control']}","{'value': 'Video generation technologies are developing rapidly and have broad potential applications. Among these technologies, camera control is crucial for generating professional-quality videos that accurately meet user expectations. However, existing camera control methods still suffer from several limitations, including control precision and the neglect of the control for subject motion dynamics. In this work, we propose I2VControl-Camera, a novel camera control method that significantly enhances controllability while providing adjustability over the strength of subject motion. To improve control precision, we employ point trajectory in the camera coordinate system instead of only extrinsic matrix information as our control signal. To accurately control and adjust the strength of subject motion, we explicitly model the higher-order components of the video trajectory expansion, not merely the linear terms, and design an operator that effectively represents the motion strength. We use an adapter architecture that is independent of the base model structure. Experiments on static and dynamic scenes show that our framework outperformances previous methods both quantitatively and qualitatively. Project page: https://wanquanf.github.io/I2VControlCamera.'}",https://openreview.net{'value': '/pdf/ab709f0880cfa10dfbac32a9fabec15dcf805f4e.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=AOlm45AUVS,{'value': 'Exploiting Structure in Offline Multi-Agent RL: The Benefits of Low Interaction Rank'},Wenhao Zhan; Scott Fujimoto; Zheqing Zhu; Jason D. Lee; Daniel Jiang; Yonathan Efroni,~Wenhao_Zhan1; ~Scott_Fujimoto1; ~Zheqing_Zhu1; ~Jason_D._Lee1; ~Daniel_R._Jiang1; ~Yonathan_Efroni2,"{'value': ['multi-agent reinforcement learning', 'offline learning', 'interaction rank', 'distribution shift']}","{'value': 'We study the problem of learning an approximate equilibrium in the offline multi-agent reinforcement learning (MARL) setting. We introduce a structural assumption---the interaction rank---and establish that functions with low interaction rank are significantly more robust to distribution shift compared to general ones. Leveraging this observation, we demonstrate that utilizing function classes with low interaction rank, when combined with regularization and no-regret learning, admits decentralized, computationally and statistically efficient learning in cooperative and competitive offline MARL. Our theoretical results are complemented by experiments that showcase the potential of critic architectures with low interaction rank in offline MARL, contrasting with commonly used single-agent value decomposition architectures.'}",https://openreview.net{'value': '/pdf/ee2f616ffa77e07cbec088997cca76489c208b7b.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=AC5n7xHuR1,{'value': 'AgentHarm: A Benchmark for Measuring Harmfulness of LLM Agents'},Maksym Andriushchenko; Alexandra Souly; Mateusz Dziemian; Derek Duenas; Maxwell Lin; Justin Wang; Dan Hendrycks; Andy Zou; J Zico Kolter; Matt Fredrikson; Yarin Gal; Xander Davies,~Maksym_Andriushchenko1; ~Alexandra_Souly1; ~Mateusz_Dziemian1; ~Derek_Duenas1; ~Maxwell_Lin1; ~Justin_Wang2; ~Dan_Hendrycks1; ~Andy_Zou1; ~J_Zico_Kolter1; ~Matt_Fredrikson1; ~Yarin_Gal1; ~Xander_Davies1,"{'value': ['Robustness', 'jailbreaking', 'adversarial attacks', 'LLM agents', 'AI safety']}","{'value': 'The robustness of LLMs to jailbreak attacks, where users design prompts to circumvent safety measures and misuse model capabilities, has been studied primarily for LLMs acting as simple chatbots. Meanwhile, LLM agents---which use external tools and can execute multi-stage tasks---may pose a greater risk if misused, but their robustness remains underexplored. To facilitate research on LLM agent misuse, we propose a new benchmark called AgentHarm. The benchmark includes a diverse set of 110 explicitly malicious agent tasks (440 with augmentations), covering 11 harm categories including fraud, cybercrime, and harassment. In addition to measuring whether models refuse harmful agentic requests, scoring well on AgentHarm requires jailbroken agents to maintain their capabilities following an attack to complete a multi-step task. We evaluate a range of leading LLMs, and find (1) leading LLMs are surprisingly complaint with malicious agent requests without jailbreaking, (2) simple universal jailbreak strings can be adapted to effectively jailbreak agents, and (3) these jailbreaks enable coherent and malicious multi-step agent behavior and retain model capabilities. To enable simple and reliable evaluation of attacks and defenses for LLM-based agents, we publicly release AgentHarm at https://huggingface.co/datasets/ai-safety-institute/AgentHarm.'}",https://openreview.net{'value': '/pdf/57757736e5c915caa584421e83e9d115eab664d2.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=AAXBfJNHDt,{'value': 'Generating  Graphs  via Spectral Diffusion'},Giorgia Minello; Alessandro Bicciato; Luca Rossi; Andrea Torsello; Luca Cosmo,~Giorgia_Minello1; ~Alessandro_Bicciato1; ~Luca_Rossi1; ~Andrea_Torsello3; ~Luca_Cosmo2,"{'value': ['graph neural networks', 'laplacian', 'eigendecomposition', 'spectrum', 'diffusion model', 'generative model']}","{'value': 'In this paper, we present GGSD, a novel graph generative model based on 1) the spectral decomposition of the graph Laplacian matrix and 2) a diffusion process. Specifically, we propose to use a denoising model to sample eigenvectors and eigenvalues from which we can reconstruct the graph Laplacian and adjacency matrix. Using the Laplacian spectrum allows us to naturally capture the structural characteristics of the graph and work directly in the node space while avoiding the quadratic complexity bottleneck that limits the applicability of other diffusion-based methods. This, in turn, is accomplished by truncating the spectrum, which, as we show in our experiments, results in a faster yet accurate generative process, and by designing a novel transformer-based architecture linear in the number of nodes. Our permutation invariant model can also handle node features by concatenating them to the eigenvectors of each node. An extensive set of experiments on both synthetic and real-world graphs demonstrates the strengths of our model against state-of-the-art alternatives.'}",https://openreview.net{'value': '/pdf/868518a4402885421381949f8c41939705e4034e.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=9vTAkJ9Tik,{'value': 'Doubly robust identification of treatment effects from multiple environments'},Piersilvio De Bartolomeis; Julia Kostin; Javier Abad; Yixin Wang; Fanny Yang,~Piersilvio_De_Bartolomeis1; ~Julia_Kostin1; ~Javier_Abad1; ~Yixin_Wang1; ~Fanny_Yang1,"{'value': ['treatment effect', 'confounding', 'heterogenous data', 'causality', 'causal inference', 'unobserved variables', 'post-treatment variables', 'collider bias']}","{'value': 'Practical and ethical constraints often require the use of observational data for causal inference, particularly in medicine and social sciences. Yet, observational datasets are prone to confounding, potentially compromising the validity of causal conclusions. \n While it is possible to correct for biases if the underlying causal graph is known, this is rarely a feasible ask in practical scenarios. A common strategy is to adjust for all available covariates, yet this approach can yield biased treatment effect estimates, especially when post-treatment or unobserved variables are present.\nWe propose RAMEN, an algorithm that produces unbiased treatment effect estimates\nby leveraging the heterogeneity of multiple data sources without the need to know or learn the underlying causal graph. Notably, RAMEN achieves *doubly robust identification*: it can identify the treatment effect whenever \nthe causal parents of the treatment or those of the outcome are observed, and the node whose parents are observed satisfies an invariance assumption. Empirical evaluations across synthetic, semi-synthetic, and real-world datasets show that our approach significantly outperforms existing methods.'}",https://openreview.net{'value': '/pdf/104bf37cd075785b0766da81f92479c0e890553a.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=9mBodivRIo,{'value': 'LocoVR: Multiuser Indoor Locomotion Dataset in Virtual Reality'},Kojiro Takeyama; Yimeng Liu; Misha Sra,~Kojiro_Takeyama1; ~Yimeng_Liu1; ~Misha_Sra1,"{'value': ['Dataset', 'Human trajectory', 'Indoor locomotion', 'Virtual reality', 'Social motion behavior']}","{'value': 'Understanding human locomotion is crucial for AI agents such as robots, particularly in complex indoor home environments. Modeling human trajectories in these spaces requires insight into how individuals maneuver around physical obstacles and manage social navigation dynamics. These dynamics include subtle behaviors influenced by proxemics - the social use of space, such as stepping aside to allow others to pass or choosing longer routes to avoid collisions. Previous research has developed datasets of human motion in indoor scenes, but these are often limited in scale and lack the nuanced social navigation dynamics common in home environments. \nTo address this, we present LocoVR, a dataset of 7000+ two-person trajectories captured in virtual reality from over 130 different indoor home environments. LocoVR provides accurate trajectory and precise spatial information, along with rich examples of socially-motivated movement behaviors. \nFor example, the dataset captures instances of individuals navigating around each other in narrow spaces, adjusting paths to respect personal boundaries in living areas, and coordinating movements in high-traffic zones like entryways and kitchens. Our evaluation shows that LocoVR significantly enhances model performance in three practical indoor tasks utilizing human trajectories, and demonstrates predicting socially-aware navigation patterns in home environments.'}",https://openreview.net{'value': '/pdf/f09d255b34007863bcd74b6fde80b26639f4a03b.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=9aTZf71uiD,{'value': 'Sports-Traj: A Unified Trajectory Generation Model for Multi-Agent Movement in Sports'},Yi Xu; Yun Fu,~Yi_Xu9; ~Yun_Fu1,"{'value': ['Trajectory Modeling', 'Trajectory Generation', 'Trajectory Prediction', 'Trajectory Imputation']}","{'value': 'Understanding multi-agent movement is critical across various fields. The conventional approaches typically focus on separate tasks such as trajectory prediction, imputation, or spatial-temporal recovery. Considering the unique formulation and constraint of each task, most existing methods are tailored for only one, limiting the ability to handle multiple tasks simultaneously, which is a common requirement in real-world scenarios. Another limitation is that widely used public datasets mainly focus on pedestrian movements with casual, loosely connected patterns, where interactions between individuals are not always present, especially at a long distance, making them less representative of more structured environments. To overcome these limitations, we propose a Unified Trajectory Generation model, UniTraj, that processes arbitrary trajectories as masked inputs, adaptable to diverse scenarios in the domain of sports games. Specifically, we introduce a Ghost Spatial Masking (GSM) module, embedded within a Transformer encoder, for spatial feature extraction. We further extend recent State Space Models (SSMs), known as the Mamba model, into a Bidirectional Temporal Mamba (BTM) to better capture temporal dependencies. Additionally, we incorporate a Bidirectional Temporal Scaled (BTS) module to thoroughly scan trajectories while preserving temporal missing relationships. Furthermore, we curate and benchmark three practical sports datasets, Basketball-U, Football-U, and Soccer-U, for evaluation. Extensive experiments demonstrate the superior performance of our model. We hope that our work can advance the understanding of human movement in real-world applications, particularly in sports. Our datasets, code, and model weights are available here https://github.com/colorfulfuture/UniTraj-pytorch.'}",https://openreview.net{'value': '/pdf/cf8be66b512605ced9183cbe431e01a01ab83ca0.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=9YNyiCJE3k,{'value': 'OSDA Agent: Leveraging Large Language Models for De Novo Design of Organic Structure Directing Agents'},Zhaolin Hu; Yixiao Zhou; Zhongan Wang; Xin Li; Weimin Yang; Hehe Fan; Yi Yang,~Zhaolin_Hu2; ~Yixiao_Zhou2; ~Zhongan_Wang1; ~Xin_Li61; ~Weimin_Yang1; ~Hehe_Fan1; ~Yi_Yang4,"{'value': ['Keywords: Large Language Model', 'OSDA', 'Zeolite', 'Molecular Design']}","{'value': ""Zeolites are crystalline porous materials that have been widely utilized in petrochemical industries as well as sustainable chemistry areas. Synthesis of zeolites often requires small molecules termed Organic Structure Directing Agents (OSDAs), which are critical in forming the porous structure. Molecule generation models can aid the design of OSDAs, but they are limited by single functionality and lack of interactivity. Meanwhile, large language models (LLMs) such as GPT-4, as general-purpose artificial intelligence systems, excel in instruction comprehension, logical reasoning, and interactive communication. However, LLMs lack in-depth chemistry knowledge and first-principle computation capabilities, resulting in uncontrollable outcomes even after fine-tuning. In this paper, we propose OSDA Agent, an interactive OSDA design framework that leverages LLMs as the brain, coupled with computational chemistry tools. The OSDA Agent consists of three main components: the Actor, responsible for generating potential OSDA structures; the Evaluator, which assesses and scores the generated OSDAs using computational chemistry tools; and the Self-reflector, which produces reflective summaries based on the Evaluator's feedback to refine the Actor's subsequent outputs. Experiments on representative zeolite frameworks show the generation-evaluation-reflection-refinement workflow can perform de novo design of OSDAs with superior generation quality than the pure LLM model, generating candidates consistent with experimentally validated OSDAs and optimizing known OSDAs.""}",https://openreview.net{'value': '/pdf/038f6de11e7b8f0eefed46bfb3c95bb7ca05810e.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=9XETcRsufZ,{'value': 'Mixture of Parrots: Experts improve memorization more than reasoning'},Samy Jelassi; Clara Mohri; David Brandfonbrener; Alex Gu; Nikhil Vyas; Nikhil Anand; David Alvarez-Melis; Yuanzhi Li; Sham M. Kakade; eran malach,~Samy_Jelassi1; ~Clara_Mohri1; ~David_Brandfonbrener1; ~Alex_Gu1; ~Nikhil_Vyas1; ~Nikhil_Anand2; ~David_Alvarez-Melis1; ~Yuanzhi_Li1; ~Sham_M._Kakade1; ~eran_malach1,"{'value': ['Mixture of Experts', 'memorization', 'reasoning']}","{'value': 'The Mixture-of-Experts (MoE) architecture enables a significant increase in the total number of model parameters with minimal computational overhead. \nHowever, it is not clear what performance tradeoffs, if any, exist between MoEs and standard dense transformers.\nIn this paper, \nwe show that as we increase the number of experts (while fixing the number of active parameters), the memorization performance consistently increases while the reasoning capabilities saturate. \n\n\nWe begin by analyzing the theoretical limitations of MoEs at reasoning. We prove that there exist graph  problems that cannot be solved by any number of experts of a certain width; however, the same task can be easily solved by a dense model with a slightly larger width. \nOn the other hand, we find that on memory-intensive tasks, MoEs can effectively leverage a small number of active parameters with a large number of experts to memorize the data. \nWe empirically validate these findings on synthetic graph problems and memory-intensive closed book retrieval tasks. \nLastly, we  pre-train a series of MoEs and dense transformers and evaluate them on commonly used benchmarks in math and natural language. \nWe find that increasing the number of experts helps solve knowledge-intensive tasks, but fails to yield the same benefits for reasoning tasks.'}",https://openreview.net{'value': '/pdf/f379a90551974f6196cfa2b2caaad533e5df73d5.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=9UGfOJBuL8,{'value': 'Conditional Diffusion with Ordinal Regression: Longitudinal Data Generation for Neurodegenerative Disease Studies'},Hyuna Cho; Ziquan Wei; Seungjoo Lee; Tingting Dan; Guorong Wu; Won Hwa Kim,~Hyuna_Cho1; ~Ziquan_Wei1; ~Seungjoo_Lee3; ~Tingting_Dan1; ~Guorong_Wu1; ~Won_Hwa_Kim4,"{'value': ['neurodegenerative disease', 'conditional diffusion model', 'longitudinal data analysis']}","{'value': 'Modeling the progression of neurodegenerative diseases such as Alzheimer’s disease (AD) is crucial for early detection and prevention given their irreversible nature. However, the scarcity of longitudinal data and complex disease dynamics make the analysis highly challenging. Moreover, longitudinal samples often contain irregular and large intervals between subject visits, which underscore the necessity for advanced data generation techniques that can accurately simulate disease progression over time. In this regime, we propose a novel conditional generative model for synthesizing longitudinal sequences and present its application to neurodegenerative disease data generation conditioned on multiple time-dependent ordinal factors, such as age and disease severity. Our method sequentially generates continuous data by bridging gaps between sparse data points with a diffusion model, ensuring a realistic representation of disease progression. The synthetic data are curated to integrate both cohort-level and individual-specific characteristics, where the cohort-level representations are modeled with an ordinal regression to capture longitudinally monotonic behavior. Extensive experiments on four AD biomarkers validate the superiority of our method over nine baseline approaches, highlighting its potential to be applied to a variety of longitudinal data generation.'}",https://openreview.net{'value': '/pdf/d65f60f1dcfe1c8f88450f60543f6ad4be2b822a.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=9RCT0ngvZP,{'value': 'Montessori-Instruct: Generate Influential Training Data Tailored for Student Learning'},Xiaochuan Li; Zichun Yu; Chenyan Xiong,~Xiaochuan_Li3; ~Zichun_Yu1; ~Chenyan_Xiong1,"{'value': ['synthetic data', 'data influence', 'instruction tuning']}","{'value': ""Synthetic data has been widely used to train large language models, but their generative nature inevitably introduces noisy, non-informative, and misleading learning signals. In this paper, we propose Montessori-Instruct, a novel data synthesis framework that tailors the data synthesis ability of the teacher language model toward the student language model's learning process. Specifically, we utilize local data influence of synthetic training data points on students to characterize students' learning preferences. Then, we train the teacher model with Direct Preference Optimization (DPO) to generate synthetic data tailored toward student learning preferences. Experiments with Llama3-8B-Instruct (teacher) and Llama3-8B (student) on Alpaca Eval and MT-Bench demonstrate that Montessori-Instruct significantly outperforms standard synthesis methods by 18.35\\% and 46.24\\% relatively. Our method also beats data synthesized by a stronger teacher model, GPT-4o. Further analysis confirms the benefits of teacher's learning to generate more influential training data in the student's improved learning, the advantages of local data influence in accurately measuring student preferences, and the robustness of Montessori-Instruct across different student models. Our code and data are open-sourced at https://github.com/cxcscmu/Montessori-Instruct.""}",https://openreview.net{'value': '/pdf/47f4123f24aa294b073b85db5a1437a1fd8f45ff.pdf'},{'abstract_filter': 'Data Synthesis'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=9NfHbWKqMF,{'value': 'SplatFormer: Point Transformer for Robust 3D Gaussian Splatting'},Yutong Chen; Marko Mihajlovic; Xiyi Chen; Yiming Wang; Sergey Prokudin; Siyu Tang,~Yutong_Chen1; ~Marko_Mihajlovic1; ~Xiyi_Chen1; ~Yiming_Wang6; ~Sergey_Prokudin1; ~Siyu_Tang1,"{'value': ['Novel View Synthesis', 'Gaussian Splatting', 'Point cloud modeling']}","{'value': '3D Gaussian Splatting (3DGS) has recently transformed photorealistic reconstruction, achieving high visual fidelity and real-time performance. However, rendering quality significantly deteriorates when test views deviate from the camera angles used during training, posing a major challenge for applications in immersive free-viewpoint rendering and navigation. In this work, we conduct a comprehensive evaluation of 3DGS and related novel view synthesis methods under out-of-distribution (OOD) test camera scenarios. By creating diverse test cases with synthetic and real-world datasets, we demonstrate that most existing methods, including those incorporating various regularization techniques and data-driven priors, struggle to generalize effectively to OOD views. To address this limitation, we introduce SplatFormer, the first point transformer model specifically designed to operate on Gaussian splats. SplatFormer takes as input an initial 3DGS set optimized under limited training views and refines it in a single forward pass, effectively removing potential artifacts in OOD test views. To our knowledge, this is the first successful application of point transformers directly on 3DGS sets, surpassing the limitations of previous multi-scene training methods, which could handle only a restricted number of input views during inference. Our model significantly improves rendering quality under extreme novel views, achieving state-of-the-art performance in these challenging scenarios and outperforming various 3DGS regularization techniques, multi-scene models tailored for sparse view synthesis, and diffusion-based frameworks. The project url is https://sergeyprokudin.github.io/splatformer.'}",https://openreview.net{'value': '/pdf/b05fcaaffbc6f81e70f605c033bb30f44fe43513.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=9FRwkPw3Cn,{'value': 'Inverse Constitutional AI: Compressing Preferences into Principles'},Arduin Findeis; Timo Kaufmann; Eyke Hüllermeier; Samuel Albanie; Robert D. Mullins,~Arduin_Findeis1; ~Timo_Kaufmann1; ~Eyke_Hüllermeier1; ~Samuel_Albanie2; ~Robert_D._Mullins1,"{'value': ['human feedback', 'evaluation', 'interpretability', 'preference learning', 'AI annotators']}","{'value': 'Feedback data is widely used for fine-tuning and evaluating state-of-the-art AI models. Pairwise text preferences, where human or AI annotators select the “better” of two options, are particularly common. Such preferences are used to train (reward) models or to rank models with aggregate statistics. For many applications it is desirable to understand annotator preferences in addition to modelling them\u2006\u2006– not least because extensive prior work has shown various unintended biases in preference datasets. Yet, preference datasets remain challenging to interpret. Neither black-box reward models nor statistics can answer why one text is preferred over another. Manual interpretation of the numerous (long) response pairs is usually equally infeasible. In this paper, we introduce the Inverse Constitutional AI (ICAI) problem, formulating the interpretation of pairwise text preference data as a compression task. In constitutional AI, a set of principles (a constitution) is used to provide feedback and fine-tune AI models. ICAI inverts this process: given a feedback dataset, we aim to extract a constitution that best enables a large language model (LLM) to reconstruct the original annotations. We propose a corresponding ICAI algorithm and validate its generated constitutions quantitatively based on annotation reconstruction accuracy on several datasets: (a)\xa0synthetic feedback data with known principles; (b)\xa0AlpacaEval cross-annotated human feedback data; (c)\xa0crowdsourced Chatbot Arena data; and (d)\xa0PRISM data from diverse demographic groups. As an example application, we further demonstrate the detection of biases in human feedback data. As a short and interpretable representation of the original dataset, generated constitutions have many potential use cases: they may help identify undesirable annotator biases, better understand model performance, scale feedback to unseen data, or assist with adapting AI models to individual user or group preferences. We release the source code for our algorithm and experiments at\xa0https://github.com/rdnfn/icai.'}",https://openreview.net{'value': '/pdf/87ddb2258aa09176470b236f69a25288cd72b963.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=97rOQDPmk2,{'value': 'On the Optimization and Generalization of Two-layer Transformers with Sign Gradient Descent'},Bingrui Li; Wei Huang; Andi Han; Zhanpeng Zhou; Taiji Suzuki; Jun Zhu; Jianfei Chen,~Bingrui_Li1; ~Wei_Huang6; ~Andi_Han1; ~Zhanpeng_Zhou1; ~Taiji_Suzuki1; ~Jun_Zhu2; ~Jianfei_Chen1,{'value': ['Sign Gradient Descent; Transformer; Training Dynamics; Theory']},"{'value': ""The Adam optimizer is widely used for transformer optimization in practice, which makes understanding the underlying optimization mechanisms an important problem.\nHowever, due to the Adam's complexity, theoretical analysis of how it optimizes transformers remains a challenging task. \nFortunately, Sign Gradient Descent (SignGD) serves as an effective surrogate for Adam.\nDespite its simplicity, theoretical understanding of how SignGD optimizes transformers still lags behind.\nIn this work, we study how SignGD optimizes a two-layer transformer -- consisting of a softmax attention layer with trainable query-key parameterization followed by a linear layer -- on \na linearly separable noisy dataset.\nWe identify four stages in the training dynamics, each exhibiting intriguing behaviors.\nBased on the training dynamics, we prove the fast convergence but poor generalization of the learned transformer on the noisy dataset.\nWe also show that Adam behaves similarly to SignGD in terms of both optimization and generalization in this setting.\nAdditionally, we find that the poor generalization of SignGD is not solely due to data noise,\nsuggesting that both SignGD and Adam requires high-quality data for real-world tasks.\nFinally, experiments on synthetic and real-world datasets empirically support our theoretical results.""}",https://openreview.net{'value': '/pdf/ed1b385f23a621d81739b6bc591c5a42087da5dd.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=90Db4RUBc7,{'value': 'Joint Fine-tuning and Conversion of Pretrained Speech and Language Models towards Linear Complexity'},Mutian He; Philip N. Garner,~Mutian_He1; ~Philip_N._Garner1,"{'value': ['pretrained models', 'efficient attention', 'uptraining', 'speech processing']}","{'value': 'Architectures such as Linformer and Mamba have recently emerged as competitive linear time replacements for transformers. However, corresponding large pretrained models are often unavailable, especially in non-text domains. To remedy this, we present a Cross-Architecture Layerwise Distillation (CALD) approach that jointly converts a transformer model to a linear time substitute and fine-tunes it to a target task. We also compare several means to guide the fine-tuning to optimally retain the desired inference capability from the original model. The methods differ in their use of the target model and the trajectory of the parameters. In a series of empirical studies on language processing, language modeling, and speech processing, we show that CALD can effectively recover the result of the original model, and that the guiding strategy contributes to the result. Some reasons for the variation are suggested.'}",https://openreview.net{'value': '/pdf/a9cc8edf71023451b13c38f586f7e6cc4ad8d7cf.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=8rbkePAapb,{'value': 'PFGuard: A Generative Framework with Privacy and Fairness Safeguards'},Soyeon Kim; Yuji Roh; Geon Heo; Steven Euijong Whang,~Soyeon_Kim3; ~Yuji_Roh1; ~Geon_Heo1; ~Steven_Euijong_Whang1,"{'value': ['Trustworthy AI', 'Responsible AI', 'ML Fairness', 'Differential Privacy', 'Generative Model']}","{'value': 'Generative models must ensure both privacy and fairness for Trustworthy AI. While these goals have been pursued separately, recent studies propose to combine existing privacy and fairness techniques to achieve both goals. However, naively combining these techniques can be insufficient due to privacy-fairness conflicts, where a sample in a minority group may be represented in ways that support fairness, only to be suppressed for privacy. We demonstrate how these conflicts lead to adverse effects, such as privacy violations and unexpected fairness-utility tradeoffs. To mitigate these risks, we propose PFGuard, a generative framework with privacy and fairness safeguards, which simultaneously addresses privacy, fairness, and utility. By using an ensemble of multiple teacher models, PFGuard balances privacy-fairness conflicts between fair and private training stages and achieves high utility based on ensemble learning. Extensive experiments show that PFGuard successfully generates synthetic data on high-dimensional data while providing both DP guarantees and convergence in fair generative modeling.'}",https://openreview.net{'value': '/pdf/0ffaaa0b96cd5705498ded4b8801f0106d57fe1d.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=8muemqlnG3,{'value': 'Causal Discovery via Bayesian Optimization'},Bao Duong; Sunil Gupta; Thin Nguyen,~Bao_Duong1; ~Sunil_Gupta2; ~Thin_Nguyen1,"{'value': ['causal discovery', 'causal structure learning', 'bayesian optimization']}","{'value': 'Existing score-based methods for directed acyclic graph (DAG) learning from observational data struggle to recover the causal graph accurately and sample-efficiently. To overcome this, in this study, we propose DrBO (DAG recovery via Bayesian Optimization)—a novel DAG learning framework leveraging Bayesian optimization (BO) to find high-scoring DAGs. We show that, by sophisticatedly choosing the promising DAGs to explore, we can find higher-scoring ones much more efficiently. To address the scalability issues of conventional BO in DAG learning, we replace Gaussian Processes commonly employed in BO with dropout neural networks, trained in a continual manner, which allows for (i) flexibly modeling the DAG scores without overfitting, (ii) incorporation of uncertainty into the estimated scores, and (iii) scaling with the number of evaluations. As a result, DrBO is computationally efficient and can find the accurate DAG in fewer trials and less time than existing state-of-the-art methods. This is demonstrated through an extensive set of empirical evaluations on many challenging settings with both synthetic and real data. Our implementation is available at https://github.com/baosws/DrBO.'}",https://openreview.net{'value': '/pdf/502a4568dd4ef45839787ec1259c87b5f75ed78c.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=8m7p4k6Zeb,{'value': 'From Artificial Needles to Real Haystacks: Improving Retrieval Capabilities in LLMs by Finetuning on Synthetic Data'},Zheyang Xiong; Vasilis Papageorgiou; Kangwook Lee; Dimitris Papailiopoulos,~Zheyang_Xiong1; ~Vasilis_Papageorgiou1; ~Kangwook_Lee1; ~Dimitris_Papailiopoulos1,"{'value': ['Synthetic Data', 'LLM finetuning', 'Long Context', 'Retrieval']}","{'value': ""Recent studies have shown that Large Language Models (LLMs) struggle to accurately retrieve information and maintain reasoning capabilities when processing long-context inputs. To address these limitations, we propose a finetuning approach utilizing a carefully designed synthetic dataset comprising numerical key-value retrieval tasks. Our experiments on models like GPT-3.5 Turbo and Mistral 7B demonstrate that finetuning LLMs on this dataset significantly improves LLMs' information retrieval and reasoning capabilities in longer-context settings. We present an analysis of the finetuned models, illustrating the transfer of skills from synthetic to real task evaluations (e.g., $10.5\\%$ improvement on $20$ documents MDQA at position $10$ for GPT-3.5 Turbo). We also find that finetuned LLMs' performance on general benchmarks remains almost constant while LLMs finetuned on other baseline long-context augmentation data can encourage hallucination (e.g., on TriviaQA, Mistral 7B finetuned on our synthetic data cause no performance drop while other baseline data can cause a drop that ranges from $2.33\\%$ to $6.19\\%$). Our study highlights the potential of finetuning on synthetic data for improving the performance of LLMs on longer-context tasks.""}",https://openreview.net{'value': '/pdf/69c8da7c040588eb1592780dea15514491b5a24e.pdf'},{'title_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=8dzKkeWUUb,{'value': 'SciLitLLM: How to Adapt LLMs for Scientific Literature Understanding'},Sihang Li; Jin Huang; Jiaxi Zhuang; Yaorui Shi; Xiaochen Cai; Mingjun Xu; Xiang Wang; Linfeng Zhang; Guolin Ke; Hengxing Cai,~Sihang_Li1; ~Jin_Huang7; ~Jiaxi_Zhuang1; ~Yaorui_Shi2; ~Xiaochen_Cai1; ~Mingjun_Xu2; ~Xiang_Wang6; ~Linfeng_Zhang1; ~Guolin_Ke3; ~Hengxing_Cai1,"{'value': ['Large Language Model', 'Pre-training', 'Supervised Fine-tuning', 'Scientific Literature Understanding']}","{'value': 'Scientific literature understanding is crucial for extracting targeted information and garnering insights, thereby significantly advancing scientific discovery.\nDespite the remarkable success of Large Language Models (LLMs), they face challenges in scientific literature understanding, primarily due to (1) a lack of scientific knowledge and (2) unfamiliarity with specialized scientific tasks.\nTo develop an LLM specialized in scientific literature understanding, we propose a hybrid strategy that integrates continual pre-training (CPT) and supervised fine-tuning (SFT), to simultaneously infuse scientific domain knowledge and enhance instruction-following capabilities for domain-specific tasks.\nIn this process, we identify two key challenges: (1) constructing high-quality CPT corpora, and (2) generating diverse SFT instructions. \nWe address these challenges through a meticulous pipeline, including PDF text extraction, parsing content error correction, quality filtering, and synthetic instruction creation.\nApplying this strategy, we present a suite of LLMs: SciLitLLM, specialized in scientific literature understanding.\nThese models demonstrate promising performance on scientific literature understanding benchmarks.\n(1) We present an effective framework that integrates CPT and SFT to adapt LLMs to scientific literature understanding, which can also be easily adapted to other domains.\n(2) We propose an LLM-based synthesis method to generate diverse and high-quality scientific instructions, resulting in a new instruction set -- SciLitIns -- for less-represented scientific domains. \n(3) SciLitLLM achieves promising performance in scientific literature understanding benchmarks.'}",https://openreview.net{'value': '/pdf/43f6c12c534f86bd8a7ce78bed1b182f11601cbf.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=8UFG9D8xeU,{'value': 'Direct Post-Training Preference Alignment for Multi-Agent Motion Generation Model Using Implicit Feedback from Pre-training Demonstrations'},Thomas Tian; Kratarth Goel,~Thomas_Tian1; ~Kratarth_Goel1,"{'value': ['Efficient Post-training Preference Alignment', 'Alignment from demonstrations', 'Multi-agent Motion Generation']}","{'value': ""Recent advancements in Large Language Models (LLMs) have revolutionized motion generation models in embodied applications such as autonomous driving and robotic manipulation. While LLM-type auto-regressive motion generation models benefit from training scalability, there remains a discrepancy between their token prediction objectives and human preferences. As a result, models pre-trained solely with token-prediction objectives often generate behaviors that deviate from what humans would prefer, making post-training preference alignment crucial for producing human-preferred motions. Unfortunately, post-training alignment requires extensive preference rankings of motions generated by the pre-trained model, which are costly and time-consuming to annotate, especially in multi-agent motion generation settings. Recently, there has been growing interest in leveraging expert demonstrations previously used during pre-training to scalably generate preference data for post-training alignment. However, these methods often adopt an adversarial assumption, treating all pre-trained model-generated samples as unpreferred examples and relying solely on pre-training expert demonstrations to construct preferred examples. This adversarial approach overlooks the valuable signal provided by preference rankings among the model's own generations, ultimately reducing alignment effectiveness and potentially leading to misaligned behaviors. In this work, instead of treating all generated samples as equally bad, we propose a principled approach that leverages implicit preferences encoded in pre-training expert demonstrations to construct preference rankings among the pre-trained model's generations, offering more nuanced preference alignment guidance with zero human cost. We apply our approach to large-scale traffic simulation (more than 100 agents) and demonstrate its effectiveness in improving the realism of pre-trained model's generated behaviors, making a lightweight 1M motion generation model comparable to state-of-the-art large imitation-based models by relying solely on implicit feedback from pre-training demonstrations, without requiring additional post-training human preference annotations or incurring high computational costs. Furthermore, we provide an in-depth analysis of preference data scaling laws and their effects on over-optimization, offering valuable insights for future studies.""}",https://openreview.net{'value': '/pdf/a9c4a760a8e787b8eaa7fbe57e48808633766ac2.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=8NlUL0Cv1L,{'value': 'GenEx: Generating an Explorable World'},TaiMing Lu; Tianmin Shu; Alan Yuille; Daniel Khashabi; Jieneng Chen,~TaiMing_Lu1; ~Tianmin_Shu1; ~Alan_Yuille1; ~Daniel_Khashabi2; ~Jieneng_Chen1,"{'value': ['Generative Models', 'Video Generation', 'Embodied AI']}","{'value': ""Understanding, navigating, and exploring the 3D physical real world has long been a central challenge in the development of artificial intelligence. In this work, we take a step toward this goal by introducing *GenEx*, a system capable of planning complex embodied world exploration, guided by its generative imagination that forms expectations about the surrounding environments. *GenEx* generates high-quality, continuous 360-degree virtual environments, achieving robust loop consistency and active 3D mapping over extended trajectories. Leveraging generative imagination, GPT-assisted agents can undertake complex embodied tasks, including goal-agnostic exploration and goal-driven navigation. Agents utilize imagined observations to update their beliefs, simulate potential outcomes, and enhance their decision-making. Training on the synthetic urban dataset *GenEx-DB* and evaluation on *GenEx-EQA* demonstrate that our approach significantly improves agents' planning capabilities, providing a transformative platform toward intelligent, imaginative embodied exploration.""}",https://openreview.net{'value': '/pdf/6a684d482e43ed5c29306fe10b38874abb2e5f27.pdf'},{'abstract_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=8KQzoD5XAr,{'value': 'CraftRTL: High-quality Synthetic Data Generation for Verilog Code Models with Correct-by-Construction Non-Textual Representations and Targeted Code Repair'},Mingjie Liu; Yun-Da Tsai; Wenfei Zhou; Haoxing Ren,~Mingjie_Liu2; ~Yun-Da_Tsai1; ~Wenfei_Zhou1; ~Haoxing_Ren1,"{'value': ['Verilog Code Generation', 'Synthetic Data Generation', 'Large Language Models']}","{'value': ""Despite the significant progress made in code generation with large language models, challenges persist, especially with hardware description languages such as Verilog. This paper first presents an analysis of fine-tuned LLMs on Verilog coding, with synthetic data from prior methods. We identify two main issues: difficulties in handling non-textual representations (Karnaugh maps, state-transition diagrams and waveforms) and significant variability during training with models randomly making ''minor'' mistakes. To address these limitations, we enhance data curation by creating correct-by-construction data targeting non-textual representations. Additionally, we introduce an automated framework that generates error reports from various model checkpoints and injects these errors into open-source code to create targeted code repair data. Our fine-tuned Starcoder2-15B outperforms prior state-of-the-art results by 3.8\\%, 10.9\\%, 6.6\\% for pass@1 on VerilogEval-Machine, VerilogEval-Human, and RTLLM.""}",https://openreview.net{'value': '/pdf/68b87ad7b877298d194b32e2a82bd20cbd1701e4.pdf'},{'title_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=8G3FyfHIko,{'value': 'GDrag:Towards General-Purpose Interactive Editing with Anti-ambiguity Point Diffusion'},Xiaojian Lin; Hanhui Li; Yuhao Cheng; Yiqiang Yan; Xiaodan Liang,~Xiaojian_Lin1; ~Hanhui_Li1; ~Yuhao_Cheng2; ~Yiqiang_Yan1; ~Xiaodan_Liang2,"{'value': ['Interactive editing', 'dragging-based image manipulation', 'diffusion models']}","{'value': 'Recent interactive point-based image manipulation methods have gained considerable attention for being user-friendly. However, these methods still face two types of ambiguity issues that can lead to unsatisfactory outcomes, namely, intention ambiguity which misinterprets the purposes of users, and content ambiguity where target image areas are distorted by distracting elements. To address these issues and achieve general-purpose manipulations, we propose a novel task-aware, training-free framework called GDrag. Specifically, GDrag defines a taxonomy of atomic manipulations, which can be parameterized and combined unitedly to represent complex manipulations, thereby reducing intention ambiguity. Furthermore, GDrag introduces two strategies to mitigate content ambiguity, including an anti-ambiguity dense trajectory calculation method (ADT) and a self-adaptive motion supervision method (SMS). Given an atomic manipulation, ADT converts the sparse user-defined handle points into a dense point set by selecting their semantic and geometric neighbors, and calculates the trajectory of the point set. Unlike previous motion supervision methods relying on a single global scale for low-rank adaption, SMS jointly optimizes point-wise adaption scales and latent feature biases. These two methods allow us to model fine-grained target contexts and generate precise trajectories. As a result, GDrag consistently produces precise and appealing results in different editing tasks. Extensive experiments on the challenging DragBench dataset demonstrate that GDrag outperforms state-of-the-art methods significantly. The code of GDrag will be released upon acceptance.'}",https://openreview.net{'value': '/pdf/40ddc7c1ae4a0dd23c4e012b289a08348d129983.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=8EB8k6DdCU,{'value': 'ToolACE: Winning the Points of LLM Function Calling'},Weiwen Liu; Xu Huang; Xingshan Zeng; xinlong hao; Shuai Yu; Dexun Li; Shuai Wang; Weinan Gan; Zhengying Liu; Yuanqing Yu; Zezhong WANG; Yuxian Wang; Wu Ning; Yutai Hou; Bin Wang; Chuhan Wu; Wang Xinzhi; Yong Liu; Yasheng Wang; Duyu Tang; Dandan Tu; Lifeng Shang; Xin Jiang; Ruiming Tang; Defu Lian; Qun Liu; Enhong Chen,~Weiwen_Liu1; ~Xu_Huang2; ~Xingshan_Zeng1; ~xinlong_hao1; ~Shuai_Yu3; ~Dexun_Li1; ~Shuai_Wang34; ~Weinan_Gan1; ~Zhengying_Liu2; ~Yuanqing_Yu1; ~Zezhong_WANG1; ~Yuxian_Wang1; ~Wu_Ning1; ~Yutai_Hou1; ~Bin_Wang12; ~Chuhan_Wu2; ~Wang_Xinzhi1; ~Yong_Liu14; ~Yasheng_Wang1; ~Duyu_Tang3; ~Dandan_Tu1; ~Lifeng_Shang1; ~Xin_Jiang1; ~Ruiming_Tang2; ~Defu_Lian1; ~Qun_Liu1; ~Enhong_Chen1,"{'value': ['Tool leaning', 'Function calling', 'Large language models']}","{'value': 'Function calling significantly extends the application boundary of large language models (LLMs), where high-quality and diverse training data is critical for unlocking this capability. However, collecting and annotating real function-calling data is challenging, while synthetic data from existing pipelines often lack coverage and accuracy. In this paper, we present ToolACE, an automatic agentic pipeline designed to generate accurate, complex, and diverse tool-learning data, specifically tailored to the capabilities of LLMs. ToolACE leverages a novel self-evolution synthesis process to curate a comprehensive API pool of 26,507 diverse APIs. Dialogs are further generated through the interplay among multiple agents, under the guidance of a complexity evaluator. To ensure data accuracy, we implement a dual-layer verification system combining rule-based and model-based checks. We demonstrate that models trained on our synthesized data---even with only 8B parameters---achieve state-of-the-art performance, comparable to the latest GPT-4 models. Our model and a subset of the data are publicly available at https://huggingface.co/Team-ACE.'}",https://openreview.net{'value': '/pdf/9c7c53cc6199348d235063c044442216d84429c4.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=82p8VHRsaK,{'value': 'Language Models are Advanced Anonymizers'},Robin Staab; Mark Vero; Mislav Balunovic; Martin Vechev,~Robin_Staab1; ~Mark_Vero1; ~Mislav_Balunovic1; ~Martin_Vechev1,"{'value': ['privacy', 'anonymization', 'large language models']}","{'value': 'Recent privacy research on large language models (LLMs) has shown that they achieve near-human-level performance at inferring personal data from online texts. With ever-increasing model capabilities, existing text anonymization methods are currently lacking behind regulatory requirements and adversarial threats. In this work, we take two steps to bridge this gap: First, we present a new setting for evaluating anonymization in the face of adversarial LLM inferences, allowing for a natural measurement of anonymization performance while remedying some of the shortcomings of previous metrics. Then, within this setting, we develop a novel LLM-based adversarial anonymization framework leveraging the strong inferential capabilities of LLMs to inform our anonymization procedure. We conduct a comprehensive experimental evaluation of adversarial anonymization across 13 LLMs on real-world and synthetic online texts, comparing it against multiple baselines and industry-grade anonymizers. Our evaluation shows that adversarial anonymization outperforms current commercial anonymizers both in terms of the resulting utility and privacy. We support our findings with a human study (n=50) highlighting a strong and consistent human preference for LLM-anonymized texts.'}",https://openreview.net{'value': '/pdf/53e35a12d9698ac977f1da0d041f2e713b801f72.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=7visV100Ms,{'value': 'Self-Boosting Large Language Models with  Synthetic Preference Data'},Qingxiu Dong; Li Dong; Xingxing Zhang; Zhifang Sui; Furu Wei,~Qingxiu_Dong1; ~Li_Dong1; ~Xingxing_Zhang1; ~Zhifang_Sui1; ~Furu_Wei1,"{'value': ['preference optimization', 'synthetic data', 'LLM alignment']}","{'value': 'Through alignment with human preferences, Large Language Models (LLMs) have advanced significantly in generating honest, harmless, and helpful responses. However, collecting high-quality preference data is a resource-intensive and creativity-demanding process, especially for the continual improvement of LLMs. We introduce SynPO, a self-boosting paradigm that leverages synthetic preference data for model alignment. SynPO employs an iterative mechanism wherein a self-prompt generator creates diverse prompts, and a response improver refines model responses progressively. This approach trains LLMs to autonomously learn the generative rewards for their own outputs and  eliminates the need for large-scale annotation of prompts and human preferences. After four SynPO iterations, Llama3-8B and Mistral-7B show significant enhancements in instruction-following abilities, achieving over 22.1% win rate improvements on AlpacaEval 2.0 and ArenaHard. Simultaneously, SynPO improves the general performance of LLMs on various tasks, validated by a 3.2 to 5.0 average score increase on the well-recognized Open LLM leaderboard.'}",https://openreview.net{'value': '/pdf/8faaa5910bf9ee2826ee00ca7db26de7e34285c1.pdf'},{'title_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=7ohlQUbTpp,{'value': 'Collab: Controlled Decoding using Mixture of Agents for LLM Alignment'},Souradip Chakraborty; Sujay Bhatt; Udari Madhushani Sehwag; Soumya Suvra Ghosal; Jiahao Qiu; Mengdi Wang; Dinesh Manocha; Furong Huang; Alec Koppel; Sumitra Ganesh,~Souradip_Chakraborty1; ~Sujay_Bhatt1; ~Udari_Madhushani_Sehwag1; ~Soumya_Suvra_Ghosal2; ~Jiahao_Qiu1; ~Mengdi_Wang1; ~Dinesh_Manocha3; ~Furong_Huang1; ~Alec_Koppel1; ~Sumitra_Ganesh1,"{'value': ['Alignment', 'Decoding', 'RLHF', 'Transfer Decoding', 'LLM']}","{'value': 'Alignment of Large Language models (LLMs) is crucial for safe and trustworthy deployment in applications. Reinforcement learning from human feedback (RLHF) has emerged as an effective technique to align LLMs to human preferences, and broader utilities, but it requires updating billions of model parameters which is computationally expensive. Controlled Decoding, by contrast, provides a mechanism for aligning a model at inference time without retraining. However, single-agent decoding approaches often struggle to adapt to diverse tasks due to the complexity and variability inherent in these tasks. To strengthen the test-time performance w.r.t the target task, we propose a mixture of agents-based decoding strategies leveraging the existing off-the-shelf aligned LLM policies. Treating each prior policy as an agent in the spirit of mixture of agent collaboration, we develop a decoding method that allows for inference-time alignment through a token-level selection strategy among multiple agents. For each token, the most suitable LLM is dynamically chosen from a pool of models based on a long-term utility metric. This policy-switching mechanism ensures optimal model selection at each step, enabling efficient collaboration and alignment among LLMs during decoding. Theoretical analysis of our proposed algorithm establishes optimal performance with respect to the target task represented via a target reward, for the given off-the-shelf models. We conduct comprehensive empirical evaluations with open-source aligned models on diverse tasks and preferences, which demonstrates the merits of this approach over single-agent decoding baselines. Notably, COLLAB surpasses the current SoTA decoding strategy, achieving an improvement of {up to 1.56x} in average reward and $71.89\\%$ in GPT-4 based win-tie rate.'}",https://openreview.net{'value': '/pdf/2fc0b7d8ce73f7a9689021e5a6f7a1784a19c0fd.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=7nOl5W6xU4,{'value': 'CityAnchor: City-scale 3D Visual Grounding with Multi-modality LLMs'},Jinpeng Li; Haiping Wang; Jiabin chen; Yuan Liu; Zhiyang Dou; Yuexin Ma; Sibei Yang; Yuan Li; Wenping Wang; Zhen Dong; Bisheng Yang,~Jinpeng_Li5; ~Haiping_Wang1; ~Jiabin_chen2; ~Yuan_Liu3; ~Zhiyang_Dou1; ~Yuexin_Ma2; ~Sibei_Yang1; ~Yuan_Li28; ~Wenping_Wang1; ~Zhen_Dong4; ~Bisheng_Yang1,"{'value': ['3D Visual Grounding', 'Large language model', 'multi-modality language model']}","{'value': 'In this paper, we present a 3D visual grounding method called CityAnchor for localizing an urban object in a city-scale point cloud. Recent developments in multiview reconstruction enable us to reconstruct city-scale point clouds but how to conduct visual grounding on such a large-scale urban point cloud remains an open problem. Previous 3D visual grounding system mainly concentrates on localizing an object in an image or a small-scale point cloud, which is not accurate and efficient enough to scale up to a city-scale point cloud. We address this problem with a multi-modality LLM which consists of two stages, a coarse localization and a fine-grained matching. Given the text descriptions, the coarse localization stage locates possible regions on a projected 2D map of the point cloud while the fine-grained matching stage accurately determines the most matched object in these possible regions. We conduct experiments on the CityRefer dataset and a new synthetic dataset annotated by us, both of which demonstrate our method can produce accurate 3D visual grounding on a city-scale 3D point cloud.'}",https://openreview.net{'value': '/pdf/ea202533c71711b996207024157c54983527897f.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=7XgKAabsPp,{'value': 'Theory on Mixture-of-Experts in Continual Learning'},Hongbo Li; Sen Lin; Lingjie Duan; Yingbin Liang; Ness Shroff,~Hongbo_Li6; ~Sen_Lin1; ~Lingjie_Duan1; ~Yingbin_Liang1; ~Ness_Shroff1,"{'value': ['continual learning', 'mixture-of-experts', 'catastrophic forgetting', 'generalization error']}","{'value': 'Continual learning (CL) has garnered significant attention because of its ability to adapt to new tasks that arrive over time. Catastrophic forgetting (of old tasks) has been identified as a major issue in CL, as the model adapts to new tasks. The Mixture-of-Experts (MoE) model has recently been shown to effectively mitigate catastrophic forgetting in CL, by employing a gating network to sparsify and distribute diverse tasks among multiple experts. However, there is a lack of theoretical analysis of MoE and its impact on the learning performance in CL. This paper provides the first theoretical results to characterize the impact of MoE in CL via the lens of overparameterized linear regression tasks. We establish the benefit of MoE over a single expert by proving that the MoE model can diversify its experts to specialize in different tasks, while its router learns to select the right expert for each task and balance the loads across all experts. Our study further suggests an intriguing fact that the MoE in CL needs to terminate the update of the gating network after sufficient training rounds to attain system convergence, which is not needed in the existing MoE studies that do not consider the continual task arrival. Furthermore, we provide explicit expressions for the expected forgetting and overall generalization error to characterize the benefit of MoE in the learning performance in CL. Interestingly, adding more experts requires additional rounds before convergence, which may not enhance the learning performance. Finally, we conduct experiments on both synthetic and real datasets to extend these insights from linear models to deep neural networks (DNNs), which also shed light on the practical algorithm design for MoE in CL.'}",https://openreview.net{'value': '/pdf/c5c8973cab66f291d1e55b41f49588c576e63d89.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=7XNgVPxCiA,{'value': 'Forte : Finding Outliers with Representation Typicality Estimation'},Debargha Ganguly; Warren Richard Morningstar; Andrew Seohwan Yu; Vipin Chaudhary,~Debargha_Ganguly1; ~Warren_Richard_Morningstar1; ~Andrew_Seohwan_Yu1; ~Vipin_Chaudhary2,"{'value': ['Generative Models', 'Out-of-Distribution Detection (OOD)']}","{'value': 'Generative models can now produce photorealistic synthetic data which is virtually indistinguishable from the real data used to train it. This is a significant evolution over previous models which could produce reasonable facsimiles of the training data, but ones which could be visually distinguished from the training data by human evaluation. Recent work on OOD detection has raised doubts that generative model likelihoods are optimal OOD detectors due to issues involving likelihood misestimation, entropy in the generative process, and typicality. We speculate that generative OOD detectors also failed because their models focused on the pixels rather than the semantic content of the data, leading to failures in near-OOD cases where the pixels may be similar but the information content is significantly different. We hypothesize that estimating typical sets using self-supervised learners leads to better OOD detectors. We introduce a novel approach that leverages representation learning, and informative summary statistics based on manifold estimation, to address all of the aforementioned issues. Our method outperforms other unsupervised approaches and achieves state-of-the art performance on well-established challenging benchmarks, and new synthetic data detection tasks.'}",https://openreview.net{'value': '/pdf/e53bb5aaad5e1ef96df9566a5271bdd33515054c.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=7WaRh4gCXp,{'value': 'NextBestPath: Efficient 3D Mapping of Unseen Environments'},Shiyao Li; Antoine Guedon; Clémentin Boittiaux; Shizhe Chen; Vincent Lepetit,~Shiyao_Li3; ~Antoine_Guedon1; ~Clémentin_Boittiaux1; ~Shizhe_Chen1; ~Vincent_Lepetit1,"{'value': ['3D reconstruction', 'active mapping']}","{'value': ""This work addresses the problem of active 3D mapping, where an agent must find an efficient trajectory to exhaustively reconstruct a new scene.\nPrevious approaches mainly predict the next best view near the agent's location, which is prone to getting stuck in local areas. Additionally, existing indoor datasets are insufficient due to limited geometric complexity and inaccurate ground truth meshes.\nTo overcome these limitations, we introduce a novel dataset AiMDoom with a map generator for the Doom video game, enabling to better benchmark active 3D mapping in diverse indoor environments.\nMoreover, we propose a new method we call next-best-path (NBP), which predicts long-term goals rather than focusing solely on short-sighted views.\nThe model jointly predicts accumulated surface coverage gains for long-term goals and obstacle maps, allowing it to efficiently plan optimal paths with a unified model.\nBy leveraging online data collection, data augmentation and curriculum learning, NBP significantly outperforms state-of-the-art methods on both the existing MP3D dataset and our AiMDoom dataset, achieving more efficient mapping in indoor environments of varying complexity.""}",https://openreview.net{'value': '/pdf/78222d5232d3ae749251ee8e30be976107357558.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=7Qa2SpjxIS,{'value': 'AI Sandbagging: Language Models can Strategically Underperform on Evaluations'},Teun van der Weij; Felix Hofstätter; Oliver Jaffe; Samuel F. Brown; Francis Rhys Ward,~Teun_van_der_Weij2; ~Felix_Hofstätter1; ~Oliver_Jaffe2; ~Samuel_F._Brown1; ~Francis_Rhys_Ward1,"{'value': ['Alignment', 'AI safety', 'sandbagging', 'AI evaluations', 'AI governance', 'NLP', 'LLM']}","{'value': ""Trustworthy capability evaluations are crucial for ensuring the safety of AI systems, and are becoming a key component of AI regulation. However, the developers of an AI system, or the AI system itself, may have incentives for evaluations to understate the AI's actual capability. These conflicting interests lead to the problem of *sandbagging* – which we define as *strategic underperformance on an evaluation*. In this paper we assess sandbagging capabilities in contemporary language models (LMs). We prompt frontier LMs, like GPT-4 and Claude 3 Opus, to selectively underperform on dangerous capability evaluations, while maintaining performance on general (harmless) capability evaluations. Moreover, we find that models can be fine-tuned, on a synthetic dataset, to hide specific capabilities unless given a password. This behaviour generalizes to high-quality, held-out benchmarks such as WMDP. In addition, we show that both frontier and smaller models can be prompted or password-locked to target specific scores on a capability evaluation. We have mediocre success in password-locking a model to mimic the answers a weaker model would give. Overall, our results suggest that capability evaluations are vulnerable to sandbagging. This vulnerability decreases the trustworthiness of evaluations, and thereby undermines important safety decisions regarding the development and deployment of advanced AI systems.\n\nSee our code at https://github.com/TeunvdWeij/sandbagging""}",https://openreview.net{'value': '/pdf/bad3f0324c39df3dc7575119c3a6976cf3209530.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=7NL74jUiMg,{'value': 'Alchemy: Amplifying Theorem-Proving Capability Through Symbolic Mutation'},Shaonan Wu; Shuai Lu; Yeyun Gong; Nan Duan; Ping Wei,~Shaonan_Wu1; ~Shuai_Lu1; ~Yeyun_Gong2; ~Nan_Duan1; ~Ping_Wei1,"{'value': ['Synthetic Data', 'Neural Theorem Proving', 'Formal Reasoning', 'Lean Theorem Prover']}","{'value': 'Formal proofs are challenging to write even for experienced experts.  Recent progress in Neural Theorem Proving (NTP) shows promise in expediting this process. However, the formal corpora available on the Internet are limited compared to the general text, posing a significant data scarcity challenge for NTP.   To address this issue, this work proposes Alchemy, a general framework for data synthesis that constructs formal theorems through symbolic mutation. Specifically, for each candidate theorem in Mathlib, we identify all invocable theorems that can be used to rewrite or apply to it. Subsequently, we mutate the candidate theorem by replacing the corresponding term in the statement with its equivalent form or antecedent. As a result, our method increases the number of theorems in Mathlib by an order of magnitude, from 110k to 6M. Furthermore, we perform continual pretraining and supervised finetuning on this augmented corpus for large language models. Experimental results demonstrate the effectiveness of our approach, achieving a 4.70% absolute performance improvement on Leandojo benchmark. Additionally, our approach achieves a 2.47% absolute performance gain on the out-of-distribution miniF2F benchmark based on the synthetic data. To provide further insights, we conduct a comprehensive analysis of synthetic data composition and the training paradigm, offering valuable guidance for developing a strong theorem prover.'}",https://openreview.net{'value': '/pdf/d749e5c013878aa7159d41d8f01842f275962ed1.pdf'},{'abstract_filter': 'Data Synthesis'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=71pur4y8gs,{'value': 'TabWak: A Watermark for Tabular Diffusion Models'},Chaoyi Zhu; Jiayi Tang; Jeroen M. Galjaard; Pin-Yu Chen; Robert Birke; Cornelis Bos; Lydia Y. Chen,~Chaoyi_Zhu2; ~Jiayi_Tang3; ~Jeroen_M._Galjaard1; ~Pin-Yu_Chen1; ~Robert_Birke1; ~Cornelis_Bos1; ~Lydia_Y._Chen1,"{'value': ['Watermarking', 'Tabular data', 'Generative models', 'Tabular diffusion models']}","{'value': 'Synthetic data offers alternatives for data augmentation and sharing. Till date, it remains unknown how to use watermarking techniques to trace and audit synthetic tables generated by tabular diffusion models to mitigate potential misuses. In this paper, we design TabWak, the first watermarking method to embed invisible signatures that control the sampling of Gaussian latent codes used to synthesize table rows via the diffusion backbone. TabWak has two key features. Different from existing image watermarking techniques, TabWak uses self-cloning and shuffling to embed the secret key in positional information of random seeds that control the Gaussian latents, allowing to use different seeds at each row for high inter-row diversity and enabling row-wise detectability. To further boost the robustness of watermark detection against post-editing attacks, TabWak uses a valid-bit mechanism that focuses on the tail of the latent code distribution for superior noise resilience. We provide theoretical guarantees on the row diversity and effectiveness of detectability. We evaluate TabWak on five datasets against baselines to show that the quality of watermarked tables remains nearly indistinguishable from non-watermarked tables while achieving high detectability in the presence of strong post-editing attacks, with a 100% true positive rate at a 0.1% false positive rate on synthetic tables with fewer than 300 rows. Our code is available at the following anonymized repository https://github.com/chaoyitud/TabWak.'}",https://openreview.net{'value': '/pdf/3a1e9d41d3b98fda3570b361a016542525a671ed.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=6z4YKr0GK6,{'value': 'ScienceAgentBench: Toward Rigorous Assessment of Language Agents for Data-Driven Scientific Discovery'},Ziru Chen; Shijie Chen; Yuting Ning; Qianheng Zhang; Boshi Wang; Botao Yu; Yifei Li; Zeyi Liao; Chen Wei; Zitong Lu; Vishal Dey; Mingyi Xue; Frazier N. Baker; Benjamin Burns; Daniel Adu-Ampratwum; Xuhui Huang; Xia Ning; Song Gao; Yu Su; Huan Sun,~Ziru_Chen1; ~Shijie_Chen1; ~Yuting_Ning1; ~Qianheng_Zhang1; ~Boshi_Wang2; ~Botao_Yu1; ~Yifei_Li5; ~Zeyi_Liao1; ~Chen_Wei14; ~Zitong_Lu2; ~Vishal_Dey1; ~Mingyi_Xue1; ~Frazier_N._Baker1; ~Benjamin_Burns2; ~Daniel_Adu-Ampratwum1; ~Xuhui_Huang2; ~Xia_Ning1; ~Song_Gao3; ~Yu_Su2; ~Huan_Sun1,"{'value': ['Benchmark', 'Evaluation', 'Large Language Model', 'Language Agent', 'AI for Science', 'Code Generation', 'Task Automation']}","{'value': 'The advancements of language language models (LLMs) have piqued growing interest in developing LLM-based language agents to automate scientific discovery end-to-end, which has sparked both excitement and skepticism about the true capabilities of such agents. In this work, we argue that for an agent to fully automate scientific discovery, it must be able to complete all essential tasks in the workflow. Thus, we call for rigorous assessment of agents on individual tasks in a scientific workflow before making bold claims on end-to-end automation. To this end, we present ScienceAgentBench, a new benchmark for evaluating language agents for data-driven scientific discovery. To ensure the scientific authenticity and real-world relevance of our benchmark, we extract 102 tasks from 44 peer-reviewed publications in four disciplines and engage nine subject matter experts to validate them. We unify the target output for every task to a self-contained Python program file and employ an array of evaluation metrics to examine the generated programs, execution results, and costs. Each task goes through multiple rounds of manual validation by annotators and subject matter experts to ensure its annotation quality and scientific plausibility. We also propose two effective strategies to mitigate data contamination concerns. Using our benchmark, we evaluate five open-weight and proprietary LLMs, each with three frameworks: direct prompting, OpenHands, and self-debug. Given three attempts for each task, the best-performing agent can only solve 32.4% of the tasks independently and 34.3% with expert-provided knowledge. These results underscore the limited capacities of current language agents in generating code for data-driven discovery, let alone end-to-end automation for scientific research.'}",https://openreview.net{'value': '/pdf/01bb45041a6c8c75021cdf0e1835d645398f660d.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=6s5uXNWGIh,{'value': 'MLE-bench: Evaluating Machine Learning Agents on Machine Learning Engineering'},Jun Shern Chan; Neil Chowdhury; Oliver Jaffe; James Aung; Dane Sherburn; Evan Mays; Giulio Starace; Kevin Liu; Leon Maksin; Tejal Patwardhan; Aleksander Madry; Lilian Weng,~Jun_Shern_Chan1; ~Neil_Chowdhury1; ~Oliver_Jaffe2; ~James_Aung1; ~Dane_Sherburn1; ~Evan_Mays1; ~Giulio_Starace1; ~Kevin_Liu2; ~Leon_Maksin1; ~Tejal_Patwardhan1; ~Aleksander_Madry1; ~Lilian_Weng1,"{'value': ['benchmark', 'evals', 'evaluations', 'dataset', 'tasks', 'data science', 'engineering', 'agents', 'language agents', 'scaffold', 'coding', 'swe', 'mle']}","{'value': ""We introduce MLE-bench, a benchmark for measuring how well AI agents perform at machine learning engineering. To this end, we curate 75 ML engineering-related competitions from Kaggle, creating a diverse set of challenging tasks that test real-world ML engineering skills such as training models, preparing datasets, and running experiments. We establish human baselines for each competition using Kaggle's publicly available leaderboards. We use open-source agent scaffolds to evaluate several frontier language models on our benchmark, finding that the best-performing setup — OpenAI's o1-preview with AIDE scaffolding — achieves at least the level of a Kaggle bronze medal in 16.9% of competitions. In addition to our main results, we investigate various forms of resource-scaling for AI agents and the impact of contamination from pre-training. We open-source our benchmark code https://github.com/openai/mle-bench to facilitate future research in understanding the ML engineering capabilities of AI agents.""}",https://openreview.net{'value': '/pdf/5ae71a36cd002781ebfc8b012440d031b9df8225.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=6kPBThI6ZJ,{'value': 'Hummingbird: High Fidelity Image Generation via Multimodal Context Alignment'},Minh-Quan Le; Gaurav Mittal; Tianjian Meng; A S M Iftekhar; Vishwas Suryanarayanan; Barun Patra; Dimitris Samaras; Mei Chen,~Minh-Quan_Le1; ~Gaurav_Mittal2; ~Tianjian_Meng2; ~A_S_M_Iftekhar1; ~Vishwas_Suryanarayanan1; ~Barun_Patra1; ~Dimitris_Samaras3; ~Mei_Chen2,"{'value': ['multimodal', 'diffusion model', 'image generation', 'lora', 'mllm', 'stable diffusion', 'mme', 'hoi', 'tta']}","{'value': ""While diffusion models are powerful in generating high-quality, diverse synthetic data for object-centric tasks, existing methods struggle with scene-aware tasks such as Visual Question Answering (VQA) and Human-Object Interaction (HOI) Reasoning, where it is critical to preserve scene attributes in generated images consistent with a multimodal context, i.e. a reference image with accompanying text guidance query. To address this, we introduce **Hummingbird**, the first diffusion-based image generator which, given a multimodal context, generates highly diverse images w.r.t. the reference image while ensuring high fidelity by accurately preserving scene attributes, such as object interactions and spatial relationships from the text guidance. Hummingbird employs a novel Multimodal Context Evaluator that simultaneously optimizes our formulated Global Semantic and Fine-grained Consistency Rewards to ensure generated images preserve the scene attributes of reference images in relation to the text guidance while maintaining diversity. As the first model to address the task of maintaining both diversity and fidelity given a multimodal context, we introduce a new benchmark formulation incorporating MME Perception and Bongard HOI datasets. Benchmark experiments show Hummingbird outperforms all existing methods by achieving superior fidelity while maintaining diversity, validating Hummingbird's potential as a robust multimodal context-aligned image generator in complex visual tasks. Project page: https://roar-ai.github.io/hummingbird""}",https://openreview.net{'value': '/pdf/f0b4659c7961c0a5a83513d1879d8a4608fbecd8.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=6cQ6cBqzV3,{'value': 'LoRA-X: Bridging Foundation Models with Training-Free Cross-Model Adaptation'},Farzad Farhadzadeh; Debasmit Das; Shubhankar Borse; Fatih Porikli,~Farzad_Farhadzadeh1; ~Debasmit_Das2; ~Shubhankar_Borse1; ~Fatih_Porikli2,"{'value': ['parameter efficient fine tuning', 'Low Rank Adaptation', 'knowledge distillation']}","{'value': 'The rising popularity of large foundation models has led to a heightened demand for parameter-efficient fine-tuning methods, such as Low-Rank Adaptation (LoRA), which offer performance comparable to full model fine-tuning while requiring only a few additional parameters tailored to the specific base model. When such base models are deprecated and replaced, all associated LoRA modules must be retrained, requiring access to either the original training data or a substantial amount of synthetic data that mirrors the original distribution. However, the original data is often inaccessible due to privacy or licensing issues, and generating synthetic data may be impractical and insufficiently representative. These factors complicate the fine-tuning process considerably. To address this challenge, we introduce a new adapter, Cross-Model Low-Rank Adaptation (LoRA-X), which enables the training-free transfer of LoRA parameters across source and target models, eliminating the need for original or synthetic training data. Our approach imposes the adapter to operate within the subspace of the source base model. This constraint is necessary because our prior knowledge of the target model is limited to its weights, and the criteria for ensuring the adapter’s transferability are restricted to the target base model’s weights and subspace.  To facilitate the transfer of LoRA parameters of the source model to a target model, we employ the adapter only in the layers of the target model that exhibit an acceptable level of subspace similarity. Our extensive experiments demonstrate the effectiveness of LoRA-X for text-to-image generation, including Stable Diffusion v1.5 and Stable Diffusion XL.'}",https://openreview.net{'value': '/pdf/1b058da2354de1538bcb70be33cafd64cc55ca62.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=6bKEWevgSd,{'value': 'ManiSkill-HAB: A Benchmark for Low-Level Manipulation in Home Rearrangement Tasks'},Arth Shukla; Stone Tao; Hao Su,~Arth_Shukla1; ~Stone_Tao1; ~Hao_Su1,"{'value': ['benchmark', 'dataset', 'simulation', 'reinforcement learning', 'imitation learning', 'robotics']}","{'value': 'High-quality benchmarks are the foundation for embodied AI research, enabling significant advancements in long-horizon navigation, manipulation and rearrangement tasks. However, as frontier tasks in robotics get more advanced, they require faster simulation speed, more intricate test environments, and larger demonstration datasets. To this end, we present MS-HAB, a holistic benchmark for low-level manipulation and in-home object rearrangement. First, we provide a GPU-accelerated implementation of the Home Assistant Benchmark (HAB). We support realistic low-level control and achieve over 3x the speed of prior magical grasp implementations at a fraction of the GPU memory usage. Second, we train extensive reinforcement learning (RL) and imitation learning (IL) baselines for future work to compare against. Finally, we develop a rule-based trajectory filtering system to sample specific demonstrations from our RL policies which match predefined criteria for robot behavior and safety. Combining demonstration filtering with our fast environments enables efficient, controlled data generation at scale.'}",https://openreview.net{'value': '/pdf/bcafead0bf180b4a8da019c355309931525f5b2a.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=6bDJ3CIm5w,{'value': 'Interference Among First-Price Pacing Equilibria: A Bias and Variance Analysis'},Luofeng Liao; Christian Kroer; Sergei Leonenkov; Okke Schrijvers; Liang Shi; Nicolas Stier Moses; Congshan Zhang,~Luofeng_Liao1; ~Christian_Kroer1; ~Sergei_Leonenkov1; ~Okke_Schrijvers1; ~Liang_Shi5; ~Nicolas_Stier_Moses1; ~Congshan_Zhang1,"{'value': ['First-price auctions', 'Pacing equilibrium', 'interference bias']}","{'value': 'A/B testing is widely used in the internet industry. For online marketplaces (such as advertising markets), standard approaches to A/B testing may lead to biased results when buyers have budget constraints, as budget consumption in one arm of the experiment impacts performance of the other arm. \nThis is often addressed using a budget-split design. Yet such splitting may degrade statistical performance as budgets become too small in each arm.\nWe propose a parallel budget-controlled A/B testing design where we use market segmentation to identify submarkets in the larger market, and we run parallel budget-split experiments in each submarket.\nWe demonstrate the effectiveness of this approach on real experiments on advertising markets at Meta.\nThen, we formally study interference that derives from such experimental designs, using the first-price pacing equilibrium framework as our model of market equilibration.\nWe propose a debiased surrogate that eliminates the first-order bias of FPPE, and derive a plug-in estimator for the surrogate and establish its asymptotic normality. We then provide an estimation procedure for submarket parallel budget-controlled A/B tests. Finally, we present numerical examples on semi-synthetic data, confirming that the debiasing technique achieves the desired coverage properties.'}",https://openreview.net{'value': '/pdf/1b705414bc5571ab69fa32c41fd85bf93e7fb289.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=6aHUmotXaw,{'value': 'Mutual Reasoning Makes Smaller LLMs Stronger Problem-Solver'},Zhenting Qi; Mingyuan MA; Jiahang Xu; Li Lyna Zhang; Fan Yang; Mao Yang,~Zhenting_Qi1; ~Mingyuan_MA2; ~Jiahang_Xu2; ~Li_Lyna_Zhang1; ~Fan_Yang28; ~Mao_Yang1,"{'value': ['LLM', 'Reasoning']}","{'value': 'This paper introduces rStar, a self-play mutual reasoning approach that significantly improves reasoning capabilities of small language models (SLMs) without fine-tuning or superior models. rStar decouples reasoning into a self-play mutual generation-discrimination process. First, a target SLM augments the Monte Carlo Tree Search (MCTS) with a rich set of human-like reasoning actions to construct higher quality reasoning trajectories. Next, another SLM, with capabilities similar to the target SLM, acts as a discriminator to verify each trajectory generated by the target SLM. The mutually agreed reasoning trajectories are considered mutual consistent, thus are more likely to be correct. Extensive experiments across five SLMs demonstrate rStar can effectively solve diverse reasoning problems, including GSM8K, GSM-Hard, MATH, SVAMP, and StrategyQA. Remarkably, rStar boosts GSM8K accuracy from 12.51\\% to 63.91\\% for LLaMA2-7B, from 36.46\\% to 81.88\\% for Mistral-7B, from 74.53\\% to 91.13\\% for LLaMA3-8B-Instruct. Code is available at https://github.com/zhentingqi/rStar.'}",https://openreview.net{'value': '/pdf/2073e21d8e0f472df85c80763435ad44336c8864.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=6VgwE2tCRm,{'value': 'POGEMA: A Benchmark Platform for Cooperative Multi-Agent Pathfinding'},Alexey Skrynnik; Anton Andreychuk; Anatolii Borzilov; Alexander Chernyavskiy; Konstantin Yakovlev; Aleksandr Panov,~Alexey_Skrynnik1; ~Anton_Andreychuk1; ~Anatolii_Borzilov1; ~Alexander_Chernyavskiy2; ~Konstantin_Yakovlev1; ~Aleksandr_Panov1,"{'value': ['MAPF', 'MARL', 'RL', 'Heuristic search']}","{'value': 'Multi-agent reinforcement learning (MARL) has recently excelled in solving challenging cooperative and competitive multi-agent problems in various environments, typically involving a small number of agents and full observability. Moreover, a range of crucial robotics-related tasks, such as multi-robot pathfinding, which have traditionally been approached with classical non-learnable methods (e.g., heuristic search), are now being suggested for solution using learning-based or hybrid methods. However, in this domain, it remains difficult, if not impossible, to conduct a fair comparison between classical, learning-based, and hybrid approaches due to the lack of a unified framework that supports both learning and evaluation. To address this, we introduce POGEMA, a comprehensive set of tools that includes a fast environment for learning, a problem instance generator, a collection of predefined problem instances, a visualization toolkit, and a benchmarking tool for automated evaluation. We also introduce and define an evaluation protocol that specifies a range of domain-related metrics, computed based on primary evaluation indicators (such as success rate and path length), enabling a fair multi-fold comparison. The results of this comparison, which involves a variety of state-of-the-art MARL, search-based, and hybrid methods, are presented.'}",https://openreview.net{'value': '/pdf/19e55d87f236d0ca49d30994ced3703e8bd5a14e.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=6Pz7afmsOp,{'value': 'Identification of Intermittent Temporal Latent Process'},Yuke Li; Yujia Zheng; Guangyi Chen; Kun Zhang; Heng Huang,~Yuke_Li1; ~Yujia_Zheng1; ~Guangyi_Chen1; ~Kun_Zhang1; ~Heng_Huang1,{'value': ['unsupervised representation learning']},"{'value': 'Identifying time-delayed latent causal process is crucial for understanding temporal dynamics and enabling downstream reasoning. While recent methods have made progress in identifying latent time-delayed causal processes, they cannot address the dynamics in which the influence of some latent factors on both the subsequent latent states and the observed data can become inactive or irrelevant at different time steps. Therefore, we introduce intermittent temporal latent processes, where: (1) any subset of latent factors may be missing during nonlinear data generation at any time step, and (2) the active latent factors at each step are unknown. This framework encompasses both nonstationary and stationary transitions, accommodating changing or consistent active factors over time. \nOur work shows that under certain assumptions, the latent causal variables are block-wise identifiable. With further conditional independence assumption, each latent variable can even be recovered up to component-wise transformations. \nUsing this identification theory, we propose an unsupervised approach, InterLatent, to reliably uncover the representations of the intermittent temporal latent process. The experimental findings on both synthetic and real-world datasets verify our theoretical claims.'}",https://openreview.net{'value': '/pdf/14969dee187ff4b541d73d49174bd3f93eca61e8.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=6NNA0MxhCH,"{'value': 'Answer, Assemble, Ace: Understanding How LMs Answer Multiple Choice Questions'}",Sarah Wiegreffe; Oyvind Tafjord; Yonatan Belinkov; Hannaneh Hajishirzi; Ashish Sabharwal,~Sarah_Wiegreffe1; ~Oyvind_Tafjord2; ~Yonatan_Belinkov1; ~Hannaneh_Hajishirzi1; ~Ashish_Sabharwal1,{'value': ['interpretability; multiple-choice question answering']},"{'value': 'Multiple-choice question answering (MCQA) is a key competence of performant transformer language models that is tested by mainstream benchmarks. However, recent evidence shows that models can have quite a range of performance, particularly when the task format is diversified slightly (such as by shuffling answer choice order). In this work we ask: how do successful models perform formatted MCQA? We employ vocabulary projection and activation patching methods to localize key hidden states that encode relevant information for predicting the correct answer. We find that prediction of a specific answer symbol is causally attributed to a few middle layers, and specifically their multi-head self-attention mechanisms. We show that subsequent layers increase the probability of the predicted answer symbol in vocabulary space, and that this probability increase is associated with a sparse set of attention heads with unique roles. We additionally uncover differences in how different models adjust to alternative symbols. Finally, we demonstrate that a synthetic task can disentangle sources of model error to pinpoint when a model has learned formatted MCQA, and show that logit differences between answer choice tokens continue to grow over the course of training.'}",https://openreview.net{'value': '/pdf/9118ef37ef938816242cacc28fa3a17c7c4a5fe9.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=6H4jRWKFc3,{'value': 'MotherNet: Fast Training and Inference via Hyper-Network Transformers'},Andreas C Mueller; Carlo A Curino; Raghu Ramakrishnan,~Andreas_C_Mueller1; ~Carlo_A_Curino1; ~Raghu_Ramakrishnan1,"{'value': ['hypernetwork', 'tabular data', 'meta-learning', 'foundational models']}","{'value': ""Foundation models are transforming machine learning across many modalities, with in-context learning replacing classical model training. Recent work on tabular data hints at a similar opportunity to build foundation models for classification for numerical data. However, existing meta-learning approaches can not compete with tree-based methods in terms of inference time. In this paper, we propose MotherNet, a hypernetwork architecture trained on synthetic classification tasks that, once prompted with a never-seen-before training set generates the weights of a trained ``child'' neural-network by in-context learning using a single forward pass. In contrast to most existing hypernetworks that are usually trained for relatively constrained multi-task settings, MotherNet can create models for multiclass classification on arbitrary tabular datasets without any dataset specific gradient descent.\nThe child network generated by MotherNet outperforms neural networks trained using gradient descent on small datasets, and is competitive with predictions by TabPFN and standard ML methods like Gradient Boosting. Unlike a direct application of TabPFN, MotherNet generated networks are highly efficient at inference time.""}",https://openreview.net{'value': '/pdf/a6c1e312db5e80b59af006404d6ea569ba92d6c0.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=6F6qwdycgJ,{'value': 'Towards Hierarchical Rectified Flow'},Yichi Zhang; Yici Yan; Alex Schwing; Zhizhen Zhao,~Yichi_Zhang22; ~Yici_Yan1; ~Alex_Schwing1; ~Zhizhen_Zhao1,"{'value': ['Generative Model', 'Flow Matching', 'Rectified Flow']}","{'value': 'We formulate a hierarchical rectified flow to model data distributions. It hierarchically couples multiple ordinary differential equations (ODEs) and defines a time-differentiable stochastic process that generates a data distribution from a known source distribution. Each ODE resembles the ODE that is solved in a classic rectified flow, but differs in its domain, i.e., location, velocity, acceleration, etc. Unlike the classic rectified flow formulation, which formulates a single ODE in the location domain and only captures the expected velocity field (sufficient to capture a multi-modal data distribution), the hierarchical rectified flow formulation models the multi-modal random velocity field, acceleration field, etc., in their entirety. This more faithful modeling of the random velocity field enables integration paths to intersect when the underlying ODE is solved during data generation. Intersecting paths in turn lead to integration trajectories that are more straight than those obtained in the classic rectified flow formulation, where integration paths cannot intersect. This leads to modeling of data distributions with fewer neural function evaluations. We empirically verify this on synthetic 1D and 2D data as well as MNIST, CIFAR-10, and ImageNet-32 data. Our code is available at: https://riccizz.github.io/HRF/.'}",https://openreview.net{'value': '/pdf/07c0a065c16e1eb52375e28265afe1d887106364.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=6Ai8SuDsh3,{'value': 'Diverse Policies Recovering via Pointwise Mutual Information Weighted Imitation Learning'},Hanlin Yang; Jian Yao; Weiming Liu; Qing Wang; Hanmin Qin; Kong hansheng; Kirk Tang; Jiechao Xiong; Chao Yu; Kai Li; Junliang Xing; Hongwu Chen; Juchao Zhuo; QIANG FU; Yang Wei; Haobo Fu,~Hanlin_Yang1; ~Jian_Yao6; ~Weiming_Liu3; ~Qing_Wang1; ~Hanmin_Qin1; ~Kong_hansheng1; ~Kirk_Tang1; ~Jiechao_Xiong1; ~Chao_Yu2; ~Kai_Li2; ~Junliang_Xing1; ~Hongwu_Chen1; ~Juchao_Zhuo1; ~QIANG_FU8; ~Yang_Wei2; ~Haobo_Fu2,"{'value': ['Imitation Learning', 'Policy Diversity', 'Offline Learning']}","{'value': ""Recovering a spectrum of diverse policies from a set of expert trajectories is an important research topic in imitation learning. After determining a latent style for a trajectory, previous diverse polices recovering methods usually employ a vanilla behavioral cloning learning objective conditioned on the latent style, treating each state-action pair in the trajectory with equal importance. Based on an observation that in many scenarios, behavioral styles are often highly relevant with only a subset of state-action pairs, this paper presents a new principled method in diverse polices recovering. In particular, after inferring or assigning a latent style for a trajectory, we enhance the vanilla behavioral cloning by incorporating a weighting mechanism based on pointwise mutual information.\nThis additional weighting reflects the significance of each state-action pair's contribution to learning the style, thus allowing our method to focus on state-action pairs most representative of that style.\nWe provide theoretical justifications for our new objective, and extensive empirical evaluations confirm the effectiveness of our method in recovering diverse polices from expert data.""}",https://openreview.net{'value': '/pdf/5049eb9f322c8b47b4114bdf870c0ace98d72e70.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=66NzcRQuOq,{'value': 'Pyramidal Flow Matching for Efficient Video Generative Modeling'},Yang Jin; Zhicheng Sun; Ningyuan Li; Kun Xu; Kun Xu; Hao Jiang; Nan Zhuang; Quzhe Huang; Yang Song; Yadong MU; Zhouchen Lin,~Yang_Jin1; ~Zhicheng_Sun1; ~Ningyuan_Li2; ~Kun_Xu4; ~Kun_Xu6; ~Hao_Jiang10; ~Nan_Zhuang1; ~Quzhe_Huang1; ~Yang_Song6; ~Yadong_MU1; ~Zhouchen_Lin1,"{'value': ['Generative Model', 'Flow Matching', 'Video Generation']}","{'value': 'Video generation requires modeling a vast spatiotemporal space, which demands significant computational resources and data usage. To reduce the complexity, the prevailing approaches employ a cascaded architecture to avoid direct training with full resolution latent. Despite reducing computational demands, the separate optimization of each sub-stage hinders knowledge sharing and sacrifices flexibility. This work introduces a unified pyramidal flow matching algorithm. It reinterprets the original denoising trajectory as a series of pyramid stages, where only the final stage operates at the full resolution, thereby enabling more efficient video generative modeling. Through our sophisticated design, the flows of different pyramid stages can be interlinked to maintain continuity. Moreover, we craft autoregressive video generation with a temporal pyramid to compress the full-resolution history. The entire framework can be optimized in an end-to-end manner and with a single unified Diffusion Transformer (DiT). Extensive experiments demonstrate that our method supports generating high-quality 5-second (up to 10-second) videos at 768p resolution and 24 FPS within 20.7k A100 GPU training hours. All code and models are open-sourced at https://pyramid-flow.github.io.'}",https://openreview.net{'value': '/pdf/df5f77e25dd81f5e80dae2a030af4c53d979861b.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=62Ff8LDAJZ,{'value': 'Not-So-Optimal Transport Flows for 3D Point Cloud Generation'},Ka-Hei Hui; Chao Liu; Xiaohui Zeng; Chi-Wing Fu; Arash Vahdat,~Ka-Hei_Hui1; ~Chao_Liu11; ~Xiaohui_Zeng2; ~Chi-Wing_Fu2; ~Arash_Vahdat3,"{'value': ['Generative models', '3D point cloud generation', 'flow matching', 'optimal transport flows']}","{'value': 'Learning generative models of 3D point clouds is one of the fundamental problems in 3D generative learning. One of the key properties of point clouds is their permutation invariance, i.e., changing the order of points in a point cloud does not change the shape they represent. In this paper, we analyze the recently proposed equivariant OT flows that learn permutation invariant generative models for point-based molecular data and we show that these models scale poorly on large point clouds. Also, we observe learning (equivariant) OT flows is generally challenging since straightening flow trajectories makes the learned flow model complex at the beginning of the trajectory. To remedy these, we propose not-so-optimal transport flow models that obtain an approximate OT by an offline OT precomputation, enabling an efficient construction of OT pairs for training. During training, we can additionally construct a hybrid coupling by combining our approximate OT and independent coupling to make the target flow models easier to learn. In an extensive empirical study, we show that our proposed model outperforms prior diffusion- and flow -based approaches on a wide range of unconditional generation and shape completion on the ShapeNet benchmark.'}",https://openreview.net{'value': '/pdf/1c91411de70802e55df50fee5f0d156a59521770.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=5z9GjHgerY,{'value': 'DPLM-2: A Multimodal Diffusion Protein Language Model'},Xinyou Wang; Zaixiang Zheng; Fei YE; Dongyu Xue; Shujian Huang; Quanquan Gu,~Xinyou_Wang1; ~Zaixiang_Zheng2; ~Fei_YE4; ~Dongyu_Xue1; ~Shujian_Huang1; ~Quanquan_Gu1,"{'value': ['protein foundation model', 'diffusion language model', 'multimodal language model']}","{'value': 'Proteins are essential macromolecules defined by their amino acid sequences, which determine their three-dimensional structures and, consequently, their functions in all living organisms. Therefore, generative protein modeling necessitates a multimodal approach to simultaneously model, understand, and generate both sequences and structures. However, existing methods typically use separate models for each modality, limiting their ability to capture the intricate relationships between sequence and structure. This results in suboptimal performance in tasks that requires joint understanding and generation of both modalities.\nIn this paper, we introduce DPLM-2, a multimodal protein foundation model that extends discrete diffusion protein language model (DPLM) to accommodate both sequences and structures.\nTo enable structural learning with the language model, 3D coordinates are converted to discrete tokens using a lookup-free quantization-based tokenizer.\nBy training on both experimental and high-quality synthetic structures, DPLM-2 learns the joint distribution of sequence and structure, as well as their marginals and conditionals.\nWe also implement an efficient warm-up strategy to exploit the connection between large-scale evolutionary data and structural inductive biases from pre-trained sequence-based protein language models.\nEmpirical evaluation shows that DPLM-2 can simultaneously generate highly compatible amino acid sequences and their corresponding 3D structures eliminating the need for a two-stage generation approach.\nMoreover, DPLM-2 demonstrates competitive performance in various conditional generation tasks, including folding, inverse folding, and scaffolding with multimodal motif inputs.'}",https://openreview.net{'value': '/pdf/13c6bc9b904922e7352e690eae7cad8a2d4526f7.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=5o9JJJPPm6,{'value': 'ComaDICE: Offline Cooperative Multi-Agent Reinforcement Learning with Stationary Distribution Shift Regularization'},The Viet Bui; Thanh Hong Nguyen; Tien Anh Mai,~The_Viet_Bui1; ~Thanh_Hong_Nguyen1; ~Tien_Anh_Mai1,"{'value': ['Offline Reinforcement Learning', 'Multi-Agent Reinforcement Learning', 'Stationary Distribution Correction Estimation']}","{'value': ""Offline reinforcement learning (RL) has garnered significant attention for its ability to learn effective policies from pre-collected datasets without the need for further environmental interactions. While promising results have been demonstrated in single-agent settings, offline multi-agent reinforcement learning (MARL) presents additional challenges due to the large joint state-action space and the complexity of multi-agent behaviors. A key issue in offline RL is the distributional shift, which arises when the target policy being optimized deviates from the behavior policy that generated the data. This problem is exacerbated in MARL due to the interdependence between agents' local policies and the expansive joint state-action space. Prior approaches have primarily addressed this challenge by incorporating regularization in the space of either Q-functions or policies. In this work, we propose a novel type of regularizer in the space of stationary distributions to address the distributional shift more effectively. Our algorithm, ComaDICE, provides a principled framework for offline cooperative MARL to correct the stationary distribution of the global policy, which is then leveraged to derive local policies for individual agents. Through extensive experiments on the offline multi-agent MuJoCo and StarCraft II benchmarks, we demonstrate that ComaDICE achieves superior performance compared to state-of-the-art offline MARL methods across nearly all tasks.""}",https://openreview.net{'value': '/pdf/47b6e4f77893ddc057541ed679a8725a2d346ae7.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=5Y9NT6lW21,{'value': 'Adversarial Policy Optimization for Offline Preference-based Reinforcement Learning'},Hyungkyu Kang; Min-hwan Oh,~Hyungkyu_Kang1; ~Min-hwan_Oh1,"{'value': ['Preference-based reinforcement learning', 'Reinforcement learning with human feedback', 'Offline reinforcement learning']}","{'value': 'In this paper, we study offline preference-based reinforcement learning (PbRL), where learning is based on pre-collected preference feedback over pairs of trajectories. While offline PbRL has demonstrated remarkable empirical success, existing theoretical approaches face challenges in ensuring conservatism under uncertainty, requiring computationally intractable confidence set constructions. We address this limitation by proposing Adversarial Preference-based Policy Optimization (APPO), a computationally efficient algorithm for offline PbRL that guarantees sample complexity bounds without relying on explicit confidence sets. By framing PbRL as a two-player game between a policy and a model, our approach enforces conservatism in a tractable manner. Using standard assumptions on function approximation and bounded trajectory concentrability, we derive a sample complexity bound. To our knowledge, APPO is the first offline PbRL algorithm to offer both statistical efficiency and practical applicability. Experimental results on continuous control tasks demonstrate that APPO effectively learns from complex datasets, showing comparable performance with existing state-of-the-art methods.'}",https://openreview.net{'value': '/pdf/22d871f7c409b4f1e56503890a3aa2e844587cd1.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=5U1rlpX68A,{'value': 'SD-LoRA: Scalable Decoupled Low-Rank Adaptation for Class Incremental Learning'},Yichen Wu; Hongming Piao; Long-Kai Huang; Renzhen Wang; Wanhua Li; Hanspeter Pfister; Deyu Meng; Kede Ma; Ying Wei,~Yichen_Wu2; ~Hongming_Piao1; ~Long-Kai_Huang1; ~Renzhen_Wang1; ~Wanhua_Li1; ~Hanspeter_Pfister1; ~Deyu_Meng1; ~Kede_Ma2; ~Ying_Wei1,{'value': ['Continual learning; Low-rank adaptation']},"{'value': 'Continual Learning (CL) with foundation models has recently emerged as a promising paradigm to exploit abundant knowledge acquired during pre-training for tackling sequential tasks. However, existing prompt-based and Low-Rank Adaptation-based (LoRA-based) methods often require expanding a prompt/LoRA pool or retaining samples of previous tasks, which poses significant scalability challenges as the number of tasks grows. \nTo address these limitations, we propose Scalable Decoupled LoRA (SD-LoRA) for class incremental learning, which continually separates the learning of the magnitude and direction of LoRA components without rehearsal. Our empirical and theoretical analysis reveals that SD-LoRA tends to follow a low-loss trajectory and converges to an overlapping low-loss region for all learned tasks, resulting in an excellent stability-plasticity trade-off. Building upon these insights, we introduce two variants of SD-LoRA with further improved parameter efficiency. All parameters of SD-LoRAs can be end-to-end optimized for CL objectives. Meanwhile, they support efficient inference by allowing direct evaluation with the finally trained model, obviating the need for component selection. Extensive experiments across multiple CL benchmarks and foundation models consistently validate the effectiveness of SD-LoRA. The code is available at https://github.com/WuYichen-97/SD-Lora-CL.'}",https://openreview.net{'value': '/pdf/2e29cb4bb87dd6967db1bff6fb7a3c783fe56588.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=5BRFddsAai,{'value': 'HASARD: A Benchmark for Vision-Based Safe Reinforcement Learning in Embodied Agents'},Tristan Tomilin; Meng Fang; Mykola Pechenizkiy,~Tristan_Tomilin1; ~Meng_Fang1; ~Mykola_Pechenizkiy1,"{'value': ['reinforcement learning', 'AI safety', 'safe RL', 'constrained RL', 'benchmark', 'vizdoom', '3D', 'difficulty levels']}","{'value': ""Advancing safe autonomous systems through reinforcement learning (RL) requires robust benchmarks to evaluate performance, analyze methods, and assess agent competencies. Humans primarily rely on embodied visual perception to safely navigate and interact with their surroundings, making it a valuable capability for RL agents. However, existing vision-based 3D benchmarks only consider simple navigation tasks. To address this shortcoming, we introduce **HASARD**, a suite of diverse and complex tasks to **HA**rness **SA**fe **R**L with **D**oom, requiring strategic decision-making, comprehending spatial relationships, and predicting the short-term future. HASARD features three difficulty levels and two action spaces. An empirical evaluation of popular baseline methods demonstrates the benchmark's complexity, unique challenges, and reward-cost trade-offs. Visualizing agent navigation during training with top-down heatmaps provides insight into a method's learning process. Incrementally training across difficulty levels offers an implicit learning curriculum. HASARD is the first safe RL benchmark to exclusively target egocentric vision-based learning, offering a cost-effective and insightful way to explore the potential and boundaries of current and future safe RL methods. The environments and baseline implementations are open-sourced.""}",https://openreview.net{'value': '/pdf/fde61410f00ccf22d9510dc28b79cc37337c80d3.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=55pCDKiS8B,{'value': 'Elucidating the Preconditioning in Consistency Distillation'},Kaiwen Zheng; Guande He; Jianfei Chen; Fan Bao; Jun Zhu,~Kaiwen_Zheng2; ~Guande_He1; ~Jianfei_Chen1; ~Fan_Bao1; ~Jun_Zhu2,"{'value': ['Diffusion Models', 'Distillation', 'Consistency Trajectory Models']}","{'value': ""Consistency distillation is a prevalent way for accelerating diffusion models adopted in consistency (trajectory) models, in which a student model is trained to traverse backward on the probability flow (PF) ordinary differential equation (ODE) trajectory determined by the teacher model. Preconditioning is a vital technique for stabilizing consistency distillation, by linear combining the input data and the network output with pre-defined coefficients as the consistency function. It imposes the boundary condition of consistency functions without restricting the form and expressiveness of the neural network. However, previous preconditionings are hand-crafted and may be suboptimal choices. In this work, we offer the first theoretical insights into the preconditioning in consistency distillation, by elucidating its design criteria and the connection to the teacher ODE trajectory. Based on these analyses, we further propose a principled way dubbed \\textit{Analytic-Precond} to analytically optimize the preconditioning according to the consistency gap (defined as the gap between the teacher denoiser and the optimal student denoiser) on a generalized teacher ODE. We demonstrate that Analytic-Precond can facilitate the learning of trajectory jumpers, enhance the alignment of the student trajectory with the teacher's, and achieve $2\\times$ to $3\\times$ training acceleration of consistency trajectory models in multi-step generation across various datasets.""}",https://openreview.net{'value': '/pdf/da71dc54754bc31da7c0f22c8e41868e74c7ba7d.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=4rEI2JdHH6,{'value': 'Let Me Grok for You: Accelerating Grokking via Embedding Transfer from a Weaker Model'},Zhiwei Xu; Zhiyu Ni; Yixin Wang; Wei Hu,~Zhiwei_Xu6; ~Zhiyu_Ni1; ~Yixin_Wang1; ~Wei_Hu1,"{'value': ['Grokking', 'feature learning', 'deep learning theory']}","{'value': ""''Grokking'' is a phenomenon where a neural network first memorizes training data and generalizes poorly, but then suddenly transitions to near-perfect generalization after prolonged training. While intriguing, this delayed generalization phenomenon compromises predictability and efficiency. Ideally, models should generalize directly without delay. To this end, this paper proposes GrokTransfer, a simple and principled method for accelerating grokking in training neural networks, based on the key observation that data embedding plays a\ncrucial role in determining whether generalization is delayed. GrokTransfer first trains a smaller, weaker model to reach a nontrivial (but far from optimal) test performance. Then, the learned input embedding from this weaker model is extracted and used to initialize the embedding in the target, stronger model. We rigorously prove that, on a synthetic XOR task where delayed generalization always\noccurs in normal training, GrokTransfer enables the target model to generalize directly without delay. Moreover, we demonstrate that, across empirical studies of different tasks, GrokTransfer effectively reshapes the training dynamics and eliminates delayed generalization, for both fully-connected neural networks and Transformers.""}",https://openreview.net{'value': '/pdf/d1b73c6c9e954534ce32bcbce30e358398c335e2.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=4hPwLg7zD3,{'value': 'Fourier Head: Helping Large Language Models Learn Complex Probability Distributions'},Nate Gillman; Daksh Aggarwal; Michael Freeman; Chen Sun,~Nate_Gillman1; ~Daksh_Aggarwal1; ~Michael_Freeman1; ~Chen_Sun1,"{'value': ['LLM', 'Fourier', 'smooth function', 'multi-class classification']}","{'value': ""As the quality of large language models has improved, there has been increased interest in using them to model non-linguistic tokens. For example, the Decision Transformer recasts agentic decision making as a sequence modeling problem, using a decoder-only LLM to model the distribution over the discrete action space for an Atari agent. However, when adapting LLMs to non-linguistic domains, it remains unclear if softmax over discrete bins captures the continuous structure of the tokens and the potentially complex distributions needed for high quality token generation. We introduce a neural network layer, constructed using Fourier series, which we can easily substitute for any linear layer if we want the outputs to have a more continuous structure. We perform extensive analysis on synthetic datasets, as well as on large-scale decision making and time series forecasting tasks. We also provide theoretical evidence that this layer can better learn signal from data while ignoring high-frequency noise. All of our results support the effectiveness of our proposed Fourier head in scenarios where the underlying data distribution has a natural continuous structure. For example, the Fourier head improves a Decision Transformer agent's returns across four benchmark Atari games by as much as 377\\%, and increases a state-of-the-art times series foundation model's forecasting performance by 3.5\\% across 20 benchmarks unseen during training.\nWe release our implementation at https://nategillman.com/fourier-head""}",https://openreview.net{'value': '/pdf/f9fb4a911927a4c00e96388c69bb7331bc620808.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=4anfpHj0wf,{'value': 'Unlocking Point Processes through Point Set Diffusion'},David Lüdke; Enric Rabasseda Raventós; Marcel Kollovieh; Stephan Günnemann,~David_Lüdke1; ~Enric_Rabasseda_Raventós1; ~Marcel_Kollovieh1; ~Stephan_Günnemann1,"{'value': ['Generative Model', 'Diffusion Model', 'Set Model', 'Point Sets', 'Forecasting', 'Density Estimation', 'Spatial', 'Temporal', 'Probabilistic Models']}","{'value': 'Point processes model the distribution of random point sets in mathematical spaces, such as spatial and temporal domains, with applications in fields like seismology, neuroscience, and economics.\nExisting statistical and machine learning models for point processes are predominantly constrained by their reliance on the characteristic intensity function, introducing an inherent trade-off between efficiency and flexibility.\nIn this paper, we introduce Point Set Diffusion, a diffusion-based latent variable model that can represent arbitrary point processes on general metric spaces without relying on the intensity function.\nBy directly learning to stochastically interpolate between noise and data point sets, our approach effectively captures the distribution of point processes and enables efficient, parallel sampling and flexible generation for complex conditional tasks.\nExperiments on synthetic and real-world datasets demonstrate that Point Set Diffusion achieves state-of-the-art performance in unconditional and conditional generation of spatial and spatiotemporal point processes while providing up to orders of magnitude faster sampling.'}",https://openreview.net{'value': '/pdf/f1c524c5cb32b89ddfa68b02c35e1f331639e0db.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=4YzVF9isgD,{'value': 'HyperFace: Generating Synthetic Face Recognition Datasets by Exploring Face Embedding Hypersphere'},Hatef Otroshi Shahreza; Sébastien Marcel,~Hatef_Otroshi_Shahreza1; ~Sébastien_Marcel1,"{'value': ['Face Recognition', 'Hypersphere Optimization', 'Privacy', 'Synthetic Data']}","{'value': ""Face recognition datasets are often collected by crawling Internet and without individuals' consents, raising  ethical and privacy concerns. Generating synthetic datasets for training face recognition models has emerged as a promising alternative. However, the generation of synthetic datasets remains  challenging as it entails adequate inter-class and intra-class variations. While advances in generative models have made it easier to increase intra-class variations in face datasets (such as pose, illumination, etc.), generating sufficient inter-class variation is still a difficult task. In this paper, we formulate the dataset generation as a packing problem on the embedding space (represented on a hypersphere) of a face recognition model and propose a new synthetic dataset generation approach, called HyperFace. We formalize our packing problem as an optimization problem and solve it with a gradient descent-based approach. Then, we use a conditional face generator model to synthesize face images from the optimized embeddings. We use our generated datasets to train face recognition models and evaluate the trained models on several benchmarking real datasets. Our experimental results show that models trained with HyperFace achieve state-of-the-art performance in training face recognition using synthetic datasets. Project page: https://www.idiap.ch/paper/hyperface""}",https://openreview.net{'value': '/pdf/2d7784b7b85159b61527b71a37708ef7ebfd2127.pdf'},{'title_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=4VHiptx7xe,{'value': 'STRAP: Robot Sub-Trajectory Retrieval for Augmented Policy Learning'},Marius Memmel; Jacob Berg; Bingqing Chen; Abhishek Gupta; Jonathan Francis,~Marius_Memmel1; ~Jacob_Berg1; ~Bingqing_Chen2; ~Abhishek_Gupta1; ~Jonathan_Francis1,"{'value': ['dynamic time warping', 'few-shot imitation learning', 'retrieval', 'foundation models']}","{'value': 'Robot learning is witnessing a significant increase in the size, diversity, and complexity of pre-collected datasets, mirroring trends in domains such as natural language processing and computer vision. Many robot learning methods treat such datasets as multi-task expert data and learn a multi-task, generalist policy by training broadly across them. Notably, while these generalist policies can improve the average performance across many tasks, the performance of generalist policies on any one task is often suboptimal due to negative transfer between partitions of the data, compared to task-specific specialist policies. In this work, we argue for the paradigm of training policies during deployment given the scenarios they encounter: rather than deploying pre-trained policies to unseen problems in a zero-shot manner, we non-parametrically retrieve and train models directly on relevant data at test time. Furthermore, we show that many robotics tasks share considerable amounts of low-level behaviors and that retrieval at the ""sub""-trajectory granularity enables significantly improved data utilization, generalization, and robustness in adapting policies to novel problems. In contrast, existing full-trajectory retrieval methods tend to underutilize the data and miss out on shared cross-task content. This work proposes STRAP, a technique for leveraging pre-trained vision foundation models and dynamic time warping to retrieve sub-sequences of trajectories from large training corpora in a robust fashion. STRAP outperforms both prior retrieval algorithms and multi-task learning methods in simulated and real experiments, showing the ability to scale to much larger offline datasets in the real world as well as the ability to learn robust control policies with just a handful of real-world demonstrations.'}",https://openreview.net{'value': '/pdf/b13eaaa9a22344704a1f69c9543bcd63cfec6b0e.pdf'},{'title_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=4R71pdPBZp,{'value': 'Self-Evolving Multi-Agent Collaboration Networks for Software Development'},Yue Hu; Yuzhu Cai; Yaxin Du; Xinyu Zhu; Xiangrui Liu; Zijie Yu; Yuchen Hou; Shuo Tang; Siheng Chen,~Yue_Hu1; ~Yuzhu_Cai1; ~Yaxin_Du1; ~Xinyu_Zhu5; ~Xiangrui_Liu4; ~Zijie_Yu2; ~Yuchen_Hou4; ~Shuo_Tang2; ~Siheng_Chen1,"{'value': ['Software development', 'LLM', 'Multi-agent collaboration']}","{'value': ""LLM-driven multi-agent collaboration (MAC) systems have demonstrated impressive capabilities in automatic software development at the function level. However, their heavy reliance on human design limits their adaptability to the diverse demands of real-world software development.\nTo address this limitation, we introduce EvoMAC, a novel self-evolving paradigm for MAC networks. Inspired by traditional neural network training, EvoMAC obtains text-based environmental feedback by verifying the MAC network's output against a target proxy and leverages a novel textual backpropagation to update the network.\nTo extend coding capabilities beyond function-level tasks to more challenging software-level development, we further propose RSD-Bench, a requirement-oriented software development benchmark, which features complex and diverse software requirements along with automatic evaluation of requirement correctness.\nOur experiments show that:\ni) The automatic requirement-aware evaluation in RSD-Bench closely aligns with human evaluations, validating its reliability as a software-level coding benchmark.\nii) EvoMAC outperforms previous SOTA methods on both the software-level RSD-Bench and the function-level HumanEval benchmarks, reflecting its superior coding capabilities.""}",https://openreview.net{'value': '/pdf/4d1910d5d3f3ab640054077163dcbbecb94629c4.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=4JK2XMGUc8,{'value': 'Free Hunch: Denoiser Covariance Estimation for Diffusion Models Without Extra Costs'},Severi Rissanen; Markus Heinonen; Arno Solin,~Severi_Rissanen1; ~Markus_Heinonen1; ~Arno_Solin1,"{'value': ['diffusion model', 'conditional generation', 'inverse problems', 'denoiser covariance estimation']}","{'value': ""The covariance for clean data given a noisy observation is an important quantity in many training-free guided generation methods for diffusion models. Current methods require heavy test-time computation, altering the standard diffusion training process or denoiser architecture, or making heavy approximations. We propose a new framework that sidesteps these issues by using covariance information that is available for free from training data and the curvature of the generative trajectory, which is linked to the covariance through the second-order Tweedie's formula. We integrate these sources of information using (i) a novel method to transfer covariance estimates across noise levels and (ii) low-rank updates in a given noise level. We validate the method on linear inverse problems, where it outperforms recent baselines, especially with fewer diffusion steps.""}",https://openreview.net{'value': '/pdf/a10202ed7e5ace01ddeb1a4f5d5c5a64957ca90d.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=46xYl55hdc,{'value': 'Single-agent Poisoning Attacks Suffice to Ruin Multi-Agent Learning'},Fan Yao; Yuwei Cheng; Ermin Wei; Haifeng Xu,~Fan_Yao2; ~Yuwei_Cheng2; ~Ermin_Wei1; ~Haifeng_Xu1,"{'value': ['Multi-agent learning', 'reward poisoning attack', 'Nash equilibrium', 'monotone game', 'convergence', 'robustness']}","{'value': ""We investigate the robustness of multi-agent learning in strongly monotone games with bandit feedback. While previous research has developed learning algorithms that achieve last-iterate convergence to the unique Nash equilibrium (NE) at a polynomial rate, we demonstrate that all such algorithms are vulnerable to adversaries capable of poisoning even a single agent's utility observations. Specifically, we propose an attacking strategy such that for any given time horizon $T$, the adversary can mislead any multi-agent learning algorithm to converge to a point other than the unique NE with a corruption budget that grows sublinearly in $T$. To further understand the inherent robustness of these algorithms, we characterize the fundamental trade-off between convergence speed and the maximum tolerable total utility corruptions for two example algorithms, including the state-of-the-art one. Our theoretical and empirical results reveal an intrinsic efficiency-robustness trade-off: the faster an algorithm converges, the more vulnerable it becomes to utility poisoning attacks. To the best of our knowledge, this is the first work to identify and characterize such a trade-off in the context of multi-agent learning.""}",https://openreview.net{'value': '/pdf/169878999e8dc53bfc8c6f3da2d648b6ced39ba6.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=44CoQe6VCq,{'value': 'Test of Time: A Benchmark for Evaluating LLMs on Temporal Reasoning'},Bahare Fatemi; Mehran Kazemi; Anton Tsitsulin; Karishma Malkan; Jinyeong Yim; John Palowitch; Sungyong Seo; Jonathan Halcrow; Bryan Perozzi,~Bahare_Fatemi1; ~Mehran_Kazemi1; ~Anton_Tsitsulin1; ~Karishma_Malkan1; ~Jinyeong_Yim1; ~John_Palowitch1; ~Sungyong_Seo1; ~Jonathan_Halcrow1; ~Bryan_Perozzi1,"{'value': ['Temporal Reasoning', 'Temporal Graphs', 'LLMs']}","{'value': 'Large language models (LLMs) have showcased remarkable reasoning capabilities, yet they remain susceptible to errors, particularly in temporal reasoning tasks involving complex temporal logic. Existing research has explored LLM performance on temporal reasoning using diverse datasets and benchmarks. However, these studies often rely on real-world data that LLMs may have encountered during pre-training or employ anonymization techniques that can inadvertently introduce factual inconsistencies. In this work, we address these limitations by introducing novel synthetic datasets specifically designed to assess LLM temporal reasoning abilities in various scenarios. The diversity of question types across these datasets enables systematic investigation into the impact of the problem structure, size, question type, fact order, and other factors on LLM performance. Our findings provide valuable insights into the strengths and weaknesses of current LLMs in temporal reasoning tasks. To foster further research in this area, we will open-source the datasets and evaluation framework used in our experiments.'}",https://openreview.net{'value': '/pdf/450fcb1667173010f7567b6eb3f774e23acb9513.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=421D67DY3i,{'value': 'Demystifying Online Clustering of Bandits: Enhanced Exploration Under Stochastic and Smoothed Adversarial Contexts'},Zhuohua Li; Maoli Liu; Xiangxiang Dai; John C.S. Lui,~Zhuohua_Li2; ~Maoli_Liu1; ~Xiangxiang_Dai2; ~John_C.S._Lui2,"{'value': ['clustering of bandits', 'linear bandits', 'online learning']}","{'value': 'The contextual multi-armed bandit (MAB) problem is crucial in sequential decision-making. A line of research, known as online clustering of bandits, extends contextual MAB by grouping similar users into clusters, utilizing shared features to improve learning efficiency. However, existing algorithms, which rely on the upper confidence bound (UCB) strategy, struggle to gather adequate statistical information to accurately identify unknown user clusters. As a result, their theoretical analyses require several strong assumptions about the ""diversity"" of contexts generated by the environment, leading to impractical settings, complicated analyses, and poor practical performance. Removing these assumptions has been a long-standing open problem in the clustering of bandits literature. In this work, we provide two partial solutions. First, we introduce an additional exploration phase to accelerate the identification of clusters. We integrate this general strategy into both graph-based and set-based algorithms and propose two new algorithms, UniCLUB and UniSCLUB. Remarkably, our algorithms require substantially weaker assumptions and simpler theoretical analyses while achieving superior cumulative regret compared to previous studies. Second, inspired by the smoothed analysis framework, we propose a more practical setting that eliminates the requirement for i.i.d. context generation used in previous studies, thus enhancing the performance of existing algorithms for online clustering of bandits. Extensive evaluations on both synthetic and real-world datasets demonstrate that our proposed algorithms outperform existing approaches.'}",https://openreview.net{'value': '/pdf/6c0a9fdde8319606191cde07904cf48fa6d378dc.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=41WIgfdd5o,{'value': 'Learning a Fast Mixing Exogenous Block MDP using a Single Trajectory'},Alexander Levine; Peter Stone; Amy Zhang,~Alexander_Levine2; ~Peter_Stone1; ~Amy_Zhang1,"{'value': ['Reinforcement Learning', 'Reinforcement Learning Theory', 'Controllable Representations', 'Representation Learning', 'Exogenous Noise', 'Controllable Latent State', 'Unsupervised Reinforcement Learning']}","{'value': ""In order to train agents that can quickly adapt to new objectives or reward functions, efficient unsupervised representation learning in sequential decision-making environments can be important. Frameworks such as the Exogenous Block Markov Decision Process (Ex-BMDP) have been proposed to formalize this representation-learning problem (Efroni et al., 2022b). In the Ex-BMDP framework, the agent's high-dimensional observations of the environment have two latent factors: a controllable factor, which evolves deterministically within a small state space according to the agent's actions, and an exogenous factor, which represents time-correlated noise, and can be highly complex. The goal of the representation learning problem is to learn an encoder that maps from observations into the controllable latent space, as well as the dynamics of this space. Efroni et al. (2022b) has shown that this is possible with a sample complexity that depends only on the size of the controllable latent space, and not on the size of the noise factor. However, this prior work has focused on the episodic setting, where the controllable latent state resets to a specific start state after a finite horizon.\n\nBy contrast, if the agent can only interact with the environment in a single continuous trajectory, prior works have not established sample-complexity bounds. We propose STEEL, the first provably sample-efficient algorithm for learning the controllable dynamics of an Ex-BMDP from a single trajectory, in the function approximation setting. STEEL has a sample complexity that depends only on the sizes of the controllable latent space and the encoder function class, and (at worst linearly) on the mixing time of the exogenous noise factor. We prove that STEEL is correct and sample-efficient, and demonstrate STEEL on two toy problems. Code is available at: https://github.com/midi-lab/steel.""}",https://openreview.net{'value': '/pdf/b3ea0b538261f3ddb732e18cf9fc38a5f0c1a05f.pdf'},{'title_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=3ygfMPLv0P,{'value': 'Tailoring Mixup to Data for Calibration'},Quentin Bouniot; Pavlo Mozharovskyi; Florence d'Alché-Buc,~Quentin_Bouniot1; ~Pavlo_Mozharovskyi1; ~Florence_d'Alché-Buc2,"{'value': ['mixup', 'calibration', 'confidence', 'robustness']}","{'value': 'Among all data augmentation techniques proposed so far, linear interpolation of training samples, also called Mixup, has found to be effective for a large panel of applications. \n  Along with improved predictive performance, Mixup is also a good technique for improving calibration.\n  However, mixing data carelessly can lead to manifold mismatch, i.e., synthetic data lying outside original  class manifolds, which can deteriorate calibration.\n  In this work, we show that the likelihood of assigning a wrong label with mixup increases with the distance between data to mix. \n  To this end, we propose to dynamically change the underlying distributions of interpolation coefficients \n  depending on the similarity between samples to mix, and define a flexible framework to do so without losing in diversity. We provide extensive experiments for classification and regression tasks, showing that our proposed method improves predictive performance \n  and calibration of models, while being much more efficient.'}",https://openreview.net{'value': '/pdf/b45c334130ad547d52ff1cc3e69b6edacb671b4e.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=3tukjsVyrE,{'value': 'Scaling Speech-Text Pre-training with Synthetic Interleaved Data'},Aohan Zeng; Zhengxiao Du; Mingdao Liu; Lei Zhang; shengmin jiang; Yuxiao Dong; Jie Tang,~Aohan_Zeng1; ~Zhengxiao_Du1; ~Mingdao_Liu1; ~Lei_Zhang83; ~shengmin_jiang2; ~Yuxiao_Dong1; ~Jie_Tang1,{'value': ['large language models; speech language model; spoken chatbots']},"{'value': 'Speech language models (SpeechLMs) accept speech input and produce speech output, allowing for more natural human-computer interaction compared to text-based large language models (LLMs).\nTraditional approaches for developing SpeechLMs are constrained by the limited availability of unsupervised speech data and parallel speech-text data, which are significantly less abundant compared to text pre-training data, thereby limiting their scalability as LLMs.\nWe propose a novel approach to scaling speech-text pre-training by leveraging large-scale synthetic interleaved data derived from text corpora, eliminating the need for parallel speech-text datasets.\nOur method efficiently constructs speech-text interleaved data by sampling text spans from existing text corpora and synthesizing corresponding speech spans using a text-to-token model, bypassing the need to generate actual speech.\nWe also employ a supervised speech tokenizer derived from an automatic speech recognition (ASR) model  by incorporating a vector-quantized bottleneck into the encoder. This supervised training approach results in discrete speech tokens with strong semantic preservation even at lower sampling rates (e.g. 12.5Hz), while still maintaining speech reconstruction quality.\nStarting from a pre-trained language model and scaling our pre-training to 1 trillion tokens (with 600B synthetic interleaved speech-text data), we achieve state-of-the-art performance in both speech language modeling and spoken question answering, improving performance on spoken questions tasks from the previous SOTA of 13\\% (Moshi) to 31\\%.\nWe further demonstrate that by fine-tuning the pre-trained model with speech dialogue data, we can develop an end-to-end spoken chatbot that achieves competitive performance comparable to existing baselines in both conversational abilities and speech quality, even operating exclusively in the speech domain.'}",https://openreview.net{'value': '/pdf/2bfb4c69dc2ba7cb7772f86bf3c3e979bffdc20c.pdf'},{'title_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=3qeOy7HwUT,{'value': 'Input Space Mode Connectivity in Deep Neural Networks'},Jakub Vrabel; Ori Shem-Ur; Yaron Oz; David Krueger,~Jakub_Vrabel1; ~Ori_Shem-Ur1; ~Yaron_Oz1; ~David_Krueger1,"{'value': ['mode connectivity', 'input space', 'deep learning', 'adversarial detection', 'interpretability', 'percolation theory']}","{'value': 'We extend the concept of loss landscape mode connectivity to the input space of deep neural networks. Mode connectivity was originally studied within parameter space, where it describes the existence of low-loss paths between different solutions (loss minimizers) obtained through gradient descent. We present theoretical and empirical evidence of its presence in the input space of deep networks, thereby highlighting the broader nature of the phenomenon. We observe that different input images with similar predictions are generally connected, and for trained models, the path tends to be simple, with only a small deviation from being a linear path. Our methodology utilizes real, interpolated, and synthetic inputs created using the input optimization technique for feature visualization. We conjecture that input space mode connectivity in high-dimensional spaces is a geometric effect that takes place even in untrained models and can be explained through percolation theory. We exploit mode connectivity to obtain new insights about adversarial examples and demonstrate its potential for adversarial detection. Additionally, we discuss applications for the interpretability of deep networks.'}",https://openreview.net{'value': '/pdf/855c1349c4a6644a61bb0a7d183591a23761276d.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=3n4RY25UWP,{'value': 'An Information Criterion for Controlled Disentanglement of Multimodal Data'},Chenyu Wang; Sharut Gupta; Xinyi Zhang; Sana Tonekaboni; Stefanie Jegelka; Tommi Jaakkola; Caroline Uhler,~Chenyu_Wang7; ~Sharut_Gupta1; ~Xinyi_Zhang16; ~Sana_Tonekaboni1; ~Stefanie_Jegelka3; ~Tommi_S._Jaakkola1; ~Caroline_Uhler1,"{'value': ['Multimodal Representation Learning', 'Disentanglement', 'Self-Supervised Learning', 'Information Theory']}","{'value': 'Multimodal representation learning seeks to relate and decompose information inherent in multiple modalities. By disentangling modality-specific information from information that is shared across modalities, we can improve interpretability and robustness and enable downstream tasks such as the generation of counterfactual outcomes. Separating the two types of information is challenging since they are often deeply entangled in many real-world applications. We propose $\\textbf{Disentangled}$ $\\textbf{S}$elf-$\\textbf{S}$upervised $\\textbf{L}$earning (DisentangledSSL), a novel self-supervised approach for learning disentangled representations. We present a comprehensive analysis of the optimality of each disentangled representation, particularly focusing on the scenario not covered in prior work where the so-called $\\textit{Minimum Necessary Information}$ (MNI) point is not attainable. We demonstrate that \\algo successfully learns shared and modality-specific features on multiple synthetic and real-world datasets and consistently outperforms baselines on various downstream tasks, including prediction tasks for vision-language data, as well as molecule-phenotype retrieval tasks for biological data.'}",https://openreview.net{'value': '/pdf/d3f8a9e64b135949514f9cf96202c357c9a20fe3.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=3ms8EQY7f8,{'value': 'Simulating Human-like Daily Activities with Desire-driven Autonomy'},Yiding Wang; Yuxuan Chen; Fangwei Zhong; Long Ma; Yizhou Wang,~Yiding_Wang1; ~Yuxuan_Chen11; ~Fangwei_Zhong3; ~Long_Ma5; ~Yizhou_Wang1,{'value': ['desire;autonomy;daily activities;']},"{'value': 'Desires motivate humans to interact autonomously with the complex world. In contrast, current AI agents require explicit task specifications, such as instructions or reward functions, which constrain their autonomy and behavioral diversity. In this paper, we introduce a Desire-driven Autonomous Agent (D2A) that can enable a large language model (LLM) to autonomously propose and select tasks, motivated by satisfying its multi-dimensional desires. Specifically, the motivational framework of D2A is mainly constructed by a dynamic $Value\\ System$, inspired by the Theory of Needs. It incorporates an understanding of human-like desires, such as the need for social interaction, personal fulfillment, and self-care. At each step, the agent evaluates the value of its current state, proposes a set of candidate activities, and selects the one that best aligns with its intrinsic motivations. We conduct experiments on Concordia, a text-based simulator, to demonstrate that our agent generates coherent, contextually relevant daily activities while exhibiting variability and adaptability similar to human behavior. A comparative analysis with other LLM-based agents demonstrates that our approach significantly enhances the rationality of the simulated activities.'}",https://openreview.net{'value': '/pdf/b88f5158be52b85d96d503ccbb21bc61dfbf62f5.pdf'},{'abstract_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=3fGtV4Zfgq,{'value': 'Fast training and sampling of Restricted Boltzmann Machines'},Nicolas BEREUX; Aurélien Decelle; Cyril Furtlehner; Lorenzo Rosset; Beatriz Seoane,~Nicolas_BEREUX1; ~Aurélien_Decelle1; ~Cyril_Furtlehner1; ~Lorenzo_Rosset1; ~Beatriz_Seoane1,"{'value': ['Restricted Boltzmann Machine', 'Fast Sampling', 'structured data learning', 'training algorithm']}","{'value': 'Restricted Boltzmann Machines (RBMs) are powerful tools for modeling complex systems and extracting insights from data, but their training is hindered by the slow mixing of Markov Chain Monte Carlo (MCMC) processes, especially with highly structured datasets. In this study, we build on recent theoretical advances in RBM training and focus on the stepwise encoding of data patterns into singular vectors of the coupling matrix, significantly reducing the cost of generating new samples and evaluating the quality of the model, as well as the training cost in highly clustered datasets.  The learning process is analogous to the thermodynamic continuous phase transitions observed in ferromagnetic models, where new modes in the probability measure emerge in a continuous manner. \nWe leverage the continuous transitions in the training process to define a smooth annealing trajectory that enables reliable and computationally efficient log-likelihood estimates. This approach enables online assessment during training and introduces a novel sampling strategy called Parallel Trajectory Tempering (PTT) that outperforms previously optimized MCMC methods.\nTo mitigate the critical slowdown effect in the early stages of training, we propose a pre-training phase. In this phase, the principal components are encoded into a low-rank RBM through a convex optimization process, facilitating efficient static Monte Carlo sampling and accurate computation of the partition function.\nOur results demonstrate that this pre-training strategy allows RBMs to efficiently handle highly structured datasets where conventional methods fail. Additionally, our log-likelihood estimation outperforms computationally intensive approaches in controlled scenarios, while the PTT algorithm significantly accelerates MCMC processes compared to conventional methods.'}",https://openreview.net{'value': '/pdf/24e5fcc6d97eafa832d2cf8d86935b02f5fb6c0d.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=3b9SKkRAKw,{'value': 'LeFusion: Controllable Pathology Synthesis via Lesion-Focused Diffusion Models'},Hantao Zhang; Yuhe Liu; Jiancheng Yang; Shouhong Wan; Xinyuan Wang; Wei Peng; Pascal Fua,~Hantao_Zhang2; ~Yuhe_Liu3; ~Jiancheng_Yang3; ~Shouhong_Wan1; ~Xinyuan_Wang2; ~Wei_Peng4; ~Pascal_Fua1,"{'value': ['data synthesis', 'diffusion models', 'cardiac MRI', 'lung nodule CT', 'segmentation']}","{'value': 'Patient data from real-world clinical practice often suffers from data scarcity and long-tail imbalances, leading to biased outcomes or algorithmic unfairness. This study addresses these challenges by generating lesion-containing image-segmentation pairs from lesion-free images. Previous efforts in medical imaging synthesis have struggled with separating lesion information from background, resulting in low-quality backgrounds and limited control over the synthetic output. Inspired by diffusion-based image inpainting, we propose LeFusion, a lesion-focused diffusion model. By redesigning the diffusion learning objectives to focus on lesion areas, we simplify the learning process and improve control over the output while preserving high-fidelity backgrounds by integrating forward-diffused background contexts into the reverse diffusion process. Additionally, we tackle two major challenges in lesion texture synthesis: 1) multi-peak and 2) multi-class lesions. We introduce two effective strategies: histogram-based texture control and multi-channel decomposition, enabling the controlled generation of high-quality lesions in difficult scenarios. Furthermore, we incorporate lesion mask diffusion, allowing control over lesion size, location, and boundary, thus increasing lesion diversity. Validated on 3D cardiac lesion MRI and lung nodule CT datasets, LeFusion-generated data significantly improves the performance of state-of-the-art segmentation models, including nnUNet and SwinUNETR.'}",https://openreview.net{'value': '/pdf/c4c499d3163801b947e70b673f9eadca4be34844.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=3UKOzGWCVY,{'value': 'Learn-by-interact: A Data-Centric Framework For Self-Adaptive Agents in Realistic Environments'},Hongjin SU; Ruoxi Sun; Jinsung Yoon; Pengcheng Yin; Tao Yu; Sercan O Arik,~Hongjin_SU1; ~Ruoxi_Sun2; ~Jinsung_Yoon1; ~Pengcheng_Yin1; ~Tao_Yu5; ~Sercan_O_Arik1,"{'value': ['Data synthesis', 'Agent', 'Adaptation']}","{'value': 'Autonomous agents powered by large language models (LLMs) have the potential to enhance human capabilities, assisting with digital tasks from sending emails to performing data analysis.   The abilities of existing LLMs at such tasks are often hindered by the lack of high-quality agent data from the corresponding environments they interact with.  We propose LEARN-BY-INTERACT, a data-centric framework to adapt LLM agents to any given environments without human annotations.   LEARN-BY-INTERACT synthesizes trajectories of agent-environment interactions based on documentations, and constructs instructions by summarizing or abstracting the interaction histories, a process called backward construction. We assess the quality of our synthetic data by using them in both training-based scenarios and training-free in-context learning (ICL), where we craft innovative retrieval approaches optimized for agents. Extensive experiments on SWE-bench, WebArena, OSWorld, and Spider2-V spanning across realistic coding, web, and desktop environments show the effectiveness of LEARN-BY-INTERACT in various downstream agentic tasks — baseline results are improved up to 11.1% for ICL with Claude-3.5 and 23.1% for training with Codestral-22B. We further demonstrate the critical role of backward construction, which provides up to 10.6% improvement for training.  Our ablation studies demonstrate the efficiency provided by our synthesized data in ICL and the superiority of our retrieval pipeline over alternative approaches like conventional retrieval-augmented generation (RAG). We expect that LEARN-BY-INTERACT will serve as a foundation for agent data synthesis as LLMs are increasingly deployed at real-world environments.'}",https://openreview.net{'value': '/pdf/12fd496c051bcdb1ac58f77a37166c88de195d80.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=3RLxccFPHz,{'value': 'An Intelligent Agentic System for Complex Image Restoration Problems'},Kaiwen Zhu; Jinjin Gu; Zhiyuan You; Yu Qiao; Chao Dong,~Kaiwen_Zhu2; ~Jinjin_Gu1; ~Zhiyuan_You1; ~Yu_Qiao1; ~Chao_Dong4,"{'value': ['image restoration', 'low-level vision', 'agent', 'large language model', 'vision language model']}","{'value': ""Real-world image restoration (IR) is inherently complex and often requires combining multiple specialized models to address diverse degradations. Inspired by human problem-solving, we propose AgenticIR, an agentic system that mimics the human approach to image processing by following five key stages: Perception, Scheduling, Execution, Reflection, and Rescheduling. AgenticIR leverages large language models (LLMs) and vision-language models (VLMs) that interact via text generation to dynamically operate a toolbox of IR models. We fine-tune VLMs for image quality analysis and employ LLMs for reasoning, guiding the system step by step. To compensate for LLMs' lack of specific IR knowledge and experience, we introduce a self-exploration method, allowing the LLM to observe and summarize restoration results into referenceable documents. Experiments demonstrate AgenticIR's potential in handling complex IR tasks, representing a promising path toward achieving general intelligence in visual processing.""}",https://openreview.net{'value': '/pdf/b8abeebdd4727d366ab252204204fa002981663c.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=3OyaXFQuDl,"{'value': 'Smaller, Weaker, Yet Better: Training LLM Reasoners via Compute-Optimal Sampling'}",Hritik Bansal; Arian Hosseini; Rishabh Agarwal; Vinh Q. Tran; Mehran Kazemi,~Hritik_Bansal2; ~Arian_Hosseini1; ~Rishabh_Agarwal2; ~Vinh_Q._Tran1; ~Mehran_Kazemi1,"{'value': ['large and small language models', 'reasoning', 'math', 'compute-optimal', 'sampling', 'supervised finetuning']}","{'value': 'Training on high-quality synthetic data from strong language models (LMs) is a common strategy to improve the reasoning performance of LMs. In this work, we revisit whether this strategy is compute-optimal under a fixed inference budget (e.g., FLOPs). To do so, we investigate the trade-offs between generating synthetic data using a stronger but more expensive (SE) model versus a weaker but cheaper (WC) model. We evaluate the generated data across three key metrics: coverage, diversity, and false positive rate, and show that the data from WC models may have higher coverage and diversity, but also exhibit higher false positive rates. We then finetune LMs on data from SE and WC models in different settings: knowledge distillation, self-improvement, and a novel weak-to-strong improvement setup where a weaker LM teaches reasoning to a stronger LM. Our findings reveal that models finetuned on WC-generated data consistently outperform those trained on SE-generated data across multiple benchmarks and multiple choices of WC and SE models. These results challenge the prevailing practice of relying on SE models for synthetic data generation, suggesting that WC may be the compute-optimal approach for training advanced LM reasoners.'}",https://openreview.net{'value': '/pdf/cb8c559106c3bf5682e2e13302e65e6d1819ebf0.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=3Oli4u6q3p,{'value': 'RelitLRM: Generative Relightable Radiance for Large Reconstruction Models'},Tianyuan Zhang; Zhengfei Kuang; Haian Jin; Zexiang Xu; Sai Bi; Hao Tan; He Zhang; Yiwei Hu; Milos Hasan; William T. Freeman; Kai Zhang; Fujun Luan,~Tianyuan_Zhang2; ~Zhengfei_Kuang1; ~Haian_Jin1; ~Zexiang_Xu1; ~Sai_Bi1; ~Hao_Tan1; ~He_Zhang16; ~Yiwei_Hu1; ~Milos_Hasan1; ~William_T._Freeman1; ~Kai_Zhang7; ~Fujun_Luan2,"{'value': ['Relightable reconstruction', 'Inverse Rendering', 'Generative Relighting']}","{'value': 'We propose RelitLRM, a Large Reconstruction Model (LRM) for generating high-quality Gaussian splatting representations of 3D objects under novel illuminations from sparse (4-8) posed images captured under unknown static lighting. Unlike prior inverse rendering methods requiring dense captures and slow optimization, often causing artifacts like incorrect highlights or shadow baking, RelitLRM adopts a feed-forward transformer-based model with a novel combination of a geometry reconstructor and a relightable appearance generator based on diffusion. The model is trained end-to-end on synthetic multi-view renderings of objects under varying known illuminations. This architecture design enables to effectively decompose geometry and appearance, resolve the ambiguity between material and lighting, and capture the multi-modal distribution of shadows and specularity in the relit appearance. We show our sparse-view feed-forward RelitLRM offers competitive relighting results to state-of-the-art dense-view optimization-based baselines while being significantly faster. Our project page is available at: https://relit-lrm.github.io/.'}",https://openreview.net{'value': '/pdf/f9083a472dd662aceefc3499059e492ec1d9d8a0.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=3MnMGLctKb,{'value': 'Multi-Modal and Multi-Attribute Generation of Single Cells with CFGen'},Alessandro Palma; Till Richter; Hanyi Zhang; Manuel Lubetzki; Alexander Tong; Andrea Dittadi; Fabian J Theis,~Alessandro_Palma1; ~Till_Richter1; ~Hanyi_Zhang1; ~Manuel_Lubetzki1; ~Alexander_Tong1; ~Andrea_Dittadi1; ~Fabian_J_Theis1,"{'value': ['scRNA-seq', 'Flow Matching', 'Generative modeling', 'Multiomics']}","{'value': 'Generative modeling of single-cell RNA-seq data is crucial for tasks like trajectory inference, batch effect removal, and simulation of realistic cellular data. However, recent deep generative models simulating synthetic single cells from noise operate on pre-processed continuous gene expression approximations, overlooking the discrete nature of single-cell data, which limits their effectiveness and hinders the incorporation of robust noise models. Additionally, aspects like controllable multi-modal and multi-label generation of cellular data remain underexplored. This work introduces CellFlow for Generation (CFGen), a flow-based conditional generative model that preserves the inherent discreteness of single-cell data. CFGen reliably generates whole-genome, multi-modal, single-cell data, improving the recovery of crucial biological data characteristics while tackling relevant generative tasks such as rare cell type augmentation and batch correction. We also introduce a novel framework for compositional data generation using Flow Matching. By showcasing CFGen on a diverse set of biological datasets and settings, we provide evidence of its value to the fields of computational biology and deep generative models.'}",https://openreview.net{'value': '/pdf/9f3fe6895d18242081f3be7e620a0f819fc30e74.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=3JsU5QXNru,{'value': 'Group Distributionally Robust Dataset Distillation with Risk Minimization'},Saeed Vahidian; Mingyu Wang; Jianyang Gu; Vyacheslav Kungurtsev; Wei Jiang; Yiran Chen,~Saeed_Vahidian1; ~Mingyu_Wang5; ~Jianyang_Gu1; ~Vyacheslav_Kungurtsev1; ~Wei_Jiang5; ~Yiran_Chen1,"{'value': ['dataset distillation', 'distributional robustness', 'generalization']}","{'value': 'Dataset distillation (DD) has emerged as a widely adopted technique for crafting a synthetic dataset that captures the essential information of a training dataset, facilitating the training of accurate neural models. Its applications span various domains, including transfer learning, federated learning, and neural architecture search. The most popular methods for constructing the synthetic data rely on matching the convergence properties of training the model with the synthetic dataset and the training dataset. However, using the empirical loss as the criterion must be thought of as auxiliary in the same sense that the training set is an approximate substitute for the population distribution, and the latter is the data of interest. Yet despite its popularity, an aspect that remains unexplored is the relationship of DD to its generalization, particularly across uncommon subgroups. That is, how can we ensure that a model trained on the synthetic dataset performs well when faced with samples from regions with low population density? Here, the representativeness and coverage of the dataset become salient over the guaranteed training error at inference. Drawing inspiration from distributionally robust optimization, we introduce an algorithm that combines clustering with the minimization of a risk measure on the loss to conduct DD. We provide a theoretical rationale for our approach and demonstrate its effective generalization and robustness across subgroups through numerical experiments.'}",https://openreview.net{'value': '/pdf/2bb88f923d1e317638423eaa696bec44706a1e32.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=3Hy00Wvabi,{'value': 'WorkflowLLM: Enhancing Workflow Orchestration Capability of Large Language Models'},Shengda Fan; Xin Cong; Yuepeng Fu; Zhong Zhang; Shuyan Zhang; Yuanwei Liu; Yesai Wu; Yankai Lin; Zhiyuan Liu; Maosong Sun,~Shengda_Fan1; ~Xin_Cong1; ~Yuepeng_Fu1; ~Zhong_Zhang5; ~Shuyan_Zhang1; ~Yuanwei_Liu4; ~Yesai_Wu1; ~Yankai_Lin1; ~Zhiyuan_Liu1; ~Maosong_Sun1,"{'value': ['Large Language Models', 'Process Automation', 'Workflow', 'Tool Learning']}","{'value': 'Recent advancements in large language models (LLMs) have driven a revolutionary paradigm shift in process automation from Robotic Process Automation to Agentic Process Automation by automating the workflow orchestration procedure based on LLMs. However, existing LLMs (even the advanced OpenAI GPT-4o) are confined to achieving satisfactory capability in workflow orchestration. To address this limitation, we present WorkflowLLM, a data-centric framework elaborately designed to enhance the capability of LLMs in workflow orchestration. It first constructs a large-scale fine-tuning dataset WorkflowBench with 106, 763 samples, covering 1, 503 APIs from 83 applications across 28 categories. Specifically, the construction process can be divided into three phases: (1) Data Collection: we collect real-world workflow data from Apple Shortcuts and RoutineHub, transcribing them into Python-style code. We further equip them with generated hierarchical thought via GPT-4o-mini. (2) Query Expansion: we prompt GPT-4o-mini to generate more task queries to enrich the diversity and complexity of workflows. (3) Workflow Generation: we leverage an annotator model trained on collected data to generate workflows for synthesized queries. Finally, we merge the synthetic samples that pass quality confirmation with the collected samples to obtain the WorkflowBench. Based on WorkflowBench, we fine-tune Llama-3.1-8B to obtain WorkflowLlama. Our experiments show that WorkflowLlama demonstrates a strong capacity to orchestrate complex workflows, while also achieving notable generalization performance on previously unseen APIs. Additionally, WorkflowBench exhibits robust zero-shot generalization capabilities on an out-of-distribution task planning dataset, T-Eval. Our data and code are available at https://github.com/OpenBMB/WorkflowLLM.'}",https://openreview.net{'value': '/pdf/c2ae3b37950645ca5b0e7bd93eb3e30fc1cbf417.pdf'},{'abstract_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=3Gzz7ZQLiz,{'value': 'Learning to Contextualize Web Pages for Enhanced Decision Making by LLM Agents'},Dongjun Lee; Juyong Lee; Kyuyoung Kim; Jihoon Tack; Jinwoo Shin; Yee Whye Teh; Kimin Lee,~Dongjun_Lee10; ~Juyong_Lee1; ~Kyuyoung_Kim1; ~Jihoon_Tack1; ~Jinwoo_Shin1; ~Yee_Whye_Teh2; ~Kimin_Lee1,"{'value': ['Large Language Models', 'LLM agent', 'Web automation']}","{'value': 'Recent advances in large language models (LLMs) have led to a growing interest in developing LLM-based agents for automating web tasks. However, these agents often struggle with even simple tasks on real-world websites due to their limited capability to understand and process complex web page structures. In this work, we introduce LCoW, a framework for Learning language models to Contextualize complex Web pages into a more comprehensible form, thereby enhancing decision making by LLM agents. LCoW decouples web page understanding from decision making by training a separate contextualization module to transform complex web pages into comprehensible format, which are then utilized by the decision-making agent. We demonstrate that our contextualization module effectively integrates with LLM agents of various scales to significantly enhance their decision-making capabilities in web automation tasks. Notably, LCoW improves the success rates of closed-source LLMs (e.g., Gemini-1.5-flash, GPT-4o, Claude-3.5-Sonnet) by an average of 15.6%, and demonstrates a 23.7% average improvement in success rates for open-source LMs (e.g., Llama-3.1-8B, Llama-3.1-70B) on the WorkArena benchmark.\nMoreover, the Gemini-1.5-flash agent with LCoW achieves state-of-the-art results on the WebShop benchmark, outperforming human experts. The relevant code materials are available at our project page: https://lcowiclr2025.github.io.'}",https://openreview.net{'value': '/pdf/ab477b5ecff7f6b73cc1151b893fb071c069c433.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=2z1HT5lw5M,{'value': 'Trajectory attention for fine-grained video motion control'},Zeqi Xiao; Wenqi Ouyang; Yifan Zhou; Shuai Yang; Lei Yang; Jianlou Si; Xingang Pan,~Zeqi_Xiao2; ~Wenqi_Ouyang1; ~Yifan_Zhou11; ~Shuai_Yang3; ~Lei_Yang7; ~Jianlou_Si1; ~Xingang_Pan1,"{'value': ['Trajectory attention', 'video generation', 'motion control']}","{'value': 'Recent advancements in video generation have been greatly driven by video diffusion models, with camera motion control emerging as a crucial challenge in creating view-customized visual content. This paper introduces trajectory attention, a novel approach that performs attention along available pixel trajectories for fine-grained camera motion control. Unlike existing methods that often yield imprecise outputs or neglect temporal correlations, our approach possesses a stronger inductive bias that seamlessly injects trajectory information into the video generation process. Importantly, our approach models trajectory attention as an auxiliary branch alongside traditional temporal attention. This design enables the original temporal attention and the trajectory attention to work in synergy, ensuring both\nprecise motion control and new content generation capability, which is critical when the trajectory is only partially available. Experiments on camera motion control for images and videos demonstrate significant improvements in precision and long-range consistency while maintaining high-quality generation. Furthermore, we show that our approach can be extended to other video motion control tasks, such as first-frame-guided video editing, where it excels in maintaining content consistency over large spatial and temporal ranges.'}",https://openreview.net{'value': '/pdf/70b9591b8b334746b2f54644f2025f648d864e85.pdf'},{'title_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=2ySt3cdGfJ,{'value': 'Distribution Backtracking Builds A Faster Convergence Trajectory for Diffusion Distillation'},Shengyuan Zhang; Ling Yang; Zejian Li; An Zhao; Chenye Meng; Changyuan Yang; Guang Yang; Zhiyuan Yang; Lingyun Sun,~Shengyuan_Zhang2; ~Ling_Yang1; ~Zejian_Li1; ~An_Zhao3; ~Chenye_Meng1; ~Changyuan_Yang1; ~Guang_Yang11; ~Zhiyuan_Yang7; ~Lingyun_Sun1,"{'value': ['Diffusion Model', 'Diffusion Distillation', 'One-step Generation']}","{'value': 'Accelerating the sampling speed of diffusion models remains a significant challenge. Recent score distillation methods distill a heavy teacher model into a student generator to achieve one-step generation, which is optimized by calculating the difference between two score functions on the samples generated by the student model.\nHowever, there is a score mismatch issue in the early stage of the score distillation process, since existing methods mainly focus on using the endpoint of pre-trained diffusion models as teacher models, overlooking the importance of the convergence trajectory between the student generator and the teacher model.\nTo address this issue, we extend the score distillation process by introducing the entire convergence trajectory of the teacher model and propose $\\textbf{Dis}$tribution $\\textbf{Back}$tracking Distillation ($\\textbf{DisBack}$). DisBask is composed of two stages: $\\textit{Degradation Recording}$ and $\\textit{Distribution Backtracking}$. \n$\\textit{Degradation Recording}$ is designed to obtain the convergence trajectory by recording the degradation path from the pre-trained teacher model to the untrained student generator.\nThe degradation path implicitly represents the intermediate distributions between the teacher and the student, and its reverse can be viewed as the convergence trajectory from the student generator to the teacher model.\nThen $\\textit{Distribution Backtracking}$ trains the student generator to backtrack the intermediate distributions along the path to approximate the convergence trajectory of the teacher model.\nExtensive experiments show that DisBack achieves faster and better convergence than the existing distillation method and achieves comparable or better generation performance, with an FID score of 1.38 on the ImageNet 64$\\times$64 dataset.\nDisBack is easy to implement and can be generalized to existing distillation methods to boost performance.'}",https://openreview.net{'value': '/pdf/77a9389d61d62361b3be59a9035a18e6cac21383.pdf'},{'title_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=2uPZ4aX1VV,{'value': 'Null Counterfactual Factor Interactions for Goal-Conditioned Reinforcement Learning'},Caleb Chuck; Fan Feng; Carl Qi; Chang Shi; Siddhant Agarwal; Amy Zhang; Scott Niekum,~Caleb_Chuck1; ~Fan_Feng2; ~Carl_Qi1; ~Chang_Shi1; ~Siddhant_Agarwal1; ~Amy_Zhang1; ~Scott_Niekum1,"{'value': ['Goal Conditioned Reinforcement Learning', 'Factor Interactions', 'Factored State', 'Hindsight Experience Replay', 'Counterfactual']}","{'value': ""Hindsight relabeling is a powerful tool for overcoming sparsity in goal-conditioned reinforcement learning (GCRL), especially in certain domains such as navigation and locomotion. However, hindsight relabeling can struggle in object-centric domains. For example, suppose that the goal space consists of a robotic arm pushing a particular target block to a goal location. In this case, hindsight relabeling will give high rewards to any trajectory that does not interact with the block. However, these behaviors are only useful when the object is already at the goal---an extremely rare case in practice. A dataset dominated by these kinds of trajectories can complicate learning and lead to failures. In object-centric domains, one key intuition is that meaningful trajectories are often characterized by object-object interactions such as pushing the block with the gripper. To leverage this intuition, we introduce Hindsight Relabeling using Interactions (HInt), which combines interactions with hindsight relabeling to improve the sample efficiency of downstream RL. However, interactions do not have a consensus statistical definition that is tractable for downstream GCRL. Therefore, we propose a definition of interactions based on the concept of _null counterfactual_: a cause object is interacting with a target object if, in a world where the cause object did not exist, the target object would have different transition dynamics. We leverage this definition to infer interactions in Null Counterfactual Interaction Inference (NCII), which uses a ``nulling'' operation with a learned model to simulate absences and infer interactions. We demonstrate that NCII is able to achieve significantly improved interaction inference accuracy in both simple linear dynamics domains and dynamic robotic domains in Robosuite, Robot Air Hockey, and Franka Kitchen. Furthermore, we demonstrate that HInt improves sample efficiency by up to $4\\times$ in these domains as goal-conditioned tasks.""}",https://openreview.net{'value': '/pdf/ece8fced83ad1562f06e5501578c6b5955a28d1d.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=2snKOc7TVp,{'value': 'VisualAgentBench: Towards Large Multimodal Models as Visual Foundation Agents'},Xiao Liu; Tianjie Zhang; Yu Gu; Iat Long Iong; Song XiXuan; Yifan Xu; Shudan Zhang; Hanyu Lai; Jiadai Sun; Xinyue Yang; Yu Yang; Zehan Qi; Shuntian Yao; Xueqiao Sun; Siyi Cheng; Qinkai Zheng; Hao Yu; Hanchen Zhang; Wenyi Hong; Ming Ding; Lihang Pan; Xiaotao Gu; Aohan Zeng; Zhengxiao Du; Chan Hee Song; Yu Su; Yuxiao Dong; Jie Tang,~Xiao_Liu15; ~Tianjie_Zhang1; ~Yu_Gu5; ~Iat_Long_Iong1; ~Song_XiXuan1; ~Yifan_Xu7; ~Shudan_Zhang1; ~Hanyu_Lai2; ~Jiadai_Sun2; ~Xinyue_Yang2; ~Yu_Yang21; ~Zehan_Qi2; ~Shuntian_Yao1; ~Xueqiao_Sun1; ~Siyi_Cheng1; ~Qinkai_Zheng2; ~Hao_Yu20; ~Hanchen_Zhang1; ~Wenyi_Hong1; ~Ming_Ding1; ~Lihang_Pan1; ~Xiaotao_Gu1; ~Aohan_Zeng1; ~Zhengxiao_Du1; ~Chan_Hee_Song1; ~Yu_Su2; ~Yuxiao_Dong1; ~Jie_Tang1,"{'value': ['Large Multimodal Models', 'Agents', 'Evaluation']}","{'value': ""Large Multimodal Models (LMMs) have ushered in a new era in artificial intelligence, merging capabilities in both language and vision to form highly capable \\textbf{Visual Foundation Agents} that are postulated to excel across a myriad of tasks. However, existing benchmarks fail to sufficiently challenge or showcase the full potential of LMMs as visual foundation agents in complex, real-world environments. To address this gap, we introduce VisualAgentBench (VAB), a comprehensive and unified benchmark specifically designed to train and evaluate LMMs as visual foundation agents across diverse scenarios in one standard setting, including Embodied, Graphical User Interface, and Visual Design, with tasks formulated to probe the depth of LMMs' understanding and interaction capabilities. Through rigorous testing across 9 proprietary LMM APIs and 9 open models (18 in total), we demonstrate the considerable yet still developing visual agent capabilities of these models. Additionally, VAB explores the synthesizing of visual agent trajectory data through hybrid methods including Program-based Solvers, LMM Agent Bootstrapping, and Human Demonstrations, offering insights into obstacles, solutions, and trade-offs one may meet in developing open LMM agents. Our work not only aims to benchmark existing models but also provides an instrumental playground for future development into visual foundation agents. Code, train, and test data are available at \\url{https://github.com/THUDM/VisualAgentBench}.""}",https://openreview.net{'value': '/pdf/bee7975a3c8aa69c07f6b3df50d3f4b390af6700.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=2rnOgyFQgb,{'value': 'SynQ: Accurate Zero-shot Quantization by Synthesis-aware Fine-tuning'},Minjun Kim; Jongjin Kim; U Kang,~Minjun_Kim5; ~Jongjin_Kim1; ~U_Kang1,"{'value': ['Network Quantization', 'Zero-shot Quantization']}","{'value': ""How can we accurately quantize a pre-trained model without any data?\nQuantization algorithms are widely used for deploying neural networks on resource-constrained edge devices.\nZero-shot Quantization (ZSQ) addresses the crucial and practical scenario where training data are inaccessible for privacy or security reasons.\nHowever, three significant challenges hinder the performance of existing ZSQ methods: 1) noise in the synthetic dataset, 2) predictions based on off-target patterns, and the 3) misguidance by erroneous hard labels.\nIn this paper, we propose SynQ (Synthesis-aware Fine-tuning for Zero-shot Quantization),\na carefully designed ZSQ framework to overcome the limitations of existing methods.\nSynQ minimizes the noise from the generated samples by exploiting a low-pass filter.\nThen, SynQ trains the quantized model to improve accuracy by aligning its class activation map with the pre-trained model.\nFurthermore, SynQ mitigates misguidance from the pre-trained model's error by leveraging only soft labels for difficult samples.\nExtensive experiments show that SynQ provides the state-of-the-art accuracy, over existing ZSQ methods.""}",https://openreview.net{'value': '/pdf/90914dabfc83f4f4a635c1781bd4eea1e0a128c8.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=2mqb8bPHeb,{'value': 'T-Stitch: Accelerating Sampling in Pre-Trained Diffusion Models with Trajectory Stitching'},Zizheng Pan; Bohan Zhuang; De-An Huang; Weili Nie; Zhiding Yu; Chaowei Xiao; Jianfei Cai; Anima Anandkumar,~Zizheng_Pan1; ~Bohan_Zhuang1; ~De-An_Huang1; ~Weili_Nie1; ~Zhiding_Yu1; ~Chaowei_Xiao2; ~Jianfei_Cai1; ~Anima_Anandkumar1,"{'value': ['diffusion model', 'transformers', 'model stitching']}","{'value': 'Sampling from diffusion probabilistic models (DPMs) is often expensive for high-quality image generation and typically requires many steps with a large model. In this paper, we introduce sampling Trajectory Stitching (T-Stitch), a simple yet efficient technique to improve the sampling efficiency with little or no generation degradation. Instead of solely using a large DPM for the entire sampling trajectory, T-Stitch first leverages a smaller DPM in the initial steps as a cheap drop-in replacement of the larger DPM and switches to the larger DPM at a later stage. Our key insight is that different diffusion models learn similar encodings under the same training data distribution and smaller models are capable of generating good global structures in the early steps. Extensive experiments demonstrate that T-Stitch is training-free, generally applicable for different architectures, and complements most existing fast sampling techniques with flexible speed and quality trade-offs. On DiT-XL, for example, 40% of the early timesteps can be safely replaced with a 10x faster DiT-S without performance drop on class-conditional ImageNet generation. We further show that our method can also be used as a drop-in technique to not only accelerate the popular pretrained stable diffusion (SD) models but also improve the prompt alignment of stylized SD models from the public model zoo. Finally, the explicit model allocation strategy of T-Stitch significantly reduces the need of training or searching, delivering high deployment efficiency.'}",https://openreview.net{'value': '/pdf/ab2f2eaf1fad1a4c3221a453d981231a07741d2b.pdf'},{'title_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=2jf5x5XoYk,{'value': 'GLoRa: A Benchmark to Evaluate the Ability to Learn Long-Range Dependencies in Graphs'},Dongzhuoran Zhou; Evgeny Kharlamov; Egor V. Kostylev,~Dongzhuoran_Zhou1; ~Evgeny_Kharlamov1; ~Egor_V._Kostylev2,"{'value': ['Graph Learning', 'Graph Neural Networks', 'Synthetic Benchmarks', 'Long-Range Dependencies']}","{'value': 'Learning on graphs is one of the most active research topics in machine learning (ML). Among the key challenges in this field, effectively learning long-range dependencies in graphs has been particularly difficult. It has been observed that, in practice, the performance of many ML approaches, including various types of graph neural networks (GNNs), degrades significantly when the learning task involves long-range dependencies—that is, when the answer is determined by the presence of a certain path of significant length in the graph. This issue has been attributed to several phenomena, including over-smoothing, over-squashing, and vanishing gradient. A number of solutions have been proposed to mitigate these causes. However, evaluation of these solutions is currently challenging because existing benchmarks do not effectively test systems for their ability to learn tasks based on long-range dependencies in a transparent manner. In this paper, we introduce GLoRa, a synthetic benchmark that allows testing of systems for this ability in a systematic way. We then evaluate state-of-the-art systems using GLoRa and conclude that none of them can confidently claim to learn long-range dependencies well. We also observe that this weak performance cannot be attributed to any of the three causes, highlighting the need for further investigation.'}",https://openreview.net{'value': '/pdf/63b8dde23781e0c030e7b7d19a35315e72f17d3a.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=2iCIHgE8KG,{'value': 'Discovering Temporally Compositional Neural Manifolds with Switching Infinite GPFA'},Changmin Yu; Maneesh Sahani; Máté Lengyel,~Changmin_Yu1; ~Maneesh_Sahani1; ~Máté_Lengyel1,"{'value': ['Computational neuroscience', 'neural data analysis', 'Bayesian nonparametrics', 'latent variable modelling;']}","{'value': 'Gaussian Process Factor Analysis (GPFA) is a powerful latent variable model for extracting low-dimensional manifolds underlying population neural activities. However, one limitation of standard GPFA models is that the number of latent factors needs to be pre-specified or selected through heuristic-based processes, and that all factors contribute at all times. We propose the infinite GPFA model, a fully Bayesian non-parametric extension of the classical GPFA by incorporating an Indian Buffet Process (IBP) prior over the factor loading process, such that it is possible to infer a potentially infinite set of latent factors, and the identity of those factors that contribute to neural firings in a compositional manner at \\textit{each} time point. Learning and inference in the infinite GPFA model is performed through variational expectation-maximisation, and we additionally propose scalable extensions based on sparse variational Gaussian Process methods. We empirically demonstrate that the infinite GPFA model correctly infers dynamically changing activations of latent factors on a synthetic dataset. By fitting the infinite GPFA model to population activities of hippocampal place cells during spatial tasks with alternating random foraging and spatial memory phases, we identify novel non-trivial and behaviourally meaningful dynamics in the neural encoding process.'}",https://openreview.net{'value': '/pdf/765376465fdc570f10ab623bfa5f0b4598499d15.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=2U8owdruSQ,{'value': 'Has the Deep Neural Network learned the Stochastic Process? An Evaluation Viewpoint'},Harshit Kumar; Beomseok Kang; Biswadeep Chakraborty; Saibal Mukhopadhyay,~Harshit_Kumar2; ~Beomseok_Kang1; ~Biswadeep_Chakraborty1; ~Saibal_Mukhopadhyay2,"{'value': ['evaluation', 'deep neural network', 'stochasticity', 'complex systems', 'forecasting']}","{'value': ""This paper presents the first systematic study of evaluating Deep Neural Networks (DNNs) designed to forecast the evolution of stochastic complex systems. We show that traditional evaluation methods like threshold-based classification metrics and error-based scoring rules assess a DNN's ability to replicate the observed ground truth but fail to measure the DNN's learning of the underlying stochastic process. To address this gap, we propose a new evaluation criteria called _Fidelity to Stochastic Process (F2SP)_, representing the DNN's ability to predict the system property _Statistic-GT_—the ground truth of the stochastic process—and introduce an evaluation metric that exclusively assesses F2SP. We formalize F2SP within a stochastic framework and establish criteria for validly measuring it. We formally show that Expected Calibration Error (ECE) satisfies the necessary condition for testing F2SP, unlike traditional evaluation methods. Empirical experiments on synthetic datasets, including wildfire, host-pathogen, and stock market models, demonstrate that ECE uniquely captures F2SP. We further extend our study to real-world wildfire data, highlighting the limitations of conventional evaluation and discuss the practical utility of incorporating F2SP into model assessment. This work offers a new perspective on evaluating DNNs modeling complex systems by emphasizing the importance of capturing underlying the stochastic process.""}",https://openreview.net{'value': '/pdf/b06ae0fc426f0b455068cfcf40a18ae1875a5d09.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=2NqssmiXLu,{'value': 'Automated Proof Generation for Rust Code via Self-Evolution'},Tianyu Chen; Shuai Lu; Shan Lu; Yeyun Gong; Chenyuan Yang; Xuheng Li; Md Rakib Hossain Misu; Hao Yu; Nan Duan; Peng CHENG; Fan Yang; Shuvendu K Lahiri; Tao Xie; Lidong Zhou,~Tianyu_Chen4; ~Shuai_Lu1; ~Shan_Lu9; ~Yeyun_Gong2; ~Chenyuan_Yang1; ~Xuheng_Li2; ~Md_Rakib_Hossain_Misu1; ~Hao_Yu11; ~Nan_Duan1; ~Peng_CHENG4; ~Fan_Yang28; ~Shuvendu_K_Lahiri1; ~Tao_Xie4; ~Lidong_Zhou1,"{'value': ['Large Language Models', 'Program Verification']}","{'value': 'Ensuring correctness is crucial for code generation. Formal verification offers a\ndefinitive assurance of correctness, but demands substantial human effort in proof\nconstruction and hence raises a pressing need for automation. The primary obsta-\ncle lies in the severe lack of data—there is much fewer proofs than code snippets\nfor Large Language Models (LLMs) to train upon. In this paper, we introduce\nSAFE, a framework that overcomes the lack of human-written proofs to enable\nautomated proof generation of Rust code. SAFE establishes a self-evolving cycle\nwhere data synthesis and fine-tuning collaborate to enhance the model capability,\nleveraging the definitive power of a symbolic verifier in telling correct proofs from\nincorrect ones. SAFE also re-purposes the large number of synthesized incorrect\nproofs to train the self-debugging capability of the fine-tuned models, empowering\nthem to fix incorrect proofs based on the verifier’s feedback. SAFE demonstrates\nsuperior efficiency and precision compared to GPT-4o. Through tens of thousands\nof synthesized proofs and the self-debugging mechanism, we improve the capa-\nbility of open-source models, initially unacquainted with formal verification, to\nautomatically write proofs for Rust code. This advancement leads to a signifi-\ncant improvement in performance, achieving a 52.52% accuracy rate in a bench-\nmark crafted by human experts, a significant leap over GPT-4o’s performance of\n14.39%.'}",https://openreview.net{'value': '/pdf/3db1c441b65ef9e2843e7519ca8ea921e82493b5.pdf'},{'abstract_filter': 'Data Synthesis'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=2G021ZqUEZ,{'value': 'From Commands to Prompts: LLM-based Semantic File System for AIOS'},Zeru Shi; Kai Mei; Mingyu Jin; Yongye Su; Chaoji Zuo; Wenyue Hua; Wujiang Xu; Yujie Ren; Zirui Liu; Mengnan Du; Dong Deng; Yongfeng Zhang,~Zeru_Shi1; ~Kai_Mei1; ~Mingyu_Jin1; ~Yongye_Su1; ~Chaoji_Zuo1; ~Wenyue_Hua1; ~Wujiang_Xu1; ~Yujie_Ren1; ~Zirui_Liu1; ~Mengnan_Du1; ~Dong_Deng1; ~Yongfeng_Zhang1,"{'value': ['Large Language Model', 'Semantic File System']}","{'value': 'Large language models (LLMs) have demonstrated significant potential in the development of intelligent LLM-based agents. However, when users use these agent applications to perform file operations, their interaction with the file system still remains the traditional paradigm: reliant on manual navigation through precise commands. This paradigm poses a bottleneck to the usability of these systems as users are required to navigate complex folder hierarchies and remember cryptic file names. To address this limitation, we propose an LLM-based Semantic File System (LSFS) for prompt-driven file management in LLM Agent Operating System (AIOS). Unlike conventional approaches, LSFS incorporates LLMs to enable users or agents to interact with files through natural language prompts, facilitating\nsemantic file management. At the macro-level, we develop a comprehensive API set to achieve semantic file management functionalities, such as semantic file retrieval, file update summarization, and semantic file rollback). At the micro-level, we store files by constructing semantic indexes for them, design and implement syscalls of different semantic operations, e.g., CRUD (create, read, update, delete),\ngroup by, join. Our experiments show that LSFS can achieve at least 15% retrieval accuracy improvement with 2.1× higher retrieval speed in the semantic file retrieval task compared with the traditional file system. In the traditional keyword-based file retrieval task (i.e., retrieving by string-matching), LSFS also performs stably well, i.e., over 89% F1-score with improved usability, especially when the keyword conditions become more complex. Additionally, LSFS supports more advanced file management operations, i.e., semantic file rollback and file sharing and achieves 100% success rates in these tasks, further suggesting the capability of LSFS . The code is available at https://github.com/agiresearch/AIOS-LSFS.'}",https://openreview.net{'value': '/pdf/649413a6a31c867e3b047ab4faa85eb2e960de94.pdf'},{'abstract_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=293V3bJbmE,{'value': 'HELMET: How to Evaluate Long-context Models Effectively and Thoroughly'},Howard Yen; Tianyu Gao; Minmin Hou; Ke Ding; Daniel Fleischer; Peter Izsak; Moshe Wasserblat; Danqi Chen,~Howard_Yen1; ~Tianyu_Gao1; ~Minmin_Hou1; ~Ke_Ding2; ~Daniel_Fleischer1; ~Peter_Izsak1; ~Moshe_Wasserblat1; ~Danqi_Chen1,"{'value': ['long-context language models', 'benchmarking']}","{'value': 'Many benchmarks exist for evaluating long-context language models (LCLMs), yet developers often rely on synthetic tasks such as needle-in-a-haystack (NIAH) or an arbitrary subset of tasks. However, it remains unclear whether these benchmarks reflect the diverse downstream applications of LCLMs, and such inconsistencies further complicate model comparison. We investigate the underlying reasons behind these practices and find that existing benchmarks often provide noisy signals due to limited coverage of applications, insufficient context lengths, unreliable metrics, and incompatibility with base models. In this work, we introduce HELMET (How to Evaluate Long-context Models Effectively and Thoroughly), a comprehensive benchmark encompassing seven diverse, application-centric categories. We also address several issues in previous benchmarks by adding controllable lengths up to 128K tokens, model-based evaluation for reliable metrics, and few-shot prompting for robustly evaluating base models. Consequently, we demonstrate that HELMET offers more reliable and consistent rankings of frontier LCLMs. Through a comprehensive study of 59 LCLMs, we find that (1) synthetic tasks like NIAH do not reliably predict downstream performance; (2) the diverse categories in HELMET exhibit distinct trends and low correlations with each other; and (3) while most LCLMs achieve perfect NIAH scores, open-source models significantly lag behind closed ones when tasks require full-context reasoning or following complex instructions---the gap widens as length increases. Finally, we recommend using our RAG tasks for fast model development, as they are easy to run and better predict other downstream performance; ultimately, we advocate for a holistic evaluation across diverse tasks.'}",https://openreview.net{'value': '/pdf/863ad3ae937a1a3c33d826adeb4f4f29cf61a6e3.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=28qOQwjuma,{'value': 'Beyond Graphs: Can Large Language Models Comprehend Hypergraphs?'},Yifan Feng; Chengwu Yang; Xingliang Hou; Shaoyi Du; Shihui Ying; Zongze Wu; Yue Gao,~Yifan_Feng1; ~Chengwu_Yang1; ~Xingliang_Hou1; ~Shaoyi_Du2; ~Shihui_Ying1; ~Zongze_Wu3; ~Yue_Gao4,"{'value': ['LLMs', 'Hypergraph', 'Benchmark']}","{'value': 'Existing benchmarks like NLGraph and GraphQA evaluate LLMs on graphs by focusing mainly on pairwise relationships, overlooking the high-order correlations found in real-world data. Hypergraphs, which can model complex beyond-pairwise relationships, offer a more robust framework but are still underexplored in the context of LLMs. To address this gap, we introduce LLM4Hypergraph, the first comprehensive benchmark comprising 21,500 problems across eight low-order, five high-order, and two isomorphism tasks, utilizing both synthetic and real-world hypergraphs from citation networks and protein structures. We evaluate six prominent LLMs, including GPT-4o, demonstrating our benchmark’s effectiveness in identifying model strengths and weaknesses. Our specialized prompt- ing framework incorporates seven hypergraph languages and introduces two novel techniques, Hyper-BAG and Hyper-COT, which enhance high-order reasoning and achieve an average 4% (up to 9%) performance improvement on structure classification tasks. This work establishes a foundational testbed for integrating hypergraph computational capabilities into LLMs, advancing their comprehension.'}",https://openreview.net{'value': '/pdf/b7bebe537f1b92e8ce617e43c1566fa2ca94df68.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=28abpUEICJ,{'value': 'CREIMBO: Cross-Regional Ensemble Interactions in Multi-view Brain Observations'},Noga Mudrik; Ryan Ly; Oliver Ruebel; Adam Shabti Charles,~Noga_Mudrik1; ~Ryan_Ly1; ~Oliver_Ruebel1; ~Adam_Shabti_Charles1,"{'value': ['computational neuroscience', 'multi-regional brain interactions', 'sparsity', 'cross-session variability', 'dynamical systems modeling', 'neural dynamics', 'non-simultaneous neural recordings']}","{'value': ""Modern recordings of neural activity provide diverse observations of neurons across brain areas, behavioral conditions, and subjects; presenting an exciting opportunity to reveal the fundamentals of brain-wide dynamics. Current analysis methods, however, often fail to fully harness the richness of such data, as they provide either uninterpretable representations (e.g., via deep networks) or oversimplify models (e.g., by assuming stationary dynamics or analyzing each session independently). Here, instead of regarding asynchronous neural recordings that lack alignment in neural identity or brain areas as a limitation, we leverage these diverse views into the brain to learn a unified model of neural dynamics. Specifically, we assume that brain activity is driven by multiple hidden global sub-circuits. These sub-circuits represent global basis interactions between neural ensembles—functional groups of neurons—such that the time-varying decomposition of these sub-circuits defines how the ensembles' interactions evolve over time non-stationarily and non-linearly.\nWe discover the neural ensembles underlying non-simultaneous observations, along with their non-stationary evolving interactions, with our new model, **CREIMBO** (**C**ross-**R**egional **E**nsemble **I**nteractions in **M**ulti-view **B**rain **O**bservations). CREIMBO identifies the hidden composition of per-session neural ensembles through novel graph-driven dictionary learning and models the ensemble dynamics on a low-dimensional manifold spanned by a sparse time-varying composition of the global sub-circuits. Thus, CREIMBO disentangles overlapping temporal neural processes while preserving interpretability due to the use of a shared underlying sub-circuit basis. Moreover, CREIMBO distinguishes session-specific computations from global (session-invariant) ones by identifying session covariates and variations in sub-circuit activations. We demonstrate CREIMBO's ability to recover true components in synthetic data, and uncover meaningful brain dynamics in human high-density electrode recordings, including cross-subject neural mechanisms as well as  inter- vs. intra-region dynamical motifs. Furthermore, using mouse whole-brain recordings, we show CREIMBO's ability to discover dynamical interactions that capture task and behavioral variables and meaningfully align with the biological importance of the brain areas they represent.""}",https://openreview.net{'value': '/pdf/3d88937c42e1c5261ec56c1c16eba6db80855750.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=1z3SOCwst9,{'value': 'Differentially private learners for heterogeneous treatment effects'},Maresa Schröder; Valentyn Melnychuk; Stefan Feuerriegel,~Maresa_Schröder1; ~Valentyn_Melnychuk1; ~Stefan_Feuerriegel1,"{'value': ['Causality', 'differential privacy', 'treatment effect estimation']}","{'value': 'Patient data is widely used to estimate heterogeneous treatment effects and understand the effectiveness and safety of drugs. Yet, patient data includes highly\nsensitive information that must be kept private. In this work, we aim to estimate\nthe conditional average treatment effect (CATE) from observational data under\ndifferential privacy. Specifically, we present DP-CATE, a novel framework for\nCATE estimation that is *Neyman-orthogonal* and ensures *differential privacy* of the estimates.\n Our framework is highly general: it applies to any two-stage\nCATE meta-learner with a Neyman-orthogonal loss function and any machine\nlearning model can be used for nuisance estimation. We further provide an extension of our DP-CATE, where we employ RKHS regression to release the complete\nCATE function while ensuring differential privacy. We demonstrate the effectiveness of DP-CATE across various experiments using synthetic and real-world\ndatasets. To the best of our knowledge, we are the first to provide a framework for\nCATE estimation that is doubly robust and differentially private.'}",https://openreview.net{'value': '/pdf/826133444ab913f4ae2058d8bce5e41a18c80c12.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=1aF2D2CPHi,{'value': 'Open-Vocabulary Customization from CLIP via Data-Free Knowledge Distillation'},Yongxian Wei; Zixuan Hu; Li Shen; Zhenyi Wang; Chun Yuan; Dacheng Tao,~Yongxian_Wei1; ~Zixuan_Hu1; ~Li_Shen1; ~Zhenyi_Wang1; ~Chun_Yuan1; ~Dacheng_Tao1,"{'value': ['Data-Free Learning', 'CLIP Model', 'Customization']}","{'value': 'Vision-language models such as CLIP have demonstrated strong zero-shot performance, but their considerable size and inefficient inference limit customizable deployment for users. While knowledge distillation is a solution, it still requires the original data, which is not always available due to copyrights and privacy concerns. For many users seeking open-vocabulary customization, Data-Free Knowledge Distillation (DFKD) emerges as a promising direction. Upon rethinking DFKD, we find that existing methods fail on CLIP due to their heavy reliance on BatchNorm layers, which are unexpectedly unusable in CLIP. Based on our findings, we adopt image-text matching to achieve DFKD for CLIP, enabling customization based on arbitrary class texts. This involves (i) inversing a surrogate dataset from CLIP based on text prompts; and (ii) distilling a student model from CLIP using the surrogate dataset. Specifically, we introduce style dictionary diversification to enhance the diversity of synthetic images. To prevent uncontrollable semantics introduced by diversification, we propose a class consistency maintaining strategy to ensure the consistency of synthetic images. Based on synthetic images with various styles, we further propose meta knowledge distillation to train the student model with good generalization ability. Moreover, we introduce a simple yet effective method to enable customization based on few example images. Comprehensive experiments showcase the superiority of our approach across twelve customized tasks, achieving a 9.33\\% improvement compared to existing DFKD methods.'}",https://openreview.net{'value': '/pdf/71b13cef3e274c5ae52fdee5ee93a77c280367f0.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=1Xg4JPPxJ0,{'value': 'Are Transformers Able to Reason by Connecting Separated Knowledge in Training Data?'},Yutong Yin; Zhaoran Wang,~Yutong_Yin1; ~Zhaoran_Wang1,{'value': ['Transformer; Chain-of-Thought; In-Context-Learning; Compositional Generalization']},"{'value': 'Humans exhibit remarkable compositional reasoning by integrating knowledge from various sources. For example, if someone learns ( B = f(A) ) from one source and ( C = g(B) ) from another, they can deduce ( C=g(B)=g(f(A)) ) even without encountering ( ABC ) together, showcasing the generalization ability of human intelligence.  In this paper, we introduce a synthetic learning task, ""FTCT"" (Fragmented at Training, Chained at Testing), to validate the potential of  Transformers in replicating this skill and interpret its inner mechanism. During training, data consist of separated knowledge fragments from an overall causal graph. In testing, Transformers must combine these fragments to infer complete causal traces. Our findings demonstrate that few-shot Chain-of-Thought prompting enables Transformers to perform compositional reasoning on FTCT by revealing correct combinations of fragments, even if such combinations were absent in training data. Furthermore, the emergence of compositional reasoning ability is strongly correlated with model complexity and training-testing data similarity. We propose, both theoretically and empirically, that Transformers learn an underlying generalizable program from training, enabling effective compositional reasoning during testing.'}",https://openreview.net{'value': '/pdf/2d58475d0979133db2c7fb27c2e5abc6899ae229.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=1ThYY28HXg,{'value': 'GenXD: Generating Any 3D and 4D Scenes'},Yuyang Zhao; Chung-Ching Lin; Kevin Lin; Zhiwen Yan; Linjie Li; Zhengyuan Yang; Jianfeng Wang; Gim Hee Lee; Lijuan Wang,~Yuyang_Zhao1; ~Chung-Ching_Lin2; ~Kevin_Lin3; ~Zhiwen_Yan1; ~Linjie_Li1; ~Zhengyuan_Yang1; ~Jianfeng_Wang4; ~Gim_Hee_Lee1; ~Lijuan_Wang1,{'value': ['3D Generation; 4D Generation; Diffusion Models']},"{'value': ""Recent developments in 2D visual generation have been remarkably successful. However, 3D and 4D generation remain challenging in real-world applications due to the lack of large-scale 4D data and effective model design. In this paper, we propose to jointly investigate general 3D and 4D generation by leveraging camera and object movements commonly observed in daily life. Due to the lack of real-world 4D data in the community, we first propose a data curation pipeline to obtain camera poses and object motion strength from videos. Based on this pipeline, we introduce a large-scale real-world 4D scene dataset: CamVid-30K. By leveraging all the 3D and 4D data, we develop our framework, GenXD, which allows us to produce any 3D or 4D scene. We propose multiview-temporal modules, which disentangle camera and object movements, to seamlessly learn from both 3D and 4D data. Additionally, GenXD employs masked latent conditions to support a variety of conditioning views. GenXD can generate videos that follow the camera trajectory as well as consistent 3D views that can be lifted into 3D representations. We perform extensive evaluations across various real-world and synthetic datasets, demonstrating GenXD's effectiveness and versatility compared to previous methods in 3D and 4D generation.""}",https://openreview.net{'value': '/pdf/9d5093dc340c035ddcd2c3403f0230977bd62c52.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=1Iuw1jcIrf,{'value': 'MathCoder2: Better Math Reasoning from Continued Pretraining on Model-translated Mathematical Code'},Zimu Lu; Aojun Zhou; Ke Wang; Houxing Ren; Weikang Shi; Junting Pan; Mingjie Zhan; Hongsheng Li,~Zimu_Lu1; ~Aojun_Zhou2; ~Ke_Wang18; ~Houxing_Ren1; ~Weikang_Shi1; ~Junting_Pan2; ~Mingjie_Zhan1; ~Hongsheng_Li3,"{'value': ['large language model', 'mathematical reasoning', 'continued pretraining']}","{'value': 'Code has been shown to be effective in enhancing the mathematical reasoning abilities of large language models due to its precision and accuracy. Previous works involving continued mathematical pretraining  often include code that utilizes math-related packages, which are primarily designed for fields such as engineering, machine learning, signal processing, or module testing, rather than being directly focused on mathematical reasoning. In this paper, we introduce a novel method for generating mathematical code accompanied with corresponding reasoning steps for continued pretraining. Our approach begins with the construction of a high-quality mathematical continued pretraining dataset by incorporating math-related web data, code using mathematical packages, math textbooks, and synthetic data. Next, we construct reasoning steps by extracting LaTeX expressions, the conditions needed for the expressions, and the results of the expressions from the previously collected dataset. Based on this extracted information, we generate corresponding code to accurately capture the mathematical reasoning process. Appending the generated code to each reasoning step results in data consisting of paired natural language reasoning steps and their corresponding code. Combining this data with the original dataset results in a 19.2B-token high-performing mathematical pretraining corpus, which we name MathCode-Pile. Training several popular base models with this corpus significantly improves their mathematical abilities, leading to the creation of the MathCoder2 family of models. All of our data processing and training code is open-sourced, ensuring full transparency and easy reproducibility of the entire data collection and training pipeline.'}",https://openreview.net{'value': '/pdf/6554080c76107a601b5c1eef919d41b97418128e.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=1CIUkpoata,{'value': '6D Object Pose Tracking in Internet Videos for Robotic Manipulation'},Georgy Ponimatkin; Martin Cífka; Tomas Soucek; Médéric Fourmy; Yann Labbé; Vladimir Petrik; Josef Sivic,~Georgy_Ponimatkin1; ~Martin_Cífka1; ~Tomas_Soucek1; ~Médéric_Fourmy1; ~Yann_Labbé1; ~Vladimir_Petrik2; ~Josef_Sivic1,"{'value': ['6DoF pose estimation', 'robotic manipulation from video']}","{'value': 'We seek to extract a temporally consistent 6D pose trajectory of a manipulated  object from an Internet instructional video. This is a challenging set-up for current 6D pose estimation methods due to uncontrolled capturing conditions, subtle but dynamic object motions, and the fact that the exact mesh of the manipulated object is not known. To address these challenges, we present the following contributions. First, we develop a new method that estimates the 6D pose of any object in the input image without prior knowledge of the object itself. The method proceeds by (i) retrieving a CAD model similar to the depicted object from a large-scale model database, (ii) 6D aligning the retrieved CAD model with the input image, and (iii) grounding the absolute scale of the object with respect to the scene. Second, we extract smooth 6D object trajectories from Internet videos by carefully tracking the detected objects across video frames. The extracted object trajectories are then retargeted via trajectory optimization into the configuration space of a robotic manipulator. Third, we thoroughly evaluate and ablate our 6D pose estimation method on YCB-V and HOPE-Video datasets as well as a new dataset of instructional videos manually annotated with approximate 6D object trajectories. We demonstrate significant improvements over existing state-of-the-art RGB 6D pose estimation methods. Finally,  we show that the 6D object motion estimated from Internet videos can be transferred to a 7-axis robotic manipulator both in a virtual simulator as well as in a real world set-up. We also successfully apply our method to egocentric videos taken from the EPIC-KITCHENS dataset, demonstrating potential for Embodied AI applications.'}",https://openreview.net{'value': '/pdf/b4cc76259c4c3f2b3ef42f95addddbab181921a6.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=0whx8MhysK,{'value': 'Influence-Guided Diffusion for Dataset Distillation'},Mingyang Chen; Jiawei Du; Bo Huang; Yi Wang; Xiaobo Zhang; Wei Wang,~Mingyang_Chen4; ~Jiawei_Du1; ~Bo_Huang6; ~Yi_Wang18; ~Xiaobo_Zhang4; ~Wei_Wang55,"{'value': ['Dataset Distillation', 'Dataset Condensation', 'Diffusion Model', 'Guided Diffusion Generation']}","{'value': 'Dataset distillation aims to streamline the training process by creating a compact yet effective dataset for a much larger original dataset. However, existing methods often struggle with distilling large, high-resolution datasets due to prohibitive resource costs and limited performance, primarily stemming from sample-wise optimizations in the pixel space. Motivated by the remarkable capabilities of diffusion generative models in learning target dataset distributions and controllably sampling high-quality data tailored to user needs, we propose framing dataset distillation as a controlled diffusion generation task aimed at generating data specifically tailored for effective training purposes. By establishing a correlation between the overarching objective of dataset distillation and the trajectory influence function, we introduce the Influence-Guided Diffusion (IGD) sampling framework to generate training-effective data without the need to retrain diffusion models. An efficient guided function is designed by leveraging the trajectory influence function as an indicator to steer diffusions to produce data with influence promotion and diversity enhancement. Extensive experiments show that the training performance of distilled datasets generated by diffusions can be significantly improved by integrating with our IGD method and achieving state-of-the-art performance in distilling ImageNet datasets. Particularly, an exceptional result is achieved on the ImageNet-1K, reaching 60.3\\% at IPC=50. Our code is available at https://github.com/mchen725/DD_IGD.'}",https://openreview.net{'value': '/pdf/cbb4e113bb5de2422391d66ad6c2ebf4db6ee12f.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=0no1Wp2R2j,{'value': 'Going Beyond Feature Similarity: Effective Dataset distillation based on Class-aware Conditional Mutual Information'},Xinhao Zhong; Bin Chen; Hao Fang; Xulin Gu; Shu-Tao Xia; EN-HUI YANG,~Xinhao_Zhong2; ~Bin_Chen4; ~Hao_Fang8; ~Xulin_Gu1; ~Shu-Tao_Xia1; ~EN-HUI_YANG1,"{'value': ['dataset distillation', 'conditional mutual information']}","{'value': 'Dataset distillation (DD) aims to minimize the time and memory consumption needed for training deep neural networks on large datasets, by creating a smaller synthetic dataset that has similar performance to that of the full real dataset. However, current dataset distillation methods often result in synthetic datasets that are excessively difficult for networks to learn from, due to the compression of a substantial amount of information from the original data through metrics measuring feature similarity, e,g., distribution matching (DM). In this work, we introduce conditional mutual information (CMI) to assess the class-aware complexity of a dataset and propose a novel method by minimizing CMI. Specifically, we minimize the distillation loss while constraining the class-aware complexity of the synthetic dataset by minimizing its empirical CMI from the feature space of pre-trained networks, simultaneously. Conducting on a thorough set of experiments, we show that our method can serve as a general regularization method to existing DD methods and improve the performance and training efficiency.'}",https://openreview.net{'value': '/pdf/4d50e80a3e344361068f76c75ecd919c4421f967.pdf'},{'abstract_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=0bmGL4q7vJ,{'value': 'Multi-modal Agent Tuning: Building a VLM-Driven Agent for Efficient Tool Usage'},Zhi Gao; Bofei Zhang; Pengxiang Li; Xiaojian Ma; Tao Yuan; Yue Fan; Yuwei Wu; Yunde Jia; Song-Chun Zhu; Qing Li,~Zhi_Gao5; ~Bofei_Zhang1; ~Pengxiang_Li1; ~Xiaojian_Ma1; ~Tao_Yuan6; ~Yue_Fan2; ~Yuwei_Wu1; ~Yunde_Jia1; ~Song-Chun_Zhu1; ~Qing_Li1,"{'value': ['Multimodal Agents', 'Vision-language Model', 'Tool usage']}","{'value': 'The advancement of large language models (LLMs) prompts the development of multi-modal agents, which are used as a controller to call external tools, providing a feasible way to solve practical tasks. In this paper, we propose a multi-modal agent tuning method that automatically generates multi-modal tool-usage data and tunes a vision-language model (VLM) as the controller for powerful tool-usage reasoning. To preserve the data quality, we prompt the GPT-4o mini model to generate queries, files, and trajectories, followed by query-file and trajectory verifiers. Based on the data synthesis pipeline, we collect the MM-Traj dataset that contains 20K tasks with trajectories of tool usage. Then, we develop the T3-Agent via Trajectory Tuning on VLMs for Tool usage using MM-Traj. Evaluations on the GTA and GAIA benchmarks show that the T3-Agent consistently achieves improvements on two popular VLMs: MiniCPM-V-8.5B and Qwen2-VL-7B, which outperforms untrained VLMs by 20%, showing the effectiveness of the proposed data synthesis pipeline, leading to high-quality data for tool-usage capabilities.'}",https://openreview.net{'value': '/pdf/5023fe68ab67d9e72385045030a9d62d49bf747d.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=0UvlnHgaii,{'value': 'Toward Exploratory Inverse Constraint Inference with Generative Diffusion Verifiers'},Runyi Zhao; Sheng Xu; Bo Yue; Guiliang Liu,~Runyi_Zhao1; ~Sheng_Xu8; ~Bo_Yue1; ~Guiliang_Liu1,"{'value': ['Inverse Reinforcement Learning', 'Generative Diffusion Model']}","{'value': ""An important prerequisite for safe control is aligning the policy with the underlying constraints in the environment. In many real-world applications, due to the difficulty of manually specifying these constraints, existing works have proposed recovering constraints from expert demonstrations by solving the Inverse Constraint Learning (ICL) problem. However, ICL is inherently ill-posed, as multiple constraints can equivalently explain the experts' preferences, making the optimal solutions not uniquely identifiable. In this work, instead of focusing solely on a single constraint, we propose the novel approach of Exploratory ICL (ExICL). The goal of ExICL is to recover a diverse set of feasible constraints, thereby providing practitioners the flexibility to select the most appropriate constraint based on the practical needs of deployment. To achieve this goal, we design a generative diffusion verifier that guides the trajectory generation process using the probabilistic representation of an optimal constrained policy. By comparing these decisions with those made by expert agents, we can efficiently verify a candidate constraint. Driven by the verification feedback, ExICL implements an exploratory constraint update mechanism that strategically facilitates diversity within the collection of feasible constraints. Our empirical results demonstrate that ExICL can seamlessly and reliably generalize across different tasks and environments. The code is available at https://github.com/ZhaoRunyi/ExICL.""}",https://openreview.net{'value': '/pdf/93382d6a85d87cda83e88ec95bbffdabc6d2e2e4.pdf'},{'abstract_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=0FK6tzqV76,{'value': 'RTDiff: Reverse Trajectory Synthesis via Diffusion for Offline Reinforcement Learning'},Qianlan Yang; Yu-Xiong Wang,~Qianlan_Yang1; ~Yu-Xiong_Wang1,"{'value': ['Reinforcement Learning', 'Diffusion Model', 'Reverse Synthesize']}","{'value': ""In offline reinforcement learning (RL), managing the distribution shift between the learned policy and the static offline dataset is a persistent challenge that can result in overestimated values and suboptimal policies. Traditional offline RL methods address this by introducing conservative biases that limit exploration to well-understood regions, but they often overly restrict the agent's generalization capabilities. Recent work has sought to generate trajectories using generative models to augment the offline dataset, yet these methods still struggle with overestimating synthesized data, especially when out-of-distribution samples are produced. To overcome this issue, we propose RTDiff, a novel diffusion-based data augmentation technique that synthesizes trajectories *in reverse*, moving from unknown to known states. Such reverse generation naturally mitigates the risk of overestimation by ensuring that the agent avoids planning through unknown states. Additionally, reverse trajectory synthesis allows us to generate longer, more informative trajectories that take full advantage of diffusion models' generative strengths while ensuring reliability. We further enhance RTDiff by introducing flexible trajectory length control and improving the efficiency of the generation process through noise management. Our empirical results show that RTDiff significantly improves the performance of several state-of-the-art offline RL algorithms across diverse environments, achieving consistent and superior results by effectively overcoming distribution shift.""}",https://openreview.net{'value': '/pdf/148b8387321b7e4b640b74802074ee7b608c5435.pdf'},{'title_filter': 'Trajectory'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=07yvxWDSla,{'value': 'Synthetic continued pretraining'},Zitong Yang; Neil Band; Shuangping Li; Emmanuel Candes; Tatsunori Hashimoto,~Zitong_Yang1; ~Neil_Band1; ~Shuangping_Li1; ~Emmanuel_Candes1; ~Tatsunori_Hashimoto1,"{'value': ['large language model', 'synthetic data', 'continued pretraining']}","{'value': 'Pretraining on large-scale, unstructured internet text enables language models to acquire a significant amount of world knowledge.\nHowever, this knowledge acquisition is data-inefficient---to learn a fact, models must be trained on hundreds to thousands of diverse representations of it.\nThis poses a challenge when adapting a pretrained model to a small corpus of domain-specific documents, where each fact may appear rarely or only once.\nWe propose to bridge this gap with synthetic continued pretraining: using the small domain-specific corpus to synthesize a large corpus more amenable to learning, and then performing continued pretraining on the synthesized corpus.\nWe instantiate this proposal with EntiGraph, a synthetic data augmentation algorithm that extracts salient entities from the source corpus and then generates diverse text by drawing connections between those entities.\nSynthetic continued pretraining with EntiGraph enables a language model to answer questions and follow generic instructions related to the source documents without access to them.\nIf the source documents are instead available at inference time, we show that the knowledge acquired through our approach compounds with retrieval-augmented generation.\nTo better understand these results, we build a simple mathematical model of EntiGraph, and show how synthetic data augmentation can ""rearrange"" knowledge to enable more data-efficient learning.'}",https://openreview.net{'value': '/pdf/bbe1cf6cdf98071c9a09408c158569879df7c0df.pdf'},{'title_filter': 'Synthetic'},ICLR.cc,2025,Conference
https://openreview.net/forum?id=00SnKBGTsz,{'value': 'DataEnvGym: Data Generation Agents in Teacher Environments with Student Feedback'},Zaid Khan; Elias Stengel-Eskin; Jaemin Cho; Mohit Bansal,~Zaid_Khan1; ~Elias_Stengel-Eskin1; ~Jaemin_Cho1; ~Mohit_Bansal2,"{'value': ['iterative data generation', 'llm agent', 'lifelong learning']}","{'value': 'The process of creating training data to teach models is currently driven by humans, who manually analyze model weaknesses and plan how to create data that improves a student model. Recent approaches using large language models (LLMs) as annotators reduce human annotation effort, but still require humans to interpret feedback from evaluations and control the LLM to produce data the student needs. Automating this labor-intensive process by creating autonomous data generation agents – or teachers – is desirable, but requires environments that can simulate the feedback-driven, iterative, closed loop of data creation. To enable rapid and scalable testing for such agents and their modules, we introduce DataEnvGym, a testbed of teacher environments for data generation agents. DataEnvGym frames data generation as a sequential decision-making task, involving an agent consisting of a data generation policy (which generates a plan for creating training data) and a data generation engine (which transforms the plan into data), inside an environment that provides feedback from a student. The agent’s end goal is to improve student model performance. Students are iteratively trained and evaluated on generated data, with their feedback (in the form of errors or weak skills) being reported to the agent after each iteration. As a general-purpose testbed, DataEnvGym includes multiple instantiations of teacher environments across three levels of structure in the state representation and action space, with varying levels of scaffolding support. More structured environments are based on automatically-inferred skills and offer a higher degree of interpretability and control over the curriculum. We support developing and testing data generation agents in four diverse tasks covering text, images, and actions (mathematics, programming, visual question answering, and tool-use) and test multiple student and teacher models. We find that example agents in our teaching environments can iteratively improve students across diverse tasks and settings. Moreover, we show that environments can teach different skill levels and can be used to test variants of key modules, pointing to directions of future work in improving data generation agents, engines, and feedback mechanisms. Project page: https://DataEnvGym.github.io.'}",https://openreview.net{'value': '/pdf/0cbfdbd88636d0adb0916637c8ca3029a3d03c10.pdf'},{'title_filter': 'Agent'},ICLR.cc,2025,Conference
