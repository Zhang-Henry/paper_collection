forum,title,authors,authorids,keywords,abstract,pdf,match,venue,year,type
https://openreview.net/forum?id=zIb2DlqBxm,{'value': 'PHD: Pixel-Based Language Modeling of Historical Documents'},Nadav Borenstein; Phillip Rust; Desmond Elliott; Isabelle Augenstein,~Nadav_Borenstein1; ~Phillip_Rust1; ~Desmond_Elliott1; ~Isabelle_Augenstein1,"{'value': ['Visual language modelling', 'Historical documents', 'Multimodal models']}","{'value': ""The digitisation of historical documents has provided historians with unprecedented research opportunities. Yet, the conventional approach to analysing historical documents involves converting them from images to text using OCR, a process that overlooks the potential benefits of treating them as images and introduces high levels of noise. To bridge this gap, we take advantage of recent advancements in pixel-based language models trained to reconstruct masked patches of pixels instead of predicting token distributions. Due to the scarcity of real historical scans, we propose a novel method for generating synthetic scans to resemble real historical documents. We then pre-train our model, PHD, on a combination of synthetic scans and real historical newspapers from the 1700-1900 period. Through our experiments, we demonstrate that PHD exhibits high proficiency in reconstructing masked image patches and provide evidence of our model's noteworthy language understanding capabilities. Notably, we successfully apply our model to a historical QA task, highlighting its usefulness in this domain.""}",https://openreview.net{'value': '/attachment/1755d499100b87fc32e92f0c2797ebeb68ddfe31.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=yO4cAfFjlp,{'value': 'Theory of Mind for Multi-Agent Collaboration via Large Language Models'},Huao Li; Yu Quan Chong; Simon Stepputtis; Joseph Campbell; Dana Hughes; Charles Michael Lewis; Katia P. Sycara,~Huao_Li1; ~Yu_Quan_Chong1; ~Simon_Stepputtis1; ~Joseph_Campbell1; ~Dana_Hughes1; ~Charles_Michael_Lewis1; ~Katia_P._Sycara1,"{'value': ['Large Language Models', 'Multi-Agent Reinforcement Learning', 'Theory of Mind']}","{'value': ""While Large Language Models (LLMs) have demonstrated impressive accomplishments in both reasoning and planning, their abilities in multi-agent collaborations remains largely unexplored. This study evaluates LLM-based agents in a multi-agent cooperative text game with Theory of Mind (ToM) inference tasks, comparing their performance with Multi-Agent Reinforcement Learning (MARL) and planning-based baselines. We observed evidence of emergent collaborative behaviors and high-order Theory of Mind capabilities among LLM-based agents. Our results reveal limitations in LLM-based agents' planning optimization due to systematic failures in managing long-horizon contexts and hallucination about the task state. We explore the use of explicit belief state representations to mitigate these issues, finding that it enhances task performance and the accuracy of ToM inferences for LLM-based agents.""}",https://openreview.net{'value': '/attachment/20287192d1ce65afb496b0a2263ffdccc3b13c00.pdf'},{'title_filter': 'Agent'},EMNLP,2023,Conference
https://openreview.net/forum?id=xxTtwEuOpS,{'value': 'Understanding Compositional Data Augmentation in Typologically Diverse Morphological Inflection'},Farhan Samir; Miikka Silfverberg,~Farhan_Samir1; ~Miikka_Silfverberg1,"{'value': ['morphological inflection', 'computational morphology', 'data augmentation']}","{'value': 'Data augmentation techniques are widely used in low-resource automatic morphological inflection to address the issue of data sparsity. However, the full implications of these techniques remain poorly understood. In this study, we aim to shed light on the theoretical aspects of the data augmentation strategy StemCorrupt, a method that generates synthetic examples by randomly substituting stem characters in existing gold standard training examples. Our analysis uncovers that StemCorrupt brings about fundamental changes in the underlying data distribution, revealing  inherent compositional concatenative structure. To complement our theoretical analysis, we investigate the data-efficiency of StemCorrupt. Through evaluation across a diverse set of seven typologically distinct languages, we demonstrate that selecting a subset of datapoints with both high diversity \\textit{and} high predictive uncertainty significantly enhances the data-efficiency of compared to competitive baselines. Furthermore, we explore the impact of typological features on the choice of augmentation strategy and find that languages incorporating non-concatenativity, such as morphonological alternations, derive less benefit from synthetic examples with high predictive uncertainty. We attribute this effect to phonotactic violations induced by StemCorrupt, emphasizing the need for further research to ensure optimal performance across the entire spectrum of natural language morphology.'}",https://openreview.net{'value': '/attachment/378d210942e3f6f4f588df7c11cc9a65129d0424.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=x7zquRQfoB,{'value': 'How to Enhance Causal Discrimination of Utterances: A Case on Affective Reasoning'},Hang Chen; Xinyu Yang; Jing Luo; Wenjing Zhu,~Hang_Chen3; ~Xinyu_Yang2; ~Jing_Luo1; ~Wenjing_Zhu1,"{'value': ['Causal Discrimination', 'Conversation', 'Independent Noise', 'SCM']}","{'value': ""Our investigation into the Affective Reasoning in Conversation (ARC) task highlights the challenge of causal discrimination. Almost all existing models, including large language models (LLMs), excel at capturing semantic correlations within utterance embeddings but fall short in determining the specific causal relationships. To overcome this limitation, we propose the incorporation of \\textit{i.i.d.} noise terms into the conversation process, thereby constructing a structural causal model (SCM). It explores how distinct causal relationships of fitted embeddings can be discerned through independent conditions. To facilitate the implementation of deep learning, we introduce the cogn frameworks to handle unstructured conversation data, and employ an autoencoder architecture to regard the unobservable noise as learnable ``implicit causes.'' Moreover, we curate a synthetic dataset that includes i.i.d. noise. Through comprehensive experiments, we validate the effectiveness and interpretability of our approach. Our code is available in https://github.com/Zodiark-ch/mater-of-our-EMNLP2023-paper.""}",https://openreview.net{'value': '/attachment/8d8a32944bc213da708f1ba8770a3c0e472528f6.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=w4FwmICSHZ,{'value': 'Multitask Multimodal Prompted Training for Interactive Embodied Task Completion'},Georgios Pantazopoulos; Malvina Nikandrou; Amit Parekh; Bhathiya Hemanthage; Arash Eshghi; Ioannis Konstas; Verena Rieser; Oliver Lemon; Alessandro Suglia,~Georgios_Pantazopoulos1; ~Malvina_Nikandrou1; ~Amit_Parekh1; ~Bhathiya_Hemanthage1; ~Arash_Eshghi1; ~Ioannis_Konstas1; ~Verena_Rieser1; ~Oliver_Lemon1; ~Alessandro_Suglia1,"{'value': ['Vision and Language', 'Embodied AI', 'Natural Language Interaction']}","{'value': 'Interactive and embodied tasks pose at least two fundamental challenges to existing Vision \\& Language (VL) models, including 1) grounding language in trajectories of actions and observations, and 2) referential disambiguation. To tackle these challenges, we propose an Embodied MultiModal Agent (EMMA): a unified encoder-decoder model that reasons over images and trajectories, and casts action prediction as multimodal text generation. By unifying all tasks as text generation, EMMA learns a language of actions which facilitates transfer across tasks. Different to previous modular approaches with independently trained components, we use a single multitask model where each task contributes to goal completion.  EMMA  performs on par with similar models on several VL benchmarks and sets a new state-of-the-art performance (36.81\\% success rate) on the Dialog-guided Task Completion (DTC), a benchmark to evaluate dialog-guided agents in the Alexa Arena.'}",https://openreview.net{'value': '/attachment/5c1740ad856e91c16c50c0af905aa4bac5a56857.pdf'},{'abstract_filter': 'Agent'},EMNLP,2023,Conference
https://openreview.net/forum?id=ul47tFdRn6,{'value': 'DiffuVST: Narrating Fictional Scenes with Global-History-Guided Denoising Models'},Shengguang Wu; Mei Yuan; Qi Su,~Shengguang_Wu1; ~Mei_Yuan1; ~Qi_Su1,"{'value': ['visual storytelling', 'diffusion language models', 'global history guidance']}","{'value': 'Recent advances in image and video creation, especially AI-based image synthesis, have led to the production of numerous visual scenes that exhibit a high level of abstractness and diversity. Consequently, Visual Storytelling (VST), a task that involves generating meaningful and coherent narratives from a collection of images, has become even more challenging and is increasingly desired beyond real-world imagery. While existing VST techniques, which typically use autoregressive decoders, have made significant progress, they suffer from low inference speed and are not well-suited for synthetic scenes. To this end, we propose a novel diffusion-based system DiffuVST, which models the generation of a series of visual descriptions as a single conditional denoising process. The stochastic and non-autoregressive nature of DiffuVST at inference time allows it to generate highly diverse narratives more efficiently. In addition, DiffuVST features a unique design with bi-directional text history guidance and multimodal adapter modules, which effectively improve inter-sentence coherence and image-to-text fidelity. Extensive experiments on the story generation task covering four fictional visual-story datasets demonstrate the superiority of DiffuVST over traditional autoregressive models in terms of both text quality and inference speed.'}",https://openreview.net{'value': '/attachment/fa696aa54cba222ef0c6f823dd78c6438302c015.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=u9gI4JlOSj,{'value': 'How Does Generative Retrieval Scale to Millions of Passages?'},Ronak Pradeep; Kai Hui; Jai Gupta; Adam D Lelkes; Honglei Zhuang; Jimmy Lin; Donald Metzler; Vinh Q. Tran,~Ronak_Pradeep1; ~Kai_Hui1; ~Jai_Gupta1; ~Adam_D_Lelkes1; ~Honglei_Zhuang1; ~Jimmy_Lin2; ~Donald_Metzler1; ~Vinh_Q._Tran1,"{'value': ['generative retrieval', 'differentiable search index', 'information retrieval']}","{'value': 'The emerging paradigm of generative retrieval re-frames the classic information retrieval problem into a sequence-to-sequence modeling task, forgoing external indices and encoding an entire document corpus within a single Transformer.\nAlthough many different approaches have been proposed to improve the effectiveness of generative retrieval, they have only been evaluated on document corpora on the order of 100K in size.\nWe conduct the first empirical study of generative retrieval techniques across various corpus scales, ultimately scaling up to the entire MS MARCO passage ranking task with a corpus of 8.8M passages and evaluating model sizes up to 11B parameters.\nWe uncover several findings about scaling generative retrieval to millions of passages; notably, the central importance of using synthetic queries as document representations during indexing, the ineffectiveness of existing proposed architecture modifications when accounting for compute cost, and the limits of naively scaling model parameters with respect to retrieval performance.\nWhile we find that generative retrieval is competitive with state-of-the-art dual encoders on small corpora, scaling to millions of passages remains an important and unsolved challenge.\nWe believe these findings will be valuable for the community to clarify the current state of generative retrieval, highlight the unique challenges, and inspire new research directions.'}",https://openreview.net{'value': '/attachment/d5ba5a246856798a3f036beb097bb3c428d6bc90.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=svSNikfCs1,{'value': 'Exploiting Asymmetry for Synthetic Training Data Generation: SynthIE and the Case of Information Extraction'},Martin Josifoski; Marija Sakota; Maxime Peyrard; Robert West,~Martin_Josifoski1; ~Marija_Sakota1; ~Maxime_Peyrard2; ~Robert_West1,"{'value': ['LLM', 'Synthetic Data Generation', 'Information Extraction', 'Closed Information Extraction', 'Parsing', 'Structured Output']}","{'value': 'Large language models (LLMs) have great potential for synthetic data generation. This work shows that useful data can be synthetically generated even for tasks that cannot be solved directly by LLMs: for problems with structured outputs, it is possible to prompt an LLM to perform the task in the reverse direction, by generating plausible input text for a target output structure. Leveraging this asymmetry in task difficulty makes it possible to produce large-scale, high-quality data for complex tasks. We demonstrate the effectiveness of this approach on closed information extraction, where collecting ground-truth data is challenging, and no satisfactory dataset exists to date. We synthetically generate a dataset of 1.8M data points, establish its superior quality compared to existing datasets in a human evaluation, and use it to finetune small models (220M and 770M parameters), termed SynthIE, that outperform the prior state of the art (with equal model size) by a substantial margin of 57 absolute points in micro-F1 and 79 points in macro-F1. Code, data, and models are available at anonymous.'}",https://openreview.net{'value': '/attachment/5a3b3789e8d350113bf0d89cb1f7673d51f28ef6.pdf'},{'title_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=sKdsBUAnts,{'value': 'Building Persona Consistent Dialogue Agents with Offline Reinforcement Learning'},Ryan Shea; Zhou Yu,~Ryan_Shea1; ~Zhou_Yu1,"{'value': ['NLP', 'persona consistent dialogue', 'offline reinforcement learning']}","{'value': 'Maintaining a consistent persona is a key quality for any open domain dialogue system. Current state-of-the-art systems do this by training agents with supervised learning or online reinforcement learning (RL). However, systems trained with supervised learning often lack consistency as they are never punished for uttering contradictions. Additional training with RL can alleviate some of these issues, however the training process is expensive. Instead, we propose an offline RL framework to improve the persona consistency of dialogue systems. Our framework allows us to combine the advantages of previous methods as we can inexpensively train our model on existing data as in supervised learning, while punishing and rewarding specific utterances as in RL. We also introduce a simple importance sampling method to reduce the variance of importance weights in offline RL training which we call Variance-Reducing MLE-Initialized (VaRMI) importance sampling. Our automatic and human evaluations show that our framework improves both the persona consistency and dialogue quality of a state-of-the-art social chatbot.'}",https://openreview.net{'value': '/attachment/c92d47f248102d96a34a5a9d13462c89c5cfbfc2.pdf'},{'title_filter': 'Agent'},EMNLP,2023,Conference
https://openreview.net/forum?id=sCu26OfxxZ,{'value': 'INA: An Integrative Approach for Enhancing Negotiation Strategies with Reward-Based Dialogue Agent'},Zishan Ahmad; Suman Saurabh; Vaishakh Sreekanth Menon; Asif Ekbal; Roshni Ramnani; ANUTOSH MAITRA,~Zishan_Ahmad2; ~Suman_Saurabh1; ~Vaishakh_Sreekanth_Menon1; ~Asif_Ekbal1; ~Roshni_Ramnani1; ~ANUTOSH_MAITRA1,"{'value': ['Negotiation', 'Dialogue Agent', 'Prompting']}","{'value': 'In this paper, we propose a novel negotiation agent designed for the online marketplace. Our dialogue agent is integrative in nature i.e, it possesses the capability to negotiate on price as well as other factors, such as the addition or removal of items from a deal bundle, thereby offering a more flexible and comprehensive negotiation experience. To enable this functionality, we create a new dataset called Integrative Negotiation Dataset (IND). For this dataset creation, we introduce a new semi-automated data creation method, which combines defining negotiation intents, actions, and intent-action simulation between users and the agent to generate potential dialogue flows. Finally, the prompting of GPT-J, a state-of-the-art language model, is done to generate dialogues for a given intent, with a human-in-the-loop process for post-editing and refining minor errors to ensure high data quality. We first train a maximum likelihood loss based model on IND, and then  employ a set of novel rewards specifically tailored for the negotiation task to train our Integrative Negotiation Agent (INA). These rewards incentivize the agent to learn effective negotiation strategies that can adapt to various contextual requirements and price proposals. We train our model and conduct experiments to evaluate the effectiveness of our reward-based dialogue agent for negotiation. Our results demonstrate that the proposed approach and reward functions significantly enhance the negotiation capabilities of the dialogue agent. The INA successfully engages in integrative negotiations, displaying the ability to dynamically adjust prices and negotiate the inclusion or exclusion of items in a deal bundle.'}",https://openreview.net{'value': '/attachment/c8f7864a6d281fa35be5eb2bd71539c735160443.pdf'},{'title_filter': 'Agent'},EMNLP,2023,Conference
https://openreview.net/forum?id=rjd8AqRyW3,{'value': 'OpenAsp: A Benchmark for Multi-document Open Aspect-based Summarization'},Shmuel Amar; Liat Schiff; Ori Ernst; Asi Shefer; Ori Shapira; Ido Dagan,~Shmuel_Amar1; ~Liat_Schiff1; ~Ori_Ernst1; ~Asi_Shefer1; ~Ori_Shapira1; ~Ido_Dagan1,"{'value': ['Aspect-based Summarization', 'Datasets', 'Annotation', 'Multi-document Summarization']}","{'value': 'The performance of automatic summarization models has improved dramatically in recent years. Yet, there is still a gap in meeting specific information needs of users in real-world scenarios, particularly when a targeted summary is sought, such as in the useful aspect-based summarization setting targeted in this paper. Previous datasets and studies for this setting have predominantly concentrated on a limited set of pre-defined aspects, focused solely on single document inputs, or relied on synthetic data. To advance research on more realistic scenarios, we introduce OpenAsp, a benchmark for multi-document open aspect-based summarization. This benchmark is created using a novel and cost-effective annotation protocol, by which an open aspect dataset is derived from existing generic multi-document summarization datasets. We analyze the properties of OpenAsp showcasing its high-quality content. Further, we show that the realistic open-aspect setting realized in OpenAsp poses a challenge for current state-of-the-art summarization models, as well as for large language models.'}",https://openreview.net{'value': '/attachment/07d2d90d62507325eae9149754fbf8ae00c564c5.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=rRwPzcSFeL,{'value': 'TrueTeacher: Learning Factual Consistency Evaluation with Large Language Models'},Zorik Gekhman; Jonathan Herzig; Roee Aharoni; Chen Elkind; Idan Szpektor,~Zorik_Gekhman1; ~Jonathan_Herzig2; ~Roee_Aharoni1; ~Chen_Elkind1; ~Idan_Szpektor1,"{'value': ['factuality', 'attribution', 'consistency', 'hallucinations']}","{'value': 'Factual consistency evaluation is often conducted using Natural Language Inference (NLI) models, yet these models exhibit limited success in evaluating summaries. Previous work improved such models with synthetic training data. However, the data is typically based on perturbed human-written summaries, which often differ in their characteristics from real model-generated summaries and have limited coverage of possible factual errors. Alternatively, large language models (LLMs) have recently shown promising results in directly evaluating generative tasks, but are too computationally expensive for practical use. Motivated by these limitations, we introduce TrueTeacher, a method for generating synthetic data by annotating diverse model-generated summaries using a LLM. Unlike prior work, TrueTeacher does not rely on human-written summaries, and is multilingual by nature. Experiments on the TRUE benchmark show that a student model trained using our data, substantially outperforms both the state-of-the-art model with similar capacity, and the LLM teacher. In a systematic study, we compare TrueTeacher to existing synthetic data generation methods and demonstrate its superiority and robustness to domain-shift. We also show that our method generalizes to multilingual scenarios. Lastly, we release our large scale synthetic dataset (1.4M examples), generated using TrueTeacher, and a checkpoint trained on this data.'}",https://openreview.net{'value': '/attachment/112c2c40ff426ab84af78072f92607d0bf7597a9.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=pyjppDCsq7,{'value': 'Influence Scores at Scale for Efficient Language Data Sampling'},Nikhil Anand; Joshua Tan; Maria Minakova,~Nikhil_Anand2; ~Joshua_Tan1; ~Maria_Minakova1,"{'value': ['data effiency', 'data sampling', 'difficulty metrics', 'influence scores', 'pruning']}","{'value': 'Modern ML systems ingest data aggregated from diverse sources, such as synthetic, human-annotated, and live customer traffic. Understanding \\textit{which} examples are important to the performance of a learning algorithm is crucial for efficient model training. Recently, a growing body of literature has given rise to various “influence scores,” which use training artifacts such as model confidence or checkpointed gradients to identify important subsets of data. However, these methods have primarily been developed in computer vision settings, and it remains unclear how well they generalize to language-based tasks using pretrained models.\n\nIn this paper, we explore the applicability of influence scores in language classification tasks. We evaluate a diverse subset of these scores on the SNLI dataset by quantifying accuracy changes in response to pruning training data through random and influence-score-based sampling. We then stress-test one of the scores – ""variance of gradients"" (VoG) from Agarwal and Hooker (2022) – in an NLU model stack that was exposed to dynamic user speech patterns in a voice assistant type of setting. Our experiments demonstrate that in many cases, encoder-based language models can be fine-tuned on roughly 50% of the original data without degradation in performance metrics. Along the way, we summarize lessons learned from applying out-of-the-box implementations of influence scores, quantify the effects of noisy and class-imbalanced data, and offer recommendations on score-based sampling for better accuracy and training efficiency.'}",https://openreview.net{'value': '/attachment/0b6e96dd22459e2f7f0d87cea4597fd998cc715b.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=oxZKOzePQX,{'value': 'SWEET - Weakly Supervised Person Name Extraction for Fighting Human Trafficking'},Javin Liu; Hao Yu; Vidya Sujaya; Pratheeksha Nair; Kellin Pelrine; Reihaneh Rabbany,~Javin_Liu1; ~Hao_Yu15; ~Vidya_Sujaya1; ~Pratheeksha_Nair2; ~Kellin_Pelrine1; ~Reihaneh_Rabbany1,"{'value': ['Information Extraction', 'Large Language Models', 'Generation', 'NLP Applications', 'Resources and Evaluation']}","{'value': 'In this work, we propose a weak supervision pipeline SWEET: Supervise Weakly for Entity Extraction to fight Trafficking for extracting person names from noisy escort advertisements. Our method combines the simplicity of rule-matching (through antirules, i.e., negated rules) and the generalizability of large language models fine-tuned on benchmark, domain-specific and synthetic datasets, treating them as weak labels.\nOne of the major challenges in this domain is limited labeled data. SWEET addresses this by obtaining multiple weak labels through labeling functions and effectively aggregating them. SWEET outperforms the previous supervised SOTA method for this task by 9% F1 score on domain data and better generalizes to common benchmark datasets. Furthermore, we also release HTGEN, a synthetically generated dataset of escort advertisements (built using ChatGPT) to facilitate further research within the community.'}",https://openreview.net{'value': '/attachment/5c06ddec152aac74268272742e9ba4c0e4b7f09c.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=oseYM8qxW4,{'value': 'Critic-Driven Decoding for Mitigating Hallucinations in Data-to-text Generation'},Mateusz Lango; Ondrej Dusek,~Mateusz_Lango1; ~Ondrej_Dusek1,"{'value': ['data-to-text generation', 'hallucinations', 'decoding approaches', 'natural language genereation']}","{'value': ""Hallucination of text ungrounded in the input is a well-known problem in neural data-to-text generation. Many methods have been proposed to mitigate it, but they typically require altering model architecture or collecting additional data, and thus cannot be easily applied to an existing model. In this paper, we explore a new way to mitigate hallucinations by combining the probabilistic output of a generator language model (LM) with the output of a special “text critic” classifier, which guides the generation by assessing the match between the input data and the text generated so far. Our method does not need any changes to the underlying LM's architecture or training procedure and can thus be combined with any model and decoding operating on word probabilities. The critic does not need any additional training data, using the base LM's training data and synthetic negative examples. Our experimental results show that our method improves over the baseline on  the WebNLG and OpenDialKG benchmarks.""}",https://openreview.net{'value': '/attachment/1d84c89ba1089931c8085745e9f3039181f8cebc.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=oqqmjw1BD1,{'value': 'Bridging the Gap between Synthetic and Authentic Images for Multimodal Machine Translation'},Wenyu Guo; Qingkai Fang; Dong Yu; Yang Feng,~Wenyu_Guo1; ~Qingkai_Fang1; ~Dong_Yu7; ~Yang_Feng4,"{'value': ['Multimodal Machine Translation', 'Text-to-image Generation']}","{'value': 'Multimodal machine translation (MMT) simultaneously takes the source sentence and a relevant image as input for translation. Since there is no paired image available for the input sentence in most cases, recent studies suggest utilizing powerful text-to-image generation models to provide image inputs. Nevertheless, synthetic images generated by these models often follow different distributions compared to authentic images. Consequently, using authentic images for training and synthetic images for inference can introduce a distribution shift, resulting in performance degradation during inference. To tackle this challenge, in this paper, we feed synthetic and authentic images to the MMT model, respectively. Then we minimize the gap between the synthetic and authentic images by drawing close the input image representations of the Transformer Encoder and the output distributions of the Transformer Decoder. Therefore, we mitigate the distribution disparity introduced by the synthetic images during inference, thereby freeing the authentic images from the inference process. Experimental results show that our approach achieves state-of-the-art performance on the Multi30K En-De and En-Fr datasets, while remaining independent of authentic images during inference.'}",https://openreview.net{'value': '/attachment/e8ea7573bdcfb355407930e2b334b31d12861026.pdf'},{'title_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=ogh9vskMDH,{'value': 'Open-Ended Instructable Embodied Agents with Memory-Augmented Large Language Models'},Gabriel Herbert Sarch; Yue Wu; Michael J. Tarr; Katerina Fragkiadaki,~Gabriel_Herbert_Sarch1; ~Yue_Wu17; ~Michael_J._Tarr1; ~Katerina_Fragkiadaki1,"{'value': ['Task Planning', 'Embodied AI', 'LLMs', 'Robotics']}","{'value': ""Pre-trained and frozen LLMs can effectively map simple scene re-arrangement instructions to programs over a robot's visuomotor functions through appropriate few-shot example prompting. To parse open-domain natural language and adapt to a user's idiosyncratic procedures, not known during prompt engineering time, fixed prompts fall short. In this paper, we introduce HELPER, an embodied agent equipped with an external memory of language-program pairs that parses free-form human-robot dialogue into action programs through retrieval-augmented LLM prompting: relevant memories are retrieved based on the current dialogue, instruction, correction or VLM description, and used as in-context prompt examples for LLM querying. The memory is expanded during deployment to include pairs of user's language and action plans, to assist future inferences and personalize them to the user's language and routines. HELPER sets a new state-of-the-art in the TEACh benchmark in both Execution from Dialog History (EDH) and Trajectory from Dialogue (TfD), with 1.7x improvement over the previous SOTA for TfD. Our models, code and video results can be found in our project's website: https://helper-agent-llm.github.io.""}",https://openreview.net{'value': '/attachment/30ff54ad8ea9d1d6fd9b652499d07d963084d3f5.pdf'},{'title_filter': 'Agent'},EMNLP,2023,Conference
https://openreview.net/forum?id=oaNa4rNIpU,{'value': 'HistAlign: Improving Context Dependency in Language Generation by Aligning with History'},David Wan; Shiyue Zhang; Mohit Bansal,~David_Wan1; ~Shiyue_Zhang1; ~Mohit_Bansal2,"{'value': ['generation', 'language models', 'summarization', 'data-to-text']}","{'value': 'Language models (LMs) can generate hallucinations and incoherent outputs, which highlights their weak context dependency. Cache-LMs, which augment LMs with a memory of recent history, can increase context dependency and have shown remarkable performance in diverse language generation tasks. However, we find that even with training, the performance gain stemming from the cache component of current cache-LMs is suboptimal due to the misalignment between the current hidden states and those stored in the memory. In this work, we present HistAlign, a new training approach to ensure good cache alignment such that the model receives useful signals from the history. We first prove our concept on a simple and synthetic task where the memory is essential for correct predictions, and we show that the cache component of HistAlign is better aligned and improves overall performance. Next, we evaluate HistAlign on diverse downstream language generation tasks, including prompt continuation, abstractive summarization, and data-to-text. We demonstrate that HistAlign improves text coherence and faithfulness in open-ended and conditional generation settings respectively. HistAlign is also generalizable across different model families, showcasing its strength in improving context dependency of LMs in diverse scenarios.'}",https://openreview.net{'value': '/attachment/86db34df1b113dc58c931829ee3d197d9ccc776b.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=oEsuNpkA8d,{'value': 'Gold: A Global and Local-aware Denoising Framework for Commonsense Knowledge Graph Noise Detection'},Zheye Deng; Weiqi Wang; Zhaowei Wang; Xin Liu; Yangqiu Song,~Zheye_Deng1; ~Weiqi_Wang1; ~Zhaowei_Wang2; ~Xin_Liu9; ~Yangqiu_Song1,"{'value': ['Knowledege Graph Denoising', 'Commonsense Reasoning', 'Question Answering']}","{'value': 'Commonsense Knowledge Graphs (CSKGs) are crucial for commonsense reasoning, yet constructing them through human annotations can be costly. As a result, various automatic methods have been proposed to construct CSKG with larger semantic coverage. However, these unsupervised approaches introduce spurious noise that can lower the quality of the resulting CSKG, which cannot be tackled easily by existing denoising algorithms due to the unique characteristics of nodes and structures in CSKGs. To address this issue, we propose Gold (Global and Local-aware Denoising), a denoising framework for CSKGs that incorporates entity semantic information, global rules, and local structural information from the CSKG. Experiment results demonstrate that Gold outperforms all baseline methods in noise detection tasks on synthetic noisy CSKG benchmarks. Furthermore, we show that denoising a real-world CSKG is effective and even benefits the downstream zero-shot commonsense question-answering task. Our code and data are publicly available at https://github.com/HKUST-KnowComp/GOLD.'}",https://openreview.net{'value': '/attachment/747daf0c31e988998cb8d55caf083bf5504c0587.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=nw6JxagUNG,{'value': 'Methodological Insights in Detecting Subtle Semantic Shifts with Contextualized and Static Language Models'},Sanne Hoeken; Özge Alacam; Antske Fokkens; Pia Sommerauer,~Sanne_Hoeken1; ~Özge_Alacam1; ~Antske_Fokkens1; ~Pia_Sommerauer1,"{'value': ['semantic shift detection', 'contextualized embeddings', 'static embeddings', 'political communities']}","{'value': 'In this paper, we investigate automatic detection of subtle semantic shifts between social communities of different political convictions in Dutch and English. We perform a methodological study comparing methods using static and contextualized language models. We investigate the impact of specializing contextualized models through fine-tuning on target corpora, word sense disambiguation and sentiment. We furthermore propose a new approach using masked token prediction, that relies on behavioral information, specifically the most probable substitutions, instead of geometrical comparison of representations. Our results show that methods using static models and our masked token prediction method can detect differences in connotation of politically loaded terms, whereas methods that rely on measuring the distance between contextualized representations are not providing clear signals, even in synthetic scenarios of extreme shifts.'}",https://openreview.net{'value': '/attachment/0d7f101e647e1de89760744b640e9963fe3c5113.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=nntsSuRSPb,{'value': 'TextMixer: Mixing Multiple Inputs for Privacy-Preserving Inference'},Xin Zhou; Yi Lu; Ruotian Ma; Tao Gui; Qi Zhang; Xuanjing Huang,~Xin_Zhou6; ~Yi_Lu7; ~Ruotian_Ma1; ~Tao_Gui1; ~Qi_Zhang8; ~Xuanjing_Huang1,"{'value': ['Privacy-preserving Inference', 'Multi-input Multi-output network']}","{'value': ""Pre-trained language models (PLMs) are often deployed as cloud services, enabling users to upload textual data and perform inference remotely. \nHowever, users' personal text often contains sensitive information,  and sharing such data directly with the service providers can lead to serious privacy leakage.\nTo address this problem, we introduce a novel privacy-preserving inference framework called \\textbf{\\textit{MixPi}}, which  prevents plaintext leakage during the inference phase. \nInspired by $k$-anonymity, MixPi aims to obfuscate a user's private input by mixing it with multiple other inputs, thereby confounding potential privacy attackers. \nTo achieve this, our approach involves: (1) proposing a novel encryption module, Privacy Mixer, which encrypts input from three distinct dimensions: mixing, representation, and position. \n(2) adopting a pre-trained Multi-input Multi-output network to handle mixed representations and obtain multiple predictions.  \n(3) employing a Privacy Demixer to ensure only the user can decrypt the real output among the multiple predictions.\nFurthermore, we explore different ways to automatically generate synthetic inputs required for mixing.\nExperimental results on token and sentence classification tasks demonstrate that MixPi greatly surpasses existing privacy-preserving methods in both performance and privacy.""}",https://openreview.net{'value': '/attachment/b56968acab7492b01fd41691b6d9208d483bf862.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=kY7lpT8z1E,{'value': 'Contrastive Learning of Sentence Embeddings from Scratch'},Junlei Zhang; Zhenzhong Lan; Junxian He,~Junlei_Zhang1; ~Zhenzhong_Lan2; ~Junxian_He1,"{'value': ['contrastive learning', 'sentence embeddings']}","{'value': 'Contrastive learning has been the dominant approach to train state-of-the-art sentence embeddings. Previous studies have typically learned sentence embeddings either through the use of human-annotated natural language inference (NLI) data or via large-scale unlabeled sentences in an unsupervised manner. However, even in the case of unlabeled data, their acquisition presents challenges in certain domains due to various reasons. due to copyright restrictions, data distribution issues, and messy formats, among other factors. To address these issues, we present SynCSE, a contrastive learning framework that trains sentence embeddings with synthetic data. Specifically, we explore utilizing large language models to synthesize the required data samples for contrastive learning, including (1) producing positive and negative annotations given unlabeled sentences SynCSE-partial, and (2) generating sentences along with their corresponding annotations from scratch SynCSE-scratch. Notably, SynCSE-scratch constitutes the first contrastive learning method to learn sentence embeddings from scratch without manually collecting any data sample. Experimental results on sentence similarity and reranking tasks indicate that both SynCSE-partial and SynCSE-scratch greatly outperform unsupervised baselines, and SynCSE-partial even achieves comparable performance to the supervised models in most settings.'}",https://openreview.net{'value': '/attachment/2244616e5f3bc9f7e162c564a71aa21d9298092c.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=kKKzd8SaMy,{'value': 'The Interpreter Understands Your Meaning: End-to-end Spoken Language Understanding Aided by Speech Translation'},Mutian He; Philip N. Garner,~Mutian_He1; ~Philip_N._Garner1,"{'value': ['spoken language understanding', 'multilinguality', 'bayesian transfer learning']}","{'value': 'End-to-end spoken language understanding (SLU) remains elusive even with current large pretrained language models on text and speech, especially in multilingual cases. Machine translation has been established as a powerful pretraining objective on text as it enables the model to capture high-level semantics of the input utterance and associations between different languages, which is desired for speech models that work on lower-level acoustic frames. Motivated particularly by the task of cross-lingual SLU, we demonstrate that the task of speech translation (ST) is a good means of pretraining speech models for end-to-end SLU on both intra- and cross-lingual scenarios. \n\nBy introducing ST, our models reach higher performance over baselines on monolingual and multilingual intent classification as well as spoken question answering using SLURP, MINDS-14, and NMSQA benchmarks. To verify the effectiveness of our methods, we also create new benchmark datasets from both synthetic and real sources, for speech summarization and low-resource/zero-shot transfer from English to French or Spanish. We further show the value of preserving knowledge for the ST pretraining task for better downstream performance, possibly using Bayesian transfer regularizers.'}",https://openreview.net{'value': '/attachment/fa5d2b40b135e71b350415534a6f089846b96cf5.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=hlqIu07ics,{'value': 'Towards a Mechanistic Interpretation of Multi-Step Reasoning Capabilities of Language Models'},Yifan Hou; Jiaoda Li; Yu Fei; Alessandro Stolfo; Wangchunshu Zhou; Guangtao Zeng; Antoine Bosselut; Mrinmaya Sachan,~Yifan_Hou1; ~Jiaoda_Li1; ~Yu_Fei2; ~Alessandro_Stolfo1; ~Wangchunshu_Zhou1; ~Guangtao_Zeng1; ~Antoine_Bosselut1; ~Mrinmaya_Sachan3,"{'value': ['model interpretation', 'reasoning', 'attention mechanism', 'large language model']}","{'value': 'Recent work has shown that language models (LMs) have strong multi-step (i.e., procedural) reasoning capabilities. However, it is unclear whether LMs perform these tasks by cheating with answers memorized from pretraining corpus, or, via a multi-step reasoning mechanism. In this paper, we try to answer this question by exploring a mechanistic interpretation of LMs for multi-step reasoning tasks. Concretely, we hypothesize that the LM implicitly embeds a reasoning tree resembling the correct reasoning process within it. We test this hypothesis by introducing a new probing approach (called MechanisticProbe) that recovers the reasoning tree from the model’s attention patterns. We use our probe to analyze two LMs: GPT-2 on a synthetic task (k-th smallest element), and LLaMA on two simple language-based reasoning tasks (ProofWriter \\& AI2 Reasoning Challenge). We show that MechanisticProbe is able to detect the information of the reasoning tree from the model’s attentions for most examples, suggesting that the LM indeed is going through a process of multi-step reasoning within its architecture in many cases.'}",https://openreview.net{'value': '/attachment/d6fb09f6162e807a559dbd76476720eb515456bd.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=ghF1EB6APx,{'value': 'Cross-Modal Conceptualization in Bottleneck Models'},Danis Alukaev; Semen Kiselev; Ilya Pershin; Bulat Ibragimov; Vladimir V. Ivanov; Alexey Kornaev; Ivan Titov,~Danis_Alukaev1; ~Semen_Kiselev1; ~Ilya_Pershin1; ~Bulat_Ibragimov3; ~Vladimir_V._Ivanov1; ~Alexey_Kornaev1; ~Ivan_Titov1,"{'value': ['interpretability', 'cross-modal learning', 'concept-based models', 'cross-attention mechanism', 'robustness']}","{'value': 'Concept Bottleneck Models (CBMs) assume that training examples (e.g., x-ray images) are annotated with high-level concepts (e.g., types of abnormalities), and perform classification by first predicting the concepts, followed by predicting the label relying on these concepts. However, the primary challenge in employing CBMs lies in the requirement of defining concepts predictive of the label and annotating training examples with these concepts. In our approach, we adopt a more moderate assumption and instead use text descriptions (e.g., radiology reports), accompanying the images, to guide the induction of concepts.  Our crossmodal approach treats concepts as discrete latent variables and promotes concepts that (1) are predictive of the label, and (2)  can be predicted reliably from both the image and text. Through experiments conducted on datasets ranging from synthetic datasets (e.g., synthetic images with generated descriptions) to realistic medical imaging datasets, we demonstrate that crossmodal learning encourages the induction of interpretable concepts while also facilitating disentanglement.'}",https://openreview.net{'value': '/attachment/a3ed1fc97d6a206656b9af9ee5c5ca0fe7d8eedb.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=g04NBFnIxb,{'value': 'ViPE: Visualise Pretty-much Everything'},Hassan Shahmohammadi; Adhiraj Ghosh; Hendrik Lensch,~Hassan_Shahmohammadi1; ~Adhiraj_Ghosh2; ~Hendrik_Lensch2,"{'value': ['Visual metaphors', 'music video generation', 'text-to-image synthesis', 'abstract visualization', 'diffusion models for abstract art', 'synthetic data generation', 'unsupervised label generation']}","{'value': 'Figurative and non-literal expressions are profoundly integrated in human communication. Visualising such expressions allow us to convey our creative thoughts, and evoke nuanced emotions. Recent text-to-image models like Stable Diffusion, on the other hand, struggle to depict non-literal expressions. Recent works primarily deal with this issue by compiling humanly annotated datasets on a small scale, which not only demands specialized expertise but also proves highly inefficient. To address this issue, we introduce ViPE: Visualise Pretty-much Everything. ViPE offers a series of lightweight and robust language models that have been trained on a large-scale set of lyrics with noisy visual descriptions that represent their implicit meaning. The synthetic visual descriptions are generated by GPT3.5 relying on neither human annotations nor images. ViPE effectively expresses any arbitrary piece of text into a visualisable description, enabling meaningful and high-quality image generation. We provide compelling evidence that ViPE is more robust than GPT3.5 in synthesising visual elaborations. ViPE also exhibits an understanding of figurative expressions comparable to human experts, providing a powerful and open-source backbone to many downstream applications such as music video and caption generation.'}",https://openreview.net{'value': '/attachment/f979398a530ad1a3cb93e56b918c2167baed3d0a.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=flkXLt9WKn,{'value': 'Dialogue Chain-of-Thought Distillation for Commonsense-aware Conversational Agents'},Hyungjoo Chae; Yongho Song; Kai Tzu-iunn Ong; Taeyoon Kwon; Minjin Kim; Youngjae Yu; Dongha Lee; Dongyeop Kang; Jinyoung Yeo,~Hyungjoo_Chae1; ~Yongho_Song1; ~Kai_Tzu-iunn_Ong1; ~Taeyoon_Kwon1; ~Minjin_Kim1; ~Youngjae_Yu1; ~Dongha_Lee1; ~Dongyeop_Kang2; ~Jinyoung_Yeo1,"{'value': ['Commonsense Reasoning', 'Dialogue', 'Large Language Model']}","{'value': 'Human-like chatbots necessitate the use of commonsense reasoning in order to effectively comprehend and respond to implicit information present within conversations. Achieving such coherence and informativeness in responses, however, is a non-trivial task. Even for large language models (LLMs), the task of identifying and aggregating key evidence within a single hop presents a substantial challenge. This complexity arises because such evidence is scattered across multiple turns in a conversation, thus necessitating integration over multiple hops. Hence, our focus is to facilitate such multi-hop reasoning over a dialogue context, namely dialogue chain-of-thought (CoT) reasoning. \nTo this end, we propose a knowledge distillation framework that leverages LLMs as unreliable teachers and selectively distills consistent and helpful rationales via alignment filters. \nWe further present DOCTOR, a DialOgue Chain-of-ThOught Reasoner that provides reliable CoT rationales for response generation.  \nWe conduct extensive experiments to show that enhancing dialogue agents with high-quality rationales from DOCTOR significantly improves the quality of their responses.'}",https://openreview.net{'value': '/attachment/10a3be324169c688ea35f4f204d0496f35411fa6.pdf'},{'title_filter': 'Agent'},EMNLP,2023,Conference
https://openreview.net/forum?id=f7eqyX0nJP,{'value': 'ZEROTOP: Zero-Shot Task-Oriented Semantic Parsing using Large Language Models'},Dheeraj Mekala; Jason Andrew Wolfe; Subhro Roy,~Dheeraj_Mekala1; ~Jason_Andrew_Wolfe1; ~Subhro_Roy1,"{'value': ['zero-shot', 'semantic parsing', 'mtop', 'large language models', 'llm', 'QA datasets']}","{'value': 'We explore the use of large language models (LLMs) for zero-shot semantic parsing. Semantic parsing involves mapping natural language utterances to task-specific meaning representations. LLMs are generally trained on publicly available text and code and cannot be expected to directly generalize to domain-specific parsing tasks in a zero-shot setting. In this work, we propose ZEROTOP, a zero-shot task-oriented parsing method that decomposes semantic parsing problem into a set of abstractive and extractive question-answering (QA) problems. For each utterance, we prompt the LLM with questions corresponding to its top-level intent and a set of slots and use the LLM generations to construct the target meaning representation. We observe that current LLMs fail to detect unanswerable questions; and as a result, cannot handle questions corresponding to missing slots. We address this by fine-tuning a language model on public QA datasets using synthetic negative samples. Experimental results show that our QA-based decomposition paired with the fine-tuned LLM can zero-shot parse ≈ 16% of utterances in the MTOP dataset.'}",https://openreview.net{'value': '/attachment/ceb4df9daabd3e682a4c6c96f838cb4e81d44472.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=f34v92a86l,{'value': 'Efficient Grammatical Error Correction Via Multi-Task Training and Optimized Training Schedule'},Andrey Bout; Alexander Podolskiy; Sergey Nikolenko; Irina Piontkovskaya,~Andrey_Bout1; ~Alexander_Podolskiy1; ~Sergey_Nikolenko1; ~Irina_Piontkovskaya2,"{'value': ['Grammatical error correction', 'Multi-task training', 'Sequence-to-sequence', 'Fine-tuning']}","{'value': 'Progress in neural grammatical error correction (GEC) is hindered by the lack of annotated training data. Sufficient amounts of high-quality manually annotated data are not available, so recent research has relied on generating synthetic data, pretraining on it, and then fine-tuning on real datasets; performance gains have been achieved either by ensembling or by using huge pretrained models such as XXL-T5 as the backbone. In this work, we explore an orthogonal direction: how to use available data more efficiently. First, we propose auxiliary tasks that exploit the alignment between the original and corrected sentences, such as predicting a sequence of corrections. We formulate each task as a sequence-to-sequence problem and perform multi-task training. Second, we discover that the order of datasets used for training and even individual instances within a dataset may have important effects on the final performance, so we set out to find the best training schedule. Together, these two ideas lead to significant improvements, producing results that improve state of the art with much smaller models; in particular, we outperform the best models based on T5-XXL (11B parameters) with a BART-based model (400M parameters).'}",https://openreview.net{'value': '/attachment/05583f8da790903cd32e7194835951a98b77df28.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=dpS5VxAwuF,{'value': 'Multimodal Embodied Plan Prediction Augmented with Synthetic Embodied Dialogue'},Aishwarya Padmakumar; Mert Inan; Spandana Gella; Patrick L. Lange; Dilek Hakkani-Tur,~Aishwarya_Padmakumar1; ~Mert_Inan1; ~Spandana_Gella2; ~Patrick_L._Lange1; ~Dilek_Hakkani-Tur1,"{'value': ['Embodied AI', 'Embodied Task Completion', 'Language and Robotics', 'Plan Prediction', 'Dialog Simulation']}","{'value': 'Embodied task completion is a challenge where an agent in a simulated environment must predict environment actions to complete tasks\nbased on natural language instructions and ego-centric visual observations. We propose a variant of this problem where the agent predicts\nactions at a higher level of abstraction called a plan, which helps make agent actions more interpretable and can be obtained from the appropriate prompting of large language models. We show that multimodal transformer models can outperform language-only models for this problem but fall significantly short of oracle plans. Since collecting human-human dialogues for embodied environments is expensive and time-consuming, we propose a method to synthetically generate such dialogues, which we then use as training data for plan prediction. We demonstrate that multimodal transformer models can attain strong zero-shot performance from our synthetic data, outperforming language-only models trained on human-human data.'}",https://openreview.net{'value': '/attachment/cbc9035f3a5396770b460133068daf7e3ee11b05.pdf'},{'title_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=cFXHe1mW7V,{'value': 'Can You Follow Me? Testing Situational Understanding for ChatGPT'},Chenghao Yang; Allyson Ettinger,~Chenghao_Yang1; ~Allyson_Ettinger1,"{'value': ['Situational Understanding', 'Analysis of Models', 'ChatGPT']}","{'value': ""Understanding sentence meanings and updating information states appropriately across time---what we call ``situational understanding'' (SU)---is a critical ability for human-like AI agents. SU is essential in particular for chat models, such as ChatGPT, to enable consistent, coherent, and effective dialogue between humans and AI. Previous works have identified certain SU limitations in non-chatbot Large Language models (LLMs), but the extent and causes of these limitations are not well understood, and capabilities of current chat-based models in this domain have not been explored. In this work we tackle these questions, proposing a novel synthetic environment for SU testing which allows us to do controlled and systematic testing of SU in chat-oriented models, through assessment of models' ability to track and enumerate environment states. Our environment also allows for close analysis of dynamics of model performance, to better understand underlying causes for performance patterns. We apply our test to ChatGPT, the state-of-the-art chatbot, and find that despite the fundamental simplicity of the task, the model's performance reflects an inability to retain correct environment states across time. Our follow-up analyses suggest that performance degradation is largely because ChatGPT has non-persistent in-context memory (although it can access the full dialogue history) and it is susceptible to hallucinated updates---including updates that artificially inflate accuracies. Our findings suggest overall that ChatGPT is not currently equipped for robust tracking of situation states, and that trust in the impressive dialogue performance of ChatGPT comes with risks. We release the codebase for reproducing our test environment, as well as all prompts and API responses from ChatGPT, at https://github.com/yangalan123/SituationalTesting.""}",https://openreview.net{'value': '/attachment/0c36be6345f4de05581f27ea86610b5a26c51917.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=bmeKrAzRqz,{'value': 'Pre-Trained Language Models Augmented with Synthetic Scanpaths for Natural Language Understanding'},Shuwen Deng; Paul Prasse; David Robert Reich; Tobias Scheffer; Lena Ann Jäger,~Shuwen_Deng1; ~Paul_Prasse1; ~David_Robert_Reich1; ~Tobias_Scheffer1; ~Lena_Ann_Jäger1,"{'value': ['Human gaze data', 'synthetic scanpaths', 'gaze-augmented language model', 'natural language understanding', 'transformer', 'deep neural networks']}","{'value': ""Human gaze data offer cognitive information that reflects natural language comprehension. Indeed, augmenting language models with human scanpaths has proven beneficial for a range of NLP tasks, including language understanding. However, the applicability of this approach is hampered because the abundance of text corpora is contrasted by a scarcity of gaze data. Although models for the generation of human-like scanpaths during reading have been developed, the potential of synthetic gaze data across NLP tasks remains largely unexplored. We develop a model that integrates synthetic scanpath generation with a scanpath-augmented language model, eliminating the need for human gaze data. Since the model's error gradient can be propagated throughout all parts of the model, the scanpath generator can be fine-tuned to downstream tasks. We find that the proposed model not only outperforms the underlying language model, but achieves a performance that is comparable to a language model augmented with real human gaze data. Our code is publicly available.""}",https://openreview.net{'value': '/attachment/08e60654005a0f8df8bb475c2fe06a3193695211.pdf'},{'title_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=Yzi6LM20E2,{'value': 'Two Directions for Clinical Data Generation with Large Language Models: Data-to-Label and Label-to-Data'},Rumeng Li; Xun Wang; hong yu,~Rumeng_Li1; ~Xun_Wang5; ~hong_yu1,"{'value': ['Large language model', 'clinical text processing', ""Alzheimer's Disease"", 'data augmentation']}","{'value': ""Large language models (LLMs) can generate natural language texts for various domains and tasks, but their potential for clinical text mining, a domain with scarce, sensitive, and imbalanced medical data, is under-explored. We investigate whether LLMs can augment clinical data for detecting Alzheimer's Disease (AD)-related signs and symptoms from electronic health records (EHRs), a challenging task that requires high expertise. We create a novel pragmatic taxonomy for AD sign and symptom progression based on expert knowledge and generated three datasets: (1) a gold dataset annotated by human experts on longitudinal EHRs of AD patients; (2) a silver dataset created by the data-to-label method, which labels sentences from a public EHR collection with AD-related signs and symptoms; and (3) a bronze dataset created by the label-to-data method which generates sentences with AD-related signs and symptoms based on the label definition.\nWe train a system to detect AD-related signs and symptoms from EHRs. We find that the silver and bronze datasets improves the system performance, outperforming the system using only the gold dataset. This shows that LLMs can generate synthetic clinical data for a complex task by incorporating expert knowledge, and our label-to-data method can produce datasets that are free of sensitive information, while maintaining acceptable quality.""}",https://openreview.net{'value': '/attachment/e2f2fcfd49c8d5a5b6959cd56806ad60351be63f.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=W4Vk1ufh7l,{'value': 'TRIP: Accelerating Document-level Multilingual Pre-training via Triangular Document-level Pre-training on Parallel Data Triplets'},Hongyuan Lu; Haoyang Huang; Shuming Ma; Dongdong Zhang; Wai Lam; Zhaochuan Gao; Anthony Aue; Arul Menezes; Furu Wei,~Hongyuan_Lu2; ~Haoyang_Huang1; ~Shuming_Ma1; ~Dongdong_Zhang4; ~Wai_Lam1; ~Zhaochuan_Gao1; ~Anthony_Aue1; ~Arul_Menezes1; ~Furu_Wei1,{'value': ['multilingual pre-training; machine translation; cross-lingual summarization']},"{'value': 'Despite the success of multilingual sequence-to-sequence pre-training, most existing approaches rely on document-level monolingual corpora in many different languages, sentence-level bilingual corpora,\\footnote{In this paper, we use bilingual corpora to denote parallel corpora with bilingual translation pairs in many different language pairs, each consisting of two sentences/documents with the same meaning written in different languages. We use trilingual corpora to denote parallel corpora with trilingual translation pairs in many different language combinations, each consisting of three sentences/documents.} and sometimes synthetic document-level bilingual corpora. This hampers the performance with cross-lingual document-level tasks such as document-level translation. Hence, we propose to mine and leverage document-level trilingual parallel corpora to improve sequence-to-sequence multilingual pre-training. We present \\textbf{Tri}angular Document-level \\textbf{P}re-training (\\textbf{TRIP}) as the first in the field to accelerate the conventional monolingual and bilingual objectives into a trilingual objective with a novel method called Grafting. Experiments show that TRIP achieves several strong state-of-the-art (SOTA) scores on three multilingual document-level machine translation benchmarks and one cross-lingual abstractive summarization benchmark, including consistent improvements by up to 3.11 d-BLEU points and 8.9 ROUGE-L points.'}",https://openreview.net{'value': '/attachment/a234db2b177ab4c59b68e28c6dbd4b663211523e.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=W1w2eovejY,{'value': 'Uncertainty-aware Parameter-Efficient Self-training for Semi-supervised Language Understanding'},Jianing Wang; Qiushi Sun; Nuo Chen; Chengyu Wang; Jun Huang; Ming Gao; Xiang Li,~Jianing_Wang4; ~Qiushi_Sun1; ~Nuo_Chen4; ~Chengyu_Wang1; ~Jun_Huang4; ~Ming_Gao1; ~Xiang_Li24,"{'value': ['Self-Training', 'Uncertainty Estimation', 'Pre-trained Language Models', 'Parameter-Efficient Learning']}","{'value': 'The recent success of large pre-trained language models (PLMs) heavily hinges on massive labeled data, which typically produces inferior performance in low-resource scenarios. To remedy this dilemma, we study self-training as one of the predominant semi-supervised learning (SSL) approaches, which utilizes large-scale unlabeled data to generate synthetic examples. However, too many noisy labels will hurt the model performance, and the self-training procedure requires multiple training iterations making it more expensive if all the model parameters of the PLM are updated. This paper presents UPET, a novel Uncertainty-aware Parameter-Efficient self-Training framework to effectively and efficiently address the labeled data scarcity issue. Specifically, we incorporate Monte Carlo (MC) dropout in Bayesian neural network (BNN) to perform uncertainty estimation for the teacher model and then judiciously select reliable pseudo-labeled examples based on confidence and certainty. During the student training, we introduce multiple parameter-efficient learning (PEL) paradigms that allow optimizes only a small percentage of parameters. We also propose a novel Easy-Hard Contrastive Tuning to enhance the robustness and generalization. Extensive experiments over multiple downstream tasks demonstrate that UPET achieves a substantial improvement in terms of performance and efficiency. Our codes and data are released at https: //github.com/wjn1996/UPET.'}",https://openreview.net{'value': '/attachment/9cff0ee16cec16403fedd8ce7b73eb88fbc78d89.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=VhL4lZXY1U,{'value': 'Beyond Candidates : Adaptive Dialogue Agent Utilizing Persona and Knowledge'},Jungwoo Lim; Myunghoon Kang; Jinsung Kim; Jeongwook Kim; Yuna Hur; Heuiseok Lim,~Jungwoo_Lim1; ~Myunghoon_Kang1; ~Jinsung_Kim2; ~Jeongwook_Kim1; ~Yuna_Hur1; ~Heuiseok_Lim1,"{'value': ['Dialogue System', 'Adaptive', 'Candidate-agnostic', 'Persona', 'Knowledge']}","{'value': 'To build ultimate dialogue agents, previous studies suggest models that ground both persona and knowledge. However, applying the dialogue system directly to the usual conversation is still limited because the system requires a complete sentence-formed persona and knowledge candidate sets from the given dataset. In contrast to the dialogue setting in the dataset, humans utilize semantic concepts in their minds rather than a set of pre-defined candidate sentences. Following this manner of human dialogue, we suggest an adaptive dialogue system that is applicable to situations where complete sentence-formed candidates are not given. Our model generates consistent and relevant persona descriptions and identifies relevant knowledge for engaging and knowledgeable responses, even with fragmentary information. We show that our model outperforms previous baselines that utilize persona and knowledge candidate sentences and conduct the human evaluation on the machine-generated responses. In addition, we conduct ablation studies to demonstrate the effectiveness of each component of our model. Furthermore, we apply our model to other dialogue datasets that only ground knowledge or persona to showcase its adaptability. Our code is available at https://github.com/dlawjddn803/BeCand.'}",https://openreview.net{'value': '/attachment/bff43e25d4ccf79d4babd8e4f2050a51ca9efe3c.pdf'},{'title_filter': 'Agent'},EMNLP,2023,Conference
https://openreview.net/forum?id=U78nBY8hRi,{'value': 'DALE: Generative Data Augmentation for Low-Resource Legal NLP'},Sreyan Ghosh; Chandra Kiran Reddy Evuru; Sonal Kumar; Ramaneswaran S; S Sakshi; Utkarsh Tyagi; Dinesh Manocha,~Sreyan_Ghosh1; ~Chandra_Kiran_Reddy_Evuru1; ~Sonal_Kumar1; ~Ramaneswaran_S1; ~S_Sakshi1; ~Utkarsh_Tyagi1; ~Dinesh_Manocha3,"{'value': ['legal', 'low-resource', 'augmentation', 'generation', 'efficient']}","{'value': 'We present DALE, a novel and effective generative Data Augmentation framework for low-resource LEgal NLP. DALE addresses the challenges existing frameworks pose in generating effective data augmentations of legal documents - legal language, with its specialized vocabulary and complex semantics, morphology, and syntax, does not benefit from data augmentations that merely rephrase the source sentence. To address this, DALE, built on an Encoder-Decoder Language Model, is pre-trained on a novel unsupervised text denoising objective based on selective masking - our masking strategy exploits the domain-specific language characteristics of templatized legal documents to mask collocated spans of text. Denoising these spans help DALE acquire broad legal knowledge and develop the ability to generate coherent and diverse augmentations with novel contexts. Finally, DALE performs conditional generation to generate synthetic augmentations for low-resource Legal NLP tasks. We demonstrate the effectiveness of DALE on 13 datasets spanning 6 tasks and 4 low-resource settings. DALE outperforms all our baselines, including LLMs, qualitatively and quantitatively, with absolute improvements of 1%-50%.'}",https://openreview.net{'value': '/attachment/4309906975825244ff9c3f9bd6723db4f6495436.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=TkJkSkmhUy,{'value': 'Injecting structural hints: Using language models to study inductive biases in language learning'},Isabel Papadimitriou; Dan Jurafsky,~Isabel_Papadimitriou1; ~Dan_Jurafsky1,"{'value': ['transfer learning', 'pretraining', 'recursion', 'context-sensitivity']}","{'value': ""Both humans and transformer language models are able to learn language without explicit structural supervision. What cognitive inductive biases make this learning possible? Here, we examine the effect of different inductive learning biases by actively controlling the inductive biases of artificial learners: we structurally bias models by pretraining on synthetic formally-structured data, and evaluate these structural biases by fine-tuning on three typologically-distant human languages: English, Japanese, and Basque. We investigate the effect on downstream language perplexity of three types of inductive bias: 1) recursive, hierarchical processing 2) unrestricted token-token dependencies that can't be modeled by context-free grammars, and 3) a Zipfian power-law vocabulary distribution. We show that complex, non-context-free interactions between tokens form the best inductive biases. Our study leverages the capabilities of transformer models to run controlled language learning experiments that are not possible to run on humans, and surfaces hypotheses about the structures that facilitate language learning in both humans and machines.""}",https://openreview.net{'value': '/pdf/c6ec2d4f4fa4c23f77b9aa44a0659c74815dd938.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=TKo2JXw7vL,{'value': 'Large Language Models Meet Harry Potter: A Dataset for Aligning Dialogue Agents with Characters'},Nuo Chen; Yan Wang; Haiyun Jiang; Deng Cai; Yuhan Li; ziyang chen; Longyue Wang; Jia Li,~Nuo_Chen1; ~Yan_Wang17; ~Haiyun_Jiang1; ~Deng_Cai1; ~Yuhan_Li3; ~ziyang_chen8; ~Longyue_Wang3; ~Jia_Li4,"{'value': ['Personalized dialogue systems', 'dataset']}","{'value': 'In recent years, Dialogue-style Large Language Models (LLMs) such as ChatGPT and GPT4 have demonstrated immense potential in constructing open-domain dialogue agents. However, aligning these agents with specific characters or individuals remains a considerable challenge due to the complexities of character representation and the lack of comprehensive annotations. In this paper, we introduce the Harry Potter Dialogue (HPD) dataset, designed to advance the study of dialogue agents and character alignment. The dataset encompasses all dialogue sessions (in both English and Chinese) from the Harry Potter series and is annotated with vital background information, including dialogue scenes, speakers, character relationships, and attributes. These extensive annotations may empower LLMs to unlock character-driven dialogue capabilities. Furthermore, it can serve as a universal benchmark for evaluating how well can a LLM aligning with a specific character. We benchmark LLMs on HPD using both fine-tuning and in-context learning settings. Evaluation results reveal that although there is substantial room for improvement in generating high-quality, character-aligned responses, the proposed dataset is valuable in guiding models toward responses that better align with the character of Harry Potter.'}",https://openreview.net{'value': '/attachment/96fba9367c96f1ee9aa990cdedf1d7f2b56d8ace.pdf'},{'title_filter': 'Agent'},EMNLP,2023,Conference
https://openreview.net/forum?id=THr9aJ3z9k,{'value': 'Quick Back-Translation for Unsupervised Machine Translation'},Benjamin Lincoln Brimacombe; Jiawei Zhou,~Benjamin_Lincoln_Brimacombe1; ~Jiawei_Zhou1,"{'value': ['unsupervised machine translation', 'back-translation', 'non-autoregressive generation', 'Transformer']}","{'value': ""The field of unsupervised machine translation has seen significant advancement from the marriage of the Transformer and the back-translation algorithm. The Transformer is a powerful generative model, and back-translation leverages Transformer's high-quality translations for iterative self-improvement. However, the Transformer is encumbered by the run-time of autoregressive inference during back-translation, and back-translation is limited by a lack of synthetic data efficiency. We propose a two-for-one improvement to Transformer back-translation: Quick Back-Translation (QBT). QBT re-purposes the encoder as a generative model, and uses encoder-generated sequences to train the decoder in conjunction with the original autoregressive back-translation step, improving data throughput and utilization. Experiments on various WMT benchmarks demonstrate that a relatively small number of refining steps of QBT improve current unsupervised machine translation models, and that QBT dramatically outperforms standard back-translation only method in terms of training efficiency for comparable translation qualities.""}",https://openreview.net{'value': '/attachment/82d3af9186e3562c5db7640db09c67fe8dcaf92c.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=T3n9nbeIKc,{'value': 'Dataset Bias Mitigation in Multiple-Choice Visual Question Answering and Beyond'},Zhecan Wang; Long Chen; Haoxuan You; Keyang Xu; Yicheng He; Wenhao Li; Noel C Codella; Kai-Wei Chang; Shih-Fu Chang,~Zhecan_Wang2; ~Long_Chen8; ~Haoxuan_You1; ~Keyang_Xu2; ~Yicheng_He1; ~Wenhao_Li5; ~Noel_C_Codella1; ~Kai-Wei_Chang1; ~Shih-Fu_Chang3,"{'value': ['vision language', 'vcr', 'vqa', 'snli-ve', 'visual question answering', 'commonsense reasoning', 'pretraining', 'multimodal', 'robust', 'low-shot', 'zero-shot', 'domain-shift', 'debiased', 'shortcut']}","{'value': ""Vision-language (VL) understanding tasks evaluate models' comprehension of complex visual scenes through multiple-choice questions. However, we have identified two dataset biases that models can exploit as shortcuts to resolve various VL tasks correctly without proper understanding. The first type of dataset bias is Unbalanced Matching bias, where the correct answer overlaps the question and image more than the incorrect answers. The second type of dataset bias is Distractor Similarity bias, where incorrect answers are overly dissimilar to the correct answer but significantly similar to other incorrect answers within the same sample. To address these dataset biases, we first propose Adversarial Data Synthesis (ADS) to generate synthetic training and debiased evaluation data. We then introduce Intra-sample Counterfactual Training (ICT) to assist models in utilizing the synthesized training data, particularly the counterfactual data, via focusing on intra-sample differentiation. Extensive experiments demonstrate the effectiveness of ADS and ICT in consistently improving model performance across different benchmarks, even in domain-shifted scenarios.""}",https://openreview.net{'value': '/pdf/83b67738233c186cd03780c4cc531e953f375b0f.pdf'},{'abstract_filter': 'Data Synthesis'},EMNLP,2023,Conference
https://openreview.net/forum?id=S5eTDhfjHM,{'value': 'tagE: Enabling an Embodied Agent to Understand Human Instructions'},Chayan Sarkar; Avik Mitra; Pradip Pramanick; Tapas Nayak,~Chayan_Sarkar1; ~Avik_Mitra1; ~Pradip_Pramanick1; ~Tapas_Nayak1,{'value': ['human-robot interaction; NLP for robotics; task and argument extraction; task and argument grounding;']},"{'value': ""Natural language serves as the primary mode of communication when an intelligent agent with a physical presence engages with human beings. While a plethora of research focuses on natural language understanding (NLU), encompassing endeavors such as sentiment analysis, intent prediction, question answering, and summarization, the scope of NLU directed at situations necessitating tangible actions by an embodied agent remains limited. The inherent ambiguity and incompleteness inherent in natural language present challenges for intelligent agents striving to decipher human intention. To tackle this predicament head-on, we introduce a novel system known as task and argument grounding for Embodied agents (tagE). At its core, our system employs an inventive neural network model designed to extract a series of tasks from complex task instructions expressed in natural language. Our proposed model adopts an encoder-decoder framework enriched with nested decoding to effectively extract tasks and their corresponding arguments from these intricate instructions. These extracted tasks are then mapped (or grounded) to the robot's established collection of skills, while the arguments find grounding in objects present within the environment. To facilitate the training and evaluation of our system, we have curated a dataset featuring complex instructions. The results of our experiments underscore the prowess of our approach, as it outperforms robust baseline models.""}",https://openreview.net{'value': '/attachment/02f3fc35fe3e2b972e4788fb32685533d1b30eb2.pdf'},{'title_filter': 'Agent'},EMNLP,2023,Conference
https://openreview.net/forum?id=QV79qiKAjD,{'value': 'On the Benefits of Learning to Route in Mixture-of-Experts Models'},Nishanth Dikkala; Nikhil Ghosh; Raghu Meka; Rina Panigrahy; Nikhil Vyas; Xin Wang,~Nishanth_Dikkala1; ~Nikhil_Ghosh1; ~Raghu_Meka1; ~Rina_Panigrahy1; ~Nikhil_Vyas1; ~Xin_Wang30,"{'value': ['mixture-of-experts', 'transformer', 'router', 'efficiency', 'conditional compute', 'sparsely activated models', 'theory']}","{'value': ""Mixture-of-Expert (MoE) Transformer models, such as the Switch Transformer, allow us to successfully scale up model sizes while keeping the amount of compute time fixed. Prior work has established the computational efficiency benefits of using these models. A core component of these models is a router that routes input tokens to different experts in a layer. We show theoretical and empirical evidence that the router's ability to route tokens intelligently confers a significant advantage to MoE models. We study synthetic settings where the input data is distributed in clusters and show theoretically and empirically that the router learns to route the inputs according to these clusters. Then we perform experiments on real data using the T5X library, where we observe that a trainable router confers a non-trivial benefit instead of a non-trainable router.""}",https://openreview.net{'value': '/attachment/d361a42eb04612d5d79fe7322592116e67da9f22.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=PffUQuD8sn,{'value': 'Statistical Depth for Ranking and Characterizing Transformer-Based Text Embeddings'},Parker Seegmiller; Sarah Masud Preum,~Parker_Seegmiller1; ~Sarah_Masud_Preum1,"{'value': ['text embeddings', 'transformers', 'statistical inference', 'corpus analysis', 'statistical depth', 'in-context learning', 'synthetic data augmentation']}","{'value': 'The popularity of transformer-based text embeddings calls for better statistical tools for measuring distributions of such embeddings. One such tool would be a method for ranking texts within a corpus by centrality, i.e. assigning each text a number signifying how representative that text is of the corpus as a whole. However, an intrinsic center-outward ordering of high-dimensional text representations is not trivial. A $\\textit{statistical depth}$ is a function for ranking $k$-dimensional objects by measuring centrality with respect to some observed $k$-dimensional distribution. We adopt a statistical depth to measure distributions of transformer-based text embeddings, $\\textit{transformer-based text embedding (TTE) depth}$, and introduce the practical use of this depth for both modeling and distributional inference in NLP pipelines. We first define TTE depth and an associated rank sum test for determining whether two corpora differ significantly in embedding space. We then use TTE depth for the task of in-context learning prompt selection, showing that this approach reliably improves performance over statistical baseline approaches across six text classification tasks. Finally, we use TTE depth and the associated rank sum test to characterize the distributions of synthesized and human-generated corpora, showing that five recent synthetic data augmentation processes cause a measurable distributional shift away from associated human-generated text.'}",https://openreview.net{'value': '/attachment/1d09737727a6bbaa9c4687459cd6c7064b933604.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=O1IEUXd4SI,{'value': 'Do Stochastic Parrots have Feelings Too? Improving Neural Detection of Synthetic Text via Emotion Recognition'},Alan Cowap; Yvette Graham; Jennifer Foster,~Alan_Cowap1; ~Yvette_Graham1; ~Jennifer_Foster2,"{'value': ['synthetic text detection', 'neural text detection', 'emotion', 'affective deficit']}","{'value': 'Recent developments in generative AI have shone a spotlight on high-performance synthetic text generation technologies. The now wide availability and ease of use of such models highlights the urgent need to provide equally powerful technologies capable of identifying synthetic text. With this in mind, we draw inspiration from psychological studies which suggest that people can be driven by emotion and encode emotion in the text they compose. We hypothesize that pretrained language models (PLMs) have an affective deficit because they lack such an emotional driver when generating text and consequently may generate synthetic text which has affective incoherence i.e. lacking the kind of emotional coherence present in human-authored text. We subsequently develop an emotionally aware detector by fine-tuning a PLM on emotion. Experiment results indicate that our emotionally-aware detector achieves improvements across a range of synthetic text generators, various sized models, datasets, and domains. Finally, we compare our emotionally-aware synthetic text detector to ChatGPT in the task of identification of its own output and show substantial gains, reinforcing the potential of emotion as a signal to identify synthetic text. Code, models, and datasets are available at https: //github.com/alanagiasi/emoPLMsynth'}",https://openreview.net{'value': '/attachment/4300aeaf087ca7833f719fb4dad558d5e0ceb386.pdf'},{'title_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=NrmYYAO7N4,"{'value': 'Expand, Highlight, Generate: RL-driven Document Generation for Passage Reranking'}",Arian Askari; Mohammad Aliannejadi; Chuan Meng; Evangelos Kanoulas; Suzan Verberne,~Arian_Askari1; ~Mohammad_Aliannejadi2; ~Chuan_Meng1; ~Evangelos_Kanoulas1; ~Suzan_Verberne1,"{'value': ['Synthetic document generation', 'Data augmentation', 'Information retrieval']}","{'value': 'Generating synthetic training data based on large language models (LLMs) for ranking models has gained attention recently. Prior studies use LLMs to build pseudo query-document pairs by generating synthetic queries from documents in a corpus. In this paper, we propose a new perspective of data augmentation: generating synthetic documents from queries. To achieve this, we propose DocGen, that consists of a three-step pipeline that utilizes the few-shot capabilities of LLMs. DocGen pipeline performs synthetic document generation by (i) expanding, (ii) highlighting the original query, and then (iii) generating a synthetic document that is likely to be relevant to the query. To further improve the relevance between generated synthetic documents and their corresponding queries, we propose DocGen-RL, which regards the estimated relevance of the document as a reward and leverages reinforcement learning (RL) to optimize DocGen pipeline. Extensive experiments demonstrate that DocGen pipeline and DocGen-RL significantly outperform existing state-of-theart data augmentation methods, such as InPars, indicating that our new perspective of generating documents leverages the capacity of LLMs in generating synthetic data more effectively. We release the code, generated data, and model checkpoints to foster research in this area.'}",https://openreview.net{'value': '/attachment/70ba88bff27943a45b6fd37d3eb4b43f12080eb4.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=NMMnxhQm01,{'value': 'The Distributional Hypothesis Does Not Fully Explain the Benefits of Masked Language Model Pretraining'},Ting-Rui Chiang; Dani Yogatama,~Ting-Rui_Chiang1; ~Dani_Yogatama2,"{'value': ['Distributional Hypothesis', 'MLM', 'Pretraining']}","{'value': ""We analyze the masked language modeling pretraining objective function from the perspective of the Distributional Hypothesis.\nWe investigate whether the better sample efficiency and\nthe better generalization capability of models\npretrained with masked language modeling can\nbe attributed to the semantic similarity encoded in the pretraining data's distributional property.\nVia a synthetic dataset, our analysis suggests that distributional property indeed leads to the better sample efficiency of pretrained masked language models, but \ndoes not fully explain the generalization capability.\nWe also conduct an analysis over two real-world datasets \nand demonstrate that the distributional property does not explain the generalization ability\nof pretrained natural language models either.\nOur results illustrate our limited understanding of model pretraining and provide future research directions.""}",https://openreview.net{'value': '/attachment/1272479384ba10c790cd33a11a7987b4092f082f.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=N7R2emgl67,{'value': 'Learning to Rank Context for Named Entity Recognition Using a Synthetic Dataset'},Arthur Amalvy; Vincent Labatut; Richard Dufour,~Arthur_Amalvy1; ~Vincent_Labatut1; ~Richard_Dufour1,"{'value': ['ner', 'transformers', 'context retrieval']}","{'value': 'While recent pre-trained transformer-based models can perform named entity recognition (NER) with great accuracy, their limited range remains an issue when applied to long documents such as whole novels. To alleviate this issue, a solution is to retrieve relevant context at the document level. Unfortunately, the lack of supervision for such a task means one has to settle for unsupervised approaches. Instead, we propose to generate a synthetic context retrieval training dataset using Alpaca, an instruction-tuned large language model (LLM). Using this dataset, we train a neural context retriever based on a BERT model that is able to find relevant context for NER. We show that our method outperforms several retrieval baselines for the NER task on an English literary dataset composed of the first chapter of 40 books.'}",https://openreview.net{'value': '/attachment/68c2ea1f54ab77158386cb516fe6deb4665632b1.pdf'},{'title_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=MyTyc69kKK,{'value': 'TSTR: Target Similarity Tuning Meets the Real World'},Anirudh Khatry; Sumit Gulwani; Priyanshu Gupta; Vu Le; Mukul Singh; Ananya Singha; Gust Verbruggen,~Anirudh_Khatry1; ~Sumit_Gulwani1; ~Priyanshu_Gupta1; ~Vu_Le2; ~Mukul_Singh1; ~Ananya_Singha1; ~Gust_Verbruggen1,"{'value': ['prompt engineering', 'code generation', 'target similarity tuning', 'example selection']}","{'value': 'Target similarity tuning (TST) is a method of selecting relevant examples in natural language (NL) to code generation through large language models (LLMs) to improve performance. Its goal is to adapt a sentence embedding model to have the similarity between two NL inputs match the similarity between their associated code outputs. In this paper, we propose different methods to apply and improve TST in the real world. First, we replace the sentence transformer with embeddings from a larger model, which reduces sensitivity to the language distribution and thus provides more flexibility in synthetic generation of examples, and we train a tiny model that transforms these embeddings to a space where embedding similarity matches code similarity, which allows the model to remain a black box and only requires a few matrix multiplications at inference time. Second, we how to efficiently select a smaller number of training examples to train the TST model. Third, we introduce a ranking-based evaluation for TST that does not require end-to-end code generation experiments, which can be expensive to perform.'}",https://openreview.net{'value': '/attachment/456f294a815d25c233fd2cae825e6f054411d457.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=MmBjKmHIND,{'value': 'Synthetic Data Generation with Large Language Models for Text Classification: Potential and Limitations'},Zhuoyan Li; Hangxiao Zhu; Zhuoran Lu; Ming Yin,~Zhuoyan_Li2; ~Hangxiao_Zhu1; ~Zhuoran_Lu1; ~Ming_Yin2,"{'value': ['Synthetic Data Generation', 'Data Augmentation', 'Large Language Models']}","{'value': 'The collection and curation of high-quality training data is crucial for developing text classification models with superior performance, but it is often associated with significant costs and time investment.  Researchers have recently explored using large language models (LLMs) to generate synthetic datasets as an alternative approach. However, the effectiveness of the LLM-generated synthetic data in supporting model training is inconsistent across different classification tasks.  To better understand factors that moderate the effectiveness of the LLM-generated synthetic data, in this study, we look into how the performance of models trained on these synthetic data may vary with the $\\textit{subjectivity}$ of classification.  Our results indicate that subjectivity, at both the task level and instance level, is negatively associated with the performance of the model trained on synthetic data.   We conclude by discussing the implications of our work on the potential and limitations of leveraging LLM for synthetic data generation.'}",https://openreview.net{'value': '/attachment/39c9c649e3a3ce6bfb08ed15a34fc90d62b55f1c.pdf'},{'title_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=MRehcsVc4y,{'value': 'RSVP: Customer Intent Detection via Agent Response Contrastive and Generative Pre-Training'},Yu-Chien Tang; Wei-Yao Wang; An-Zi Yen; Wen-Chih Peng,~Yu-Chien_Tang1; ~Wei-Yao_Wang1; ~An-Zi_Yen1; ~Wen-Chih_Peng1,"{'value': ['Intent Detection', 'Task Adaptive Fine-Tuning', 'Contrastive Learning', 'Question Answering']}","{'value': ""The dialogue systems in customer services have been developed with neural models to provide users with precise answers and round-the-clock support in task-oriented conversations by detecting customer intents based on their utterances. Existing intent detection approaches have highly relied on adaptively pre-training language models with large-scale datasets, yet the predominant cost of data collection may hinder their superiority. In addition, they neglect the information within the conversational responses of the agents, which have a lower collection cost, but are significant to customer intent as agents must tailor their replies based on the customers' intent. In this paper, we propose RSVP, a self-supervised framework dedicated to task-oriented dialogues, which utilizes agent responses for pre-training in a two-stage manner. Specifically, we introduce two pre-training tasks to incorporate the relations of utterance-response pairs: 1) Response Retrieval by selecting a correct response from a batch of candidates, and 2) Response Generation by mimicking agents to generate the response to a given utterance. Our benchmark results for two real-world customer service datasets show that RSVP significantly outperforms the state-of-the-art baselines by 4.95% for accuracy, 3.4% for MRR@3, and 2.75% for MRR@5 on average. Extensive case studies are investigated to show the validity of incorporating agent responses into the pre-training stage.""}",https://openreview.net{'value': '/attachment/6586ea73f903f174835e2ac5651567aa2c96b2f5.pdf'},{'title_filter': 'Agent'},EMNLP,2023,Conference
https://openreview.net/forum?id=KCe98ynJl3,{'value': 'Zero-shot Faithfulness Evaluation for Text Summarization with Foundation Language Model'},Qi Jia; Siyu Ren; Yizhu Liu; Kenny Q. Zhu,~Qi_Jia3; ~Siyu_Ren1; ~Yizhu_Liu2; ~Kenny_Q._Zhu1,"{'value': ['Faithfulness Evaluation', 'Summarization Evaluation', 'Hallucination Detection']}","{'value': 'Despite tremendous improvements in natural language generation, summarization models still suffer from the unfaithfulness issue. Previous work evaluates faithfulness either using models trained on the other tasks or in-domain synthetic data, or prompting a large model such as ChatGPT. This paper proposes to do zero-shot faithfulness evaluation simply with a moderately-sized foundation language model. We introduce a new metric FFLM, which is a combination of probability changes based on the intuition that prefixing a piece of text that is consistent with the output will increase the probability of predicting the output. Experiments show that FFLM performs competitively with or even outperforms ChatGPT on both inconsistency detection and faithfulness rating with 24x fewer parameters. FFLM also achieves improvements over other strong baselines.'}",https://openreview.net{'value': '/attachment/50494bca31793ed71f5dbe8659234b44289e3073.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=JiUTJJrkL4,{'value': 'clembench: Using Game Play to Evaluate Chat-Optimized Language Models as Conversational Agents'},Kranti CH; Jana Götze; Sherzod Hakimov; Brielen Madureira; Philipp Sadler; David Schlangen,~Kranti_CH1; ~Jana_Götze1; ~Sherzod_Hakimov1; ~Brielen_Madureira1; ~Philipp_Sadler1; ~David_Schlangen1,{'value': ['large language models; evaluation; dialogue; dialogue games; interaction']},"{'value': 'Recent work has proposed a methodology for the systematic evaluation of ""Situated Language Understanding Agents"" --- agents that operate in rich linguistic and non-linguistic contexts --- through testing them in carefully constructed interactive settings. Other recent work has argued that Large Language Models (LLMs), if suitably set up, can be understood as (simulators of) such agents. A connection suggests itself, which this paper explores: Can LLMs be evaluated meaningfully by exposing them to constrained game-like settings that are built to challenge specific capabilities? As a proof of concept, this paper investigates five interaction settings, showing that current chat-optimised LLMs are, to an extent, capable of following game-play instructions. Both this capability and the quality of the game play, measured by how well the objectives of the different games are met, follows the development cycle, with newer models generally performing better. The metrics even for the comparatively simple example games are far from being saturated, suggesting that the proposed instrument will remain to have diagnostic value.'}",https://openreview.net{'value': '/attachment/c29e81e7791138f665103950989c37b18d1b1148.pdf'},{'title_filter': 'Agent'},EMNLP,2023,Conference
https://openreview.net/forum?id=J9vgDEDjAw,{'value': 'UDAPDR: Unsupervised Domain Adaptation via LLM Prompting and Distillation of Rerankers'},Jon Saad-Falcon; Omar Khattab; Keshav Santhanam; Radu Florian; Martin Franz; Salim Roukos; Avirup Sil; Md Arafat Sultan; Christopher Potts,~Jon_Saad-Falcon1; ~Omar_Khattab1; ~Keshav_Santhanam1; ~Radu_Florian1; ~Martin_Franz1; ~Salim_Roukos1; ~Avirup_Sil1; ~Md_Arafat_Sultan1; ~Christopher_Potts1,"{'value': ['Natural Language Processing', 'Information Retrieval', 'Domain Adaptation']}","{'value': 'Many information retrieval tasks require large labeled datasets for fine-tuning. However, such datasets are often unavailable, and their utility for real-world applications can diminish quickly due to domain shifts. To address this challenge, we develop and motivate a method for using large language models (LLMs) to generate large numbers of synthetic queries cheaply. The method begins by generating a small number of synthetic queries using an expensive LLM. After that, a much less expensive one is used to create large numbers of synthetic queries, which are used to fine-tune a family of reranker models. These rerankers are then distilled into a single efficient retriever for use in the target domain. We show that this technique boosts zero-shot accuracy in long-tail domains and achieves substantially lower latency than standard reranking methods.'}",https://openreview.net{'value': '/attachment/1d83ea61724eac656c33bdb7269e0a4f19ca72ef.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=J6pq6AcmbE,{'value': 'A Zero-Shot Language Agent for Computer Control with Structured Reflection'},Tao Li; Gang Li; Zhiwei Deng; Bryan Wang; Yang Li,~Tao_Li11; ~Gang_Li13; ~Zhiwei_Deng3; ~Bryan_Wang1; ~Yang_Li2,"{'value': ['planning', 'reflection', 'action', 'grounding']}","{'value': 'Large language models (LLMs) have shown increasing capacity at planning and executing a high-level goal in a live computer environment (e.g. MiniWoB++). To perform a task, recent works often require a model to learn from trace examples of the task via either supervised learning or few/many-shot prompting. Without these trace examples, it remains a challenge how an agent can autonomously learn and improve its control on a computer, which limits the ability of an agent to perform a new task. We approach this problem with a zero-shot agent that requires no given expert traces. Our agent plans for executable actions on a partially observed environment, and iteratively progresses a task by identifying and learning from its mistakes via self-reflection and structured thought management. On the easy tasks of MiniWoB++, we show that our zero-shot agent often outperforms recent SoTAs, with more efficient reasoning. For tasks with more complexity, our reflective agent performs on par with prior best models, even though previous works had the advantages of accessing expert traces or additional screen information.'}",https://openreview.net{'value': '/attachment/4028119d75addd89b552522d9f0c1da15d315911.pdf'},{'title_filter': 'Agent'},EMNLP,2023,Conference
https://openreview.net/forum?id=Itnbse9MMW,{'value': 'An Integrative Survey on Mental Health Conversational Agents to Bridge Computer Science and Medical Perspectives'},Young Min Cho; Sunny Rai; Lyle Ungar; João Sedoc; Sharath Chandra Guntuku,~Young_Min_Cho1; ~Sunny_Rai1; ~Lyle_Ungar1; ~João_Sedoc1; ~Sharath_Chandra_Guntuku2,"{'value': ['Conversational Agent', 'Chatbot', 'Mental health']}","{'value': 'Mental health conversational agents (a.k.a. chatbots) are widely studied for their potential to offer accessible support to those experiencing mental health challenges. Previous surveys on the topic primarily consider papers published in either computer science or medicine, leading to a divide in understanding and hindering the sharing of beneficial knowledge between both domains. To bridge this gap, we conduct a comprehensive literature review using the PRISMA framework, reviewing 534 papers published in both computer science and medicine. Our systematic review reveals 136 key papers on building mental health-related conversational agents with diverse characteristics of modeling and experimental design techniques. We find that computer science papers focus on LLM techniques and evaluating response quality using automated metrics with little attention to the application while medical papers use rule-based conversational agents and outcome metrics to measure the health outcomes of participants. Based on our findings on transparency, ethics, and cultural heterogeneity in this review, we provide a few recommendations to help bridge the disciplinary divide and enable the cross-disciplinary development of mental health conversational agents.'}",https://openreview.net{'value': '/attachment/1b544f811a7f93df40e36ccdc78c706743ec9c76.pdf'},{'title_filter': 'Agent'},EMNLP,2023,Conference
https://openreview.net/forum?id=IXuCeFnnxU,{'value': 'Noisy Pair Corrector for Dense Retrieval'},Hang Zhang; Yeyun Gong; Xingwei He; Dayiheng Liu; Daya Guo; Jiancheng Lv; Jian Guo,~Hang_Zhang6; ~Yeyun_Gong2; ~Xingwei_He1; ~Dayiheng_Liu1; ~Daya_Guo2; ~Jiancheng_Lv2; ~Jian_Guo2,"{'value': ['Dense Retrieval', 'Noisy Pair']}","{'value': 'Most dense retrieval models contain an implicit assumption: the training query-document pairs are exactly matched. Since it is expensive to annotate the corpus manually, training pairs in real-world applications are usually collected automatically, which inevitably introduces mismatched-pair noise. In this paper, we explore an interesting and challenging problem in dense retrieval, how to train an effective model with mismatched-pair noise. To solve this problem, we propose a novel approach called Noisy Pair Corrector (NPC), which consists of a detection module and a correction module. The detection module estimates noise pairs by calculating the perplexity between annotated positive and easy negative documents. The correction module utilizes an exponential moving average (EMA) model to provide a soft supervised signal, aiding in mitigating the effects of noise. We conduct experiments on text-retrieval benchmarks Natural Question and TriviaQA, code-search benchmarks StaQC and SO-DS. Experimental results show that NPC achieves excellent performance in handling both synthetic and realistic noise.'}",https://openreview.net{'value': '/attachment/88aa49e9d8cc6006ead1ec1b5a81131486c10dd9.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=I5NWLjXbQl,{'value': 'ACQUIRED: A Dataset for Answering Counterfactual Questions In Real-Life Videos'},Te-Lin Wu; Zi-Yi Dou; Qingyuan Hu; Yu Hou; Nischal Reddy Chandra; Marjorie Freedman; Ralph M. Weischedel; Nanyun Peng,~Te-Lin_Wu1; ~Zi-Yi_Dou1; ~Qingyuan_Hu2; ~Yu_Hou1; ~Nischal_Reddy_Chandra1; ~Marjorie_Freedman1; ~Ralph_M._Weischedel1; ~Nanyun_Peng1,"{'value': ['Counterfactual reasoning', 'Video Question Answering', 'Commonsense', 'Multimodal']}","{'value': 'Multimodal counterfactual reasoning is a vital yet challenging ability for AI systems. It involves predicting the outcomes of hypothetical circumstances based on vision and language inputs, which enables AI models to learn from failures and explore hypothetical scenarios. Despite its importance, there are only a few datasets targeting the counterfactual reasoning abilities of multimodal models. Among them, they only cover reasoning over synthetic environments or specific types of events (e.g. traffic collisions), making them hard to reliably benchmark the model generalization ability in diverse real-world scenarios and reasoning dimensions. To overcome these limitations, we develop a video question answering dataset, ACQUIRED: it consists of 3.9K annotated videos, encompassing a wide range of event types and incorporating both first and third-person viewpoints, which ensures a focus on real-world diversity. In addition, each video is annotated with questions that span three distinct dimensions of reasoning, including physical, social, and temporal, which can comprehensively evaluate the model counterfactual abilities along multiple aspects. We benchmark our dataset against several state-of-the-art language-only and multimodal models and experimental results demonstrate a significant performance gap (>13%) between models and humans. The findings suggest that multimodal counterfactual reasoning remains an open challenge and ACQUIRED  is a comprehensive and reliable benchmark for inspiring future research in this direction.'}",https://openreview.net{'value': '/attachment/f70b15837d8e6c90c16625d6efbb3ce60160c169.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=GSNoZKqHgO,"{'value': ""Let's Synthesize Step by Step: Iterative Dataset Synthesis with Large Language Models by Extrapolating Errors from Small Models""}",Ruida WANG; Wangchunshu Zhou; Mrinmaya Sachan,~Ruida_WANG1; ~Wangchunshu_Zhou1; ~Mrinmaya_Sachan3,"{'value': ['Dataset Synthesis', 'large language models', 'efficiency']}","{'value': '*Data Synthesis* is a promising way to train a small model with very little labeled data. One approach for data synthesis is to leverage the rich knowledge from large language models to synthesize pseudo training examples for small models, making it possible to achieve both data and compute efficiency at the same time. However, a key challenge in data synthesis is that the synthesized dataset often suffers from a large distributional discrepancy from the *real task* data distribution. Thus, in this paper, we propose *Synthesis Step by Step* (**S3**), a data synthesis framework that shrinks this distribution gap by iteratively extrapolating the errors made by a small model trained on the synthesized dataset on a small real-world validation dataset using a large language model. Extensive experiments on multiple NLP tasks show that our approach improves the performance of a small model by reducing the gap between the synthetic dataset and the real data, resulting in significant improvement compared to several baselines: 9.48% improvement compared to ZeroGen and 2.73% compared to GoldGen, and at most 15.17% improvement compared to the small model trained on human-annotated data.'}",https://openreview.net{'value': '/attachment/7a00ad41be274fee35acd8057e867f488d04132d.pdf'},{'title_filter': 'Data Synthesis'},EMNLP,2023,Conference
https://openreview.net/forum?id=Faxkz2V56o,{'value': 'Noisy Self-Training with Synthetic Queries for Dense Retrieval'},Fan Jiang; Tom Drummond; Trevor Cohn,~Fan_Jiang2; ~Tom_Drummond1; ~Trevor_Cohn1,"{'value': ['dense retrieval', 'self training', 'synthetic queries']}","{'value': 'Although existing neural retrieval models reveal promising results when training data is abundant and the performance keeps improving as training data increases, collecting high-quality annotated data is prohibitively costly. To this end, we introduce a novel noisy self-training framework combined with synthetic queries, showing that neural retrievers can be improved in a self-evolution manner with no reliance on any external models. Experimental results show that our method improves consistently over existing methods on both general-domain (e.g., MS-MARCO) and out-of-domain (i.e., BEIR) retrieval benchmarks. Extra analysis on low-resource settings reveals that our method is data efficient and outperforms competitive baselines, with as little as 30\\% of labelled training data. Further extending the framework for reranker training demonstrates that the proposed method is general and yields additional gains on tasks of diverse domains.\\footnote{Source code is available at \\url{https://github.com/Fantabulous-J/Self-Training-DPR}}'}",https://openreview.net{'value': '/attachment/2f55e2a1b6650868207552cefbd9dd769d4f2ce9.pdf'},{'title_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=DSmHC8bi3j,{'value': 'Noise-Robust Fine-Tuning of Pretrained Language Models via External Guidance'},Song Wang; Zhen Tan; Ruocheng Guo; Jundong Li,~Song_Wang6; ~Zhen_Tan2; ~Ruocheng_Guo1; ~Jundong_Li2,"{'value': ['Pretrained Language Models', 'Large-scale Language Models', 'Learning from Noisy Labels']}","{'value': 'Adopting a two-stage paradigm of pretraining followed by fine-tuning, Pretrained Language Models (PLMs) have achieved substantial advancements in the field of natural language processing. However, in real-world scenarios, data labels are often noisy due to the complex annotation process, making it essential to develop strategies for fine-tuning PLMs with such noisy labels. To this end, we introduce an innovative approach for fine-tuning PLMs using noisy labels, which incorporates the guidance of Large Language Models (LLMs) like ChatGPT. This guidance assists in accurately distinguishing between clean and noisy samples and provides supplementary information beyond the noisy labels, thereby boosting the learning process during fine-tuning PLMs. Extensive experiments on synthetic and real-world noisy datasets further demonstrate the superior advantages of our framework over the state-of-the-art baselines.'}",https://openreview.net{'value': '/attachment/565d18e5236d3614315884d6113d937d322f9402.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=DQVGhBdAPG,{'value': 'Identification of Multimodal Stance Towards Frames of Communication'},Maxwell Weinzierl; Sanda Harabagiu,~Maxwell_Weinzierl1; ~Sanda_Harabagiu1,"{'value': ['stance detection', 'covid-19', 'social media', 'twitter', 'multimodal', 'images', 'multimedia']}","{'value': 'Frames of communication are often evoked in multimedia documents. When an author decides to add an image to a text, one or both of the modalities may evoke a communication frame. Moreover, when evoking the frame, the author also conveys her/his stance towards the frame. Until now, determining if the author is in favor of, against or has no stance towards the frame was performed automatically only when processing texts. This is due to the absence of stance annotations on multimedia documents. In this paper we introduce MMVax-Stance, a dataset of 11,300 multimedia documents retrieved from social media, which have stance annotations towards 113 different frames of communication. This dataset allowed us to experiment with several models of multimedia stance detection, which revealed important interactions between texts and images in the inference of stance towards communication frames. When inferring the text/image relations, a set of 46,606 synthetic examples of multimodal documents with known stance was generated. This greatly impacted the quality of identifying multimedia stance, yielding an improvement of 20% in F1-score.'}",https://openreview.net{'value': '/attachment/b4fd3afefc3901739819a2211f074c9c5b3321ae.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=D9oq45WsKq,{'value': 'Ensemble-Instruct: Instruction Tuning Data Generation with a Heterogeneous Mixture of LMs'},Young-Suk Lee; Md Arafat Sultan; Yousef El-Kurdi; Tahira Naseem; Asim Munawar; Radu Florian; Salim Roukos; Ramón Fernandez Astudillo,~Young-Suk_Lee1; ~Md_Arafat_Sultan1; ~Yousef_El-Kurdi1; ~Tahira_Naseem1; ~Asim_Munawar2; ~Radu_Florian1; ~Salim_Roukos1; ~Ramón_Fernandez_Astudillo1,"{'value': ['instruction tuning data generation', 'prompt learning', 'ensemble learning']}","{'value': 'Using in-context learning (ICL) for data generation, techniques such as Self-Instruct (Wang et al., 2023) or the follow-up Alpaca (Taori et al., 2023) can train strong conversational agents with only a small amount of human supervision. One limitation of these approaches is that they resort to very large language models (around 175B parameters) that are also proprietary and non-public. Here we explore the application of such techniques to language models that are much smaller (around 10B--40B parameters) and have permissive licenses. \nWe find the Self-Instruct approach to be less effective at these sizes and propose new ICL methods that draw on two main ideas: (a) categorization and simplification of the ICL templates to make prompt learning easier for the LM, and (b) ensembling over multiple LM outputs to help select high-quality synthetic examples. Our algorithm leverages the 175 Self-Instruct seed tasks and employs separate pipelines for instructions that require an input and instructions that do not. Empirical investigations with different LMs show that: (1) Our proposed method yields higher-quality instruction tuning data than Self-Instruct, (2) It improves performances of both vanilla and instruction-tuned LMs by significant margins, and (3) Smaller instruction-tuned LMs generate more useful examples than their larger un-tuned counterparts.'}",https://openreview.net{'value': '/attachment/7c9050ede90d00594710a3777569623457aceb91.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=CfJiBuysQQ,{'value': 'CLEVR-Implicit: A Diagnostic Dataset for Implicit Reasoning in Referring Expression Comprehension'},Jingwei Zhang; Xin Wu; Yi Cai,~Jingwei_Zhang12; ~Xin_Wu4; ~Yi_Cai1,"{'value': ['referring expression comprehension', 'implicit reasoning', 'prompt tuning']}","{'value': 'Recently, pre-trained vision-language (VL) models have achieved remarkable success in various cross-modal tasks, including referring expression comprehension (REC). These models are pre-trained on the large-scale image-text pairs to learn the alignment between words in textual descriptions and objects in the corresponding images and then fine-tuned on downstream tasks. However, the performance of VL models is hindered when dealing with implicit text, which describes objects through comparisons between two or more objects rather than explicitly mentioning them. This is because the models struggle to align the implicit text with the objects in the images. To address the challenge, we introduce CLEVR-Implicit, a dataset consisting of synthetic images and corresponding two types of implicit text for the REC task. Additionally, to enhance the performance of VL models on implicit text, we propose a method called Transforming Implicit text into Explicit text (TIE), which enables VL models to reason with the implicit text. TIE consists of two modules: (1) the prompt design module builds prompts for implicit text by adding masked tokens, and (2) the cloze procedure module fine-tunes the prompts by utilizing masked language modeling (MLM) to predict the explicit words with the implicit prompts. Experimental results on our dataset demonstrate a significant improvement of 37.94\\% in the performance of VL models on implicit text after employing our TIE method.'}",https://openreview.net{'value': '/attachment/253384d94dbd9d6fab5c96c52b02c09ba2a9e514.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=Bou2YHsRvG,{'value': 'Code-Switching with Word Senses for Pretraining in Neural Machine Translation'},Vivek Iyer; Edoardo Barba; Alexandra Birch; Jeff Z. Pan; Roberto Navigli,~Vivek_Iyer1; ~Edoardo_Barba1; ~Alexandra_Birch1; ~Jeff_Z._Pan1; ~Roberto_Navigli2,"{'value': ['Word Sense Disambiguation', 'Pretraining approaches', 'Neural Machine Translation']}","{'value': 'Lexical ambiguity is a significant and pervasive challenge in Neural Machine Translation (NMT), with many state-of-the-art (SOTA) NMT systems struggling to handle polysemous words (Campolungo et al., 2022). The same holds for the NMT pretraining paradigm of denoising synthetic ""code-switched"" text (Pan et al., 2021; Iyer et al., 2023), where word senses are ignored in the noising stage -- leading to harmful sense biases in the pretraining data that are subsequently inherited by the resulting models. In this work, we introduce Word Sense Pretraining for Neural Machine Translation (WSP-NMT) - an end-to-end approach for pretraining multilingual NMT models leveraging word sense-specific information from Knowledge Bases. Our experiments show significant improvements in overall translation quality. Then, we show the robustness of our approach to scale to various challenging data and resource-scarce scenarios and, finally, report fine-grained accuracy improvements on the DiBiMT disambiguation benchmark. Our studies yield interesting and novel insights into the merits and challenges of integrating word sense information and structured knowledge in multilingual pretraining for NMT.'}",https://openreview.net{'value': '/attachment/49580956ca45109a1571db46e21a321f441577f1.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=BYkD1gjbxm,{'value': 'Optimized Tokenization for Transcribed Error Correction'},Tomer Wullach; Shlomo Chazan,~Tomer_Wullach1; ~Shlomo_Chazan1,"{'value': ['NLP', 'Speech Recognition', 'Error Correction']}","{'value': 'The challenges facing speech recognition systems, such as variations in pronunciations, adverse audio conditions, and the scarcity of labeled data, emphasize the necessity for a post-processing step that corrects recurring errors. Previous research has shown the advantages of employing dedicated error correction models, yet training such models requires large amounts of labeled data which is not easily obtained. To overcome this limitation, synthetic transcribed-like data is often utilized, however, bridging the distribution gap between transcribed errors and synthetic noise is not trivial.\nIn this paper, we demonstrate that the performance of correction models can be significantly increased by training solely using synthetic data. \nSpecifically, we empirically show that: (1) synthetic data generated using the error distribution derived from a set of transcribed data outperforms the common approach of applying random perturbations; (2) applying language-specific adjustments to the vocabulary of a BPE tokenizer strike a balance between adapting to unseen distributions and retaining knowledge of transcribed errors.\nWe showcase the benefits of these key observations, and evaluate our approach using multiple languages, speech recognition systems and prominent speech recognition datasets.'}",https://openreview.net{'value': '/attachment/f5ba3fe3121f9461225d65e237822992c5abb809.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=B6BXB4g8eQ,"{'value': 'Be Selfish, But Wisely: Investigating the Impact of Agent Personality in Mixed-Motive Human-Agent Interactions'}",Kushal Chawla; Ian Wu; Yu Rong; Gale Lucas; Jonathan Gratch,~Kushal_Chawla2; ~Ian_Wu1; ~Yu_Rong5; ~Gale_Lucas1; ~Jonathan_Gratch1,"{'value': ['dialogue', 'negotiation', 'personality', 'reinforcement learning']}","{'value': 'A natural way to design a negotiation dialogue system is via self-play RL: train an agent that learns to maximize its performance by interacting with a simulated user that has been designed to imitate human-human dialogue data. Although this procedure has been adopted in prior work, we find that it results in a fundamentally flawed system that fails to learn the value of compromise in a negotiation, which can often lead to no agreements (i.e., the partner walking away without a deal), ultimately hurting the model’s overall performance. We investigate this observation in the context of DealOrNoDeal task, a multi-issue negotiation over books, hats, and balls. Grounded in negotiation theory from Economics, we modify the training procedure in two novel ways to design agents with diverse personalities and analyze their performance with human partners. We find that although both techniques show promise, a selfish agent, which maximizes its own performance while also avoiding walkaways, performs superior to other variants by implicitly learning to generate value for both itself and the negotiation partner. We discuss the implications of our findings for what it means to be a successful negotiation dialogue system and how these systems should be designed in the future.'}",https://openreview.net{'value': '/attachment/c17be3a845e0ced6b505dd3007f69e1a24b5beeb.pdf'},{'title_filter': 'Agent'},EMNLP,2023,Conference
https://openreview.net/forum?id=AptTXihnhH,{'value': 'Character-LLM: A Trainable Agent for Role-Playing'},Yunfan Shao; Linyang Li; Junqi Dai; Xipeng Qiu,~Yunfan_Shao1; ~Linyang_Li1; ~Junqi_Dai1; ~Xipeng_Qiu1,"{'value': ['human simulacra', 'LLM']}","{'value': 'Large language models (LLMs) can be used to serve as agents to simulate human behaviors, given the powerful ability to understand human instructions and provide high-quality generated texts.\nSuch ability stimulates us to wonder whether LLMs can simulate a person in a higher form than simple human behaviors.\nTherefore, we aim to train an agent with the profile, experience, and emotional states of a specific person instead of using limited prompts to instruct ChatGPT API. \nIn this work, we introduce Character-LLM that teach LLMs to act as specific people such as Beethoven, Queen Cleopatra, Julius Caesar, etc.\nOur method focuses on editing profiles as experiences of a certain character and training models to be personal simulacra with these experiences.\nTo assess the effectiveness of our approach, we build a test playground that interviews trained agents and evaluates whether the agents \\textit{memorize} their characters and experiences.\nExperimental results show interesting observations that help build future simulacra of humankind.\\footnote{Code and datasets are public at \\url{https://github.com/choosewhatulike/trainable-agents}}'}",https://openreview.net{'value': '/attachment/86874ca293d90b1c161141d1cc98056cc2fb0e1f.pdf'},{'title_filter': 'Agent'},EMNLP,2023,Conference
https://openreview.net/forum?id=A0xVOahTiw,{'value': 'MaNtLE: Model-agnostic Natural Language Explainer'},Rakesh R Menon; Kerem Zaman; Shashank Srivastava,~Rakesh_R_Menon3; ~Kerem_Zaman1; ~Shashank_Srivastava1,"{'value': ['explainable AI', 'interpretability']}","{'value': 'Understanding the internal reasoning behind the predictions of machine learning systems is increasingly vital, given their rising adoption and acceptance. While previous approaches, such as LIME generate algorithmic explanations by attributing importance to input features for individual examples, recent research indicates that practitioners prefer examining language explanations that explain sub-groups of examples (Lakkaraju et al., 2022). In this paper, we introduce MaNtLE, a model-agnostic natural language explainer that analyzes a set of classifier predictions and generates faithful natural language explanations of classifier rationale for structured classification tasks. MaNtLE uses multi-task training on thousands of synthetic classification tasks to generate faithful explanations. Our experiments indicate that, on average, MaNtLE-generated explanations are at least 11% more faithful compared to LIME and Anchors explanations across three tasks. Human evaluations demonstrate that users can better predict model behavior using explanations from MaNtLE compared to other techniques.'}",https://openreview.net{'value': '/attachment/9a2a6299478c7c521b4f6a661066f6bf135b19a6.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=9GxP2Kw8IC,"{'value': 'Synthesize, if you do not have: Effective Synthetic Dataset Creation Strategies for Self-Supervised Opinion Summarization in E-commerce'}",Tejpalsingh Siledar; Suman Banerjee; Amey Patil; Sudhanshu Shekhar Singh; Muthusamy Chelliah; Nikesh Garera; Pushpak Bhattacharyya,~Tejpalsingh_Siledar2; ~Suman_Banerjee4; ~Amey_Patil1; ~Sudhanshu_Shekhar_Singh1; ~Muthusamy_Chelliah1; ~Nikesh_Garera1; ~Pushpak_Bhattacharyya1,"{'value': ['opinion summarization', 'summarization', 'ecommerce', 'nlp']}","{'value': 'In e-commerce, opinion summarization is the process of condensing the opinions presented in product reviews. However, the absence of\nlarge amounts of supervised datasets presents challenges in generating both aspect-specific and general opinion summaries. Existing\napproaches have attempted to address these challenges through synthetic dataset creation (SDC). However, general opinion summarization models struggle to generate summaries faithful to the input reviews whereas aspect-specific opinion summarization models are limited due to their reliance on human-specified aspects and seed words. To address this, we propose SDC strategies tailored for general and aspect-specific opinion summarization. We experimented on three e-commerce test sets: Oposum+, Amazon, and Flipkart. For general opinion summarization, pre-trained language model (PLM) fine-tuned on our general synthetic dataset surpass the SOTA on average by 2.3 R1 points. Faithfulness evaluation metrics and human evaluations indicate that our model-generated summaries are more faithful to the input compared to others. For aspect-specific opinion summarization, PLM fine-tuned on our aspect-specific synthetic dataset surpass SOTA by ∼ 1 R1 point without the aid of any human-specified aspects or seed words.'}",https://openreview.net{'value': '/attachment/7f15eebf6ae758a03bb491ae2bea13e0c21f17a9.pdf'},{'title_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=9EYS2EEqFq,{'value': 'CAR: Conceptualization-Augmented Reasoner for Zero-Shot Commonsense Question Answering'},Weiqi Wang; Tianqing Fang; Wenxuan Ding; Baixuan Xu; Xin Liu; Yangqiu Song; Antoine Bosselut,~Weiqi_Wang1; ~Tianqing_Fang1; ~Wenxuan_Ding1; ~Baixuan_Xu1; ~Xin_Liu9; ~Yangqiu_Song1; ~Antoine_Bosselut1,"{'value': ['commonsense reasoning', 'conceptualization', 'zero shot', 'question answering']}","{'value': 'The task of zero-shot commonsense question answering evaluates models on their capacity to reason about general scenarios beyond\nthose presented in specific datasets. Existing approaches for tackling this task leverage external knowledge from CommonSense Knowledge Bases (CSKBs) by pre-training the model on synthetic QA pairs constructed from CSKBs. In these approaches, negative examples (distractors) are formulated by randomly sampling from CSKBs using fairly primitive keyword constraints. However, two bottlenecks limit these approaches: the inherent incompleteness of CSKBs limits the semantic coverage of synthetic QA pairs, and the lack of human annotations makes the sampled negative examples potentially uninformative and contradictory. \n\nTo tackle these limitations above, we propose Conceptualization-Augmented Reasoner (CAR), a zero-shot commonsense question-answering framework that fully leverages the power of conceptualization. Specifically, CAR abstracts a commonsense knowledge triple to many higher-level instances, which increases the coverage of the CSKB and expands the ground-truth answer space, reducing the likelihood of selecting false negative distractors. Extensive experiments demonstrate that CAR more robustly generalizes to answering questions about zero-shot \ncommonsense scenarios than existing methods, including large language models, such as GPT3.5 and ChatGPT. Our code, data, and model checkpoints are available at https://github.com/HKUST-KnowComp/CAR.'}",https://openreview.net{'value': '/attachment/3bc13a573a86701ea0ad9b89cb01d276ab02401e.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=8iB0FJmOfV,{'value': 'q2d: Turning Questions into Dialogs to Teach Models How to Search'},Yonatan Bitton; Shlomi Cohen-Ganor; Ido Hakimi; Yoad Lewenberg; Roee Aharoni; Enav Weinreb,~Yonatan_Bitton1; ~Shlomi_Cohen-Ganor1; ~Ido_Hakimi1; ~Yoad_Lewenberg1; ~Roee_Aharoni1; ~Enav_Weinreb1,"{'value': ['Large language models', 'dialog generation', 'query generation', 'external search API', 'synthetic training data', 'QReCC dataset', 'information-seeking dialogs', 'q2d', 'data generation pipeline', 'synthetic dialogs', 'human-generated dialogs', 'grounded responses', 'anaphora', 'outdated information', 'hallucinations', 'factually consistent responses', 'multi-hop QA', 'PaLM']}","{'value': 'One of the exciting capabilities of recent language models for dialog is their ability to independently search for relevant information to ground a given dialog response. However, obtaining training data to teach models how to issue search queries is time and resource consuming.\nIn this work, we propose $q2d$: an automatic data generation pipeline that generates information-seeking dialogs from questions. We prompt a large language model (PaLM) to create conversational versions of question answering datasets, and use it to improve query generation models that communicate with external search APIs to ground dialog responses. Unlike previous approaches which relied on human written dialogs with search queries, our method allows to automatically generate query-based grounded dialogs with better control and scale.\nOur experiments demonstrate that: (1) For query generation on the QReCC dataset, models trained on our synthetically-generated data achieve 90%-97% of the performance of models trained on the human-generated data; (2) We can successfully generate data for training dialog models in new domains without any existing dialog data as demonstrated on the multi-hop MuSiQue and Bamboogle QA datasets. (3) We perform a thorough analysis of the generated dialogs showing that humans find them of high quality and struggle to distinguish them from human-written dialogs.'}",https://openreview.net{'value': '/attachment/40d4666dc5e449ca495e45560518e8d8e0298270.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=8gYRHspcxK,{'value': 'Aligning Large Language Models through Synthetic Feedback'},Sungdong Kim; Sanghwan Bae; Jamin Shin; Soyoung Kang; Donghyun Kwak; Kang Min Yoo; Minjoon Seo,~Sungdong_Kim1; ~Sanghwan_Bae1; ~Jamin_Shin1; ~Soyoung_Kang1; ~Donghyun_Kwak1; ~Kang_Min_Yoo2; ~Minjoon_Seo1,"{'value': ['Alignment Learning', 'Large Language Models']}","{'value': 'Aligning large language models (LLMs) to human values has become increasingly important as it enables sophisticated steering of LLMs. However, it requires significant human demonstrations and feedback or distillation from proprietary LLMs such as ChatGPT.\nIn this work, we propose a novel alignment learning framework with synthetic feedback not dependent on extensive human annotations and proprietary LLMs. First, we perform reward modeling (RM) with synthetic feedback by contrasting responses from vanilla LLMs with various sizes and prompts. Then, we use the RM to simulate high-quality demonstrations to train a supervised policy and further optimize the model with reinforcement learning. Our resulting model, Aligned Language Model with Synthetic Training dataset (ALMoST), outperforms recent open-sourced models, which are trained on the outputs of InstructGPT or human-annotated demonstrations, in alignment benchmarks. In human evaluation, our model is preferred to Alpaca and Dolly-v2, 55.0% and 58.5% of the time, respectively. Further analyses demonstrate the efficacy and importance of synthetic feedback in our framework.'}",https://openreview.net{'value': '/attachment/7b103bbf98a3d6d87c87dfe1e04eaa37354e35fa.pdf'},{'title_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=8LSuy5nNmz,{'value': 'Multilingual Generation and Answering of Questions from Texts and Knowledge Graphs'},Kelvin Han; Claire Gardent,~Kelvin_Han1; ~Claire_Gardent1,"{'value': ['question generation', 'question answering', 'multilinguality', 'multi-modality', 'knowledge bases', 'consistency']}","{'value': 'The ability to bridge Question Generation (QG) and Question Answering (QA) across structured and unstructured modalities has the potential for aiding different NLP applications. One key application is in QA-based methods that have recently been shown to be useful for automatically evaluating Natural Language (NL) texts generated from Knowledge Graphs (KG). While methods have been proposed for QG-QA across these modalities, these efforts have been in English only; in this work, we bring multilinguality (Brazilian Portuguese and Russian) to multimodal (KG and NL) QG-QA. Using synthetic data generation and machine translation to produce QG-QA data that is aligned between graph and text, we are able to train multimodal, multi-task models that can perform multimodal QG and QA in Portuguese and Russian. We show that our approach outperforms a baseline which is derived from previous work on English and adapted to handle these two languages.'}",https://openreview.net{'value': '/attachment/aff7162063aa822f842a996f8989f7a8f618d020.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=7Gy8FXaTv6,{'value': 'CRUSH4SQL: Collective Retrieval Using Schema Hallucination For Text2SQL'},Mayank Kothyari; Dhruva Dhingra; Sunita Sarawagi; Soumen Chakrabarti,~Mayank_Kothyari1; ~Dhruva_Dhingra1; ~Sunita_Sarawagi1; ~Soumen_Chakrabarti1,"{'value': ['Text-to-SQL', 'LLM', 'Retrieval augmentation', 'Query decomposition']}","{'value': 'Existing Text-to-SQL generators require the entire schema to be encoded with the user text.  This is expensive or impractical for large databases with tens of thousands of columns.  Standard dense retrieval techniques are inadequate for schema subsetting of a large structured database, where the correct semantics of retrieval demands that we rank sets of schema elements rather than individual documents. In response, we propose a two-stage process for effective coverage during retrieval.  First, we use an LLM to hallucinate a minimal DB schema that it deems adequate to answer the query.  We use the hallucinated schema to retrieve a subset of the actual schema, by composing the results from multiple dense retrievals. Remarkably, hallucination --- generally considered a nuisance --- turns out to be actually useful as a bridging mechanism. Since no existing benchmarks exist for schema subsetting on large databases, we introduce two benchmarks: (1) A semi-synthetic dataset of 4502 schema elements, by taking a union of schema on the well-known SPIDER dataset, and (2) A real-life benchmark called SocialDB sourced from an actual large data warehouse comprising of 17844 schema elements. We show that our method leads to significantly higher recall than SOTA retrieval-based augmentation methods.'}",https://openreview.net{'value': '/attachment/3ec188f01858186d1687328ebbbc7f239a56edb7.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=7D4TPisEBk,{'value': 'Selective Demonstrations for Cross-domain Text-to-SQL'},Shuaichen Chang; Eric Fosler-Lussier,~Shuaichen_Chang1; ~Eric_Fosler-Lussier1,"{'value': ['text-to-SQL', 'semantic parsing', 'in-context learning']}","{'value': ""Large language models (LLMs) with in-context learning have demonstrated impressive generalization capabilities in the cross-domain text-to-SQL task, without the use of in-domain annotations. However, incorporating in-domain demonstration examples has been found to greatly enhance LLMs' performance. In this paper, we delve into the key factors within in-domain examples that contribute to the improvement and explore whether we can harness these benefits without relying on in-domain annotations. Based on our findings, we propose a demonstration selection framework, ODIS, which utilizes both out-of-domain examples and synthetically generated in-domain examples to construct demonstrations. By retrieving demonstrations from hybrid sources, ODIS leverages the advantages of both, showcasing its effectiveness compared to baseline methods that rely on a single data source. Furthermore, ODIS outperforms state-of-the-art approaches on two cross-domain text-to-SQL datasets, with improvements of 1.1 and 11.8 points in execution accuracy, respectively.""}",https://openreview.net{'value': '/attachment/c12da830c2e5a365b7f6fd62618977b7d9348734.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=4uylA0mUkk,{'value': 'Data Factors for Better Compositional Generalization'},Xiang Zhou; Yichen Jiang; Mohit Bansal,~Xiang_Zhou3; ~Yichen_Jiang1; ~Mohit_Bansal2,"{'value': ['compositional generalization', 'data factors']}","{'value': 'Recent diagnostic datasets on compositional generalization, such as SCAN (Lake and Baroni, 2018) and COGS (Kim and Linzen, 2020), expose severe problems in models trained from scratch on these datasets. However, in contrast to this poor performance, state-of-the-art models trained on larger and more general datasets show better generalization ability. In this work, to reconcile this inconsistency, we conduct an empirical analysis by training Transformer models on a variety of training sets with different data factors, including dataset scale, pattern complexity, example difficulty, etc. First, we show that increased dataset complexity can lead to better generalization behavior on multiple different generalization challenges. To further understand this improvement, we show two axes of the benefit from more complex datasets: they provide more diverse examples so compositional understanding becomes more effective, and they also prevent ungeneralizable memorization of the examples due to reduced example repetition frequency. Finally, we explore how training examples of different difficulty levels influence generalization differently. On synthetic datasets, simple examples invoke stronger compositionality than hard examples do. On larger-scale real language datasets, while hard examples become more important potentially to ensure decent data coverage, a balanced mixture of simple and hard examples manages to induce the strongest generalizability.'}",https://openreview.net{'value': '/attachment/2e1c05c6d64ceec186a53e89ca3656e092b7115d.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=3gdG9upo7e,{'value': 'Generative Table Pre-training Empowers Models for Tabular Prediction'},Tianping Zhang; Shaowen Wang; Shuicheng YAN; Li Jian; Qian Liu,~Tianping_Zhang1; ~Shaowen_Wang3; ~Shuicheng_YAN3; ~Jian_Li2; ~Qian_Liu2,"{'value': ['tabular prediction', 'generative table pre-training']}","{'value': 'Recently, the topic of table pre-training has attracted considerable research interest. However, how to employ table pre-training to boost the performance of tabular prediction remains an open challenge. In this paper, we propose TapTap, the first attempt that leverages table pre-training to empower models for tabular prediction. After pre-training on a large corpus of real-world tabular data, TapTap can generate high-quality synthetic tables to support various applications on tabular data, including privacy protection, low resource regime, missing value imputation, and imbalanced classification. Extensive experiments on $12$ datasets demonstrate that TapTap outperforms a total of $16$ baselines in different scenarios. Meanwhile, it can be easily combined with various backbone models, including LightGBM, Multilayer Perceptron (MLP) and Transformer. Moreover, with the aid of table pre-training, models trained using synthetic data generated by TapTap can even compete with models using the original dataset on half of the experimental datasets, marking a milestone in the development of synthetic tabular data generation. The code and datasets are available at https://github.com/ZhangTP1996/TapTap.'}",https://openreview.net{'value': '/attachment/da83df19feb0191eb11da50a92a35b3b0753926e.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=3Q6LON8y2I,{'value': 'Is ChatGPT Good at Search? Investigating Large Language Models as Re-Ranking Agents'},Weiwei Sun; Lingyong Yan; Xinyu Ma; Shuaiqiang Wang; Pengjie Ren; Zhumin Chen; Dawei Yin; Zhaochun Ren,~Weiwei_Sun9; ~Lingyong_Yan1; ~Xinyu_Ma4; ~Shuaiqiang_Wang2; ~Pengjie_Ren1; ~Zhumin_Chen1; ~Dawei_Yin1; ~Zhaochun_Ren1,"{'value': ['Passage Re-ranking', 'Information Retrieval', 'Large Language Models']}","{'value': ""Large Language Models (LLMs) have demonstrated remarkable zero-shot generalization across various language-related tasks, including search engines. \nHowever, existing work utilizes the generative ability of LLMs for Information Retrieval (IR) rather than direct passage ranking.\nThe discrepancy between the pre-training objectives of LLMs and the ranking objective poses another challenge.\nIn this paper, we first investigate generative LLMs such as ChatGPT and GPT-4 for relevance ranking in IR. Surprisingly, our experiments reveal that properly instructed LLMs can deliver competitive, even superior results to state-of-the-art supervised methods on popular IR benchmarks. \nFurthermore, to address concerns about data contamination of LLMs, we collect a new test set called NovelEval, based on the latest knowledge and aiming to verify the model's ability to rank unknown knowledge. \nFinally, to improve efficiency in real-world applications, we delve into the potential for distilling the ranking capabilities of ChatGPT into small specialized models using a permutation distillation scheme.\nOur evaluation results turn out that a distilled 440M model outperforms a 3B supervised model on the BEIR benchmark.\nThe code to reproduce our results is available at www.github.com/sunnweiwei/RankGPT.""}",https://openreview.net{'value': '/pdf/5e777785606401dbdbb03544916e6637096ef274.pdf'},{'title_filter': 'Agent'},EMNLP,2023,Conference
https://openreview.net/forum?id=3Nq9KRcvx5,{'value': 'DiNeR: A Large Realistic Dataset for Evaluating Compositional Generalization'},Chengang Hu; Xiao Liu; Yansong Feng,~Chengang_Hu1; ~Xiao_Liu19; ~Yansong_Feng1,"{'value': ['compositional generalization', 'dish name recognition', 'large realistic dataset', 'language model evaluation']}","{'value': 'Most of the existing compositional generalization datasets are synthetically-generated, resulting in a lack of natural language variation. While there have been recent attempts to introduce non-synthetic datasets for compositional generalization, they suffer from either limited data scale or a lack of diversity in the forms of combinations. To better investigate compositional generalization with more linguistic phenomena and compositional diversity, we propose the DIsh NamE Recognition (DiNeR) task and create a large realistic Chinese dataset. Given a recipe instruction, models are required to recognize the dish name composed of diverse combinations of food, actions, and flavors. Our dataset consists of 3,811 dishes and 228,114 recipes, and involves plenty of linguistic phenomena such as anaphora, omission and ambiguity. We provide two strong baselines based on T5 and large language models (LLMs). This work contributes a challenging task, baseline methods to tackle the task, and insights into compositional generalization in the context of dish name recognition.'}",https://openreview.net{'value': '/attachment/92307dad9259923b112014c0fe6c9254388db900.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=38k1q1yyCe,{'value': 'Crossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss Weighting'},Emmy Liu; Aditi Chaudhary; Graham Neubig,~Emmy_Liu1; ~Aditi_Chaudhary1; ~Graham_Neubig1,"{'value': ['machine translation', 'idioms', 'multi-word expressions', 'retrieval-based machine translation']}","{'value': 'Idioms are common in everyday language, but often pose a challenge to translators because their meanings do not follow from the meanings of their parts. Despite significant advances, machine translation systems still struggle to translate idiomatic expressions. We provide a simple characterization of idiomatic translation and related issues. This allows us to conduct a synthetic experiment revealing a tipping point at which transformer-based machine translation models correctly default to idiomatic translations. To expand multilingual resources, we compile a dataset of ~4k natural sentences containing idiomatic expressions in French, Finnish, and Japanese. To improve translation of natural idioms, we introduce two straightforward yet effective techniques: the strategic upweighting of training loss on potentially idiomatic sentences, and using retrieval-augmented models. This not only improves the accuracy of a strong pretrained MT model on idiomatic sentences by up to 13\\% in absolute accuracy, but also holds potential benefits for non-idiomatic sentences.'}",https://openreview.net{'value': '/attachment/f5742eeefd5131ba30b8a74c57fd178251bce6ef.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=2WZ4Wp1OSo,{'value': 'Building Multi-domain Dialog State Trackers from Single-domain Dialogs'},Qi Zhu; Zheng Zhang; Xiaoyan Zhu; Minlie Huang,~Qi_Zhu8; ~Zheng_Zhang12; ~Xiaoyan_Zhu1; ~Minlie_Huang1,"{'value': ['dialog state tracking', 'multi-domain dialog', 'conversational query rewrite']}","{'value': 'Existing multi-domain dialog state tracking (DST) models are developed based on multi-domain dialogs, which require significant manual effort to define domain relations and collect data. This process can be challenging and expensive, particularly when numerous domains are involved. In this paper, we propose a divide-and-conquer (DAC) DST paradigm and a multi-domain dialog synthesis framework, which makes building multi-domain DST models from single-domain dialogs possible. The DAC paradigm segments a multi-domain dialog into multiple single-domain dialogs for DST, which makes models generalize better on dialogs involving unseen domain combinations. The multi-domain dialog synthesis framework merges several potentially related single-domain dialogs into one multi-domain dialog and modifies the dialog to simulate domain relations. The synthesized dialogs can help DST models capture the value transfer between domains. Experiments with three representative DST models on two datasets demonstrate the effectiveness of our proposed DAC paradigm and data synthesis framework.'}",https://openreview.net{'value': '/attachment/2b72f7fce04b206f139e3c77a93fb57de3052590.pdf'},{'abstract_filter': 'Data Synthesis'},EMNLP,2023,Conference
https://openreview.net/forum?id=2UJvVc8gnP,{'value': 'Masked Path Modeling for Vision-and-Language Navigation'},Zi-Yi Dou; Feng Gao; Nanyun Peng,~Zi-Yi_Dou1; ~Feng_Gao2; ~Nanyun_Peng1,"{'value': ['Vision-and-Language Navigation', 'Masked Data Modeling']}","{'value': ""Vision-and-language navigation (VLN) agents are trained to navigate in real-world environments based on natural language instructions. A major challenge in VLN is the limited available training data, which hinders the models' ability to generalize effectively. Previous approaches have attempted to alleviate this issue by using external tools to generate pseudo-labeled data or integrating web-scaled image-text pairs during training. However, these methods often rely on automatically-generated or out-of-domain data, leading to challenges such as suboptimal data quality and domain mismatch. In this paper, we introduce a masked path modeling (MPM) objective. MPM pretrains an agent using self-collected data for subsequent navigation tasks, eliminating the need for external tools. Specifically, our method allows the agent to explore navigation environments and record the paths it traverses alongside the corresponding agent actions. Subsequently, we train the agent on this collected data to reconstruct the original action sequence when given a randomly masked subsequence of the original path. This approach enables the agent to accumulate a diverse and substantial dataset, facilitating the connection between visual observations of paths and the agent's actions, which is the foundation of the VLN task. Importantly, the collected data are in-domain, and the training process avoids synthetic data with uncertain quality, addressing previous issues. We conduct experiments on various VLN datasets and demonstrate the applications of MPM across different levels of instruction complexity. Our results exhibit significant improvements in success rates, with enhancements of 1.3\\%, 1.1\\%, and 1.2\\% on the val-unseen split of the Room-to-Room, Room-for-Room, and Room-across-Room datasets, respectively. Additionally, we underscore the adaptability of MPM as well as the potential for additional improvements when the agent is allowed to explore unseen environments prior to testing.""}",https://openreview.net{'value': '/attachment/d8c9feb591eaf721e0ae8979122d3d486fdef994.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=2TtN6DqjWa,{'value': 'Learning Interpretable Style Embeddings via Prompting LLMs'},Ajay Patel; Delip Rao; Ansh Kothary; Kathleen McKeown; Chris Callison-Burch,~Ajay_Patel2; ~Delip_Rao1; ~Ansh_Kothary1; ~Kathleen_McKeown1; ~Chris_Callison-Burch1,"{'value': ['style', 'stylometry', 'representation learning', 'embeddings', 'vectors', 'interpretability', 'prompting', 'llm']}","{'value': 'Style representation learning builds content-independent representations of author style in text. To date, no large dataset of texts with stylometric annotations on a wide range of style dimensions has been compiled, perhaps because the linguistic expertise to perform such annotation would be prohibitively expensive. Therefore, current style representation approaches make use of unsupervised neural methods to disentangle style from content to create style vectors. These approaches, however, result in uninterpretable representations, complicating their usage in downstream applications like authorship attribution where auditing and explainability is critical. In this work, we use prompting to perform stylometry on a large number of texts to generate a synthetic stylometry dataset. We use this synthetic data to then train human-interpretable style representations we call LISA embeddings. We release our synthetic dataset (StyleGenome) and our interpretable style embedding model (LISA) as resources.'}",https://openreview.net{'value': '/attachment/d738c3db9a67f57512a2595ba941b6ef8a3514cb.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=2MXXycs2T6,{'value': 'QADYNAMICS: Training Dynamics-Driven Synthetic QA Diagnostic for Zero-Shot Commonsense Question Answering'},Haochen Shi; Weiqi Wang; Tianqing Fang; Baixuan Xu; Wenxuan Ding; Xin Liu; Yangqiu Song,~Haochen_Shi4; ~Weiqi_Wang1; ~Tianqing_Fang1; ~Baixuan_Xu1; ~Wenxuan_Ding1; ~Xin_Liu9; ~Yangqiu_Song1,"{'value': ['commonsense reasoning', 'question-answering', 'training dynamics', 'zero shot']}","{'value': 'Zero-shot commonsense Question-Answering (QA) requires models to reason about general situations beyond specific benchmarks. State-of-the-art approaches fine-tune language models on QA pairs constructed from CommonSense Knowledge Bases (CSKBs) to equip the models with more commonsense knowledge in a QA context. However, current QA synthesis protocols may introduce noise from the CSKBs and generate ungrammatical questions and false negative options, which impede the model’s ability to generalize. To address these issues, we propose QADYNAMICS, a training dynamics-driven framework for QA diagnostics and refinement. Our approach analyzes the training dynamics of each QA pair at both the question level and option level, discarding machine-detectable artifacts by removing uninformative QA pairs and mislabeled or false-negative options. Extensive experiments demonstrate the effectiveness of our approach, which outperforms all baselines while using only 33% of the synthetic data, even including LLMs such as ChatGPT. Moreover, expert evaluations confirm that our framework significantly improves the quality of QA synthesis. Our code and model checkpoints are available at https://github.com/HKUST-KnowComp/QaDynamics.'}",https://openreview.net{'value': '/attachment/91942333303c18cf5853e9179dc1bfb9b4d65441.pdf'},{'title_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=266rF9DyWk,{'value': 'Automatic Transcription of Handwritten Old Occitan Language'},Esteban Garces Arias; Vallari Pai; Matthias Schöffel; Christian Heumann; Matthias Aßenmacher,~Esteban_Garces_Arias1; ~Vallari_Pai1; ~Matthias_Schöffel1; ~Christian_Heumann1; ~Matthias_Aßenmacher1,"{'value': ['handwritten text recognition', 'low-resource languages', 'transformer', 'computer vision', 'natural language processing']}","{'value': 'While existing neural network-based approaches have shown promising results in Handwritten Text Recognition (HTR) for high-resource languages and standardized/machine-written text, their application to low-resource languages often presents challenges, resulting in reduced effectiveness. In this paper, we propose an innovative HTR approach that leverages the Transformer architecture for recognizing handwritten Old Occitan language. Given the limited availability of data, which comprises only word pairs of graphical variants and lemmas, we develop and rely on elaborate data augmentation techniques for both text and image data. Our model combines a custom-trained Swin image encoder with a BERT text decoder, which we pre-train using a large-scale augmented synthetic data set and fine-tune on the small human-labeled data set. Experimental results reveal that our approach surpasses the performance of current state-of-the-art models for Old Occitan HTR, including open-source Transformer-based models such as a fine-tuned TrOCR and commercial applications like Google Cloud Vision. To nurture further research and development, we make our models, data sets, and code publicly available.'}",https://openreview.net{'value': '/attachment/0c7e2b7deb8ed18877a06585b378035d7edf2aac.pdf'},{'abstract_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=1CaBi9kEng,{'value': 'ScanDL: A Diffusion Model for Generating Synthetic Scanpaths on Texts'},Lena Sophia Bolliger; David Robert Reich; Patrick Haller; Deborah Noemie Jakobi; Paul Prasse; Lena Ann Jäger,~Lena_Sophia_Bolliger1; ~David_Robert_Reich1; ~Patrick_Haller1; ~Deborah_Noemie_Jakobi1; ~Paul_Prasse1; ~Lena_Ann_Jäger1,"{'value': ['scanpath generation', 'eye movements', 'diffusion models', 'computational psycholinguistics', 'deep neural networks', 'transformer', 'eye tracking']}","{'value': ""Eye movements in reading play a crucial role in psycholinguistic research studying the cognitive mechanisms underlying human language processing. More recently, the tight coupling between eye movements and cognition has also been leveraged for language-related machine learning tasks such as the interpretability, enhancement, and pre-training of language models, as well as the inference of reader- and text-specific properties. However,  scarcity of eye movement data and its unavailability at application time poses a major challenge for this line of research. Initially, this problem was tackled by resorting to cognitive models for synthesizing eye movement data. However, for the sole purpose of generating human-like scanpaths, purely data-driven machine-learning-based methods have proven to be more suitable. Following recent advances in adapting diffusion processes to discrete data, we propose ScanDL, a novel discrete sequence-to-sequence diffusion model that generates synthetic scanpaths on texts. By leveraging pre-trained word representations and jointly embedding both the stimulus text and the fixation sequence, our model captures multi-modal interactions between the two inputs. We evaluate ScanDL within- and across-dataset and demonstrate that it significantly outperforms state-of-the-art scanpath generation methods. Finally, we provide an extensive psycholinguistic analysis that underlines the model's ability to exhibit human-like reading behavior. Our implementation is made available at https://github.com/DiLi-Lab/ScanDL.""}",https://openreview.net{'value': '/attachment/a71d667f268d5b1a0eb3d6ad8f8180dddb5a630d.pdf'},{'title_filter': 'Synthetic'},EMNLP,2023,Conference
https://openreview.net/forum?id=0VQImEvjPJ,{'value': 'NormDial: A Comparable Bilingual Synthetic Dialog Dataset for Modeling Social Norm Adherence and Violation'},Oliver Li; Mallika Subramanian; Arkadiy Saakyan; Sky CH-Wang; Smaranda Muresan,~Oliver_Li1; ~Mallika_Subramanian1; ~Arkadiy_Saakyan1; ~Sky_CH-Wang1; ~Smaranda_Muresan3,"{'value': ['social norms', 'resources and evaluation', 'large language models']}","{'value': 'Social norms fundamentally shape interpersonal communication. We present NormDial, a high-quality dyadic dialogue dataset with turn-by-turn annotations of social norm adherences and violations for Chinese and American cultures. Introducing the task of social norm observance detection, our dataset is synthetically generated in both Chinese and English using a human-in-the-loop pipeline by prompting large language models with a small collection of expert-annotated social norms. We show that our generated dialogues are of high quality through human evaluation and further evaluate the performance of existing large language models on this task. Our findings point towards new directions for understanding the nuances of social norms as they manifest in conversational contexts that span across languages and cultures.'}",https://openreview.net{'value': '/attachment/34bc9924b63e6e4b8fb30e8ce72e9c90cff12d82.pdf'},{'title_filter': 'Synthetic'},EMNLP,2023,Conference
